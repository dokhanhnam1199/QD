```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes bins using adaptive scaling, fit, fullness, and exploration, with refined scaling and penalty."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    remaining_capacity = bins_remain_cap - item
    fit_indices = remaining_capacity >= 0

    if np.any(fit_indices):
        # Adaptive scaling based on remaining capacity and item size, emphasizing smaller bins
        scale = np.mean(bins_remain_cap[fit_indices]) + item
        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale)**0.5 / (remaining_capacity[fit_indices] + 1e-9)

        # Add fullness component, favoring bins that will be filled more completely
        fullness = (item / bins_remain_cap[fit_indices])
        priorities[fit_indices] += fullness

        # Dynamic exploration factor, scaled by the number of fit bins and item size
        exploration_factor = min(0.1, 0.01 * np.sum(fit_indices) * item)
        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor

    # Stronger penalty for bins where item doesn't fit, proportional to the overflow
    overflow = np.abs(remaining_capacity[remaining_capacity < 0])
    priorities[remaining_capacity < 0] = -1e9 - overflow * 100

    # Normalize priorities, handling potential negative values more carefully
    if np.sum(priorities) > 0:
        priorities = priorities / np.sum(priorities)
    elif np.sum(priorities) < 0:
         min_priority = np.min(priorities)
         priorities = priorities - min_priority  # Shift to non-negative
         if np.sum(priorities) > 0:
             priorities = priorities / np.sum(priorities)
         else:
             priorities = np.ones_like(priorities) / len(priorities) # All bins equally likely

    return priorities
```
