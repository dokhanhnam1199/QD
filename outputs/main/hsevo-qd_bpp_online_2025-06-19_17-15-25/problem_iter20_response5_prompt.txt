{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins considering fit, remaining capacity, and fragmentation, with adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Prioritize based on how well the item fits (smaller remaining capacity is better)\n        fit_priority = 1 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Prioritize based on fullness (higher fullness is better)\n        fullness_priority = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]\n\n        # Adaptive scaling based on item size and average bin capacity\n        scale = item / (np.mean(bins_remain_cap[fit_indices]) + 1e-9)\n\n        # Combine fit and fullness priorities with adaptive scaling\n        priorities[fit_indices] = (fit_priority * scale + fullness_priority)\n\n        # Dynamic exploration factor, scaled by the number of viable bins and item size\n        exploration_factor = min(0.1, 0.01 * np.sum(fit_indices) * item)\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    # Penalize bins where the item doesn't fit heavily\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure consistent selection behavior\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n          priorities = priorities - np.min(priorities)\n          priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses adaptive scaling, fit, fullness, exploration, and normalization, while the worst uses only log ratios. (2nd best) vs (second worst) reveals a similar pattern: adaptive scaling, fullness, and exploration are superior to a simple fit-based approach. Comparing (1st) vs (2nd), we see the exploration factor calculation differ. Comparing (3rd) vs (4th), we see the 3rd uses more explicit parameters. Comparing (second worst) vs (worst), we see using scaling based on how much empty space left in bin is bad and using the inverse is better; Overall: the better heuristics combine multiple factors like fit, fullness, and exploration, and normalizes the priorities. Adaptive scaling based on the item size and bin capacities improves performance. Introducing randomness helps in exploration. The explicit handling of edge cases, such as normalization, and bins where the item doesn't fit, also contributes to better results.\n- \nOkay, let's refine our approach to self-reflection for designing better heuristics, focusing on practical application and avoiding common pitfalls.\n\nHere's a breakdown:\n\n*   **Keywords:** Multi-faceted Evaluation, Adaptive Prioritization, Guided Randomness, Robustness Testing.\n\n*   **Advice:** Quantify the impact of each factor (fullness, fit, etc.) via performance metrics and use that to inform adaptive prioritization. Test robustness by generating diverse edge cases.\n\n*   **Avoid:** Vague \"considerations\" or \"balance\" without specific implementation details. Avoid over-parameterization without validation on a diverse test suite.\n\n*   **Explanation:** Move beyond simply listing factors. The goal is to design a process of *quantifying* their impact and *dynamically* adjusting the heuristic. Focus on rigorous testing, especially around constraints.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}