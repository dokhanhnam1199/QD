{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on fullness, fit, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices]) # Dynamic scale \n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on a combination of factors, focusing on best fit,\n    penalizing near misses, and adaptively scaling based on item size.  Includes a\n    dynamically adjusted exploration factor.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n    n_bins = len(bins_remain_cap)\n\n    if np.any(fit_indices):\n        # 1. Best Fit Emphasis: Prioritize bins where the item fits best (smallest waste).\n        priorities[fit_indices] = 1.0 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # 2. Penalize Near Misses (Bins that are just too small): Soft constraint handling.\n        near_miss_indices = (remaining_capacity < 0) & (bins_remain_cap >= (item - 0.1 * item)) # within 10% of fitting\n        priorities[near_miss_indices] = -0.5 # Small negative priority; consider if other options exist\n\n        # 3. Adaptive Scaling Based on Item Size: Adjust priority scaling based on the item's relative size.\n        item_size_ratio = item / np.mean(bins_remain_cap[fit_indices]) if np.any(fit_indices) else 0.5  #Ratio of the current item size to average bin capacity.\n        scale_factor = max(0.1, min(1.0, item_size_ratio))  # Clamp to [0.1, 1] to avoid extreme scaling\n        priorities[fit_indices] *= scale_factor\n\n        # 4. Dynamic Exploration:  Introduce randomness that *decreases* as more bins become suitable.\n        #    Fewer suitable bins = more exploration needed.\n        exploration_factor = 0.1 * (1 - (np.sum(fit_indices) / n_bins))  # Scale randomness based on fit ratio\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    else:\n        # If NO bins fit, give a very small non-zero chance to bins which are closest to the required size.\n        closest_bin_index = np.argmin(bins_remain_cap)\n        priorities[closest_bin_index] = 0.0001\n\n    # 5. Bins where the item doesn't fit at all get a very negative priority (unless we're *forced* to use them).\n    priorities[remaining_capacity < 0] = np.where(priorities[remaining_capacity < 0] != -0.5, -1e9, priorities[remaining_capacity < 0])\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    priority_sum = np.sum(priorities)\n    if priority_sum > 0:\n        priorities = priorities / priority_sum\n    elif priority_sum < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities) if np.sum(priorities) > 0 else np.full_like(priorities, 1/len(priorities))\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (14th), we see 1st includes randomness for exploration while 14th doesn't. 1st prioritizes bins based on fullness, fit, adaptive scaling, and randomness while 14th focuses mainly on fullness and fit.\n*   Comparing (8th) vs (14th), we see 8th is better because it has parameters for random component weight and a more complex priority calculation to minimize fragmentation; also uses `division_eps` to avoid division by zero. 14th is simpler but less adaptable.\n*   Comparing (10th) vs (11th), we see 10th has adaptive scaling based on item size, penalizes near misses. 11th only has adaptive scaling based on remaining capacity.\n*   Comparing (20th) vs (18th), we see that 20th penalizes near misses (bins that almost fit), which 18th does not. 20th also includes a dynamic exploration factor scaled based on the number of suitable bins, while 18th uses a fixed exploration noise. 20th includes a fallback strategy when no bins fit.\n*   Comparing (15th) vs (14th), we see 15th provides more parameters to control the heuristic's behavior (e.g., `fit_priority_scale`, `no_fit_priority`, `avoid_zero_division`, `priority_initial_value`), offering greater flexibility and potential for fine-tuning, while 14th uses hardcoded values.\n\nOverall: The better heuristics prioritize bins by considering fullness, fit (remaining capacity), and use adaptive scaling to the item size or remaining capacity, and add a small random component to encourage exploration; normalize priorities, handle edge cases, and provide more parameters to control behavior.\n- \nOkay, let's refine \"Current Self-Reflection\" to build better heuristics. We'll focus on actionable insights and avoid pitfalls.\n\n*   **Keywords:** Multi-faceted evaluation, adaptive scaling, exploration, robust constraints.\n\n*   **Advice:** Design heuristics to intelligently balance multiple factors (e.g., fill level, item fit, wasted space). Use adaptive scaling to dynamically adjust priorities based on remaining capacity or problem context. Strategically inject randomness to diversify solutions.\n\n*   **Avoid:** Sole reliance on raw ratios or overly simplistic metrics. Over-complicating heuristics with too many unvalidated, dynamically adjusted parameters.\n\n*   **Explanation:** Effective heuristics consider multiple aspects of the problem, adapting to the current state and exploring diverse solutions while respecting constraints, leading to improved performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}