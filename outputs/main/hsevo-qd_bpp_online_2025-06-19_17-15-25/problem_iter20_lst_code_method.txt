{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using adaptive scaling, fit, fullness, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity and item size\n        scale = np.mean(bins_remain_cap[fit_indices]) + item\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n\n        # Dynamic exploration factor\n        exploration_factor = min(0.1, 0.01 * np.sum(fit_indices))\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    # Penalize bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins with adaptive scaling, fullness, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity and item size\n        scale = np.mean(bins_remain_cap[fit_indices]) + item\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Dynamic exploration factor\n        exploration_factor = min(0.1, 0.01 * np.sum(fit_indices))\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    # Penalize bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                randomness_strength: float = 0.09055507501984036,\n                no_fit_priority: float = -1668213914.7516727,\n                epsilon: float = 4.1062069920696874e-09) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, adaptive scaling, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on average remaining capacity of bins where the item fits.\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + epsilon)\n\n        # Introduce randomness for exploration.\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * randomness_strength\n\n    # Very low priority to bins where item doesn't fit.\n    priorities[remaining_capacity < 0] = no_fit_priority\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, adaptive scaling, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on average remaining capacity of bins where the item fits.\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Introduce randomness for exploration.\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices]) # Dynamic scale \n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_random_component_weight: float = 0.06363480534447948, not_fit_priority: float = -3127673057.0031824, division_eps: float = 2.258132558622918e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_random_component_weight: Weight of the small random component. Default is 0.01.\n        not_fit_priority: Priority given to bins where the item doesn't fit. Default is -1e9.\n        division_eps: Epsilon value to avoid division by zero. Default is 1e-9.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + division_eps) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * small_random_component_weight\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = not_fit_priority  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_random_component_weight: float = 0.06363480534447948, not_fit_priority: float = -3127673057.0031824, division_eps: float = 2.258132558622918e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_random_component_weight: Weight of the small random component. Default is 0.01.\n        not_fit_priority: Priority given to bins where the item doesn't fit. Default is -1e9.\n        division_eps: Epsilon value to avoid division by zero. Default is 1e-9.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + division_eps) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * small_random_component_weight\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = not_fit_priority  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_random_component_weight: float = 0.06363480534447948, not_fit_priority: float = -3127673057.0031824, division_eps: float = 2.258132558622918e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_random_component_weight: Weight of the small random component. Default is 0.01.\n        not_fit_priority: Priority given to bins where the item doesn't fit. Default is -1e9.\n        division_eps: Epsilon value to avoid division by zero. Default is 1e-9.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + division_eps) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * small_random_component_weight\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = not_fit_priority  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_random_component_weight: float = 0.06363480534447948, not_fit_priority: float = -3127673057.0031824, division_eps: float = 2.258132558622918e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_random_component_weight: Weight of the small random component. Default is 0.01.\n        not_fit_priority: Priority given to bins where the item doesn't fit. Default is -1e9.\n        division_eps: Epsilon value to avoid division by zero. Default is 1e-9.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + division_eps) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * small_random_component_weight\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = not_fit_priority  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a combination of factors, including best fit,\n    fullness, and adaptive scaling, with a focus on balancing exploration and exploitation.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Best-Fit component: Prioritize bins where the remaining capacity is smallest.\n        best_fit_priority = 1 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Fullness component: Prioritize bins that are already relatively full.\n        fullness_priority = (bins_remain_cap[fit_indices].max() - bins_remain_cap[fit_indices]) / (bins_remain_cap[fit_indices].max()+1e-9)\n\n        # Adaptive Scaling: Scale based on item size.  Larger items favor tighter fits.\n        scale = item / bins_remain_cap[fit_indices].mean() if bins_remain_cap[fit_indices].mean() > 0 else item\n        adaptive_priority = scale * best_fit_priority  # Scale best-fit\n\n        # Combine priorities. Use a weighted average to balance fit and fullness.\n        priorities[fit_indices] = 0.6 * adaptive_priority + 0.4 * fullness_priority\n\n        # Introduce more strategic randomness (exploration) proportional to remaining space.\n        exploration_factor = np.random.rand(np.sum(fit_indices)) * (remaining_capacity[fit_indices] / bins_remain_cap[fit_indices].max()) * 0.1\n        priorities[fit_indices] += exploration_factor\n\n    # Bins where the item doesn't fit get a very low priority.\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize only if positive priorities exist\n    if np.any(priorities > 0):\n        priorities[priorities > 0] /= np.sum(priorities[priorities > 0])\n    elif np.any(priorities < 0) and np.all(priorities <=0):\n        priorities = priorities - np.min(priorities)\n        if np.sum(priorities) > 0:\n            priorities = priorities / np.sum(priorities)\n    #Else do nothing: all zeroes or all negative\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fit, fullness, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fit, fullness, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering fit, remaining capacity, and fragmentation, with adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Prioritize based on how well the item fits (smaller remaining capacity is better)\n        fit_priority = 1 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Prioritize based on fullness (higher fullness is better)\n        fullness_priority = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]\n\n        # Adaptive scaling based on item size and average bin capacity\n        scale = item / (np.mean(bins_remain_cap[fit_indices]) + 1e-9)\n\n        # Combine fit and fullness priorities with adaptive scaling\n        priorities[fit_indices] = (fit_priority * scale + fullness_priority)\n\n        # Dynamic exploration factor, scaled by the number of viable bins and item size\n        exploration_factor = min(0.1, 0.01 * np.sum(fit_indices) * item)\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    # Penalize bins where the item doesn't fit heavily\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure consistent selection behavior\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n          priorities = priorities - np.min(priorities)\n          priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                fit_priority_scale: float = 4.80808521021539,\n                no_fit_priority: float = -4449241166.928589,\n                avoid_zero_division: float = 9.480380501898912e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        fit_priority_scale: Scaling factor for the priority of bins where the item fits.\n        no_fit_priority: Priority given to bins where the item doesn't fit.\n        avoid_zero_division: Small value to avoid division by zero.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = fit_priority_scale / (remaining_capacity[fit_indices] + avoid_zero_division)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = no_fit_priority  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering fit, remaining capacity, and fragmentation, with adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Prioritize based on how well the item fits (smaller remaining capacity is better)\n        fit_priority = 1 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Prioritize based on fullness (higher fullness is better)\n        fullness_priority = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]\n\n        # Adaptive scaling based on item size and average bin capacity\n        scale = item / (np.mean(bins_remain_cap[fit_indices]) + 1e-9)\n\n        # Combine fit and fullness priorities with adaptive scaling\n        priorities[fit_indices] = (fit_priority * scale + fullness_priority)\n\n        # Dynamic exploration factor, scaled by the number of viable bins and item size\n        exploration_factor = min(0.1, 0.01 * np.sum(fit_indices) * item)\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    # Penalize bins where the item doesn't fit heavily\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure consistent selection behavior\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n          priorities = priorities - np.min(priorities)\n          priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                fit_priority_scale: float = 7.682424551077083,\n                no_fit_priority: float = -5901544632.397996,\n                avoid_zero_division: float = 7.329912700727891e-09,\n                priority_initial_value: float = 0.40093602976369525) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        fit_priority_scale: Scaling factor for the priority of bins where the item fits.\n        no_fit_priority: Priority given to bins where the item doesn't fit.\n        avoid_zero_division: Small value to avoid division by zero.\n        priority_initial_value: Initial value for the priority array.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, priority_initial_value, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = fit_priority_scale / (remaining_capacity[fit_indices] + avoid_zero_division)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = no_fit_priority  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = 1 / (remaining_capacity[fit_indices] + 1e-9)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                fit_priority_scale: float = 4.80808521021539,\n                no_fit_priority: float = -4449241166.928589,\n                avoid_zero_division: float = 9.480380501898912e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        fit_priority_scale: Scaling factor for the priority of bins where the item fits.\n        no_fit_priority: Priority given to bins where the item doesn't fit.\n        avoid_zero_division: Small value to avoid division by zero.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = fit_priority_scale / (remaining_capacity[fit_indices] + avoid_zero_division)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = no_fit_priority  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}