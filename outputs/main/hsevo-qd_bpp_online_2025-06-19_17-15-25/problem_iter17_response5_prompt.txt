{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on fullness, fit, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices]) # Dynamic scale \n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see that the better heuristic incorporates remaining capacity, fit indices, and normalization, while the worse heuristic uses only item/bin ratios and log ratios.\n*   (2nd best) vs (second worst) shows that the second best also incorporates randomness, normalization, and fit indices. In contrast, the second worst uses a simple division to calculate remaining capacities without considering the item's fit.\n*   Comparing (1st) vs (2nd), both are identical, suggesting that their performance is the same, and likely near optimal given the information available.\n*   (3rd) vs (4th), we see the introduction of configurable parameters (randomness strength, no fit priority, epsilon) in the 4th heuristic. This allows for fine-tuning but doesn't necessarily guarantee better performance without proper parameter setting.\n*   Comparing (second worst) vs (worst), the second worst prioritizes based on remaining capacity and penalizes bins where items don't fit, whereas the worst simply calculates ratios. The normalization in the second worst is also important.\n*   Overall: The superior heuristics integrate fit, fullness (remaining capacity), adaptive scaling, exploration (randomness), and proper normalization of priorities. Penalizing bins where items don't fit is a consistent theme. Adaptive scaling considers the relationship between item size and bin capacity. Simpler heuristics focusing solely on ratios or without normalization tend to perform worse. The best approaches use adaptive scaling based on average bin capacities and a small amount of randomness for exploration.\n- \nOkay, let's redefine \"Current Self-Reflection\" for better heuristic design, focusing on actionable insights and avoiding common pitfalls.\n\nHere's a breakdown to guide the process:\n\n*   **Keywords:** Adaptive scaling, normalization, multi-factor consideration, exploration (randomness), edge cases, configurable parameters, robustness, infeasibility penalties.\n\n*   **Advice:** Focus on dynamically adjusting heuristic priorities based on item sizes, bin capacities, and remaining space. Normalization of priorities makes selection consistent. Rigorously test and tune configurable parameters to avoid overfitting.\n\n*   **Avoid:** Oversimplified calculations, neglecting edge cases and constraints, overly complex dynamically adjusted weights without validation, ignoring infeasible solutions.\n\n*   **Explanation:** The goal is to create heuristics that are both efficient and robust. Adaptive scaling improves adaptability to different problem instances. Normalization ensures fair comparison of priorities. Exploration helps escape local optima. Configurable parameters enable fine-tuning. Proper handling of edge cases ensures reliability.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}