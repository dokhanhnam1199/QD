{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins with adaptive scaling, fullness, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity and item size\n        scale = np.mean(bins_remain_cap[fit_indices]) + item\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Dynamic exploration factor\n        exploration_factor = min(0.1, 0.01 * np.sum(fit_indices))\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    # Penalize bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on fullness, fit, adaptive scaling, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on average remaining capacity of bins where the item fits.\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Introduce randomness for exploration.\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see the best heuristic uses a multi-faceted approach considering fullness, remaining capacity, adaptive scaling based on item size, and an exploration strategy with randomness, while the worst uses a simple logarithmic ratio of item size to bin capacity.\n*   Comparing (2nd best) vs (second worst), they're similar to the (best) and (worst) pair: the second-best includes fullness, remaining capacity, adaptive scaling, and randomness, while the second-worst uses the same logarithmic ratio. This highlights the importance of considering multiple factors versus relying on a single metric.\n*   Comparing (1st) vs (2nd), we see no difference between them. This suggests that their performance might be virtually identical, or the ranking criteria couldn't differentiate them.\n*   Comparing (3rd) vs (4th), the code is identical.\n*   Comparing (second worst) vs (worst), we see that both use the same, very basic logarithmic ratio approach. This confirms the inadequacy of such a simple metric for effective bin packing.\n*   Comparing (16th) vs (17th), (16th) considers best fit, fullness, adaptive scaling based on item size and bin capacity, strategic exploration based on remaining capacity and item size. By contrast, (17th) simply calculates priorities based only on fit and remaining capacity with normalization. This shows more comprehensive heuristics are better.\n*   Comparing (9th) vs (10th), (9th) includes dynamic weights, and considers fullness, remaining capacity, item size, and adaptive randomness; while (10th) only uses fullness, fit, adaptive scaling and fixed random values.\n\nOverall: The better heuristics use a combination of factors such as fullness, remaining capacity, item size, and exploration to decide where to put the items. Adaptive scaling, which adjusts the priority based on the item size and bin characteristics, is a common feature. The inclusion of randomness, particularly when scaled relative to item size or remaining bin capacity, promotes exploration and can help avoid local optima. The poorer heuristics oversimplify the problem, often relying on a single metric like the ratio of item size to bin capacity. The worst heuristics lack normalization and can result in skewed priorities. Robust handling, such as dealing with edge cases where priorities may be negative, and avoiding division by zero, contributes to the robustness of the heuristics.\n- \nOkay, let's redefine \"Current self-reflection\" for improved heuristic design, focusing on actionable insights and avoiding common pitfalls.\n\nHere's a breakdown for effective heuristic design, incorporating your feedback:\n\n*   **Keywords:** Multi-factor, Adaptive Scaling, Controlled Randomness, Normalization, Edge Cases, Validation, Context-Aware.\n*   **Advice:** Combine factors contextually. Adapt parameter scaling dynamically. Use controlled randomness for exploration and normalization. Handle all edge cases. Test the effectiveness thoroughly.\n*   **Avoid:** Oversimplification, overly-complex dynamic adjustments without validation, fixed constants, infeasible solution generation.\n*   **Explanation:** Effective heuristics blend informed choices with exploration, adapting to specific problem characteristics. Rigorous testing is vital.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}