```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes bins based on multiple factors, dynamically adjusting parameters based on context."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    remaining_capacity = bins_remain_cap - item
    fit_indices = remaining_capacity >= 0

    if np.any(fit_indices):
        # Fullness factor: Prioritize bins that are already relatively full
        fullness = (bins_remain_cap[fit_indices].max() - bins_remain_cap[fit_indices]) / bins_remain_cap[fit_indices].max()
        fullness_priority = fullness

        # Remaining capacity factor: Prefer bins with tighter fits but avoid nearly full bins
        remaining_cap_priority = 1.0 / (remaining_capacity[fit_indices] + 0.01)  # Avoid division by zero

        # Combine fullness and remaining capacity.
        combined_priority = fullness_priority + remaining_cap_priority

        # Data-driven adaptive scaling based on item and bin characteristics
        bin_capacity_mean = np.mean(bins_remain_cap[fit_indices])
        item_scale = min(1.0, item / bin_capacity_mean) #Scale relative to the average bin size. Cap at 1 to avoid excessive scaling for large item

        # Contextual Scaling: Dynamically adjust the scale based on item size relative to bin capacity
        scale = bin_capacity_mean * (1 - 0.5 * item_scale)  # Reduce scale for larger items to encourage filling smaller bins first
        priorities[fit_indices] = combined_priority / (scale + 1e-9)  # Adding small value to avoid potential division by zero

        # Calibrated Randomness: Item-size aware and decaying randomness with capacity awareness
        exploration_strength = min(0.1, item / bin_capacity_mean)  # Smaller items relative to bin capacity get more exploration
        exploration_bonus = np.random.rand(np.sum(fit_indices)) * exploration_strength
        priorities[fit_indices] += exploration_bonus

    # Penalize bins where the item doesn't fit heavily
    priorities[remaining_capacity < 0] = -1e9

    # Robust Handling and Normalization
    if np.sum(priorities) > 0:
        priorities = priorities / np.sum(priorities)
    elif np.sum(priorities) < 0:
        min_priority = np.min(priorities)
        priorities = priorities - min_priority
        priorities = priorities / np.sum(priorities) if np.sum(priorities) > 0 else np.zeros_like(priorities) # Handle case where all priorities are very negative after shift

    return priorities
```
