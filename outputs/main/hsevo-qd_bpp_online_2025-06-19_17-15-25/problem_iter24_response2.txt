```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes bins based on a data-driven approach, adaptive scaling, and calibrated randomness."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    remaining_capacity = bins_remain_cap - item
    fit_indices = remaining_capacity >= 0

    if np.any(fit_indices):
        # Calculate fullness for bins where the item fits
        fullness = (bins_remain_cap[fit_indices].max() - bins_remain_cap[fit_indices]) / (bins_remain_cap[fit_indices].max() + 1e-9)  # Avoid division by zero
        fullness_priority = fullness

        # Remaining capacity priority with a softened inverse
        remaining_cap_priority = 1.0 / (remaining_capacity[fit_indices] + 0.05 * np.mean(bins_remain_cap)) #Dynamic offset based on mean

        # Combine fullness and remaining capacity.
        combined_priority = fullness_priority + remaining_cap_priority

        # Data-driven scaling based on item size relative to average bin capacity
        scale = item / (np.mean(bins_remain_cap) + 1e-9)  # Normalize item size
        scaled_priority = combined_priority * np.exp(-scale) # Reduce priority if item is large relative to bin size

        priorities[fit_indices] = scaled_priority

        # Calibrated randomness: Higher for smaller items and emptier bins
        bin_emptiness = 1 - (bins_remain_cap[fit_indices] / bins_remain_cap.max()) # 0 for nearly full, 1 for nearly empty
        exploration_strength = min(0.15, item) * (bin_emptiness + 0.1) # Emptier bins get more exploration, but limit to 0.15
        exploration_bonus = np.random.rand(np.sum(fit_indices)) * exploration_strength
        priorities[fit_indices] += exploration_bonus

    # Penalize bins where the item doesn't fit heavily
    priorities[remaining_capacity < 0] = -1e9

    # Robust normalization: Handle edge cases and avoid NaN
    total_priority = np.sum(priorities)
    if total_priority > 1e-6: # Using a small threshold to avoid potential issues with very small numbers
        priorities = priorities / total_priority
    elif total_priority < -1e-6: # Handle the case where the total priority is significantly negative
        min_priority = np.min(priorities)
        priorities = priorities - min_priority  # Shift to make all priorities non-negative
        total_priority = np.sum(priorities)  # Recalculate the sum
        if total_priority > 1e-6:
            priorities = priorities / total_priority # Normalize
        else:
            priorities = np.ones_like(priorities) / len(priorities) # Distribute evenly if still near zero
    else:
        priorities = np.ones_like(priorities) / len(priorities) #Distribute evenly if the sum is zero.


    return priorities
```
