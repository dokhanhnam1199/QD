import numpy as np
import random
import math
import scipy
import torch
def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                randomness_strength: float = 0.08310735187022673,
                no_fit_priority: float = -1531146965.7332,
                epsilon: float = 2.764240343757514e-09,
                priority_initial_value: float = -0.7156670686902094,
                normalize_positive_threshold: float = -0.9239027948058396,
                normalize_negative_threshold: float = 0.9746200494614701) -> np.ndarray:
    """Prioritizes bins based on fullness, fit, adaptive scaling, and randomness."""
    priorities = np.full_like(bins_remain_cap, priority_initial_value, dtype=float)
    remaining_capacity = bins_remain_cap - item
    fit_indices = remaining_capacity >= 0

    if np.any(fit_indices):
        # Adaptive scaling based on average remaining capacity of bins where the item fits.
        scale = np.mean(bins_remain_cap[fit_indices])
        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + epsilon)

        # Introduce randomness for exploration.
        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * randomness_strength

    # Very low priority to bins where item doesn't fit.
    priorities[remaining_capacity < 0] = no_fit_priority

    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).
    if np.sum(priorities) > normalize_positive_threshold:
        priorities = priorities / np.sum(priorities)
    elif np.sum(priorities) < normalize_negative_threshold:
        priorities = priorities - np.min(priorities)
        priorities = priorities / np.sum(priorities)

    return priorities
