{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, adaptive scaling, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on average remaining capacity of bins where the item fits.\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Introduce randomness for exploration.\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, adaptive scaling, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on average remaining capacity of bins where the item fits.\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Introduce randomness for exploration.\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, adaptive scaling, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on average remaining capacity of bins where the item fits.\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Introduce randomness for exploration.\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices]) # Dynamic scale \n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fullness, fit, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices]) # Dynamic scale \n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_random_component_weight: float = 0.06363480534447948, not_fit_priority: float = -3127673057.0031824, division_eps: float = 2.258132558622918e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_random_component_weight: Weight of the small random component. Default is 0.01.\n        not_fit_priority: Priority given to bins where the item doesn't fit. Default is -1e9.\n        division_eps: Epsilon value to avoid division by zero. Default is 1e-9.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + division_eps) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * small_random_component_weight\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = not_fit_priority  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_random_component_weight: float = 0.06363480534447948, not_fit_priority: float = -3127673057.0031824, division_eps: float = 2.258132558622918e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_random_component_weight: Weight of the small random component. Default is 0.01.\n        not_fit_priority: Priority given to bins where the item doesn't fit. Default is -1e9.\n        division_eps: Epsilon value to avoid division by zero. Default is 1e-9.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + division_eps) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * small_random_component_weight\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = not_fit_priority  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_random_component_weight: float = 0.06363480534447948, not_fit_priority: float = -3127673057.0031824, division_eps: float = 2.258132558622918e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_random_component_weight: Weight of the small random component. Default is 0.01.\n        not_fit_priority: Priority given to bins where the item doesn't fit. Default is -1e9.\n        division_eps: Epsilon value to avoid division by zero. Default is 1e-9.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + division_eps) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * small_random_component_weight\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = not_fit_priority  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on remaining capacity, fit, item size, and bin occupancy, with adaptive scaling and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # 1. Prioritize bins with tighter fit, encouraging better space utilization\n        fit_priority = 1 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # 2. Prioritize bins with higher occupancy (more items already packed), aiming to consolidate packings\n        occupancy_priority = (bins_remain_cap[fit_indices].max() - bins_remain_cap[fit_indices]) / (bins_remain_cap[fit_indices].max()+ 1e-9)\n\n        # 3. Adaptive scaling based on the item size relative to average remaining capacity.  Larger items favor almost full bins\n        scale = np.mean(bins_remain_cap[fit_indices])\n        item_size_priority = (item / (scale + 1e-9)) \n\n        #4. Combine priorities with weights. Dynamically adjust weights based on performance characteristics (omitted for simplicity but crucial in a real-world scenario).\n        alpha, beta, gamma = 0.6, 0.3, 0.1 # Weights can be dynamically tuned. Experiment with different values to improve performance.\n        priorities[fit_indices] = alpha * fit_priority + beta * occupancy_priority + gamma * item_size_priority\n        \n        # 5. Constrained Random Exploration: Add small noise only to promising bins\n        exploration_noise = np.random.rand(np.sum(fit_indices)) * 0.01\n        priorities[fit_indices] += exploration_noise\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n    \n    # Normalize priorities to a probability distribution\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n          priorities = priorities - np.min(priorities)\n          priorities = priorities / np.sum(priorities)\n\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                fit_priority_scale: float = 7.682424551077083,\n                no_fit_priority: float = -5901544632.397996,\n                avoid_zero_division: float = 7.329912700727891e-09,\n                priority_initial_value: float = 0.40093602976369525) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        fit_priority_scale: Scaling factor for the priority of bins where the item fits.\n        no_fit_priority: Priority given to bins where the item doesn't fit.\n        avoid_zero_division: Small value to avoid division by zero.\n        priority_initial_value: Initial value for the priority array.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, priority_initial_value, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = fit_priority_scale / (remaining_capacity[fit_indices] + avoid_zero_division)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = no_fit_priority  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are already relatively full, to reduce fragmentation.\n    It also includes a small random component to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        # Prioritize bins that are already relatively full.  We want to minimize fragmentation.\n        # The smaller the remaining capacity after adding the item, the higher the priority.\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices] + 1 / (remaining_capacity[fit_indices] + 1e-9) # (bins_remain_cap[fit_indices] - remaining_capacity[fit_indices]) / bins_remain_cap[fit_indices]   # Avoid division by zero\n        \n        # Add a small random component to encourage exploration and escape local optima\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9  # Large negative value\n    \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = 1 / (remaining_capacity[fit_indices] + 1e-9)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a combination of factors, focusing on best fit,\n    penalizing near misses, and adaptively scaling based on item size.  Includes a\n    dynamically adjusted exploration factor.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n    n_bins = len(bins_remain_cap)\n\n    if np.any(fit_indices):\n        # 1. Best Fit Emphasis: Prioritize bins where the item fits best (smallest waste).\n        priorities[fit_indices] = 1.0 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # 2. Penalize Near Misses (Bins that are just too small): Soft constraint handling.\n        near_miss_indices = (remaining_capacity < 0) & (bins_remain_cap >= (item - 0.1 * item)) # within 10% of fitting\n        priorities[near_miss_indices] = -0.5 # Small negative priority; consider if other options exist\n\n        # 3. Adaptive Scaling Based on Item Size: Adjust priority scaling based on the item's relative size.\n        item_size_ratio = item / np.mean(bins_remain_cap[fit_indices]) if np.any(fit_indices) else 0.5  #Ratio of the current item size to average bin capacity.\n        scale_factor = max(0.1, min(1.0, item_size_ratio))  # Clamp to [0.1, 1] to avoid extreme scaling\n        priorities[fit_indices] *= scale_factor\n\n        # 4. Dynamic Exploration:  Introduce randomness that *decreases* as more bins become suitable.\n        #    Fewer suitable bins = more exploration needed.\n        exploration_factor = 0.1 * (1 - (np.sum(fit_indices) / n_bins))  # Scale randomness based on fit ratio\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    else:\n        # If NO bins fit, give a very small non-zero chance to bins which are closest to the required size.\n        closest_bin_index = np.argmin(bins_remain_cap)\n        priorities[closest_bin_index] = 0.0001\n\n    # 5. Bins where the item doesn't fit at all get a very negative priority (unless we're *forced* to use them).\n    priorities[remaining_capacity < 0] = np.where(priorities[remaining_capacity < 0] != -0.5, -1e9, priorities[remaining_capacity < 0])\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    priority_sum = np.sum(priorities)\n    if priority_sum > 0:\n        priorities = priorities / priority_sum\n    elif priority_sum < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities) if np.sum(priorities) > 0 else np.full_like(priorities, 1/len(priorities))\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = 1 / (remaining_capacity[fit_indices] + 1e-9)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = 1 / (remaining_capacity[fit_indices] + 1e-9)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a combination of factors, focusing on best fit,\n    penalizing near misses, and adaptively scaling based on item size.  Includes a\n    dynamically adjusted exploration factor.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n    n_bins = len(bins_remain_cap)\n\n    if np.any(fit_indices):\n        # 1. Best Fit Emphasis: Prioritize bins where the item fits best (smallest waste).\n        priorities[fit_indices] = 1.0 / (remaining_capacity[fit_indices] + 1e-9)\n\n        # 2. Penalize Near Misses (Bins that are just too small): Soft constraint handling.\n        near_miss_indices = (remaining_capacity < 0) & (bins_remain_cap >= (item - 0.1 * item)) # within 10% of fitting\n        priorities[near_miss_indices] = -0.5 # Small negative priority; consider if other options exist\n\n        # 3. Adaptive Scaling Based on Item Size: Adjust priority scaling based on the item's relative size.\n        item_size_ratio = item / np.mean(bins_remain_cap[fit_indices]) if np.any(fit_indices) else 0.5  #Ratio of the current item size to average bin capacity.\n        scale_factor = max(0.1, min(1.0, item_size_ratio))  # Clamp to [0.1, 1] to avoid extreme scaling\n        priorities[fit_indices] *= scale_factor\n\n        # 4. Dynamic Exploration:  Introduce randomness that *decreases* as more bins become suitable.\n        #    Fewer suitable bins = more exploration needed.\n        exploration_factor = 0.1 * (1 - (np.sum(fit_indices) / n_bins))  # Scale randomness based on fit ratio\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * exploration_factor\n\n    else:\n        # If NO bins fit, give a very small non-zero chance to bins which are closest to the required size.\n        closest_bin_index = np.argmin(bins_remain_cap)\n        priorities[closest_bin_index] = 0.0001\n\n    # 5. Bins where the item doesn't fit at all get a very negative priority (unless we're *forced* to use them).\n    priorities[remaining_capacity < 0] = np.where(priorities[remaining_capacity < 0] != -0.5, -1e9, priorities[remaining_capacity < 0])\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    priority_sum = np.sum(priorities)\n    if priority_sum > 0:\n        priorities = priorities / priority_sum\n    elif priority_sum < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities) if np.sum(priorities) > 0 else np.full_like(priorities, 1/len(priorities))\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item.\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and leaves minimal waste.\n    fit_indices = remaining_capacity >= 0\n    if np.any(fit_indices):\n        priorities[fit_indices] = 1 / (remaining_capacity[fit_indices] + 1e-9)  # Avoid division by zero\n    \n    # Give a very low priority (or negative) to bins where the item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9  # Large negative value\n        \n    # Normalize the priorities\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n      priorities = priorities - np.min(priorities)\n      priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}