{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on multiple factors, dynamically adjusting parameters based on context.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Fullness factor: Prioritize bins that are already relatively full\n        fullness = (bins_remain_cap[fit_indices].max() - bins_remain_cap[fit_indices]) / bins_remain_cap[fit_indices].max()\n        fullness_priority = fullness\n\n        # Remaining capacity factor: Prefer bins with tighter fits but avoid nearly full bins\n        remaining_cap_priority = 1.0 / (remaining_capacity[fit_indices] + 0.01)  # Avoid division by zero\n\n        # Combine fullness and remaining capacity.\n        combined_priority = fullness_priority + remaining_cap_priority\n\n        # Data-driven adaptive scaling based on item and bin characteristics\n        bin_capacity_mean = np.mean(bins_remain_cap[fit_indices])\n        item_scale = min(1.0, item / bin_capacity_mean) #Scale relative to the average bin size. Cap at 1 to avoid excessive scaling for large item\n\n        # Contextual Scaling: Dynamically adjust the scale based on item size relative to bin capacity\n        scale = bin_capacity_mean * (1 - 0.5 * item_scale)  # Reduce scale for larger items to encourage filling smaller bins first\n        priorities[fit_indices] = combined_priority / (scale + 1e-9)  # Adding small value to avoid potential division by zero\n\n        # Calibrated Randomness: Item-size aware and decaying randomness with capacity awareness\n        exploration_strength = min(0.1, item / bin_capacity_mean)  # Smaller items relative to bin capacity get more exploration\n        exploration_bonus = np.random.rand(np.sum(fit_indices)) * exploration_strength\n        priorities[fit_indices] += exploration_bonus\n\n    # Penalize bins where the item doesn't fit heavily\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Robust Handling and Normalization\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        min_priority = np.min(priorities)\n        priorities = priorities - min_priority\n        priorities = priorities / np.sum(priorities) if np.sum(priorities) > 0 else np.zeros_like(priorities) # Handle case where all priorities are very negative after shift\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see the best heuristic uses a multi-faceted approach considering fullness, remaining capacity, adaptive scaling based on item size, and an exploration strategy with randomness, while the worst uses a simple logarithmic ratio of item size to bin capacity.\n*   Comparing (2nd best) vs (second worst), they're similar to the (best) and (worst) pair: the second-best includes fullness, remaining capacity, adaptive scaling, and randomness, while the second-worst uses the same logarithmic ratio. This highlights the importance of considering multiple factors versus relying on a single metric.\n*   Comparing (1st) vs (2nd), we see no difference between them. This suggests that their performance might be virtually identical, or the ranking criteria couldn't differentiate them.\n*   Comparing (3rd) vs (4th), the code is identical.\n*   Comparing (second worst) vs (worst), we see that both use the same, very basic logarithmic ratio approach. This confirms the inadequacy of such a simple metric for effective bin packing.\n*   Comparing (16th) vs (17th), (16th) considers best fit, fullness, adaptive scaling based on item size and bin capacity, strategic exploration based on remaining capacity and item size. By contrast, (17th) simply calculates priorities based only on fit and remaining capacity with normalization. This shows more comprehensive heuristics are better.\n*   Comparing (9th) vs (10th), (9th) includes dynamic weights, and considers fullness, remaining capacity, item size, and adaptive randomness; while (10th) only uses fullness, fit, adaptive scaling and fixed random values.\n\nOverall: The better heuristics use a combination of factors such as fullness, remaining capacity, item size, and exploration to decide where to put the items. Adaptive scaling, which adjusts the priority based on the item size and bin characteristics, is a common feature. The inclusion of randomness, particularly when scaled relative to item size or remaining bin capacity, promotes exploration and can help avoid local optima. The poorer heuristics oversimplify the problem, often relying on a single metric like the ratio of item size to bin capacity. The worst heuristics lack normalization and can result in skewed priorities. Robust handling, such as dealing with edge cases where priorities may be negative, and avoiding division by zero, contributes to the robustness of the heuristics.\n- \nOkay, let's redefine \"Current self-reflection\" for improved heuristic design, focusing on actionable insights and avoiding common pitfalls.\n\nHere's a breakdown for effective heuristic design, incorporating your feedback:\n\n*   **Keywords:** Multi-factor, Adaptive Scaling, Controlled Randomness, Normalization, Edge Cases, Validation, Context-Aware.\n*   **Advice:** Combine factors contextually. Adapt parameter scaling dynamically. Use controlled randomness for exploration and normalization. Handle all edge cases. Test the effectiveness thoroughly.\n*   **Avoid:** Oversimplification, overly-complex dynamic adjustments without validation, fixed constants, infeasible solution generation.\n*   **Explanation:** Effective heuristics blend informed choices with exploration, adapting to specific problem characteristics. Rigorous testing is vital.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}