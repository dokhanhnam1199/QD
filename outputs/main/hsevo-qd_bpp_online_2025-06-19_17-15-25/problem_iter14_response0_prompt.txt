{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on fullness, fit, adaptive scaling, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on average remaining capacity of bins where the item fits.\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Introduce randomness for exploration.\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit.\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize priorities to ensure they sum to 1 (or handle negative priorities).\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on fit, fullness, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n    fit_indices = remaining_capacity >= 0\n\n    if np.any(fit_indices):\n        # Adaptive scaling based on remaining capacity\n        scale = np.mean(bins_remain_cap[fit_indices])\n        priorities[fit_indices] = (bins_remain_cap[fit_indices] / scale) / (remaining_capacity[fit_indices] + 1e-9)\n\n        # Incorporate some randomness for exploration\n        priorities[fit_indices] += np.random.rand(np.sum(fit_indices)) * 0.01\n\n    # Very low priority to bins where item doesn't fit\n    priorities[remaining_capacity < 0] = -1e9\n\n    # Normalize\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    elif np.sum(priorities) < 0:\n        priorities = priorities - np.min(priorities)\n        priorities = priorities / np.sum(priorities)\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (14th), we see 1st includes randomness for exploration while 14th doesn't. 1st prioritizes bins based on fullness, fit, adaptive scaling, and randomness while 14th focuses mainly on fullness and fit.\n*   Comparing (8th) vs (14th), we see 8th is better because it has parameters for random component weight and a more complex priority calculation to minimize fragmentation; also uses `division_eps` to avoid division by zero. 14th is simpler but less adaptable.\n*   Comparing (10th) vs (11th), we see 10th has adaptive scaling based on item size, penalizes near misses. 11th only has adaptive scaling based on remaining capacity.\n*   Comparing (20th) vs (18th), we see that 20th penalizes near misses (bins that almost fit), which 18th does not. 20th also includes a dynamic exploration factor scaled based on the number of suitable bins, while 18th uses a fixed exploration noise. 20th includes a fallback strategy when no bins fit.\n*   Comparing (15th) vs (14th), we see 15th provides more parameters to control the heuristic's behavior (e.g., `fit_priority_scale`, `no_fit_priority`, `avoid_zero_division`, `priority_initial_value`), offering greater flexibility and potential for fine-tuning, while 14th uses hardcoded values.\n\nOverall: The better heuristics prioritize bins by considering fullness, fit (remaining capacity), and use adaptive scaling to the item size or remaining capacity, and add a small random component to encourage exploration; normalize priorities, handle edge cases, and provide more parameters to control behavior.\n- \nOkay, let's refine \"Current Self-Reflection\" to build better heuristics. We'll focus on actionable insights and avoid pitfalls.\n\n*   **Keywords:** Multi-faceted evaluation, adaptive scaling, exploration, robust constraints.\n\n*   **Advice:** Design heuristics to intelligently balance multiple factors (e.g., fill level, item fit, wasted space). Use adaptive scaling to dynamically adjust priorities based on remaining capacity or problem context. Strategically inject randomness to diversify solutions.\n\n*   **Avoid:** Sole reliance on raw ratios or overly simplistic metrics. Over-complicating heuristics with too many unvalidated, dynamically adjusted parameters.\n\n*   **Explanation:** Effective heuristics consider multiple aspects of the problem, adapting to the current state and exploring diverse solutions while respecting constraints, leading to improved performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}