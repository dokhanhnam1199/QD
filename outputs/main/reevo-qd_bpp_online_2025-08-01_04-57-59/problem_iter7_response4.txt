```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a more aggressive Best Fit-like strategy.

    This version enhances 'priority_v1' by applying a more aggressive, non-linear reward
    for tight and near-perfect fits, further minimizing remaining capacity and fragmentation,
    and maximizing bin utilization. It prioritizes existing bins by making very tight fits
    in them exceptionally attractive.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Bins that cannot fit the item will have a priority score of 0.
        For bins that can fit, a higher score indicates a 'tighter' fit (smaller remaining capacity).
    """
    # Calculate the remaining capacity if the item were to be placed in each bin.
    potential_remaining_space = bins_remain_cap - item

    # Initialize priority scores. Default to 0, meaning no priority or cannot fit.
    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)

    # Create a boolean mask for bins where the item can actually fit (remaining space must be non-negative).
    can_fit_mask = potential_remaining_space >= 0

    # Hyperparameter for aggressive non-linear scaling.
    # A power factor greater than 1 makes the reward for smaller remaining space
    # disproportionately higher, aggressively favoring tighter fits.
    # For example, with power_factor = 2.0, a remaining space of 0.1 gets 1/(0.1^2) = 100,
    # while a remaining space of 0.2 gets 1/(0.2^2) = 25. This creates a much sharper
    # preference for very tight fits compared to a linear inverse.
    power_factor = 2.0

    # Epsilon to prevent division by zero for perfect fits (potential_remaining_space = 0).
    # It also ensures perfect fits get a finite, very large score, making them highly prioritized.
    epsilon = 1e-9

    # Apply the inverse calculation with the power_factor only to the bins where the item fits.
    # This assigns a much higher score to bins where the item fits snugly
    # (potential_remaining_space is small).
    # The term (potential_remaining_space + epsilon) is raised to the power_factor,
    # causing scores to grow much faster as remaining space approaches zero.
    priority_scores[can_fit_mask] = 1.0 / ((potential_remaining_space[can_fit_mask] + epsilon) ** power_factor)

    return priority_scores
```
