```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin,
    implementing an even more aggressive Best Fit heuristic with boosted
    perfect fits and a sharper non-linear penalty reduction for near-perfect fits,
    to further minimize fragmentation.

    This strategy explicitly assigns the highest possible priority to perfect fits.
    For remaining capacities within a defined 'near-perfect' threshold,
    the penalty is drastically reduced using a higher-order polynomial decay (e.g., quartic),
    making these bins extremely desirable. For capacities above the threshold,
    a standard linear Best Fit penalty is applied. This aims to 'trap' items
    even more efficiently and prevent the creation of any unnecessary fragmentation,
    optimizing for the smallest number of bins used.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of current remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher scores indicate a more desirable bin.
    """
    # Initialize all priorities to a very low negative number (effectively -infinity)
    # for bins that cannot accommodate the item.
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Identify bins where the item can fit
    can_fit_mask = bins_remain_cap >= item
    
    # Calculate remaining capacity after fit for eligible bins
    remaining_after_fit_eligible = bins_remain_cap[can_fit_mask] - item

    # Define a threshold for what constitutes a "near-perfect" fit.
    # This threshold assumes items and bin capacities are normalized, e.g., to 1.0.
    # A remaining capacity <= 0.05 (e.g., 5% of a standard bin) is considered near-perfect.
    near_perfect_threshold = 0.05

    # Power factor for the non-linear scaling.
    # A higher power_factor provides a more aggressive incentive for very small
    # remaining capacities. priority_v1 implied cubic (k=3); this uses quartic (k=4).
    power_factor = 4 

    # Temporary array to hold scores for eligible bins, initialized to a base value.
    # This will be populated based on the conditions below.
    current_scores = np.zeros_like(remaining_after_fit_eligible, dtype=float)

    # Condition 1: Perfect fit (remaining_after_fit_eligible == 0)
    # Assign the highest possible priority score (e.g., 1.0) to perfect fits.
    perfect_fit_cond = (remaining_after_fit_eligible == 0)
    current_scores[perfect_fit_cond] = 1.0 

    # Condition 2: Near-perfect fit (0 < r <= near_perfect_threshold)
    # Apply a non-linear (quartic) penalty reduction.
    near_perfect_cond = (remaining_after_fit_eligible > 0) & (remaining_after_fit_eligible <= near_perfect_threshold)
    
    # Calculate scaled remainder: (r^k / T^(k-1))
    # This makes the penalty for small 'r' values much smaller (closer to 0),
    # thus making such bins significantly more attractive.
    scaled_remainder = (
        remaining_after_fit_eligible[near_perfect_cond] ** power_factor
    ) / (near_perfect_threshold ** (power_factor - 1))
    
    current_scores[near_perfect_cond] = -scaled_remainder

    # Condition 3: Other fits (r > near_perfect_threshold)
    # Apply a standard linear Best Fit penalty (negative of remaining capacity).
    other_fits_cond = (remaining_after_fit_eligible > near_perfect_threshold)
    current_scores[other_fits_cond] = -remaining_after_fit_eligible[other_fits_cond]

    # Assign the calculated scores for eligible bins back to the main scores array
    scores[can_fit_mask] = current_scores

    return scores
```
