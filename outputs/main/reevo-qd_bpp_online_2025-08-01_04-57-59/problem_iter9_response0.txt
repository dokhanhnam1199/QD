```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add an item to each bin,
    using a Best Fit-like strategy enhanced with non-linear rewards
    to encourage closing bins and a bias towards existing, partially filled bins.

    This strategy aims to:
    1. Heavily reward 'tight' or 'near-perfect' fits to minimize remaining
       fragmentation and effectively 'close' bins (Best Fit principle).
    2. Favor placing items into bins that are already partially filled,
       encouraging consolidation and higher utilization of existing bins
       before opening new ones or using mostly empty ones.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score for each bin.
        Bins that cannot fit the item will have a priority score of 0.
        For bins that can fit, a higher score indicates a more desirable placement.
    """
    # Calculate the remaining capacity if the item were to be placed in each bin.
    # This value indicates how much space would be left after placing the item.
    potential_remaining_space = bins_remain_cap - item

    # Initialize priority scores. Default to 0, meaning no priority or cannot fit.
    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)

    # Create a boolean mask for bins where the item can actually fit (remaining space must be non-negative).
    can_fit_mask = potential_remaining_space >= 0

    # Define a small positive epsilon to prevent division by zero when calculating
    # inverse values (e.g., for perfect fits or completely empty bins).
    # It also ensures that very small remaining spaces still yield finite, very large scores.
    epsilon = 1e-9

    # Define weights for the two primary components of the priority score.
    # These weights can be tuned to emphasize one aspect over the other.
    # w1: Weight for the "tight fit" component (squared inverse of potential remaining space).
    #     A higher w1 means tighter fits are much more strongly preferred,
    #     aggressively trying to minimize leftover space and 'close' bins.
    w1 = 1.0

    # w2: Weight for the "favor partially filled" component (inverse of current bin remaining capacity).
    #     A higher w2 means bins that are already more utilized (less remaining capacity
    #     before placing the item) are given a stronger bonus. This promotes consolidation.
    w2 = 0.1

    # Calculate priority only for bins where the item can fit.
    if np.any(can_fit_mask):
        # Component 1: Non-linear reward for tight fits (squared inverse of remaining space).
        # Squaring the denominator makes the reward steeply non-linear, meaning small
        # potential remaining spaces receive a disproportionately higher score,
        # thereby strongly incentivizing near-perfect fits and bin closure.
        term1 = 1.0 / (potential_remaining_space[can_fit_mask]**2 + epsilon)

        # Component 2: Reward for already partially filled bins.
        # This term provides a bonus inversely proportional to the *current* remaining capacity
        # of the bin. Bins that are already more full (have less `bins_remain_cap`) will get
        # a higher score from this term, thus biasing placement towards existing, used bins.
        term2 = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)

        # Combine the two weighted terms to get the final priority score for fitting bins.
        priority_scores[can_fit_mask] = w1 * term1 + w2 * term2

    return priority_scores
```
