```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit's tightness preference with a penalty for bins that are too full,
    using a sigmoid to create a nuanced preference.
    """
    # Identify bins that can accommodate the item.
    can_fit_mask = bins_remain_cap >= item
    
    # Initialize priorities to negative infinity for bins that cannot fit.
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # For bins that can fit, calculate a priority score.
    fitting_bins_cap = bins_remain_cap[can_fit_mask]

    # Calculate the remaining capacity after placing the item. This is the "waste".
    # Smaller waste is better (closer to zero).
    waste = fitting_bins_cap - item

    # Use a sigmoid function to prioritize bins with minimal waste.
    # The sigmoid maps smaller waste values to higher priority scores.
    # We invert the waste to make higher values (less waste) correspond to higher sigmoid outputs.
    # A small constant is added to avoid division by zero if waste is exactly zero,
    # and to slightly penalize bins that become completely full.
    # A moderate steepness `k` balances prioritizing minimal waste with avoiding extremely tight fits
    # that might leave no room for future small items.
    k_steepness = 5.0  # Controls how sharply the preference changes around the optimal waste.
    smoothing_factor = 0.1 * item + 1e-6 # Smooths the transition, slightly penalizing zero waste.

    # Calculate the score: higher score for less waste.
    # The term `(waste + smoothing_factor)` aims to create a peak preference
    # slightly above zero waste.
    # `k_steepness * (-(waste + smoothing_factor))` makes the sigmoid decrease as waste increases,
    # and increase as waste decreases towards zero.
    # The inverted sigmoid `1 / (1 + exp(k * x))` gives higher values for smaller x.
    # So, we want `x` to be small for low waste.
    # Let's use `-(waste + smoothing_factor)` as the argument to sigmoid.
    # A higher score will come from smaller `waste + smoothing_factor`.
    
    # The expression `1 / (1 + np.exp(k_steepness * (-(waste + smoothing_factor))))`
    # can be simplified to `1 / (1 + np.exp(-k_steepness * (waste + smoothing_factor)))`
    # This sigmoid will output values close to 1 for small `waste + smoothing_factor`
    # and values close to 0 for large `waste + smoothing_factor`.
    
    scores = 1 / (1 + np.exp(-k_steepness * (waste + smoothing_factor)))

    # Assign these calculated scores to the priorities of the fitting bins.
    priorities[can_fit_mask] = scores

    return priorities
```
