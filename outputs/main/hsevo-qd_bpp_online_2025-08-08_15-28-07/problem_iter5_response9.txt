```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines Best Fit with a sigmoid penalty for overly empty bins.

    Prioritizes bins that offer the tightest fit, while slightly penalizing
    bins that are excessively under-filled, aiming for a balanced approach.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities # No bin can fit the item

    fit_diff = bins_remain_cap[can_fit_mask] - item
    
    # Primary score: Sigmoid of negative fit difference (favors tight fits)
    # The closer fit_diff is to 0, the higher the score.
    # Using negative fit_diff maps 0 to 0 for sigmoid, so we shift it.
    # Let z = -fit_diff. Sigmoid(z) peaks at z=0 (fit_diff=0).
    # We want to penalize small fit_diff (very tight) and large fit_diff (too empty).
    # Let's focus on minimizing waste (fit_diff).
    # A common approach for preference around 0 is exp(-k * abs(value)).
    # To use sigmoid, we can map fit_diff to a value where preference is high.
    # Let's use a sigmoid that is high for small positive fit_diff.
    # sigmoid(k * (target - value)) where target is the ideal fit_diff (close to 0).
    # Let target_fit_diff = 0.1 * item (a small slack)
    target_fit_diff = 0.1 * item + 1e-9 # Add small epsilon for stability
    
    # Score component 1: Prioritize bins with minimal positive remaining capacity.
    # We want to maximize the score when `fit_diff` is small and positive.
    # Use sigmoid on `target_fit_diff - fit_diff`.
    # This will be high when `fit_diff` is close to `target_fit_diff`.
    k_tightness = 10.0 # Controls sensitivity to tightness
    tightness_score = 1 / (1 + np.exp(-k_tightness * (target_fit_diff - fit_diff)))

    # Score component 2: Penalize bins that are excessively empty.
    # Bins with large `fit_diff` are less desirable.
    # Use sigmoid to give a lower score to large `fit_diff`.
    # sigmoid(k * (target - value)) where target is large. Or sigmoid(-k * (value - target)).
    # Let's use a sigmoid that penalizes large `fit_diff` values.
    # sigmoid(-k * fit_diff) will be low for large positive fit_diff.
    k_emptiness_penalty = 3.0 # Controls sensitivity to being too empty
    emptiness_penalty_score = 1 / (1 + np.exp(k_emptiness_penalty * fit_diff))

    # Combine scores: Primarily favor tightness, secondarily penalize emptiness.
    # Multiplying ensures that if either score is low (e.g., very empty bin),
    # the overall priority is low.
    combined_score = tightness_score * emptiness_penalty_score
    
    priorities[can_fit_mask] = combined_score

    return priorities
```
