```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Sigmoid Fit Score.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # We want bins that are a good fit but not too tight.
    # A sigmoid function can model this preference: high score for medium-tightness.
    # The "center" of the sigmoid should ideally be related to the item size itself,
    # aiming for bins that are slightly larger than the item.
    # Let's use a scaling factor that inversely relates to the item size,
    # pushing the sigmoid's steep part towards bins with remaining capacity close to item size.

    # Avoid division by zero or extremely small capacities that would lead to huge k values.
    # Also, prevent k from becoming excessively large for very small items.
    safe_bins_remain_cap = np.maximum(bins_remain_cap, 1e-9)

    # We want to prioritize bins where remaining capacity is "just right" for the item.
    # This means remaining capacity slightly larger than the item.
    # The sigmoid function is suitable here:
    # - For bins much larger than item, the sigmoid should approach 1.
    # - For bins much smaller than item, the sigmoid should approach 0.
    # - For bins with remaining capacity close to item size, we want a high score.

    # Let's consider a "sweet spot" for remaining capacity as `item * (1 + margin)`
    # where `margin` is a small positive value (e.g., 0.1 for 10% overhead).
    # This is where we want the sigmoid to peak.

    # A common form of sigmoid is 1 / (1 + exp(-k * (x - x0))).
    # Here, x is the "fit quality", and we want the peak at a specific fit.
    # Let's define "fit quality" as remaining_capacity / item_size.
    # We want the peak when remaining_capacity / item_size is slightly > 1.
    # So, let's say our peak is at remaining_capacity / item_size = 1.2.
    # This means x0 = 1.2.

    # The steepness 'k' can be influenced by how selective we are.
    # A larger 'k' means a sharper peak.
    # We can make 'k' dependent on the item size itself, such that smaller items
    # are more flexible in their bin choices (lower k), while larger items
    # require more precise fits (higher k). Or, the other way around: larger items
    # have fewer fitting bins, so we want to be more aggressive in picking a good one.

    # Let's try to make the "good fit" region centered around the item size.
    # Bins that are too full (remaining_cap < item) should have a very low priority.
    # Bins that are very empty (remaining_cap >> item) should have a medium-high priority,
    # as they offer flexibility for future items.
    # Bins where remaining_cap is slightly larger than item should have the highest priority.

    # Let's use the sigmoid to model the "how well does this bin accept the item
    # without being too empty or too full".

    # Consider the ratio `bins_remain_cap / item`.
    # If item is 0, this is problematic. Handle this case.
    if item < 1e-9:
        # If the item is negligible, any bin is a good fit.
        # Prioritize bins with less remaining capacity to consolidate.
        # But to keep it within the sigmoid idea, let's just give them a high score.
        # Or maybe prioritize less filled bins to encourage spreading out.
        # For this problem, if item is zero, we don't need to place it. Let's return zeros or a very small value.
        return np.zeros_like(bins_remain_cap)

    ratios = bins_remain_cap / item

    # We want a peak when ratio is slightly greater than 1.
    # Let's aim for a peak around ratio = 1.2 (meaning bin is 20% larger than item).
    x0 = 1.2

    # Steepness factor k. We want a higher score for ratios closer to x0.
    # Let's try to make k inversely proportional to item size: smaller items are more flexible.
    # Or, more directly, let's make k related to how tightly we want to pack.
    # A simple sigmoid: 1 / (1 + exp(-k * (ratios - x0)))
    # This function will be near 0 for ratios < x0 and near 1 for ratios > x0.
    # We want the opposite: high score for ratios close to x0.
    # So let's use: exp(-k * abs(ratios - x0))
    # Or a sigmoid where the center is x0 and it decays away from it.
    # A Gaussian-like shape could work: exp(- (ratios - x0)^2 / (2 * sigma^2))
    # But we are asked to use Sigmoid Fit Score strategy.

    # Let's use a sigmoid that peaks at x0 and decays on both sides.
    # This can be achieved by combining two sigmoids or using a logistic function with a central shift.
    # A simpler approach is to use the sigmoid's property of mapping to [0, 1] and
    # transform it.

    # Let's use a standard sigmoid: sigmoid(z) = 1 / (1 + exp(-z)).
    # We want higher values when `ratios` is close to `x0`.
    # Let's map `ratios` to `z` such that `z=0` when `ratios=x0`.
    # `z = -k * (ratios - x0)`.

    # The steepness 'k' can be tuned. Let's try to make it moderate.
    # A fixed k might be too sensitive. Let's try a k that adapts a bit.
    # For example, k could be related to the average bin fill ratio across all bins.
    # For now, let's pick a reasonable fixed k.
    k = 5.0 # Controls the steepness of the sigmoid. Higher k means a sharper peak.

    # Calculate the sigmoid value. This will be close to 0 for ratios < x0 and close to 1 for ratios > x0.
    # We want the opposite: low priority for ratios too small, high for ratios around x0,
    # and medium-high for ratios much larger than x0 (to keep them as fallback).
    # This suggests we are looking for bins that are 'just right'.

    # Let's consider the "distance" from the ideal ratio `x0`.
    # We want bins where `ratios` is close to `x0`.
    # Let's re-center the sigmoid: `1 / (1 + exp(-k * (ratios - x0)))`
    # This gives higher values for larger ratios.

    # We want bins that are NOT too full (ratio >= 1).
    # Bins with ratio < 1 should have zero priority.
    # Bins with ratio >= 1, we want to prioritize those closest to `x0`.

    # Let's define a function that is high around `x0` and decreases away.
    # Option 1: Logistic "bump" function: `1 / (1 + exp(k * (ratios - x0))) * 1 / (1 + exp(-k * (ratios - x0)))`
    # This is effectively `sech^2(k * (ratios - x0) / 2)`. This is Gaussian-like.

    # Option 2: Two-sided sigmoid approach.
    # If `ratios < x0`, we want priority to increase as `ratios` increases.
    # If `ratios > x0`, we want priority to decrease as `ratios` increases.

    # Let's try mapping the ratio to a value that we can then apply a sigmoid to.
    # We want the "best" fit to be around `item` capacity.
    # Consider the "slack" in the bin: `bins_remain_cap - item`.
    # We want slack to be small but positive.

    # Let's try a sigmoid that models "how suitable" a bin is.
    # For bins with `bins_remain_cap < item`, they are unsuitable. Priority = 0.
    # For bins with `bins_remain_cap >= item`, they are suitable to some degree.
    # Let's focus on `bins_remain_cap >= item`.
    # We want to give higher scores to bins with `bins_remain_cap` closer to `item`.
    # But also, bins with slightly more capacity than `item` might be better than exact fits.

    # Let's use the original item size `item` as the reference.
    # And `bins_remain_cap` as the actual remaining capacity.
    # We are looking for bins where `bins_remain_cap` is "just enough" but not too much.

    # Let `ideal_cap = item * 1.1` (a bit more than the item itself).
    # And `slack = bins_remain_cap - ideal_cap`.
    # We want to maximize the sigmoid of `-slack`. This means small positive slack is best.

    # To use the sigmoid fitting strategy, we need to map our 'quality' metric
    # to an argument for the sigmoid function.
    # Let's use the ratio `bins_remain_cap / item`.
    # We want to prioritize bins where this ratio is close to 1.0 to 1.2.
    # Let `x = bins_remain_cap / item`.
    # Let's use a sigmoid function of the form `1 / (1 + exp(-k * (x - x0)))`.
    # If we want higher values for `x` around `x0`, this standard sigmoid is problematic.

    # Let's reframe: A good bin is one that accepts the item AND leaves a "good" amount of space.
    # "Good" space is relative to the item.

    # Consider a scoring function that rewards bins that are not too full and not too empty.
    # Bins that cannot fit the item get a score of 0.
    can_fit = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # For bins that can fit the item, let's compute a score based on remaining capacity.
    # We want remaining capacity slightly larger than `item`.
    # Let's define a "target remaining capacity" `target_rc`.
    # A reasonable target is `item * 1.2`.
    target_rc = item * 1.2

    # The difference from the target: `bins_remain_cap[can_fit] - target_rc`
    # We want this difference to be close to 0.
    # Let's map this difference using a sigmoid that peaks at 0.
    # `1 / (1 + exp(-k * (-difference)))` which is `1 / (1 + exp(k * difference))`.
    # This function is high when `difference` is negative (i.e., `bins_remain_cap` is less than `target_rc`).
    # And low when `difference` is positive. This is the opposite of what we want.

    # We want a function that is high when `difference` is near 0.
    # So, let's consider `exp(-k * (difference)^2)` which is Gaussian.
    # But we need a sigmoid.

    # Let's go back to the ratio `ratios = bins_remain_cap / item`.
    # Target ratio `x0 = 1.2`.
    # We want values close to `x0` to have high priority.
    # Let's try a sigmoid which increases towards `x0` and then decreases after `x0`.
    # This can be seen as `sigmoid(k * (ratios - x0))` where `k` is negative for the decreasing part.
    # This implies `sigmoid_part1 = 1 / (1 + exp(-k1 * (ratios - x0)))` and
    # `sigmoid_part2 = 1 / (1 + exp(k2 * (ratios - x0)))`.
    # Then combine them: `score = sigmoid_part1 * sigmoid_part2`.
    # For a symmetric peak, k1=k2. Let k1 = k2 = k.
    # `score = (1 / (1 + exp(-k * (ratios - x0)))) * (1 / (1 + exp(k * (ratios - x0))))`
    # `score = 1 / ((1 + exp(-k * (ratios - x0))) * (1 + exp(k * (ratios - x0))))`
    # `score = 1 / (1 + exp(-k*(ratios-x0)) + exp(k*(ratios-x0)) + 1)`
    # `score = 1 / (2 + 2 * cosh(k * (ratios - x0)))`
    # This is proportional to `sech^2`.

    # Let's simplify. We want bins that are "just right".
    # bins_remain_cap is the remaining capacity. `item` is the item size.
    # The "fit" can be measured by `bins_remain_cap - item`.
    # We want this difference to be small and positive.

    # Let's define `fit_metric = bins_remain_cap / item`.
    # Target `x0 = 1.2`.
    # Sigmoid: `S(z) = 1 / (1 + exp(-z))`
    # We want high score for `fit_metric` near `x0`.

    # Let's try to model "fit goodness" with a sigmoid.
    # A bin that's too full has a negative value. A bin that's perfectly full has a zero value.
    # A bin that's just right has a small positive value.
    # A bin that's too empty has a large positive value.

    # Let's consider the "filling ratio" if the item is placed: `(bins_remain_cap - item) / bins_remain_cap_initial`.
    # This is tricky as initial capacity isn't given directly in this function.

    # Let's use the remaining capacity and item size directly.
    # A bin is "good" if `bins_remain_cap >= item`.
    # Among these, we want those where `bins_remain_cap` is closest to `item`.

    # Sigmoid strategy implies using `1 / (1 + exp(-x))` or its variants.
    # We want to map our "goodness" measure to `x`.
    # Let's define a "desirability" score:
    # Bins that cannot fit the item get score 0.
    # For bins that can fit (`bins_remain_cap >= item`):
    # We want higher scores for `bins_remain_cap` closer to `item`.
    # Let `distance_from_ideal = bins_remain_cap - item`.
    # We want to minimize this distance.
    # Let's map `distance_from_ideal` to `z` for a sigmoid.

    # Let's try to get a score that is high for `bins_remain_cap` slightly greater than `item`.
    # Consider `score = 1 / (1 + exp(-k * (bins_remain_cap - item)))`.
    # This score increases with `bins_remain_cap`. This favors larger bins.
    # We need to penalize bins that are too large.

    # Let's use the ratio again: `ratios = bins_remain_cap / item`.
    # Target `x0 = 1.2`.
    # Let's consider the "excess capacity ratio": `excess_ratio = (bins_remain_cap - item) / item`.
    # We want `excess_ratio` to be small and positive.
    # Let `y = excess_ratio`. We want peak at `y` near 0.2 (which corresponds to ratio 1.2).
    # A sigmoid that peaks around a value and decreases symmetrically is difficult with a single sigmoid.

    # Let's try a simple sigmoid interpretation that captures "goodness of fit".
    # The sigmoid function is monotonic. So we can use it to express "how likely is this to be a good fit".
    # A common approach is to map a "quality" to the argument of the sigmoid.

    # Let's consider bins where `bins_remain_cap >= item`.
    # For these bins, let's define a "fit quality" `f`.
    # We want `f` to be higher when `bins_remain_cap` is closer to `item`.
    # Let's use the ratio `ratios = bins_remain_cap / item`.
    # We want higher scores for `ratios` around `1.0` to `1.2`.

    # Let's use `score = 1 / (1 + exp(-k * (ratios - x0)))`.
    # This score increases with `ratios`. So it favors larger remaining capacities.
    # To favor bins that are "just right", we need a score that drops for larger capacities.

    # Consider a "penalty" for being too empty: `penalty_empty = max(0, item - bins_remain_cap)`.
    # Consider a "penalty" for being too full (but still fits): `penalty_full = max(0, bins_remain_cap - item * 1.2)`.
    # We want to minimize penalties.

    # Let's use the Sigmoid Fit Score as a measure of "how well does this bin 'fit' the item
    # in a way that's optimal for future packing."
    # The ideal scenario is a bin that is *almost* full, but not quite.
    # Let's consider bins that have remaining capacity `c`.
    # We are placing an item of size `i`.
    # A bin is a potential candidate if `c >= i`.
    # Among these, we want bins where `c` is "just enough" but not excessively large.

    # Let's use the ratio `c / i`.
    # Target ratio `x0 = 1.2` (meaning bin has 20% spare capacity).
    # A standard sigmoid `S(z) = 1 / (1 + exp(-z))` is increasing.
    # If we use `z = k * (c/i - x0)`, then score increases as `c/i` increases.
    # This isn't quite right, as it rewards large remaining capacities.

    # Let's consider the complement of the standard sigmoid for the "decreasing" part.
    # `1 - S(z) = exp(-z) / (1 + exp(-z))`. This is decreasing.
    # If we want a peak, we can combine two sigmoids:
    # `Score = S(k * (c/i - x0)) * (1 - S(k * (c/i - x0)))` -- this is Gaussian-like.

    # Let's consider a simpler interpretation of "Sigmoid Fit Score".
    # We want to prioritize bins that are not too full and not too empty.
    # Let's define a "tightness score":
    # `tightness = bins_remain_cap / item`
    # We want tightness to be around `1.0` to `1.2`.
    # Let `ideal_tightness = 1.1`.
    # `z = k * (tightness - ideal_tightness)`
    # A score like `1 / (1 + exp(-z))` favors higher tightness.

    # Let's consider the "waste": `waste = bins_remain_cap - item`.
    # We want waste to be small and positive.
    # Let `waste_score = exp(-k * waste)`. This favors smaller waste.
    # This isn't a sigmoid-fit score though.

    # Let's use a Sigmoid to represent "how well does this bin perform IF it fits".
    # A bin that is too full has poor performance.
    # A bin that is very empty also has poor performance (wasted space).
    # The best performance is for bins that are "just right".

    # Let `r = bins_remain_cap / item`.
    # We want a high score for `r` around `1.0` to `1.2`.
    # Let's use `x0 = 1.1` as the center of our preference.
    # Consider `sigmoid_up = 1 / (1 + np.exp(-k * (r - x0)))`. This increases with `r`.
    # Consider `sigmoid_down = 1 / (1 + np.exp(k * (r - x0)))`. This decreases with `r`.
    # A product could give a peak: `score = sigmoid_up * sigmoid_down`.
    # This would be `1 / (2 + exp(k*(r-x0)) + exp(-k*(r-x0)))`.

    # Let's consider bins that are too small first.
    can_fit_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # For bins that can fit, let's calculate their suitability score.
    # Suitability should be higher for bins with remaining capacity closer to `item`,
    # but slightly larger.
    # Let the target remaining capacity be `target = item * 1.2`.
    target_capacity = item * 1.2

    # We want to maximize a score related to `target_capacity - bins_remain_cap`.
    # Specifically, we want a high score when `target_capacity - bins_remain_cap` is near 0.
    # This is essentially `bins_remain_cap - target_capacity`. We want this to be near 0.
    # Let `diff = bins_remain_cap[can_fit_mask] - target_capacity`
    # We want a function that is high for `diff` near 0.
    # Let's use `f(diff) = 1 / (1 + exp(-k * diff))`. This peaks at 0 and is decreasing.
    # No, this peaks at 0 and is INCREASING. `1 / (1 + exp(-z))`.
    # `f(z) = 1 / (1 + exp(-z))` means `f` increases with `z`. So if `z = k * diff`, `f` increases with `diff`.
    # This means it favors bins that are LARGER than the target.

    # Let's use `z = k * (target_capacity - bins_remain_cap[can_fit_mask])`.
    # Then `f(z) = 1 / (1 + exp(-z))` will be high when `target_capacity - bins_remain_cap` is positive and large.
    # This favors bins that are SMALLER than the target.

    # We need a function that is high when `bins_remain_cap` is NEAR `target_capacity`.
    # A sigmoid centered at the target capacity is needed for the "goodness".

    # Let's try using `sigmoid(k * (bin_capacity - item))` to favor bins that are not too small.
    # And `sigmoid(k * (item * 1.5 - bin_capacity))` to favor bins that are not too large.
    # Let `target_peak = item * 1.1`.
    # We can use the ratio `r = bins_remain_cap / item`.
    # We want to score bins where `r` is near `1.0` to `1.2`.

    # Consider a metric: how "close" is `bins_remain_cap` to `item`?
    # `distance = abs(bins_remain_cap - item)`
    # We want to minimize this distance for bins that can fit.

    # Let's use the sigmoid function directly to represent the desirability of remaining capacity.
    # For a bin to be desirable, it should have capacity `c` such that `item <= c <= item * some_factor`.
    # Let the factor be `F = 1.5`. So we prefer `item <= c <= 1.5 * item`.
    # `ratios = bins_remain_cap / item`. We prefer `1.0 <= ratios <= 1.5`.

    # Sigmoid form: `1 / (1 + exp(-k * x))`
    # If we want a score that peaks, it means it increases and then decreases.
    # Let `ideal_ratio = 1.1`.
    # Let `k = 5.0` (controls steepness).

    # Consider the "goodness" metric: `goodness = bins_remain_cap / item`.
    # We want to give a higher score to values close to `1.1`.
    # Let `z = k * (goodness - 1.1)`.
    # We want the sigmoid function to evaluate to something high when `z` is close to `0`.
    # The function `1 / (1 + exp(-z))` increases as `z` increases.
    # To get a peak, we need a function that increases and then decreases.
    # This can be achieved by multiplying two sigmoids, or using a bell-shaped curve.
    # A common approach to get a peak using sigmoids is:
    # `score = Sigmoid(k1 * (value - center1)) * Sigmoid(-k2 * (value - center2))`
    # For a symmetric peak, center1 = center2 = `ideal_value`, and `k1 = k2 = k`.
    # `score = Sigmoid(k * (value - ideal_value)) * Sigmoid(-k * (value - ideal_value))`
    # `score = [1 / (1 + exp(-k*(value - ideal_value)))] * [1 / (1 + exp(k*(value - ideal_value)))]`

    # Let's apply this:
    # `value = bins_remain_cap / item`
    # `ideal_value = 1.1` (meaning we prefer bins with 10% more capacity than the item)
    # `k = 5.0` (controls how sharp the peak is)

    # First, handle cases where `item` is zero or negative (although problem implies positive sizes).
    if item <= 1e-9:
        # If item size is negligible, all bins are equally suitable.
        # Prioritize bins with less remaining capacity to encourage packing tighter.
        # A simple approach is to return the inverse of remaining capacity, normalized.
        # Or just return a flat score, as any bin will do.
        # For consistency with the sigmoid idea, let's give a high score to less filled bins.
        # Let's return a score based on how much capacity is LEFT, inversely.
        # The flatter the capacity, the better it is for future items.
        # So, a higher score for bins with LESS remaining capacity.
        # We want a high score for smaller `bins_remain_cap`.
        # Let's use sigmoid `1 / (1 + exp(-k * (-bins_remain_cap)))` which is `1 / (1 + exp(k * bins_remain_cap))`.
        # This decreases with `bins_remain_cap`. So we need the inverse: `1 - 1 / (1 + exp(k * bins_remain_cap))`
        # which is `exp(k * bins_remain_cap) / (1 + exp(k * bins_remain_cap))`. This increases with capacity.
        # We want to prioritize LESS capacity.
        # Let's use sigmoid on inverse capacity: `1 / (1 + exp(-k * (-bins_remain_cap)))` where `k` is positive.
        # So, `1 / (1 + exp(k * bins_remain_cap))`.
        # To prioritize LESS remaining capacity, we want this score to be HIGH for small bins_remain_cap.
        # The function `1 / (1 + exp(k * x))` decreases with x. So this works.
        # However, we are trying to PACK an item. If item is 0, it doesn't need packing.
        # Let's return zeros, or perhaps a preference for the most empty bins to leave room for larger items.
        # For the problem statement (packing an item), a zero item doesn't need placing.
        # However, if we interpret it as "if there's a zero item, which bin is most 'optimal' to put it in",
        # it might be the least filled bin.
        # Let's return a score that is higher for bins with less remaining capacity.
        # `priorities = 1.0 - bins_remain_cap / np.max(bins_remain_cap)` is simple, but not sigmoid.
        # `priorities = 1 / (1 + np.exp(5 * bins_remain_cap))`. This decreases as capacity increases.
        # Let's just return a constant high value, indicating all are equally good for a null item.
        return np.ones_like(bins_remain_cap) * 0.5 # Mid-range preference, not too full, not too empty.

    ratios = bins_remain_cap / item
    ideal_ratio = 1.1  # Target: bin capacity should be 1.1 times the item size.
    k = 5.0          # Steepness parameter for the sigmoid.

    # Calculate the first sigmoid component: favors ratios less than or equal to ideal_ratio.
    # `sigmoid_up = 1 / (1 + exp(-k * (ratios - ideal_ratio)))`
    # This score is high when `ratios - ideal_ratio` is positive, i.e., ratios > ideal_ratio.
    # We want high score when `ratios` is NOT too large.
    # So, let's use `1 - sigmoid(k * (ratios - ideal_ratio))`
    # which is `exp(-k * (ratios - ideal_ratio)) / (1 + exp(-k * (ratios - ideal_ratio)))`.
    # This is `sigmoid(-k * (ratios - ideal_ratio))`.
    sigmoid_part1 = 1 / (1 + np.exp(-k * (ratios - ideal_ratio))) # High for ratios > ideal_ratio

    # Calculate the second sigmoid component: favors ratios greater than or equal to ideal_ratio.
    # We want high score when `ratios` is NOT too small (i.e., >= item).
    # `sigmoid_down = 1 / (1 + exp(k * (ratios - ideal_ratio)))`
    # This score is high when `ratios - ideal_ratio` is negative, i.e., ratios < ideal_ratio.
    # We want to prioritize bins that can fit the item (`ratios >= 1`).
    # So, let's use this to favor ratios closer to ideal_ratio from below.
    sigmoid_part2 = 1 / (1 + np.exp(k * (ratios - ideal_ratio))) # High for ratios < ideal_ratio

    # Combine the two: the product will be high only when both sigmoids are moderately high.
    # This creates a peak around `ideal_ratio`.
    priorities = sigmoid_part1 * sigmoid_part2

    # Ensure that bins that cannot fit the item (bins_remain_cap < item) get zero priority.
    # This means `ratios < 1`.
    # For `ratios < 1`, `ratios - ideal_ratio` is negative and large.
    # `sigmoid_part1` will be close to 0. `sigmoid_part2` will be close to 1.
    # The product `priorities` will be close to 0. This is good.

    # Let's refine the "ideal_ratio". It should ideally be related to `item` size.
    # A larger `k` makes the peak narrower and higher.
    # The product `sigmoid_part1 * sigmoid_part2` creates a bell-like shape.
    # `sigmoid_part1` increases with `ratios`. `sigmoid_part2` decreases with `ratios`.
    # The peak is at `ratios = ideal_ratio`.

    # Let's reconsider the core idea: Sigmoid Fit Score.
    # This should capture how well the item *fits*.
    # A tight fit is good, but not if it leaves no room.
    # An excess of room is also not ideal (wasted space).
    # The "perfect" fit leaves minimal, but positive, remaining space.

    # Let's use a single sigmoid to represent the "quality of space left".
    # `remaining_space = bins_remain_cap - item`.
    # We want this to be positive and small.
    # Let `ideal_remaining_space = item * 0.1` (10% of item size).
    # `z = k * (remaining_space - ideal_remaining_space)`
    # `score = 1 / (1 + exp(-z))`
    # This score increases as `remaining_space` increases. So it favors larger remaining spaces.
    # We need to cap this and also ensure it's 0 for `remaining_space < 0`.

    # Let's go back to the `ratios = bins_remain_cap / item`.
    # The goal is to place the item into a bin such that the resulting `bins_remain_cap` is optimal.
    # The optimal state is often considered to be bins that are "nearly full".
    # Let's assign a priority score that represents how close we are to this "nearly full" state.

    # Let's use a Sigmoid to represent the "closeness" to being full.
    # Remaining capacity `c`. Item size `i`.
    # Bin is "fuller" when `c` is smaller (for a fixed item `i`).
    # We want smaller `c` values (but `c >= i`).
    # Let's focus on bins where `bins_remain_cap >= item`.
    # Let `x = bins_remain_cap`.
    # We want to prioritize `x` values that are small, but not smaller than `item`.
    # Let `ideal_max_remain_cap = item * 1.2`.
    # We want high scores for `bins_remain_cap` in the range `[item, ideal_max_remain_cap]`.

    # Let's use `score = 1 / (1 + exp(-k * (ideal_max_remain_cap - bins_remain_cap)))` for bins where `bins_remain_cap >= item`.
    # This function increases as `bins_remain_cap` increases. It peaks at `bins_remain_cap = ideal_max_remain_cap`.
    # This is still favoring larger remaining capacities up to a point.

    # The Sigmoid Fit Score implies that the *fit itself* should be evaluated using a sigmoid.
    # Let's try again with `ratios = bins_remain_cap / item`.
    # `ideal_ratio = 1.1`.
    # We want a function that is high for ratios near `1.1`.
    # `sigmoid_peak = lambda val: 1 / (1 + np.exp(-k * (val - x0)))`
    # A symmetric peak can be achieved with `sigmoid_peak(val) * sigmoid_peak(-val)`
    # Or `sigmoid_peak(val) * (1 - sigmoid_peak(val))` (Gaussian-like).

    # Let's simplify the interpretation: We want bins that are not overly full, and not overly empty.
    # `score = sigmoid(k * (bins_remain_cap - item))` penalizes bins where `bins_remain_cap < item`.
    # `score = 1 / (1 + exp(-k * (bins_remain_cap - item)))`.
    # This score is low if `bins_remain_cap` is much less than `item`. It increases as `bins_remain_cap` increases.
    # This already gives a preference to bins that can fit.
    # To refine it, we want to favor bins that aren't excessively large.

    # Let's use `k1` for the initial increase and `k2` for the subsequent decrease.
    # `part1 = 1 / (1 + np.exp(-k1 * (bins_remain_cap - item)))` (favors fitting)
    # `part2 = 1 / (1 + np.exp(-k2 * (item * target_factor - bins_remain_cap)))` (favors not too large)
    # `target_factor = 1.2`
    # `priorities = part1 * part2`

    # Ensure `item` is positive for division.
    if item < 1e-9:
        # If item is zero, all bins are equally "good" or irrelevant.
        # Returning a uniform score (e.g., 0.5) is reasonable.
        return np.ones_like(bins_remain_cap) * 0.5

    # Calculate suitability for bins that can fit the item.
    # `ratios = bins_remain_cap / item`
    # We want to prioritize ratios that are close to a 'sweet spot'.
    # The sweet spot is slightly larger than 1, allowing some remaining capacity.
    # Let the ideal remaining capacity be `item * 1.2`.
    # So the ideal ratio is `1.2`.

    # Using two sigmoids to create a peak.
    # `k_steepness` controls how sharp the peak is.
    k_steepness = 6.0
    ideal_ratio = 1.1  # Prefer bins that leave around 10% of item size as remaining capacity.

    # Sigmoid 1: Score increases as `bins_remain_cap / item` increases.
    # This favors bins that are not too full.
    # `score1 = 1 / (1 + exp(-k * (ratio - x0)))`
    # Let `x0 = ideal_ratio`. So `score1` is high for `ratio > ideal_ratio`.
    # We want to favor bins that are not excessively full, and not excessively empty.
    # Let's use `sigmoid(k * (ratio - ideal_ratio))`. This is high for `ratio > ideal_ratio`.
    score_part1 = 1 / (1 + np.exp(-k_steepness * (ratios - ideal_ratio)))

    # Sigmoid 2: Score decreases as `bins_remain_cap / item` increases.
    # This favors bins that are not too empty.
    # We want score to be high for `ratio < ideal_ratio`.
    # Use `sigmoid(-k * (ratio - ideal_ratio))`. This is high for `ratio < ideal_ratio`.
    score_part2 = 1 / (1 + np.exp(k_steepness * (ratios - ideal_ratio)))

    # The product gives a peak around `ideal_ratio`.
    priorities = score_part1 * score_part2

    # Ensure bins too small to fit the item have zero priority.
    # For `ratios < 1`, `ratios - ideal_ratio` is negative.
    # `score_part1` will be close to 0, `score_part2` will be close to 1. Product is close to 0. Correct.

    # What if `bins_remain_cap` is very large?
    # `ratios` is very large. `score_part1` is near 1. `score_part2` is near 0. Product is near 0. Correct.

    # This approach effectively creates a Gaussian-like peak, using sigmoids.
    # This is a common way to interpret "Sigmoid Fit Score" for optimization where
    # a middle ground is preferred.

    return priorities
```
