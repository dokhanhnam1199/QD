```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines Best Fit with a preference for moderately filled bins using sigmoid.

    Prioritizes bins that offer a tight fit (Best Fit) but also favors bins
    that aren't excessively empty after packing, aiming for a balanced state.
    """
    if item < 1e-9:
        # If item is negligible, any bin is fine. Prioritize less filled bins.
        # Return higher scores for bins with less remaining capacity.
        return 1.0 / (bins_remain_cap + 1e-9)

    # --- Best Fit Component ---
    # Prioritize bins that leave minimal remaining capacity after fitting the item.
    # This is equivalent to maximizing -(bins_remain_cap - item), or item - bins_remain_cap.
    # We use a large negative value for bins that can fit, favoring smaller differences.
    # Add a small epsilon to avoid division by zero issues and to prioritize exact fits.
    best_fit_scores = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit_mask = bins_remain_cap >= item
    
    # Calculate the remaining capacity for bins that can fit the item.
    remaining_after_fit = bins_remain_cap[can_fit_mask] - item
    
    # Apply a sigmoid to map the "tightness" (small remaining capacity) to a high score.
    # We want a high score when remaining_after_fit is small (close to 0).
    # A sigmoid of the form 1 / (1 + exp(-k * x)) increases with x.
    # So, we use x = -(remaining_after_fit) to make it decrease with remaining_after_fit.
    # Or, we use a reversed sigmoid: 1 - (1 / (1 + exp(-k * x))) which is exp(-k*x)/(1+exp(-k*x))
    # A simpler way for tight fit: use a large negative value for bins_remain_cap - item.
    # The smaller (bins_remain_cap - item) is, the higher the score.
    # Let's assign a score based on -(remaining_after_fit).
    # To make it more sigmoid-like and smooth, let's use a sigmoid centered at 0 for this "slack".
    # We want a peak at slack=0, so we can use a Gaussian-like function formed by two sigmoids.
    # For this iteration, let's simplify the best-fit component:
    # Prioritize bins that are closest to fitting the item.
    # A simple "best fit" score can be the negative difference: item - bins_remain_cap
    # which becomes positive for bins that can fit.
    # Let's use a sigmoid on this difference to get a score.
    # Target slack = 0. Use sigmoid(k * (-slack))
    slack = remaining_after_fit
    k_fit = 8.0 # Steepness for "best fit" preference
    
    # Score component that favors small, non-negative slack
    best_fit_scores[can_fit_mask] = 1.0 / (1.0 + np.exp(k_fit * slack)) # High when slack is small

    # --- Almost Full Fit Component ---
    # Prioritize bins that are not excessively empty after fitting.
    # This means we don't want too much capacity left.
    # Let's consider the ratio of remaining capacity to item size.
    # We prefer ratios closer to 1 (tight fit) but also moderate ratios, not excessively large ones.
    # Let's use a sigmoid that penalizes bins that are much larger than needed.
    # Define an "ideal" remaining capacity as slightly larger than the item, e.g., item * 1.3
    # This component will penalize bins where (bins_remain_cap - item) is large.
    
    ideal_excess_capacity = item * 0.3 # Prefer bins that leave up to 30% of item size as excess
    excess_capacity = bins_remain_cap[can_fit_mask] - item
    
    # Use a sigmoid to penalize large excess capacity.
    # A sigmoid that decreases with excess capacity.
    # 1 / (1 + exp(k * x)) decreases with x. Let x = excess_capacity - ideal_excess_capacity.
    k_penalty = 4.0 # Steepness for penalizing excess capacity
    
    almost_full_scores = np.zeros_like(bins_remain_cap, dtype=float)
    almost_full_scores[can_fit_mask] = 1.0 / (1.0 + np.exp(k_penalty * (excess_capacity - ideal_excess_capacity))) # High when excess_capacity is small/ideal


    # --- Combination ---
    # Combine the two scores. The best fit score is high for tight fits.
    # The almost full fit score is high for bins that aren't overly empty.
    # A multiplicative combination can work well: prioritize bins that score high on *both*.
    combined_priorities = np.zeros_like(bins_remain_cap, dtype=float)
    combined_priorities[can_fit_mask] = best_fit_scores[can_fit_mask] * almost_full_scores[can_fit_mask]
    
    # Ensure bins that cannot fit have zero priority.
    # This is handled by initializing with zeros and only updating can_fit_mask bins.

    return combined_priorities
```
