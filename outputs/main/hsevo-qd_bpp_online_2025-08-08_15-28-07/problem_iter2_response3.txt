```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes bins that offer a tight fit while also considering overall capacity."""
    available_bins_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    if not np.any(available_bins_mask):
        return priorities

    available_bins_cap = bins_remain_cap[available_bins_mask]

    # Heuristic 1 (priority_v0) inspired: Inverse ratio for tight fit
    # Higher values for bins that leave less remaining space after fitting the item.
    tight_fit_score = available_bins_cap / (available_bins_cap - item + 1e-9)

    # Add a factor that favors bins that are not *too* full initially,
    # preventing premature exhaustion of good, large bins.
    # This part is inspired by the idea behind sigmoid approaches that find a balance.
    # We use a simple inverse to penalize very small remaining capacities.
    # A very small remaining capacity after fitting (i.e., bins_remain_cap - item is small)
    # also means the initial capacity was not excessively large compared to the item.
    # This is a simplified way to balance tightness with not using a huge bin for a small item.
    # Higher values for bins that have a moderate amount of remaining capacity after fitting.
    # Using 1 / (residual_capacity + epsilon) can be brittle. Let's try to leverage the
    # initial capacity relative to the item size.
    # If initial bin capacity is `B` and item is `i`, we want to minimize `B-i`.
    # The `tight_fit_score` already does this.
    # Let's consider the "Almost Full Fit" idea where we want `remaining_caps_after_fit` to be small.
    # The `priority_v0` already captures this well with `available_bins_cap / (available_bins_cap - item)`.
    # Let's refine it by adding a small penalty for bins that are *excessively* large,
    # ensuring we don't just pick the largest bin that fits if a much tighter fit is available.
    # A simple way is to slightly penalize bins with very large remaining capacity *after* the item is placed.
    # This is implicitly handled by the division in `tight_fit_score`.

    # Let's re-evaluate based on "closer to zero remaining capacity is better",
    # and "don't waste large bins".
    # The `priority_v0` effectively implements "Minimize remaining capacity after fit".
    # A slightly different perspective is to maximize `item / bin_capacity`. This favors
    # filling bins more densely.
    # Let's combine the idea of "tight fit" (priority_v0) with a slight preference for
    # bins that are not excessively large *relative to the item*.

    # Consider the ratio of the item size to the bin's current capacity.
    # A higher ratio means the item takes up a larger portion of the bin's current capacity.
    # This favors fuller bins, which is good for minimizing bin count.
    # However, this might conflict with "tight fit" if a large item goes into a large bin.

    # Let's stick to the core idea of v0: prioritize bins where the remaining capacity after fitting is minimal.
    # This is achieved by maximizing `bin_capacity / (bin_capacity - item)`.
    # We can add a small component that slightly penalizes bins that have *significantly* more capacity than needed,
    # to avoid picking a very large bin when a slightly smaller one provides a similarly tight fit.

    # Let's try to combine "tight fit" with a slight preference for bins that are not "overly large" for the item.
    # The "tight_fit_score" already favors bins where `available_bins_cap - item` is small.
    # Let's also consider the ratio `item / available_bins_cap`. Higher values mean better utilization.
    # However, a very small item in a very large bin would have a low `item / available_bins_cap` but might have
    # a good tight fit if other bins are even larger.

    # Let's combine the inverse distance (tightness) with a sigmoid-like preference for bins that are not *too* empty.
    # The sigmoid approach aimed to balance. If we have `B` as remaining capacity and `i` as item size,
    # we want to minimize `B-i`. The `priority_v0` does this.
    # A secondary goal is to not put a small item into a huge bin if a medium bin fits well.

    # Combine the tight fit score with a term that slightly favors bins that are not excessively larger than the item.
    # Let's use `item / available_bins_cap` as a secondary score.
    # However, this can be problematic for small items in large bins.

    # Revisit "Almost Full Fit": `1.0 / (remaining_caps_after_fit + epsilon)`
    # This is what `priority_v0` does with `available_bins_cap / (available_bins_cap - item + 1e-9)`.
    # The analysis suggests this is a strong heuristic.

    # Let's try to introduce a slight bias towards bins that are not *extremely* larger than the item.
    # This can be done by considering `item / available_bins_cap`.
    # If `available_bins_cap` is much larger than `item`, `item / available_bins_cap` is small.
    # We want to *prefer* bins where this ratio is higher, but not at the expense of tightness.

    # Let's combine the tight fit score with a normalized version of how much of the bin the item occupies.
    # Consider `tight_fit_score` (from v0) and `utilization_score = item / available_bins_cap`.
    # We want to maximize `tight_fit_score` and also maximize `utilization_score` (to some extent).
    # A simple combination: `tight_fit_score * (1 + utilization_score)` ?
    # This could over-penalize large bins if `utilization_score` is very small.

    # Let's use the v0's tight fit score.
    # And add a small penalty for bins that are vastly larger than the item *after* the fit.
    # This means if `available_bins_cap - item` is very large, we slightly down-weight.
    # This is the inverse of what we want for tight fit.

    # Let's reconsider the sigmoid idea: finding a balance.
    # We want `bins_remain_cap - item` to be small.
    # What if we want `bins_remain_cap` to be just enough?
    # A simple way to capture "just enough" is to look at `item / bins_remain_cap`.
    # High values mean the item fills a good portion of the bin.
    # Let's combine `priority_v0`'s "tight fit" with this "good utilization" idea.

    # Final attempt: Combine tight fit (inverse of remaining capacity after fit) with a slight preference for bins that are not excessively large for the item.
    # The "tight fit" is `available_bins_cap / (available_bins_cap - item + 1e-9)`.
    # To penalize overly large bins relative to the item, we can consider `item / available_bins_cap`.
    # If `available_bins_cap` is much larger than `item`, `item / available_bins_cap` is small.
    # We want to prioritize bins where `item / available_bins_cap` is not too small, but this should be secondary to tight fit.

    # Let's try a weighted sum of two components:
    # Component 1: Tightness (inverse of remaining capacity after fit)
    # Component 2: Utilization (item size / current bin capacity)
    # We want to give more weight to tightness.
    utilization_score = item / (available_bins_cap + 1e-9)
    combined_score = tight_fit_score + 0.5 * utilization_score # Arbitrary weight for utilization

    priorities[available_bins_mask] = combined_score

    return priorities
```
