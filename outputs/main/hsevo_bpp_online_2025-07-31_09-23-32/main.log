[2025-07-31 09:23:32,479][root][INFO] - Workspace: /home/dokhanhnam1199/QD/outputs/main/hsevo_bpp_online_2025-07-31_09-23-32
[2025-07-31 09:23:32,479][root][INFO] - Project Root: /home/dokhanhnam1199/QD
[2025-07-31 09:23:32,479][root][INFO] - Using LLM: gemini/gemma-3-27b-it
[2025-07-31 09:23:32,479][root][INFO] - Using Algorithm: hsevo
[2025-07-31 09:23:33,511][httpx][INFO] - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json "HTTP/1.1 200 OK"
[2025-07-31 09:23:34,376][root][INFO] - Problem: bpp_online
[2025-07-31 09:23:34,376][root][INFO] - Problem description: Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
[2025-07-31 09:23:34,377][root][INFO] - Function name: priority
[2025-07-31 09:23:34,377][root][INFO] - Evaluating seed function...
[2025-07-31 09:23:34,377][root][INFO] - Seed function code: 
import numpy as np
import random
import math
import scipy
import torch
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)
[2025-07-31 09:23:34,377][root][INFO] - Iteration 0: Running Code 0
[2025-07-31 09:23:36,648][root][INFO] - Iteration 0: Code Run 0 successful!
[2025-07-31 09:23:37,517][root][INFO] - Iteration 0: Code Run 0 successful!
[2025-07-31 09:23:39,278][root][INFO] - bd_process: <Popen: returncode: 0 args: ['python3', '-u', '/home/dokhanhnam1199/QD/probl...>
[2025-07-31 09:23:39,280][root][INFO] - Iteration 0: Code Run 0 successful!
[2025-07-31 09:23:41,063][root][INFO] - bd_process: <Popen: returncode: 0 args: ['python3', '-u', '/home/dokhanhnam1199/QD/probl...>
[2025-07-31 09:23:41,063][root][INFO] - Iteration 0, response_id 0: Objective value: 4.487435181491823
[2025-07-31 09:23:41,063][root][INFO] - Iteration 0: Elitist: 4.487435181491823
[2025-07-31 09:23:41,064][root][INFO] - Iteration 0 finished...
[2025-07-31 09:23:41,064][root][INFO] - Best obj: 4.487435181491823, Best Code Path: problem_iter0_code0.py
[2025-07-31 09:23:41,064][root][INFO] - LLM usage: prompt_tokens = 0, completion_tokens = 0
[2025-07-31 09:23:41,064][root][INFO] - LLM Requests: 0
[2025-07-31 09:23:41,064][root][INFO] - Function Evals: 1
[2025-07-31 09:23:41,064][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,064][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Albert Einstein, relativity theory developer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Albert Einstein, relativity theory developer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,065][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Isaac Newton, the father of physics. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Isaac Newton, the father of physics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,065][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Marie Curie, pioneer in radioactivity. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Marie Curie, pioneer in radioactivity. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,065][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Nikola Tesla, master of electricity. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Nikola Tesla, master of electricity. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,065][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Galileo Galilei, champion of heliocentrism. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Galileo Galilei, champion of heliocentrism. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,066][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Stephen Hawking, black hole theorist. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Stephen Hawking, black hole theorist. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,066][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Richard Feynman, quantum mechanics genius. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Richard Feynman, quantum mechanics genius. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,066][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Rosalind Franklin, DNA structure revealer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Rosalind Franklin, DNA structure revealer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,067][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Ada Lovelace, computer programming pioneer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Ada Lovelace, computer programming pioneer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,067][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,067][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Albert Einstein, relativity theory developer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Albert Einstein, relativity theory developer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,067][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Isaac Newton, the father of physics. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Isaac Newton, the father of physics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,068][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Marie Curie, pioneer in radioactivity. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Marie Curie, pioneer in radioactivity. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,068][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Nikola Tesla, master of electricity. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Nikola Tesla, master of electricity. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,068][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Galileo Galilei, champion of heliocentrism. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Galileo Galilei, champion of heliocentrism. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,069][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Stephen Hawking, black hole theorist. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Stephen Hawking, black hole theorist. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,069][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Richard Feynman, quantum mechanics genius. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Richard Feynman, quantum mechanics genius. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,069][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Rosalind Franklin, DNA structure revealer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Rosalind Franklin, DNA structure revealer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,069][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Ada Lovelace, computer programming pioneer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Ada Lovelace, computer programming pioneer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,070][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,070][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Albert Einstein, relativity theory developer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Albert Einstein, relativity theory developer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,070][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Isaac Newton, the father of physics. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Isaac Newton, the father of physics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,070][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Marie Curie, pioneer in radioactivity. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Marie Curie, pioneer in radioactivity. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,071][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Nikola Tesla, master of electricity. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Nikola Tesla, master of electricity. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,071][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Galileo Galilei, champion of heliocentrism. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Galileo Galilei, champion of heliocentrism. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,071][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Stephen Hawking, black hole theorist. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Stephen Hawking, black hole theorist. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,071][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Richard Feynman, quantum mechanics genius. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Richard Feynman, quantum mechanics genius. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,072][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Rosalind Franklin, DNA structure revealer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Rosalind Franklin, DNA structure revealer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,072][root][INFO] - Initial Population Prompt: 
System Prompt: 
You are Ada Lovelace, computer programming pioneer. Your task is to design heuristics that can effectively solve optimization problems.
Your response outputs Python code and nothing else. Format your code as a Python code string: "```python ... ```".

User Prompt: 
You are Ada Lovelace, computer programming pioneer. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.
The priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.

def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    return np.zeros_like(bins_remain_cap)

Refer to the format of a trivial design above. Be very creative and give `priority_v2`. Output code only and enclose your code with Python code block: ```python ... ```.

[2025-07-31 09:23:41,081][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:41,083][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:41,299][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:41,321][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:41,325][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:41,327][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:44,330][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:44,332][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:44,518][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:44,520][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:44,526][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:44,529][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:47,525][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:47,533][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:47,661][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:47,664][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:47,667][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:47,670][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:50,669][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:50,674][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:50,796][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:50,798][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:50,808][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:50,819][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:53,805][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:53,823][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:53,960][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:53,962][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:53,978][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:53,981][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:56,967][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:56,986][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:23:57,128][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:57,130][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:23:57,140][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:23:57,142][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:00,135][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:00,147][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:00,308][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:00,311][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:00,334][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:00,336][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:03,315][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:03,341][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:03,457][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:03,460][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:03,525][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:03,528][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:06,465][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:06,532][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:06,597][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:06,599][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:06,643][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:06,645][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:09,604][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:09,650][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:09,716][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:09,720][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:09,783][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:09,785][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:12,725][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:12,789][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:12,855][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:12,858][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:12,894][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:12,896][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:15,864][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:15,901][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:16,017][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:16,020][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:16,049][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:16,052][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:19,024][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:19,056][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:19,172][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:19,175][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:19,191][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:19,194][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:22,179][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:22,198][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:22,311][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:22,314][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:22,348][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:22,351][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:25,318][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:25,356][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:25,451][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:25,453][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:25,490][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:25,493][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:28,458][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:28,498][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:28,595][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:28,598][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:28,632][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:24:28,635][root][INFO] - Attempt 16 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

[2025-07-31 09:24:31,603][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:31,645][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:31,731][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:24:31,733][root][INFO] - Attempt 17 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:24:31,783][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:24:31,786][root][INFO] - Attempt 17 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:24:34,738][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:34,790][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:34,852][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:24:34,854][root][INFO] - Attempt 18 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:24:34,894][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:24:34,896][root][INFO] - Attempt 18 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:24:37,859][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:37,900][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:37,966][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:24:37,968][root][INFO] - Attempt 19 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:24:38,017][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:24:38,019][root][INFO] - Attempt 19 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:24:40,973][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:41,024][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:41,071][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:41,073][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:41,149][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:41,151][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:44,109][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:44,164][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:44,219][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:44,221][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:44,295][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:44,297][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:47,226][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:47,302][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:47,337][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:47,344][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:47,412][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:47,414][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:50,348][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:50,419][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:50,441][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:50,443][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:50,534][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:50,536][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:53,449][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:53,532][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:53,534][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:53,541][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:53,632][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:53,635][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:56,539][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:56,638][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:56,639][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:56,645][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:56,738][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:56,740][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:59,649][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:59,745][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:24:59,752][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:59,754][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:24:59,852][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:24:59,855][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:02,760][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:02,859][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:02,861][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:02,863][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:02,979][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:02,981][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:05,868][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:05,983][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:05,985][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:05,988][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:06,089][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:06,092][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:08,991][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:09,096][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:09,100][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:09,102][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:09,204][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:09,207][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:12,109][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:12,211][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:12,216][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:12,219][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:12,323][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:12,326][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:15,222][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:25:15,224][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:15,325][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:15,328][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:15,329][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:25:15,332][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:15,442][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:15,445][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:18,333][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:18,438][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:18,441][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:18,449][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:18,554][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:18,557][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:21,447][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:21,561][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:21,572][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:21,574][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:21,661][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:21,663][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:24,578][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:24,668][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:24,686][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:24,691][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:24,775][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:24,777][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:27,695][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:27,782][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:27,811][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:27,814][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:27,887][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:27,889][root][INFO] - Attempt 5 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "32s"
      }
    ]
  }
}

[2025-07-31 09:25:30,820][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:30,894][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:30,929][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:30,931][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:25:31,003][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:31,005][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:25:33,936][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:34,010][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:34,052][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:34,059][root][INFO] - Attempt 7 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:25:34,119][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:34,122][root][INFO] - Attempt 7 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:25:37,063][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:37,126][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:37,170][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:37,173][root][INFO] - Attempt 8 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:25:37,230][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:37,265][root][INFO] - Attempt 8 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:25:40,186][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:40,270][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:40,332][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:40,335][root][INFO] - Attempt 9 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:25:40,371][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:25:40,374][root][INFO] - Attempt 9 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:25:43,340][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:43,378][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:43,474][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:43,476][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:43,514][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:43,516][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:46,481][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:46,521][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:46,610][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:46,612][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:46,653][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:46,655][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:49,617][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:49,660][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:49,741][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:49,744][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:49,779][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:49,781][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:52,748][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:52,792][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:52,859][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:52,861][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:52,904][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:52,906][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:55,866][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:55,911][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:55,974][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:55,978][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:56,022][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:56,024][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:58,982][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:59,029][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:25:59,098][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:59,100][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:25:59,131][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:25:59,133][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:02,104][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:02,142][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:02,254][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:02,257][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:02,273][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:02,275][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:05,261][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:05,280][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:05,400][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:05,402][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:05,418][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:05,420][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:08,407][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:08,424][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:08,543][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:08,546][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:08,560][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:08,563][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:11,552][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:11,567][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:11,705][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:11,707][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:11,707][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:11,709][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:14,712][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:14,713][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:14,871][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:14,873][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:14,881][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:14,883][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:17,878][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:17,887][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:18,024][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:18,026][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:18,028][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:18,030][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:21,031][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:21,036][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:21,194][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:21,196][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:21,208][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:21,210][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:24,201][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:24,214][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:24,340][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:24,342][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:24,358][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:24,361][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:27,347][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:27,365][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:27,499][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:27,502][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:27,522][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:27,525][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:30,508][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:30,529][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:30,641][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:30,644][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:30,664][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:26:30,667][root][INFO] - Attempt 25 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:26:33,648][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:33,672][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:33,813][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:26:33,814][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:26:33,819][root][INFO] - Attempt 26 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:26:33,820][root][INFO] - Attempt 26 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:26:36,824][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:36,825][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:36,975][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:26:36,976][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:26:36,980][root][INFO] - Attempt 27 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:26:36,981][root][INFO] - Attempt 27 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:26:39,987][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:39,989][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:40,154][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:26:40,156][root][INFO] - Attempt 28 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:26:40,167][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:26:40,170][root][INFO] - Attempt 28 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:26:43,161][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:43,174][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:43,311][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:43,314][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:43,333][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:43,336][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:46,318][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:46,340][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:46,465][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:46,467][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:46,487][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:46,490][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:49,470][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:26:49,472][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:49,493][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:26:49,498][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:49,601][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:49,604][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:49,656][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:49,658][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:52,608][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:52,663][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:52,715][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:52,717][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:52,820][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:52,822][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:55,722][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:55,818][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:55,820][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:55,826][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:55,926][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:55,928][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:58,825][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:58,920][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:58,922][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:26:58,933][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:26:59,032][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:26:59,035][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:01,927][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:02,031][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:02,033][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:02,039][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:02,142][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:02,144][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:05,038][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:05,141][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:05,143][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:05,149][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:05,258][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:05,260][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:08,148][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:08,256][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:08,258][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:08,264][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:08,381][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:08,384][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:11,263][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:11,357][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:11,360][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:11,388][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:11,497][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:11,501][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:14,364][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:14,478][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:14,480][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:14,505][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:14,608][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:14,610][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:17,484][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:17,568][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:17,572][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:17,615][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:17,708][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:17,710][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:20,577][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:20,690][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:20,692][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:20,715][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:20,837][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:20,841][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:23,697][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:23,803][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:23,806][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:23,846][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:23,943][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:23,946][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:26,811][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:26,914][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:26,916][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:26,950][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:27,059][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:27,062][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:29,921][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:30,014][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:30,017][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:30,066][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:30,201][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:27:30,203][root][INFO] - Attempt 14 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:27:33,029][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:33,129][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:27:33,132][root][INFO] - Attempt 15 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:27:33,207][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:33,345][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:27:33,347][root][INFO] - Attempt 15 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:27:36,137][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:36,250][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:27:36,253][root][INFO] - Attempt 16 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:27:36,352][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:36,449][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:27:36,452][root][INFO] - Attempt 16 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:27:39,257][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:39,364][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:27:39,366][root][INFO] - Attempt 17 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:27:39,455][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:39,553][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:27:39,558][root][INFO] - Attempt 17 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:27:42,371][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:42,474][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:42,476][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:42,563][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:42,656][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:42,658][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:45,481][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:45,575][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:45,579][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:45,663][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:45,778][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:45,780][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:48,584][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:48,694][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:48,697][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:48,785][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:48,888][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:48,892][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:51,701][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:51,794][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:51,796][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:51,897][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:51,986][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:51,988][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:54,801][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:54,898][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:54,902][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:54,993][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:55,120][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:55,123][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:57,907][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:58,014][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:58,016][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:27:58,128][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:27:58,229][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:27:58,233][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:01,021][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:01,127][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:01,130][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:01,237][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:01,339][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:01,341][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:04,134][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:04,236][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:04,240][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:04,346][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:04,454][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:04,456][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:07,244][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:07,348][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:07,350][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:07,461][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:07,559][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:07,563][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:10,355][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:10,446][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:10,449][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:10,567][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:10,662][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:10,664][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:13,453][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:13,562][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:13,566][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:13,669][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:13,773][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:13,776][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:16,571][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:16,666][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:16,668][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:16,780][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:16,879][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:16,883][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:19,673][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:19,780][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:19,782][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:19,887][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:19,989][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:19,991][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:22,786][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:28:22,787][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:22,888][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:22,892][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:22,995][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:28:22,996][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:23,107][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:23,109][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:25,896][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:26,007][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:26,010][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:26,114][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:26,260][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:26,263][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:29,020][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:29,114][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:29,117][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:29,267][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:29,359][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:28:29,362][root][INFO] - Attempt 3 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "30s"
      }
    ]
  }
}

[2025-07-31 09:28:32,122][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:32,207][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:28:32,212][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:28:32,366][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:32,467][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:28:32,470][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:28:35,216][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:35,308][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:28:35,310][root][INFO] - Attempt 5 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:28:35,474][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:35,566][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:28:35,570][root][INFO] - Attempt 5 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:28:38,315][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:38,426][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:28:38,428][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:28:38,575][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:38,672][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:28:38,674][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:28:41,433][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:41,530][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:41,533][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:41,679][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:41,778][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:41,780][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:44,538][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:44,644][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:44,646][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:44,785][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:44,898][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:44,902][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:47,651][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:47,775][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:47,778][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:47,907][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:48,006][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:48,008][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:50,782][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:50,881][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:50,884][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:51,013][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:51,110][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:51,112][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:53,889][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:53,990][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:53,991][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:54,117][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:54,224][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:54,228][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:56,996][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:57,094][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:57,096][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:28:57,233][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:28:57,331][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:28:57,333][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:00,101][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:00,209][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:00,213][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:00,338][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:00,430][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:00,432][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:03,218][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:03,322][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:03,324][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:03,437][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:03,529][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:03,533][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:06,329][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:06,429][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:06,431][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:06,538][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:06,635][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:06,637][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:09,436][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:09,531][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:09,535][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:09,642][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:09,726][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:09,728][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:12,540][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:12,638][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:12,641][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:12,733][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:12,820][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:12,824][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:15,645][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:15,734][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:15,736][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:15,828][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:15,925][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:15,927][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:18,741][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:18,842][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:18,846][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:18,932][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:19,032][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:19,035][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:21,850][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:21,979][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:21,982][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:22,040][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:22,177][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:22,180][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:24,994][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:25,093][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:25,095][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:25,185][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:25,299][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:25,301][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:28,100][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:28,198][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:28,203][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:28,306][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:28,405][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:28,407][root][INFO] - Attempt 22 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

[2025-07-31 09:29:31,208][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:31,295][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:31,297][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:29:31,412][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:31,511][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:31,516][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:29:34,302][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:34,387][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:34,390][root][INFO] - Attempt 24 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:29:34,520][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:34,621][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:34,623][root][INFO] - Attempt 24 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:29:37,394][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:37,493][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:37,498][root][INFO] - Attempt 25 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:29:37,628][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:37,727][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:37,730][root][INFO] - Attempt 25 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:29:40,502][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:40,594][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:40,597][root][INFO] - Attempt 26 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:29:40,734][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:40,832][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:29:40,836][root][INFO] - Attempt 26 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:29:43,601][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:43,695][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:43,697][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:43,841][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:43,948][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:43,950][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:46,701][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:46,803][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:46,807][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:46,954][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:47,073][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:47,075][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:49,811][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:49,906][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:49,909][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:50,080][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:50,184][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:50,188][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:52,913][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:53,015][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:53,017][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:53,193][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:53,276][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:53,279][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:56,020][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:29:56,022][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:56,125][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:56,129][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:56,282][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:29:56,283][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:56,380][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:56,383][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:59,134][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:59,224][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:59,227][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:29:59,388][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:29:59,496][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:29:59,500][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:02,232][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:02,329][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:02,331][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:02,504][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:02,603][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:02,605][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:05,336][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:05,435][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:05,439][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:05,610][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:05,719][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:05,722][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:08,444][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:08,558][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:08,560][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:08,726][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:08,818][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:08,822][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:11,565][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:11,661][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:11,663][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:11,827][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:11,930][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:11,932][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:14,668][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:14,779][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:14,781][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:14,937][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:15,036][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:15,038][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:17,786][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:17,890][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:17,892][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:18,043][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:18,183][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:18,185][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:20,906][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:21,024][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:21,027][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:21,190][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:21,281][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:21,283][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:24,032][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:24,134][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:24,138][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:24,287][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:24,394][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:24,396][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:27,143][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:27,243][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:27,245][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:27,399][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:27,500][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:27,504][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:30,250][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:30,339][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:30,341][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:30,509][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:30,603][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:30:30,606][root][INFO] - Attempt 12 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:30:33,346][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:33,440][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:30:33,444][root][INFO] - Attempt 13 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:30:33,610][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:33,700][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:30:33,702][root][INFO] - Attempt 13 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:30:36,448][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:36,543][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:30:36,545][root][INFO] - Attempt 14 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:30:36,706][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:36,800][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:30:36,805][root][INFO] - Attempt 14 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:30:39,550][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:39,659][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:30:39,661][root][INFO] - Attempt 15 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:30:39,809][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:39,904][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:30:39,907][root][INFO] - Attempt 15 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:30:42,666][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:42,776][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:42,780][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:42,912][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:43,047][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:43,049][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:45,785][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:45,886][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:45,888][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:46,054][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:46,147][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:46,150][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:48,893][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:49,011][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:49,014][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:49,155][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:49,254][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:49,256][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:52,018][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:52,116][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:52,120][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:52,261][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:52,362][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:52,364][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:55,125][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:55,229][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:55,232][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:55,369][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:55,472][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:55,476][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:58,236][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:58,332][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:58,335][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:30:58,481][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:30:58,609][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:30:58,612][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:01,339][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:01,448][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:01,453][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:01,616][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:01,710][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:01,712][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:04,458][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:04,564][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:04,566][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:04,717][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:04,813][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:04,817][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:07,571][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:07,670][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:07,672][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:07,822][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:07,916][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:07,919][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:10,677][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:10,777][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:10,781][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:10,923][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:11,024][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:11,026][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:13,786][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:13,882][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:13,884][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:14,031][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:14,164][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:14,166][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:16,897][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:16,999][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:17,001][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:17,171][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:17,263][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:17,265][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:20,005][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:20,133][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:20,138][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:20,270][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:20,378][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:20,380][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:23,142][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:23,257][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:23,259][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:23,385][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:23,493][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:23,497][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:26,264][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:26,409][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:26,411][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:26,502][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:26,603][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:26,605][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:29,414][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:31:29,416][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:29,525][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:29,529][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:29,608][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:31:29,610][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:29,705][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:31:29,708][root][INFO] - Attempt 1 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "30s"
      }
    ]
  }
}

[2025-07-31 09:31:32,533][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:32,636][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:31:32,638][root][INFO] - Attempt 2 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:31:32,712][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:32,818][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:31:32,822][root][INFO] - Attempt 2 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:31:35,642][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:35,726][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:31:35,728][root][INFO] - Attempt 3 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:31:35,827][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:35,923][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:31:35,926][root][INFO] - Attempt 3 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:31:38,733][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:38,825][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:31:38,829][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:31:38,930][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:39,038][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:31:39,041][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:31:41,834][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:41,933][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:41,936][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:42,045][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:42,148][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:42,152][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:44,940][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:45,040][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:45,043][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:45,157][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:45,263][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:45,265][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:48,048][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:48,151][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:48,156][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:48,270][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:48,360][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:48,362][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:51,160][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:51,260][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:51,262][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:51,367][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:51,478][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:51,482][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:54,267][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:54,364][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:54,367][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:54,486][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:54,572][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:54,575][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:57,371][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:57,503][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:57,506][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:31:57,579][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:31:57,687][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:31:57,689][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:00,511][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:00,630][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:00,633][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:00,694][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:00,806][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:00,810][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:03,637][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:03,735][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:03,738][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:03,815][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:03,921][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:03,923][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:06,742][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:06,847][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:06,849][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:06,928][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:07,018][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:07,021][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:09,854][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:09,951][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:09,954][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:10,025][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:10,159][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:10,161][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:12,966][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:13,064][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:13,067][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:13,166][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:13,260][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:13,262][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:16,072][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:16,165][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:16,170][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:16,266][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:16,367][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:16,369][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:19,174][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:19,275][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:19,278][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:19,374][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:19,479][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:19,484][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:22,282][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:22,379][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:22,381][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:22,488][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:22,587][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:22,589][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:25,386][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:25,478][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:25,482][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:25,594][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:25,695][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:25,697][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:28,486][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:28,582][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:28,585][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:28,702][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:28,799][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:32:28,803][root][INFO] - Attempt 20 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

[2025-07-31 09:32:31,589][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:31,710][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:32:31,713][root][INFO] - Attempt 21 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:32:31,807][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:31,906][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:32:31,909][root][INFO] - Attempt 21 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:32:34,717][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:34,822][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:32:34,826][root][INFO] - Attempt 22 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:32:34,913][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:35,009][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:32:35,011][root][INFO] - Attempt 22 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:32:37,831][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:37,921][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:32:37,923][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:32:38,016][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:38,120][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:32:38,125][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:32:40,928][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:41,037][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:41,039][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:41,129][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:41,240][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:41,243][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:44,044][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:44,135][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:44,139][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:44,247][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:44,343][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:44,345][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:47,146][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:47,316][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:47,318][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:47,350][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:47,452][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:47,456][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:50,323][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:50,435][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:50,438][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:50,461][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:50,572][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:50,575][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:53,442][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:53,547][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:53,551][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:53,579][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:53,682][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:53,684][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:56,556][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:56,665][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:56,667][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:56,689][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:56,779][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:56,783][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:59,672][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:59,767][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:59,770][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:32:59,787][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:32:59,886][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:32:59,888][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:02,773][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:33:02,774][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:02,876][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:02,878][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:02,891][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:33:02,893][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:02,999][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:03,001][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:05,883][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:06,006][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:06,008][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:06,010][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:06,142][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:06,144][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:09,023][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:09,138][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:09,140][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:09,149][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:09,254][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:09,256][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:12,145][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:12,261][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:12,266][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:12,268][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:12,352][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:12,354][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:15,273][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:15,359][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:15,372][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:15,374][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:15,460][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:15,462][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:18,379][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:18,467][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:18,468][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:18,471][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:18,568][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:18,570][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:21,476][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:21,578][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:21,580][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:21,583][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:21,683][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:21,685][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:24,588][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:24,684][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:24,687][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:24,690][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:24,787][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:24,790][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:27,692][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:27,786][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:27,789][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:27,794][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:27,896][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:27,899][root][INFO] - Attempt 9 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "32s"
      }
    ]
  }
}

[2025-07-31 09:33:30,793][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:30,893][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:30,896][root][INFO] - Attempt 10 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:33:30,903][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:31,006][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:31,009][root][INFO] - Attempt 10 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:33:33,900][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:34,001][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:34,004][root][INFO] - Attempt 11 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:33:34,013][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:34,105][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:34,110][root][INFO] - Attempt 11 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:33:37,009][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:37,106][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:37,108][root][INFO] - Attempt 12 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:33:37,114][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:37,203][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:37,206][root][INFO] - Attempt 12 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:33:40,113][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:40,202][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:40,206][root][INFO] - Attempt 13 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:33:40,210][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:40,310][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:33:40,312][root][INFO] - Attempt 13 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:33:43,211][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:43,305][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:43,307][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:43,317][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:43,416][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:43,420][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:46,312][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:46,415][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:46,417][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:46,425][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:46,528][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:46,531][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:49,422][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:49,524][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:49,528][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:49,535][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:49,657][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:49,659][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:52,533][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:52,625][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:52,627][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:52,664][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:52,763][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:52,767][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:55,632][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:55,726][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:55,728][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:55,771][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:55,879][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:55,881][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:58,733][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:58,848][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:58,851][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:33:58,885][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:33:58,989][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:33:58,991][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:01,856][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:01,966][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:01,968][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:01,996][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:02,135][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:02,137][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:04,981][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:05,082][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:05,084][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:05,142][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:05,239][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:05,241][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:08,088][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:08,199][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:08,352][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:08,418][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:08,490][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:08,492][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:11,422][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:11,497][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:11,521][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:11,529][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:11,608][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:11,611][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:14,534][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:14,615][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:14,633][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:14,635][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:14,714][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:14,717][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:17,640][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:17,721][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:17,748][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:17,753][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:17,815][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:17,818][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:20,759][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:20,822][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:20,864][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:20,867][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:20,938][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:20,940][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:23,871][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:23,946][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:23,967][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:23,970][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:24,039][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:24,041][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:26,974][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:27,046][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:27,067][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:27,069][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:27,145][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:27,148][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:30,074][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:30,152][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:30,162][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:30,164][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:30,253][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:34:30,255][root][INFO] - Attempt 29 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:34:33,171][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:33,260][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:33,267][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:34:33,269][root][INFO] - Attempt 30 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:34:33,345][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:34:33,347][root][INFO] - Attempt 30 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:34:36,272][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:34:36,274][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:36,351][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:34:36,354][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:36,384][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:34:36,387][root][INFO] - Attempt 1 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:34:36,442][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:34:36,444][root][INFO] - Attempt 1 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:34:39,391][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:39,449][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:39,491][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:34:39,493][root][INFO] - Attempt 2 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:34:39,561][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:34:39,563][root][INFO] - Attempt 2 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:34:42,498][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:42,568][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:42,589][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:42,591][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:42,665][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:42,667][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:45,597][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:45,671][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:45,708][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:45,711][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:45,787][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:45,789][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:48,715][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:48,796][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:48,809][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:48,811][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:48,900][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:48,902][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:51,816][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:51,907][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:51,919][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:51,921][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:52,008][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:52,010][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:54,926][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:55,015][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:55,029][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:55,031][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:55,113][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:55,115][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:58,067][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:58,122][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:34:58,159][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:58,162][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:34:58,218][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:34:58,221][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:01,167][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:01,225][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:01,284][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:01,287][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:01,322][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:01,324][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:04,292][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:04,329][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:04,405][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:04,407][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:04,453][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:04,455][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:07,412][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:07,466][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:07,524][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:07,528][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:07,579][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:07,581][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:10,533][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:10,586][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:10,633][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:10,635][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:10,686][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:10,688][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:13,640][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:13,693][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:13,734][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:13,736][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:13,793][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:13,795][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:16,741][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:16,800][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:16,837][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:16,839][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:16,901][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:16,904][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:19,844][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:19,908][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:19,951][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:19,955][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:19,999][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:20,001][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:22,959][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:23,005][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:23,070][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:23,074][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:23,114][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:23,117][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:26,080][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:26,121][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:26,203][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:26,206][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:26,245][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:26,247][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:29,210][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:29,251][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:29,338][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:29,340][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:29,375][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:35:29,378][root][INFO] - Attempt 18 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "30s"
      }
    ]
  }
}

[2025-07-31 09:35:32,345][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:32,382][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:32,453][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:35:32,456][root][INFO] - Attempt 19 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:35:32,496][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:35:32,498][root][INFO] - Attempt 19 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:35:35,459][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:35,503][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:35,566][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:35:35,569][root][INFO] - Attempt 20 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:35:35,609][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:35:35,612][root][INFO] - Attempt 20 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:35:38,573][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:38,616][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:38,681][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:35:38,687][root][INFO] - Attempt 21 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:35:38,728][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:35:38,730][root][INFO] - Attempt 21 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:35:41,692][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:41,735][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:41,811][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:41,813][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:41,865][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:41,867][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:44,820][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:44,871][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:44,924][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:44,927][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:44,981][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:44,983][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:47,931][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:47,988][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:48,038][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:48,045][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:48,103][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:48,105][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:51,049][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:51,109][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:51,142][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:51,144][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:51,215][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:51,249][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:54,151][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:54,246][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:54,248][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:54,254][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:54,356][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:54,358][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:57,254][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:57,370][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:35:57,393][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:57,399][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:35:57,518][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:35:57,520][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:00,404][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:00,507][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:00,509][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:00,525][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:00,631][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:00,633][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:03,516][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:03,624][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:03,627][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:03,638][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:03,729][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:03,732][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:06,631][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:06,735][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:06,763][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:06,772][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:06,840][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:06,843][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:09,775][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:36:09,777][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:09,845][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:36:09,847][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:09,884][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:09,886][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:09,964][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:09,967][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:12,893][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:12,971][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:12,988][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:12,990][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:13,062][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:13,064][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:15,995][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:16,069][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:16,097][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:16,104][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:16,171][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:16,173][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:19,109][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:19,178][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:19,209][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:19,211][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:19,280][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:19,282][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:22,217][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:22,287][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:22,323][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:22,326][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:22,385][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:22,388][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:25,330][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:25,392][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:25,428][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:25,434][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:25,485][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:25,488][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:28,439][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:28,492][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:28,541][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:28,544][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:28,597][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:28,599][root][INFO] - Attempt 7 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

[2025-07-31 09:36:31,550][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:31,604][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:31,652][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:31,654][root][INFO] - Attempt 8 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:36:31,701][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:31,703][root][INFO] - Attempt 8 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:36:34,659][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:34,708][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:34,756][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:34,763][root][INFO] - Attempt 9 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:36:34,809][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:34,811][root][INFO] - Attempt 9 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:36:37,768][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:37,816][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:37,872][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:37,875][root][INFO] - Attempt 10 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:36:37,948][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:37,950][root][INFO] - Attempt 10 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:36:40,881][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:40,955][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:40,979][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:36:40,981][root][INFO] - Attempt 11 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:36:41,061][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:41,063][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:43,986][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:44,067][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:44,115][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:44,123][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:44,172][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:44,175][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:47,128][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:47,179][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:47,224][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:47,226][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:47,304][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:47,336][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:50,232][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:50,329][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:50,331][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:50,340][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:50,438][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:50,440][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:53,336][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:53,444][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:53,451][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:53,453][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:53,555][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:53,557][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:56,458][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:56,557][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:56,560][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:56,562][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:56,650][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:56,653][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:59,566][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:59,657][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:36:59,658][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:59,662][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:36:59,763][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:36:59,765][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:02,666][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:02,763][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:02,765][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:02,771][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:02,871][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:02,873][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:05,770][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:05,870][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:05,873][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:05,878][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:05,989][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:05,991][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:08,879][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:08,984][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:08,987][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:08,996][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:09,092][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:09,095][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:11,991][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:12,084][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:12,086][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:12,101][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:12,200][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:12,202][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:15,091][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:15,187][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:15,189][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:15,207][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:15,300][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:15,302][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:18,195][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:18,284][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:18,286][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:18,307][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:18,419][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:18,421][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:21,291][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:21,404][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:21,407][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:21,428][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:21,555][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:21,557][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:24,411][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:24,515][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:24,518][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:24,561][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:24,666][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:24,668][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:27,524][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:27,619][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:27,621][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:27,673][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:27,769][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:27,772][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:30,626][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:30,722][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:30,724][root][INFO] - Attempt 27 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:37:30,778][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:30,883][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:30,885][root][INFO] - Attempt 27 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:37:33,729][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:33,827][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:33,830][root][INFO] - Attempt 28 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:37:33,889][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:33,981][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:33,984][root][INFO] - Attempt 28 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:37:36,845][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:36,992][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:37,251][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:37,262][root][INFO] - Attempt 29 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:37:37,468][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:37,471][root][INFO] - Attempt 29 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:37:40,272][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:40,502][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:40,771][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:40,790][root][INFO] - Attempt 30 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:37:40,959][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:37:40,973][root][INFO] - Attempt 30 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:37:43,796][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:37:43,798][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:43,976][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:37:43,978][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:44,064][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:44,067][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:44,215][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:44,301][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:47,089][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:47,247][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:47,254][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:47,309][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:47,451][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:47,453][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:50,259][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:50,433][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:50,444][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:50,459][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:50,620][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:50,629][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:53,451][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:53,595][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:53,598][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:53,634][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:53,769][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:53,776][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:56,604][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:56,733][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:56,737][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:56,781][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:56,909][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:56,912][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:59,741][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:37:59,840][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:37:59,844][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:37:59,917][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:00,016][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:00,018][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:02,848][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:02,954][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:02,957][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:03,022][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:03,136][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:03,140][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:05,961][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:06,065][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:06,067][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:06,145][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:06,242][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:06,245][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:09,072][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:09,194][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:09,198][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:09,249][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:09,350][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:09,353][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:12,202][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:12,294][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:12,297][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:12,358][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:12,460][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:12,464][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:15,301][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:15,394][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:15,396][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:15,469][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:15,569][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:15,572][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:18,401][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:18,502][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:18,506][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:18,574][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:18,665][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:18,668][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:21,511][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:21,604][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:21,606][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:21,672][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:21,771][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:21,775][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:24,611][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:24,720][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:24,722][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:24,779][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:24,874][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:24,876][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:27,726][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:27,830][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:27,834][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:27,881][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:27,968][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:27,970][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:30,839][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:30,938][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:30,940][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:30,975][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:31,066][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:38:31,069][root][INFO] - Attempt 16 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:38:33,945][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:34,037][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:38:34,039][root][INFO] - Attempt 17 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:38:34,074][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:34,181][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:38:34,183][root][INFO] - Attempt 17 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:38:37,044][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:37,135][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:38:37,138][root][INFO] - Attempt 18 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:38:37,188][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:37,283][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:38:37,286][root][INFO] - Attempt 18 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:38:40,142][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:40,257][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:38:40,259][root][INFO] - Attempt 19 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:38:40,290][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:40,433][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:38:40,436][root][INFO] - Attempt 19 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:38:43,271][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:43,365][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:43,368][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:43,440][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:43,563][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:43,565][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:46,371][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:46,470][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:46,472][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:46,570][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:46,677][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:46,679][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:49,477][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:49,583][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:49,585][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:49,684][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:49,775][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:49,779][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:52,590][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:52,691][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:52,693][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:52,784][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:52,895][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:52,898][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:55,698][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:55,801][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:55,805][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:55,903][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:56,007][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:56,009][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:58,810][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:58,903][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:58,905][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:38:59,014][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:38:59,135][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:38:59,139][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:01,910][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:02,009][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:02,011][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:02,144][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:02,264][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:02,266][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:05,016][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:05,108][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:05,112][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:05,271][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:05,355][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:05,358][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:08,117][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:08,205][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:08,208][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:08,362][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:08,472][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:08,476][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:11,212][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:11,302][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:11,305][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:11,480][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:11,572][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:11,574][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:14,309][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:14,432][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:14,436][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:14,578][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:14,676][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:14,678][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:17,440][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:39:17,441][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:17,541][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:17,543][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:17,681][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:39:17,683][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:17,770][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:17,774][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:20,548][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:20,647][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:20,649][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:20,779][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:20,885][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:20,887][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:23,654][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:23,758][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:23,762][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:23,892][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:23,986][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:23,989][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:26,766][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:26,877][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:26,879][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:26,993][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:27,094][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:27,098][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:29,884][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:29,977][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:29,980][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:30,103][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:30,205][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:30,207][root][INFO] - Attempt 5 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:39:32,984][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:33,079][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:33,081][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:39:33,212][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:33,297][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:33,299][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:39:36,086][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:36,182][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:36,184][root][INFO] - Attempt 7 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:39:36,303][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:36,425][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:36,427][root][INFO] - Attempt 7 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:39:39,196][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:39,289][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:39,291][root][INFO] - Attempt 8 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:39:39,432][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:39,537][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:39,539][root][INFO] - Attempt 8 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:39:42,296][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:42,398][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:39:42,401][root][INFO] - Attempt 9 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "17s"
      }
    ]
  }
}

[2025-07-31 09:39:42,544][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:42,647][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:42,650][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:45,405][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:45,499][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:45,501][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:45,654][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:45,748][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:45,753][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:48,506][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:48,596][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:48,598][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:48,757][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:48,857][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:48,859][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:51,603][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:51,711][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:51,715][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:51,864][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:51,963][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:51,966][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:54,719][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:54,817][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:54,819][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:54,970][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:55,069][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:55,072][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:57,823][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:57,924][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:57,926][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:39:58,077][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:39:58,190][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:39:58,192][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:00,930][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:01,027][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:01,031][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:01,197][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:01,304][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:01,306][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:04,035][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:04,144][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:04,147][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:04,311][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:04,422][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:04,426][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:07,152][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:07,435][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:07,446][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:07,449][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:07,639][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:07,642][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:10,456][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:10,610][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:10,614][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:10,645][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:10,744][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:10,747][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:13,618][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:13,721][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:13,723][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:13,751][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:13,849][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:13,853][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:16,728][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:16,834][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:16,837][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:16,858][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:17,015][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:17,017][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:19,841][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:19,936][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:19,940][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:20,021][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:20,113][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:20,116][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:22,945][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:23,043][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:23,046][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:23,120][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:23,210][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:23,214][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:26,050][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:26,151][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:26,153][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:26,218][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:26,319][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:26,321][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:29,158][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:29,260][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:29,264][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:29,326][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:29,420][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:29,422][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:32,269][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:32,372][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:40:32,374][root][INFO] - Attempt 25 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:40:32,427][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:32,557][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:40:32,559][root][INFO] - Attempt 25 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:40:35,387][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:35,471][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:40:35,473][root][INFO] - Attempt 26 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:40:35,564][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:35,667][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:40:35,669][root][INFO] - Attempt 26 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:40:38,478][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:38,569][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:40:38,573][root][INFO] - Attempt 27 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:40:38,674][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:38,760][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:40:38,762][root][INFO] - Attempt 27 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:40:41,578][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:41,689][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:41,692][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:41,767][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:41,870][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:41,874][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:44,696][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:44,804][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:44,806][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:44,878][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:44,973][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:44,975][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:47,811][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:47,917][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:47,921][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:47,980][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:48,074][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:48,076][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:50,924][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:40:50,926][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:51,029][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:51,032][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:51,080][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:40:51,081][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:51,184][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:51,188][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:54,036][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:54,139][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:54,141][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:54,193][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:54,284][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:54,286][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:57,146][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:57,256][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:57,261][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:40:57,290][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:40:57,382][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:40:57,385][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:00,265][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:00,351][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:00,353][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:00,387][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:00,486][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:00,490][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:03,357][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:03,456][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:03,459][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:03,495][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:03,598][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:03,600][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:06,463][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:06,578][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:06,582][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:06,605][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:06,710][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:06,712][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:09,587][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:09,698][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:09,700][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:09,717][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:09,807][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:09,811][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:12,705][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:12,808][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:12,811][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:12,816][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:12,911][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:12,914][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:15,815][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:15,911][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:15,915][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:15,918][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:16,018][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:16,021][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:18,920][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:19,022][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:19,024][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:19,026][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:19,231][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:19,235][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:22,029][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:22,124][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:22,126][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:22,240][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:22,349][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:22,351][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:25,131][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:25,230][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:25,232][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:25,356][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:25,456][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:25,458][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:28,237][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:28,329][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:28,331][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:28,463][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:28,598][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:28,600][root][INFO] - Attempt 13 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

[2025-07-31 09:41:31,344][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:31,445][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:31,447][root][INFO] - Attempt 14 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:41:31,605][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:31,711][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:31,713][root][INFO] - Attempt 14 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:41:34,452][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:34,557][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:34,561][root][INFO] - Attempt 15 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:41:34,718][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:34,851][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:34,853][root][INFO] - Attempt 15 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:41:37,566][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:37,660][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:37,662][root][INFO] - Attempt 16 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:41:37,858][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:37,955][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:37,959][root][INFO] - Attempt 16 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:41:40,667][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:40,769][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:41:40,771][root][INFO] - Attempt 17 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:41:40,963][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:41,051][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:41,053][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:43,776][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:43,876][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:43,880][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:44,058][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:44,186][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:44,188][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:46,884][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:46,986][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:46,989][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:47,193][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:47,295][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:47,299][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:49,993][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:50,088][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:50,090][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:50,304][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:50,400][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:50,402][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:53,094][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:53,193][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:53,197][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:53,407][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:53,509][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:53,511][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:56,201][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:56,306][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:56,308][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:56,516][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:56,604][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:56,609][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:59,313][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:59,414][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:59,417][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:41:59,613][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:41:59,715][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:41:59,718][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:02,421][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:02,518][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:02,521][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:02,722][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:02,817][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:02,819][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:05,526][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:05,636][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:05,638][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:05,824][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:05,941][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:05,945][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:08,643][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:08,757][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:08,759][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:08,950][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:09,063][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:09,066][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:11,764][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:11,858][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:11,861][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:12,070][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:12,169][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:12,171][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:14,866][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:14,967][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:14,970][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:15,176][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:15,279][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:15,283][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:17,974][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:18,076][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:18,078][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:18,288][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:18,377][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:18,380][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:21,082][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:21,177][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:21,180][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:21,384][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:21,480][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:21,482][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:24,187][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:42:24,189][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:24,298][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:24,304][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:24,485][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:42:24,487][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:24,624][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:24,626][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:27,317][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:27,421][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:27,424][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:27,631][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:27,725][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:27,728][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:30,427][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:30,551][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:30,553][root][INFO] - Attempt 3 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:42:30,731][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:30,840][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:30,843][root][INFO] - Attempt 3 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:42:33,557][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:33,656][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:33,658][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:42:33,846][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:33,947][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:33,951][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:42:36,663][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:36,777][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:36,784][root][INFO] - Attempt 5 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:42:36,956][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:37,081][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:37,084][root][INFO] - Attempt 5 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:42:39,789][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:39,874][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:39,879][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:42:40,093][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:40,199][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:42:40,202][root][INFO] - Attempt 6 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:42:42,883][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:42,990][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:42,992][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:43,206][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:43,308][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:43,312][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:45,997][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:46,101][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:46,103][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:46,317][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:46,420][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:46,422][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:49,107][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:49,203][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:49,207][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:49,424][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:49,525][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:49,527][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:52,211][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:52,311][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:52,317][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:52,532][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:52,640][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:52,645][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:55,322][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:55,417][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:55,419][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:55,649][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:55,752][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:55,754][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:58,424][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:58,526][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:58,529][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:42:58,759][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:42:58,871][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:42:58,873][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:01,534][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:01,668][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:01,671][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:01,878][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:01,996][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:02,000][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:04,675][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:04,767][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:04,770][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:05,004][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:05,119][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:05,121][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:07,774][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:07,877][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:07,881][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:08,126][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:08,238][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:08,241][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:10,886][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:10,985][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:10,988][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:11,246][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:11,359][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:11,363][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:13,993][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:14,091][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:14,093][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:14,368][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:14,463][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:14,466][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:17,097][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:17,192][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:17,196][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:17,470][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:17,588][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:17,590][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:20,201][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:20,310][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:20,312][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:20,595][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:20,735][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:20,737][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:23,325][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:23,455][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:23,457][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:23,743][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:23,958][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:23,960][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:26,462][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:26,563][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:26,568][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:26,965][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:27,079][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:27,082][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:29,572][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:29,669][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:29,672][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:30,086][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:30,175][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:43:30,180][root][INFO] - Attempt 22 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:43:32,676][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:32,771][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:43:32,773][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:43:33,184][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:33,280][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:43:33,283][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:43:35,778][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:35,878][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:43:35,882][root][INFO] - Attempt 24 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:43:36,287][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:36,373][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:43:36,376][root][INFO] - Attempt 24 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:43:38,886][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:38,978][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:43:38,981][root][INFO] - Attempt 25 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:43:39,380][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:39,476][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:43:39,481][root][INFO] - Attempt 25 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:43:41,985][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:42,084][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:42,086][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:42,486][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:42,577][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:42,579][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:45,090][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:45,194][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:45,198][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:45,584][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:45,678][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:45,681][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:48,203][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:48,303][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:48,305][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:48,685][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:48,784][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:48,788][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:51,310][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:51,401][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:51,403][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:51,792][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:51,897][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:51,899][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:54,408][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:54,500][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:54,504][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:54,904][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:54,993][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:54,995][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:57,507][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:43:57,509][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:57,659][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:57,661][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:43:57,998][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:43:58,000][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:43:58,099][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:43:58,103][root][INFO] - Attempt 1 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:00,666][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:00,776][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:00,778][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:01,108][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:01,211][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:01,213][root][INFO] - Attempt 2 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:03,783][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:03,887][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:03,891][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:04,218][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:04,334][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:04,336][root][INFO] - Attempt 3 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:06,895][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:06,989][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:06,992][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:07,341][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:07,447][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:07,451][root][INFO] - Attempt 4 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:09,996][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:10,092][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:10,095][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:10,456][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:10,559][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:10,561][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:13,100][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:13,198][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:13,200][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:13,565][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:13,661][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:13,663][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:16,205][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:16,298][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:16,301][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:16,668][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:16,814][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:16,817][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:19,315][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:19,414][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:19,417][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:19,821][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:19,925][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:19,927][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:22,421][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:22,514][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:22,520][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:22,932][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:23,035][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:23,037][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:25,524][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:25,625][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:25,627][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:26,042][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:26,130][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:26,134][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:28,632][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:28,725][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:28,728][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:29,139][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:29,248][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:44:29,250][root][INFO] - Attempt 11 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "30s"
      }
    ]
  }
}

[2025-07-31 09:44:31,732][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:31,829][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:44:31,834][root][INFO] - Attempt 12 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:44:32,255][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:32,357][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:44:32,359][root][INFO] - Attempt 12 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "27s"
      }
    ]
  }
}

[2025-07-31 09:44:34,838][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:34,941][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:44:34,943][root][INFO] - Attempt 13 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:44:35,364][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:35,458][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:44:35,463][root][INFO] - Attempt 13 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "24s"
      }
    ]
  }
}

[2025-07-31 09:44:37,947][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:38,047][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:44:38,050][root][INFO] - Attempt 14 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:44:38,467][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:38,571][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:44:38,573][root][INFO] - Attempt 14 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "21s"
      }
    ]
  }
}

[2025-07-31 09:44:41,054][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:41,153][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:41,157][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:41,578][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:41,724][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:41,726][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:44,161][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:44,260][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:44,262][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:44,731][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:44,835][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:44,839][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:47,266][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:47,402][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:47,405][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:47,843][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:47,932][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:47,934][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:50,409][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:50,497][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:50,501][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:50,939][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:51,039][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:51,041][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:53,506][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:53,614][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:53,616][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:54,046][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:54,159][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:54,163][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:56,621][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:56,724][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:56,726][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:57,168][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:57,262][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:57,264][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:44:59,731][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:44:59,828][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:44:59,832][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:00,269][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:00,364][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:00,367][root][INFO] - Attempt 21 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:02,837][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:02,945][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:02,948][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:03,371][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:03,470][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:03,475][root][INFO] - Attempt 22 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:05,953][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:06,051][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:06,053][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:06,479][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:06,603][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:06,605][root][INFO] - Attempt 23 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:09,058][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:09,157][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:09,161][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:09,610][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:09,707][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:09,709][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:12,165][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:12,276][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:12,278][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:12,714][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:12,855][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:12,857][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:15,292][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:15,395][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:15,397][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:15,862][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:15,960][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:15,962][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:18,402][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:18,513][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:18,518][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:18,967][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:19,055][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:19,058][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:21,522][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:21,628][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:21,630][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:22,062][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:22,171][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:22,175][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:24,635][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:24,733][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:24,736][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:25,180][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:25,279][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:25,281][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:27,741][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:27,878][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:27,882][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:28,286][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:28,380][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:28,382][root][INFO] - Attempt 30 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "31s"
      }
    ]
  }
}

[2025-07-31 09:45:30,886][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:45:30,887][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:30,995][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:30,998][root][INFO] - Attempt 1 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:45:31,386][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:45:31,387][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:31,492][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:31,497][root][INFO] - Attempt 1 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "28s"
      }
    ]
  }
}

[2025-07-31 09:45:34,003][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:34,099][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:34,101][root][INFO] - Attempt 2 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:45:34,502][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:34,621][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:34,623][root][INFO] - Attempt 2 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

[2025-07-31 09:45:37,105][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:37,195][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:37,199][root][INFO] - Attempt 3 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:45:37,628][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:37,737][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:37,740][root][INFO] - Attempt 3 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "22s"
      }
    ]
  }
}

[2025-07-31 09:45:40,204][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:40,306][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:40,308][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:45:40,745][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:40,836][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:45:40,840][root][INFO] - Attempt 4 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

[2025-07-31 09:45:43,313][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:43,407][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:43,409][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:43,845][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:43,946][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:43,948][root][INFO] - Attempt 5 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:46,414][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:46,526][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:46,530][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:46,953][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:47,041][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:47,043][root][INFO] - Attempt 6 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:49,535][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:49,645][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:49,648][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:50,048][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:50,155][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:50,159][root][INFO] - Attempt 7 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:52,652][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:52,763][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:52,765][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:53,163][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:53,252][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:53,255][root][INFO] - Attempt 8 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:55,769][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:55,863][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:55,867][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:56,259][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:56,358][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:56,361][root][INFO] - Attempt 9 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:58,871][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:58,970][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:58,972][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:45:59,365][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:45:59,469][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:45:59,473][root][INFO] - Attempt 10 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:01,977][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:02,089][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:02,091][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:02,478][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:02,577][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:02,579][root][INFO] - Attempt 11 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:05,096][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:05,207][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:05,209][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:05,584][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:05,685][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:05,688][root][INFO] - Attempt 12 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:08,214][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:08,310][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:08,313][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:08,692][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:08,811][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:08,813][root][INFO] - Attempt 13 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:11,327][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:11,430][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:11,434][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:11,818][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:11,910][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:11,912][root][INFO] - Attempt 14 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:14,438][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:14,537][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:14,542][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:14,917][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:15,015][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:15,017][root][INFO] - Attempt 15 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:17,547][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:17,648][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:17,650][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:18,022][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:18,116][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:18,119][root][INFO] - Attempt 16 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:20,655][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:20,783][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:20,786][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:21,124][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:21,229][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:21,231][root][INFO] - Attempt 17 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:23,790][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:23,910][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:23,914][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:24,236][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:24,340][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:24,342][root][INFO] - Attempt 18 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:26,919][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:27,029][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:27,031][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:27,347][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:27,444][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:27,448][root][INFO] - Attempt 19 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:30,036][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:30,126][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:30,128][root][INFO] - Attempt 20 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:30,453][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:30,548][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:46:30,550][root][INFO] - Attempt 20 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "29s"
      }
    ]
  }
}

[2025-07-31 09:46:33,133][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:33,264][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:46:33,268][root][INFO] - Attempt 21 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:46:33,555][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:33,666][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:46:33,669][root][INFO] - Attempt 21 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "26s"
      }
    ]
  }
}

[2025-07-31 09:46:36,272][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:36,362][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:46:36,365][root][INFO] - Attempt 22 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:46:36,674][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:36,760][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:46:36,764][root][INFO] - Attempt 22 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "23s"
      }
    ]
  }
}

[2025-07-31 09:46:39,369][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:39,470][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:46:39,472][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemma-3-27b"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:46:39,768][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:39,860][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 429 Too Many Requests"
[2025-07-31 09:46:39,862][root][INFO] - Attempt 23 failed with error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemma-3-27b",
              "location": "global"
            },
            "quotaValue": "30"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

[2025-07-31 09:46:42,477][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:42,581][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:42,585][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:42,867][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:42,977][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:42,979][root][INFO] - Attempt 24 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:45,589][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:45,687][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:45,689][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:45,984][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:46,079][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:46,084][root][INFO] - Attempt 25 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:48,694][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:48,803][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:48,805][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:49,089][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:49,200][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:49,202][root][INFO] - Attempt 26 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:51,810][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:51,926][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:51,930][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:52,207][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:52,304][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:52,306][root][INFO] - Attempt 27 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:54,935][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:55,046][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:55,048][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:55,311][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:55,415][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:55,419][root][INFO] - Attempt 28 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:58,053][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:58,147][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:58,150][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:46:58,424][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:46:58,525][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:46:58,527][root][INFO] - Attempt 29 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:47:01,154][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:47:01,272][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:47:01,276][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:47:01,532][LiteLLM][INFO] - 
LiteLLM completion() model= gemma-3-27b-it; provider = gemini
[2025-07-31 09:47:01,632][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemma-3-27b-it:generateContent?key=AIzaSyAOsThfG73iYOo3u3cx1v42lCg1Uq9I4g4 "HTTP/1.1 400 Bad Request"
[2025-07-31 09:47:01,634][root][INFO] - Attempt 30 failed with error: litellm.BadRequestError: VertexAIException BadRequestError - {
  "error": {
    "code": 400,
    "message": "Developer instruction is not enabled for models/gemma-3-27b-it",
    "status": "INVALID_ARGUMENT"
  }
}

[2025-07-31 09:47:04,279][root][INFO] - Code terminated due to too many failed attempts!
[2025-07-31 09:47:04,638][root][INFO] - Code terminated due to too many failed attempts!
