{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A refined priority function for online bin packing that combines multiple factors\n    with adaptive weighting and stochastic exploration.\n    \"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # 1. Capacity-Aware Newtonian Potential\n    potential = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # 2. Normalized Remaining Capacity\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    capacity_priority = np.log(capacity_ratio)\n\n    # 3. Bin Utilization (Encourages filling partially full bins)\n    bin_utilization = 1 - (safe_bins_remain_cap / np.max(bins_remain_cap))  # Normalize to 0-1\n    utilization_priority = np.where(safe_bins_remain_cap >= item, bin_utilization, -np.inf)\n\n    # 4. Item Size Relative to Average Available Capacity (Adaptive Weighting)\n    avg_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1e-9\n    weight_newtonian = np.clip(item / (avg_capacity + 1e-9), 0.0, 1.0)\n    weight_capacity = np.clip(1 - item / (avg_capacity + 1e-9), 0.0, 1.0)\n\n    # 5. Combine Priorities with Adaptive Weights\n    combined_priority = (\n        weight_newtonian * newtonian_priority +\n        weight_capacity * capacity_priority +\n        0.2 * utilization_priority # Weight for utilization\n    )\n\n    # 6. Stochastic Exploration (Introduce some randomness)\n    exploration_factor = 0.01  # Adjust for desired exploration level\n    random_noise = np.random.normal(0, exploration_factor, size=bins_remain_cap.shape)\n    combined_priority += random_noise\n\n    # 7. Handling Invalid Bins and NaN values\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    An enhanced priority function that incorporates adaptive weighting, temperature-based exploration,\n    a refined capacity ratio, and penalties for near-misses.\n    \"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # 1. Capacity-Aware Newtonian Potential (with softened denominator)\n    potential = safe_bins_remain_cap / (np.abs(safe_bins_remain_cap - item) + 0.1)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # 2. Refined Capacity Ratio: Emphasize bins slightly larger than the item.\n    capacity_ratio = safe_bins_remain_cap / (item + 1e-9)\n    capacity_priority = np.where(\n        safe_bins_remain_cap >= item,\n        np.exp(-(capacity_ratio - 1)**2 / 0.5),  # Gaussian-like preference around ratio=1\n        -np.inf\n    )\n\n    # 3. Bin Utilization (Encourages filling partially full bins)\n    bin_utilization = 1 - (safe_bins_remain_cap / np.max(bins_remain_cap))\n    utilization_priority = np.where(safe_bins_remain_cap >= item, bin_utilization, -np.inf)\n\n    # 4. Near-Miss Penalty: Discourage bins that are almost big enough.\n    near_miss_penalty = np.where(\n        (safe_bins_remain_cap < item) & (safe_bins_remain_cap > item * 0.75),  # Tune 0.75\n        -10,  # Significant penalty\n        0\n    )\n\n    # 5. Adaptive Weighting based on Item Size and Available Capacity\n    avg_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1e-9\n    item_size_ratio = np.clip(item / (avg_capacity + 1e-9), 0.0, 1.0)\n    weight_newtonian = 1 - item_size_ratio\n    weight_capacity = item_size_ratio\n\n    # 6. Temperature-Based Stochastic Exploration (Simulated Annealing)\n    temperature = 0.1  # Adjust cooling schedule as needed\n    exploration_factor = temperature * np.exp(-item_size_ratio) # Reduce exploration as item size increase\n    random_noise = np.random.normal(0, exploration_factor, size=bins_remain_cap.shape)\n\n    # 7. Combine Priorities with Adaptive Weights\n    combined_priority = (\n        weight_newtonian * newtonian_priority +\n        weight_capacity * capacity_priority +\n        0.2 * utilization_priority +\n        near_miss_penalty + # Directly add penalty\n        random_noise # Add the noise\n    )\n\n    # 8. Handle Invalid Bins and NaN values\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses a combination of Newtonian potential, capacity ratio, bin utilization, adaptive weighting, and stochastic exploration while the worst heuristic uses only the log of the ratio between the item size and the remaining bin capacity. (2nd) vs (19th) shows same as (1st) vs (20th) with less effect; Comparing (1st) vs (2nd), we see the best heuristic adds bin utilization and stochastic exploration compared to the second best. (3rd) vs (4th) shows the same functionality; Comparing (second worst) vs (worst), we see both heuristics only use log ratios, but the second worst adds a lot of unused library imports; Overall: Better heuristics combine multiple factors, adaptively weight them, and use stochastic exploration. The worst heuristic is too simplistic, and higher-ranked heuristics also benefit from considerations like bin utilization and penalties for near misses.\n- \nOkay, let's redefine \"Current Self-Reflection\" to create better heuristic design strategies. Here's a breakdown focusing on actionable improvements and avoiding common pitfalls, aiming for a balanced and effective approach:\n\n*   **Keywords:** Iterative refinement, problem-specific tuning, balanced complexity, empirical validation.\n\n*   **Advice:** Begin with a basic, interpretable heuristic. Progressively enhance it based on *problem-specific* performance data and insights. Focus on understanding *why* a factor improves results, not just adding it.\n\n*   **Avoid:** Prematurely optimizing for complexity. Avoid overly relying on inspiration from unrelated domains without clear justification and rigorous testing. Don't equate sophistication with effectiveness.\n\n*   **Explanation:** Heuristic design should be an iterative process driven by empirical results. Start simple, then refine by adding complexity only when demonstrably beneficial and well-understood within the problem's context. Prioritize interpretability and validation to avoid over-fitting to specific scenarios.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}