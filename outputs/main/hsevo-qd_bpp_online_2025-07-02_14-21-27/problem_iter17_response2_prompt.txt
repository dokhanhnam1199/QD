{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines Newtonian potential and ratio, adaptively weighted.\"\"\"\n    valid_bins = bins_remain_cap > 0\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Newtonian component\n    potential = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    newtonian_priority = np.nan_to_num(newtonian_priority, neginf=-np.inf)\n\n    # Ratio component\n    ratio_priority = np.log(np.clip(safe_bins_remain_cap / item, 0.001, 1000))\n\n    # Adaptive weighting\n    weight = np.clip(item / (safe_bins_remain_cap + 1e-9), 0.0, 1.0)\n    combined_priority = weight * newtonian_priority + (1 - weight) * ratio_priority\n\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Newtonian Optimization Heuristic: Inspired by gravitational potential,\n    prioritizes bins based on how \"close\" the item's size is to the bin's\n    remaining capacity, scaled by the remaining capacity itself.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero and negative capacity\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n      return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Calculate \"gravitational potential\" - higher potential = higher priority\n    potential = (safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item))\n\n    # Further emphasize bins with capacities closest to the item size but also penalize overflowing the bin\n    priorities = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    priorities = np.nan_to_num(priorities, neginf=-np.inf) # Handle inf values when item >> safe_bins_remain_cap after masking\n    priorities = np.where(~valid_bins, -np.inf, priorities) # Ensure that bins that are initially invalid has -inf priorities\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic incorporates several factors like Newtonian potential, capacity ratio, fragmentation penalty, and adaptive weighting along with a stochastic element, while the worst only considers the ratio of item size to bin capacity. (2nd best) vs (second worst) shows a similar pattern, the second-best also considers Newtonian potential, capacity ratio, fragmentation penalty, adaptive weighting along with a stochastic element, while the second worst also only considers the ratio of item size to bin capacity. Comparing (1st) vs (2nd), we see that they are identical. Comparing (3rd) vs (4th), we see that they are identical. Comparing (second worst) vs (worst), we see that they are identical. Overall: The better heuristics consider multiple factors and adaptive weighting to make more informed decisions, while the worse heuristics rely on simple ratios that are not nuanced enough. The use of techniques like Newtonian potential and fragmentation penalty, along with stochasticity, helps in exploring the solution space and avoiding local optima.\n- \nOkay, let's refine \"Current Self-Reflection\" for designing better heuristics, focusing on actionable improvements and avoiding common pitfalls. Here's a breakdown:\n\n*   **Keywords:** Adaptive weighting, Exploration, Robustness, Multi-factor, Error handling, Context awareness, Iterative testing.\n*   **Advice:** Prioritize creating multi-faceted heuristics with adaptive weighting, robust error handling, and mechanisms for exploration to escape local optima.\n*   **Avoid:** Over-simplification, relying on single-factor heuristics, neglecting edge cases, and insufficient testing of heuristic components.\n*   **Explanation:** Effective heuristics balance complexity and computational cost. Combining multiple factors with adaptive weights allows the heuristic to adapt to different problem instances. Exploration mechanisms (e.g., randomness) prevent stagnation. Robust error handling is crucial for real-world applications. Iterative testing and refinement ensure the chosen heuristic components contribute positively to the overall performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}