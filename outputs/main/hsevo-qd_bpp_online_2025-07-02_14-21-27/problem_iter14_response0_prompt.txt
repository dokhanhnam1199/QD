{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines Newtonian potential and capacity ratio with adaptive weighting.\"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Newtonian component (Focuses on bins close to the item size)\n    potential = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # Capacity ratio component (Prioritizes bins that have space relative to item)\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    ratio_priority = np.log(capacity_ratio)\n\n    # Adaptive weighting based on item size relative to *available* capacity\n    weight = np.clip(item / (np.mean(bins_remain_cap[valid_bins]) + 1e-9), 0.0, 1.0)\n\n    # Combine the priorities with adaptive weighting\n    combined_priority = weight * newtonian_priority + (1 - weight) * ratio_priority\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian and ratio-based approaches for bin packing priority.\"\"\"\n    # Newtonian component (with safety checks)\n    valid_bins = bins_remain_cap > 0\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n    potential = (safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item))\n    newton_priorities = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    newton_priorities = np.nan_to_num(newton_priorities, neginf=-np.inf)\n    newton_priorities = np.where(~valid_bins, -np.inf, newton_priorities)\n\n    # Ratio component (dampened to avoid dominance)\n    ratios = item / bins_remain_cap\n    ratios = np.clip(ratios, ratio_min, ratio_max)  # Clamp for stability\n    log_ratios = np.log(ratios)\n    ratio_priorities = -log_ratios\n\n    # Weighted combination - adaptive weight based on item size relative to bin capacities\n    mean_cap = np.mean(bins_remain_cap) if bins_remain_cap.size > 0 else 0\n    weight = np.clip(item / (mean_cap + epsilon), weight_clip_min, weight_clip_max)  # Avoid division by zero\n\n    combined_priorities = (1 - weight) * newton_priorities + weight * ratio_priorities\n    return combined_priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses a combination of Newtonian potential and capacity ratio with adaptive weighting, while the worst only uses the ratio component. (2nd) incorporates a fragmentation penalty and stochastic exploration, which are absent in (20th). Comparing (2nd best) vs (second worst), (2nd) includes a fragmentation penalty and exploration, while (19th) solely relies on log ratios. Comparing (1st) vs (2nd), (1st) focuses on adaptive weighting between Newtonian potential and capacity ratio, while (2nd) adds a fragmentation penalty and stochastic exploration. (3rd) vs (4th) show negligible differences; they are essentially identical. Comparing (second worst) vs (worst), they are identical. Overall: The better heuristics combine multiple factors (Newtonian potential, capacity ratio, fragmentation penalty) and use adaptive weighting to adjust their behavior based on item size and bin capacity. The poorer heuristics rely on simpler calculations, such as just the ratio of item size to remaining capacity. Adding stochastic elements may improve exploration.\n- \nOkay, let's redefine \"Current self-reflection\" to design better heuristics, focusing on actionable advice and avoiding common pitfalls of ineffective self-reflection.\nHere's a revised approach:\n\n*   **Keywords:** Multi-factor, Adaptive Weights, Error Handling, Stochastic Exploration, Edge Cases, Robustness, Nuance.\n\n*   **Advice:** Systematically combine relevant factors, dynamically adjust weights based on performance, implement comprehensive error handling for edge cases, and introduce controlled randomness for exploration.\n\n*   **Avoid:** Oversimplification (single-factor heuristics), relying solely on computationally cheap solutions, neglecting testing and validation.\n\n*   **Explanation:** Effective heuristic design requires a balanced approach that considers multiple perspectives, learns from past performance through adaptive weighting, and anticipates potential failures with robust error handling. Stochastic exploration is necessary to escape local optima.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}