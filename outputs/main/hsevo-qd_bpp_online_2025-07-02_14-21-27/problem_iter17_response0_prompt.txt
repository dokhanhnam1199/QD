{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A refined priority function for online bin packing that dynamically adjusts\n    its strategy based on item size and bin availability. It combines\n    modified Newtonian potential, capacity ratio, and a fragmentation penalty\n    with adaptive weighting and considers a stochastic element for exploration.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # --- Newtonian Potential (Focus on near-fit bins) ---\n    potential = safe_bins_remain_cap / (np.abs(safe_bins_remain_cap - item) + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # --- Capacity Ratio (How well the item fits relative to bin size) ---\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    ratio_priority = np.log(capacity_ratio)\n\n    # --- Fragmentation Penalty (Discourage leaving very small spaces) ---\n    fragmentation_threshold = 0.1  # As a fraction of bin capacity\n    fragmentation_penalty = np.where(\n        (safe_bins_remain_cap - item > fragmentation_threshold) & (safe_bins_remain_cap >= item),\n        0,  # No penalty if the remaining space is above the threshold OR bin does not fit.\n        -1.0, # High penalty if remains a very small space after placing the item\n    )\n\n    # --- Adaptive Weighting (Item size vs. Available Capacity) ---\n    mean_available_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0\n    weight = np.clip(item / (mean_available_capacity + 1e-9), 0.0, 1.0)\n\n    # --- Combined Priority ---\n    combined_priority = (\n        weight * newtonian_priority\n        + (1 - weight) * ratio_priority\n        + fragmentation_penalty\n    )\n\n    # --- Stochastic Element for Exploration (Optional) ---\n    exploration_probability = 0.01 # Probability to randomly select any valid bin\n    if np.random.rand() < exploration_probability:\n        valid_indices = np.where(valid_bins)[0]\n        if len(valid_indices) > 0:\n            random_index = np.random.choice(valid_indices)\n            combined_priority[:] = -np.inf  # Reset all priorities\n            combined_priority[random_index] = 10 # Give a very high priority\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian and ratio-based approaches for bin packing priority.\"\"\"\n    # Newtonian component (with safety checks)\n    valid_bins = bins_remain_cap > 0\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n    potential = (safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item))\n    newton_priorities = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    newton_priorities = np.nan_to_num(newton_priorities, neginf=-np.inf)\n    newton_priorities = np.where(~valid_bins, -np.inf, newton_priorities)\n\n    # Ratio component (dampened to avoid dominance)\n    ratios = item / bins_remain_cap\n    ratios = np.clip(ratios, ratio_min, ratio_max)  # Clamp for stability\n    log_ratios = np.log(ratios)\n    ratio_priorities = -log_ratios\n\n    # Weighted combination - adaptive weight based on item size relative to bin capacities\n    mean_cap = np.mean(bins_remain_cap) if bins_remain_cap.size > 0 else 0\n    weight = np.clip(item / (mean_cap + epsilon), weight_clip_min, weight_clip_max)  # Avoid division by zero\n\n    combined_priorities = (1 - weight) * newton_priorities + weight * ratio_priorities\n    return combined_priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic incorporates several factors like Newtonian potential, capacity ratio, fragmentation penalty, and adaptive weighting along with a stochastic element, while the worst only considers the ratio of item size to bin capacity. (2nd best) vs (second worst) shows a similar pattern, the second-best also considers Newtonian potential, capacity ratio, fragmentation penalty, adaptive weighting along with a stochastic element, while the second worst also only considers the ratio of item size to bin capacity. Comparing (1st) vs (2nd), we see that they are identical. Comparing (3rd) vs (4th), we see that they are identical. Comparing (second worst) vs (worst), we see that they are identical. Overall: The better heuristics consider multiple factors and adaptive weighting to make more informed decisions, while the worse heuristics rely on simple ratios that are not nuanced enough. The use of techniques like Newtonian potential and fragmentation penalty, along with stochasticity, helps in exploring the solution space and avoiding local optima.\n- \nOkay, let's refine \"Current Self-Reflection\" for designing better heuristics, focusing on actionable improvements and avoiding common pitfalls. Here's a breakdown:\n\n*   **Keywords:** Adaptive weighting, Exploration, Robustness, Multi-factor, Error handling, Context awareness, Iterative testing.\n*   **Advice:** Prioritize creating multi-faceted heuristics with adaptive weighting, robust error handling, and mechanisms for exploration to escape local optima.\n*   **Avoid:** Over-simplification, relying on single-factor heuristics, neglecting edge cases, and insufficient testing of heuristic components.\n*   **Explanation:** Effective heuristics balance complexity and computational cost. Combining multiple factors with adaptive weights allows the heuristic to adapt to different problem instances. Exploration mechanisms (e.g., randomness) prevent stagnation. Robust error handling is crucial for real-world applications. Iterative testing and refinement ensure the chosen heuristic components contribute positively to the overall performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}