```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An enhanced priority function for online bin packing, incorporating adaptive weights,
    edge case handling, stochastic exploration, and multi-factor analysis for robustness.
    """

    valid_bins = bins_remain_cap > 0
    if not np.any(valid_bins):
        return np.zeros_like(bins_remain_cap)

    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)

    # 1. First-Fit Decreasing Inspired Score
    # Prioritize bins that have just enough space (or a little more)
    ff_score = np.exp(-np.abs(safe_bins_remain_cap - item) / (item + 1e-9))
    ff_priority = np.where(safe_bins_remain_cap >= item, ff_score, -np.inf)

    # 2. Waste Minimization Score
    # Encourage filling bins completely, penalize leaving too much space
    waste = safe_bins_remain_cap - item
    waste_penalty = np.where(waste >= 0, np.exp(-waste / (np.mean(safe_bins_remain_cap[safe_bins_remain_cap >= item]) + 1e-9)), -np.inf) # Adjust scale by average. If no valid average use a small value

    # 3. Remaining Capacity Ratio
    capacity_ratio = np.clip(safe_bins_remain_cap / (np.max(bins_remain_cap) + 1e-9), 0.001, 1.0)
    capacity_priority = np.log(capacity_ratio)

    # 4. Adaptive Weighting
    # Adjust weights based on item size relative to available capacity
    avg_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1e-9
    item_ratio = item / (avg_capacity + 1e-9)
    weight_ff = np.clip(1 - item_ratio, 0.1, 0.9)  # Favor FF for smaller items
    weight_waste = np.clip(item_ratio, 0.1, 0.9)  # Favor waste minimization for larger items
    weight_capacity = 0.2

    # 5. Combined Priority
    combined_priority = (
        weight_ff * ff_priority +
        weight_waste * waste_penalty +
        weight_capacity * capacity_priority
    )

    # 6. Stochastic Exploration with Adaptive Noise
    exploration_factor = np.clip(0.1 / (1 + item_ratio), 0.001, 0.05)  # Reduce exploration for larger items
    random_noise = np.random.normal(0, exploration_factor, size=bins_remain_cap.shape)
    combined_priority += random_noise

    # 7. Bin Diversity (Slightly penalize using same bin repeatedly)
    bin_usage_history = np.zeros_like(bins_remain_cap, dtype=float)  # Assume no prior usage initially - adjust as needed in application
    bin_usage_penalty = bin_usage_history / (np.sum(bin_usage_history) + 1e-9) if np.sum(bin_usage_history) > 0 else 0 # normalize usage
    combined_priority -= 0.01 * bin_usage_penalty # Small penalty for overused bins

    # 8. Handling Invalid Bins and NaN values
    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)
    priorities = np.where(~valid_bins, -np.inf, combined_priority)

    return priorities
```
