[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Newtonian Optimization Heuristic: Inspired by gravitational potential,\n    prioritizes bins based on how \"close\" the item's size is to the bin's\n    remaining capacity, scaled by the remaining capacity itself.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero and negative capacity\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n      return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Calculate \"gravitational potential\" - higher potential = higher priority\n    potential = (safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item))\n\n    # Further emphasize bins with capacities closest to the item size but also penalize overflowing the bin\n    priorities = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    priorities = np.nan_to_num(priorities, neginf=-np.inf) # Handle inf values when item >> safe_bins_remain_cap after masking\n    priorities = np.where(~valid_bins, -np.inf, priorities) # Ensure that bins that are initially invalid has -inf priorities\n\n    return priorities",
    "response_id": 2,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 182.83669636412918,
    "mi": 76.27174945664568,
    "token_count": 160.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian and ratio-based approaches for bin packing priority.\"\"\"\n    # Newtonian component (with safety checks)\n    valid_bins = bins_remain_cap > 0\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n    potential = (safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item))\n    newton_priorities = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    newton_priorities = np.nan_to_num(newton_priorities, neginf=-np.inf)\n    newton_priorities = np.where(~valid_bins, -np.inf, newton_priorities)\n\n    # Ratio component (dampened to avoid dominance)\n    ratios = item / bins_remain_cap\n    ratios = np.clip(ratios, 0.01, 100)  # Clamp for stability\n    log_ratios = np.log(ratios)\n    ratio_priorities = -log_ratios\n\n    # Weighted combination - adaptive weight based on item size relative to bin capacities\n    mean_cap = np.mean(bins_remain_cap) if bins_remain_cap.size > 0 else 0\n    weight = np.clip(item / (mean_cap + 1e-9), 0, 1)  # Avoid division by zero\n\n    combined_priorities = (1 - weight) * newton_priorities + weight * ratio_priorities\n    return combined_priorities",
    "response_id": 9,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 218.7248250995196,
    "mi": 84.29374525432536,
    "token_count": 208.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Adaptive Capacity Matching Heuristic: Prioritizes bins based on how well\n    the item's size \"fits\" into the remaining capacity, considering both\n    the absolute difference and the proportion of the bin filled. Also includes a small random factor to handle pathological cases.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero and negative capacity\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n      return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Calculate capacity difference\n    capacity_diff = np.abs(safe_bins_remain_cap - item)\n\n    # Calculate proportion of bin filled if item is added\n    proportion_filled = np.where(safe_bins_remain_cap >= item, item / safe_bins_remain_cap, -np.inf)  # Negative inf if item doesn't fit\n\n    # Calculate a combined score: lower difference AND higher fill is better\n    priority = proportion_filled / (capacity_diff + 1e-6) # Adding small number to prevent division by zero and stabilize\n\n    # Add a small random factor to avoid stagnation and explore different solutions\n    priority += np.random.rand(len(bins_remain_cap)) * 0.01\n\n    # Ensure the item fits in the bin, otherwise, very low priority\n    priority = np.where(safe_bins_remain_cap >= item, priority, -np.inf)\n\n    priority = np.nan_to_num(priority, neginf=-np.inf)\n    priority = np.where(~valid_bins, -np.inf, priority)  # Invalid bins get lowest priority\n    return priority",
    "response_id": 2,
    "tryHS": true,
    "obj": 3.9888312724371757,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 299.8556500836541,
    "mi": 70.66480832368308,
    "token_count": 229.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, invalid_priority: float = -66.93412907195969) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Newtonian Optimization Heuristic: Inspired by gravitational potential,\n    prioritizes bins based on how \"close\" the item's size is to the bin's\n    remaining capacity, scaled by the remaining capacity itself.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        invalid_priority: Priority assigned to invalid bins (e.g., negative capacity).\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero and negative capacity\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n      return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 4.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 11.60964047443681,
    "mi": 64.37926284605251,
    "token_count": 59.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian and ratio-based approaches with adaptive weighting.\"\"\"\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n    \n    # Newtonian component\n    potential = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # Ratio-based component\n    ratio_priority = np.log(np.clip(safe_bins_remain_cap / item, 0.001, 1000))  # Clip for stability\n\n    # Adaptive weighting based on item size relative to bin capacity\n    weight = np.clip(item / (safe_bins_remain_cap + 1e-9), 0.0, 1.0) # Avoid zero division\n    combined_priority = weight * newtonian_priority + (1 - weight) * ratio_priority\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n    \n    return priorities",
    "response_id": 1,
    "tryHS": true,
    "obj": 3.9688871160749857,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 185.46604019833754,
    "mi": 77.54416164681646,
    "token_count": 160.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines several strategies:\n    - Volume Utilization: Encourages filling bins as much as possible.\n    - Balance: Tries to equalize the remaining space in the bins.\n    - Penalty for large items: Reduce the chance that large items leave bins highly fragmented.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, -1)  # Use -1 for invalid bins\n\n    # 1. Volume Utilization Priority: Favor bins that will be filled well.\n    volume_utilization_priority = np.where(safe_bins_remain_cap >= item, item / safe_bins_remain_cap, -np.inf)\n\n    # 2. Remaining Space Balance Priority:  Penalize bins which after insertion would have small remaining space and large items.\n    balance_priority = np.where(safe_bins_remain_cap >= item, (safe_bins_remain_cap - item) / np.max(bins_remain_cap), -np.inf)\n\n    # 3. Large Item Penalty\n    large_item_penalty = np.where(item > np.mean(bins_remain_cap), -0.1, 0.0)  # Small penalty if item is large\n\n    # 4. Combine Priorities with weights\n\n    combined_priority = (\n        0.6 * volume_utilization_priority +\n        0.3 * (-balance_priority) +  # Invert to prefer smaller remaining space.\n        0.1 * large_item_penalty\n    )\n\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 270.0,
    "mi": 85.55467272227024,
    "token_count": 224.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_hs0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, ratio_min: float = 0.06147170424328355, ratio_max: float = 22.675894460204006, weight_clip_min: float = 0.049915106775598406, weight_clip_max: float = 0.9977039285217217, epsilon: float = 4.547998327897835e-09) -> np.ndarray:\n    \"\"\"Combines Newtonian and ratio-based approaches for bin packing priority.\"\"\"\n    # Newtonian component (with safety checks)\n    valid_bins = bins_remain_cap > 0\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n    potential = (safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item))\n    newton_priorities = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    newton_priorities = np.nan_to_num(newton_priorities, neginf=-np.inf)\n    newton_priorities = np.where(~valid_bins, -np.inf, newton_priorities)\n\n    # Ratio component (dampened to avoid dominance)\n    ratios = item / bins_remain_cap\n    ratios = np.clip(ratios, ratio_min, ratio_max)  # Clamp for stability\n    log_ratios = np.log(ratios)\n    ratio_priorities = -log_ratios\n\n    # Weighted combination - adaptive weight based on item size relative to bin capacities\n    mean_cap = np.mean(bins_remain_cap) if bins_remain_cap.size > 0 else 0\n    weight = np.clip(item / (mean_cap + epsilon), weight_clip_min, weight_clip_max)  # Avoid division by zero\n\n    combined_priorities = (1 - weight) * newton_priorities + weight * ratio_priorities\n    return combined_priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 218.7248250995196,
    "mi": 84.29374525432536,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian potential and ratio, adaptively weighted.\"\"\"\n    valid_bins = bins_remain_cap > 0\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Newtonian component\n    potential = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n    newtonian_priority = np.nan_to_num(newtonian_priority, neginf=-np.inf)\n\n    # Ratio component\n    ratio_priority = np.log(np.clip(safe_bins_remain_cap / item, 0.001, 1000))\n\n    # Adaptive weighting\n    weight = np.clip(item / (safe_bins_remain_cap + 1e-9), 0.0, 1.0)\n    combined_priority = weight * newtonian_priority + (1 - weight) * ratio_priority\n\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 3.9688871160749857,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 235.5603911808226,
    "mi": 83.62467320946914,
    "token_count": 208.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response3.txt_stdout.txt",
    "code_path": "problem_iter9_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A multifactorial and adaptive priority function for online bin packing.\n\n    Combines multiple heuristics with adaptive weighting based on bin fill level and item size.\n    Prioritizes bins that are neither too full nor too empty and encourages exploration of less utilized bins.\n    \"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n    bin_size = np.max(bins_remain_cap) # Assuming all bins have the same max capacity\n\n    # Heuristic 1: Remaining Capacity Ratio (Focus: Utilization)\n    capacity_ratio = safe_bins_remain_cap / bin_size\n    capacity_priority = capacity_ratio  # Higher remaining capacity is initially better.\n\n    # Heuristic 2: Item Fit Score (Focus: Avoiding Fragmentation)\n    fit_score = np.exp(-np.abs(safe_bins_remain_cap - item) / (bin_size / 4)) # Gaussian-like preference for close fits. Adjusted standard deviation to bin_size /4\n    fit_priority = fit_score\n\n    # Heuristic 3: Bin Usage (Focus: Exploration)\n    usage_level = 1 - capacity_ratio\n    usage_priority = np.sqrt(usage_level) # Preferentially selects bins with higher utilization for exploration. Square root dampens the effect.\n\n    # Heuristic 4: Modified Newtonian (Focus: Packing Efficiency)\n    newtonian_component = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, newtonian_component, -np.inf)\n\n\n    # Adaptive Weighting based on item size\n    item_size_ratio = item / bin_size\n    weight_capacity = 0.2 if item_size_ratio < 0.3 else (0.1 if item_size_ratio < 0.6 else 0.05)  # Smaller items: prioritize filling almost empty bins.\n    weight_fit = 0.5 if item_size_ratio < 0.3 else (0.4 if item_size_ratio < 0.6 else 0.3 ) # Moderate item fit is more important for small items\n    weight_usage = 0.2 if item_size_ratio < 0.3 else (0.3 if item_size_ratio < 0.6 else 0.4)  # larger items focus on usage\n    weight_newtonian = 0.1 if item_size_ratio < 0.3 else (0.2 if item_size_ratio < 0.6 else 0.25) # packing efficiency\n\n    # Combined Priority\n    combined_priority = (\n        weight_capacity * capacity_priority +\n        weight_fit * fit_priority +\n        weight_usage * usage_priority +\n        weight_newtonian * newtonian_priority\n    )\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 27.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 476.48372872560566,
    "mi": 79.21177752051561,
    "token_count": 342.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian potential and capacity ratio with adaptive weighting.\"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Newtonian component (Focuses on bins close to the item size)\n    potential = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # Capacity ratio component (Prioritizes bins that have space relative to item)\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    ratio_priority = np.log(capacity_ratio)\n\n    # Adaptive weighting based on item size relative to *available* capacity\n    weight = np.clip(item / (np.mean(bins_remain_cap[valid_bins]) + 1e-9), 0.0, 1.0)\n\n    # Combine the priorities with adaptive weighting\n    combined_priority = weight * newtonian_priority + (1 - weight) * ratio_priority\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 3.7893897088153174,
    "SLOC": 13.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 277.43499338166504,
    "mi": 86.60858784422052,
    "token_count": 209.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A refined priority function for online bin packing that dynamically adjusts\n    its strategy based on item size and bin availability. It combines\n    modified Newtonian potential, capacity ratio, and a fragmentation penalty\n    with adaptive weighting and considers a stochastic element for exploration.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # --- Newtonian Potential (Focus on near-fit bins) ---\n    potential = safe_bins_remain_cap / (np.abs(safe_bins_remain_cap - item) + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # --- Capacity Ratio (How well the item fits relative to bin size) ---\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    ratio_priority = np.log(capacity_ratio)\n\n    # --- Fragmentation Penalty (Discourage leaving very small spaces) ---\n    fragmentation_threshold = 0.1  # As a fraction of bin capacity\n    fragmentation_penalty = np.where(\n        (safe_bins_remain_cap - item > fragmentation_threshold) & (safe_bins_remain_cap >= item),\n        0,  # No penalty if the remaining space is above the threshold OR bin does not fit.\n        -1.0, # High penalty if remains a very small space after placing the item\n    )\n\n    # --- Adaptive Weighting (Item size vs. Available Capacity) ---\n    mean_available_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0\n    weight = np.clip(item / (mean_available_capacity + 1e-9), 0.0, 1.0)\n\n    # --- Combined Priority ---\n    combined_priority = (\n        weight * newtonian_priority\n        + (1 - weight) * ratio_priority\n        + fragmentation_penalty\n    )\n\n    # --- Stochastic Element for Exploration (Optional) ---\n    exploration_probability = 0.01 # Probability to randomly select any valid bin\n    if np.random.rand() < exploration_probability:\n        valid_indices = np.where(valid_bins)[0]\n        if len(valid_indices) > 0:\n            random_index = np.random.choice(valid_indices)\n            combined_priority[:] = -np.inf  # Reset all priorities\n            combined_priority[random_index] = 10 # Give a very high priority\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 3.799361786996424,
    "SLOC": 21.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 463.551887559856,
    "mi": 81.66963847055679,
    "token_count": 289.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response0.txt_stdout.txt",
    "code_path": "problem_iter13_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, ratio_clip_lower: float = 0.009147337158257685, ratio_clip_upper: float = 2188.9067474017284, weight_clip_lower: float = -0.8025456592788214, weight_clip_upper: float = 0.42596515735241103, weight_epsilon: float = 5.620047065084735e-07) -> np.ndarray:\n    \"\"\"Combines Newtonian and ratio-based approaches with adaptive weighting.\"\"\"\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 4.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 11.60964047443681,
    "mi": 77.02781257964013,
    "token_count": 80.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian potential, capacity ratio, and fragmentation penalty.\"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Newtonian potential\n    potential = safe_bins_remain_cap / (np.abs(safe_bins_remain_cap - item) + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # Capacity ratio\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    ratio_priority = np.log(capacity_ratio)\n\n    # Fragmentation penalty\n    fragmentation_threshold = 0.1\n    fragmentation_penalty = np.where(\n        (safe_bins_remain_cap - item > fragmentation_threshold) & (safe_bins_remain_cap >= item),\n        0,\n        -1.0,\n    )\n\n    # Adaptive weighting\n    mean_available_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0\n    weight = np.clip(item / (mean_available_capacity + 1e-9), 0.0, 1.0)\n\n    # Combined priority\n    combined_priority = (\n        weight * newtonian_priority\n        + (1 - weight) * ratio_priority\n        + fragmentation_penalty\n    )\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.7893897088153174,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 129.32351694048162,
    "mi": 90.2030355961449,
    "token_count": 143.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response0.txt_stdout.txt",
    "code_path": "problem_iter15_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A refined priority function for online bin packing that combines multiple factors\n    with adaptive weighting and stochastic exploration.\n    \"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # 1. Capacity-Aware Newtonian Potential\n    potential = safe_bins_remain_cap / np.abs(safe_bins_remain_cap - item + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # 2. Normalized Remaining Capacity\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    capacity_priority = np.log(capacity_ratio)\n\n    # 3. Bin Utilization (Encourages filling partially full bins)\n    bin_utilization = 1 - (safe_bins_remain_cap / np.max(bins_remain_cap))  # Normalize to 0-1\n    utilization_priority = np.where(safe_bins_remain_cap >= item, bin_utilization, -np.inf)\n\n    # 4. Item Size Relative to Average Available Capacity (Adaptive Weighting)\n    avg_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1e-9\n    weight_newtonian = np.clip(item / (avg_capacity + 1e-9), 0.0, 1.0)\n    weight_capacity = np.clip(1 - item / (avg_capacity + 1e-9), 0.0, 1.0)\n\n    # 5. Combine Priorities with Adaptive Weights\n    combined_priority = (\n        weight_newtonian * newtonian_priority +\n        weight_capacity * capacity_priority +\n        0.2 * utilization_priority # Weight for utilization\n    )\n\n    # 6. Stochastic Exploration (Introduce some randomness)\n    exploration_factor = 0.01  # Adjust for desired exploration level\n    random_noise = np.random.normal(0, exploration_factor, size=bins_remain_cap.shape)\n    combined_priority += random_noise\n\n    # 7. Handling Invalid Bins and NaN values\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 3.769445552453127,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 436.75452949098377,
    "mi": 81.07918893168419,
    "token_count": 321.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Newtonian potential, capacity ratio, and fragmentation penalty with adaptive weighting.\"\"\"\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)\n\n    # Newtonian Potential\n    potential = safe_bins_remain_cap / (np.abs(safe_bins_remain_cap - item) + 1e-9)\n    newtonian_priority = np.where(safe_bins_remain_cap >= item, potential, -np.inf)\n\n    # Capacity Ratio\n    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)\n    ratio_priority = np.log(capacity_ratio)\n\n    # Fragmentation Penalty\n    fragmentation_threshold = 0.1\n    fragmentation_penalty = np.where(\n        (safe_bins_remain_cap - item > fragmentation_threshold) & (safe_bins_remain_cap >= item),\n        0,\n        -1.0,\n    )\n\n    # Adaptive Weighting\n    mean_available_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0\n    weight = np.clip(item / (mean_available_capacity + 1e-9), 0.0, 1.0)\n\n    # Combined Priority\n    combined_priority = (\n        weight * newtonian_priority\n        + (1 - weight) * ratio_priority\n        + fragmentation_penalty\n    )\n\n    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)\n    priorities = np.where(~valid_bins, -np.inf, combined_priority)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 3.7893897088153174,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 85.95159310338741,
    "mi": 63.47042011276681,
    "token_count": 134.0,
    "exec_success": true
  }
]