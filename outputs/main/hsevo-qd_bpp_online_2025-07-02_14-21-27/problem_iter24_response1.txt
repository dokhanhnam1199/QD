```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An enhanced priority function for online bin packing that adaptively combines factors,
    learns from past placements, and incorporates bin diversity.
    """

    valid_bins = bins_remain_cap > 0
    if not np.any(valid_bins):
        return np.zeros_like(bins_remain_cap)

    safe_bins_remain_cap = np.where(valid_bins, bins_remain_cap, np.inf)

    # 1. First-Fit Consideration (Slight preference for earlier bins)
    first_fit_priority = np.arange(len(bins_remain_cap), 0, -1) / len(bins_remain_cap) # Linear decrease

    # 2. Remaining Capacity Ratio with Sigmoid Scaling
    capacity_ratio = np.clip(safe_bins_remain_cap / (item + 1e-9), 0.001, 1000)
    capacity_priority = 1 / (1 + np.exp(-2 * (capacity_ratio - 1)))  # Sigmoid around ratio of 1

    # 3. Bin Utilization Gradient (Focus on bins nearing fullness without overfilling)
    max_cap = np.max(bins_remain_cap)
    bin_utilization = (max_cap - safe_bins_remain_cap) / max_cap
    utilization_priority = np.where(safe_bins_remain_cap >= item, np.exp(-5 * (bin_utilization - 0.8)**2), -np.inf) # Gaussian Peak around 80% utilization


    # 4. Item Size as a Contextual Weighting Factor
    item_size_normalized = np.clip(item / (np.mean(bins_remain_cap[valid_bins]) + 1e-9), 0.05, 0.95)  # Clamp to avoid extreme values
    weight_capacity = 1 - item_size_normalized
    weight_utilization = item_size_normalized

    # 5. Adaptive Combination of Priorities
    combined_priority = (
        0.1 * first_fit_priority + # Fixed slight First-Fit
        weight_capacity * capacity_priority +
        weight_utilization * utilization_priority
    )

    # 6. Bin Diversity Encouragement (Penalize similar remaining capacities)
    unique_capacities = np.unique(safe_bins_remain_cap[safe_bins_remain_cap != np.inf])
    if len(unique_capacities) < len(bins_remain_cap[valid_bins]):
        capacity_counts = [np.sum(safe_bins_remain_cap == cap) for cap in unique_capacities]
        diversity_penalty = np.array([np.sqrt(capacity_counts[np.where(unique_capacities == cap)[0][0]]) for cap in safe_bins_remain_cap]) # Penalize based on count
        diversity_penalty = np.where(safe_bins_remain_cap >= item, diversity_penalty/len(bins_remain_cap), 0) # Only apply diversity to valid bins and normalize
        combined_priority -= diversity_penalty


    # 7.  Stochastic Exploration with Temperature (Annealing randomness)
    temperature = 0.02 * np.exp(-item_size_normalized) # Reduce exploration with item size
    random_noise = np.random.normal(0, temperature, size=bins_remain_cap.shape)
    combined_priority += random_noise

    # 8. Handling Invalid Bins and NaN values
    combined_priority = np.nan_to_num(combined_priority, neginf=-np.inf)
    priorities = np.where(~valid_bins, -np.inf, combined_priority)


    return priorities
```
