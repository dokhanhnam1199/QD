[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes inverse waste for tight fits, with a subtle bonus for\n    bins already fuller. Uses machine epsilon for stability.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    can_fit_mask = bins_remain_cap >= item\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Use machine epsilon for robust numerical stability, as recommended by analysis.\n    epsilon = np.finfo(float).eps\n\n    # Core Best Fit (BF) priority: Inverse of (remaining_waste + epsilon).\n    # This provides a strong non-linear preference for perfect or very tight fits,\n    # consistent with the top-performing 'priority_v0' heuristic.\n    base_priority = 1.0 / (remaining_waste + epsilon)\n\n    # Adaptive / Global Utility Element:\n    # Introduce a subtle bonus for bins that are already more full (have less remaining capacity).\n    # This element aligns with \"Adaptive Logic\" and \"Global Utility\" advice by encouraging\n    # the closing of already utilized bins. It acts as a weighted tie-breaker or minor nudge\n    # when the primary Best Fit scores are very close.\n    # We assume a normalized bin capacity of 1.0, where `1.0 - bins_remain_cap` represents\n    # the portion of the bin that is already filled.\n    WEIGHT_FULLNESS_BONUS = 1e-7 # A small, tunable weight chosen to ensure this bonus\n                                 # is secondary and does not override the primary\n                                 # waste minimization unless scores are extremely close.\n\n    current_fullness = 1.0 - bins_remain_cap[can_fit_mask]\n    \n    fullness_bonus = WEIGHT_FULLNESS_BONUS * current_fullness\n    \n    # Combine the dominant Best Fit priority with the subtle fullness bonus.\n    priorities[can_fit_mask] = base_priority + fullness_bonus\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines robust Best Fit (prioritizing minimal waste) with an adaptive, linear bias\n    towards selecting already fuller bins. This hybrid approach aims for both immediate\n    waste minimization and long-term bin consolidation for improved global utility.\n    \"\"\"\n    # Initialize all priorities to negative infinity, unequivocally marking bins\n    # that cannot accommodate the item as unavailable.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify which bins have sufficient capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return the initialized priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the potential remaining space (waste) if the item were placed in fit-capable bins.\n    potential_remaining_space = bins_remain_cap[can_fit_mask] - item\n\n    # Use a small epsilon for numerical stability, especially for perfect fits (waste = 0).\n    # This ensures perfect fits receive a very high, but finite, priority score.\n    epsilon = np.finfo(float).eps\n\n    # Core Best Fit Component: Assign priority as the inverse of (potential remaining space + epsilon).\n    # This strongly favors bins that result in minimal remaining space.\n    best_fit_scores = 1.0 / (potential_remaining_space + epsilon)\n\n    # Adaptive Consolidation Bias Component:\n    # Introduce a positive bias for bins that are already relatively full.\n    # This encourages packing into existing, more utilized bins, contributing to\n    # overall bin consolidation and reducing the number of bins used.\n    # We use the maximum remaining capacity among *all* bins as a dynamic reference\n    # for what an \"empty\" bin looks like in the current system state.\n    max_rem_cap = np.max(bins_remain_cap)\n\n    # Calculate the relative \"fullness\" of each fitting bin. A lower bins_remain_cap\n    # indicates a fuller bin, resulting in a higher fullness score (closer to 1).\n    # Add epsilon to denominator to prevent division by zero if max_rem_cap is 0 (e.g., all bins are full).\n    # In such a case, can_fit_mask would likely be all false unless item is 0.\n    relative_fullness = (max_rem_cap - bins_remain_cap[can_fit_mask]) / (max_rem_cap + epsilon)\n\n    # Define the weight of the consolidation bias. This is a tunable parameter.\n    # A small positive value ensures this bias influences decisions, especially\n    # when Best Fit scores are very close, without overpowering the primary\n    # waste minimization objective.\n    consolidation_bias_weight = 0.05\n\n    # Combine the Best Fit score with the adaptive consolidation bias.\n    # The bias is added to the Best Fit score, subtly promoting fuller bins.\n    priorities[can_fit_mask] = best_fit_scores + consolidation_bias_weight * relative_fullness\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using an \"Accelerated Best Fit\" heuristic. It strongly favors\n    tight fits by minimizing waste, and applies an additional non-linear penalty to larger\n    waste values, thereby accelerating the preference for bin completion and reducing fragmentation.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): A NumPy array representing the remaining capacity\n                                      in each bin.\n\n    Returns:\n        np.ndarray: A NumPy array of priorities for each bin. Bins unable to fit\n                    the item will have a priority of -np.inf.\n    \"\"\"\n    # Use machine epsilon for numerical stability, ensuring perfect fits (waste = 0)\n    # receive an extremely high, finite priority score.\n    epsilon = np.finfo(float).eps\n\n    # Initialize priorities to negative infinity, unequivocally disqualifying bins\n    # that cannot accommodate the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins with sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining space (waste) in suitable bins after placing the item.\n    # A smaller waste indicates a more efficient fit.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Define a coefficient for the squared waste penalty. This constant can be tuned,\n    # but a value of 1.0 provides a significant, disproportionate penalty for larger wastes.\n    # This term makes the heuristic more aggressive in pursuing very tight fits.\n    # It indirectly promotes closing bins faster and discourages leaving moderately large gaps.\n    waste_squared_penalty_coeff = 1.0\n\n    # Calculate priority as the inverse of a \"penalized waste\" term.\n    # The term `(remaining_waste + epsilon)` handles the standard Best Fit.\n    # The additional term `waste_squared_penalty_coeff * remaining_waste**2` introduces\n    # a stronger, non-linear penalty for larger waste values. This effectively\n    # \"accelerates\" the preference for minimal waste.\n    penalized_waste = remaining_waste + epsilon + waste_squared_penalty_coeff * (remaining_waste**2)\n\n    priorities[can_fit_mask] = 1.0 / penalized_waste\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid Best Fit: prioritizes tight fits, with a bonus for already-full bins.\n    Combines inverse waste minimization (Best Fit) with a proportional bonus for\n    the current fullness of a bin, encouraging efficient bin closure.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Epsilon for numerical stability, especially for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Primary Best Fit component: Inverse of (remaining_waste + epsilon).\n    # This gives disproportionately high scores to tighter fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap).\n    # It acts as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)\n\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence, acting as a tie-breaker\n    # or a mild preference for already-fuller bins with similar Best Fit scores.\n    alpha = 0.01  # Tunable parameter: Adjust based on desired balance.\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + alpha * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced. This hybrid approach\n    # aims for immediate efficiency (Best Fit) while adaptively guiding towards bin closure.\n    priorities[can_fit_mask] = best_fit_score * (1.0 + alpha * bin_fullness_score)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item into each bin, implementing a\n    Best Fit with Strong Perfect Fit Preference and Inverse Waste Scoring.\n\n    This heuristic prioritizes bins with smallest remaining capacity,\n    strongly favoring perfect fits. For others, it uses inverse waste\n    scoring, penalizing larger gaps non-linearly. Combines robust\n    tight-fit with bin closure incentive.\n    \"\"\"\n    # Assuming bin capacity is normalized to 1.0. This simplifies thresholds.\n    # If actual capacities vary, a `bin_capacity` parameter would be needed.\n    BIN_CAPACITY = 1.0\n\n    # A small tolerance for floating-point comparisons to consider a fit \"perfect\"\n    PERFECT_FIT_TOLERANCE = 1e-6\n\n    # Smallest positive float for numerical stability, primarily to prevent division by zero.\n    EPSILON = np.finfo(float).eps\n\n    # A very high score assigned to perfect or near-perfect fits.\n    # This makes them unequivocally the most desirable choice, encouraging bin closure.\n    MAX_PRIORITY_SCORE = 1e12  # A large constant to ensure dominance of perfect fits\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this value, ensuring they are never chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We allow a tiny negative remaining space due to floating-point precision.\n    can_fit_mask = potential_remaining_space >= -PERFECT_FIT_TOLERANCE\n\n    # Extract the potential remaining spaces only for bins where the item can fit.\n    fitting_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Initialize priorities for fitting bins.\n    fitting_priorities = np.zeros_like(fitting_potential_rem_space)\n\n    # Identify perfect or near-perfect fits based on the defined tolerance.\n    perfect_fit_mask = np.abs(fitting_potential_rem_space) <= PERFECT_FIT_TOLERANCE\n\n    # Assign the maximal priority score for perfect fits. This strongly encourages closing bins.\n    fitting_priorities[perfect_fit_mask] = MAX_PRIORITY_SCORE\n\n    # For bins that are not a perfect fit, apply an inverse waste scoring.\n    # This creates a strong non-linear preference for smaller remaining spaces (less waste).\n    # The smaller the remaining space, the higher the 1/waste score.\n    non_perfect_fit_mask = ~perfect_fit_mask\n    \n    # Calculate waste for inverse scoring. Since perfect_fit_mask handles near-zero,\n    # fitting_potential_rem_space[non_perfect_fit_mask] will be positive.\n    waste_for_inverse = fitting_potential_rem_space[non_perfect_fit_mask]\n\n    # Apply the inverse waste function. Adding EPSILON prevents division by zero for\n    # extremely small non-zero remaining capacities.\n    fitting_priorities[non_perfect_fit_mask] = 1 / (waste_for_inverse + EPSILON)\n\n    # Update the main priorities array with the scores for fitting bins.\n    priorities[can_fit_mask] = fitting_priorities\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Consolidation-Aware Best Fit: Prioritizes minimal waste (Best Fit) while subtly\n    favoring bins that are already fuller. This encourages faster bin closure\n    and more efficient bin consolidation, integrating adaptive logic.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): Remaining capacity in each bin. Assumes capacities\n                                      are normalized (e.g., max capacity of 1.0).\n\n    Returns:\n        np.ndarray: Priority scores for each bin. Bins unable to fit the item get -np.inf.\n    \"\"\"\n    # Initialize priorities to negative infinity, ensuring bins unable to fit\n    # the item are unequivocally disqualified.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining space (waste) in suitable bins after placing the item.\n    # A smaller waste indicates a more efficient, tighter fit.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the current fullness of bins that can fit the item.\n    # This assumes a maximum bin capacity of 1.0 for normalized problems.\n    # Higher fullness implies the bin is closer to being 'closed'.\n    current_fullness = 1.0 - bins_remain_cap[can_fit_mask]\n\n    # A small positive constant for numerical stability and to ensure a finite,\n    # very high priority for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Define a consolidation factor. This value is chosen to be small enough\n    # to ensure the primary Best Fit term (inverse waste) remains dominant,\n    # but large enough to provide a subtle preference among bins with\n    # very similar waste values. It acts as an adaptive consolidation incentive.\n    CONSOLIDATION_FACTOR = 0.1\n\n    # Primary score: Inverse of waste. This strongly rewards tight fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Secondary score: Bonus for current fullness. This nudges the selection\n    # towards bins that are already more filled, encouraging their closure.\n    consolidation_bonus = CONSOLIDATION_FACTOR * current_fullness\n\n    # Combine the scores. The Best Fit dominates, but bins closer to full\n    # receive a slight advantage, reflecting a more global optimization strategy.\n    priorities[can_fit_mask] = best_fit_score + consolidation_bonus\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit with strong preference for perfect fits.\n    Prioritizes bins inversely to remaining waste, ensuring numerical stability.\n    Leverages inverse waste to balance immediate tight fits with robustness for various item sizes.\n    \"\"\"\n    # Initialize all priorities to negative infinity, excluding bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space if the item were placed in fitting bins.\n    fitting_bins_current_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_current_cap - item\n\n    # Define constants for heuristic scoring.\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12 \n    # A small epsilon for numerical stability in inverse calculations, preventing division by zero.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # This inherently penalizes larger waste (including small fragments) by giving them disproportionately lower scores.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n    \n    # Calculate inverse of (waste + epsilon) for non-perfect fits.\n    # A smaller waste results in a higher priority.\n    inverse_waste_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = inverse_waste_scores\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Prioritizes bins using an adaptive Best Fit approach, emphasizing tight fits for\n    global utility and robustly handling edge cases for predictive packing.\n\n    This heuristic combines the effectiveness of inverse waste minimization with\n    adaptive numerical stability, aiming for bin configurations that enhance\n    future packing opportunities. It assigns the highest priority to perfect fits\n    and uses a non-linear inverse function for others, subtly scaled by bin\n    capacity to be problem-aware.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures bins that cannot fit\n    # the item are never chosen, providing a clear baseline for infeasible options.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed without exceeding capacity.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # Scaling by `bin_capacity` makes this score adaptive to the problem's scale,\n    # ensuring perfect fits are overwhelmingly dominant regardless of the bin size.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity # A large multiplier ensures dominance.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a higher priority. The `STABILITY_EPSILON` is\n    # dynamically scaled by `bin_capacity` to maintain numerical stability and\n    # problem-awareness across different bin scales (e.g., a tiny absolute waste\n    # in a large bin might be effectively 'zero'). This avoids explicit \"dead space\"\n    # penalties, letting the inverse relationship naturally de-prioritize larger wastes.\n    STABILITY_EPSILON = np.finfo(float).eps * bin_capacity \n    \n    # Ensure epsilon is not zero, especially for very small bin_capacity values if they could occur.\n    if STABILITY_EPSILON == 0.0:\n        STABILITY_EPSILON = np.finfo(float).eps \n\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by aggressively minimizing waste, with adaptive scores.\n\n    Explicitly awards perfect fits maximal priority, and for others,\n    uses a robust inverse-waste score to favor tight fits, anticipating\n    efficient bin closure and minimal fragmentation.\n    \"\"\"\n    # Initialize priorities for all bins to a very low value (-infinity).\n    # This ensures that any bin that cannot fit the item will have the lowest\n    # possible priority and will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the remaining space in each bin if the current item were placed there.\n    # A non-negative value means the item can fit; a negative value means it cannot.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Create a boolean mask to identify only those bins that can actually\n    # accommodate the current item (remaining space must be non-negative).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Extract the potential remaining space only for the bins that can fit the item.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n\n    # Create masks to distinguish between perfect fits (waste = 0) and non-perfect fits (waste > 0).\n    perfect_fit_mask = (valid_potential_remaining_space == 0)\n    non_perfect_fit_mask = (valid_potential_remaining_space > 0)\n\n    # 1. Explicitly prioritize perfect fits with a very high, distinct score.\n    # This guarantees they are chosen over any other fit, promoting immediate bin closure\n    # and simplifying future packing decisions for that bin.\n    PERFECT_FIT_SCORE = 1e12\n\n    # Apply the perfect fit score to relevant bins through the nested masks.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a significantly higher priority score.\n    # np.finfo(float).eps provides robust numerical stability, giving very high\n    # scores for extremely tight fits (waste approaching zero) without division by zero.\n    TIGHT_FIT_EPSILON = np.finfo(float).eps\n\n    # Apply the inverse-waste priority score to non-perfect fit bins.\n    priorities[can_fit_mask][non_perfect_fit_mask] = \\\n        1.0 / (valid_potential_remaining_space[non_perfect_fit_mask] + TIGHT_FIT_EPSILON)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item, combining Best Fit with a strong perfect-fit bonus\n    and a subtle discouragement for creating \"dead space\" remnants.\n\n    This heuristic prioritizes perfect fits for global utility (bin closure). It uses\n    Best Fit as the primary mechanism, but adaptively applies a soft penalty to\n    discourage leaving very small, potentially unusable \"dead space\" in bins,\n    promoting more versatile remaining capacities.\n    \"\"\"\n\n    # Initialize priorities to negative infinity for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate potential remaining space for each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Mask for bins where the item can fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Apply the base Best Fit priority: negative of the potential remaining space.\n    # Smaller remaining space -> higher priority (less negative).\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    # --- Incorporate \"Predictive State\" and \"Global Utility\" via Perfect Fit Bonus ---\n    # Identify perfect fits (potential_remaining_space is effectively zero).\n    # Using a small epsilon for robust floating point comparison.\n    PERFECT_FIT_TOLERANCE = np.finfo(float).eps * 10 # A small tolerance for near-zero remaining space\n\n    perfect_fit_mask = can_fit_mask & (potential_remaining_space <= PERFECT_FIT_TOLERANCE)\n\n    # Assign a very high score for perfect fits to make them overwhelmingly preferred.\n    # This ensures bins are \"closed\" as efficiently as possible, a strong global optimization.\n    # The bonus is scaled by bin_capacity for robustness across different bin sizes.\n    PERFECT_FIT_BONUS = 1e6 * bin_capacity\n\n    # Only apply bonus to perfect fits among those that can fit\n    priorities[perfect_fit_mask] = PERFECT_FIT_BONUS\n\n    # --- Incorporate \"Adaptive Logic\" and \"Problem-aware Robustness\" via Soft Dead Space Discouragement ---\n    # Define thresholds for 'dead space' relative to bin_capacity.\n    # 'Dead space' is a small, non-zero remaining capacity that might be hard to fill later.\n    DEAD_SPACE_LOWER_BOUND = PERFECT_FIT_TOLERANCE  # Must be strictly greater than zero to exclude perfect fits\n    DEAD_SPACE_UPPER_BOUND = 0.15 * bin_capacity     # e.g., up to 15% of bin capacity is considered 'dead space'\n\n    # Identify bins that would create 'dead space' after placement.\n    dead_space_creation_mask = (potential_remaining_space > DEAD_SPACE_LOWER_BOUND) & \\\n                               (potential_remaining_space < DEAD_SPACE_UPPER_BOUND) & \\\n                               can_fit_mask\n\n    # Apply a 'soft' penalty. This penalty aims to make 'dead space' options\n    # slightly less attractive than leaving a larger, potentially more useful space.\n    # The magnitude is chosen to shift the priority below immediate Best Fit options\n    # that leave more versatile space, but not so drastically that it's always worse\n    # than opening an entirely empty new bin.\n    SOFT_DEAD_SPACE_PENALTY_VALUE = 0.20 * bin_capacity # Penalty value, scaled by bin_capacity\n\n    # Apply penalty to the priorities of bins creating dead space.\n    priorities[dead_space_creation_mask] -= SOFT_DEAD_SPACE_PENALTY_VALUE\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, implementing a refined Best Fit.\n\n    This heuristic extends Best Fit by incorporating \"predictive state\" and \"global utility\"\n    considerations, moving beyond a purely immediate greedy fit. It aims to:\n\n    1.  **Strongly prioritize perfect fits**: Bins that will be exactly full after placing the item\n        are given the highest possible priority. This helps to \"close\" bins efficiently,\n        contributing directly to minimizing the total number of bins used.\n    2.  **Standard Best Fit for 'useful' remaining capacities**: Among other valid fits,\n        it generally follows the Best Fit principle, preferring bins that result in smaller\n        remaining capacity.\n    3.  **Penalize \"small, unusable gaps\"**: It introduces a penalty for bins that would be\n        left with a very small amount of remaining capacity (e.g., less than 5% of bin size)\n        that is positive but too small to be generally useful for future items. This anticipates\n        future bin configurations, preventing the accumulation of many bins with tiny,\n        ineffective leftover spaces. By encouraging either a perfect fit or a more\n        substantive, useful amount of remaining space, it promotes better long-term bin utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n                         Assumes bin capacities are normalized (e.g., bin size = 1.0)\n                         for the 'small_gap_threshold' to be meaningful.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot fit the item receive the lowest possible priority (-inf).\n    \"\"\"\n    # Calculate the remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can fit (remaining space non-negative).\n    # Using a small epsilon for robust floating-point comparison with zero.\n    can_fit_mask = potential_remaining_space >= -1e-9\n\n    # Apply base Best Fit logic for eligible bins:\n    # A smaller positive remaining space yields a higher priority.\n    # A perfect fit (0 remaining space) will result in a priority of 0 at this stage.\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    # --- Refinements for Predictive State and Global Utility ---\n\n    # Hyperparameters for tuning:\n    # This threshold defines what constitutes a \"small, potentially unusable\" gap.\n    # E.g., 0.2 means any remaining capacity between (0, 0.2] is considered a small gap.\n    # This value typically relates to the expected smallest item size or average item size.\n    small_gap_threshold = 0.2\n\n    # A large bonus for perfect fits to make them highly desirable.\n    perfect_fit_bonus = 100.0\n\n    # A penalty for leaving small, \"unusable\" gaps. This value should be\n    # significant enough to make a small gap less desirable than a more\n    # substantial, usable gap (e.g., -0.5) that is further from the Best Fit ideal.\n    small_gap_penalty = 5.0\n\n    # Apply perfect fit bonus: If remaining space is exactly 0 (or very close).\n    perfect_fit_mask = np.isclose(potential_remaining_space, 0, atol=1e-9) & can_fit_mask\n    priorities[perfect_fit_mask] += perfect_fit_bonus\n\n    # Apply small gap penalty: If remaining space is positive but below the threshold.\n    # This logic explicitly targets gaps that are > 0 and <= small_gap_threshold.\n    small_gap_mask = (potential_remaining_space > 1e-9) & \\\n                     (potential_remaining_space <= small_gap_threshold) & \\\n                     can_fit_mask\n    priorities[small_gap_mask] -= small_gap_penalty\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item in a bin, implementing a Best Fit\n    variation with an explicit penalty for creating very small, potentially\n    unusable gaps. This heuristic aims to anticipate future bin configurations\n    and improve global utility by reducing wasted small spaces.\n\n    This heuristic attempts to improve upon a simple Best Fit by:\n    1.  Prioritizing bins that result in a nearly full bin (standard Best Fit).\n    2.  Applying a significant penalty to bins that, after placing the item,\n        would be left with a very small remaining capacity (a \"small gap\").\n        Such small gaps are often too small to fit subsequent items,\n        leading to wasted space or the premature opening of new bins.\n        This moves beyond immediate greedy fits by considering the quality of\n        the residual bin state.\n    3.  Ensuring that perfect fits (where remaining capacity becomes exactly 0)\n        are always given the highest possible priority, as they represent\n        optimal utilization of a bin and do not create a \"small gap\" penalty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-np.inf).\n    \"\"\"\n    # Define what constitutes a \"small, potentially unusable gap\".\n    # This is a heuristic value, typically a small fraction of the bin's total capacity.\n    # Assuming bin capacity is normalized (e.g., 1.0), 0.05 implies gaps smaller than 5%\n    # of the bin's capacity are considered problematic. This anticipates future item placement.\n    SMALL_GAP_THRESHOLD = 0.05\n\n    # Define the penalty for creating a small gap.\n    # This value is crucial: it should be large enough to make a \"small gap fit\"\n    # less desirable than a \"suboptimal but non-small-gap fit\".\n    # For example, if a Best Fit leaves 0.01 (base priority -0.01) and a slightly\n    # worse fit leaves 0.1 (base priority -0.1), the penalty should push -0.01\n    # to be worse than -0.1 (e.g., -0.01 - 0.1 = -0.11, which is lower than -0.1).\n    SMALL_GAP_PENALTY = 0.1\n\n    # Calculate the remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this lowest priority and will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit (remaining space is non-negative).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # For bins where the item can fit, calculate a base priority.\n    # This follows the Best Fit logic: a smaller positive remaining space\n    # (closer to a perfect fit) results in a higher (less negative) priority.\n    base_priorities = -potential_remaining_space[can_fit_mask]\n\n    # Identify bins among the \"can fit\" ones that would result in a \"small gap\".\n    # A small gap is one where the remaining space is positive but falls below the threshold.\n    # Perfect fits (potential_remaining_space == 0) are explicitly excluded from this penalty\n    # by the `> 0` condition, ensuring they retain their highest possible priority (0.0).\n    small_gap_mask = (potential_remaining_space[can_fit_mask] > 0) & \\\n                     (potential_remaining_space[can_fit_mask] < SMALL_GAP_THRESHOLD)\n\n    # Apply the defined penalty to the base priorities for bins that create small gaps.\n    # This negative adjustment makes these bins less attractive.\n    base_priorities[small_gap_mask] -= SMALL_GAP_PENALTY\n\n    # Assign the calculated priorities to the main priorities array for the bins that can fit.\n    priorities[can_fit_mask] = base_priorities\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority for placing an item in each bin, implementing a Best Fit with Gap Avoidance strategy.\n\n    This heuristic extends the Best Fit approach (as in priority_v1) by adding a penalty\n    for creating small, non-zero remaining capacities in bins. The goal is to avoid\n    fragmentation and leave more \"useful\" gaps, anticipating future item placements.\n\n    A bin with a perfect fit (remaining capacity = 0) still receives the highest priority.\n    For non-perfect fits, bins that would result in a very small, non-zero remaining capacity\n    (below a defined epsilon_threshold) are penalized, making them less desirable than bins\n    that would result in larger, potentially more useful remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin. Assumes bin capacities\n                         are normalized, e.g., between 0 and 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect fit gets the highest possible score,\n        while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Heuristic Parameters (tunable based on problem characteristics)\n    # These values assume normalized bin capacities (e.g., max capacity of 1.0)\n    # If bins_remain_cap are not normalized, adjust EPSILON_THRESHOLD and PENALTY_VALUE accordingly.\n    \n    # Define a threshold for what constitutes a \"small\" remaining gap.\n    # For example, 0.05 means any gap less than 5% of original bin capacity is considered small.\n    EPSILON_THRESHOLD = 0.05 \n    \n    # Penalty applied to bins that result in a small, non-zero remaining gap.\n    # This value should be large enough to make penalized bins less attractive than\n    # bins leaving larger, useful gaps, but not so large that it overrides perfect fits.\n    PENALTY_VALUE = 0.5 \n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Extract potential remaining spaces for bins where the item can fit.\n    fit_potential_remaining_space = potential_remaining_space[can_fit_mask]\n\n    # Base priorities: Apply the Best Fit logic (smaller remaining space = higher priority).\n    # A perfect fit (0 remaining space) will result in a priority of 0 (the highest in this scale).\n    base_priorities = -fit_potential_remaining_space\n\n    # Identify bins that would result in a \"small, non-zero\" remaining capacity.\n    # These are gaps that are too small to be generally useful for future items,\n    # but not a perfect zero fit.\n    small_undesirable_gap_mask = (fit_potential_remaining_space > 0) & \\\n                                 (fit_potential_remaining_space < EPSILON_THRESHOLD)\n\n    # Apply a penalty to the base priorities of these \"undesirable\" gaps.\n    # This makes them less attractive compared to bins that leave either perfect fits\n    # or larger, more flexible remaining capacities.\n    base_priorities[small_undesirable_gap_mask] -= PENALTY_VALUE\n\n    # Assign the calculated priorities back to the full priorities array using the mask.\n    priorities[can_fit_mask] = base_priorities\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\n# Assuming BIN_CAPACITY can be inferred or passed. For this function, as `bins_remain_cap`\n# is an array of float values (e.g., [1.0, 0.5, 0.2]), we can infer that the maximum\n# value in this array (or a conceptual \"full\" bin capacity) is 1.0 (normalized).\nBIN_CAPACITY_UNIT = 1.0 \n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add an item to each bin, implementing a Best Fit\n    variation that strategically avoids creating very small, \"unusable\" remaining gaps,\n    while still highly prioritizing perfect fits.\n\n    This heuristic applies an \"adaptive logic\" by categorizing potential bin states\n    after an item is placed, aiming to improve \"global utility\" by anticipating\n    future bin configurations and managing dynamic bin states:\n\n    1.  **Perfect Fit**: If placing the item fills the bin exactly (remaining capacity becomes 0).\n        This receives the highest possible priority score. This is a highly desirable outcome\n        as it \"closes\" a bin efficiently.\n\n    2.  **Good Gap**: If placing the item leaves a remaining capacity that is large enough\n        to be potentially useful for future items (i.e., above a defined 'small gap threshold').\n        These bins are scored similarly to standard Best Fit (preferring smaller remaining space\n        amongst themselves), but are always considered more desirable than 'Bad Gaps'. This\n        promotes filling bins without creating highly fragmented space.\n\n    3.  **Bad Gap**: If placing the item leaves a very small, non-zero remaining capacity\n        (below the 'small gap threshold'). Such capacities are often difficult to fill with\n        subsequent items, leading to wasted space and an increased number of bins used overall.\n        These bins are heavily penalized to ensure they are chosen only if no 'Good Gap'\n        or 'Perfect Fit' options are available.\n\n    This approach moves beyond simply \"over-emphasizing immediate greedy fits\" by adding\n    a foresight mechanism that penalizes outcomes likely to lead to future fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin (float, typically between 0 and BIN_CAPACITY_UNIT).\n        bins_remain_cap: Array of current remaining capacities for each bin (float, typically\n                         between 0 and BIN_CAPACITY_UNIT).\n\n    Return:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-np.inf).\n    \"\"\"\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # Using a small epsilon (1e-9) to account for floating-point inaccuracies\n    # when an item perfectly fills a bin (e.g., 0.5 - 0.5 = 0.0, but float math might yield 1e-17).\n    can_fit_mask = potential_remaining_space >= -1e-9\n\n    # Filter potential remaining spaces for only those bins where the item can fit.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n    \n    # Initialize a temporary array for priorities of valid bins.\n    valid_priorities = np.zeros_like(valid_potential_remaining_space, dtype=float)\n\n    # --- Heuristic Parameters ---\n    # This threshold defines the upper bound for what is considered a \"small\" and\n    # potentially \"unusable\" remaining gap. A value of 0.15 means any remaining\n    # space less than 15% of the bin capacity (and greater than zero) is considered a \"bad gap\".\n    # This parameter is crucial and may require tuning based on the problem's item size distribution.\n    SMALL_GAP_THRESHOLD = 0.15 * BIN_CAPACITY_UNIT \n\n    # This is a large negative offset applied to \"bad gaps\". It ensures that\n    # any 'Good Gap' (even a very large one, which would typically get a low negative score)\n    # will always have a higher priority than any 'Bad Gap'.\n    # The range of scores for 'Good Gaps' typically falls within [-(BIN_CAPACITY_UNIT - min_item_size), 0].\n    # An offset like -100.0 is sufficiently large to push 'Bad Gap' scores well below this range.\n    BAD_GAP_SCORE_OFFSET = -100.0 \n\n    # --- Scoring Logic based on Categories ---\n\n    # 1. Perfect Fit: Remaining space is approximately zero.\n    # These receive the highest possible score (0.0), making them the top choice.\n    perfect_fit_mask = np.isclose(valid_potential_remaining_space, 0.0, atol=1e-9)\n    valid_priorities[perfect_fit_mask] = 0.0 \n\n    # 2. Bad Gap: Remaining space is small but non-zero (i.e., (0, SMALL_GAP_THRESHOLD)).\n    # These are heavily penalized. Their score is calculated as -(remaining_space)\n    # plus the large negative offset. This ensures they are ranked lower than all 'Good Gaps'.\n    small_gap_mask = (valid_potential_remaining_space > 1e-9) & \\\n                     (valid_potential_remaining_space < SMALL_GAP_THRESHOLD)\n    valid_priorities[small_gap_mask] = -valid_potential_remaining_space[small_gap_mask] + BAD_GAP_SCORE_OFFSET\n\n    # 3. Good Gap: Remaining space is greater than or equal to the threshold ([SMALL_GAP_THRESHOLD, BIN_CAPACITY_UNIT]).\n    # These are scored in a \"Best Fit\" manner: -(remaining_space). Among these, smaller\n    # remaining spaces (closer to the threshold) will have higher scores (closer to 0.0).\n    # Due to BAD_GAP_SCORE_OFFSET, these scores will always be higher than those of 'Bad Gaps'.\n    other_gap_mask = valid_potential_remaining_space >= SMALL_GAP_THRESHOLD\n    valid_priorities[other_gap_mask] = -valid_potential_remaining_space[other_gap_mask]\n\n    # Assign the calculated priorities back to the full 'priorities' array\n    # using the original mask for all bins that could fit the item.\n    priorities[can_fit_mask] = valid_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a Best-Fit-Preferential strategy with fragmentation avoidance.\n\n    This heuristic extends Best Fit by heavily penalizing bins that would be left\n    with a very small, potentially unusable amount of remaining capacity after\n    the item is placed. It aims to prevent bin fragmentation and leave more\n    \"useful\" space in bins that are not perfectly filled. This introduces an\n    adaptive element, prioritizing not just the tightest fit, but also\n    considering the quality of the remaining space for future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. This is crucial\n                      for defining the threshold for \"small, fragmented\"\n                      remaining space. Defaults to 1.0 if not specified.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that:\n        1. A perfect fit (remaining capacity = 0) receives the highest possible score.\n        2. Bins that would be left with a small, 'fragmented' capacity (i.e.,\n           a remainder too small to be generally useful but not zero) receive\n           a significant penalty, making them less desirable than bins leaving\n           larger, more usable space.\n        3. Among other bins (those not leading to fragmentation or perfect fit),\n           the Best Fit principle applies (prioritizing smaller remaining space).\n        4. Bins that cannot accommodate the item receive the lowest possible priority (-inf).\n    \"\"\"\n\n    # Calculate the remaining space in each bin if the item were placed.\n    # A smaller positive value here means a \"tighter fit\".\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Get the potential remaining space only for bins where the item can fit.\n    fitting_remaining_space = potential_remaining_space[can_fit_mask]\n\n    # --- Scoring Logic ---\n\n    # 1. Base Score: Apply the Best Fit principle (negative of remaining space).\n    #    A perfect fit (0 remaining space) will result in a priority of 0 (highest base score).\n    base_scores = -fitting_remaining_space\n\n    # 2. Fragmentation Penalty: Identify and penalize \"fragmented\" remaining spaces.\n    #    These are small, positive remaining capacities that are often hard to fill\n    #    with subsequent items, leading to wasted space and potentially more bins.\n\n    # Define a threshold for what constitutes a \"small, fragmented\" gap.\n    # This is a fraction of the total bin capacity. For example, 10% of bin capacity.\n    FRAGMENTATION_EPSILON_RATIO = 0.10  \n    fragmentation_threshold = bin_capacity * FRAGMENTATION_EPSILON_RATIO\n\n    # Define the magnitude of the penalty. This value should be large enough\n    # to make a fragmented fit less desirable than most non-fragmented fits.\n    # A value significantly greater than `bin_capacity` (the maximum possible base score magnitude)\n    # ensures that a penalized score is worse than any non-penalized score.\n    FRAGMENTATION_PENALTY_MAGNITUDE = bin_capacity * 2.0 \n\n    # Apply penalty only if the remaining space is positive (i.e., not a perfect fit)\n    # AND falls within the defined fragmentation threshold.\n    is_fragmented_gap = (fitting_remaining_space > 0) & \\\n                        (fitting_remaining_space <= fragmentation_threshold)\n\n    penalties = np.zeros_like(base_scores)\n    penalties[is_fragmented_gap] = FRAGMENTATION_PENALTY_MAGNITUDE\n\n    # Combine base scores with penalties.\n    # Penalized scores will become significantly more negative, effectively\n    # pushing them down the priority list.\n    priorities[can_fit_mask] = base_scores - penalties\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]