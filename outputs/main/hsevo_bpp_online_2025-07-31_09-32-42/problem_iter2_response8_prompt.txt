{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin, implementing a variation of Best Fit.\n\n    This heuristic aims to select the bin that will have the least remaining capacity\n    after the item is placed, effectively trying to \"fill up\" a bin as much as possible.\n    Bins that cannot accommodate the item receive the lowest possible priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect fit (remaining capacity = 0) gets the\n        highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Calculate the remaining space in each bin if the item were placed.\n    # A smaller positive value here means a \"better fit\".\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # For bins where the item can fit, assign a priority based on the negative\n    # of the potential remaining space.\n    # By maximizing this value, we are effectively minimizing the potential remaining space.\n    # A perfect fit (0 remaining space) will result in a priority of 0 (the highest).\n    # A larger remaining space (e.g., 0.5) will result in a lower priority (-0.5).\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    \n    This implementation prioritizes bins using a \"Best Fit Decreasing\" like heuristic\n    for online packing. Bins that result in the smallest non-negative remaining capacity\n    after adding the item receive higher priority. Perfect fits are given the highest\n    possible priority (infinity). Bins that cannot accommodate the item receive a \n    priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with a priority score for each bin.\n        A higher score indicates a higher preference for placing the item in that bin.\n    \"\"\"\n    # Initialize priorities for all bins to 0. Bins that cannot fit the item\n    # or are not prioritized will retain this score.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Create a boolean mask for bins that have enough capacity to hold the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining capacity for bins where the item can fit\n    # We only operate on the subset of bins identified by can_fit_mask\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Identify bins that would be perfectly filled by the item\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n\n    # Assign infinite priority to perfect fits. This ensures they are always chosen\n    # over any other non-perfect fit, as they utilize space most efficiently.\n    priorities[can_fit_mask][perfect_fit_mask] = np.inf\n\n    # For bins that can fit the item but are not perfectly filled:\n    # Prioritize them inversely to their remaining capacity.\n    # A smaller remaining capacity means a 'tighter' or 'better' fit, thus higher priority.\n    # This encourages packing items into bins that are nearly full,\n    # leaving larger bins for potentially larger future items.\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n    \n    # Calculate inverse for positive remaining capacities.\n    # Add a small epsilon if needed to prevent division by zero for values\n    # extremely close to zero but not exactly zero, though `potential_remain_after_fit > 0`\n    # should ideally handle this.\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / potential_remain_after_fit[non_perfect_fit_mask]\n\n    return priorities\n\n### Analyze & experience\n- All provided heuristics implement variations of the \"Best Fit\" strategy for online bin packing, where the goal is to choose a bin that minimizes the remaining capacity after placing an item. The ranking indicates nuanced differences in their effectiveness.\n\nComparing (Best) Heuristic 1st vs (Middle Group) Heuristics 2nd-10th:\nHeuristic 1st calculates priority as `1.0 / (remaining_waste + epsilon)`. This creates a strong non-linear preference for bins with very little remaining waste; smaller waste leads to disproportionately higher priority. The `epsilon` term ensures numerical stability, especially for perfect fits (waste = 0), yielding a very high, but finite, priority (`1.0 / epsilon`).\nHeuristics 2nd-10th (which are functionally identical) calculate priority as `-remaining_waste`. This provides a linear prioritization where perfect fits get a score of `0`, and any waste results in a negative score.\nThe superior ranking of Heuristic 1st suggests that the non-linear, exponentially stronger preference for very tight fits (including perfect fits) is more effective in practice than a linear prioritization. Both correctly use `-np.inf` for bins that cannot fit the item.\n\nComparing (Best) Heuristic 1st vs (Worst Group) Heuristics 11th-20th:\nHeuristic 1st's `1.0 / (waste + epsilon)` approach provides consistent numerical stability across all valid fits, including perfect ones, where `1/epsilon` acts as the highest possible score. It robustly uses `-np.inf` for non-fitting bins.\nHeuristics 11th-20th (which are functionally identical) set priority to `np.inf` for perfect fits and `1.0 / waste` for other valid fits. While `np.inf` clearly signals perfect fits, `1.0 / waste` for `waste > 0` can be numerically unstable if `waste` is an extremely small positive floating-point number (e.g., due to precision errors), potentially leading to `OverflowError` or unreliably large numbers not intended to be \"infinite\". Furthermore, they initialize priorities for non-fitting bins to `0` instead of `-np.inf`. While `np.argmax` might still function, `0` is an ambiguous signal for \"unselectable\" compared to `-np.inf`, which unequivocally disqualifies a bin. This makes them less robust and potentially problematic if the calling logic isn't strictly `np.argmax`.\n\nComparing (Middle Group) Heuristics 2nd-10th vs (Worst Group) Heuristics 11th-20th:\nThe middle group (H2-10) offers a simple, robust linear \"Best Fit\" strategy, using `-np.inf` for invalid bins. The worst group (H11-20) attempts a `1/x` type of prioritization (similar in spirit to H1), but introduces potential numerical instability for very small positive `waste` values and uses an ambiguous `0` for non-fitting bins. The ranking implies that the simple, robust linear approach is preferable to a numerically less stable `1/x` approach with ambiguous invalid signals.\n\nOverall: The ranking prioritizes heuristics that give strong preference to tight fits and demonstrate robust handling of edge cases and invalid options.\n- \nHere's a redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Adaptive Search, Problem-aware Robustness, Informed Exploration\n*   **Advice:** Design heuristics to dynamically adjust strategies, learn from search outcomes (e.g., failures), and exploit inherent problem structures for efficient, robust exploration.\n*   **Avoid:** Defining 'good' heuristics merely by static numerical stability or clear output signals; instead, focus on how the heuristic's *design* actively achieves adaptiveness and inherent robustness.\n*   **Explanation:** This fosters truly intelligent, self-improving heuristics capable of navigating complex landscapes proactively, far beyond merely avoiding computational pitfalls.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}