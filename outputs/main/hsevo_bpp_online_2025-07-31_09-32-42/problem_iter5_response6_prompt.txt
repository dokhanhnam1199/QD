{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority for placing an item into bins, implementing a more sophisticated strategy\n    than a simple Best Fit. This heuristic aims to:\n\n    1. Strongly prioritize perfect fits, as they optimally utilize bin space.\n    2. Explicitly penalize situations where placing an item leaves a very small,\n       \"fragment\" space in the bin. Such fragments are often hard to fill later,\n       leading to wasted capacity.\n    3. Slightly reward leaving a sufficiently large remaining space, as this preserves\n       flexibility for larger future items, which is beneficial in online scenarios.\n    4. Among other valid fits, it still leans towards minimizing remaining capacity,\n       but with the adjustments from points 1-3.\n\n    This approach reflects 'Adaptive Search' by adjusting priorities based on the\n    quality of the resulting bin state, 'Problem-aware Robustness' by explicitly\n    mitigating fragmentation, and 'Informed Exploration' by using knowledge about\n    useful versus problematic remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        BIN_CAPACITY: The original maximum capacity of a single bin. Default to 1.0,\n                      assuming item and capacities are normalized (e.g., between 0 and 1).\n                      If your problem uses absolute capacities (e.g., 100, 200),\n                      this value should match that maximum capacity.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-inf).\n    \"\"\"\n    # Calculate the remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Define tunable thresholds and associated bonuses/penalties.\n    # These are percentages of the BIN_CAPACITY, reflecting problem-specific knowledge.\n    # A small tolerance for floating point comparisons to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    \n    # Threshold for a \"fragment\" - if remaining space is below this, it's penalized.\n    # E.g., remaining space less than 15% of bin capacity is considered a fragment.\n    FRAGMENT_THRESHOLD = 0.15 * BIN_CAPACITY \n    \n    # Threshold for a \"large\" remaining space - if remaining space is above this, it's rewarded.\n    # E.g., remaining space more than 40% of bin capacity is considered large/flexible.\n    LARGE_SPACE_THRESHOLD = 0.40 * BIN_CAPACITY \n\n    # Heuristic scores/penalties (relative to the base Best Fit score).\n    # These values can be tuned to emphasize different aspects of the strategy.\n    PERFECT_FIT_BONUS = 100.0  # Strong bonus to make perfect fits highly desirable.\n    FRAGMENT_PENALTY = -5.0    # Significant penalty to discourage creating small, unusable gaps.\n    LARGE_SPACE_BONUS = 0.5    # Small bonus to slightly prefer bins that leave large, flexible spaces.\n\n    # 1. Start with the base Best Fit priority for fitting bins: -potential_remaining_space.\n    # This ensures that among similar categories, smaller remaining space is preferred.\n    fitting_bins_potential_rem = potential_remaining_space[can_fit_mask]\n    base_priorities = -fitting_bins_potential_rem\n\n    # Create a copy to apply adjustments\n    adjusted_priorities = np.copy(base_priorities)\n\n    # 2. Apply Perfect Fit Bonus\n    # Identify bins that result in a near-perfect fit.\n    perfect_fit_mask = np.abs(fitting_bins_potential_rem) < PERFECT_FIT_TOLERANCE\n    adjusted_priorities[perfect_fit_mask] += PERFECT_FIT_BONUS\n\n    # 3. Apply Fragment Penalty\n    # Identify bins that leave a small, non-zero fragment.\n    # Exclude perfect fits from this penalty.\n    fragment_mask = (fitting_bins_potential_rem > PERFECT_FIT_TOLERANCE) & \\\n                    (fitting_bins_potential_rem < FRAGMENT_THRESHOLD)\n    adjusted_priorities[fragment_mask] += FRAGMENT_PENALTY\n\n    # 4. Apply Large Space Bonus\n    # Identify bins that leave a large, potentially useful space.\n    large_space_mask = fitting_bins_potential_rem >= LARGE_SPACE_THRESHOLD\n    adjusted_priorities[large_space_mask] += LARGE_SPACE_BONUS\n    \n    # Assign the calculated adjusted priorities to the main priorities array\n    priorities[can_fit_mask] = adjusted_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive Best Fit: Prioritizes bins to minimize waste, with distinct high score for perfect fits and robust inverse for others.\"\"\"\n\n    # Initialize priorities to negative infinity. This explicitly excludes bins\n    # that cannot fit the item from consideration, making them the lowest possible priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # This guarantees they are chosen over any other fit while maintaining\n    # numerical stability (avoiding np.inf).\n    PERFECT_FIT_SCORE = 1e12  # A large number ensuring perfect fit dominance\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste yields a higher priority. A small epsilon is added\n    # to the denominator to ensure numerical stability, especially for very\n    # small positive waste values, preventing potential overflows.\n    STABILITY_EPSILON = 1e-9 # Ensures division by zero or near-zero is handled\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd) vs (4th) vs (9th), we see they are virtually identical implementations of Best Fit with an inverse-waste priority. Their top ranking suggests this simple, non-linear preference for tight fits, using `np.finfo(float).eps` for numerical stability, is highly effective.\n\nComparing (2nd) vs (3rd), and (4th) vs (3rd), 3rd is ranked worse despite similar core logic. The key differences are that 3rd uses a hardcoded `epsilon` value as a function argument and includes unused imports (`random`, `math`, `scipy`, `torch`). This suggests that using `np.finfo(float).eps` for maximum numerical robustness and keeping imports clean contributes to better heuristic design and possibly performance.\n\nComparing (4th) vs (5th), and also the general cluster of 1st,2nd,4th,9th (simple inverse Best Fit) against 5th, 7th, 8th, 10th (fragmentation aversion/dead space penalty), the simpler inverse Best Fit consistently ranks higher. This indicates that explicitly trying to avoid \"fragmentation\" or \"dead space\" with additional penalty logic, even if well-intentioned, might introduce complexity that hinders overall performance compared to directly prioritizing the smallest waste. The non-linear `1/(waste+epsilon)` already inherently penalizes larger waste, including small \"awkward\" ones, by giving them disproportionately lower scores.\n\nComparing (6th) vs (7th), 7th is a more complex version of fragmentation aversion with multiple thresholds and bonuses/penalties. It's ranked worse than 6th (which is effectively a basic Best Fit with issues). This reinforces that increased algorithmic complexity with multiple tunable parameters can be detrimental.\n\nComparing (8th) vs (9th), 9th (simple inverse Best Fit) is better than 8th (Best Fit with dead space penalty). This further supports the strength of the `1/(waste+epsilon)` approach over explicit penalty schemes.\n\nComparing (10th) vs (11th), 11th (Adaptive Best Fit with explicit high score for perfect fits) is better than 10th (dead space penalty). This indicates that making perfect fits unequivocally dominant via a very large, fixed score (like `1e12`) can be an effective refinement, though it's still ranked below the top simple inverse Best Fit.\n\nComparing (14th) vs (15th), and analyzing the entire bottom cluster (15th-20th) of \"Adaptive Median Fit\" against the higher-ranked heuristics, the \"Adaptive Median Fit\" consistently performs the worst. This heuristic tries to select a bin whose remaining capacity is closest to the *median* of all possible remaining capacities, aiming for a \"balanced\" bin state. This strong negative result suggests that aiming for uniformity or balancing remaining bin capacities is counterproductive for bin packing, which typically benefits from aggressive waste minimization and closing bins efficiently, even if it leads to some highly filled and some empty bins.\n\nOverall: The best heuristics are robust Best Fit variants with a strong, non-linear preference for tight fits (implicit or explicit) and good numerical stability. Added complexity like fragmentation aversion or \"balancing\" strategies tend to degrade performance.\n- \n### Current self-reflection\n*   **Keywords**: Predictive State, Adaptive Logic, Global Utility, Hybrid Search.\n*   **Advice**: Design scoring that anticipates future bin configurations. Integrate adaptive strategies for dynamic bin management. Explore controlled look-ahead or multi-objective trade-offs for superior global utility.\n*   **Avoid**: Over-emphasizing only immediate greedy fits. Merely stating implementation robustness (e.g., epsilon) or error handling as core design principles.\n*   **Explanation**: Advancing heuristics requires foresight into bin states and dynamic adaptation, moving beyond local optimality. Focus on conceptual logic, not just robust implementation.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}