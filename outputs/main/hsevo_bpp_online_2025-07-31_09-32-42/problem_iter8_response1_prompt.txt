{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Assuming BIN_CAPACITY can be inferred or passed. For this function, as `bins_remain_cap`\n# is an array of float values (e.g., [1.0, 0.5, 0.2]), we can infer that the maximum\n# value in this array (or a conceptual \"full\" bin capacity) is 1.0 (normalized).\nBIN_CAPACITY_UNIT = 1.0 \n\n    \"\"\"\n    Returns priority with which to add an item to each bin, implementing a Best Fit\n    variation that strategically avoids creating very small, \"unusable\" remaining gaps,\n    while still highly prioritizing perfect fits.\n\n    This heuristic applies an \"adaptive logic\" by categorizing potential bin states\n    after an item is placed, aiming to improve \"global utility\" by anticipating\n    future bin configurations and managing dynamic bin states:\n\n    1.  **Perfect Fit**: If placing the item fills the bin exactly (remaining capacity becomes 0).\n        This receives the highest possible priority score. This is a highly desirable outcome\n        as it \"closes\" a bin efficiently.\n\n    2.  **Good Gap**: If placing the item leaves a remaining capacity that is large enough\n        to be potentially useful for future items (i.e., above a defined 'small gap threshold').\n        These bins are scored similarly to standard Best Fit (preferring smaller remaining space\n        amongst themselves), but are always considered more desirable than 'Bad Gaps'. This\n        promotes filling bins without creating highly fragmented space.\n\n    3.  **Bad Gap**: If placing the item leaves a very small, non-zero remaining capacity\n        (below the 'small gap threshold'). Such capacities are often difficult to fill with\n        subsequent items, leading to wasted space and an increased number of bins used overall.\n        These bins are heavily penalized to ensure they are chosen only if no 'Good Gap'\n        or 'Perfect Fit' options are available.\n\n    This approach moves beyond simply \"over-emphasizing immediate greedy fits\" by adding\n    a foresight mechanism that penalizes outcomes likely to lead to future fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin (float, typically between 0 and BIN_CAPACITY_UNIT).\n        bins_remain_cap: Array of current remaining capacities for each bin (float, typically\n                         between 0 and BIN_CAPACITY_UNIT).\n\n    Return:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-np.inf).\n    \"\"\"\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # Using a small epsilon (1e-9) to account for floating-point inaccuracies\n    # when an item perfectly fills a bin (e.g., 0.5 - 0.5 = 0.0, but float math might yield 1e-17).\n    can_fit_mask = potential_remaining_space >= -1e-9\n\n    # Filter potential remaining spaces for only those bins where the item can fit.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n    \n    # Initialize a temporary array for priorities of valid bins.\n    valid_priorities = np.zeros_like(valid_potential_remaining_space, dtype=float)\n\n    # --- Heuristic Parameters ---\n    # This threshold defines the upper bound for what is considered a \"small\" and\n    # potentially \"unusable\" remaining gap. A value of 0.15 means any remaining\n    # space less than 15% of the bin capacity (and greater than zero) is considered a \"bad gap\".\n    # This parameter is crucial and may require tuning based on the problem's item size distribution.\n    SMALL_GAP_THRESHOLD = 0.15 * BIN_CAPACITY_UNIT \n\n    # This is a large negative offset applied to \"bad gaps\". It ensures that\n    # any 'Good Gap' (even a very large one, which would typically get a low negative score)\n    # will always have a higher priority than any 'Bad Gap'.\n    # The range of scores for 'Good Gaps' typically falls within [-(BIN_CAPACITY_UNIT - min_item_size), 0].\n    # An offset like -100.0 is sufficiently large to push 'Bad Gap' scores well below this range.\n    BAD_GAP_SCORE_OFFSET = -100.0 \n\n    # --- Scoring Logic based on Categories ---\n\n    # 1. Perfect Fit: Remaining space is approximately zero.\n    # These receive the highest possible score (0.0), making them the top choice.\n    perfect_fit_mask = np.isclose(valid_potential_remaining_space, 0.0, atol=1e-9)\n    valid_priorities[perfect_fit_mask] = 0.0 \n\n    # 2. Bad Gap: Remaining space is small but non-zero (i.e., (0, SMALL_GAP_THRESHOLD)).\n    # These are heavily penalized. Their score is calculated as -(remaining_space)\n    # plus the large negative offset. This ensures they are ranked lower than all 'Good Gaps'.\n    small_gap_mask = (valid_potential_remaining_space > 1e-9) & \\\n                     (valid_potential_remaining_space < SMALL_GAP_THRESHOLD)\n    valid_priorities[small_gap_mask] = -valid_potential_remaining_space[small_gap_mask] + BAD_GAP_SCORE_OFFSET\n\n    # 3. Good Gap: Remaining space is greater than or equal to the threshold ([SMALL_GAP_THRESHOLD, BIN_CAPACITY_UNIT]).\n    # These are scored in a \"Best Fit\" manner: -(remaining_space). Among these, smaller\n    # remaining spaces (closer to the threshold) will have higher scores (closer to 0.0).\n    # Due to BAD_GAP_SCORE_OFFSET, these scores will always be higher than those of 'Bad Gaps'.\n    other_gap_mask = valid_potential_remaining_space >= SMALL_GAP_THRESHOLD\n    valid_priorities[other_gap_mask] = -valid_potential_remaining_space[other_gap_mask]\n\n    # Assign the calculated priorities back to the full 'priorities' array\n    # using the original mask for all bins that could fit the item.\n    priorities[can_fit_mask] = valid_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins by aggressively minimizing waste, with adaptive scores.\n\n    Explicitly awards perfect fits maximal priority, and for others,\n    uses a robust inverse-waste score to favor tight fits, anticipating\n    efficient bin closure and minimal fragmentation.\n    \"\"\"\n    # Initialize priorities for all bins to a very low value (-infinity).\n    # This ensures that any bin that cannot fit the item will have the lowest\n    # possible priority and will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the remaining space in each bin if the current item were placed there.\n    # A non-negative value means the item can fit; a negative value means it cannot.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Create a boolean mask to identify only those bins that can actually\n    # accommodate the current item (remaining space must be non-negative).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Extract the potential remaining space only for the bins that can fit the item.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n\n    # Create masks to distinguish between perfect fits (waste = 0) and non-perfect fits (waste > 0).\n    perfect_fit_mask = (valid_potential_remaining_space == 0)\n    non_perfect_fit_mask = (valid_potential_remaining_space > 0)\n\n    # 1. Explicitly prioritize perfect fits with a very high, distinct score.\n    # This guarantees they are chosen over any other fit, promoting immediate bin closure\n    # and simplifying future packing decisions for that bin.\n    PERFECT_FIT_SCORE = 1e12\n\n    # Apply the perfect fit score to relevant bins through the nested masks.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a significantly higher priority score.\n    # np.finfo(float).eps provides robust numerical stability, giving very high\n    # scores for extremely tight fits (waste approaching zero) without division by zero.\n    TIGHT_FIT_EPSILON = np.finfo(float).eps\n\n    # Apply the inverse-waste priority score to non-perfect fit bins.\n    priorities[can_fit_mask][non_perfect_fit_mask] = \\\n        1.0 / (valid_potential_remaining_space[non_perfect_fit_mask] + TIGHT_FIT_EPSILON)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we observe a shift from fixed, categorical gap management to a more continuous, adaptive approach. The best heuristic (1st) combines a core inverse Best Fit (prioritizing minimal waste) with an *adaptive*, linear bias towards selecting already fuller bins. This bias dynamically references the `max_rem_cap` in the system, making it more robust across varying bin states. In contrast, the second-best heuristic (2nd) employs a fixed `SMALL_GAP_THRESHOLD` and `BAD_GAP_SCORE_OFFSET` to categorize and penalize small, unusable gaps. The adaptive, continuous nature of the consolidation bias in (1st) likely provides a smoother and more effective optimization over (2nd)'s discrete, threshold-based logic.\n\nComparing (2nd) vs (3rd), the significant improvement lies in (2nd)'s explicit awareness of \"bad gaps.\" While (3rd) is a simple Best Fit (`-potential_remaining_space`), (2nd) introduces a foresight mechanism by heavily penalizing bin placements that would leave very small, hard-to-use remaining capacities. This strategic penalty in (2nd) helps reduce fragmentation and improves global utility over (3rd)'s purely greedy, linear approach.\n\nComparing (3rd) vs (4th), the major upgrade is the introduction of `inverse waste` scoring and a strong `PERFECT_FIT_TOLERANCE` with a `MAX_PRIORITY_SCORE` in (4th). (3rd) uses a linear negative score for waste, while (4th)'s `1 / (waste + EPSILON)` disproportionately favors tighter fits (non-linear penalization of waste) and explicitly ensures perfect fits are unequivocally the best choice. This aggressive preference for tight and perfect fits significantly improves performance over simple linear scoring.\n\nComparing (4th) vs (5th), both incorporate inverse waste, but (5th) (and its identical counterparts 8th, 9th) introduces a *multiplicative* bonus for bin fullness. This differs from (1st)'s additive bias, and (4th)'s explicit `MAX_PRIORITY_SCORE`. The multiplicative `(1.0 + alpha * bin_fullness_score)` in (5th) amplifies the primary Best Fit score based on current fullness, aiming for consolidation. However, such multiplicative factors can sometimes lead to less predictable score distributions compared to additive biases.\n\nComparing (5th) vs (6th), both aim for consolidation alongside Best Fit. (5th) uses a *multiplicative* fullness bonus, whereas (6th) employs an *additive* consolidation bonus (`CONSOLIDATION_FACTOR * current_fullness`). Additive biases are generally considered easier to tune and less prone to distorting the primary ranking significantly. The fact that (6th) is ranked below (5th) suggests that for the specific test cases, the multiplicative amplification or the particular fullness definition in (5th) provided a slight advantage.\n\nComparing (6th) vs (10th), (6th) uses inverse waste and an additive consolidation bonus, aiming for smooth, continuous improvement. (10th) reverts to a linear Best Fit with a distinct, fixed `SMALL_GAP_PENALTY`. The continuous nature of inverse waste (in 6th) generally outperforms discrete penalty thresholds (in 10th) by providing a more nuanced ranking of suboptimal fits.\n\nComparing (10th) vs (11th), (11th) (and its identical counterparts 14th, 17th, 18th, 19th) significantly improves by moving from (10th)'s linear Best Fit with a rigid \"small gap\" penalty to a robust `inverse waste` scoring system for non-perfect fits, coupled with an explicit `PERFECT_FIT_SCORE` identified via `PERFECT_FIT_TOLERANCE`. This robust inverse approach implicitly handles undesirable gaps more smoothly and effectively than a fixed penalty.\n\nComparing (11th) vs (12th), the primary difference is how perfect fits are identified. (11th) uses `np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE`, which is numerically robust for floating-point comparisons. (12th) uses a direct equality check `(valid_potential_remaining_space == 0)`. The `tolerance`-based approach in (11th) correctly identifies near-perfect fits, preventing potential misclassifications due to minor floating-point inaccuracies, thus making it slightly superior.\n\nComparing (12th) vs (13th), (13th) (and its identical counterparts 15th, 16th, 20th) introduces a crucial improvement for generalizability: scaling the `PERFECT_FIT_SCORE` and `STABILITY_EPSILON` by `bin_capacity`. This makes the heuristic \"problem-aware\" and robust across different bin scales. While theoretically superior for wider application, its lower ranking suggests that for the specific test cases, this scaling either did not yield benefit or introduced minor complexities that were not advantageous, or the `bin_capacity` was uniform.\n\nOverall: The progression from worst to best demonstrates a clear evolution from simple greedy approaches to sophisticated, hybrid strategies. Key themes include: aggressively prioritizing perfect fits, employing non-linear waste penalization (inverse functions), proactively managing fragmentation (either by direct penalty or implicit via inverse functions), and incorporating adaptive biases for bin consolidation. Numerical stability through `epsilon` and `tolerance` is consistently vital. The top-performing heuristic effectively balances immediate waste minimization with long-term bin consolidation using adaptive mechanisms. The observed redundancies in the provided list's ranking suggest that performance can be highly sensitive to specific test sets or external factors not captured in the code snippets.\n- \nHere's a redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Adaptive, Strategic, Multi-objective, Predictive, Robustness.\n*   **Advice:** Design multi-stage heuristics blending immediate gains with strategic bin consolidation and fragmentation minimization. Employ adaptive parameters responding to problem state. Prioritize exact fits. Ensure numerical robustness via scale-aware comparisons and integer representations.\n*   **Avoid:** Relying purely on single-pass greedy methods. Neglecting explicit fragmentation or balanced bin states as core objectives. Fixed thresholds or simplistic non-adaptive scoring. Superficial epsilon-only numerical fixes.\n*   **Explanation:** Better heuristics leverage foresight: multi-objective optimization balancing current placement with future bin utility, and dynamic adaptation to problem complexity, for robust, generalizable performance.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}