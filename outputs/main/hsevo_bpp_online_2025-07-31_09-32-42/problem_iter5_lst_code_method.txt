{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit with strong preference for tight/perfect fits.\n    Uses inverse of remaining waste + epsilon for numerical stability,\n    and clear disqualification for unfit bins with -inf.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    # This value will be non-negative for bins where the item fits.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Add a small epsilon to the denominator for numerical stability.\n    # This prevents division by zero for perfect fits (waste = 0) and\n    # ensures very large, but finite, priority for them.\n    # It also handles very small positive waste values gracefully.\n    epsilon = np.finfo(float).eps\n\n    # The priority is the inverse of (remaining_waste + epsilon).\n    # This creates a strong non-linear preference: smaller waste yields\n    # disproportionately higher priority. Perfect fits receive the highest score (1/epsilon).\n    priorities[can_fit_mask] = 1.0 / (remaining_waste + epsilon)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority for each bin, leveraging a robust Best Fit strategy.\n    Prioritizes bins that minimize remaining space, using an inverse function for strong preference,\n    and ensures numerical stability with epsilon. Non-fitting bins receive lowest priority.\n    \"\"\"\n    # Initialize all priorities to negative infinity, unequivocally marking bins\n    # that cannot accommodate the item as unavailable.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify which bins have sufficient capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space (waste) if the item were placed in fit-capable bins.\n    potential_remaining_space = bins_remain_cap[can_fit_mask] - item\n\n    # Add a small epsilon to the remaining space to ensure numerical stability when\n    # dividing by very small numbers or zero (for perfect fits). This also provides\n    # a consistently high, but finite, priority for perfect fits.\n    epsilon = np.finfo(float).eps  # Smallest positive float for stability\n\n    # Assign priority as the inverse of (potential remaining space + epsilon).\n    # This non-linear relationship strongly favors bins that leave minimal space,\n    # ensuring that perfect or near-perfect fits receive significantly higher scores.\n    priorities[can_fit_mask] = 1.0 / (potential_remaining_space + epsilon)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 6.859306265095145e-06) -> np.ndarray:\n    \"\"\"Prioritizes bins using a non-linear 'Best Fit' approach, emphasizing very\n    tight fits while robustly disqualifying bins that cannot fit the item.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): A NumPy array representing the remaining capacity\n                                      in each bin.\n        epsilon (float): A small positive constant to ensure numerical stability and to\n                         assign a very high, finite priority to perfect fits (waste = 0).\n                         This creates a strong non-linear preference for bins that are\n                         nearly or perfectly full.\n\n    Returns:\n        np.ndarray: A NumPy array of priorities for each bin. Bins unable to fit\n                    the item will have a priority of -np.inf.\n    \"\"\"\n    # Initialize priorities to negative infinity, ensuring bins unable to fit\n    # the item are unequivocally disqualified. This is a robust signal.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining space (waste) in suitable bins after placing the item.\n    # A smaller waste indicates a more efficient, tighter fit.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate priority as the inverse of (waste + epsilon).\n    # This non-linear function disproportionately rewards very small waste values,\n    # making perfect or near-perfect fits highly desirable.\n    priorities[can_fit_mask] = 1.0 / (remaining_waste + epsilon)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit with strong preference for tight/perfect fits.\n    Uses inverse of remaining waste + epsilon for numerical stability,\n    and clear disqualification for unfit bins with -inf.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    # This value will be non-negative for bins where the item fits.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Add a small epsilon to the denominator for numerical stability.\n    # This prevents division by zero for perfect fits (waste = 0) and\n    # ensures very large, but finite, priority for them.\n    # It also handles very small positive waste values gracefully.\n    epsilon = np.finfo(float).eps\n\n    # The priority is the inverse of (remaining_waste + epsilon).\n    # This creates a strong non-linear preference: smaller waste yields\n    # disproportionately higher priority. Perfect fits receive the highest score (1/epsilon).\n    priorities[can_fit_mask] = 1.0 / (remaining_waste + epsilon)\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add an item to each bin, implementing a\n    Balanced Best Fit with Fragmentation Aversion heuristic.\n\n    This heuristic extends the standard Best Fit approach (`priority_v1`) by\n    introducing a significant penalty for placing an item into a bin if doing\n    so results in a small, \"awkwardly\" sized remaining capacity (a 'fragment').\n    The goal is to encourage either:\n    1.  A nearly perfect fit, effectively 'closing' the bin.\n    2.  Leaving a substantial amount of remaining capacity, keeping the bin\n        'open' and useful for larger future items.\n    This strategy aims to reduce the creation of unusable fragmented space,\n    leading to potentially better overall bin utilization and fewer bins used.\n\n    The heuristic is \"problem-aware\" by identifying and penalizing a common\n    pitfall (fragmentation) in online bin packing. It's \"adaptive\" in that\n    its selection criteria dynamically shift based on the nature of the\n    potential remaining space in each bin.\n\n    Args:\n        item: Size of the item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n                         It's assumed that item sizes and bin capacities are\n                         normalized such that the maximum bin capacity is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-inf).\n    \"\"\"\n    # Assuming bin capacity is normalized to 1.0. This allows thresholds to be\n    # set as ratios of the full bin capacity. If actual capacities vary,\n    # this might need adjustment or a `bin_capacity` parameter.\n    BIN_CAPACITY = 1.0\n\n    # A small tolerance for floating-point comparisons to consider a fit \"perfect\"\n    PERFECT_FIT_TOLERANCE = 1e-6\n\n    # Define the range for \"fragmented\" remaining space.\n    # A remaining space is considered a fragment if it's greater than almost zero\n    # but less than or equal to this threshold. For example, 0.2 means any remaining\n    # space between 0 and 20% of bin capacity is a fragment.\n    FRAGMENT_THRESHOLD_RATIO = 0.25 # Can be tuned (e.g., 0.1 to 0.3)\n    FRAGMENT_THRESHOLD = BIN_CAPACITY * FRAGMENT_THRESHOLD_RATIO\n\n    # A penalty applied to bins that would result in a 'fragmented' remaining space.\n    # This penalty should be significant enough to make fragmented options less\n    # desirable than options that leave larger, more useful spaces.\n    FRAGMENT_PENALTY = BIN_CAPACITY * 0.7 # Can be tuned (e.g., 0.5 to 1.0)\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We use tolerance to account for floating point inaccuracies near zero.\n    can_fit_mask = potential_remaining_space >= -PERFECT_FIT_TOLERANCE\n\n    # Step 1: Apply the base Best Fit logic for bins where the item can fit.\n    # A smaller positive potential_remaining_space results in a higher (less negative) score.\n    # A perfect fit (0) gets a score of 0, which is the highest initial score.\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    # Step 2: Refine priorities based on the Fragmentation Aversion strategy.\n    # Get the potential remaining space for only those bins where the item fits.\n    fitting_potential_rem_space = potential_remaining_space[can_fit_mask]\n    fitting_priorities = priorities[can_fit_mask]\n\n    # Identify remaining spaces that fall into the \"fragmentation trap\":\n    # These are spaces that are small (below FRAGMENT_THRESHOLD) but are not\n    # considered a perfect fit (i.e., greater than PERFECT_FIT_TOLERANCE).\n    fragment_trap_mask = (fitting_potential_rem_space > PERFECT_FIT_TOLERANCE) & \\\n                         (fitting_potential_rem_space <= FRAGMENT_THRESHOLD)\n\n    # For bins that would create a fragment, apply a significant penalty to their priority.\n    # This makes these options less attractive compared to bins that leave either\n    # very little space (perfect fit) or ample space (useful for larger items).\n    fitting_priorities[fragment_trap_mask] -= FRAGMENT_PENALTY\n\n    # Update the main priorities array with the refined scores.\n    priorities[can_fit_mask] = fitting_priorities\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 6.859306265095145e-06) -> np.ndarray:\n    \"\"\"Prioritizes bins using a non-linear 'Best Fit' approach, emphasizing very\n    tight fits while robustly disqualifying bins that cannot fit the item.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): A NumPy array representing the remaining capacity\n                                      in each bin.\n        epsilon (float): A small positive constant to ensure numerical stability and to\n                         assign a very high, finite priority to perfect fits (waste = 0).\n                         This creates a strong non-linear preference for bins that are\n                         nearly or perfectly full.\n\n    Returns:\n        np.ndarray: A NumPy array of priorities for each bin. Bins unable to fit\n                    the item will have a priority of -np.inf.\n    \"\"\"\n    # Initialize priorities to negative infinity, ensuring bins unable to fit\n    # the item are unequivocally disqualified. This is a robust signal.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining space (waste) in suitable bins after placing the item.\n    # A smaller waste indicates a more efficient, tighter fit.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate priority as the inverse of (waste + epsilon).\n    # This non-linear function disproportionately rewards very small waste values,\n    # making perfect or near-perfect fits highly desirable.\n    priorities[can_fit_mask] = 1.0 / (remaining_waste + epsilon)\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item into bins, implementing a more sophisticated strategy\n    than a simple Best Fit. This heuristic aims to:\n\n    1. Strongly prioritize perfect fits, as they optimally utilize bin space.\n    2. Explicitly penalize situations where placing an item leaves a very small,\n       \"fragment\" space in the bin. Such fragments are often hard to fill later,\n       leading to wasted capacity.\n    3. Slightly reward leaving a sufficiently large remaining space, as this preserves\n       flexibility for larger future items, which is beneficial in online scenarios.\n    4. Among other valid fits, it still leans towards minimizing remaining capacity,\n       but with the adjustments from points 1-3.\n\n    This approach reflects 'Adaptive Search' by adjusting priorities based on the\n    quality of the resulting bin state, 'Problem-aware Robustness' by explicitly\n    mitigating fragmentation, and 'Informed Exploration' by using knowledge about\n    useful versus problematic remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        BIN_CAPACITY: The original maximum capacity of a single bin. Default to 1.0,\n                      assuming item and capacities are normalized (e.g., between 0 and 1).\n                      If your problem uses absolute capacities (e.g., 100, 200),\n                      this value should match that maximum capacity.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-inf).\n    \"\"\"\n    # Calculate the remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Define tunable thresholds and associated bonuses/penalties.\n    # These are percentages of the BIN_CAPACITY, reflecting problem-specific knowledge.\n    # A small tolerance for floating point comparisons to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    \n    # Threshold for a \"fragment\" - if remaining space is below this, it's penalized.\n    # E.g., remaining space less than 15% of bin capacity is considered a fragment.\n    FRAGMENT_THRESHOLD = 0.15 * BIN_CAPACITY \n    \n    # Threshold for a \"large\" remaining space - if remaining space is above this, it's rewarded.\n    # E.g., remaining space more than 40% of bin capacity is considered large/flexible.\n    LARGE_SPACE_THRESHOLD = 0.40 * BIN_CAPACITY \n\n    # Heuristic scores/penalties (relative to the base Best Fit score).\n    # These values can be tuned to emphasize different aspects of the strategy.\n    PERFECT_FIT_BONUS = 100.0  # Strong bonus to make perfect fits highly desirable.\n    FRAGMENT_PENALTY = -5.0    # Significant penalty to discourage creating small, unusable gaps.\n    LARGE_SPACE_BONUS = 0.5    # Small bonus to slightly prefer bins that leave large, flexible spaces.\n\n    # 1. Start with the base Best Fit priority for fitting bins: -potential_remaining_space.\n    # This ensures that among similar categories, smaller remaining space is preferred.\n    fitting_bins_potential_rem = potential_remaining_space[can_fit_mask]\n    base_priorities = -fitting_bins_potential_rem\n\n    # Create a copy to apply adjustments\n    adjusted_priorities = np.copy(base_priorities)\n\n    # 2. Apply Perfect Fit Bonus\n    # Identify bins that result in a near-perfect fit.\n    perfect_fit_mask = np.abs(fitting_bins_potential_rem) < PERFECT_FIT_TOLERANCE\n    adjusted_priorities[perfect_fit_mask] += PERFECT_FIT_BONUS\n\n    # 3. Apply Fragment Penalty\n    # Identify bins that leave a small, non-zero fragment.\n    # Exclude perfect fits from this penalty.\n    fragment_mask = (fitting_bins_potential_rem > PERFECT_FIT_TOLERANCE) & \\\n                    (fitting_bins_potential_rem < FRAGMENT_THRESHOLD)\n    adjusted_priorities[fragment_mask] += FRAGMENT_PENALTY\n\n    # 4. Apply Large Space Bonus\n    # Identify bins that leave a large, potentially useful space.\n    large_space_mask = fitting_bins_potential_rem >= LARGE_SPACE_THRESHOLD\n    adjusted_priorities[large_space_mask] += LARGE_SPACE_BONUS\n    \n    # Assign the calculated adjusted priorities to the main priorities array\n    priorities[can_fit_mask] = adjusted_priorities\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Returns priority with which to add an item to each bin, implementing a Best Fit\n    variant with a dynamic 'dead space' penalty for problem-aware robustness and\n    informed exploration.\n\n    This heuristic extends the standard Best Fit approach by actively discouraging\n    the creation of small, potentially unusable gaps (referred to as \"dead space\")\n    within bins. While Best Fit prioritizes minimizing remaining capacity, this\n    `priority_v2` introduces an adaptive penalty. If placing an item results in a\n    remaining capacity that falls into a predefined 'dead space' range (too small\n    to be generally useful, but not perfectly zero), the priority for that bin\n    is significantly reduced. This aims to prevent bin fragmentation, improve\n    overall bin utilization, and encourage more robust packing solutions, especially\n    when dealing with items that could leave awkward small residuals.\n\n    The penalty ensures that creating such \"dead space\" is often considered worse\n    than placing the item into a much emptier bin, thereby nudging the heuristic\n    away from locally optimal but globally inefficient choices.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. This is crucial for\n                      scaling the 'dead space' threshold and penalty value. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that:\n        - A perfect fit (remaining capacity = 0) receives the highest possible score (0).\n        - Bins that create \"dead space\" after placement receive a heavily penalized score.\n        - Bins that cannot accommodate the item receive the lowest possible priority (-inf).\n    \"\"\"\n    # Define thresholds and penalty for 'dead space'. These are dynamically\n    # scaled relative to the bin_capacity for problem-aware robustness.\n    # A remaining space is considered 'dead space' if it's greater than 0\n    # but less than a certain fraction (e.g., 10%) of the bin's total capacity.\n    DEAD_SPACE_THRESHOLD = 0.1 * bin_capacity\n\n    # The penalty value is set to the full bin capacity. This makes creating\n    # a dead space gap significantly less desirable than placing the item\n    # into a brand new, empty bin (which would result in a score of -bin_capacity).\n    PENALTY_VALUE = bin_capacity\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Apply the base Best Fit priority: negative of the potential remaining space.\n    # A smaller remaining space results in a higher (less negative) priority.\n    # A perfect fit (0 remaining space) will result in a priority of 0 (the highest possible base score).\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    # Identify bins that, if chosen, would result in 'dead space'.\n    # This applies to bins where:\n    # 1. The item *can* fit (already covered by can_fit_mask).\n    # 2. The resulting `potential_remaining_space` is greater than 0 (not a perfect fit).\n    # 3. The resulting `potential_remaining_space` is less than the `DEAD_SPACE_THRESHOLD`.\n    dead_space_creation_mask = (potential_remaining_space > 0) & (potential_remaining_space < DEAD_SPACE_THRESHOLD)\n\n    # Combine the masks: apply penalty only to bins that can fit the item AND create dead space.\n    apply_penalty_mask = can_fit_mask & dead_space_creation_mask\n\n    # Apply the significant penalty to the priorities of identified 'dead space' bins.\n    # This actively discourages choices that lead to awkward, unusable gaps,\n    # thereby introducing 'problem-aware robustness' into the heuristic.\n    priorities[apply_penalty_mask] -= PENALTY_VALUE\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using a robust Best Fit strategy.\n    \n    Assigns high priority to bins that result in minimal remaining capacity,\n    using a 1/(waste + epsilon) non-linear score for strong preference\n    towards tight fits, and -inf for bins that cannot fit the item.\n    \"\"\"\n    # Initialize priorities for all bins to a very low value (-infinity).\n    # This ensures that any bin that cannot fit the item will have the lowest\n    # possible priority and will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the remaining space in each bin if the current item were placed there.\n    # A non-negative value means the item can fit; a negative value means it cannot.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Create a boolean mask to identify only those bins that can actually\n    # accommodate the current item (remaining space must be non-negative).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Define a small positive constant to ensure numerical stability.\n    # This epsilon is crucial to prevent division by zero when an item\n    # perfectly fills a bin (potential_remaining_space = 0). It ensures\n    # perfect fits get a very high, but finite, priority score.\n    epsilon = np.finfo(float).eps \n\n    # For the bins that can fit the item, calculate their priority.\n    # The heuristic uses an inverse relationship: smaller remaining space\n    # (after placing the item) results in a larger priority score.\n    # The `+ epsilon` makes `1.0 / (0 + epsilon)` a very large number,\n    # effectively giving perfect fits the highest possible priority among valid bins.\n    priorities[can_fit_mask] = 1.0 / (potential_remaining_space[can_fit_mask] + epsilon)\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Returns priority with which to add an item to each bin, implementing a Best Fit\n    variant with a dynamic 'dead space' penalty for problem-aware robustness and\n    informed exploration.\n\n    This heuristic extends the standard Best Fit approach by actively discouraging\n    the creation of small, potentially unusable gaps (referred to as \"dead space\")\n    within bins. While Best Fit prioritizes minimizing remaining capacity, this\n    `priority_v2` introduces an adaptive penalty. If placing an item results in a\n    remaining capacity that falls into a predefined 'dead space' range (too small\n    to be generally useful, but not perfectly zero), the priority for that bin\n    is significantly reduced. This aims to prevent bin fragmentation, improve\n    overall bin utilization, and encourage more robust packing solutions, especially\n    when dealing with items that could leave awkward small residuals.\n\n    The penalty ensures that creating such \"dead space\" is often considered worse\n    than placing the item into a much emptier bin, thereby nudging the heuristic\n    away from locally optimal but globally inefficient choices.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. This is crucial for\n                      scaling the 'dead space' threshold and penalty value. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that:\n        - A perfect fit (remaining capacity = 0) receives the highest possible score (0).\n        - Bins that create \"dead space\" after placement receive a heavily penalized score.\n        - Bins that cannot accommodate the item receive the lowest possible priority (-inf).\n    \"\"\"\n    # Define thresholds and penalty for 'dead space'. These are dynamically\n    # scaled relative to the bin_capacity for problem-aware robustness.\n    # A remaining space is considered 'dead space' if it's greater than 0\n    # but less than a certain fraction (e.g., 10%) of the bin's total capacity.\n    DEAD_SPACE_THRESHOLD = 0.1 * bin_capacity\n\n    # The penalty value is set to the full bin capacity. This makes creating\n    # a dead space gap significantly less desirable than placing the item\n    # into a brand new, empty bin (which would result in a score of -bin_capacity).\n    PENALTY_VALUE = bin_capacity\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Apply the base Best Fit priority: negative of the potential remaining space.\n    # A smaller remaining space results in a higher (less negative) priority.\n    # A perfect fit (0 remaining space) will result in a priority of 0 (the highest possible base score).\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    # Identify bins that, if chosen, would result in 'dead space'.\n    # This applies to bins where:\n    # 1. The item *can* fit (already covered by can_fit_mask).\n    # 2. The resulting `potential_remaining_space` is greater than 0 (not a perfect fit).\n    # 3. The resulting `potential_remaining_space` is less than the `DEAD_SPACE_THRESHOLD`.\n    dead_space_creation_mask = (potential_remaining_space > 0) & (potential_remaining_space < DEAD_SPACE_THRESHOLD)\n\n    # Combine the masks: apply penalty only to bins that can fit the item AND create dead space.\n    apply_penalty_mask = can_fit_mask & dead_space_creation_mask\n\n    # Apply the significant penalty to the priorities of identified 'dead space' bins.\n    # This actively discourages choices that lead to awkward, unusable gaps,\n    # thereby introducing 'problem-aware robustness' into the heuristic.\n    priorities[apply_penalty_mask] -= PENALTY_VALUE\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive Best Fit: Prioritizes bins to minimize waste, with distinct high score for perfect fits and robust inverse for others.\"\"\"\n\n    # Initialize priorities to negative infinity. This explicitly excludes bins\n    # that cannot fit the item from consideration, making them the lowest possible priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # This guarantees they are chosen over any other fit while maintaining\n    # numerical stability (avoiding np.inf).\n    PERFECT_FIT_SCORE = 1e12  # A large number ensuring perfect fit dominance\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste yields a higher priority. A small epsilon is added\n    # to the denominator to ensure numerical stability, especially for very\n    # small positive waste values, preventing potential overflows.\n    STABILITY_EPSILON = 1e-9 # Ensures division by zero or near-zero is handled\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive Best Fit: Prioritizes bins to minimize waste, with distinct high score for perfect fits and robust inverse for others.\"\"\"\n\n    # Initialize priorities to negative infinity. This explicitly excludes bins\n    # that cannot fit the item from consideration, making them the lowest possible priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # This guarantees they are chosen over any other fit while maintaining\n    # numerical stability (avoiding np.inf).\n    PERFECT_FIT_SCORE = 1e12  # A large number ensuring perfect fit dominance\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste yields a higher priority. A small epsilon is added\n    # to the denominator to ensure numerical stability, especially for very\n    # small positive waste values, preventing potential overflows.\n    STABILITY_EPSILON = 1e-9 # Ensures division by zero or near-zero is handled\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive Best Fit: Prioritizes bins to minimize waste, with distinct high score for perfect fits and robust inverse for others.\"\"\"\n\n    # Initialize priorities to negative infinity. This explicitly excludes bins\n    # that cannot fit the item from consideration, making them the lowest possible priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # This guarantees they are chosen over any other fit while maintaining\n    # numerical stability (avoiding np.inf).\n    PERFECT_FIT_SCORE = 1e12  # A large number ensuring perfect fit dominance\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste yields a higher priority. A small epsilon is added\n    # to the denominator to ensure numerical stability, especially for very\n    # small positive waste values, preventing potential overflows.\n    STABILITY_EPSILON = 1e-9 # Ensures division by zero or near-zero is handled\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive Best Fit: Prioritizes bins to minimize waste, with distinct high score for perfect fits and robust inverse for others.\"\"\"\n\n    # Initialize priorities to negative infinity. This explicitly excludes bins\n    # that cannot fit the item from consideration, making them the lowest possible priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # This guarantees they are chosen over any other fit while maintaining\n    # numerical stability (avoiding np.inf).\n    PERFECT_FIT_SCORE = 1e12  # A large number ensuring perfect fit dominance\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste yields a higher priority. A small epsilon is added\n    # to the denominator to ensure numerical stability, especially for very\n    # small positive waste values, preventing potential overflows.\n    STABILITY_EPSILON = 1e-9 # Ensures division by zero or near-zero is handled\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add item to each bin, implementing an Adaptive Median Fit heuristic.\n\n    This heuristic dynamically adjusts its target remaining capacity based on the current\n    distribution of *potential* remaining capacities among bins that can fit the item.\n    It aims to select the bin that, after placing the item, would result in a remaining\n    capacity closest to the median of all possible remaining capacities among valid bins.\n\n    This approach seeks to:\n    1.  Promote a more uniform distribution of remaining bin capacities across the system,\n        reducing fragmentation where some bins are left with tiny, unusable gaps while\n        others are very large. This addresses \"Problem-aware Robustness\".\n    2.  Provide \"Adaptive Search\" by not always pursuing the absolute tightest fit (as Best Fit does),\n        but rather a fit that aligns with the current central tendency of available options.\n        This allows for more flexible bin states for future items.\n    3.  Offer \"Informed Exploration\" by considering the overall landscape of available fits\n        (the distribution of potential remaining spaces) rather than just a local minimum.\n        It subtly guides the packing towards a more balanced, sustainable state.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect match to the 'target_remaining_capacity'\n        gets the highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Identify bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Get the potential remaining spaces for only those bins that can fit the item.\n    fitting_bins_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Handle edge case: if no bin can fit the item, all priorities remain -inf.\n    # If only one bin fits, its priority will be 0 (as median is itself), ensuring it's chosen.\n    if len(fitting_bins_potential_rem_space) == 0:\n        return priorities\n\n    # Calculate the median of the potential remaining spaces among fitting bins.\n    # This acts as our dynamic \"target remaining capacity\". By seeking the median,\n    # we aim to homogenize the bin states, avoiding extremes (too tight or too loose).\n    target_remaining_capacity = np.median(fitting_bins_potential_rem_space)\n\n    # For bins where the item can fit, assign a priority based on how close\n    # their potential remaining space is to the target_remaining_capacity.\n    # We use negative absolute difference: a smaller difference (closer to target)\n    # yields a higher priority (closer to 0, which is the maximum score).\n    priorities[can_fit_mask] = -np.abs(fitting_bins_potential_rem_space - target_remaining_capacity)\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add item to each bin, implementing an Adaptive Median Fit heuristic.\n\n    This heuristic dynamically adjusts its target remaining capacity based on the current\n    distribution of *potential* remaining capacities among bins that can fit the item.\n    It aims to select the bin that, after placing the item, would result in a remaining\n    capacity closest to the median of all possible remaining capacities among valid bins.\n\n    This approach seeks to:\n    1.  Promote a more uniform distribution of remaining bin capacities across the system,\n        reducing fragmentation where some bins are left with tiny, unusable gaps while\n        others are very large. This addresses \"Problem-aware Robustness\".\n    2.  Provide \"Adaptive Search\" by not always pursuing the absolute tightest fit (as Best Fit does),\n        but rather a fit that aligns with the current central tendency of available options.\n        This allows for more flexible bin states for future items.\n    3.  Offer \"Informed Exploration\" by considering the overall landscape of available fits\n        (the distribution of potential remaining spaces) rather than just a local minimum.\n        It subtly guides the packing towards a more balanced, sustainable state.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect match to the 'target_remaining_capacity'\n        gets the highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Identify bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Get the potential remaining spaces for only those bins that can fit the item.\n    fitting_bins_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Handle edge case: if no bin can fit the item, all priorities remain -inf.\n    # If only one bin fits, its priority will be 0 (as median is itself), ensuring it's chosen.\n    if len(fitting_bins_potential_rem_space) == 0:\n        return priorities\n\n    # Calculate the median of the potential remaining spaces among fitting bins.\n    # This acts as our dynamic \"target remaining capacity\". By seeking the median,\n    # we aim to homogenize the bin states, avoiding extremes (too tight or too loose).\n    target_remaining_capacity = np.median(fitting_bins_potential_rem_space)\n\n    # For bins where the item can fit, assign a priority based on how close\n    # their potential remaining space is to the target_remaining_capacity.\n    # We use negative absolute difference: a smaller difference (closer to target)\n    # yields a higher priority (closer to 0, which is the maximum score).\n    priorities[can_fit_mask] = -np.abs(fitting_bins_potential_rem_space - target_remaining_capacity)\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add item to each bin, implementing an Adaptive Median Fit heuristic.\n\n    This heuristic dynamically adjusts its target remaining capacity based on the current\n    distribution of *potential* remaining capacities among bins that can fit the item.\n    It aims to select the bin that, after placing the item, would result in a remaining\n    capacity closest to the median of all possible remaining capacities among valid bins.\n\n    This approach seeks to:\n    1.  Promote a more uniform distribution of remaining bin capacities across the system,\n        reducing fragmentation where some bins are left with tiny, unusable gaps while\n        others are very large. This addresses \"Problem-aware Robustness\".\n    2.  Provide \"Adaptive Search\" by not always pursuing the absolute tightest fit (as Best Fit does),\n        but rather a fit that aligns with the current central tendency of available options.\n        This allows for more flexible bin states for future items.\n    3.  Offer \"Informed Exploration\" by considering the overall landscape of available fits\n        (the distribution of potential remaining spaces) rather than just a local minimum.\n        It subtly guides the packing towards a more balanced, sustainable state.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect match to the 'target_remaining_capacity'\n        gets the highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Identify bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Get the potential remaining spaces for only those bins that can fit the item.\n    fitting_bins_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Handle edge case: if no bin can fit the item, all priorities remain -inf.\n    # If only one bin fits, its priority will be 0 (as median is itself), ensuring it's chosen.\n    if len(fitting_bins_potential_rem_space) == 0:\n        return priorities\n\n    # Calculate the median of the potential remaining spaces among fitting bins.\n    # This acts as our dynamic \"target remaining capacity\". By seeking the median,\n    # we aim to homogenize the bin states, avoiding extremes (too tight or too loose).\n    target_remaining_capacity = np.median(fitting_bins_potential_rem_space)\n\n    # For bins where the item can fit, assign a priority based on how close\n    # their potential remaining space is to the target_remaining_capacity.\n    # We use negative absolute difference: a smaller difference (closer to target)\n    # yields a higher priority (closer to 0, which is the maximum score).\n    priorities[can_fit_mask] = -np.abs(fitting_bins_potential_rem_space - target_remaining_capacity)\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add item to each bin, implementing an Adaptive Median Fit heuristic.\n\n    This heuristic dynamically adjusts its target remaining capacity based on the current\n    distribution of *potential* remaining capacities among bins that can fit the item.\n    It aims to select the bin that, after placing the item, would result in a remaining\n    capacity closest to the median of all possible remaining capacities among valid bins.\n\n    This approach seeks to:\n    1.  Promote a more uniform distribution of remaining bin capacities across the system,\n        reducing fragmentation where some bins are left with tiny, unusable gaps while\n        others are very large. This addresses \"Problem-aware Robustness\".\n    2.  Provide \"Adaptive Search\" by not always pursuing the absolute tightest fit (as Best Fit does),\n        but rather a fit that aligns with the current central tendency of available options.\n        This allows for more flexible bin states for future items.\n    3.  Offer \"Informed Exploration\" by considering the overall landscape of available fits\n        (the distribution of potential remaining spaces) rather than just a local minimum.\n        It subtly guides the packing towards a more balanced, sustainable state.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect match to the 'target_remaining_capacity'\n        gets the highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Identify bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Get the potential remaining spaces for only those bins that can fit the item.\n    fitting_bins_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Handle edge case: if no bin can fit the item, all priorities remain -inf.\n    # If only one bin fits, its priority will be 0 (as median is itself), ensuring it's chosen.\n    if len(fitting_bins_potential_rem_space) == 0:\n        return priorities\n\n    # Calculate the median of the potential remaining spaces among fitting bins.\n    # This acts as our dynamic \"target remaining capacity\". By seeking the median,\n    # we aim to homogenize the bin states, avoiding extremes (too tight or too loose).\n    target_remaining_capacity = np.median(fitting_bins_potential_rem_space)\n\n    # For bins where the item can fit, assign a priority based on how close\n    # their potential remaining space is to the target_remaining_capacity.\n    # We use negative absolute difference: a smaller difference (closer to target)\n    # yields a higher priority (closer to 0, which is the maximum score).\n    priorities[can_fit_mask] = -np.abs(fitting_bins_potential_rem_space - target_remaining_capacity)\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add item to each bin, implementing an Adaptive Median Fit heuristic.\n\n    This heuristic dynamically adjusts its target remaining capacity based on the current\n    distribution of *potential* remaining capacities among bins that can fit the item.\n    It aims to select the bin that, after placing the item, would result in a remaining\n    capacity closest to the median of all possible remaining capacities among valid bins.\n\n    This approach seeks to:\n    1.  Promote a more uniform distribution of remaining bin capacities across the system,\n        reducing fragmentation where some bins are left with tiny, unusable gaps while\n        others are very large. This addresses \"Problem-aware Robustness\".\n    2.  Provide \"Adaptive Search\" by not always pursuing the absolute tightest fit (as Best Fit does),\n        but rather a fit that aligns with the current central tendency of available options.\n        This allows for more flexible bin states for future items.\n    3.  Offer \"Informed Exploration\" by considering the overall landscape of available fits\n        (the distribution of potential remaining spaces) rather than just a local minimum.\n        It subtly guides the packing towards a more balanced, sustainable state.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect match to the 'target_remaining_capacity'\n        gets the highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Identify bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Get the potential remaining spaces for only those bins that can fit the item.\n    fitting_bins_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Handle edge case: if no bin can fit the item, all priorities remain -inf.\n    # If only one bin fits, its priority will be 0 (as median is itself), ensuring it's chosen.\n    if len(fitting_bins_potential_rem_space) == 0:\n        return priorities\n\n    # Calculate the median of the potential remaining spaces among fitting bins.\n    # This acts as our dynamic \"target remaining capacity\". By seeking the median,\n    # we aim to homogenize the bin states, avoiding extremes (too tight or too loose).\n    target_remaining_capacity = np.median(fitting_bins_potential_rem_space)\n\n    # For bins where the item can fit, assign a priority based on how close\n    # their potential remaining space is to the target_remaining_capacity.\n    # We use negative absolute difference: a smaller difference (closer to target)\n    # yields a higher priority (closer to 0, which is the maximum score).\n    priorities[can_fit_mask] = -np.abs(fitting_bins_potential_rem_space - target_remaining_capacity)\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add item to each bin, implementing an Adaptive Median Fit heuristic.\n\n    This heuristic dynamically adjusts its target remaining capacity based on the current\n    distribution of *potential* remaining capacities among bins that can fit the item.\n    It aims to select the bin that, after placing the item, would result in a remaining\n    capacity closest to the median of all possible remaining capacities among valid bins.\n\n    This approach seeks to:\n    1.  Promote a more uniform distribution of remaining bin capacities across the system,\n        reducing fragmentation where some bins are left with tiny, unusable gaps while\n        others are very large. This addresses \"Problem-aware Robustness\".\n    2.  Provide \"Adaptive Search\" by not always pursuing the absolute tightest fit (as Best Fit does),\n        but rather a fit that aligns with the current central tendency of available options.\n        This allows for more flexible bin states for future items.\n    3.  Offer \"Informed Exploration\" by considering the overall landscape of available fits\n        (the distribution of potential remaining spaces) rather than just a local minimum.\n        It subtly guides the packing towards a more balanced, sustainable state.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect match to the 'target_remaining_capacity'\n        gets the highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Identify bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Get the potential remaining spaces for only those bins that can fit the item.\n    fitting_bins_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Handle edge case: if no bin can fit the item, all priorities remain -inf.\n    # If only one bin fits, its priority will be 0 (as median is itself), ensuring it's chosen.\n    if len(fitting_bins_potential_rem_space) == 0:\n        return priorities\n\n    # Calculate the median of the potential remaining spaces among fitting bins.\n    # This acts as our dynamic \"target remaining capacity\". By seeking the median,\n    # we aim to homogenize the bin states, avoiding extremes (too tight or too loose).\n    target_remaining_capacity = np.median(fitting_bins_potential_rem_space)\n\n    # For bins where the item can fit, assign a priority based on how close\n    # their potential remaining space is to the target_remaining_capacity.\n    # We use negative absolute difference: a smaller difference (closer to target)\n    # yields a higher priority (closer to 0, which is the maximum score).\n    priorities[can_fit_mask] = -np.abs(fitting_bins_potential_rem_space - target_remaining_capacity)\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}