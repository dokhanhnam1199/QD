{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin, implementing a\n    relative utilization-based heuristic that encourages emergent packing behavior.\n\n    This heuristic assigns a priority to each bin based on how much of its current\n    remaining capacity the incoming item would consume. The goal is to maximize\n    the 'relative utilization' for the current placement. This local rule aims to\n    drive the system towards effectively filling bins. Bins that cannot accommodate\n    the item receive the lowest possible priority (0.0), ensuring they are not chosen,\n    without relying on specific numerical artifacts like infinity.\n\n    Args:\n        item: Size of item to be added to the bin. Assumed to be a positive float.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n                         Assumed to contain non-negative float values.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores range from 0.0 (for non-fitting bins or bins with very large remaining\n        capacity relative to the item) up to 1.0 (for a perfect fit).\n    \"\"\"\n    # Initialize all priorities to 0.0. This value implicitly represents the\n    # lowest possible priority for a valid item and will be assigned to bins\n    # that cannot fit the item. This avoids reliance on -np.inf.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # If item is positive, and bins_remain_cap is 0, this mask will correctly\n    # exclude that bin, preventing division by zero.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the priority for bins where the item can fit.\n    # The priority is the ratio of the item's size to the bin's remaining capacity.\n    # A higher ratio indicates that the item consumes a larger proportion of the\n    # available space, leading to a \"tighter\" relative fit.\n    # This promotes the local rule of maximizing current space efficiency.\n    # For a perfect fit (item == bins_remain_cap), the score will be 1.0,\n    # representing the highest possible priority.\n    \n    # We use `np.where` for a vectorized conditional assignment.\n    # For bins where `can_fit_mask` is True, we calculate `item / bins_remain_cap`.\n    # For bins where `can_fit_mask` is False (item does not fit), we assign 0.0.\n    # Note: `item / bins_remain_cap` for elements where `bins_remain_cap` is 0\n    # and `can_fit_mask` is False will not be evaluated, thus preventing ZeroDivisionError.\n    priorities = np.where(can_fit_mask, item / bins_remain_cap, 0.0)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin, implementing a variation of Worst Fit.\n\n    This heuristic aims to select the bin that has the most remaining capacity before the item is\n    placed (since item size is constant for comparison), effectively trying to keep bins\n    as 'open' or 'empty' as possible for as long as possible. The primary goal is to distribute\n    items widely, promoting an emergent behavior of balanced bin usage across the available\n    containers, rather than aggressively filling and closing bins. This approach attempts to\n    preserve larger contiguous spaces in bins, potentially beneficial for future larger items.\n\n    This design adheres to the principle of \"minimal, local decision rules where desired global\n    outcomes emerge from their aggregate application,\" avoiding explicit global objectives or\n    reliance on numerical infinities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive a low, fixed finite priority score.\n    \"\"\"\n    # Initialize all priorities to a sufficiently low, but finite, number.\n    # This ensures that any bin that cannot fit the item will have a lower priority\n    # than any bin that can fit it, without relying on -infinity or other numerical mechanisms.\n    LOW_PRIORITY = -1000.0\n    priorities = np.full_like(bins_remain_cap, LOW_PRIORITY, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins where the item can fit, assign a priority based directly on their\n    # current remaining capacity. By maximizing this value, we are effectively choosing\n    # the bin with the most remaining space (Worst Fit). This is a simple, local rule\n    # that encourages spreading out items across bins, allowing the overall distribution\n    # of items to emerge from these repeated local decisions.\n    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask]\n\n    return priorities\n\n### Analyze & experience\n- Comparing the provided heuristics, it's evident that strategies focusing on maximizing bin utilization and minimizing wasted space perform significantly better. The list contains several identical heuristics, which will be noted in the comparisons.\n\n*   **Comparing (1st) vs (2nd):** The 1st heuristic, ranked best, employs a robust Best Fit core and a strong, fixed `PERFECT_FIT_BONUS` (1000.0). In contrast, the 2nd heuristic introduces a subtle, proportional consolidation bonus and a lower `EXACT_FIT_BONUS` (100.0). The superior performance of 1st suggests that a very high, overriding bonus for exact fits is more critical than a nuanced, proportional consolidation strategy. Simplicity and dominance of the perfect fit rule likely contribute to its effectiveness.\n\n*   **Comparing (2nd) vs (3rd):** The 2nd heuristic uses a linear Best Fit score, while the 3rd uses an inverse Best Fit score (`1.0 / (potential_remaining_space + EPSILON)`) and an inverse fullness consolidation bonus. The 3rd also uses an even higher `PERFECT_FIT_SCORE` (1e30). While the higher perfect fit score in 3rd is beneficial, the inverse scoring for Best Fit and consolidation can make the heuristic highly sensitive to small numerical differences, potentially leading to instability or less predictable behavior compared to the more stable linear approach in 2nd. The ranking suggests that the linear Best Fit combined with a strong exact fit bonus (as in 2nd) is more effective than the inverse-based scaling of 3rd, despite 3rd's even higher perfect fit constant.\n    *   *Note:* Heuristics 6th and 8th are identical to 3rd.\n\n*   **Comparing (3rd) vs (4th):** The 3rd heuristic uses inverse scoring for its Best Fit and consolidation components. The 4th heuristic reverts to a linear Best Fit score (`-potential_remaining_space`) combined with a dominant exact fit bonus and a *fixed additive* `PARTIALLY_FILLED_BIN_BONUS`. The 4th's superior ranking over 3rd indicates that a simpler, fixed consolidation bonus is more effective or robust than a complex inverse-proportional one. It reinforces the idea that linear Best Fit scoring is preferable.\n    *   *Note:* Heuristic 7th is identical to 4th.\n\n*   **Comparing (4th) vs (5th):** The 4th heuristic employs a consolidation bonus to fill partially used bins, while the 5th heuristic introduces a *penalty* for creating \"fragmented\" gaps. The better performance of 4th suggests that a positive incentive for consolidation (filling existing bins) is generally more effective or easier to tune than a negative incentive for avoiding specific types of gaps. Both aim to improve space utilization but consolidation seems to yield better overall results in this ranking.\n\n*   **Comparing (5th) vs (9th):** The 5th heuristic is a refined Best Fit variant. The 9th heuristic introduces a \"relative utilization\" approach (`item / bins_remain_cap`), prioritizing bins where the item consumes a larger *proportion* of the remaining capacity. The significant drop in rank shows that classic Best Fit (minimizing absolute remaining space) is vastly superior to relative utilization for general bin packing, as the latter might lead to many partially filled bins if not carefully balanced.\n\n*   **Comparing (9th) vs (10th):** The 9th heuristic (relative utilization) is outperformed by the 10th, which is a pure Best Fit implementation (`-potential_remaining_space`). This clearly demonstrates that Best Fit, by directly aiming to minimize wasted space within a bin, is a stronger foundational heuristic for reducing the total number of bins compared to a relative fit approach.\n\n*   **Comparing (10th) vs (11th):** The 10th heuristic (Pure Best Fit) ranks much higher than the 11th (Worst Fit based on potential remaining space). This is a well-known result in bin packing: Best Fit generally minimizes the number of bins by packing them tightly, while Worst Fit aims to distribute items, often leading to more open bins and higher bin counts.\n\n*   **Comparing (11th) vs (12th):** Both are Worst Fit variants. The 11th prioritizes bins that will have the *most remaining space after placement*. The 12th prioritizes bins that *currently have the most remaining capacity*. The marginally better ranking of 11th suggests that considering the *post-placement* state for a Worst Fit strategy is slightly more effective than solely relying on the pre-placement state.\n    *   *Note:* Heuristics 13th, 14th, 15th, 17th, 19th, 20th are identical to 12th. Heuristics 16th and 18th are identical to 11th.\n\n**Overall:**\nThe best heuristics are always variants of Best Fit. The most critical factor for performance in bin packing is the overwhelming priority given to exact or near-exact fits. Additional strategic bonuses for consolidating items into existing, partially-filled bins can provide a further edge, but simpler, fixed additive bonuses often perform more robustly than complex proportional or inverse weighting schemes. Worst Fit strategies consistently perform poorly for minimizing bin count.\n- \n*   **Keywords**: Direct, Greedy, Simplicity, Waste Minimization, Fixed.\n*   **Advice**: Prioritize direct waste minimization with immediate, greedy choices. Apply only fixed, additive adjustments for highly desirable, simple outcomes like perfect fits.\n*   **Avoid**: Complex, non-linear, or multiplicative scoring; adaptive parameters; explicit fragmentation penalties or bin balancing; general numerical robustness as a design principle.\n*   **Explanation**: Effective heuristics remain simple, direct, and focused on immediate optimal outcomes. Overcomplicating objectives or using indirect, complex strategies often leads to suboptimal performance and instability.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}