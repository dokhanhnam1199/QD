{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Assume a global BIN_CAPACITY for context. This is typical in Bin Packing Problem (BPP)\n# where items and bin capacities are often normalized, e.g., to 1.0.\nBIN_CAPACITY = 1.0\n\n# Define heuristic parameters for strategic adjustments.\n# These values are empirical and might require tuning for specific problem distributions.\n\n# EPSILON_CLOSE_TO_ZERO: Tolerance for floating-point comparisons to detect \"exact\" fits.\n# Essential for numerical robustness in comparisons with zero.\nEPSILON_CLOSE_TO_ZERO = 1e-6\n\n# FRAGMENTATION_LOW_THRESHOLD & FRAGMENTATION_HIGH_THRESHOLD:\n# Define a range for \"fragmented\" gaps. These are remaining capacities that are\n# too small to be widely useful for future items, but not small enough to be\n# considered a \"perfect fit\". Placing an item here might lead to wasted space.\nFRAGMENTATION_LOW_THRESHOLD = 0.05 * BIN_CAPACITY # e.g., 5% of bin capacity\nFRAGMENTATION_HIGH_THRESHOLD = 0.20 * BIN_CAPACITY # e.g., 20% of bin capacity\n\n# FRAGMENTATION_PENALTY: The amount by which to reduce the priority for creating\n# a fragmented gap. This is a fixed additive penalty, designed to discourage\n# such outcomes without overriding truly tight fits.\nFRAGMENTATION_PENALTY = 0.3 # A moderate, fixed penalty value.\n\n    \"\"\"\n    Prioritizes bins using a Best Fit core, with an absolute preference for exact fits,\n    and a fixed penalty for creating small, fragmented remaining capacities.\n    \"\"\"\n    # Calculate the remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We allow for very small negative remaining space due to floating point inaccuracies,\n    # treating them as effectively zero.\n    can_fit_mask = potential_remaining_space >= -EPSILON_CLOSE_TO_ZERO\n\n    # Extract the potential remaining space for only the bins where the item can fit.\n    fitting_rem_space = potential_remaining_space[can_fit_mask]\n\n    # --- Step 1: Base Priority (Best Fit logic) ---\n    # The base priority is the negative of the potential remaining space.\n    # This means a smaller remaining space (closer to zero) results in a\n    # higher (less negative or zero) priority score. A perfect fit (0 remaining space)\n    # gets a base score of 0, which is the highest possible \"default\" score.\n    current_priorities_for_fit_bins = -fitting_rem_space\n\n    # --- Step 2: Strategic Additive Adjustments ---\n\n    # 2.1. Overwhelming Priority for Exact/Near-Exact Fits:\n    # Identify bins where the item perfectly or very nearly perfectly fills the bin.\n    # Assign them an extremely high, distinct priority to ensure they are always chosen\n    # if available, as this represents maximal bin utilization.\n    is_exact_or_near_fit = np.abs(fitting_rem_space) < EPSILON_CLOSE_TO_ZERO\n    current_priorities_for_fit_bins[is_exact_or_near_fit] = np.finfo(float).max / 2.0\n\n    # For subsequent adjustments, we only consider bins that are not an exact fit,\n    # as their priority has already been set to the highest possible value.\n    non_exact_mask = ~is_exact_or_near_fit\n\n    # 2.2. Penalty for Fragmented Gaps:\n    # Identify bins that, if chosen, would result in a remaining capacity falling\n    # within the \"fragmentation zone\". Reduce their priority to discourage their selection,\n    # promoting the creation of either very small (perfect fit) or larger, more usable gaps.\n    is_fragmented_zone_gap = (fitting_rem_space > FRAGMENTATION_LOW_THRESHOLD) & \\\n                             (fitting_rem_space < FRAGMENTATION_HIGH_THRESHOLD) & \\\n                             non_exact_mask\n    current_priorities_for_fit_bins[is_fragmented_zone_gap] -= FRAGMENTATION_PENALTY\n\n    # Assign the calculated priorities for fitting bins back into the main priorities array.\n    priorities[can_fit_mask] = current_priorities_for_fit_bins\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin, implementing a variation of Worst Fit.\n\n    This heuristic aims to select the bin that has the most remaining capacity before the item is\n    placed (since item size is constant for comparison), effectively trying to keep bins\n    as 'open' or 'empty' as possible for as long as possible. The primary goal is to distribute\n    items widely, promoting an emergent behavior of balanced bin usage across the available\n    containers, rather than aggressively filling and closing bins. This approach attempts to\n    preserve larger contiguous spaces in bins, potentially beneficial for future larger items.\n\n    This design adheres to the principle of \"minimal, local decision rules where desired global\n    outcomes emerge from their aggregate application,\" avoiding explicit global objectives or\n    reliance on numerical infinities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive a low, fixed finite priority score.\n    \"\"\"\n    # Initialize all priorities to a sufficiently low, but finite, number.\n    # This ensures that any bin that cannot fit the item will have a lower priority\n    # than any bin that can fit it, without relying on -infinity or other numerical mechanisms.\n    LOW_PRIORITY = -1000.0\n    priorities = np.full_like(bins_remain_cap, LOW_PRIORITY, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins where the item can fit, assign a priority based directly on their\n    # current remaining capacity. By maximizing this value, we are effectively choosing\n    # the bin with the most remaining space (Worst Fit). This is a simple, local rule\n    # that encourages spreading out items across bins, allowing the overall distribution\n    # of items to emerge from these repeated local decisions.\n    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask]\n\n    return priorities\n\n### Analyze & experience\n- Comparing the provided heuristics, it's evident that strategies focusing on maximizing bin utilization and minimizing wasted space perform significantly better. The list contains several identical heuristics, which will be noted in the comparisons.\n\n*   **Comparing (1st) vs (2nd):** The 1st heuristic, ranked best, employs a robust Best Fit core and a strong, fixed `PERFECT_FIT_BONUS` (1000.0). In contrast, the 2nd heuristic introduces a subtle, proportional consolidation bonus and a lower `EXACT_FIT_BONUS` (100.0). The superior performance of 1st suggests that a very high, overriding bonus for exact fits is more critical than a nuanced, proportional consolidation strategy. Simplicity and dominance of the perfect fit rule likely contribute to its effectiveness.\n\n*   **Comparing (2nd) vs (3rd):** The 2nd heuristic uses a linear Best Fit score, while the 3rd uses an inverse Best Fit score (`1.0 / (potential_remaining_space + EPSILON)`) and an inverse fullness consolidation bonus. The 3rd also uses an even higher `PERFECT_FIT_SCORE` (1e30). While the higher perfect fit score in 3rd is beneficial, the inverse scoring for Best Fit and consolidation can make the heuristic highly sensitive to small numerical differences, potentially leading to instability or less predictable behavior compared to the more stable linear approach in 2nd. The ranking suggests that the linear Best Fit combined with a strong exact fit bonus (as in 2nd) is more effective than the inverse-based scaling of 3rd, despite 3rd's even higher perfect fit constant.\n    *   *Note:* Heuristics 6th and 8th are identical to 3rd.\n\n*   **Comparing (3rd) vs (4th):** The 3rd heuristic uses inverse scoring for its Best Fit and consolidation components. The 4th heuristic reverts to a linear Best Fit score (`-potential_remaining_space`) combined with a dominant exact fit bonus and a *fixed additive* `PARTIALLY_FILLED_BIN_BONUS`. The 4th's superior ranking over 3rd indicates that a simpler, fixed consolidation bonus is more effective or robust than a complex inverse-proportional one. It reinforces the idea that linear Best Fit scoring is preferable.\n    *   *Note:* Heuristic 7th is identical to 4th.\n\n*   **Comparing (4th) vs (5th):** The 4th heuristic employs a consolidation bonus to fill partially used bins, while the 5th heuristic introduces a *penalty* for creating \"fragmented\" gaps. The better performance of 4th suggests that a positive incentive for consolidation (filling existing bins) is generally more effective or easier to tune than a negative incentive for avoiding specific types of gaps. Both aim to improve space utilization but consolidation seems to yield better overall results in this ranking.\n\n*   **Comparing (5th) vs (9th):** The 5th heuristic is a refined Best Fit variant. The 9th heuristic introduces a \"relative utilization\" approach (`item / bins_remain_cap`), prioritizing bins where the item consumes a larger *proportion* of the remaining capacity. The significant drop in rank shows that classic Best Fit (minimizing absolute remaining space) is vastly superior to relative utilization for general bin packing, as the latter might lead to many partially filled bins if not carefully balanced.\n\n*   **Comparing (9th) vs (10th):** The 9th heuristic (relative utilization) is outperformed by the 10th, which is a pure Best Fit implementation (`-potential_remaining_space`). This clearly demonstrates that Best Fit, by directly aiming to minimize wasted space within a bin, is a stronger foundational heuristic for reducing the total number of bins compared to a relative fit approach.\n\n*   **Comparing (10th) vs (11th):** The 10th heuristic (Pure Best Fit) ranks much higher than the 11th (Worst Fit based on potential remaining space). This is a well-known result in bin packing: Best Fit generally minimizes the number of bins by packing them tightly, while Worst Fit aims to distribute items, often leading to more open bins and higher bin counts.\n\n*   **Comparing (11th) vs (12th):** Both are Worst Fit variants. The 11th prioritizes bins that will have the *most remaining space after placement*. The 12th prioritizes bins that *currently have the most remaining capacity*. The marginally better ranking of 11th suggests that considering the *post-placement* state for a Worst Fit strategy is slightly more effective than solely relying on the pre-placement state.\n    *   *Note:* Heuristics 13th, 14th, 15th, 17th, 19th, 20th are identical to 12th. Heuristics 16th and 18th are identical to 11th.\n\n**Overall:**\nThe best heuristics are always variants of Best Fit. The most critical factor for performance in bin packing is the overwhelming priority given to exact or near-exact fits. Additional strategic bonuses for consolidating items into existing, partially-filled bins can provide a further edge, but simpler, fixed additive bonuses often perform more robustly than complex proportional or inverse weighting schemes. Worst Fit strategies consistently perform poorly for minimizing bin count.\n- \n*   **Keywords**: Direct, Greedy, Simplicity, Waste Minimization, Fixed.\n*   **Advice**: Prioritize direct waste minimization with immediate, greedy choices. Apply only fixed, additive adjustments for highly desirable, simple outcomes like perfect fits.\n*   **Avoid**: Complex, non-linear, or multiplicative scoring; adaptive parameters; explicit fragmentation penalties or bin balancing; general numerical robustness as a design principle.\n*   **Explanation**: Effective heuristics remain simple, direct, and focused on immediate optimal outcomes. Overcomplicating objectives or using indirect, complex strategies often leads to suboptimal performance and instability.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}