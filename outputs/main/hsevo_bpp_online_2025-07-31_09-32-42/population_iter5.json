[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes inverse waste for tight fits, with a subtle bonus for\n    bins already fuller. Uses machine epsilon for stability.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    can_fit_mask = bins_remain_cap >= item\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Use machine epsilon for robust numerical stability, as recommended by analysis.\n    epsilon = np.finfo(float).eps\n\n    # Core Best Fit (BF) priority: Inverse of (remaining_waste + epsilon).\n    # This provides a strong non-linear preference for perfect or very tight fits,\n    # consistent with the top-performing 'priority_v0' heuristic.\n    base_priority = 1.0 / (remaining_waste + epsilon)\n\n    # Adaptive / Global Utility Element:\n    # Introduce a subtle bonus for bins that are already more full (have less remaining capacity).\n    # This element aligns with \"Adaptive Logic\" and \"Global Utility\" advice by encouraging\n    # the closing of already utilized bins. It acts as a weighted tie-breaker or minor nudge\n    # when the primary Best Fit scores are very close.\n    # We assume a normalized bin capacity of 1.0, where `1.0 - bins_remain_cap` represents\n    # the portion of the bin that is already filled.\n    WEIGHT_FULLNESS_BONUS = 1e-7 # A small, tunable weight chosen to ensure this bonus\n                                 # is secondary and does not override the primary\n                                 # waste minimization unless scores are extremely close.\n\n    current_fullness = 1.0 - bins_remain_cap[can_fit_mask]\n    \n    fullness_bonus = WEIGHT_FULLNESS_BONUS * current_fullness\n    \n    # Combine the dominant Best Fit priority with the subtle fullness bonus.\n    priorities[can_fit_mask] = base_priority + fullness_bonus\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines robust Best Fit (prioritizing minimal waste) with an adaptive, linear bias\n    towards selecting already fuller bins. This hybrid approach aims for both immediate\n    waste minimization and long-term bin consolidation for improved global utility.\n    \"\"\"\n    # Initialize all priorities to negative infinity, unequivocally marking bins\n    # that cannot accommodate the item as unavailable.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify which bins have sufficient capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return the initialized priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the potential remaining space (waste) if the item were placed in fit-capable bins.\n    potential_remaining_space = bins_remain_cap[can_fit_mask] - item\n\n    # Use a small epsilon for numerical stability, especially for perfect fits (waste = 0).\n    # This ensures perfect fits receive a very high, but finite, priority score.\n    epsilon = np.finfo(float).eps\n\n    # Core Best Fit Component: Assign priority as the inverse of (potential remaining space + epsilon).\n    # This strongly favors bins that result in minimal remaining space.\n    best_fit_scores = 1.0 / (potential_remaining_space + epsilon)\n\n    # Adaptive Consolidation Bias Component:\n    # Introduce a positive bias for bins that are already relatively full.\n    # This encourages packing into existing, more utilized bins, contributing to\n    # overall bin consolidation and reducing the number of bins used.\n    # We use the maximum remaining capacity among *all* bins as a dynamic reference\n    # for what an \"empty\" bin looks like in the current system state.\n    max_rem_cap = np.max(bins_remain_cap)\n\n    # Calculate the relative \"fullness\" of each fitting bin. A lower bins_remain_cap\n    # indicates a fuller bin, resulting in a higher fullness score (closer to 1).\n    # Add epsilon to denominator to prevent division by zero if max_rem_cap is 0 (e.g., all bins are full).\n    # In such a case, can_fit_mask would likely be all false unless item is 0.\n    relative_fullness = (max_rem_cap - bins_remain_cap[can_fit_mask]) / (max_rem_cap + epsilon)\n\n    # Define the weight of the consolidation bias. This is a tunable parameter.\n    # A small positive value ensures this bias influences decisions, especially\n    # when Best Fit scores are very close, without overpowering the primary\n    # waste minimization objective.\n    consolidation_bias_weight = 0.05\n\n    # Combine the Best Fit score with the adaptive consolidation bias.\n    # The bias is added to the Best Fit score, subtly promoting fuller bins.\n    priorities[can_fit_mask] = best_fit_scores + consolidation_bias_weight * relative_fullness\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using an \"Accelerated Best Fit\" heuristic. It strongly favors\n    tight fits by minimizing waste, and applies an additional non-linear penalty to larger\n    waste values, thereby accelerating the preference for bin completion and reducing fragmentation.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): A NumPy array representing the remaining capacity\n                                      in each bin.\n\n    Returns:\n        np.ndarray: A NumPy array of priorities for each bin. Bins unable to fit\n                    the item will have a priority of -np.inf.\n    \"\"\"\n    # Use machine epsilon for numerical stability, ensuring perfect fits (waste = 0)\n    # receive an extremely high, finite priority score.\n    epsilon = np.finfo(float).eps\n\n    # Initialize priorities to negative infinity, unequivocally disqualifying bins\n    # that cannot accommodate the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins with sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining space (waste) in suitable bins after placing the item.\n    # A smaller waste indicates a more efficient fit.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Define a coefficient for the squared waste penalty. This constant can be tuned,\n    # but a value of 1.0 provides a significant, disproportionate penalty for larger wastes.\n    # This term makes the heuristic more aggressive in pursuing very tight fits.\n    # It indirectly promotes closing bins faster and discourages leaving moderately large gaps.\n    waste_squared_penalty_coeff = 1.0\n\n    # Calculate priority as the inverse of a \"penalized waste\" term.\n    # The term `(remaining_waste + epsilon)` handles the standard Best Fit.\n    # The additional term `waste_squared_penalty_coeff * remaining_waste**2` introduces\n    # a stronger, non-linear penalty for larger waste values. This effectively\n    # \"accelerates\" the preference for minimal waste.\n    penalized_waste = remaining_waste + epsilon + waste_squared_penalty_coeff * (remaining_waste**2)\n\n    priorities[can_fit_mask] = 1.0 / penalized_waste\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid Best Fit: prioritizes tight fits, with a bonus for already-full bins.\n    Combines inverse waste minimization (Best Fit) with a proportional bonus for\n    the current fullness of a bin, encouraging efficient bin closure.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Epsilon for numerical stability, especially for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Primary Best Fit component: Inverse of (remaining_waste + epsilon).\n    # This gives disproportionately high scores to tighter fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap).\n    # It acts as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)\n\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence, acting as a tie-breaker\n    # or a mild preference for already-fuller bins with similar Best Fit scores.\n    alpha = 0.01  # Tunable parameter: Adjust based on desired balance.\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + alpha * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced. This hybrid approach\n    # aims for immediate efficiency (Best Fit) while adaptively guiding towards bin closure.\n    priorities[can_fit_mask] = best_fit_score * (1.0 + alpha * bin_fullness_score)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item into each bin, implementing a\n    Best Fit with Strong Perfect Fit Preference and Inverse Waste Scoring.\n\n    This heuristic prioritizes bins with smallest remaining capacity,\n    strongly favoring perfect fits. For others, it uses inverse waste\n    scoring, penalizing larger gaps non-linearly. Combines robust\n    tight-fit with bin closure incentive.\n    \"\"\"\n    # Assuming bin capacity is normalized to 1.0. This simplifies thresholds.\n    # If actual capacities vary, a `bin_capacity` parameter would be needed.\n    BIN_CAPACITY = 1.0\n\n    # A small tolerance for floating-point comparisons to consider a fit \"perfect\"\n    PERFECT_FIT_TOLERANCE = 1e-6\n\n    # Smallest positive float for numerical stability, primarily to prevent division by zero.\n    EPSILON = np.finfo(float).eps\n\n    # A very high score assigned to perfect or near-perfect fits.\n    # This makes them unequivocally the most desirable choice, encouraging bin closure.\n    MAX_PRIORITY_SCORE = 1e12  # A large constant to ensure dominance of perfect fits\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this value, ensuring they are never chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We allow a tiny negative remaining space due to floating-point precision.\n    can_fit_mask = potential_remaining_space >= -PERFECT_FIT_TOLERANCE\n\n    # Extract the potential remaining spaces only for bins where the item can fit.\n    fitting_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Initialize priorities for fitting bins.\n    fitting_priorities = np.zeros_like(fitting_potential_rem_space)\n\n    # Identify perfect or near-perfect fits based on the defined tolerance.\n    perfect_fit_mask = np.abs(fitting_potential_rem_space) <= PERFECT_FIT_TOLERANCE\n\n    # Assign the maximal priority score for perfect fits. This strongly encourages closing bins.\n    fitting_priorities[perfect_fit_mask] = MAX_PRIORITY_SCORE\n\n    # For bins that are not a perfect fit, apply an inverse waste scoring.\n    # This creates a strong non-linear preference for smaller remaining spaces (less waste).\n    # The smaller the remaining space, the higher the 1/waste score.\n    non_perfect_fit_mask = ~perfect_fit_mask\n    \n    # Calculate waste for inverse scoring. Since perfect_fit_mask handles near-zero,\n    # fitting_potential_rem_space[non_perfect_fit_mask] will be positive.\n    waste_for_inverse = fitting_potential_rem_space[non_perfect_fit_mask]\n\n    # Apply the inverse waste function. Adding EPSILON prevents division by zero for\n    # extremely small non-zero remaining capacities.\n    fitting_priorities[non_perfect_fit_mask] = 1 / (waste_for_inverse + EPSILON)\n\n    # Update the main priorities array with the scores for fitting bins.\n    priorities[can_fit_mask] = fitting_priorities\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Consolidation-Aware Best Fit: Prioritizes minimal waste (Best Fit) while subtly\n    favoring bins that are already fuller. This encourages faster bin closure\n    and more efficient bin consolidation, integrating adaptive logic.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): Remaining capacity in each bin. Assumes capacities\n                                      are normalized (e.g., max capacity of 1.0).\n\n    Returns:\n        np.ndarray: Priority scores for each bin. Bins unable to fit the item get -np.inf.\n    \"\"\"\n    # Initialize priorities to negative infinity, ensuring bins unable to fit\n    # the item are unequivocally disqualified.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining space (waste) in suitable bins after placing the item.\n    # A smaller waste indicates a more efficient, tighter fit.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the current fullness of bins that can fit the item.\n    # This assumes a maximum bin capacity of 1.0 for normalized problems.\n    # Higher fullness implies the bin is closer to being 'closed'.\n    current_fullness = 1.0 - bins_remain_cap[can_fit_mask]\n\n    # A small positive constant for numerical stability and to ensure a finite,\n    # very high priority for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Define a consolidation factor. This value is chosen to be small enough\n    # to ensure the primary Best Fit term (inverse waste) remains dominant,\n    # but large enough to provide a subtle preference among bins with\n    # very similar waste values. It acts as an adaptive consolidation incentive.\n    CONSOLIDATION_FACTOR = 0.1\n\n    # Primary score: Inverse of waste. This strongly rewards tight fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Secondary score: Bonus for current fullness. This nudges the selection\n    # towards bins that are already more filled, encouraging their closure.\n    consolidation_bonus = CONSOLIDATION_FACTOR * current_fullness\n\n    # Combine the scores. The Best Fit dominates, but bins closer to full\n    # receive a slight advantage, reflecting a more global optimization strategy.\n    priorities[can_fit_mask] = best_fit_score + consolidation_bonus\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit with strong preference for perfect fits.\n    Prioritizes bins inversely to remaining waste, ensuring numerical stability.\n    Leverages inverse waste to balance immediate tight fits with robustness for various item sizes.\n    \"\"\"\n    # Initialize all priorities to negative infinity, excluding bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space if the item were placed in fitting bins.\n    fitting_bins_current_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_current_cap - item\n\n    # Define constants for heuristic scoring.\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12 \n    # A small epsilon for numerical stability in inverse calculations, preventing division by zero.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # This inherently penalizes larger waste (including small fragments) by giving them disproportionately lower scores.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n    \n    # Calculate inverse of (waste + epsilon) for non-perfect fits.\n    # A smaller waste results in a higher priority.\n    inverse_waste_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = inverse_waste_scores\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Prioritizes bins using an adaptive Best Fit approach, emphasizing tight fits for\n    global utility and robustly handling edge cases for predictive packing.\n\n    This heuristic combines the effectiveness of inverse waste minimization with\n    adaptive numerical stability, aiming for bin configurations that enhance\n    future packing opportunities. It assigns the highest priority to perfect fits\n    and uses a non-linear inverse function for others, subtly scaled by bin\n    capacity to be problem-aware.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures bins that cannot fit\n    # the item are never chosen, providing a clear baseline for infeasible options.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed without exceeding capacity.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # Scaling by `bin_capacity` makes this score adaptive to the problem's scale,\n    # ensuring perfect fits are overwhelmingly dominant regardless of the bin size.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity # A large multiplier ensures dominance.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a higher priority. The `STABILITY_EPSILON` is\n    # dynamically scaled by `bin_capacity` to maintain numerical stability and\n    # problem-awareness across different bin scales (e.g., a tiny absolute waste\n    # in a large bin might be effectively 'zero'). This avoids explicit \"dead space\"\n    # penalties, letting the inverse relationship naturally de-prioritize larger wastes.\n    STABILITY_EPSILON = np.finfo(float).eps * bin_capacity \n    \n    # Ensure epsilon is not zero, especially for very small bin_capacity values if they could occur.\n    if STABILITY_EPSILON == 0.0:\n        STABILITY_EPSILON = np.finfo(float).eps \n\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by aggressively minimizing waste, with adaptive scores.\n\n    Explicitly awards perfect fits maximal priority, and for others,\n    uses a robust inverse-waste score to favor tight fits, anticipating\n    efficient bin closure and minimal fragmentation.\n    \"\"\"\n    # Initialize priorities for all bins to a very low value (-infinity).\n    # This ensures that any bin that cannot fit the item will have the lowest\n    # possible priority and will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the remaining space in each bin if the current item were placed there.\n    # A non-negative value means the item can fit; a negative value means it cannot.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Create a boolean mask to identify only those bins that can actually\n    # accommodate the current item (remaining space must be non-negative).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Extract the potential remaining space only for the bins that can fit the item.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n\n    # Create masks to distinguish between perfect fits (waste = 0) and non-perfect fits (waste > 0).\n    perfect_fit_mask = (valid_potential_remaining_space == 0)\n    non_perfect_fit_mask = (valid_potential_remaining_space > 0)\n\n    # 1. Explicitly prioritize perfect fits with a very high, distinct score.\n    # This guarantees they are chosen over any other fit, promoting immediate bin closure\n    # and simplifying future packing decisions for that bin.\n    PERFECT_FIT_SCORE = 1e12\n\n    # Apply the perfect fit score to relevant bins through the nested masks.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a significantly higher priority score.\n    # np.finfo(float).eps provides robust numerical stability, giving very high\n    # scores for extremely tight fits (waste approaching zero) without division by zero.\n    TIGHT_FIT_EPSILON = np.finfo(float).eps\n\n    # Apply the inverse-waste priority score to non-perfect fit bins.\n    priorities[can_fit_mask][non_perfect_fit_mask] = \\\n        1.0 / (valid_potential_remaining_space[non_perfect_fit_mask] + TIGHT_FIT_EPSILON)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item, combining Best Fit with a strong perfect-fit bonus\n    and a subtle discouragement for creating \"dead space\" remnants.\n\n    This heuristic prioritizes perfect fits for global utility (bin closure). It uses\n    Best Fit as the primary mechanism, but adaptively applies a soft penalty to\n    discourage leaving very small, potentially unusable \"dead space\" in bins,\n    promoting more versatile remaining capacities.\n    \"\"\"\n\n    # Initialize priorities to negative infinity for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate potential remaining space for each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Mask for bins where the item can fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Apply the base Best Fit priority: negative of the potential remaining space.\n    # Smaller remaining space -> higher priority (less negative).\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    # --- Incorporate \"Predictive State\" and \"Global Utility\" via Perfect Fit Bonus ---\n    # Identify perfect fits (potential_remaining_space is effectively zero).\n    # Using a small epsilon for robust floating point comparison.\n    PERFECT_FIT_TOLERANCE = np.finfo(float).eps * 10 # A small tolerance for near-zero remaining space\n\n    perfect_fit_mask = can_fit_mask & (potential_remaining_space <= PERFECT_FIT_TOLERANCE)\n\n    # Assign a very high score for perfect fits to make them overwhelmingly preferred.\n    # This ensures bins are \"closed\" as efficiently as possible, a strong global optimization.\n    # The bonus is scaled by bin_capacity for robustness across different bin sizes.\n    PERFECT_FIT_BONUS = 1e6 * bin_capacity\n\n    # Only apply bonus to perfect fits among those that can fit\n    priorities[perfect_fit_mask] = PERFECT_FIT_BONUS\n\n    # --- Incorporate \"Adaptive Logic\" and \"Problem-aware Robustness\" via Soft Dead Space Discouragement ---\n    # Define thresholds for 'dead space' relative to bin_capacity.\n    # 'Dead space' is a small, non-zero remaining capacity that might be hard to fill later.\n    DEAD_SPACE_LOWER_BOUND = PERFECT_FIT_TOLERANCE  # Must be strictly greater than zero to exclude perfect fits\n    DEAD_SPACE_UPPER_BOUND = 0.15 * bin_capacity     # e.g., up to 15% of bin capacity is considered 'dead space'\n\n    # Identify bins that would create 'dead space' after placement.\n    dead_space_creation_mask = (potential_remaining_space > DEAD_SPACE_LOWER_BOUND) & \\\n                               (potential_remaining_space < DEAD_SPACE_UPPER_BOUND) & \\\n                               can_fit_mask\n\n    # Apply a 'soft' penalty. This penalty aims to make 'dead space' options\n    # slightly less attractive than leaving a larger, potentially more useful space.\n    # The magnitude is chosen to shift the priority below immediate Best Fit options\n    # that leave more versatile space, but not so drastically that it's always worse\n    # than opening an entirely empty new bin.\n    SOFT_DEAD_SPACE_PENALTY_VALUE = 0.20 * bin_capacity # Penalty value, scaled by bin_capacity\n\n    # Apply penalty to the priorities of bins creating dead space.\n    priorities[dead_space_creation_mask] -= SOFT_DEAD_SPACE_PENALTY_VALUE\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]