[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float) -> np.ndarray:\n    \"\"\"\n    Combines robust Best Fit with explicit perfect fit prioritization and\n    an adaptive bias for bin consolidation.\n    \"\"\"\n    # Initialize all priorities to negative infinity, marking bins that cannot fit the item as unavailable.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify which bins have sufficient capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return the initialized priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Constants for Heuristic Scoring ---\n    # A small epsilon for numerical stability, preventing division by zero in inverse calculations.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # Tolerance for identifying near-perfect fits, scaled by the bin capacity for robustness.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e15 \n\n    # Define the weight of the consolidation bias. This is a tunable parameter.\n    # It subtly promotes filling already utilized bins.\n    CONSOLIDATION_BIAS_WEIGHT = 0.05 \n\n    # --- Calculations for fitting bins ---\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_remain_cap - item\n\n    # 1. Prioritize Perfect Fits: Identify and assign an overwhelmingly high score to near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    \n    # Apply the perfect fit score to the corresponding bins.\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For Non-Perfect Fits: Apply Best Fit (inverse waste) combined with an adaptive consolidation bias.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    \n    if np.any(non_perfect_fit_mask_in_fitting):\n        non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n        \n        # Core Best Fit Component: Assign priority as the inverse of (potential remaining space + epsilon).\n        # This strongly favors bins that result in minimal remaining waste.\n        best_fit_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n\n        # Adaptive Consolidation Bias Component:\n        # Encourage packing into existing, more utilized bins to reduce the total bin count.\n        # The 'fullness' is determined relative to the most empty bin currently available,\n        # making the bias adaptive to the current system state.\n        max_rem_cap_overall = np.max(bins_remain_cap)\n        \n        # Calculate the relative \"fullness\" of each fitting non-perfect bin.\n        # A lower remaining capacity (more full) results in a higher fullness score.\n        relative_fullness = (max_rem_cap_overall - fitting_bins_remain_cap[non_perfect_fit_mask_in_fitting]) / \\\n                            (max_rem_cap_overall + STABILITY_EPSILON)\n        \n        # Combine the Best Fit score with the adaptive consolidation bias.\n        # The bias is added to the Best Fit score, subtly promoting fuller bins.\n        combined_scores = best_fit_scores + CONSOLIDATION_BIAS_WEIGHT * relative_fullness\n        \n        # Apply these combined scores to the non-perfect fitting bins.\n        priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = combined_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\nTypeError: priority_v2() missing 1 required positional argument: 'BIN_CAPACITY'\n20\n1\n"
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by combining aggressive inverse-waste minimization,\n    a distinct high score for perfect fits, and a strategic penalty\n    for leaving very small, \"unusable\" remaining capacities (bad gaps).\n    This heuristic minimizes fragmentation while favoring tight fits.\n    \"\"\"\n    BIN_CAPACITY_UNIT = 1.0  # Assumed normalized bin capacity\n\n    # Heuristic Parameters\n    # Tolerance for identifying a perfect fit (remaining capacity approximately 0)\n    PERFECT_FIT_TOLERANCE = 1e-9 \n    # A very high, distinct score assigned to perfect fits to ensure top priority\n    MAX_PERFECT_FIT_SCORE = 1000.0 \n    # Threshold below which a remaining gap is considered \"bad\" (difficult to fill)\n    SMALL_GAP_THRESHOLD = 0.15 * BIN_CAPACITY_UNIT \n    # A large negative offset applied to \"bad gap\" scores. This ensures they are\n    # heavily penalized and ranked lower than any \"good gap\", despite their\n    # raw inverse-waste score potentially being high.\n    BAD_GAP_PENALTY_OFFSET = -2000.0 # Adjusted to be sufficiently negative to push\n                                     # bad gaps (which can have high 1/waste scores)\n                                     # below good gaps (e.g., if 1/waste for bad gap is 1000,\n                                     # and min 1/waste for good gap is 6.67, then 1000 - 2000 = -1000, which is < 6.67)\n\n    # Small epsilon for numerical stability in inverse calculations (prevents division by zero)\n    TIGHT_FIT_EPSILON = np.finfo(float).eps \n\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this value and thus never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We use -PERFECT_FIT_TOLERANCE to account for floating-point inaccuracies\n    # when `item` might slightly exceed `bins_remain_cap` due to precision issues.\n    can_fit_mask = potential_remaining_space >= -PERFECT_FIT_TOLERANCE\n\n    # Filter potential remaining spaces for only those bins where the item can fit.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n    \n    # Initialize a temporary array for priorities of valid bins.\n    valid_priorities = np.zeros_like(valid_potential_remaining_space, dtype=float)\n\n    # --- Scoring Logic based on Categories ---\n\n    # 1. Perfect Fit: Remaining space is approximately zero.\n    # These receive the highest possible score, making them the top choice.\n    perfect_fit_mask = np.isclose(valid_potential_remaining_space, 0.0, atol=PERFECT_FIT_TOLERANCE)\n    valid_priorities[perfect_fit_mask] = MAX_PERFECT_FIT_SCORE \n\n    # 2. Bad Gap: Remaining space is small but non-zero (i.e., (0, SMALL_GAP_THRESHOLD)).\n    # These are scored using inverse waste, but then heavily penalized by a large negative offset.\n    # This ensures they are chosen only if no 'Good Gap' or 'Perfect Fit' options are available.\n    small_gap_mask = (valid_potential_remaining_space > PERFECT_FIT_TOLERANCE) & \\\n                     (valid_potential_remaining_space < SMALL_GAP_THRESHOLD)\n    \n    # Calculate base inverse waste score for bad gaps\n    bad_gap_base_scores = 1.0 / (valid_potential_remaining_space[small_gap_mask] + TIGHT_FIT_EPSILON)\n    # Apply the heavy penalty\n    valid_priorities[small_gap_mask] = bad_gap_base_scores + BAD_GAP_PENALTY_OFFSET\n\n    # 3. Good Gap: Remaining space is greater than or equal to the threshold ([SMALL_GAP_THRESHOLD, BIN_CAPACITY_UNIT]).\n    # These are scored in a \"Best Fit\" manner using inverse waste: 1.0 / (remaining_space + epsilon).\n    # A smaller remaining space (tighter fit) results in a higher positive score.\n    other_gap_mask = valid_potential_remaining_space >= SMALL_GAP_THRESHOLD\n    valid_priorities[other_gap_mask] = 1.0 / (valid_potential_remaining_space[other_gap_mask] + TIGHT_FIT_EPSILON)\n\n    # Assign the calculated priorities back to the full 'priorities' array\n    # using the original mask for all bins that could fit the item.\n    priorities[can_fit_mask] = valid_priorities\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float) -> np.ndarray:\n    \"\"\"Prioritizes bins using a robust Best Fit approach with inverse waste and a strategic consolidation bonus.\n\n    This heuristic combines inverse waste minimization, ensures perfect fits are highest priority,\n    and adds a strategic bonus to already fuller bins to promote consolidation.\n    \"\"\"\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item will retain this low priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 1. Identify bins where the item can be placed without exceeding capacity.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item,\n    # but only for those bins that can accommodate it.\n    potential_remain_after_fit_valid = bins_remain_cap[can_fit_mask] - item\n\n    # Define constants for numerical stability and perfect fit identification.\n    # Scaling by bin_capacity makes these parameters adaptive to the problem's scale.\n    STABILITY_EPSILON = np.finfo(float).eps * bin_capacity \n    PERFECT_FIT_TOLERANCE = 1e-9 * bin_capacity \n\n    # Ensure epsilon and tolerance are not effectively zero, especially for very small bin_capacity values.\n    STABILITY_EPSILON = max(STABILITY_EPSILON, np.finfo(float).eps)\n    PERFECT_FIT_TOLERANCE = max(PERFECT_FIT_TOLERANCE, 1e-9) \n\n    # 2. Separate valid bins into perfect fits and non-perfect fits, using tolerance for robustness.\n    perfect_fit_sub_mask = np.abs(potential_remain_after_fit_valid) < PERFECT_FIT_TOLERANCE\n    non_perfect_fit_sub_mask = potential_remain_after_fit_valid >= PERFECT_FIT_TOLERANCE\n\n    # Create full masks to directly index the `priorities` array based on original bin indices.\n    perfect_fit_full_mask = np.zeros_like(bins_remain_cap, dtype=bool)\n    perfect_fit_full_mask[can_fit_mask] = perfect_fit_sub_mask\n\n    non_perfect_fit_full_mask = np.zeros_like(bins_remain_cap, dtype=bool)\n    non_perfect_fit_full_mask[can_fit_mask] = non_perfect_fit_sub_mask\n\n    # Apply priority scores:\n    # A. Perfect fits receive the highest possible priority (np.inf) to ensure unequivocal selection.\n    priorities[perfect_fit_full_mask] = np.inf\n\n    # B. For non-perfect fits, the base score is calculated as the inverse of the remaining waste.\n    # This non-linear function disproportionately favors tighter fits over looser ones.\n    base_inverse_waste_scores = 1.0 / (potential_remain_after_fit_valid[non_perfect_fit_sub_mask] + STABILITY_EPSILON)\n    \n    # C. Add a consolidation bonus to bins that are already more filled.\n    # This additive term encourages placing items into bins that are close to being full,\n    # thereby helping to minimize the total number of bins used (consolidation).\n    CONSOLIDATION_FACTOR = 10.0 # Tunable parameter: determines the weight of the consolidation bias.\n                                 # A higher value gives more emphasis to filling existing bins.\n    \n    current_fullness_for_non_perfect_fits = (bin_capacity - bins_remain_cap[non_perfect_fit_full_mask]) / bin_capacity\n    consolidation_bonus = CONSOLIDATION_FACTOR * current_fullness_for_non_perfect_fits\n\n    # Combine the inverse waste score with the consolidation bonus for non-perfect fits.\n    priorities[non_perfect_fit_full_mask] = base_inverse_waste_scores + consolidation_bonus\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\nTypeError: priority_v2() missing 1 required positional argument: 'bin_capacity'\n20\n1\n"
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with Strong Perfect Fit Preference, Inverse Waste Scoring,\n    and an Adaptive Consolidation Bias to encourage filling existing bins faster.\n    \"\"\"\n    BIN_CAPACITY = 1.0\n    PERFECT_FIT_TOLERANCE = 1e-6\n    EPSILON = np.finfo(float).eps\n    MAX_PRIORITY_SCORE = 1e12\n    # A factor to weigh the consolidation bias. A small positive value ensures it\n    # influences choices among bins with similar inverse waste scores without dominating.\n    CONSOLIDATION_FACTOR = 0.1\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this value, ensuring they are never chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We allow a tiny negative remaining space due to floating-point precision.\n    can_fit_mask = potential_remaining_space >= -PERFECT_FIT_TOLERANCE\n\n    # Extract the potential remaining spaces only for bins where the item can fit.\n    fitting_potential_rem_space = potential_remaining_space[can_fit_mask]\n    \n    # Get the original remaining capacities for these fitting bins.\n    # This is needed to calculate the current \"fullness\" before placing the item.\n    fitting_bins_original_cap = bins_remain_cap[can_fit_mask]\n\n    # Initialize priorities for fitting bins.\n    fitting_priorities = np.zeros_like(fitting_potential_rem_space)\n\n    # Identify perfect or near-perfect fits based on the defined tolerance.\n    perfect_fit_mask = np.abs(fitting_potential_rem_space) <= PERFECT_FIT_TOLERANCE\n\n    # Assign the maximal priority score for perfect fits. This strongly encourages closing bins.\n    fitting_priorities[perfect_fit_mask] = MAX_PRIORITY_SCORE\n\n    # For bins that are not a perfect fit, apply an inverse waste scoring\n    # and add a consolidation bias.\n    non_perfect_fit_mask = ~perfect_fit_mask\n    \n    # Calculate waste for inverse scoring. Since perfect_fit_mask handles near-zero,\n    # fitting_potential_rem_space[non_perfect_fit_mask] will be positive.\n    waste_for_inverse = fitting_potential_rem_space[non_perfect_fit_mask]\n\n    # Calculate current bin fullness: (BIN_CAPACITY - current_remaining_capacity) / BIN_CAPACITY.\n    # A bin that is already 'fuller' (i.e., has less remaining capacity) gets a higher fullness score.\n    # This term acts as an adaptive, linear bias, encouraging consolidation by slightly preferring\n    # bins that are already well-filled, given similar waste.\n    current_bin_fullness = (BIN_CAPACITY - fitting_bins_original_cap[non_perfect_fit_mask]) / BIN_CAPACITY\n    \n    # Apply the inverse waste function. Adding EPSILON prevents division by zero.\n    # Then add the consolidation bias.\n    fitting_priorities[non_perfect_fit_mask] = (\n        1 / (waste_for_inverse + EPSILON) + CONSOLIDATION_FACTOR * current_bin_fullness\n    )\n\n    # Update the main priorities array with the scores for fitting bins.\n    priorities[can_fit_mask] = fitting_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Hybrid Best Fit with explicit perfect fit priority and fullness bonus.\n    Prioritizes perfect fits, then combines inverse waste minimization with a\n    multiplicative bonus for bin fullness to encourage consolidation.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 1. Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Extract relevant data for bins that can fit, to avoid re-indexing.\n    relevant_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    potential_remain_after_fit = relevant_bins_remain_cap - item\n\n    # Epsilon for numerical stability, using a small standard machine epsilon.\n    epsilon = np.finfo(float).eps\n\n    # 2. Prioritize Perfect Fits: Assign a very high, distinct score.\n    # Use a tolerance for floating point comparisons, scaled by bin_capacity for robustness\n    # across different problem scales.\n    PERFECT_FIT_TOLERANCE = epsilon * bin_capacity \n    \n    # Mask for perfect fits *within the set of bins that can fit*.\n    perfect_fit_sub_mask = (np.abs(potential_remain_after_fit) < PERFECT_FIT_TOLERANCE)\n    \n    # A large, bin_capacity-scaled score ensures perfect fits are unequivocally dominant.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity \n    \n    # Assign perfect fit scores to the identified bins.\n    priorities[can_fit_mask][perfect_fit_sub_mask] = PERFECT_FIT_SCORE\n\n    # 3. Process Non-Perfect Fits: Apply the hybrid Best Fit + Fullness logic.\n    # Mask for non-perfect fits *within the set of bins that can fit*.\n    non_perfect_fit_sub_mask = ~perfect_fit_sub_mask\n\n    # Get the remaining waste and bin remaining capacities specifically for non-perfect fits.\n    remaining_waste_non_perfect = potential_remain_after_fit[non_perfect_fit_sub_mask]\n    bins_remain_cap_non_perfect = relevant_bins_remain_cap[non_perfect_fit_sub_mask]\n\n    # Primary Best Fit component: Inverse of (remaining_waste + epsilon).\n    # This gives disproportionately high scores to tighter (but not perfect) fits.\n    best_fit_score = 1.0 / (remaining_waste_non_perfect + epsilon)\n\n    # Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap),\n    # acting as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (bins_remain_cap_non_perfect + epsilon)\n\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence, encouraging bin closure.\n    alpha = 0.01  # Tunable parameter: Adjust based on desired balance.\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + alpha * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced.\n    combined_score = best_fit_score * (1.0 + alpha * bin_fullness_score)\n\n    # Assign these combined scores to the corresponding non-perfect fit bins.\n    priorities[can_fit_mask][non_perfect_fit_sub_mask] = combined_score\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Hybrid Heuristic: Combines robust best-fit, explicit perfect-fit,\n    and consolidation bias, scaled for problem awareness.\n    \"\"\"\n    # Initialize all priorities to negative infinity. Bins unable to fit are disqualified.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit, return the initialized (all -inf) priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the potential remaining space (waste) in suitable bins after placing the item.\n    potential_waste = bins_remain_cap[can_fit_mask] - item\n\n    # --- Problem-aware constants for numerical stability and scaling ---\n    # EPSILON: A small value for numerical stability in inverse calculations, scaled by bin_capacity\n    # to maintain relative precision across different bin sizes.\n    EPSILON = np.finfo(float).eps * bin_capacity \n    if EPSILON == 0.0: # Safeguard for very small bin_capacity values\n        EPSILON = np.finfo(float).eps\n\n    # PERFECT_FIT_TOLERANCE: Tolerance for identifying \"perfect fits\" to account for\n    # floating-point inaccuracies, scaled by bin_capacity.\n    PERFECT_FIT_TOLERANCE = 1e-9 * bin_capacity \n\n    # PERFECT_FIT_SCORE: A very high score for perfect fits, scaled by bin_capacity\n    # to ensure they are overwhelmingly prioritized regardless of problem scale.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity \n\n    # CONSOLIDATION_FACTOR: Weight for the consolidation bonus. This additive factor\n    # encourages selecting already fuller bins, promoting their closure.\n    CONSOLIDATION_FACTOR = 0.1 \n\n    # --- Assign priorities based on fit characteristics ---\n\n    # 1. Prioritize perfect fits (waste is zero or very close to zero).\n    perfect_fit_mask = np.isclose(potential_waste, 0, atol=PERFECT_FIT_TOLERANCE)\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits (some waste remains), use a combined score.\n    non_perfect_fit_mask = ~perfect_fit_mask \n\n    if np.any(non_perfect_fit_mask):\n        # Extract waste for only the non-perfect fitting bins.\n        current_potential_waste = potential_waste[non_perfect_fit_mask]\n\n        # Primary score: Inverse of waste. This strongly rewards tighter fits\n        # by making smaller wastes result in disproportionately higher scores.\n        best_fit_score = 1.0 / (current_potential_waste + EPSILON)\n\n        # Secondary score: Bonus based on the bin's current fullness (before placing item).\n        # This is normalized (0 to 1) and encourages selecting bins closer to full.\n        current_fullness = (bin_capacity - bins_remain_cap[can_fit_mask][non_perfect_fit_mask]) / bin_capacity\n\n        # Additive consolidation bonus.\n        consolidation_bonus = CONSOLIDATION_FACTOR * current_fullness\n\n        # Combine the scores. Best Fit is dominant, but fuller bins get a slight edge.\n        priorities[can_fit_mask][non_perfect_fit_mask] = best_fit_score + consolidation_bonus\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines robust Best Fit with adaptive bin consolidation and explicit perfect fit prioritization.\n    Prioritizes minimal waste, encourages using fuller bins, and ensures perfect fits are optimal.\n    \"\"\"\n    # Initialize all priorities to negative infinity, unequivocally marking bins\n    # that cannot accommodate the item as unavailable.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify which bins have sufficient capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return the initialized priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Step 1: Calculate core Best Fit and Adaptive Consolidation scores ---\n\n    # Potential remaining space (waste) if the item were placed in fit-capable bins.\n    potential_remaining_space = bins_remain_cap[can_fit_mask] - item\n\n    # Small epsilon for numerical stability, especially for near-zero remaining space.\n    # This prevents division by zero and ensures very small waste values don't cause issues.\n    EPSILON = np.finfo(float).eps\n\n    # Core Best Fit Component: Assign priority as the inverse of (potential remaining space + epsilon).\n    # This strongly favors bins that result in minimal remaining space (tightest fit).\n    best_fit_scores = 1.0 / (potential_remaining_space + EPSILON)\n\n    # Adaptive Consolidation Bias Component: Promote packing into already fuller bins.\n    # This encourages overall bin consolidation, aiming to reduce the total number of bins used.\n    # We use the maximum remaining capacity among *all* bins as a dynamic reference\n    # for what an \"empty\" bin looks like in the current system state.\n    max_rem_cap = np.max(bins_remain_cap)\n\n    # Calculate the relative \"fullness\" of each fitting bin. A lower bins_remain_cap\n    # indicates a fuller bin, resulting in a higher fullness score (closer to 1).\n    # Add epsilon to denominator to prevent division by zero if max_rem_cap is 0.\n    relative_fullness = (max_rem_cap - bins_remain_cap[can_fit_mask]) / (max_rem_cap + EPSILON)\n\n    # Tunable weight for the consolidation bias. A small positive value ensures this\n    # bias influences decisions without overpowering the primary waste minimization.\n    CONSOLIDATION_BIAS_WEIGHT = 0.05\n\n    # Combine the Best Fit score with the adaptive consolidation bias.\n    # This forms the base priority for all fit-capable bins.\n    priorities[can_fit_mask] = best_fit_scores + CONSOLIDATION_BIAS_WEIGHT * relative_fullness\n\n    # --- Step 2: Explicitly boost perfect fits to ensure their absolute priority ---\n\n    # Tolerance for identifying near-perfect fits to handle floating-point inaccuracies.\n    # A small absolute value is used for robustness across different bin capacities/item sizes.\n    PERFECT_FIT_TOLERANCE = 1e-9\n\n    # A very high score to ensure perfect fits are chosen over any other option.\n    # This value must be significantly larger than any possible score derived from Step 1\n    # to guarantee that a perfect fit always receives the highest priority.\n    PERFECT_FIT_SCORE = 1e30 \n\n    # Identify perfect or near-perfect fits within the fitting bins.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n\n    # Apply the super-high score to bins that are perfect fits.\n    # This overrides any score calculated in Step 1 for these specific bins,\n    # making perfect fits the unequivocally best choice.\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid Best Fit with explicit Perfect Fit priority and adaptive bin consolidation.\n    Combines inverse waste minimization with a multiplicative bonus for bin fullness,\n    while ensuring perfect fits are chosen first.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return priorities as is (-inf for all).\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    # Only for bins that can fit the item.\n    current_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_waste = current_bins_remain_cap - item\n\n    # Constants for heuristic scoring\n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    # Using an absolute tolerance suitable for general floating-point comparisons.\n    PERFECT_FIT_TOLERANCE = 1e-9\n    # Epsilon for numerical stability, preventing division by zero, especially for small waste or remaining capacity.\n    STABILITY_EPSILON = np.finfo(float).eps\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence towards bin closure.\n    ALPHA_FULLNESS_BONUS = 0.01\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    # These are cases where potential_remaining_waste is very close to zero.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_waste) < PERFECT_FIT_TOLERANCE\n    \n    # Assign the high perfect fit score to the corresponding bins.\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, apply a hybrid Best Fit strategy with a fullness bonus.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    \n    # Select the relevant subsets for non-perfect fits.\n    non_perfect_waste = potential_remaining_waste[non_perfect_fit_mask_in_fitting]\n    non_perfect_bins_remain_cap = current_bins_remain_cap[non_perfect_fit_mask_in_fitting]\n\n    # Calculate the primary Best Fit component: Inverse of (waste + epsilon).\n    # This gives disproportionately high scores to tighter fits.\n    best_fit_score = 1.0 / (non_perfect_waste + STABILITY_EPSILON)\n\n    # Calculate the Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap).\n    # It acts as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (non_perfect_bins_remain_cap + STABILITY_EPSILON)\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + ALPHA_FULLNESS_BONUS * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced. This hybrid approach\n    # aims for immediate efficiency (Best Fit) while adaptively guiding towards bin closure.\n    combined_score = best_fit_score * (1.0 + ALPHA_FULLNESS_BONUS * bin_fullness_score)\n\n    # Assign the combined scores to the non-perfect fitting bins.\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = combined_score\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid Best Fit with explicit perfect fit priority and bin consolidation bonus.\n    Prioritizes perfect fits. For others, balances tight fit (inverse waste) with\n    a subtle bonus for fuller bins to encourage closure.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, all priorities remain -inf.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_remain_cap - item\n\n    # Constants for numerical stability and scoring.\n    STABILITY_EPSILON = np.finfo(float).eps  # Smallest representable float\n    PERFECT_FIT_TOLERANCE = 1e-6             # Absolute tolerance for near-perfect fits\n    PERFECT_FIT_SCORE = 1e12                 # High score for perfect fits to guarantee selection\n    ALPHA_FULLNESS_BONUS = 0.01              # Weight for the bin fullness component (0.01-0.05 is often a good start)\n\n    # 1. Explicitly identify and prioritize perfect or near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    \n    # Apply the highest score to perfect fit bins.\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, calculate a combined score.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    \n    # Only proceed if there are bins that are not perfect fits but can still fit the item.\n    if np.any(non_perfect_fit_mask_in_fitting):\n        non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n        non_perfect_bins_remain_cap = fitting_bins_remain_cap[non_perfect_fit_mask_in_fitting]\n\n        # Primary component: Inverse of remaining waste (Best Fit).\n        # This gives disproportionately higher scores to tighter fits.\n        best_fit_score = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n\n        # Secondary component: Inverse of remaining capacity (Fullness Bonus).\n        # Gives higher scores to bins that are already more full (smaller remaining capacity),\n        # acting as a subtle bias towards closing bins.\n        bin_fullness_score = 1.0 / (non_perfect_bins_remain_cap + STABILITY_EPSILON)\n\n        # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n        # The '1.0 + alpha * ...' ensures the primary best_fit_score is amplified, not replaced,\n        # by the fullness component, balancing immediate fit quality with bin consolidation.\n        combined_score = best_fit_score * (1.0 + ALPHA_FULLNESS_BONUS * bin_fullness_score)\n        \n        # Assign these combined scores to the non-perfect fitting bins.\n        priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = combined_score\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse waste (Best Fit) with explicit perfect fit prioritization\n    and a severe penalty for creating small, potentially unusable gaps, enhancing\n    global bin utilization and reducing fragmentation.\n    \"\"\"\n    PERFECT_FIT_TOLERANCE = 1e-9  # Tolerance for floating point perfect fit check\n    PERFECT_FIT_SCORE = 1e12    # Very high score for perfect fits\n    STABILITY_EPSILON = np.finfo(float).eps # Small epsilon for numerical stability in inverse division\n\n    SMALL_GAP_THRESHOLD = 0.05  # Threshold for what constitutes a \"small gap\"\n    # A large negative penalty to significantly de-prioritize bins leaving small, bad gaps.\n    # This must be large enough to make the penalized inverse score worse than any desirable non-small-gap score.\n    SMALL_GAP_SEVERE_PENALTY = 1000.0 \n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this lowest priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the remaining space in these bins if the item were placed.\n    potential_remaining_space = bins_remain_cap[can_fit_mask] - item\n\n    # Initialize priorities for currently valid bins.\n    current_bin_priorities = np.zeros_like(potential_remaining_space)\n\n    # 1. Assign Perfect Fit Score: If remaining space is zero (within tolerance), it's a perfect fit.\n    # These should always be the highest priority.\n    perfect_fit_mask = potential_remaining_space <= PERFECT_FIT_TOLERANCE\n    current_bin_priorities[perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. Assign Inverse Waste Score for Non-Perfect Fits: For bins where the item fits\n    # but some space remains, prioritize inversely to the remaining waste. Smaller waste\n    # yields higher priority. Add epsilon for numerical stability.\n    non_perfect_fit_mask = potential_remaining_space > PERFECT_FIT_TOLERANCE\n    current_bin_priorities[non_perfect_fit_mask] = \\\n        1.0 / (potential_remaining_space[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    # 3. Apply Small Gap Penalty: Identify non-perfect fits that result in a \"small gap\".\n    # These are highly undesirable as they fragment bin capacity. Apply a severe penalty\n    # to make them less attractive than larger, more usable remaining spaces, or even opening a new bin.\n    small_gap_to_penalize_mask = (potential_remaining_space > PERFECT_FIT_TOLERANCE) & \\\n                                 (potential_remaining_space < SMALL_GAP_THRESHOLD)\n    \n    current_bin_priorities[small_gap_to_penalize_mask] -= SMALL_GAP_SEVERE_PENALTY\n\n    # Assign the calculated priorities back to the main priorities array for bins that can fit.\n    priorities[can_fit_mask] = current_bin_priorities\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]