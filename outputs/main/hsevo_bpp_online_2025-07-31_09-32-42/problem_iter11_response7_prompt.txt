{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Assume a global BIN_CAPACITY for context. This is typical in Bin Packing Problem (BPP)\n# where items and bin capacities are often normalized, e.g., to 1.0.\n# The thresholds below are defined relative to this capacity.\nBIN_CAPACITY = 1.0\n\n# Define heuristic parameters for strategic adjustments.\n# These values are empirical and might require tuning for specific problem distributions.\n\n# EPSILON_CLOSE_TO_ZERO: Tolerance for floating-point comparisons to detect \"exact\" fits.\nEPSILON_CLOSE_TO_ZERO = 1e-6\n\n# FRAGMENTATION_LOW_THRESHOLD & FRAGMENTATION_HIGH_THRESHOLD:\n# Define a range for \"fragmented\" gaps. These are remaining capacities that are\n# too small to be widely useful for future items, but not small enough to be\n# considered a \"perfect fit\". Placing an item here might lead to wasted space.\nFRAGMENTATION_LOW_THRESHOLD = 0.05 * BIN_CAPACITY  # e.g., 5% of bin capacity\nFRAGMENTATION_HIGH_THRESHOLD = 0.20 * BIN_CAPACITY # e.g., 20% of bin capacity\n\n# FRAGMENTATION_PENALTY: The amount by which to reduce the priority for creating\n# a fragmented gap. A higher value makes fragmented gaps significantly less desirable.\n# This value is relative to the base Best Fit score (which is typically small negative numbers).\nFRAGMENTATION_PENALTY = 0.5\n\n# LARGE_GAP_THRESHOLD: Defines a threshold for what's considered a \"large\" remaining gap.\n# If no tight fit is available, leaving a large gap might be strategically beneficial\n# to accommodate larger future items, thus keeping the bin \"open\".\nLARGE_GAP_THRESHOLD = 0.50 * BIN_CAPACITY # e.g., 50% of bin capacity\n\n# LARGE_GAP_BONUS: The amount by which to increase the priority for leaving a large gap.\n# This bonus should be small enough not to override truly tight fits, but\n# sufficient to make large gaps slightly more attractive than medium-sized,\n# potentially fragmented ones, when no tight fit is an option.\nLARGE_GAP_BONUS = 0.1\n\n    \"\"\"\n    Returns a priority score for placing an item in each bin, enhancing the\n    Best Fit (BF) heuristic with strategic considerations for bin consolidation,\n    fragmentation avoidance, and maintaining bin utility.\n\n    This heuristic aims to:\n    1.  **Strongly Prioritize Exact Fits:** Always choose a bin that can be\n        perfectly (or near-perfectly) filled by the item, ensuring maximum bin utilization.\n    2.  **Discourage Fragmentation:** Penalize bins that would result in a\n        small, potentially unusable \"fragmented\" remaining capacity after placement.\n        This encourages filling bins more completely or leaving larger, more useful gaps.\n    3.  **Encourage Large Usable Gaps (Strategic Worst Fit):** If no tight fit is\n        available, slightly prefer bins that leave a substantial remaining capacity.\n        This keeps bins strategically \"open\" to accommodate larger future items,\n        reducing the chance of using many bins with small, varied, and hard-to-fill gaps.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: A NumPy array containing the remaining capacity of each bin.\n\n    Return:\n        A NumPy array of the same size as `bins_remain_cap`, with a priority score\n        for each bin. A higher score indicates a higher priority for placing the\n        item in that bin. Bins that cannot accommodate the item receive -infinity.\n    \"\"\"\n    # Calculate the remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We allow for very small negative remaining space due to floating point inaccuracies,\n    # treating them as effectively zero.\n    can_fit_mask = potential_remaining_space >= -EPSILON_CLOSE_TO_ZERO\n\n    # Extract the potential remaining space for only the bins where the item can fit.\n    fitting_rem_space = potential_remaining_space[can_fit_mask]\n\n    # --- Step 1: Base Priority (Best Fit logic) ---\n    # The base priority is the negative of the potential remaining space.\n    # This means a smaller remaining space (closer to zero) results in a\n    # higher (less negative or zero) priority score.\n    # A perfect fit (0 remaining space) gets a base score of 0.\n    current_priorities_for_fit_bins = -fitting_rem_space\n\n    # --- Step 2: Strategic Adjustments ---\n\n    # 2.1. Very High Priority for Exact/Near-Exact Fits:\n    # Identify bins where the item perfectly or very nearly perfectly fills the bin.\n    # Assign them an extremely high, distinct priority to ensure they are always chosen if available.\n    is_exact_or_near_fit = np.abs(fitting_rem_space) < EPSILON_CLOSE_TO_ZERO\n    current_priorities_for_fit_bins[is_exact_or_near_fit] = np.finfo(float).max / 2.0 # Use a very large float value\n\n    # For subsequent adjustments, we only consider bins that are not an exact fit,\n    # as their priority has already been set to the highest possible value.\n    non_exact_mask = ~is_exact_or_near_fit\n\n    # 2.2. Penalty for Fragmented Gaps:\n    # Identify bins that, if chosen, would result in a remaining capacity falling\n    # within the \"fragmentation zone\" (e.g., too small to be useful for many items,\n    # but not a perfect fit). Reduce their priority to discourage their selection.\n    is_fragmented_zone_gap = (fitting_rem_space > FRAGMENTATION_LOW_THRESHOLD) & \\\n                             (fitting_rem_space < FRAGMENTATION_HIGH_THRESHOLD) & \\\n                             non_exact_mask\n    current_priorities_for_fit_bins[is_fragmented_zone_gap] -= FRAGMENTATION_PENALTY\n\n    # 2.3. Bonus for Large Usable Gaps:\n    # Identify bins that, if chosen, would leave a large remaining capacity.\n    # If no exact or very tight fit is available, it might be strategically better\n    # to leave a large, reusable space rather than a fragmented one. This applies\n    # a small bonus to make these bins slightly more attractive among non-tight options.\n    is_large_usable_gap = (fitting_rem_space >= LARGE_GAP_THRESHOLD) & \\\n                          non_exact_mask\n    current_priorities_for_fit_bins[is_large_usable_gap] += LARGE_GAP_BONUS\n\n    # Assign the calculated priorities for fitting bins back into the main priorities array.\n    priorities[can_fit_mask] = current_priorities_for_fit_bins\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Hybrid Best Fit with explicit perfect fit priority and fullness bonus.\n    Prioritizes perfect fits, then combines inverse waste minimization with a\n    multiplicative bonus for bin fullness to encourage consolidation.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 1. Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Extract relevant data for bins that can fit, to avoid re-indexing.\n    relevant_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    potential_remain_after_fit = relevant_bins_remain_cap - item\n\n    # Epsilon for numerical stability, using a small standard machine epsilon.\n    epsilon = np.finfo(float).eps\n\n    # 2. Prioritize Perfect Fits: Assign a very high, distinct score.\n    # Use a tolerance for floating point comparisons, scaled by bin_capacity for robustness\n    # across different problem scales.\n    PERFECT_FIT_TOLERANCE = epsilon * bin_capacity \n    \n    # Mask for perfect fits *within the set of bins that can fit*.\n    perfect_fit_sub_mask = (np.abs(potential_remain_after_fit) < PERFECT_FIT_TOLERANCE)\n    \n    # A large, bin_capacity-scaled score ensures perfect fits are unequivocally dominant.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity \n    \n    # Assign perfect fit scores to the identified bins.\n    priorities[can_fit_mask][perfect_fit_sub_mask] = PERFECT_FIT_SCORE\n\n    # 3. Process Non-Perfect Fits: Apply the hybrid Best Fit + Fullness logic.\n    # Mask for non-perfect fits *within the set of bins that can fit*.\n    non_perfect_fit_sub_mask = ~perfect_fit_sub_mask\n\n    # Get the remaining waste and bin remaining capacities specifically for non-perfect fits.\n    remaining_waste_non_perfect = potential_remain_after_fit[non_perfect_fit_sub_mask]\n    bins_remain_cap_non_perfect = relevant_bins_remain_cap[non_perfect_fit_sub_mask]\n\n    # Primary Best Fit component: Inverse of (remaining_waste + epsilon).\n    # This gives disproportionately high scores to tighter (but not perfect) fits.\n    best_fit_score = 1.0 / (remaining_waste_non_perfect + epsilon)\n\n    # Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap),\n    # acting as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (bins_remain_cap_non_perfect + epsilon)\n\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence, encouraging bin closure.\n    alpha = 0.01  # Tunable parameter: Adjust based on desired balance.\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + alpha * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced.\n    combined_score = best_fit_score * (1.0 + alpha * bin_fullness_score)\n\n    # Assign these combined scores to the corresponding non-perfect fit bins.\n    priorities[can_fit_mask][non_perfect_fit_sub_mask] = combined_score\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (15th), we see a stark contrast. The 1st ranked heuristic is a pure Best Fit approach, prioritizing bins that result in the least remaining capacity. In contrast, the 15th (worst unique) heuristic is a complex hybrid: it combines inverse waste best-fit, explicit perfect-fit prioritization, and a multiplicative bonus for bin fullness, all with constants scaled by `bin_capacity`. The best performance by the simplest heuristic suggests that for this problem, added complexity, especially through multiplicative scoring and multiple tuning parameters, may introduce instability or conflicting objectives that degrade overall performance.\n\nComparing (2nd) vs (13th), the second-best heuristic introduces fixed additive bonuses for exact fits and partially filled bins over the simple Best Fit. The 13th heuristic employs an inverse waste primary score, explicit perfect fit, and an *additive* consolidation bonus based on normalized current fullness, with `bin_capacity`-scaled constants. The ranking suggests that fixed, perhaps overly simplistic, additive bonuses (2nd) perform better than a more mathematically nuanced additive consolidation with inverse waste (13th). The non-adaptive nature of 2nd's bonuses might be less disruptive than the specific implementation of consolidation in 13th.\n\nComparing (1st) vs (2nd), the 1st heuristic uses a straightforward negative remaining capacity (Best Fit). The 2nd adds fixed additive bonuses for exact fits and preferring partially filled bins. The degradation from 1st to 2nd indicates that these fixed bonuses, while aiming for consolidation, might disrupt the optimal ordering of pure Best Fit, leading to suboptimal choices by favoring bins that are not the absolute tightest fit in all scenarios.\n\nComparing (2nd) vs (3rd), the 2nd relies on linear negative remaining capacity with fixed additive bonuses. The 3rd shifts to an inverse waste function, a strong perfect fit bonus, and an *adaptive* additive consolidation based on current bin fullness. The higher rank of 2nd suggests that while inverse waste and adaptive consolidation are theoretically powerful, their specific implementation and tuning (or lack thereof) in 3rd might have introduced too much sensitivity or an ineffective consolidation bias compared to 2nd's simpler approach.\n\nComparing (3rd) vs (4th), both heuristics employ an inverse waste function, strong perfect-fit prioritization, and an additive consolidation bias. The key difference in 4th is using `relative_fullness` (based on `max_rem_cap`) for its consolidation bias, rather than 3rd's simpler `current_bin_fullness`. The performance drop indicates that dynamically adapting the consolidation bias to the overall maximum remaining capacity (4th) was less effective than a bias solely based on the individual bin's current fullness (3rd), possibly due to the `max_rem_cap` metric being less indicative of optimal consolidation opportunities.\n\nComparing (4th) vs (5th), the 4th uses an inverse waste core with adaptive consolidation. The 5th returns to a scaled linear Best Fit component but critically introduces an adaptive penalty for creating \"fragmented\" small remaining spaces. The lower rank of 5th suggests that its linear Best Fit scoring might be less effective than inverse waste, or that the fragmentation penalty, while conceptually sound, might be overly aggressive or poorly calibrated, leading to the selection of less optimal bins.\n\nComparing (5th) vs (6th), the 5th heuristic focuses on linear Best Fit with fragmentation avoidance. The 6th is a highly complex multi-objective heuristic with linear Best Fit, perfect/near-perfect bonuses, adaptive fragmentation avoidance specific to small items, and a \"worst-fit\" tendency for small items to preserve space for larger items. The significantly lower rank of 6th strongly indicates that its highly nuanced and multi-faceted adaptive logic, with many parameters and potentially conflicting objectives (like worst-fit for small items vs. general best-fit), made it less robust and less effective than simpler strategies.\n\nComparing (6th) vs (7th), the very complex 6th is outperformed by the 7th heuristic. The 7th simplifies by focusing on an inverse waste base, a perfect fit bonus, and a *severe* fixed penalty for small gaps. This suggests that a targeted, strong penalty for unequivocally bad states (like very small, unusable gaps), combined with a powerful inverse waste mechanism, can be more effective than a broadly adaptive, complex approach.\n\nComparing (7th) vs (8th), the 7th uses inverse waste for its base, while 8th reverts to a simpler negative remaining space (linear Best Fit). Both apply penalties for fragmentation, but 8th also adds a bonus for leaving *large usable gaps*. The ranking suggests that 8th's linear Best Fit is less effective than inverse waste for driving optimal tight fits, and its \"large gap bonus\" might encourage suboptimal bin usage if better, tighter fits exist, thus performing worse than 7th.\n\nComparing (8th) vs (11th), the 8th uses linear Best Fit with additive adjustments. The 11th returns to the inverse waste primary component and introduces a *multiplicative* bonus for bin fullness. The degradation in rank from 8th to 11th indicates that the multiplicative fullness bonus, despite aiming for consolidation, may be too sensitive or poorly controlled compared to additive adjustments, leading to less stable and effective prioritization.\n\nComparing (11th) vs (13th), both use inverse waste and perfect fit. The 11th applies a multiplicative fullness bonus without `bin_capacity` scaling. The 13th uses an additive consolidation bonus based on normalized fullness, crucially introducing `bin_capacity`-scaled constants. The fact that 13th performs worse than 11th, despite the seemingly better practice of `bin_capacity` scaling, suggests that the additive consolidation, or its specific `CONSOLIDATION_FACTOR`, was less effective for the problem than the multiplicative one from 11th, or that the parameter values in 13th were not well-tuned.\n\nComparing (13th) vs (15th), both are scaled by `bin_capacity` and feature inverse waste and perfect fit. The key difference is the consolidation bonus: 13th uses an *additive* factor based on normalized current fullness, while 15th uses a *multiplicative* factor based on inverse remaining capacity. The worse performance of 15th confirms the pattern observed earlier: multiplicative bonuses, even with scaling, tend to be less robust and harder to tune than additive ones, potentially leading to less effective heuristics.\n\nOverall: The consistent pattern is that simpler heuristics, particularly those leveraging a robust Best Fit (negative remaining space), tend to outperform more complex multi-objective heuristics with many tunable parameters and intricate interaction rules. Attempts to introduce \"smart\" adaptive behaviors, multiple bonuses, or multiplicative scoring often lead to worse performance, likely due to increased sensitivity, conflicting objectives, or insufficient parameter tuning for the specific problem distribution. Explicitly overriding scores for \"perfect fits\" is a generally good practice.\n- \nHere's a redefined 'Current self-reflection':\n\n*   **Keywords**: Emergent Behavior, Local Rules, State Evolution, Information Flow.\n*   **Advice**: Design heuristics with minimal, local decision rules where desired global outcomes emerge from their aggregate application. Focus on how problem state changes meaningfully propagate to inform subsequent choices.\n*   **Avoid**: Hardcoding explicit global objectives or dynamic parameter adjustments that react to problem state. Do not rely on specific numerical stability mechanisms (e.g., epsilon, infinity) or predefined \"best fit\" criteria.\n*   **Explanation**: Powerful heuristics often arise from simple, iterative processes where decisions progressively shape the problem state, rather than from pre-engineered complex strategies or numerical safeguards.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}