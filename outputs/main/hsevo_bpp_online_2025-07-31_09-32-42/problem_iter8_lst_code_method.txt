{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines robust Best Fit (prioritizing minimal waste) with an adaptive, linear bias\n    towards selecting already fuller bins. This hybrid approach aims for both immediate\n    waste minimization and long-term bin consolidation for improved global utility.\n    \"\"\"\n    # Initialize all priorities to negative infinity, unequivocally marking bins\n    # that cannot accommodate the item as unavailable.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify which bins have sufficient capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return the initialized priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the potential remaining space (waste) if the item were placed in fit-capable bins.\n    potential_remaining_space = bins_remain_cap[can_fit_mask] - item\n\n    # Use a small epsilon for numerical stability, especially for perfect fits (waste = 0).\n    # This ensures perfect fits receive a very high, but finite, priority score.\n    epsilon = np.finfo(float).eps\n\n    # Core Best Fit Component: Assign priority as the inverse of (potential remaining space + epsilon).\n    # This strongly favors bins that result in minimal remaining space.\n    best_fit_scores = 1.0 / (potential_remaining_space + epsilon)\n\n    # Adaptive Consolidation Bias Component:\n    # Introduce a positive bias for bins that are already relatively full.\n    # This encourages packing into existing, more utilized bins, contributing to\n    # overall bin consolidation and reducing the number of bins used.\n    # We use the maximum remaining capacity among *all* bins as a dynamic reference\n    # for what an \"empty\" bin looks like in the current system state.\n    max_rem_cap = np.max(bins_remain_cap)\n\n    # Calculate the relative \"fullness\" of each fitting bin. A lower bins_remain_cap\n    # indicates a fuller bin, resulting in a higher fullness score (closer to 1).\n    # Add epsilon to denominator to prevent division by zero if max_rem_cap is 0 (e.g., all bins are full).\n    # In such a case, can_fit_mask would likely be all false unless item is 0.\n    relative_fullness = (max_rem_cap - bins_remain_cap[can_fit_mask]) / (max_rem_cap + epsilon)\n\n    # Define the weight of the consolidation bias. This is a tunable parameter.\n    # A small positive value ensures this bias influences decisions, especially\n    # when Best Fit scores are very close, without overpowering the primary\n    # waste minimization objective.\n    consolidation_bias_weight = 0.05\n\n    # Combine the Best Fit score with the adaptive consolidation bias.\n    # The bias is added to the Best Fit score, subtly promoting fuller bins.\n    priorities[can_fit_mask] = best_fit_scores + consolidation_bias_weight * relative_fullness\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\n# Assuming BIN_CAPACITY can be inferred or passed. For this function, as `bins_remain_cap`\n# is an array of float values (e.g., [1.0, 0.5, 0.2]), we can infer that the maximum\n# value in this array (or a conceptual \"full\" bin capacity) is 1.0 (normalized).\nBIN_CAPACITY_UNIT = 1.0 \n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add an item to each bin, implementing a Best Fit\n    variation that strategically avoids creating very small, \"unusable\" remaining gaps,\n    while still highly prioritizing perfect fits.\n\n    This heuristic applies an \"adaptive logic\" by categorizing potential bin states\n    after an item is placed, aiming to improve \"global utility\" by anticipating\n    future bin configurations and managing dynamic bin states:\n\n    1.  **Perfect Fit**: If placing the item fills the bin exactly (remaining capacity becomes 0).\n        This receives the highest possible priority score. This is a highly desirable outcome\n        as it \"closes\" a bin efficiently.\n\n    2.  **Good Gap**: If placing the item leaves a remaining capacity that is large enough\n        to be potentially useful for future items (i.e., above a defined 'small gap threshold').\n        These bins are scored similarly to standard Best Fit (preferring smaller remaining space\n        amongst themselves), but are always considered more desirable than 'Bad Gaps'. This\n        promotes filling bins without creating highly fragmented space.\n\n    3.  **Bad Gap**: If placing the item leaves a very small, non-zero remaining capacity\n        (below the 'small gap threshold'). Such capacities are often difficult to fill with\n        subsequent items, leading to wasted space and an increased number of bins used overall.\n        These bins are heavily penalized to ensure they are chosen only if no 'Good Gap'\n        or 'Perfect Fit' options are available.\n\n    This approach moves beyond simply \"over-emphasizing immediate greedy fits\" by adding\n    a foresight mechanism that penalizes outcomes likely to lead to future fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin (float, typically between 0 and BIN_CAPACITY_UNIT).\n        bins_remain_cap: Array of current remaining capacities for each bin (float, typically\n                         between 0 and BIN_CAPACITY_UNIT).\n\n    Return:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-np.inf).\n    \"\"\"\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # Using a small epsilon (1e-9) to account for floating-point inaccuracies\n    # when an item perfectly fills a bin (e.g., 0.5 - 0.5 = 0.0, but float math might yield 1e-17).\n    can_fit_mask = potential_remaining_space >= -1e-9\n\n    # Filter potential remaining spaces for only those bins where the item can fit.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n    \n    # Initialize a temporary array for priorities of valid bins.\n    valid_priorities = np.zeros_like(valid_potential_remaining_space, dtype=float)\n\n    # --- Heuristic Parameters ---\n    # This threshold defines the upper bound for what is considered a \"small\" and\n    # potentially \"unusable\" remaining gap. A value of 0.15 means any remaining\n    # space less than 15% of the bin capacity (and greater than zero) is considered a \"bad gap\".\n    # This parameter is crucial and may require tuning based on the problem's item size distribution.\n    SMALL_GAP_THRESHOLD = 0.15 * BIN_CAPACITY_UNIT \n\n    # This is a large negative offset applied to \"bad gaps\". It ensures that\n    # any 'Good Gap' (even a very large one, which would typically get a low negative score)\n    # will always have a higher priority than any 'Bad Gap'.\n    # The range of scores for 'Good Gaps' typically falls within [-(BIN_CAPACITY_UNIT - min_item_size), 0].\n    # An offset like -100.0 is sufficiently large to push 'Bad Gap' scores well below this range.\n    BAD_GAP_SCORE_OFFSET = -100.0 \n\n    # --- Scoring Logic based on Categories ---\n\n    # 1. Perfect Fit: Remaining space is approximately zero.\n    # These receive the highest possible score (0.0), making them the top choice.\n    perfect_fit_mask = np.isclose(valid_potential_remaining_space, 0.0, atol=1e-9)\n    valid_priorities[perfect_fit_mask] = 0.0 \n\n    # 2. Bad Gap: Remaining space is small but non-zero (i.e., (0, SMALL_GAP_THRESHOLD)).\n    # These are heavily penalized. Their score is calculated as -(remaining_space)\n    # plus the large negative offset. This ensures they are ranked lower than all 'Good Gaps'.\n    small_gap_mask = (valid_potential_remaining_space > 1e-9) & \\\n                     (valid_potential_remaining_space < SMALL_GAP_THRESHOLD)\n    valid_priorities[small_gap_mask] = -valid_potential_remaining_space[small_gap_mask] + BAD_GAP_SCORE_OFFSET\n\n    # 3. Good Gap: Remaining space is greater than or equal to the threshold ([SMALL_GAP_THRESHOLD, BIN_CAPACITY_UNIT]).\n    # These are scored in a \"Best Fit\" manner: -(remaining_space). Among these, smaller\n    # remaining spaces (closer to the threshold) will have higher scores (closer to 0.0).\n    # Due to BAD_GAP_SCORE_OFFSET, these scores will always be higher than those of 'Bad Gaps'.\n    other_gap_mask = valid_potential_remaining_space >= SMALL_GAP_THRESHOLD\n    valid_priorities[other_gap_mask] = -valid_potential_remaining_space[other_gap_mask]\n\n    # Assign the calculated priorities back to the full 'priorities' array\n    # using the original mask for all bins that could fit the item.\n    priorities[can_fit_mask] = valid_priorities\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, implementing a variation of Best Fit.\n\n    This heuristic aims to select the bin that will have the least remaining capacity\n    after the item is placed, effectively trying to \"fill up\" a bin as much as possible.\n    Bins that cannot accommodate the item receive the lowest possible priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Scores are designed such that a perfect fit (remaining capacity = 0) gets the\n        highest possible score (0), while bins that cannot fit the item get -inf.\n    \"\"\"\n    # Calculate the remaining space in each bin if the item were placed.\n    # A smaller positive value here means a \"better fit\".\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. This ensures that\n    # any bin that cannot fit the item will never be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit (remaining space >= 0).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # For bins where the item can fit, assign a priority based on the negative\n    # of the potential remaining space.\n    # By maximizing this value, we are effectively minimizing the potential remaining space.\n    # A perfect fit (0 remaining space) will result in a priority of 0 (the highest).\n    # A larger remaining space (e.g., 0.5) will result in a lower priority (-0.5).\n    priorities[can_fit_mask] = -potential_remaining_space[can_fit_mask]\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item into each bin, implementing a\n    Best Fit with Strong Perfect Fit Preference and Inverse Waste Scoring.\n\n    This heuristic prioritizes bins with smallest remaining capacity,\n    strongly favoring perfect fits. For others, it uses inverse waste\n    scoring, penalizing larger gaps non-linearly. Combines robust\n    tight-fit with bin closure incentive.\n    \"\"\"\n    # Assuming bin capacity is normalized to 1.0. This simplifies thresholds.\n    # If actual capacities vary, a `bin_capacity` parameter would be needed.\n    BIN_CAPACITY = 1.0\n\n    # A small tolerance for floating-point comparisons to consider a fit \"perfect\"\n    PERFECT_FIT_TOLERANCE = 1e-6\n\n    # Smallest positive float for numerical stability, primarily to prevent division by zero.\n    EPSILON = np.finfo(float).eps\n\n    # A very high score assigned to perfect or near-perfect fits.\n    # This makes them unequivocally the most desirable choice, encouraging bin closure.\n    MAX_PRIORITY_SCORE = 1e12  # A large constant to ensure dominance of perfect fits\n\n    # Calculate the potential remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this value, ensuring they are never chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    # We allow a tiny negative remaining space due to floating-point precision.\n    can_fit_mask = potential_remaining_space >= -PERFECT_FIT_TOLERANCE\n\n    # Extract the potential remaining spaces only for bins where the item can fit.\n    fitting_potential_rem_space = potential_remaining_space[can_fit_mask]\n\n    # Initialize priorities for fitting bins.\n    fitting_priorities = np.zeros_like(fitting_potential_rem_space)\n\n    # Identify perfect or near-perfect fits based on the defined tolerance.\n    perfect_fit_mask = np.abs(fitting_potential_rem_space) <= PERFECT_FIT_TOLERANCE\n\n    # Assign the maximal priority score for perfect fits. This strongly encourages closing bins.\n    fitting_priorities[perfect_fit_mask] = MAX_PRIORITY_SCORE\n\n    # For bins that are not a perfect fit, apply an inverse waste scoring.\n    # This creates a strong non-linear preference for smaller remaining spaces (less waste).\n    # The smaller the remaining space, the higher the 1/waste score.\n    non_perfect_fit_mask = ~perfect_fit_mask\n    \n    # Calculate waste for inverse scoring. Since perfect_fit_mask handles near-zero,\n    # fitting_potential_rem_space[non_perfect_fit_mask] will be positive.\n    waste_for_inverse = fitting_potential_rem_space[non_perfect_fit_mask]\n\n    # Apply the inverse waste function. Adding EPSILON prevents division by zero for\n    # extremely small non-zero remaining capacities.\n    fitting_priorities[non_perfect_fit_mask] = 1 / (waste_for_inverse + EPSILON)\n\n    # Update the main priorities array with the scores for fitting bins.\n    priorities[can_fit_mask] = fitting_priorities\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid Best Fit: prioritizes tight fits, with a bonus for already-full bins.\n    Combines inverse waste minimization (Best Fit) with a proportional bonus for\n    the current fullness of a bin, encouraging efficient bin closure.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Epsilon for numerical stability, especially for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Primary Best Fit component: Inverse of (remaining_waste + epsilon).\n    # This gives disproportionately high scores to tighter fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap).\n    # It acts as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)\n\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence, acting as a tie-breaker\n    # or a mild preference for already-fuller bins with similar Best Fit scores.\n    alpha = 0.01  # Tunable parameter: Adjust based on desired balance.\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + alpha * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced. This hybrid approach\n    # aims for immediate efficiency (Best Fit) while adaptively guiding towards bin closure.\n    priorities[can_fit_mask] = best_fit_score * (1.0 + alpha * bin_fullness_score)\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Consolidation-Aware Best Fit: Prioritizes minimal waste (Best Fit) while subtly\n    favoring bins that are already fuller. This encourages faster bin closure\n    and more efficient bin consolidation, integrating adaptive logic.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): Remaining capacity in each bin. Assumes capacities\n                                      are normalized (e.g., max capacity of 1.0).\n\n    Returns:\n        np.ndarray: Priority scores for each bin. Bins unable to fit the item get -np.inf.\n    \"\"\"\n    # Initialize priorities to negative infinity, ensuring bins unable to fit\n    # the item are unequivocally disqualified.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining space (waste) in suitable bins after placing the item.\n    # A smaller waste indicates a more efficient, tighter fit.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the current fullness of bins that can fit the item.\n    # This assumes a maximum bin capacity of 1.0 for normalized problems.\n    # Higher fullness implies the bin is closer to being 'closed'.\n    current_fullness = 1.0 - bins_remain_cap[can_fit_mask]\n\n    # A small positive constant for numerical stability and to ensure a finite,\n    # very high priority for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Define a consolidation factor. This value is chosen to be small enough\n    # to ensure the primary Best Fit term (inverse waste) remains dominant,\n    # but large enough to provide a subtle preference among bins with\n    # very similar waste values. It acts as an adaptive consolidation incentive.\n    CONSOLIDATION_FACTOR = 0.1\n\n    # Primary score: Inverse of waste. This strongly rewards tight fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Secondary score: Bonus for current fullness. This nudges the selection\n    # towards bins that are already more filled, encouraging their closure.\n    consolidation_bonus = CONSOLIDATION_FACTOR * current_fullness\n\n    # Combine the scores. The Best Fit dominates, but bins closer to full\n    # receive a slight advantage, reflecting a more global optimization strategy.\n    priorities[can_fit_mask] = best_fit_score + consolidation_bonus\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines robust Best Fit (prioritizing minimal waste) with an adaptive, linear bias\n    towards selecting already fuller bins. This hybrid approach aims for both immediate\n    waste minimization and long-term bin consolidation for improved global utility.\n    \"\"\"\n    # Initialize all priorities to negative infinity, unequivocally marking bins\n    # that cannot accommodate the item as unavailable.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify which bins have sufficient capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return the initialized priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the potential remaining space (waste) if the item were placed in fit-capable bins.\n    potential_remaining_space = bins_remain_cap[can_fit_mask] - item\n\n    # Use a small epsilon for numerical stability, especially for perfect fits (waste = 0).\n    # This ensures perfect fits receive a very high, but finite, priority score.\n    epsilon = np.finfo(float).eps\n\n    # Core Best Fit Component: Assign priority as the inverse of (potential remaining space + epsilon).\n    # This strongly favors bins that result in minimal remaining space.\n    best_fit_scores = 1.0 / (potential_remaining_space + epsilon)\n\n    # Adaptive Consolidation Bias Component:\n    # Introduce a positive bias for bins that are already relatively full.\n    # This encourages packing into existing, more utilized bins, contributing to\n    # overall bin consolidation and reducing the number of bins used.\n    # We use the maximum remaining capacity among *all* bins as a dynamic reference\n    # for what an \"empty\" bin looks like in the current system state.\n    max_rem_cap = np.max(bins_remain_cap)\n\n    # Calculate the relative \"fullness\" of each fitting bin. A lower bins_remain_cap\n    # indicates a fuller bin, resulting in a higher fullness score (closer to 1).\n    # Add epsilon to denominator to prevent division by zero if max_rem_cap is 0 (e.g., all bins are full).\n    # In such a case, can_fit_mask would likely be all false unless item is 0.\n    relative_fullness = (max_rem_cap - bins_remain_cap[can_fit_mask]) / (max_rem_cap + epsilon)\n\n    # Define the weight of the consolidation bias. This is a tunable parameter.\n    # A small positive value ensures this bias influences decisions, especially\n    # when Best Fit scores are very close, without overpowering the primary\n    # waste minimization objective.\n    consolidation_bias_weight = 0.05\n\n    # Combine the Best Fit score with the adaptive consolidation bias.\n    # The bias is added to the Best Fit score, subtly promoting fuller bins.\n    priorities[can_fit_mask] = best_fit_scores + consolidation_bias_weight * relative_fullness\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid Best Fit: prioritizes tight fits, with a bonus for already-full bins.\n    Combines inverse waste minimization (Best Fit) with a proportional bonus for\n    the current fullness of a bin, encouraging efficient bin closure.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Epsilon for numerical stability, especially for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Primary Best Fit component: Inverse of (remaining_waste + epsilon).\n    # This gives disproportionately high scores to tighter fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap).\n    # It acts as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)\n\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence, acting as a tie-breaker\n    # or a mild preference for already-fuller bins with similar Best Fit scores.\n    alpha = 0.01  # Tunable parameter: Adjust based on desired balance.\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + alpha * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced. This hybrid approach\n    # aims for immediate efficiency (Best Fit) while adaptively guiding towards bin closure.\n    priorities[can_fit_mask] = best_fit_score * (1.0 + alpha * bin_fullness_score)\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid Best Fit: prioritizes tight fits, with a bonus for already-full bins.\n    Combines inverse waste minimization (Best Fit) with a proportional bonus for\n    the current fullness of a bin, encouraging efficient bin closure.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity (waste) if the item is placed.\n    remaining_waste = bins_remain_cap[can_fit_mask] - item\n\n    # Epsilon for numerical stability, especially for perfect fits (waste = 0).\n    epsilon = np.finfo(float).eps\n\n    # Primary Best Fit component: Inverse of (remaining_waste + epsilon).\n    # This gives disproportionately high scores to tighter fits.\n    best_fit_score = 1.0 / (remaining_waste + epsilon)\n\n    # Bin Fullness component: Inverse of (bins_remain_cap + epsilon).\n    # This term gives higher scores to bins that are already more full (smaller bins_remain_cap).\n    # It acts as a bias towards closing bins.\n    bin_fullness_score = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)\n\n    # Weighting factor for the bin fullness bonus.\n    # A small alpha ensures that the primary Best Fit (waste minimization) remains dominant,\n    # but the fullness component provides a subtle, adaptive influence, acting as a tie-breaker\n    # or a mild preference for already-fuller bins with similar Best Fit scores.\n    alpha = 0.01  # Tunable parameter: Adjust based on desired balance.\n\n    # Combine: Multiply the best-fit score by a factor that increases with bin fullness.\n    # The '1.0 + alpha * ...' ensures the base best_fit_score is always present\n    # and is only amplified by the fullness, not replaced. This hybrid approach\n    # aims for immediate efficiency (Best Fit) while adaptively guiding towards bin closure.\n    priorities[can_fit_mask] = best_fit_score * (1.0 + alpha * bin_fullness_score)\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority for placing an item in a bin, implementing a Best Fit\n    variation with an explicit penalty for creating very small, potentially\n    unusable gaps. This heuristic aims to anticipate future bin configurations\n    and improve global utility by reducing wasted small spaces.\n\n    This heuristic attempts to improve upon a simple Best Fit by:\n    1.  Prioritizing bins that result in a nearly full bin (standard Best Fit).\n    2.  Applying a significant penalty to bins that, after placing the item,\n        would be left with a very small remaining capacity (a \"small gap\").\n        Such small gaps are often too small to fit subsequent items,\n        leading to wasted space or the premature opening of new bins.\n        This moves beyond immediate greedy fits by considering the quality of\n        the residual bin state.\n    3.  Ensuring that perfect fits (where remaining capacity becomes exactly 0)\n        are always given the highest possible priority, as they represent\n        optimal utilization of a bin and do not create a \"small gap\" penalty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        A higher score indicates a higher priority for placing the item in that bin.\n        Bins that cannot accommodate the item receive the lowest possible priority (-np.inf).\n    \"\"\"\n    # Define what constitutes a \"small, potentially unusable gap\".\n    # This is a heuristic value, typically a small fraction of the bin's total capacity.\n    # Assuming bin capacity is normalized (e.g., 1.0), 0.05 implies gaps smaller than 5%\n    # of the bin's capacity are considered problematic. This anticipates future item placement.\n    SMALL_GAP_THRESHOLD = 0.05\n\n    # Define the penalty for creating a small gap.\n    # This value is crucial: it should be large enough to make a \"small gap fit\"\n    # less desirable than a \"suboptimal but non-small-gap fit\".\n    # For example, if a Best Fit leaves 0.01 (base priority -0.01) and a slightly\n    # worse fit leaves 0.1 (base priority -0.1), the penalty should push -0.01\n    # to be worse than -0.1 (e.g., -0.01 - 0.1 = -0.11, which is lower than -0.1).\n    SMALL_GAP_PENALTY = 0.1\n\n    # Calculate the remaining space in each bin if the item were placed.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Initialize all priorities to negative infinity. Bins that cannot fit the item\n    # will retain this lowest priority and will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit (remaining space is non-negative).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # For bins where the item can fit, calculate a base priority.\n    # This follows the Best Fit logic: a smaller positive remaining space\n    # (closer to a perfect fit) results in a higher (less negative) priority.\n    base_priorities = -potential_remaining_space[can_fit_mask]\n\n    # Identify bins among the \"can fit\" ones that would result in a \"small gap\".\n    # A small gap is one where the remaining space is positive but falls below the threshold.\n    # Perfect fits (potential_remaining_space == 0) are explicitly excluded from this penalty\n    # by the `> 0` condition, ensuring they retain their highest possible priority (0.0).\n    small_gap_mask = (potential_remaining_space[can_fit_mask] > 0) & \\\n                     (potential_remaining_space[can_fit_mask] < SMALL_GAP_THRESHOLD)\n\n    # Apply the defined penalty to the base priorities for bins that create small gaps.\n    # This negative adjustment makes these bins less attractive.\n    base_priorities[small_gap_mask] -= SMALL_GAP_PENALTY\n\n    # Assign the calculated priorities to the main priorities array for the bins that can fit.\n    priorities[can_fit_mask] = base_priorities\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit with strong preference for perfect fits.\n    Prioritizes bins inversely to remaining waste, ensuring numerical stability.\n    Leverages inverse waste to balance immediate tight fits with robustness for various item sizes.\n    \"\"\"\n    # Initialize all priorities to negative infinity, excluding bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space if the item were placed in fitting bins.\n    fitting_bins_current_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_current_cap - item\n\n    # Define constants for heuristic scoring.\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12 \n    # A small epsilon for numerical stability in inverse calculations, preventing division by zero.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # This inherently penalizes larger waste (including small fragments) by giving them disproportionately lower scores.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n    \n    # Calculate inverse of (waste + epsilon) for non-perfect fits.\n    # A smaller waste results in a higher priority.\n    inverse_waste_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = inverse_waste_scores\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by aggressively minimizing waste, with adaptive scores.\n\n    Explicitly awards perfect fits maximal priority, and for others,\n    uses a robust inverse-waste score to favor tight fits, anticipating\n    efficient bin closure and minimal fragmentation.\n    \"\"\"\n    # Initialize priorities for all bins to a very low value (-infinity).\n    # This ensures that any bin that cannot fit the item will have the lowest\n    # possible priority and will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Calculate the remaining space in each bin if the current item were placed there.\n    # A non-negative value means the item can fit; a negative value means it cannot.\n    potential_remaining_space = bins_remain_cap - item\n\n    # Create a boolean mask to identify only those bins that can actually\n    # accommodate the current item (remaining space must be non-negative).\n    can_fit_mask = potential_remaining_space >= 0\n\n    # Extract the potential remaining space only for the bins that can fit the item.\n    valid_potential_remaining_space = potential_remaining_space[can_fit_mask]\n\n    # Create masks to distinguish between perfect fits (waste = 0) and non-perfect fits (waste > 0).\n    perfect_fit_mask = (valid_potential_remaining_space == 0)\n    non_perfect_fit_mask = (valid_potential_remaining_space > 0)\n\n    # 1. Explicitly prioritize perfect fits with a very high, distinct score.\n    # This guarantees they are chosen over any other fit, promoting immediate bin closure\n    # and simplifying future packing decisions for that bin.\n    PERFECT_FIT_SCORE = 1e12\n\n    # Apply the perfect fit score to relevant bins through the nested masks.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a significantly higher priority score.\n    # np.finfo(float).eps provides robust numerical stability, giving very high\n    # scores for extremely tight fits (waste approaching zero) without division by zero.\n    TIGHT_FIT_EPSILON = np.finfo(float).eps\n\n    # Apply the inverse-waste priority score to non-perfect fit bins.\n    priorities[can_fit_mask][non_perfect_fit_mask] = \\\n        1.0 / (valid_potential_remaining_space[non_perfect_fit_mask] + TIGHT_FIT_EPSILON)\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Prioritizes bins using an adaptive Best Fit approach, emphasizing tight fits for\n    global utility and robustly handling edge cases for predictive packing.\n\n    This heuristic combines the effectiveness of inverse waste minimization with\n    adaptive numerical stability, aiming for bin configurations that enhance\n    future packing opportunities. It assigns the highest priority to perfect fits\n    and uses a non-linear inverse function for others, subtly scaled by bin\n    capacity to be problem-aware.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures bins that cannot fit\n    # the item are never chosen, providing a clear baseline for infeasible options.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed without exceeding capacity.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # Scaling by `bin_capacity` makes this score adaptive to the problem's scale,\n    # ensuring perfect fits are overwhelmingly dominant regardless of the bin size.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity # A large multiplier ensures dominance.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a higher priority. The `STABILITY_EPSILON` is\n    # dynamically scaled by `bin_capacity` to maintain numerical stability and\n    # problem-awareness across different bin scales (e.g., a tiny absolute waste\n    # in a large bin might be effectively 'zero'). This avoids explicit \"dead space\"\n    # penalties, letting the inverse relationship naturally de-prioritize larger wastes.\n    STABILITY_EPSILON = np.finfo(float).eps * bin_capacity \n    \n    # Ensure epsilon is not zero, especially for very small bin_capacity values if they could occur.\n    if STABILITY_EPSILON == 0.0:\n        STABILITY_EPSILON = np.finfo(float).eps \n\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit with strong preference for perfect fits.\n    Prioritizes bins inversely to remaining waste, ensuring numerical stability.\n    Leverages inverse waste to balance immediate tight fits with robustness for various item sizes.\n    \"\"\"\n    # Initialize all priorities to negative infinity, excluding bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space if the item were placed in fitting bins.\n    fitting_bins_current_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_current_cap - item\n\n    # Define constants for heuristic scoring.\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12 \n    # A small epsilon for numerical stability in inverse calculations, preventing division by zero.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # This inherently penalizes larger waste (including small fragments) by giving them disproportionately lower scores.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n    \n    # Calculate inverse of (waste + epsilon) for non-perfect fits.\n    # A smaller waste results in a higher priority.\n    inverse_waste_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = inverse_waste_scores\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Prioritizes bins using an adaptive Best Fit approach, emphasizing tight fits for\n    global utility and robustly handling edge cases for predictive packing.\n\n    This heuristic combines the effectiveness of inverse waste minimization with\n    adaptive numerical stability, aiming for bin configurations that enhance\n    future packing opportunities. It assigns the highest priority to perfect fits\n    and uses a non-linear inverse function for others, subtly scaled by bin\n    capacity to be problem-aware.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures bins that cannot fit\n    # the item are never chosen, providing a clear baseline for infeasible options.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed without exceeding capacity.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # Scaling by `bin_capacity` makes this score adaptive to the problem's scale,\n    # ensuring perfect fits are overwhelmingly dominant regardless of the bin size.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity # A large multiplier ensures dominance.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a higher priority. The `STABILITY_EPSILON` is\n    # dynamically scaled by `bin_capacity` to maintain numerical stability and\n    # problem-awareness across different bin scales (e.g., a tiny absolute waste\n    # in a large bin might be effectively 'zero'). This avoids explicit \"dead space\"\n    # penalties, letting the inverse relationship naturally de-prioritize larger wastes.\n    STABILITY_EPSILON = np.finfo(float).eps * bin_capacity \n    \n    # Ensure epsilon is not zero, especially for very small bin_capacity values if they could occur.\n    if STABILITY_EPSILON == 0.0:\n        STABILITY_EPSILON = np.finfo(float).eps \n\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Prioritizes bins using an adaptive Best Fit approach, emphasizing tight fits for\n    global utility and robustly handling edge cases for predictive packing.\n\n    This heuristic combines the effectiveness of inverse waste minimization with\n    adaptive numerical stability, aiming for bin configurations that enhance\n    future packing opportunities. It assigns the highest priority to perfect fits\n    and uses a non-linear inverse function for others, subtly scaled by bin\n    capacity to be problem-aware.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures bins that cannot fit\n    # the item are never chosen, providing a clear baseline for infeasible options.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed without exceeding capacity.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # Scaling by `bin_capacity` makes this score adaptive to the problem's scale,\n    # ensuring perfect fits are overwhelmingly dominant regardless of the bin size.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity # A large multiplier ensures dominance.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a higher priority. The `STABILITY_EPSILON` is\n    # dynamically scaled by `bin_capacity` to maintain numerical stability and\n    # problem-awareness across different bin scales (e.g., a tiny absolute waste\n    # in a large bin might be effectively 'zero'). This avoids explicit \"dead space\"\n    # penalties, letting the inverse relationship naturally de-prioritize larger wastes.\n    STABILITY_EPSILON = np.finfo(float).eps * bin_capacity \n    \n    # Ensure epsilon is not zero, especially for very small bin_capacity values if they could occur.\n    if STABILITY_EPSILON == 0.0:\n        STABILITY_EPSILON = np.finfo(float).eps \n\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit with strong preference for perfect fits.\n    Prioritizes bins inversely to remaining waste, ensuring numerical stability.\n    Leverages inverse waste to balance immediate tight fits with robustness for various item sizes.\n    \"\"\"\n    # Initialize all priorities to negative infinity, excluding bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space if the item were placed in fitting bins.\n    fitting_bins_current_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_current_cap - item\n\n    # Define constants for heuristic scoring.\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12 \n    # A small epsilon for numerical stability in inverse calculations, preventing division by zero.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # This inherently penalizes larger waste (including small fragments) by giving them disproportionately lower scores.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n    \n    # Calculate inverse of (waste + epsilon) for non-perfect fits.\n    # A smaller waste results in a higher priority.\n    inverse_waste_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = inverse_waste_scores\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit with strong preference for perfect fits.\n    Prioritizes bins inversely to remaining waste, ensuring numerical stability.\n    Leverages inverse waste to balance immediate tight fits with robustness for various item sizes.\n    \"\"\"\n    # Initialize all priorities to negative infinity, excluding bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space if the item were placed in fitting bins.\n    fitting_bins_current_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_current_cap - item\n\n    # Define constants for heuristic scoring.\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12 \n    # A small epsilon for numerical stability in inverse calculations, preventing division by zero.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # This inherently penalizes larger waste (including small fragments) by giving them disproportionately lower scores.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n    \n    # Calculate inverse of (waste + epsilon) for non-perfect fits.\n    # A smaller waste results in a higher priority.\n    inverse_waste_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = inverse_waste_scores\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit with strong preference for perfect fits.\n    Prioritizes bins inversely to remaining waste, ensuring numerical stability.\n    Leverages inverse waste to balance immediate tight fits with robustness for various item sizes.\n    \"\"\"\n    # Initialize all priorities to negative infinity, excluding bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually be placed.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the potential remaining space if the item were placed in fitting bins.\n    fitting_bins_current_cap = bins_remain_cap[can_fit_mask]\n    potential_remaining_space = fitting_bins_current_cap - item\n\n    # Define constants for heuristic scoring.\n    # A small tolerance for robust floating-point comparison to identify perfect fits.\n    PERFECT_FIT_TOLERANCE = 1e-9 * BIN_CAPACITY \n    # A very high score to ensure perfect fits are chosen over any other option.\n    PERFECT_FIT_SCORE = 1e12 \n    # A small epsilon for numerical stability in inverse calculations, preventing division by zero.\n    STABILITY_EPSILON = np.finfo(float).eps\n\n    # 1. Apply Perfect Fit Bonus: Identify and highly prioritize near-perfect fits.\n    perfect_fit_mask_in_fitting = np.abs(potential_remaining_space) < PERFECT_FIT_TOLERANCE\n    priorities[can_fit_mask][perfect_fit_mask_in_fitting] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # This inherently penalizes larger waste (including small fragments) by giving them disproportionately lower scores.\n    non_perfect_fit_mask_in_fitting = ~perfect_fit_mask_in_fitting\n    non_perfect_potential_rem = potential_remaining_space[non_perfect_fit_mask_in_fitting]\n    \n    # Calculate inverse of (waste + epsilon) for non-perfect fits.\n    # A smaller waste results in a higher priority.\n    inverse_waste_scores = 1.0 / (non_perfect_potential_rem + STABILITY_EPSILON)\n    priorities[can_fit_mask][non_perfect_fit_mask_in_fitting] = inverse_waste_scores\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Prioritizes bins using an adaptive Best Fit approach, emphasizing tight fits for\n    global utility and robustly handling edge cases for predictive packing.\n\n    This heuristic combines the effectiveness of inverse waste minimization with\n    adaptive numerical stability, aiming for bin configurations that enhance\n    future packing opportunities. It assigns the highest priority to perfect fits\n    and uses a non-linear inverse function for others, subtly scaled by bin\n    capacity to be problem-aware.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The total capacity of a single bin. Default is 1.0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to negative infinity. This ensures bins that cannot fit\n    # the item are never chosen, providing a clear baseline for infeasible options.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can be placed without exceeding capacity.\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the potential remaining capacity (waste) after placing the item\n    # for only those bins that can accommodate it.\n    potential_remain_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Separate valid bins into two categories: perfect fits and non-perfect fits (some waste).\n    perfect_fit_mask = (potential_remain_after_fit == 0)\n    non_perfect_fit_mask = (potential_remain_after_fit > 0)\n\n    # 1. Prioritize perfect fits with a very high, distinct finite score.\n    # Scaling by `bin_capacity` makes this score adaptive to the problem's scale,\n    # ensuring perfect fits are overwhelmingly dominant regardless of the bin size.\n    PERFECT_FIT_SCORE = 1e6 * bin_capacity # A large multiplier ensures dominance.\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. For non-perfect fits, prioritize inversely to the remaining waste.\n    # A smaller waste results in a higher priority. The `STABILITY_EPSILON` is\n    # dynamically scaled by `bin_capacity` to maintain numerical stability and\n    # problem-awareness across different bin scales (e.g., a tiny absolute waste\n    # in a large bin might be effectively 'zero'). This avoids explicit \"dead space\"\n    # penalties, letting the inverse relationship naturally de-prioritize larger wastes.\n    STABILITY_EPSILON = np.finfo(float).eps * bin_capacity \n    \n    # Ensure epsilon is not zero, especially for very small bin_capacity values if they could occur.\n    if STABILITY_EPSILON == 0.0:\n        STABILITY_EPSILON = np.finfo(float).eps \n\n    priorities[can_fit_mask][non_perfect_fit_mask] = 1.0 / (potential_remain_after_fit[non_perfect_fit_mask] + STABILITY_EPSILON)\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}