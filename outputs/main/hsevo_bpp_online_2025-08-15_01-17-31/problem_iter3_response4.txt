```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    
    suitable_bins_mask = bins_remain_cap >= item
    
    if np.any(suitable_bins_mask):
        suitable_bins_cap = bins_remain_cap[suitable_bins_mask]
        
        # --- Heuristic Improvement ---
        # Instead of just finding the best fit, we'll introduce a tunable parameter
        # and consider the "goodness" of a fit based on how much capacity is left.
        # A smaller remaining capacity (closer to the item size) is generally better,
        # but we also don't want to create too many bins with very little remaining space
        # if a slightly larger bin offers more flexibility for future items.
        
        # Calculate the "waste" for suitable bins
        waste = suitable_bins_cap - item
        
        # We want to prioritize bins with less waste.
        # Let's define a priority score that inversely relates to waste, but with a twist.
        # A common approach is to use something like 1 / (1 + waste) or similar.
        # Here, let's try to give a higher score to bins that are "tight" fits,
        # but also give a slight boost to bins that have a moderate amount of space
        # to allow for future item packing.
        
        # Normalize waste to a 0-1 range for smoother scaling if needed, or use directly.
        # For simplicity, we'll use a function that rewards smaller waste.
        # Let's try a score that is high when waste is low, and decreases as waste increases.
        # A possible function could be exp(-k * waste) where k is a parameter.
        # Or a simpler inverse relation.
        
        # Let's consider a combination: prioritize tight fits (low waste) but don't
        # completely ignore bins with slightly more space if they are "good enough".
        
        # Simple approach: Inverse of waste + small penalty for very large remaining capacity
        # This encourages tight fits but avoids extremely tight fits that might be too restrictive.
        
        # A more adaptive idea (conceptual):
        # If we have many items, we might want tighter fits to conserve bins.
        # If we have few items, we might want slightly more room to accommodate potential larger items.
        # This requires state tracking beyond just remaining capacities, which is beyond a simple function.
        
        # For this function, let's refine the "best fit" idea by adding a small bonus
        # for bins that are not *too* empty. This is a heuristic modification to avoid
        # creating many bins with almost no remaining capacity.
        
        # Consider the inverse of waste as a primary score component.
        # A small epsilon to avoid division by zero if waste can be zero.
        epsilon = 1e-9
        primary_score = 1.0 / (waste + epsilon)
        
        # Add a secondary component that penalizes bins with a lot of remaining capacity.
        # This component should be smaller than the primary score.
        # We can cap the remaining capacity to avoid extreme values.
        max_capacity = np.max(bins_remain_cap) # Or a predefined bin capacity
        capped_remain_cap = np.minimum(suitable_bins_cap, max_capacity)
        
        # A simple penalty that decreases as remaining capacity increases.
        # We want to slightly *down-weight* bins with a lot of empty space.
        # Let's make it such that larger remaining capacity gives a lower score modifier.
        secondary_score_modifier = 1.0 / (1.0 + capped_remain_cap / (max_capacity + epsilon))
        
        # Combine scores. The primary score (related to waste) should dominate.
        # A simple weighted sum or multiplicative approach.
        # Let's try to slightly boost bins with *some* remaining capacity, but not too much.
        # This is tricky without more context.
        
        # Let's go back to the core idea of best-fit but add a second criterion.
        # Priority 1: Tightest fit (smallest waste)
        # Priority 2: If multiple bins have the same tightest fit, pick the one with
        #             more remaining capacity to allow for future items.
        # This is a "Best Fit Decreasing" variation, but applied online.
        
        min_waste = np.min(waste)
        best_fit_indices_in_suitable = np.where(waste == min_waste)[0]
        
        if len(best_fit_indices_in_suitable) == 1:
            # Only one best fit, assign high priority
            priorities[np.where(suitable_bins_mask)[0][best_fit_indices_in_suitable[0]]] = 1.0
        else:
            # Multiple bins have the same minimal waste.
            # Among these, pick the one with the largest remaining capacity.
            candidate_bins_cap = suitable_bins_cap[best_fit_indices_in_suitable]
            max_remaining_cap_among_best_fit = np.max(candidate_bins_cap)
            
            indices_with_max_cap = np.where(candidate_bins_cap == max_remaining_cap_among_best_fit)[0]
            
            # Get the original indices in bins_remain_cap
            original_indices_of_best_fits = np.where(suitable_bins_mask)[0][best_fit_indices_in_suitable]
            
            # Assign priority to the chosen bin(s)
            chosen_indices = original_indices_of_best_fits[indices_with_max_cap]
            
            # Give a higher priority to these bins
            priorities[chosen_indices] = 1.0
            
            # For all other suitable bins that were not the absolute best fit, assign a lower priority.
            # This ensures the "best" ones are strongly preferred.
            all_suitable_original_indices = np.where(suitable_bins_mask)[0]
            non_best_fit_suitable_indices = np.setdiff1d(all_suitable_original_indices, chosen_indices)
            
            # Assign a secondary priority to other suitable bins.
            # The value should be less than 1.0 to distinguish them.
            # Let's assign a priority based on their "goodness" but lower than the top tier.
            
            other_suitable_indices_mask = np.isin(all_suitable_original_indices, non_best_fit_suitable_indices)
            other_suitable_bins_cap = suitable_bins_cap[other_suitable_indices_mask]
            other_waste = other_suitable_bins_cap - item
            
            # A score that is lower than the primary score for best fits.
            # Using a scaled inverse of waste.
            secondary_priorities = 0.5 * (1.0 / (other_waste + epsilon))
            
            # Normalize these secondary priorities to be less than 1.0 but still comparable.
            # For simplicity, let's just assign a fixed lower value or a scaled value.
            # A simple approach is to assign a value between 0 and 0.9.
            # Let's use a scaled version of their fitness, but capped.
            max_secondary_score_val = np.max(secondary_priorities)
            if max_secondary_score_val > 0:
                normalized_secondary_priorities = 0.8 * (secondary_priorities / max_secondary_score_val)
            else:
                normalized_secondary_priorities = np.zeros_like(secondary_priorities)
            
            priorities[non_best_fit_suitable_indices] = normalized_secondary_priorities

    return priorities
```
