{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines strong Best Fit with an adaptive, smoothed penalty based on capacity-to-item ratio.\n    Prioritizes tight fits while gracefully penalizing bins with disproportionately large remaining space.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Consider only bins that can fit the item\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    if valid_bins_remain_cap.size > 0:\n        # Calculate the remaining capacity after placing the item\n        remaining_after_fit = valid_bins_remain_cap - item\n        \n        # Best Fit component: prioritize smaller gaps (higher score for smaller gaps).\n        # Add epsilon for numerical stability.\n        best_fit_scores = 1.0 / (remaining_after_fit + 1e-9)\n        \n        # Adaptive Penalty component: Penalize based on the ratio of remaining space to the item size.\n        # A higher ratio (more wasted space relative to the item) gets a higher penalty (lower priority).\n        # Using a sigmoid-like function to smoothly increase the penalty as the ratio exceeds a threshold.\n        # This provides a more nuanced penalty than a simple logarithmic function.\n        penalty_threshold_ratio = 1.5 # Ratio where penalty starts to increase significantly\n        penalty_steepness = 0.8 # Controls how quickly the penalty increases\n        \n        # Calculate penalty: sigmoid function ensures values between 0 and 1.\n        # Penalty is high when capacity/item ratio is much larger than threshold.\n        # Add epsilon to item in denominator to prevent division by zero for zero-sized items.\n        capacity_ratio = valid_bins_remain_cap / (item + 1e-9)\n        penalty = 1.0 / (1.0 + np.exp(-penalty_steepness * (capacity_ratio - penalty_threshold_ratio)))\n        \n        # Combine Best Fit score with penalty (subtract penalty from score)\n        combined_scores = best_fit_scores - penalty\n        \n        # Normalize the combined scores to be between 0 and 1.\n        # This makes scores comparable across different item/bin configurations and ensures positive priorities.\n        min_score = np.min(combined_scores)\n        max_score = np.max(combined_scores)\n        \n        if max_score > min_score:\n            normalized_scores = (combined_scores - min_score) / (max_score - min_score)\n        else:\n            # If all valid bins have the same combined score, assign a uniform medium priority\n            normalized_scores = np.full_like(combined_scores, 0.5)\n            \n        # Assign the calculated priorities back to the original indices\n        original_indices = np.where(can_fit_mask)[0]\n        priorities[original_indices] = normalized_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if np.any(suitable_bins_mask):\n        suitable_bins_cap = bins_remain_cap[suitable_bins_mask]\n        \n        # Best Fit Component: Prioritize bins that leave the least remaining space\n        best_fit_diff = suitable_bins_cap - item\n        min_diff = np.min(best_fit_diff)\n        best_fit_scores = np.exp(-best_fit_diff / (np.mean(bins_remain_cap) + 1e-6)) # Exponential decay, scaled by average remaining capacity\n        \n        # First Fit Component (implicitly handled by order but can be boosted): Prioritize bins that are used earlier\n        # For online, earlier bins are those with lower indices. We can use inverse index for priority.\n        original_indices = np.where(suitable_bins_mask)[0]\n        first_fit_scores = 1.0 / (original_indices + 1.0) \n        \n        # Combine components with adaptive weighting\n        # Weighting can be adaptive based on the distribution of remaining capacities.\n        # If capacities are very spread out, Best Fit might be more important.\n        # If capacities are similar, First Fit might help with fragmentation.\n        \n        capacity_std = np.std(bins_remain_cap)\n        capacity_mean = np.mean(bins_remain_cap)\n        \n        # Heuristic weighting: more weight to first fit if std is low (bins are similar)\n        # more weight to best fit if std is high (bins are diverse)\n        ff_weight = np.exp(-capacity_std / (capacity_mean + 1e-6)) \n        bf_weight = 1.0 - ff_weight\n        \n        combined_scores = bf_weight * best_fit_scores + ff_weight * first_fit_scores\n        \n        # Normalize scores to be between 0 and 1\n        if np.max(combined_scores) > 0:\n            normalized_scores = combined_scores / np.max(combined_scores)\n        else:\n            normalized_scores = combined_scores # Should not happen if suitable bins exist\n\n        # Assign priorities to the original indices\n        priorities[original_indices] = normalized_scores\n        \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1-2 (identical) vs. Heuristics 4-6 (identical): Heuristics 1-2 use a weighted combination of normalized differences and capacities, while 4-6 implement a strict Best Fit by picking the minimum difference. Heuristics 1-2 are more nuanced by considering the overall bin capacity, potentially leading to better packing density.\n\nComparing Heuristics 3 & 5-6 (identical) vs. Heuristics 7-9 & 13-15 & 18-19 (identical): Heuristics 3, 5-6 use a sigmoid-based penalty for remaining capacity in conjunction with Best Fit. Heuristics 7-9, 13-15, 18-19 use a similar concept but with different formulations (sigmoid vs. log) and parameters. Heuristic 7, in particular, introduces an adaptive penalty based on the capacity-to-item ratio, which is more dynamic than a fixed sigmoid. The ranking suggests that the specific implementation of these combined strategies matters.\n\nComparing Heuristics 7 vs. 10-12 vs. 20: Heuristics 10-12 and 20 refine the Best Fit with penalties, with 10-12 using a sigmoid-like penalty and 20 adding an overall capacity bias. Heuristic 7 uses a sigmoid-like penalty but on the capacity-to-item ratio, which might be more robust than penalizing raw remaining capacity directly. Heuristic 20's explicit addition of a capacity bias might lead to over-optimization for specific scenarios.\n\nComparing Heuristics 16-17 (identical) vs. others: Heuristics 16-17 combine Best Fit and First Fit with adaptive weights based on capacity standard deviation. This is a novel approach that attempts to balance tightness and fragmentation. However, their lower ranking suggests this adaptive weighting might not always be superior or is perhaps less effectively implemented than the refined Best Fit with penalties.\n\nComparing Heuristics 13-15 & 18-19 (identical) vs. Heuristics 8-9 (identical): Heuristics 13-15 and 18-19 seem to be incomplete versions of the strategy in Heuristics 8-9, which implement Best Fit with a logarithmic penalty. The absence of the actual calculation in the former makes them worse.\n\nOverall: The best heuristics (1-3, 7, 10-12, 16-17, 20) generally combine a strong Best Fit component with some form of penalty or score for remaining capacity, often using sigmoid or logarithmic functions for smooth adjustments. Normalization and adaptive weighting (like in 7, 10-12, 16-17) appear to be key for robust performance. Strict Best Fit (4-6) and incomplete implementations are worst.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Adaptive penalties, multi-objective optimization, normalization, weighting, stability, generalization.\n\n*   **Advice:** Design heuristics that balance multiple, potentially conflicting objectives (e.g., fit tightness, bin fullness, minimizing bin usage) using adaptive penalty functions and robust normalization techniques. Focus on creating a composite score that generalizes well across diverse problem instances.\n\n*   **Avoid:** Purely \"greedy\" single-metric optimization (like minimizing only the remaining gap), overly aggressive or linear penalty functions, additive combinations of unnormalized scores, and hardcoded parameters without considering numerical stability or generalization.\n\n*   **Explanation:** By integrating adaptive penalties and normalization, heuristics become more resilient and less susceptible to overfitting on specific data distributions. This allows for a more nuanced trade-off between objectives, leading to better overall performance and broader applicability, rather than relying on simple, potentially brittle, single-criterion decisions.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}