```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit's precision with an adaptive logarithmic penalty.
    Prioritizes tight fits while smoothly penalizing underfilled bins,
    using ratio-based penalty and normalization for robust scoring.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf)
    suitable_bins_mask = bins_remain_cap >= item

    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]
    gaps = suitable_bins_caps - item

    # Best Fit Score: Inverted gap to favor smaller gaps. Add epsilon for numerical stability.
    best_fit_score = 1.0 / (gaps + 1e-6)

    # Adaptive Logarithmic Penalty: Penalizes bins with significantly more remaining capacity
    # than the item size, using a logarithmic scale for smoothness.
    # The penalty is proportional to log(remaining_capacity / item_size).
    # A small epsilon added to item size prevents division by zero.
    # A penalty_factor controls the impact of this penalty.
    penalty_factor = 0.15 # Slightly increased penalty factor for more influence
    capacity_ratio = suitable_bins_caps / (item + 1e-9)
    excess_capacity_penalty = penalty_factor * np.log1p(capacity_ratio)

    # Combined Score: Subtract the penalty from the best-fit score.
    # Higher scores indicate more preferred bins.
    combined_scores = best_fit_scores - excess_capacity_penalty

    # Normalization: Scale scores to a [0, 1] range for consistent comparison.
    min_score = np.min(combined_scores)
    max_score = np.max(combined_scores)
    if max_score > min_score:
        normalized_scores = (combined_scores - min_score) / (max_score - min_score)
    else:
        # If all scores are the same, assign a neutral score (e.g., 0.5)
        normalized_scores = np.ones_like(combined_scores) * 0.5

    priorities[suitable_bins_mask] = normalized_scores

    return priorities
```
