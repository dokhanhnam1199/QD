{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a normalized, sigmoid-based penalty for remaining capacity.\n    Prioritizes tight fits while smoothly penalizing bins with excessive empty space.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n    penalty_strength = 5.0 # Tune this parameter to control penalty intensity\n\n    can_fit_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    if valid_bins_remain_cap.size > 0:\n        remaining_after_fit = valid_bins_remain_cap - item\n        \n        # Best Fit score: inverse of the remaining space for tighter fits\n        best_fit_scores = 1.0 / (remaining_after_fit + epsilon)\n        \n        # Sigmoid-based penalty: Penalizes large remaining capacities smoothly.\n        # Scales the remaining capacity relative to the item size and bin capacity (implicitly)\n        # The sigmoid function ensures the penalty grows but saturates.\n        normalized_remaining = remaining_after_fit / np.maximum(bins_remain_cap[can_fit_mask], epsilon)\n        penalty_scores = 1.0 / (1.0 + np.exp(penalty_strength * (1.0 - normalized_remaining))) # Penalizes larger remaining space\n        \n        # Combine Best Fit with penalty: subtract penalty from the score\n        combined_priorities = best_fit_scores - penalty_scores\n        \n        # Normalize combined priorities to [0, 1] for consistent comparison\n        min_p, max_p = np.min(combined_priorities), np.max(combined_priorities)\n        if max_p > min_p:\n            normalized_priorities = (combined_priorities - min_p) / (max_p - min_p)\n        else:\n            normalized_priorities = np.ones_like(combined_priorities) * 0.5 # All scores are same\n            \n        original_indices = np.where(can_fit_mask)[0]\n        priorities[original_indices] = normalized_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a calibrated logarithmic penalty for excessive remaining capacity,\n    favoring bins that offer a tight fit while moderately penalizing large unused space.\n    Also incorporates a slight bias towards bins with less remaining capacity overall.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    gaps = suitable_bins_caps - item\n\n    # Best Fit Score: Higher for smaller gaps (tighter fit). Add epsilon for stability.\n    best_fit_score = 1.0 / (gaps + 1e-6)\n\n    # Calibrated Logarithmic Penalty: Penalizes large gaps more significantly but smoothly.\n    # The penalty increases logarithmically with the gap size.\n    penalty_factor = 0.1\n    excess_capacity_penalty = penalty_factor * np.log1p(gaps)\n\n    # Additional heuristic: Favor bins with less remaining capacity overall (less waste)\n    # This is a simple additive term that slightly boosts bins with less overall capacity.\n    # Normalizing this to be on a similar scale as the best_fit_score.\n    # We subtract it to prefer smaller remaining capacities.\n    # Avoid division by zero by adding a small epsilon.\n    overall_capacity_bias = 1.0 / (suitable_bins_caps + 1e-6)\n    normalized_capacity_bias = (overall_capacity_bias - np.min(overall_capacity_bias)) / (np.max(overall_capacity_bias) - np.min(overall_capacity_bias) + 1e-9)\n\n\n    # Combine scores: Subtract the penalty from the best-fit score, and also subtract the bias for larger capacities.\n    combined_priorities = best_fit_score - excess_capacity_penalty - normalized_capacity_bias * 0.2 # Adjust weight for bias\n\n    # Normalize priorities to be between 0 and 1 for consistent behavior\n    min_priority = np.min(combined_priorities)\n    max_priority = np.max(combined_priorities)\n    if max_priority > min_priority:\n        normalized_priorities = (combined_priorities - min_priority) / (max_priority - min_priority)\n    else:\n        normalized_priorities = np.ones_like(combined_priorities) * 0.5 # Default if all scores are same\n\n    priorities[suitable_bins_mask] = normalized_priorities\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1-2 (identical) vs. Heuristics 4-6 (identical): Heuristics 1-2 use a weighted combination of normalized differences and capacities, while 4-6 implement a strict Best Fit by picking the minimum difference. Heuristics 1-2 are more nuanced by considering the overall bin capacity, potentially leading to better packing density.\n\nComparing Heuristics 3 & 5-6 (identical) vs. Heuristics 7-9 & 13-15 & 18-19 (identical): Heuristics 3, 5-6 use a sigmoid-based penalty for remaining capacity in conjunction with Best Fit. Heuristics 7-9, 13-15, 18-19 use a similar concept but with different formulations (sigmoid vs. log) and parameters. Heuristic 7, in particular, introduces an adaptive penalty based on the capacity-to-item ratio, which is more dynamic than a fixed sigmoid. The ranking suggests that the specific implementation of these combined strategies matters.\n\nComparing Heuristics 7 vs. 10-12 vs. 20: Heuristics 10-12 and 20 refine the Best Fit with penalties, with 10-12 using a sigmoid-like penalty and 20 adding an overall capacity bias. Heuristic 7 uses a sigmoid-like penalty but on the capacity-to-item ratio, which might be more robust than penalizing raw remaining capacity directly. Heuristic 20's explicit addition of a capacity bias might lead to over-optimization for specific scenarios.\n\nComparing Heuristics 16-17 (identical) vs. others: Heuristics 16-17 combine Best Fit and First Fit with adaptive weights based on capacity standard deviation. This is a novel approach that attempts to balance tightness and fragmentation. However, their lower ranking suggests this adaptive weighting might not always be superior or is perhaps less effectively implemented than the refined Best Fit with penalties.\n\nComparing Heuristics 13-15 & 18-19 (identical) vs. Heuristics 8-9 (identical): Heuristics 13-15 and 18-19 seem to be incomplete versions of the strategy in Heuristics 8-9, which implement Best Fit with a logarithmic penalty. The absence of the actual calculation in the former makes them worse.\n\nOverall: The best heuristics (1-3, 7, 10-12, 16-17, 20) generally combine a strong Best Fit component with some form of penalty or score for remaining capacity, often using sigmoid or logarithmic functions for smooth adjustments. Normalization and adaptive weighting (like in 7, 10-12, 16-17) appear to be key for robust performance. Strict Best Fit (4-6) and incomplete implementations are worst.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Adaptive penalties, multi-objective optimization, normalization, weighting, stability, generalization.\n\n*   **Advice:** Design heuristics that balance multiple, potentially conflicting objectives (e.g., fit tightness, bin fullness, minimizing bin usage) using adaptive penalty functions and robust normalization techniques. Focus on creating a composite score that generalizes well across diverse problem instances.\n\n*   **Avoid:** Purely \"greedy\" single-metric optimization (like minimizing only the remaining gap), overly aggressive or linear penalty functions, additive combinations of unnormalized scores, and hardcoded parameters without considering numerical stability or generalization.\n\n*   **Explanation:** By integrating adaptive penalties and normalization, heuristics become more resilient and less susceptible to overfitting on specific data distributions. This allows for a more nuanced trade-off between objectives, leading to better overall performance and broader applicability, rather than relying on simple, potentially brittle, single-criterion decisions.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}