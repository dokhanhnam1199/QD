{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if np.any(suitable_bins_mask):\n        suitable_bins_cap = bins_remain_cap[suitable_bins_mask]\n        \n        # Calculate the \"wasted space\" for each suitable bin\n        wasted_space = suitable_bins_cap - item\n        \n        # Calculate the inverse of wasted space to prioritize bins with less wasted space\n        # Add a small epsilon to avoid division by zero if wasted_space is 0\n        inverse_wasted_space = 1.0 / (wasted_space + 1e-9)\n        \n        # Normalize these scores to be between 0 and 1\n        if np.max(inverse_wasted_space) > 0:\n            normalized_scores = inverse_wasted_space / np.max(inverse_wasted_space)\n        else:\n            normalized_scores = np.zeros_like(inverse_wasted_space)\n            \n        # Assign these normalized scores to the corresponding original indices\n        original_indices = np.where(suitable_bins_mask)[0]\n        priorities[original_indices] = normalized_scores\n        \n        # Additionally, give a slight bonus to bins that are almost full (closer to bin capacity)\n        # This encourages fuller bins, which can be beneficial in some scenarios\n        fullness_score = (suitable_bins_cap - item) / suitable_bins_cap if np.any(suitable_bins_cap > 0) else np.zeros_like(suitable_bins_cap)\n        fullness_score = 1.0 - fullness_score # Higher score for fuller bins\n        \n        # Combine the two scores (e.g., weighted average)\n        # For simplicity, we'll just add them, giving more weight to the inverse_wasted_space score\n        # You might want to tune these weights or use a more sophisticated combination\n        combined_scores = normalized_scores + 0.2 * fullness_score\n        \n        # Re-normalize the combined scores\n        if np.max(combined_scores) > 0:\n            final_priorities = combined_scores / np.max(combined_scores)\n        else:\n            final_priorities = np.zeros_like(combined_scores)\n            \n        priorities[original_indices] = final_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a penalty for overly large remaining capacity.\n    Prioritizes bins with minimal remaining space after packing, but penalizes\n    bins that would leave excessive space, promoting balanced utilization.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    can_fit_mask = bins_remain_cap >= item\n    \n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    if valid_bins_remain_cap.size > 0:\n        # Calculate the remaining capacity after placing the item\n        remaining_after_fit = valid_bins_remain_cap - item\n        \n        # Best Fit component: prioritize smaller remaining space\n        # Use inverse of remaining space for higher scores for tighter fits.\n        epsilon = 1e-9\n        best_fit_scores = 1.0 / (remaining_after_fit + epsilon)\n        \n        # Introduce a penalty for leaving too much space (less than \"good enough\" fit)\n        # This component aims to avoid \"overly empty\" bins, promoting better overall distribution.\n        # We can use a sigmoid-like penalty: larger remaining_after_fit leads to a smaller score.\n        # Let's define a threshold for \"too much\" space, e.g., 30% of item size, or a fixed value.\n        # A simple approach is to scale the best_fit_scores down if remaining_after_fit is large.\n        \n        # Let's use a penalty that reduces the priority if remaining_after_fit is large.\n        # A linear penalty might be simple: score = best_fit_score * (1 - alpha * remaining_after_fit)\n        # Or, a capping mechanism: if remaining_after_fit > threshold, reduce score significantly.\n        \n        # Consider a strategy where we want bins that leave very little space,\n        # but also don't want bins that are *almost* empty after packing.\n        # The previous '1 / (remaining_after_fit + epsilon)' strongly favors very small gaps.\n        \n        # Let's refine the 'Best Fit' idea by adding a secondary objective:\n        # prefer bins that become 'moderately' full rather than 'almost completely' full\n        # IF there's a choice between a perfect fit and a slightly less perfect fit that still leaves\n        # a reasonable amount of space. This is tricky in online BPP.\n        \n        # A common strategy is to favor bins that are \"nearly full\" without being *too* full.\n        # The 'Best Fit' strategy by itself already does this by minimizing residual space.\n        \n        # Let's enhance the 'Best Fit' by considering the *original* bin capacity.\n        # Prioritize bins where (remaining_after_fit / original_bin_capacity) is minimized.\n        # This is essentially Best Fit Normalized.\n        \n        # Let's try a hybrid:\n        # 1. Base priority: 1.0 / (remaining_after_fit + epsilon) (Best Fit)\n        # 2. Add a penalty if remaining_after_fit is *too large* relative to the item size.\n        #    This prevents selecting a large bin for a small item just because it's the smallest available.\n        \n        # Let's define a \"good fit\" target, which is a small positive remaining capacity.\n        # We want to reward bins where remaining_after_fit is close to zero.\n        # Let's cap the penalty.\n        \n        # Example:\n        # Item = 0.4, Bins: [0.5, 0.6, 1.0]\n        # Remaining after fit: [0.1, 0.2, 0.6]\n        # Best fit scores: [10, 5, 1.67]\n        \n        # If we want to penalize leaving a lot of space (e.g., 0.6), we could do:\n        # If remaining_after_fit > K * item:\n        #   priority *= penalty_factor (e.g., 0.5)\n        \n        penalty_threshold_factor = 0.5 # Penalize if remaining space is more than 50% of item size\n        penalty_factor = 0.7 # Reduce priority by 30%\n        \n        penalty_mask = remaining_after_fit > (penalty_threshold_factor * item)\n        \n        # Apply the base best fit scores\n        combined_priorities = best_fit_scores.copy()\n        \n        # Apply penalty to bins that leave too much space\n        combined_priorities[penalty_mask] *= penalty_factor\n        \n        priorities[can_fit_mask] = combined_priorities\n    \n    return priorities\n\n### Analyze & experience\n- *   **Comparing (1st) vs (2nd):** Heuristic 1 uses a simple average of 'best fit' and 'slack' scores, aiming to balance immediate fit with fuller bins. Heuristic 2 combines 'best fit' with an 'almost full' boost, prioritizing very tight fits. Heuristic 1's approach seems more balanced by explicitly considering slack.\n*   **Comparing (2nd) vs (3rd):** Heuristic 2 is identical to Heuristic 1, but with different internal calculation names and a slightly different combination logic (addition vs. averaging). Heuristic 3 is identical to Heuristic 1. There seems to be a misunderstanding in the ranking or code provided, as 1, 2, and 3 are very similar. However, focusing on the *intended* logic of Heuristic 2 (adding `almost_full_boost`), it might overemphasize \"almost full\" bins compared to the balanced approach of Heuristic 1/3.\n*   **Comparing (3rd) vs (4th):** Heuristic 3 (and 1) uses a scoring system based on inverse capacities. Heuristic 4 implements a pure \"Best Fit\" by assigning a priority of 1.0 to bins with the minimum gap, and 0 otherwise. Heuristic 3's nuanced scoring is generally better than a binary Best Fit, as it allows for finer selection among good fits.\n*   **Comparing (4th) vs (5th):** Heuristic 4 is pure Best Fit. Heuristic 5 attempts to normalize Best Fit scores and add a \"fullness\" score, but the combination (addition) and re-normalization might lead to unintended weighting. Heuristic 4's simplicity and directness of Best Fit might be more robust than Heuristic 5's complex normalization and combination.\n*   **Comparing (5th) vs (6th):** Heuristic 5 attempts normalization and a weighted combination. Heuristic 6 is identical to Heuristic 4 (pure Best Fit). This reinforces that Heuristic 4 (pure Best Fit) is likely superior to Heuristic 5's complicated approach.\n*   **Comparing (7th) and (11th/12th/13th):** Heuristic 7 proposes a score of `(1.0 / gaps) - bins_that_can_fit_caps`. This attempts to combine Best Fit with a penalty for large bin capacity, which can be good. However, the direct subtraction might lead to negative priorities where the penalty outweighs the Best Fit score, making interpretation and comparison difficult. Heuristics 11-13 implement a similar idea with a conditional penalty for \"too much\" remaining space. This conditional penalty (Heuristics 11-13) is a more controlled way to handle the \"overly large remaining capacity\" issue than Heuristic 7's direct subtraction.\n*   **Comparing (8th) vs (2nd):** Heuristic 8 is identical to Heuristic 2.\n*   **Comparing (9th) vs (1st):** Heuristic 9 weights 'waste reduction' (similar to Best Fit) and 'capacity utilization' (inverse of remaining capacity). This is a reasonable hybrid. Heuristic 1 averages these concepts. Heuristic 9's weighted approach might offer better control than Heuristic 1's simple average.\n*   **Comparing (10th) vs (1st):** Heuristic 10 combines Best Fit with a factor that *reduces* priority for bins with *more* remaining capacity. This aims to penalize lightly used bins. Heuristic 1's \"slack score\" (inverse of remaining capacity) also favors fuller bins. Heuristic 10's multiplicative approach might be more effective at modulating Best Fit scores.\n*   **Comparing (14th-20th) vs (4th):** Heuristics 14-20 are identical. They combine a normalized Best Fit score with an exponential penalty for \"very empty\" bins based on a capacity ratio. This is a sophisticated approach that balances tight fits with avoiding overly empty bins. It's more nuanced than pure Best Fit (Heuristic 4).\n\nOverall: The top heuristics (1-3, 8-10) attempt to combine Best Fit with a secondary objective like favoring fuller bins or penalizing under-utilized bins using additive or multiplicative factors. Heuristics 14-20 represent a more refined version of this by using a normalized Best Fit score combined with an adaptive penalty. Heuristics 7 and 11-13 try to penalize large remaining capacities, but the implementation in 7 is problematic, while 11-13 are better. Pure Best Fit (4, 6) is simpler but less adaptive.\n- \nHere's a redefined self-reflection for designing better heuristics, focusing on actionable insights:\n\n*   **Keywords:** Hybrid heuristics, weighted combination, conditional logic, penalty mechanisms.\n*   **Advice:** Design hybrid heuristics that dynamically adjust their criteria. Explore conditional logic to switch between primary and secondary metrics based on the problem state (e.g., bin fullness).\n*   **Avoid:** Over-reliance on a single, static metric (like inverse of remaining gap) as it can be brittle. Avoid overly complex multiplicative combinations that are hard to tune.\n*   **Explanation:** Pure \"best fit\" is often suboptimal. Combining metrics thoughtfully, perhaps by penalizing certain outcomes or prioritizing states, leads to more robust and adaptable heuristics that can better navigate diverse problem instances.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}