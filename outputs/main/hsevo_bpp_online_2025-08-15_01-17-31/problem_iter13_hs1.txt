import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 7.601456499548414e-07, log_offset: float = 4.4238923109801185) -> np.ndarray:
    """
    Combines Best Fit strategy with an adaptive logarithmic penalty for remaining capacity.
    Prioritizes bins that minimize wasted space after packing, with a nuanced penalty
    for larger remaining capacities to avoid overly aggressive bin selection.

    Args:
        item (float): The size of the item to be packed.
        bins_remain_cap (np.ndarray): A numpy array representing the remaining capacity of each bin.
        epsilon (float): A small constant added to the denominator to prevent division by zero.
        log_offset (float): A constant added to the denominator of the log function to ensure values are not excessively large.

    Returns:
        np.ndarray: A numpy array representing the priority of each bin for the given item.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    
    suitable_bins_mask = bins_remain_cap >= item
    
    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_cap = bins_remain_cap[suitable_bins_mask]
    
    # Best Fit: Minimize remaining capacity after packing
    # Calculate the difference between remaining capacity and item size
    remaining_after_fit = suitable_bins_cap - item
    
    # Adaptive penalty: Use a logarithmic function of the ratio of remaining capacity to item size.
    # This penalizes larger gaps more, but with diminishing returns (smoother than linear).
    # Add a small epsilon to the denominator to avoid division by zero if item size is 0 (though unlikely in BPP).
    # Add log_offset to the denominator to ensure values are not excessively large when remaining_after_fit is small.
    penalty = np.log1p(remaining_after_fit / (item + epsilon))
    
    # Normalize the penalty to be between 0 and 1. Higher penalty should result in lower priority.
    # We want to invert this relationship, so we use (1 - normalized_penalty).
    max_penalty = np.max(penalty)
    if max_penalty > 0:
        normalized_penalty = penalty / max_penalty
        normalized_scores = 1.0 - normalized_penalty
    else:
        normalized_scores = np.ones_like(suitable_bins_cap) # All penalties were zero or negative (unlikely with log1p)

    # Assign priorities to the original indices
    original_indices = np.where(suitable_bins_mask)[0]
    priorities[original_indices] = normalized_scores
    
    return priorities
