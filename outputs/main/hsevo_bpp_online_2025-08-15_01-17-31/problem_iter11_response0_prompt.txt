{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a calibrated logarithmic penalty for excessive remaining capacity,\n    favoring bins that offer a tight fit while moderately penalizing large unused space.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    gaps = suitable_bins_caps - item\n\n    # Best Fit Score: Higher for smaller gaps (tighter fit). Add epsilon for stability.\n    best_fit_score = 1.0 / (gaps + 1e-6)\n\n    # Calibrated Logarithmic Penalty: Penalizes large gaps more significantly but smoothly.\n    # The penalty increases logarithmically with the gap size.\n    # Using np.log1p(gaps) is numerically stable for small gaps and avoids log(0).\n    # A scaling factor (0.1) controls the penalty's impact.\n    penalty_factor = 0.1\n    excess_capacity_penalty = penalty_factor * np.log1p(gaps)\n\n    # Combine scores: Subtract the penalty from the best-fit score.\n    # Higher combined score indicates a preferred bin.\n    combined_priorities = best_fit_score - excess_capacity_penalty\n\n    # Normalize priorities to be between 0 and 1 for consistent behavior\n    min_priority = np.min(combined_priorities)\n    max_priority = np.max(combined_priorities)\n    if max_priority > min_priority:\n        normalized_priorities = (combined_priorities - min_priority) / (max_priority - min_priority)\n    else:\n        normalized_priorities = np.ones_like(combined_priorities) * 0.5 # Default if all scores are same\n\n    priorities[suitable_bins_mask] = normalized_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a smooth, adaptive penalty for large remaining capacities.\n    Prioritizes tight fits while penalizing significantly underfilled bins gracefully.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    can_fit_mask = bins_remain_cap >= item\n    \n    suitable_bins_caps = bins_remain_cap[can_fit_mask]\n    \n    if suitable_bins_caps.size > 0:\n        gaps = suitable_bins_caps - item\n        \n        # Best Fit component: prioritize smaller gaps (higher score for smaller gaps)\n        # Using 1/(gap + epsilon) provides a good base score.\n        best_fit_scores = 1.0 / (gaps + 1e-9)\n        \n        # Adaptive penalty for large remaining capacity:\n        # Penalize bins where remaining capacity is much larger than the item size.\n        # Using a sigmoid-like function centered around a ratio (e.g., 2.0)\n        # to smoothly increase penalty as capacity exceeds item size significantly.\n        # A steepness factor controls how quickly the penalty ramps up.\n        penalty_threshold_ratio = 2.0 \n        penalty_steepness = 0.7 # Slightly steeper than v1 for more pronounced penalty\n        \n        # Penalty is high when capacity is much larger than item * ratio, approaches 0 otherwise.\n        # This encourages using bins that are not excessively empty relative to the item.\n        large_capacity_penalty = 1.0 / (1.0 + np.exp(-penalty_steepness * (suitable_bins_caps / (item + 1e-9) - penalty_threshold_ratio)))\n        \n        # Combine scores: Subtract the penalty from the best-fit score.\n        # This means a bin with a good fit (high best_fit_score) but also a large\n        # remaining capacity (high penalty) will have its priority reduced.\n        combined_scores = best_fit_scores - large_capacity_penalty\n        \n        priorities[can_fit_mask] = combined_scores\n        \n    return priorities\n\n### Analyze & experience\n- *   **Heuristic 1 vs. Heuristic 2:** Heuristic 2 introduces parameters (`epsilon`, `penalty_factor`) that are explicitly tuned, suggesting an attempt at calibration. It also uses a ratio-based penalty (`remaining_after_fit / item`), which is more adaptive to item size than the absolute gap used in Heuristic 1. Heuristic 2 also normalizes its final scores to [0, 1], promoting consistency.\n*   **Heuristic 2 vs. Heuristic 3:** Heuristic 2's penalty is logarithmic and ratio-based, offering a smoother and more adaptive penalization compared to Heuristic 3's linear, ratio-based penalty. Heuristic 3's normalization is absent, which can lead to less predictable priority scales.\n*   **Heuristic 3 vs. Heuristic 4:** Heuristic 4 attempts to normalize its \"Best Fit\" scores and uses an exponential penalty (though the implementation seems to use a log-based penalty which is then normalized). Heuristic 3 uses a simpler linear penalty on the ratio. The normalization and smoother penalty in Heuristic 4 are generally preferred.\n*   **Heuristic 4 vs. Heuristic 5:** Heuristic 4 normalizes its best-fit scores and applies a normalized log penalty, aiming for a more balanced approach. Heuristic 5 uses a simpler additive penalty (the remaining capacity itself), which can be overly aggressive in discarding larger bins, and it doesn't normalize its final scores.\n*   **Heuristic 5 vs. Heuristic 6:** Heuristic 6 is identical to Heuristic 1. Heuristic 5 uses an additive penalty (remaining capacity), which is less nuanced than Heuristic 1's logarithmic penalty.\n*   **Heuristic 6 vs. Heuristic 7:** Heuristic 7 is identical to Heuristic 2. Heuristic 6 (same as 1) uses an absolute gap penalty, whereas Heuristic 7 (same as 2) uses a ratio-based, logarithmic penalty, making Heuristic 7's approach more adaptive.\n*   **Heuristic 7 vs. Heuristic 8:** Heuristic 7 focuses on Best Fit and a ratio-based penalty. Heuristic 8 combines Best Fit, First Fit, and a fullness score with fixed weights. While multi-objective is good, the fixed weights and the specific formulation of the \"fullness score\" (potentially assuming fixed bin capacity) make it less robust than Heuristic 7's adaptive ratio penalty. The normalization in Heuristic 7 is also clearer.\n*   **Heuristic 8 vs. Heuristic 9:** Heuristic 9 is identical to Heuristic 8.\n*   **Heuristic 9 vs. Heuristic 10:** Heuristic 10 uses a sigmoid-like penalty, which is a more sophisticated way to penalize large remaining capacities compared to the weighted sum in Heuristic 9. Heuristic 10 also adapts the penalty relative to the item size more directly.\n*   **Heuristic 10 vs. Heuristic 11:** Heuristic 11 is identical to Heuristic 10.\n*   **Heuristic 11 vs. Heuristic 12:** Heuristic 12 is identical to Heuristic 10.\n*   **Heuristic 12 vs. Heuristic 13:** Heuristic 13 is identical to Heuristic 10.\n*   **Heuristic 13 vs. Heuristic 14:** Heuristic 14 is identical to Heuristic 10.\n*   **Heuristic 14 vs. Heuristic 15:** Heuristic 15 is identical to Heuristics 16-20, representing minimal logic. Heuristic 14 (and 10-13) implements a combination of Best Fit and a sophisticated sigmoid-based penalty.\n*   **Heuristics 15-20:** These heuristics are identical and only provide the initial setup (priorities array and mask check), offering no actual scoring logic. They are the worst due to lack of implementation.\n\nOverall, heuristics combining a strong Best Fit component with adaptive, smooth penalties (especially ratio-based or sigmoid-based) that are normalized tend to perform better. Tuned parameters and explicit normalization contribute to a more robust and predictable heuristic.\n- \nHere's a redefined approach to self-reflection for heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Adaptive penalties, normalization, multi-objective weighting, parameter tuning, stability.\n*   **Advice:** Focus on relative performance and feature interactions. Design adaptive penalty functions that scale with the problem's current state (e.g., problem size, constraint violation magnitude). Experiment with different normalization techniques and their impact on score aggregation.\n*   **Avoid:** Rigid, absolute penalty structures. Ignoring the interplay between different objectives when combining them. Overly simplistic aggregation methods for multi-objective problems.\n*   **Explanation:** The goal is to build heuristics that learn and adapt. Instead of fixed penalties, use functions that dynamically adjust. Normalization ensures that disparate metrics contribute meaningfully. Multi-objective design requires careful consideration of how to balance trade-offs, often favoring multiplicative or conditional logic over simple addition.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}