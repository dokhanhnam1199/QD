{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic penalty based on the ratio of remaining capacity to item size.\n    Prioritizes tight fits while penalizing bins that leave disproportionately large empty space.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Consider only bins that can fit the item\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    if valid_bins_remain_cap.size > 0:\n        # Calculate the remaining capacity after placing the item\n        remaining_after_fit = valid_bins_remain_cap - item\n        \n        # Best Fit component: inverse of remaining space for tighter fits.\n        epsilon = 1e-9\n        best_fit_scores = 1.0 / (remaining_after_fit + epsilon)\n        \n        # Dynamic Penalty component: Penalize based on the ratio of remaining space to the item size.\n        # A higher ratio (more wasted space relative to the item) gets a higher penalty (lower priority).\n        # Using log to dampen the effect of very large remaining spaces.\n        # The penalty factor is tuned to be significant but not overwhelming.\n        penalty_factor = 0.5  # Controls the strength of the penalty\n        # Avoid division by zero or log of non-positive values for penalty calculation\n        penalty_terms = np.maximum(remaining_after_fit, epsilon) / np.maximum(item, epsilon)\n        penalty = penalty_factor * np.log1p(penalty_terms) # Use log1p for better numerical stability near 0\n\n        # Combine Best Fit score with penalty (subtract penalty from score)\n        # This effectively reduces the priority of bins with large relative remaining capacity.\n        combined_priorities = best_fit_scores - penalty\n        \n        # Normalize the combined scores to be between 0 and 1\n        # This makes scores comparable across different item/bin configurations.\n        min_priority = np.min(combined_priorities)\n        max_priority = np.max(combined_priorities)\n        \n        if max_priority > min_priority:\n            normalized_priorities = (combined_priorities - min_priority) / (max_priority - min_priority)\n        else:\n            # If all valid bins have the same combined score, assign a uniform priority\n            normalized_priorities = np.ones_like(combined_priorities) * 0.5\n            \n        # Assign the calculated priorities back to the original indices\n        original_indices = np.where(can_fit_mask)[0]\n        priorities[original_indices] = normalized_priorities\n\n    return priorities\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}