```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with an adaptive logarithmic penalty on remaining capacity.
    Prioritizes bins that minimize wasted space, with a nuanced penalty for
    larger remaining capacities to avoid overly aggressive bin selection.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    
    suitable_bins_mask = bins_remain_cap >= item
    
    if not np.any(suitable_bins_mask):
        return priorities
    
    suitable_bins_cap = bins_remain_cap[suitable_bins_mask]
    
    epsilon = 1e-9
    log_offset = 1.0
    
    # Calculate the difference for Best Fit
    best_fit_diff = suitable_bins_cap - item
    
    # Calculate a penalty based on remaining capacity (logarithmic)
    # Add log_offset to avoid log(0) or very small numbers.
    # The larger the remaining capacity, the higher the penalty (lower priority).
    penalty = np.log(suitable_bins_cap + log_offset)
    
    # Normalize the best_fit_diff to get a score between 0 and 1
    # A smaller difference means a higher score.
    # Add epsilon to avoid division by zero if all suitable bins have the same capacity.
    normalized_diff_score = 1.0 - (best_fit_diff / (np.max(suitable_bins_cap) + epsilon))
    
    # Combine the Best Fit score and the penalty.
    # We want to prioritize small differences (high normalized_diff_score)
    # and penalize large remaining capacities (low penalty value).
    # A simple additive combination with appropriate scaling or a multiplicative
    # approach could be used. Here, we invert the penalty to make higher values
    # correspond to higher priority.
    # A simple additive combination: priority = best_fit_score - penalty_factor * penalty
    # Or, priority = best_fit_score * (1 / penalty)
    
    # Let's try a formulation that rewards small gaps and penalizes large remaining capacities.
    # We want small `best_fit_diff` and also want to avoid bins with very large remaining capacity
    # that would be better used by a much larger item later.
    # A common approach is to make the priority inversely related to the remaining capacity.
    # Combining `normalized_diff_score` (high for good fit) and `1/penalty` (high for small remaining capacity)
    # Since penalty = log(cap + offset), 1/penalty is high for small cap.
    
    # We can also add a term that penalizes large remaining capacity directly.
    # Consider the combined score: normalized_diff_score * (1 / (suitable_bins_cap + epsilon))
    # This rewards a good fit and a small remaining capacity.
    
    # Let's combine Best Fit difference with a penalty on the remaining capacity.
    # Lower difference is better for Best Fit.
    # Lower remaining capacity is generally better to keep bins more full.
    # So, we want to reward bins with `suitable_bins_cap - item` being small AND `suitable_bins_cap` being small.
    # This suggests a score that is inversely proportional to both.
    
    # Consider the inverse of the remaining capacity as a positive score component.
    # score = normalized_diff_score / (suitable_bins_cap + epsilon)
    # This gives high scores to bins with small remaining capacity AND small gap.
    
    # Let's refine: Best Fit aims to minimize `suitable_bins_cap - item`.
    # A secondary goal is to leave less "wasted" space in the bin if possible.
    # So, prioritize bins where `suitable_bins_cap - item` is small.
    # Among those with similar `suitable_bins_cap - item`, prioritize bins with smaller `suitable_bins_cap`.
    
    # This can be achieved by giving a higher score to smaller `suitable_bins_cap - item`,
    # and then a further bonus for smaller `suitable_bins_cap`.
    
    # Option 1: Weighted sum of reciprocal values
    # Score = w1 * (1 / (suitable_bins_cap - item + epsilon)) + w2 * (1 / (suitable_bins_cap + epsilon))
    
    # Option 2: Use the difference and penalize based on remaining capacity logarithmically.
    # priority = (1.0 / (best_fit_diff + epsilon)) * (1.0 / (suitable_bins_cap + log_offset))
    # This rewards small differences and small remaining capacities.
    
    # Let's try a simpler combination that directly reflects the goals:
    # High priority for bins with small `best_fit_diff`.
    # Among bins with similar `best_fit_diff`, prefer those with smaller `suitable_bins_cap`.
    
    # We can create a composite score. A common heuristic is to combine these terms.
    # Example: Priority = (Constant - best_fit_diff) * (Constant / suitable_bins_cap)
    # Or, more directly: Priority = 1 / (best_fit_diff + suitable_bins_cap)
    
    # Let's use the Best Fit difference and add a penalty based on the remaining capacity.
    # We want to MINIMIZE `best_fit_diff` and MINIMIZE `suitable_bins_cap`.
    # So, a score that is inversely related to both.
    
    # A common approach is to use the negative of the remaining capacity as a score component.
    # Or, a penalty that increases with remaining capacity.
    
    # Let's use the normalized difference score and penalize based on the original capacity.
    # A bin that fits the item snugly (low normalized_diff_score) should have high priority.
    # Among bins with similar snugness, a bin with less remaining capacity is preferred.
    
    # Prioritize bins with small `best_fit_diff`.
    # Penalize bins with large `suitable_bins_cap`.
    # Let's use a score that is the inverse of the difference, PLUS an inverse of the capacity.
    # This favors small gaps and small bins.
    
    # The idea from 'Analyze & experience' suggests combining Best Fit with a penalty on remaining capacity.
    # Heuristic 8-9 uses Best Fit with a logarithmic penalty.
    # `priority = 1 / (best_fit_diff + epsilon) * (1 / np.log(suitable_bins_cap + log_offset))`
    # This prioritizes small differences AND small remaining capacities.
    
    # Let's try this: higher score for smaller diff, and higher score for smaller remaining capacity.
    # score_diff = 1.0 / (best_fit_diff + epsilon)
    # score_cap = 1.0 / (suitable_bins_cap + epsilon)
    # priority = score_diff * score_cap
    
    # Let's adopt the "Best Fit with a logarithmic penalty" strategy as described in analysis for Heuristics 8-9.
    # This combines the tightness of Best Fit with a penalty for leaving too much space.
    # We want to minimize `best_fit_diff`. So, `1 / (best_fit_diff + epsilon)` is a good component.
    # We want to penalize large `suitable_bins_cap`. So, `1 / log(suitable_bins_cap + log_offset)` is a good component.
    
    combined_score = (1.0 / (best_fit_diff + epsilon)) * (1.0 / np.log(suitable_bins_cap + log_offset))
    
    original_indices = np.where(suitable_bins_mask)[0]
    
    # Assign the calculated scores to the priorities array
    priorities[original_indices] = combined_score
    
    return priorities
```
