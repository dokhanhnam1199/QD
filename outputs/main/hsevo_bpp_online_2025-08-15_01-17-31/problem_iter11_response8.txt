```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with a smooth, adaptive penalty for large remaining capacities,
    enhanced by normalization for stable multi-bin selection.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    can_fit_mask = bins_remain_cap >= item
    
    suitable_bins_caps = bins_remain_cap[can_fit_mask]
    
    if suitable_bins_caps.size > 0:
        gaps = suitable_bins_caps - item
        
        # Best Fit component: prioritize smaller gaps. Use a scaled inverse for emphasis.
        best_fit_scores = 1.0 / (gaps + 1e-9)
        
        # Adaptive penalty for large remaining capacity using a sigmoid-like function.
        # This smoothly penalizes bins with significantly more capacity than needed.
        penalty_threshold_ratio = 2.0 
        penalty_steepness = 0.7 
        
        # Calculate penalty: high when capacity >> item * ratio, approaches 0 otherwise.
        large_capacity_penalty = 1.0 / (1.0 + np.exp(-penalty_steepness * (suitable_bins_caps / (item + 1e-9) - penalty_threshold_ratio)))
        
        # Combine scores: Subtract penalty from Best Fit score.
        combined_scores = best_fit_scores - large_capacity_penalty
        
        # Normalize scores to [0, 1] for stable comparison across different item sizes.
        # This helps in situations where absolute score differences might vary wildly.
        if combined_scores.size > 0:
            min_score = np.min(combined_scores)
            max_score = np.max(combined_scores)
            if max_score - min_score > 1e-9:
                normalized_scores = (combined_scores - min_score) / (max_score - min_score)
            else:
                normalized_scores = np.ones_like(combined_scores) * 0.5 # Assign neutral score if all scores are same
        else:
            normalized_scores = np.array([])

        priorities[can_fit_mask] = normalized_scores
        
    return priorities
```
