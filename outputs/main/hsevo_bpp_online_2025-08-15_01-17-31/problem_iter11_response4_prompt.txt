{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a scaled penalty for remaining capacity,\n    prioritizing tight fits and moderately penalizing under-filled bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n    \n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Best Fit component: inverse of the gap. Higher score for smaller gaps.\n    epsilon = 1e-9\n    best_fit_scores = 1.0 / (valid_bins_remain_cap - item + epsilon)\n    \n    # Penalty component: Penalize bins with large remaining capacity after packing.\n    # This penalty is relative to the item size to adapt to different item magnitudes.\n    # We use a simple linear penalty that increases with the remaining capacity\n    # scaled by the item size. This is a refinement from simpler additive penalties.\n    # Penalty = penalty_strength * (remaining_capacity / item_size)\n    # We add 1 to the denominator to avoid division by zero if item is 0 and\n    # to ensure a base penalty for any remaining capacity.\n    penalty_strength = 0.2  # Tunable parameter for penalty aggression\n    \n    # Calculate the \"excess\" capacity relative to the item size.\n    # We are penalizing if this excess is large.\n    excess_capacity_ratio = (valid_bins_remain_cap - item) / (item + epsilon)\n    \n    # We want to reduce the priority if excess_capacity_ratio is high.\n    # A simple penalty is to subtract this ratio, scaled by penalty_strength.\n    # This is similar to priority_v0's linear penalty but scaled by item size.\n    penalty = penalty_strength * excess_capacity_ratio\n    \n    # Combine the best fit score with the penalty.\n    # The score is essentially `best_fit_score - penalty`.\n    # A higher score means a better bin choice.\n    combined_priorities = best_fit_scores - penalty\n    \n    # Assign priorities back to the original array structure\n    original_indices = np.where(can_fit_mask)[0]\n    priorities[original_indices] = combined_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if np.any(suitable_bins_mask):\n        suitable_bins_cap = bins_remain_cap[suitable_bins_mask]\n        \n        # Best Fit: Minimize remaining capacity after packing\n        best_fit_diff = suitable_bins_cap - item\n        min_diff_score = 1.0 / (1.0 + best_fit_diff) # Higher score for smaller diff\n        \n        # First Fit: Prioritize bins that have been used longer (lower index)\n        first_fit_score = 1.0 / (1.0 + np.arange(len(suitable_bins_cap)))\n        \n        # Consider bin fullness: prioritize bins that are more full (less remaining capacity)\n        # This is inverse of remaining capacity, normalized by bin capacity (assuming fixed bin capacity, e.g., 1.0)\n        # If bin capacity varies, you would need that information. Assuming bin capacity is 1.0 for simplicity here.\n        # A more robust approach would involve knowing the original bin capacity.\n        # For now, we can use the reciprocal of remaining capacity if it's not too close to zero.\n        fullness_score = np.zeros_like(suitable_bins_cap)\n        non_zero_remain_cap_mask = suitable_bins_cap > 1e-9 # Avoid division by zero\n        fullness_score[non_zero_remain_cap_mask] = 1.0 / suitable_bins_cap[non_zero_remain_cap_mask]\n        \n        # Combine objectives with adaptive weights. For demonstration, let's use fixed weights,\n        # but in a real adaptive system, these would be learned or adjusted.\n        # For now, let's slightly favor best-fit, then first-fit, then fullness.\n        # These weights could be tuned.\n        weight_best_fit = 0.5\n        weight_first_fit = 0.3\n        weight_fullness = 0.2\n        \n        combined_scores = (weight_best_fit * min_diff_score +\n                           weight_first_fit * first_fit_score +\n                           weight_fullness * fullness_score)\n        \n        # Normalize scores to be between 0 and 1\n        if np.max(combined_scores) > 0:\n            normalized_scores = combined_scores / np.max(combined_scores)\n        else:\n            normalized_scores = combined_scores\n        \n        # Assign priorities to the original indices\n        original_indices = np.where(suitable_bins_mask)[0]\n        priorities[original_indices] = normalized_scores\n        \n    return priorities\n\n### Analyze & experience\n- *   **Heuristic 1 vs. Heuristic 2:** Heuristic 2 introduces parameters (`epsilon`, `penalty_factor`) that are explicitly tuned, suggesting an attempt at calibration. It also uses a ratio-based penalty (`remaining_after_fit / item`), which is more adaptive to item size than the absolute gap used in Heuristic 1. Heuristic 2 also normalizes its final scores to [0, 1], promoting consistency.\n*   **Heuristic 2 vs. Heuristic 3:** Heuristic 2's penalty is logarithmic and ratio-based, offering a smoother and more adaptive penalization compared to Heuristic 3's linear, ratio-based penalty. Heuristic 3's normalization is absent, which can lead to less predictable priority scales.\n*   **Heuristic 3 vs. Heuristic 4:** Heuristic 4 attempts to normalize its \"Best Fit\" scores and uses an exponential penalty (though the implementation seems to use a log-based penalty which is then normalized). Heuristic 3 uses a simpler linear penalty on the ratio. The normalization and smoother penalty in Heuristic 4 are generally preferred.\n*   **Heuristic 4 vs. Heuristic 5:** Heuristic 4 normalizes its best-fit scores and applies a normalized log penalty, aiming for a more balanced approach. Heuristic 5 uses a simpler additive penalty (the remaining capacity itself), which can be overly aggressive in discarding larger bins, and it doesn't normalize its final scores.\n*   **Heuristic 5 vs. Heuristic 6:** Heuristic 6 is identical to Heuristic 1. Heuristic 5 uses an additive penalty (remaining capacity), which is less nuanced than Heuristic 1's logarithmic penalty.\n*   **Heuristic 6 vs. Heuristic 7:** Heuristic 7 is identical to Heuristic 2. Heuristic 6 (same as 1) uses an absolute gap penalty, whereas Heuristic 7 (same as 2) uses a ratio-based, logarithmic penalty, making Heuristic 7's approach more adaptive.\n*   **Heuristic 7 vs. Heuristic 8:** Heuristic 7 focuses on Best Fit and a ratio-based penalty. Heuristic 8 combines Best Fit, First Fit, and a fullness score with fixed weights. While multi-objective is good, the fixed weights and the specific formulation of the \"fullness score\" (potentially assuming fixed bin capacity) make it less robust than Heuristic 7's adaptive ratio penalty. The normalization in Heuristic 7 is also clearer.\n*   **Heuristic 8 vs. Heuristic 9:** Heuristic 9 is identical to Heuristic 8.\n*   **Heuristic 9 vs. Heuristic 10:** Heuristic 10 uses a sigmoid-like penalty, which is a more sophisticated way to penalize large remaining capacities compared to the weighted sum in Heuristic 9. Heuristic 10 also adapts the penalty relative to the item size more directly.\n*   **Heuristic 10 vs. Heuristic 11:** Heuristic 11 is identical to Heuristic 10.\n*   **Heuristic 11 vs. Heuristic 12:** Heuristic 12 is identical to Heuristic 10.\n*   **Heuristic 12 vs. Heuristic 13:** Heuristic 13 is identical to Heuristic 10.\n*   **Heuristic 13 vs. Heuristic 14:** Heuristic 14 is identical to Heuristic 10.\n*   **Heuristic 14 vs. Heuristic 15:** Heuristic 15 is identical to Heuristics 16-20, representing minimal logic. Heuristic 14 (and 10-13) implements a combination of Best Fit and a sophisticated sigmoid-based penalty.\n*   **Heuristics 15-20:** These heuristics are identical and only provide the initial setup (priorities array and mask check), offering no actual scoring logic. They are the worst due to lack of implementation.\n\nOverall, heuristics combining a strong Best Fit component with adaptive, smooth penalties (especially ratio-based or sigmoid-based) that are normalized tend to perform better. Tuned parameters and explicit normalization contribute to a more robust and predictable heuristic.\n- \nHere's a redefined approach to self-reflection for heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Adaptive penalties, normalization, multi-objective weighting, parameter tuning, stability.\n*   **Advice:** Focus on relative performance and feature interactions. Design adaptive penalty functions that scale with the problem's current state (e.g., problem size, constraint violation magnitude). Experiment with different normalization techniques and their impact on score aggregation.\n*   **Avoid:** Rigid, absolute penalty structures. Ignoring the interplay between different objectives when combining them. Overly simplistic aggregation methods for multi-objective problems.\n*   **Explanation:** The goal is to build heuristics that learn and adapt. Instead of fixed penalties, use functions that dynamically adjust. Normalization ensures that disparate metrics contribute meaningfully. Multi-objective design requires careful consideration of how to balance trade-offs, often favoring multiplicative or conditional logic over simple addition.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}