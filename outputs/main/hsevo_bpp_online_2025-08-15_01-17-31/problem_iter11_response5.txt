```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines normalized Best Fit with a smooth, adaptive penalty for large remaining capacities.
    Prioritizes tight fits while gracefully penalizing underutilized bins.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    
    # Identify bins that can accommodate the item
    suitable_bins_mask = bins_remain_cap >= item
    
    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_cap = bins_remain_cap[suitable_bins_mask]
    
    # Best Fit component: Prioritize bins that leave minimal remaining space.
    # Calculate the difference: remaining capacity - item size. Smaller is better.
    best_fit_diff = suitable_bins_cap - item
    
    # Normalize Best Fit scores to [0, 1]. A smaller difference gets a higher score (closer to 1).
    # Add a small epsilon to prevent division by zero if all suitable bins have the same remaining space.
    epsilon = 1e-9
    min_diff = np.min(best_fit_diff)
    max_diff = np.max(best_fit_diff)
    
    if max_diff > min_diff:
        best_fit_scores = 1.0 - (best_fit_diff - min_diff) / (max_diff - min_diff + epsilon)
    else:
        best_fit_scores = np.ones_like(best_fit_diff) # All fits are equally good

    # Adaptive Penalty component: Penalize bins with disproportionately large remaining capacities relative to the item size.
    # This uses a logarithmic function for smoothness, inspired by heuristics that handle large gaps gracefully.
    # Calculate the ratio of remaining capacity to item size.
    # Penalize more when this ratio is high.
    # We want to *subtract* this penalty from the best_fit_scores. So, the penalty itself should increase with the gap.
    # Using log1p(excess_capacity) provides a smooth increase and is robust to small values.
    excess_capacity = suitable_bins_cap - item
    
    # Raw penalty based on the log of (1 + excess capacity). Add 1 to avoid log(0).
    # The +1 is crucial here to handle cases where excess_capacity is 0.
    log_penalty_raw = np.log1p(excess_capacity) 
    
    # Normalize the penalty to have a consistent scale across different item/bin sizes.
    # We scale it relative to the maximum raw penalty among suitable bins.
    max_log_penalty = np.max(log_penalty_raw)
    if max_log_penalty > epsilon:
        normalized_penalty = log_penalty_raw / max_log_penalty
    else:
        normalized_penalty = np.zeros_like(log_penalty_raw)

    # Combine scores: Subtract the normalized penalty from the Best Fit score.
    # This means good fits (high best_fit_scores) are favored, and bins with large excess capacity (high normalized_penalty) are penalized.
    combined_priorities = best_fit_scores - normalized_penalty
    
    # Ensure final priorities are non-negative.
    combined_priorities = np.maximum(combined_priorities, 0)

    # Assign the calculated priorities back to their original positions in the priorities array.
    original_indices = np.where(suitable_bins_mask)[0]
    priorities[original_indices] = combined_priorities
    
    return priorities
```
