{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines normalized Best Fit with a smooth, exponential penalty for large gaps,\n    prioritizing tight fits and penalizing excessive waste more gracefully.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if np.any(suitable_bins_mask):\n        suitable_bins_cap = bins_remain_cap[suitable_bins_mask]\n        \n        # Best Fit component: Minimize remaining capacity after packing.\n        # Smaller difference means higher score.\n        best_fit_diff = suitable_bins_cap - item\n        \n        # Normalize Best Fit scores to [0, 1], where 1 is the best fit (smallest diff).\n        # Add epsilon to avoid division by zero if all suitable bins have the same remaining space.\n        epsilon = 1e-9\n        if np.max(best_fit_diff) > np.min(best_fit_diff):\n            best_fit_scores = 1.0 - (best_fit_diff - np.min(best_fit_diff)) / (np.max(best_fit_diff) - np.min(best_fit_diff) + epsilon)\n        else:\n            best_fit_scores = np.ones_like(best_fit_diff) # All fits are equally \"best\"\n\n        # Penalty component: Exponential penalty for large remaining capacities (Heuristic 13-16 inspiration).\n        # Penalizes bins where remaining capacity is significantly larger than the item.\n        # A higher ratio (remaining_cap / item) leads to a higher penalty score.\n        # We want to *reduce* the priority for large gaps, so we use this penalty as a subtractive term.\n        # The exponential function provides a smooth transition.\n        capacity_ratio = suitable_bins_cap / item\n        # Penalty grows smoothly as capacity_ratio increases beyond a certain point (e.g., 1.5).\n        # Using exp(-k * (ratio - threshold)) makes it decrease as ratio increases, so we use exp(k * (ratio - threshold)) or similar form.\n        # Let's use a penalty that *increases* with the ratio and subtract it.\n        # Penalty should be low for small ratios and higher for large ratios.\n        # A simple increasing function: log(ratio) or ratio itself.\n        # A more calibrated approach: using exp to make it more sensitive to larger gaps.\n        # Let's try a penalty that is 0 for ratio <= 1 and grows.\n        # We want to *subtract* this penalty from best_fit_scores.\n        # So penalty should be low for good fits and high for bad fits.\n        # A simple penalty: max(0, capacity_ratio - 1.5) * weight\n        # Let's try a smooth penalty: exp( (suitable_bins_cap - item) / item ) - 1.0, scaled.\n        # A penalty inspired by Heuristic 13-16: exp(-penalty_steepness * (ratio - threshold))\n        # This means penalty is high when ratio < threshold and low when ratio > threshold.\n        # We want to penalize *large* remaining capacities, so the penalty should be high when `suitable_bins_cap - item` is large.\n        # Let's reverse the logic of 13-16 and use a penalty that *increases* with remaining capacity.\n        # Penalty: 1.0 / (1.0 + exp(-steepness * (suitable_bins_cap - item))) scaled.\n        # A simpler approach inspired by 4th and 7th: subtract a value proportional to the gap.\n        # Let's try a normalized gap: (suitable_bins_cap - item) / max_bin_capacity or similar.\n        # The 'Analyze & experience' suggests that multiplicative penalties (like in v0) and smooth exponential penalties (like in 13-16) are good.\n        # Let's combine a normalized best fit with a penalty that *decreases* the score if the gap is large.\n        # Penalty strength should increase with the excess capacity.\n        # Penalty = f(excess_capacity / item_size)\n        # Let's use a penalty inspired by 13-16: `1.0 / (1.0 + np.exp(-penalty_steepness * (suitable_bins_cap - item)))`\n        # This penalty is high for small `suitable_bins_cap - item` and low for large ones.\n        # We want to *reduce* the score if `suitable_bins_cap - item` is large.\n        # So we subtract a penalty that *increases* with the gap.\n        # Penalty = k * (suitable_bins_cap - item)\n        # Let's try a smoothed penalty: `np.log1p(suitable_bins_cap - item)` (inspired by 11th/12th) and normalize it.\n        \n        # Let's combine normalized best-fit with a penalty that decreases the score if the remaining capacity is \"too much\" relative to the item size.\n        # Use a penalty term that is high when `suitable_bins_cap - item` is large, and subtract it.\n        # Penalty function: a scaled version of the excess capacity, perhaps using a log scale for smoothness.\n        # Penalty increases with `suitable_bins_cap - item`.\n        excess_capacity = suitable_bins_cap - item\n        \n        # Use a log-based penalty for smoothness, similar to Heuristics 11/12, but ensure it penalizes *large* gaps.\n        # Penalty should be small for small gaps and large for large gaps.\n        # We will subtract this penalty. So we want a function that grows with excess_capacity.\n        # Add epsilon for log(0).\n        log_penalty_raw = np.log1p(excess_capacity) \n        \n        # Normalize the penalty to avoid overly aggressive subtraction.\n        # Scale it relative to the maximum possible log penalty (or a reasonable upper bound).\n        # A simple normalization: divide by max log penalty across suitable bins.\n        if np.max(log_penalty_raw) > epsilon:\n            normalized_penalty = log_penalty_raw / np.max(log_penalty_raw)\n        else:\n            normalized_penalty = np.zeros_like(log_penalty_raw)\n\n        # Combine: Best Fit score minus the normalized penalty.\n        # This means: high best_fit_score is good, high normalized_penalty (large excess capacity) is bad.\n        combined_priorities = best_fit_scores - normalized_penalty\n        \n        # Ensure priorities don't go below zero (optional, but good practice for scores)\n        combined_priorities = np.maximum(combined_priorities, 0)\n\n        # Assign the calculated priorities to the original indices\n        original_indices = np.where(suitable_bins_mask)[0]\n        priorities[original_indices] = combined_priorities\n        \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n### Analyze & experience\n- *   **Heuristic 1 vs. Heuristic 2:** Heuristic 2 introduces parameters (`epsilon`, `penalty_factor`) that are explicitly tuned, suggesting an attempt at calibration. It also uses a ratio-based penalty (`remaining_after_fit / item`), which is more adaptive to item size than the absolute gap used in Heuristic 1. Heuristic 2 also normalizes its final scores to [0, 1], promoting consistency.\n*   **Heuristic 2 vs. Heuristic 3:** Heuristic 2's penalty is logarithmic and ratio-based, offering a smoother and more adaptive penalization compared to Heuristic 3's linear, ratio-based penalty. Heuristic 3's normalization is absent, which can lead to less predictable priority scales.\n*   **Heuristic 3 vs. Heuristic 4:** Heuristic 4 attempts to normalize its \"Best Fit\" scores and uses an exponential penalty (though the implementation seems to use a log-based penalty which is then normalized). Heuristic 3 uses a simpler linear penalty on the ratio. The normalization and smoother penalty in Heuristic 4 are generally preferred.\n*   **Heuristic 4 vs. Heuristic 5:** Heuristic 4 normalizes its best-fit scores and applies a normalized log penalty, aiming for a more balanced approach. Heuristic 5 uses a simpler additive penalty (the remaining capacity itself), which can be overly aggressive in discarding larger bins, and it doesn't normalize its final scores.\n*   **Heuristic 5 vs. Heuristic 6:** Heuristic 6 is identical to Heuristic 1. Heuristic 5 uses an additive penalty (remaining capacity), which is less nuanced than Heuristic 1's logarithmic penalty.\n*   **Heuristic 6 vs. Heuristic 7:** Heuristic 7 is identical to Heuristic 2. Heuristic 6 (same as 1) uses an absolute gap penalty, whereas Heuristic 7 (same as 2) uses a ratio-based, logarithmic penalty, making Heuristic 7's approach more adaptive.\n*   **Heuristic 7 vs. Heuristic 8:** Heuristic 7 focuses on Best Fit and a ratio-based penalty. Heuristic 8 combines Best Fit, First Fit, and a fullness score with fixed weights. While multi-objective is good, the fixed weights and the specific formulation of the \"fullness score\" (potentially assuming fixed bin capacity) make it less robust than Heuristic 7's adaptive ratio penalty. The normalization in Heuristic 7 is also clearer.\n*   **Heuristic 8 vs. Heuristic 9:** Heuristic 9 is identical to Heuristic 8.\n*   **Heuristic 9 vs. Heuristic 10:** Heuristic 10 uses a sigmoid-like penalty, which is a more sophisticated way to penalize large remaining capacities compared to the weighted sum in Heuristic 9. Heuristic 10 also adapts the penalty relative to the item size more directly.\n*   **Heuristic 10 vs. Heuristic 11:** Heuristic 11 is identical to Heuristic 10.\n*   **Heuristic 11 vs. Heuristic 12:** Heuristic 12 is identical to Heuristic 10.\n*   **Heuristic 12 vs. Heuristic 13:** Heuristic 13 is identical to Heuristic 10.\n*   **Heuristic 13 vs. Heuristic 14:** Heuristic 14 is identical to Heuristic 10.\n*   **Heuristic 14 vs. Heuristic 15:** Heuristic 15 is identical to Heuristics 16-20, representing minimal logic. Heuristic 14 (and 10-13) implements a combination of Best Fit and a sophisticated sigmoid-based penalty.\n*   **Heuristics 15-20:** These heuristics are identical and only provide the initial setup (priorities array and mask check), offering no actual scoring logic. They are the worst due to lack of implementation.\n\nOverall, heuristics combining a strong Best Fit component with adaptive, smooth penalties (especially ratio-based or sigmoid-based) that are normalized tend to perform better. Tuned parameters and explicit normalization contribute to a more robust and predictable heuristic.\n- \nHere's a redefined approach to self-reflection for heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Adaptive penalties, normalization, multi-objective weighting, parameter tuning, stability.\n*   **Advice:** Focus on relative performance and feature interactions. Design adaptive penalty functions that scale with the problem's current state (e.g., problem size, constraint violation magnitude). Experiment with different normalization techniques and their impact on score aggregation.\n*   **Avoid:** Rigid, absolute penalty structures. Ignoring the interplay between different objectives when combining them. Overly simplistic aggregation methods for multi-objective problems.\n*   **Explanation:** The goal is to build heuristics that learn and adapt. Instead of fixed penalties, use functions that dynamically adjust. Normalization ensures that disparate metrics contribute meaningfully. Multi-objective design requires careful consideration of how to balance trade-offs, often favoring multiplicative or conditional logic over simple addition.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}