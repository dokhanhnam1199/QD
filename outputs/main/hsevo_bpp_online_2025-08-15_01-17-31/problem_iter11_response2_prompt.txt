{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic penalty based on the ratio of remaining capacity to item size.\n    Prioritizes tight fits while penalizing bins that leave disproportionately large empty space.\n    \n    Args:\n        item: The size of the item to be placed.\n        bins_remain_cap: A numpy array representing the remaining capacity of each bin.\n        epsilon: A small float to avoid division by zero or log of non-positive values.\n        penalty_factor: Controls the strength of the penalty.\n    \n    Returns:\n        A numpy array of priorities for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Consider only bins that can fit the item\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    if valid_bins_remain_cap.size > 0:\n        # Calculate the remaining capacity after placing the item\n        remaining_after_fit = valid_bins_remain_cap - item\n        \n        # Best Fit component: inverse of remaining space for tighter fits.\n        best_fit_scores = 1.0 / (remaining_after_fit + epsilon)\n        \n        # Dynamic Penalty component: Penalize based on the ratio of remaining space to the item size.\n        # A higher ratio (more wasted space relative to the item) gets a higher penalty (lower priority).\n        # Using log to dampen the effect of very large remaining spaces.\n        # The penalty factor is tuned to be significant but not overwhelming.\n        \n        # Avoid division by zero or log of non-positive values for penalty calculation\n        penalty_terms = np.maximum(remaining_after_fit, epsilon) / np.maximum(item, epsilon)\n        penalty = penalty_factor * np.log1p(penalty_terms) # Use log1p for better numerical stability near 0\n\n        # Combine Best Fit score with penalty (subtract penalty from score)\n        # This effectively reduces the priority of bins with large relative remaining capacity.\n        combined_priorities = best_fit_scores - penalty\n        \n        # Normalize the combined scores to be between 0 and 1\n        # This makes scores comparable across different item/bin configurations.\n        min_priority = np.min(combined_priorities)\n        max_priority = np.max(combined_priorities)\n        \n        if max_priority > min_priority:\n            normalized_priorities = (combined_priorities - min_priority) / (max_priority - min_priority)\n        else:\n            # If all valid bins have the same combined score, assign a uniform priority\n            normalized_priorities = np.ones_like(combined_priorities) * 0.5\n            \n        # Assign the calculated priorities back to the original indices\n        original_indices = np.where(can_fit_mask)[0]\n        priorities[original_indices] = normalized_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n### Analyze & experience\n- *   **Heuristic 1 vs. Heuristic 2:** Heuristic 2 introduces parameters (`epsilon`, `penalty_factor`) that are explicitly tuned, suggesting an attempt at calibration. It also uses a ratio-based penalty (`remaining_after_fit / item`), which is more adaptive to item size than the absolute gap used in Heuristic 1. Heuristic 2 also normalizes its final scores to [0, 1], promoting consistency.\n*   **Heuristic 2 vs. Heuristic 3:** Heuristic 2's penalty is logarithmic and ratio-based, offering a smoother and more adaptive penalization compared to Heuristic 3's linear, ratio-based penalty. Heuristic 3's normalization is absent, which can lead to less predictable priority scales.\n*   **Heuristic 3 vs. Heuristic 4:** Heuristic 4 attempts to normalize its \"Best Fit\" scores and uses an exponential penalty (though the implementation seems to use a log-based penalty which is then normalized). Heuristic 3 uses a simpler linear penalty on the ratio. The normalization and smoother penalty in Heuristic 4 are generally preferred.\n*   **Heuristic 4 vs. Heuristic 5:** Heuristic 4 normalizes its best-fit scores and applies a normalized log penalty, aiming for a more balanced approach. Heuristic 5 uses a simpler additive penalty (the remaining capacity itself), which can be overly aggressive in discarding larger bins, and it doesn't normalize its final scores.\n*   **Heuristic 5 vs. Heuristic 6:** Heuristic 6 is identical to Heuristic 1. Heuristic 5 uses an additive penalty (remaining capacity), which is less nuanced than Heuristic 1's logarithmic penalty.\n*   **Heuristic 6 vs. Heuristic 7:** Heuristic 7 is identical to Heuristic 2. Heuristic 6 (same as 1) uses an absolute gap penalty, whereas Heuristic 7 (same as 2) uses a ratio-based, logarithmic penalty, making Heuristic 7's approach more adaptive.\n*   **Heuristic 7 vs. Heuristic 8:** Heuristic 7 focuses on Best Fit and a ratio-based penalty. Heuristic 8 combines Best Fit, First Fit, and a fullness score with fixed weights. While multi-objective is good, the fixed weights and the specific formulation of the \"fullness score\" (potentially assuming fixed bin capacity) make it less robust than Heuristic 7's adaptive ratio penalty. The normalization in Heuristic 7 is also clearer.\n*   **Heuristic 8 vs. Heuristic 9:** Heuristic 9 is identical to Heuristic 8.\n*   **Heuristic 9 vs. Heuristic 10:** Heuristic 10 uses a sigmoid-like penalty, which is a more sophisticated way to penalize large remaining capacities compared to the weighted sum in Heuristic 9. Heuristic 10 also adapts the penalty relative to the item size more directly.\n*   **Heuristic 10 vs. Heuristic 11:** Heuristic 11 is identical to Heuristic 10.\n*   **Heuristic 11 vs. Heuristic 12:** Heuristic 12 is identical to Heuristic 10.\n*   **Heuristic 12 vs. Heuristic 13:** Heuristic 13 is identical to Heuristic 10.\n*   **Heuristic 13 vs. Heuristic 14:** Heuristic 14 is identical to Heuristic 10.\n*   **Heuristic 14 vs. Heuristic 15:** Heuristic 15 is identical to Heuristics 16-20, representing minimal logic. Heuristic 14 (and 10-13) implements a combination of Best Fit and a sophisticated sigmoid-based penalty.\n*   **Heuristics 15-20:** These heuristics are identical and only provide the initial setup (priorities array and mask check), offering no actual scoring logic. They are the worst due to lack of implementation.\n\nOverall, heuristics combining a strong Best Fit component with adaptive, smooth penalties (especially ratio-based or sigmoid-based) that are normalized tend to perform better. Tuned parameters and explicit normalization contribute to a more robust and predictable heuristic.\n- \nHere's a redefined approach to self-reflection for heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Adaptive penalties, normalization, multi-objective weighting, parameter tuning, stability.\n*   **Advice:** Focus on relative performance and feature interactions. Design adaptive penalty functions that scale with the problem's current state (e.g., problem size, constraint violation magnitude). Experiment with different normalization techniques and their impact on score aggregation.\n*   **Avoid:** Rigid, absolute penalty structures. Ignoring the interplay between different objectives when combining them. Overly simplistic aggregation methods for multi-objective problems.\n*   **Explanation:** The goal is to build heuristics that learn and adapt. Instead of fixed penalties, use functions that dynamically adjust. Normalization ensures that disparate metrics contribute meaningfully. Multi-objective design requires careful consideration of how to balance trade-offs, often favoring multiplicative or conditional logic over simple addition.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}