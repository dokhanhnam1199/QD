```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with a penalty for bins that are "too full",
    prioritizing bins that are nearly full but can still accommodate the item.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    
    suitable_bins_mask = bins_remain_cap >= item
    
    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_cap = bins_remain_cap[suitable_bins_mask]
    
    # "Best Fit" component: prioritize smaller gaps
    gaps = suitable_bins_cap - item
    best_fit_priorities = 1.0 / (gaps + 1e-9)

    # Add a penalty for bins that are "too full" after fitting.
    # This can be achieved by favoring bins with a larger remaining capacity *after* the item is placed,
    # but not so large that it's wasteful. Let's use a sigmoid-like approach to dampen high remaining capacities.
    # We want to penalize large gaps (i.e., low priority) and favor small gaps (high priority).
    # We can invert the gap and apply a function that still emphasizes smaller gaps more.
    # The heuristic 14-17 uses a sigmoid. Let's adapt that idea to prioritize bins that are *not* too empty.
    # A simple inversion of remaining capacity after fit is already good. Let's try to make it more robust.
    
    # Instead of just inverse, let's combine inverse with a slight preference for larger remaining capacities
    # to avoid fragmentation. This is a bit counter to pure best-fit.
    # Let's stick to Best Fit but refine it. The original Best Fit (v0, 3rd, 8th) is generally strong.
    # The analysis highlighted that inverse of gap is good. v0 is a good baseline.
    # Let's try to make it more robust by considering the 'tightness' more aggressively.
    
    # Combining v0's simplicity with a consideration for multiple "good" fits.
    # The inverse of the gap is a strong indicator. Let's consider what could make it better.
    # Maybe a slight boost to bins that are "almost full" but still fit.
    
    # Let's use the inverse of the gap as a base, and add a bonus if the remaining capacity is small.
    # This is essentially what the inverse gap already does.

    # Let's re-evaluate based on analysis: "inverse of the remaining gap (1 / (gap + epsilon))" is a strong indicator.
    # Heuristic v0 already does this effectively.
    # The issue might be in *how* many such bins are prioritized.
    # The analysis on 10th and 18th suggests scaling and exponentiation.
    # Let's try a simplified approach: normalize the inverse gaps.

    normalized_best_fit_priorities = best_fit_priorities / np.max(best_fit_priorities + 1e-9)
    
    # Let's consider a scenario where we want to avoid very large remaining capacities.
    # A sigmoid might help here, as seen in heuristics 14-17.
    # If the gap is very small, it's good. If it's moderately large, it's less good.
    
    # Let's use the inverse of the gap as a base, and then apply a function that doesn't over-penalize slightly larger gaps.
    # The sigmoid in 14-17 uses (slope * excess_capacity + intercept). We want higher values for smaller excess_capacity.
    # So, the input to sigmoid should be negatively correlated with excess_capacity.
    # Let's try -excess_capacity.
    
    slope = 10.0
    intercept = 5.0 # Increased intercept to shift sigmoid response towards smaller capacities
    
    # We want to prioritize smaller gaps. Sigmoid(x) increases with x.
    # If we input `-(gaps)` into sigmoid, it will prioritize smaller gaps.
    # `1 / (1 + exp(-(-slope * gaps + intercept)))`
    
    adjusted_gaps = -gaps
    sigmoid_priorities = 1 / (1 + np.exp(-(slope * adjusted_gaps + intercept)))

    # Combine the direct inverse fit with the sigmoid idea.
    # The inverse provides a direct measure of "how well" it fits.
    # The sigmoid can then modulate this based on the absolute size of the gap.
    
    # Let's try a weighted sum: heavily favouring the inverse gap, with sigmoid as a minor adjustment.
    # Or, let's use the sigmoid directly but focus on the *inverse* of the gap as input.
    # This means inputting `1/gap` into a sigmoid. But sigmoid works better on a range like [-inf, inf].
    
    # Reverting to a simpler, robust combination:
    # Best Fit (inverse of gap) is proven effective. Let's stick to that, but ensure it's well-scaled.
    # The v0 heuristic is already quite good. What if we wanted to be more conservative and prefer
    # bins that are *just* large enough? This is exactly what 1/(gap + epsilon) does.
    
    # Let's consider the "Almost Full Fit" idea from 1st and 2nd, combined with Best Fit.
    # "Almost Full Fit" implies a bonus for bins that are close to full.
    # If a bin has remaining capacity `R` and the item is `I`, the gap is `R-I`.
    # Small gap is good (Best Fit).
    # If `R` is very small, the gap is small.
    
    # Let's try to give a boost to bins where the remaining capacity AFTER fitting is small, but not too small.
    # We already have `1.0 / (bins_remain_cap[i] - item + 1e-9)`.
    
    # Consider the analysis: "These heuristics (5th, 6th, 7th, 9th) are largely similar to the "Best Fit" approach (3rd/8th),
    # using 1.0 / (bins_remain_cap - item + epsilon)". Heuristic 9th explicitly sets non-fitting bins to -float('inf').
    # This is a good robust strategy.
    
    # Let's combine the "Best Fit" principle with a secondary criterion.
    # Primary: Best Fit (inverse of gap).
    # Secondary: If multiple bins have very similar inverse gaps, pick the one that leaves the least remaining capacity.
    # This is implicitly handled by the inverse gap already.
    
    # Let's re-examine the sigmoid-based approaches.
    # Heuristics 14-17: `1 / (1 + np.exp(-(slope * (excess_capacity) + intercept)))`
    # This prioritizes smaller `excess_capacity`.
    # We can combine this with Best Fit.
    
    # Let's try this: Use the Best Fit score (inverse of gap). Then, for bins that are "almost full" (small remaining capacity after fit),
    # give them an additional boost.
    
    # Final strategy: Use the inverse of the gap as the primary score.
    # Then, use a sigmoid function on the *remaining capacity after fit* (which is `gaps`)
    # to give a penalty for bins that would be left "too empty".
    # This means we want the sigmoid to be high for small gaps, and low for large gaps.
    # The sigmoid formula `1 / (1 + exp(-x))` increases with `x`.
    # So, we need to input `f(gap)` where `f` is decreasing. Let's use `-(gap)`.
    
    # `sigmoid_penalty = 1 / (1 + np.exp(-(slope * gaps + intercept)))`
    # This sigmoid_penalty is high for small gaps and low for large gaps.
    # We want to *boost* bins with small gaps. So, we should *add* this penalty.
    
    # Let's try a weighted sum of the inverse gap and the sigmoid penalty.
    # The inverse gap is the dominant factor. The sigmoid can fine-tune.
    
    # Let's define `f(gap) = 1.0 / (gap + 1e-9)` and `g(gap) = 1 / (1 + np.exp(-(slope * gap + intercept)))`.
    # We want to prioritize small gaps. `f(gap)` does this. `g(gap)` also does this if `slope` is negative, or if we use `-gap`.
    # Let's use `g(gap)` with `slope` positive and input `-(gap)`: `g_inv_gap(gap) = 1 / (1 + np.exp(-(slope * (-gap) + intercept)))`.
    # This `g_inv_gap(gap)` is high for small gaps.
    
    # Let's combine: `priority = A * f(gap) + B * g_inv_gap(gap)`
    # A should be larger than B.
    
    A = 1.0
    B = 0.5
    slope = 10.0
    intercept = 5.0 # Tunable parameter: higher means stronger penalty for larger gaps.
    
    # The inverse gap `1.0 / (gaps + 1e-9)`
    # The sigmoid on negative gap: `1 / (1 + np.exp(-(slope * (-gaps) + intercept)))`

    combined_priorities = A * (1.0 / (gaps + 1e-9)) + B * (1 / (1 + np.exp(-(slope * (-gaps) + intercept))))
    
    priorities[suitable_bins_mask] = combined_priorities
    
    return priorities
```
