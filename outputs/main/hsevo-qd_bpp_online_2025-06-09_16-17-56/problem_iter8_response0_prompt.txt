{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines FFD, almost full bin filling, and a small remainder preference.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    not_fit_penalty = -1e9\n    almost_full_threshold = 0.9\n    almost_full_boost = 0.5\n    small_item_threshold = 0.1 * np.max(bins_remain_cap)\n    random_factor = 0.01\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            wasted_space = cap - item\n            priorities[i] = 1.0 / (1.0 + wasted_space)\n        else:\n            priorities[i] = not_fit_penalty\n\n    is_almost_full = bins_remain_cap / np.max(bins_remain_cap) < (1 - almost_full_threshold)\n    for i, is_full in enumerate(is_almost_full):\n        if is_full and bins_remain_cap[i] >= item:\n            priorities[i] += almost_full_boost\n\n    if item < small_item_threshold:\n        for i, cap in enumerate(bins_remain_cap):\n            remainder = cap - item\n            if 0 < remainder < small_item_threshold:\n                priorities[i] += 0.3\n\n    priorities += np.random.rand(len(bins_remain_cap)) * random_factor\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: First Fit Decreasing (FFD) inspired - prefer bins with enough space, penalized by wasted space.\n    # Bins that cannot fit the item get a very low priority.\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Calculate the wasted space. Aim to minimize wasted space\n            wasted_space = cap - item\n            priorities[i] = 1.0 / (1.0 + wasted_space)  # Higher priority for less wasted space\n        else:\n            priorities[i] = -1e9  # Very low priority if item doesn't fit.\n\n    # Heuristic 2: Address potential fragmentation by occasionally filling bins that are almost full.\n    # This helps consolidate existing items and prevents creation of many small empty bins.\n\n    almost_full_threshold = 0.9  # Tuneable parameter: what fraction of full is \"almost full\"?\n    is_almost_full = bins_remain_cap / np.max(bins_remain_cap) < (1 - almost_full_threshold)\n\n    for i, is_full in enumerate(is_almost_full):\n        if is_full and bins_remain_cap[i] >= item:\n            priorities[i] += 0.5  # Boost priority for filling up almost full bins\n\n    # Heuristic 3: Introduce a \"balance\" heuristic. Prefer bins that are neither too full nor too empty.\n    # This can prevent creating very small residual bins while also avoiding excessive wasted space early on.\n\n    balance_threshold_low = 0.2  # Tuneable parameter: lower bound of \"balanced\" fill level\n    balance_threshold_high = 0.8  # Tuneable parameter: upper bound of \"balanced\" fill level\n\n    bin_fill_levels = (np.max(bins_remain_cap) - bins_remain_cap) / np.max(bins_remain_cap) #Calculate current fill level\n\n    is_balanced = (bin_fill_levels >= balance_threshold_low) & (bin_fill_levels <= balance_threshold_high)\n\n    for i, is_bal in enumerate(is_balanced):\n        if is_bal and bins_remain_cap[i] >= item:\n            priorities[i] += 0.25  # Give a moderate boost to balanced bins\n\n    # Heuristic 4: Small items should prefer bins that would leave a small, but non-zero, remainder.\n    small_item_threshold = 0.1 * np.max(bins_remain_cap)  # Define \"small\" relative to bin size\n    if item < small_item_threshold:\n      for i, cap in enumerate(bins_remain_cap):\n        remainder = cap - item\n        if 0 < remainder < small_item_threshold: #If remainder is small and positive\n          priorities[i] += 0.3\n\n    # Heuristic 5: Add a small random factor to break ties and encourage exploration of different bin assignments.\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the inclusion of more sophisticated heuristics like \"almost full,\" \"balanced bin,\" and \"small item\" preferences, along with tunable parameters and random factors, contributes to better performance. Conversely, (20th) relies solely on a logarithmic ratio, lacking nuanced considerations.\n\nComparing (6th) vs (10th), (6th) has almost_full_threshold, almost_full_boost, small_item_threshold, random_factor are hard code while (10th) has almost_full_threshold, random_factor are hard code, so (6th) is better than (10th).\n\nComparing (1st) vs (6th), we see that (1st) use many parameters while (6th) do not, this make (1st) better than (6th). Comparing (1st) vs (2nd), (2nd) vs (3rd), (3rd) vs (4th), (4th) vs (5th), all the same so no difference here. Comparing (6th) vs (7th), (7th) vs (8th), (8th) vs (9th), all the same so no difference here. Comparing (10th) vs (11th), (11th) vs (12th), (12th) vs (13th), (13th) vs (14th), (14th) vs (15th), all the same so no difference here. Comparing (17th) vs (18th), (18th) vs (19th), all the same so no difference here.\n\nComparing (second worst) vs (worst), we see that (16th) use  capacity ratio for bin priority while (20th) is not, so (16th) is better. Overall: Using more tunable parameters, and adding more heuristic algorithm like \"almost full,\" \"balanced bin,\" and \"small item\" contribute to better performance.\n- \nOkay, I understand. Let's redefine \"Current Self-Reflection\" to be more effective in designing better heuristics, steering clear of the pitfalls in \"Ineffective Self-Reflection\":\n\n*   **Keywords:** Deliberate Design, Adaptive Strategy, Edge-Case Focus, Performance Feedback.\n*   **Advice:** Focus on the *intentional* design of heuristics, emphasizing adaptability and precise handling of edge cases, incorporating a feedback loop based on performance metrics.\n*   **Avoid:** Overly complex methods without clear benefit, generic \"consider multiple factors,\" and simply stating \"balancing exploration/exploitation\" without specific implementation details.\n*   **Explanation:** Instead of vague suggestions, emphasize creating a planful approach, tailoring heuristics to specific problem features, and continuously refining the approach based on observed performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}