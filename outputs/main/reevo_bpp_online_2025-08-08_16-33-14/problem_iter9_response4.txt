[Prior reflection]
Prioritize perfect/tight fits. Quadratically reward snugness. Adapt thresholds and penalties to item/bin state. Tune scaling factors and decay. Balance exploration/exploitation for better bin packing.

[Code]
```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements an improved priority function for the online Bin Packing Problem,
    focusing on prioritizing tight fits, quadratically rewarding snugness,
    and using adaptive thresholds and penalties.

    The priority is calculated as follows:
    1. Bins that cannot fit the item receive a priority of 0.
    2. For bins that can fit the item:
       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.
       b. Tight Fits (remaining capacity after packing is small and positive):
          Quadratically rewarded for snugness. Higher priority for smaller remaining capacity.
       c. Good Fits (remaining capacity after packing is moderate): Priority decreases
          with remaining capacity, but less steeply than tight fits.
       d. Wasteful Fits (remaining capacity after packing is large):
          Significantly penalized. Penalty increases with the amount of wasted space
          relative to the item size and the bin's current remaining capacity.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.

    Returns:
        A NumPy array of the same size as bins_remain_cap, where each element
        represents the priority score for placing the item in the corresponding bin.
        Higher scores indicate higher priority.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    # Define thresholds adaptively.
    epsilon = 1e-9  # Tolerance for floating-point comparisons

    # Threshold for "tight" fits: remaining space is less than or equal to a fraction of the item size.
    # This is a more dynamic definition of tightness compared to just item size.
    tight_fit_threshold = 0.2 * item  # e.g., remaining space is 20% of item size

    # Threshold for "wasteful" fits: remaining space is significantly larger than the item size,
    # and also large relative to the bin's current capacity.
    # This is a two-pronged approach to identify wasteful bins.
    wasteful_threshold_item_ratio = 3.0 * item
    wasteful_threshold_bin_ratio = 0.5 * bins_remain_cap[can_fit_mask] # If remaining space > 50% of *original* capacity

    # --- Scoring Logic ---
    scores = np.zeros_like(remaining_after_fit)

    # 1. Perfect Fits: Highest priority.
    perfect_mask = (remaining_after_fit < epsilon)
    scores[perfect_mask] = 1000.0

    # 2. Tight Fits: Quadratically rewarded for snugness.
    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)
    # Quadratic reward: higher score for smaller remaining capacity.
    # Scale the quadratic term to ensure it's significant but doesn't dominate perfect fits.
    # Add a small constant to avoid division by zero or very large numbers.
    scores[tight_mask] = 200.0 - 5000.0 * (remaining_after_fit[tight_mask] / (tight_fit_threshold + epsilon))**2


    # 3. Good Fits: Priority decreases with remaining capacity, less steeply than tight fits.
    # These are bins that fit, but are not "tight" and not yet "wasteful".
    good_mask = ~perfect_mask & ~tight_mask & \
                (remaining_after_fit <= wasteful_threshold_item_ratio) & \
                (remaining_after_fit <= wasteful_threshold_bin_ratio)

    # Use a less steep decay, like a scaled reciprocal or power function.
    # We use a function that interpolates between tight and wasteful behaviors.
    scores[good_mask] = 100.0 / (1.0 + 2.0 * np.sqrt(remaining_after_fit[good_mask]))


    # 4. Wasteful Fits: Significantly penalized.
    # These bins have remaining space significantly larger than the item and/or bin capacity.
    wasteful_mask = ~perfect_mask & ~tight_mask & \
                    (remaining_after_fit > wasteful_threshold_item_ratio) | \
                    (remaining_after_fit > wasteful_threshold_bin_ratio)

    # Penalize based on how much excess space is left, normalized.
    # The penalty should increase more aggressively as the "wastefulness" increases.
    # Using a rational function that decays, but with a stronger initial decay.
    # The penalty term is subtracted from a base score to create negative priorities that get clamped to 0.
    base_score = 50.0
    # Penalty increases with the ratio of wasted space to remaining capacity.
    waste_ratio = remaining_after_fit[wasteful_mask] / (fitting_bins_caps[wasteful_mask] + epsilon)
    penalty = base_score * (waste_ratio**2)
    scores[wasteful_mask] = np.maximum(0, base_score - penalty * 5.0) # Ensure scores are non-negative

    # Ensure all calculated scores are non-negative after all calculations.
    scores[scores < 0] = 0

    # Exploration: Add a small amount of random jitter to scores of bins with similar priorities.
    # This helps to break ties randomly and can improve exploration without explicit exploration bonuses.
    # The jitter scale is relative to the maximum possible score to ensure it's a small perturbation.
    exploration_jitter_scale = 0.05
    max_potential_score = 1000.0
    jitter = np.random.uniform(-exploration_jitter_scale * max_potential_score, exploration_jitter_scale * max_potential_score, size=len(scores))
    final_scores = scores + jitter

    # Ensure jitter doesn't make scores negative.
    final_scores[final_scores < 0] = 0

    # Assign the calculated scores to the corresponding bins in the original priority array.
    priorities[can_fit_mask] = final_scores

    return priorities
```
```
