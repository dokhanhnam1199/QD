```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements a refined priority function for online Bin Packing Problem,
    incorporating stochasticity and explicit penalization of overly large remaining capacities.

    The function categorizes fits and assigns scores:
    1. Perfect Fit: Highest score, zero remaining capacity.
    2. Tight Fit: High score, remaining capacity is small but positive and not exceeding item size.
    3. Good Fit: Moderate score, remaining capacity is larger than item size but not excessively so.
    4. Overly Loose Fit: Low score, remaining capacity is very large, potentially indicating wasted space.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    fitting_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    # Define thresholds for categorizing fits. These are relative to the bin's *original* capacity
    # to better capture "overly loose" fits, not just relative to the item.
    # This approach aims to keep bins that are "nearly full" but not "nearly empty" after packing.

    # Threshold for 'tight' fit: bin remaining capacity should be very small relative to bin's total capacity.
    # Let's consider a bin "tight" if its remaining capacity after fitting is less than 10% of its *original* capacity.
    # We need the original capacity. For simplicity in this function, we'll use remaining_after_fit,
    # but a more robust version might have access to original bin capacities or a constant bin size.
    # For now, let's stick to thresholds relative to the *item size* but with a clearer distinction for "overly loose".

    epsilon = 1e-9 # For perfect fits
    tight_fit_upper_bound = item * 1.5 # Bin should not have much more than item size left.
    overly_loose_threshold = item * 5.0 # A bin that has 5x item size left is considered "overly loose".

    # Scores for different fit categories
    perfect_fit_scores = np.zeros_like(remaining_after_fit)
    tight_fit_scores = np.zeros_like(remaining_after_fit)
    good_fit_scores = np.zeros_like(remaining_after_fit)
    overly_loose_scores = np.zeros_like(remaining_after_fit)

    # Assign scores
    # Perfect Fit: highest priority
    perfect_mask = (remaining_after_fit < epsilon)
    perfect_fit_scores[perfect_mask] = 10.0

    # Tight Fit: Prioritize bins that leave little room. Higher score for smaller remaining capacity.
    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_upper_bound)
    # Use inverse of remaining capacity, scaled to avoid very large values for small remaining capacities.
    tight_fit_scores[tight_mask] = 5.0 / (1.0 + remaining_after_fit[tight_mask] * 0.5)

    # Good Fit: Bins with moderate remaining space.
    good_mask = (remaining_after_fit > tight_fit_upper_bound) & (remaining_after_fit <= overly_loose_threshold)
    # Penalize larger remaining capacities within this "good" range.
    good_fit_scores[good_mask] = 2.0 / (1.0 + remaining_after_fit[good_mask] * 0.1)

    # Overly Loose Fit: Penalize bins that leave excessively large remaining capacity.
    overly_loose_mask = (remaining_after_fit > overly_loose_threshold)
    # Assign a significantly lower score, possibly negative, or a very small positive one to just indicate it's usable.
    # We will use a small positive score to differentiate from non-fitting bins but still make them less desirable.
    overly_loose_scores[overly_loose_mask] = 0.1 / (1.0 + remaining_after_fit[overly_loose_mask] * 0.01)


    # Combine scores with weights. Weights reflect preference: Perfect > Tight > Good > Overly Loose.
    # The weights are heuristic and can be tuned.
    combined_scores = (
        perfect_fit_scores * 1.0 +
        tight_fit_scores * 0.8 +
        good_fit_scores * 0.5 +
        overly_loose_scores * 0.1
    )

    # Add a small stochastic component for exploration to all fitting bins.
    # This helps in diversifying bin choices and potentially finding better solutions.
    exploration_factor = 0.15
    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * (1.0 + np.log1p(remaining_after_fit))
    # Scaling random scores slightly with remaining capacity can encourage exploration of less full bins.
    combined_scores += random_scores

    # Assign the calculated scores to the corresponding bins in the original priority array
    priorities[can_fit_mask] = combined_scores

    return priorities
```
