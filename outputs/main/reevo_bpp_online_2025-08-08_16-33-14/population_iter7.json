[
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an enhanced priority function for online Bin Packing Problem,\n    focusing on a more adaptive and nuanced scoring mechanism.\n\n    This version aims to balance the \"best fit\" principle with a consideration\n    for future packing flexibility. It categorizes potential bins and assigns\n    scores that reflect desirability, with tunable parameters.\n\n    Categories and scoring logic:\n    1. Perfect Fit: Remaining capacity is virtually zero. Highest priority.\n    2. Tight Fit: Remaining capacity is small, close to zero but positive.\n                   Prioritized highly, score decreases as remaining capacity increases.\n    3. Good Fit: Remaining capacity is moderate, offering a reasonable space for future items.\n                   Scores decrease, but at a slower rate than tight fits.\n    4. Loose Fit: Remaining capacity is large. Lowest priority among fitting bins,\n                   but still offers a small score to encourage exploration.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n        Bins that cannot fit the item will have a score of 0.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Tunable Parameters ---\n    # Epsilon for floating-point comparisons (perfect fit)\n    epsilon = 1e-9\n\n    # Thresholds for categorizing fits relative to item size.\n    # These can be adjusted for different problem instances.\n    # Example: Tight fit is when remaining capacity is <= 1 * item size.\n    tight_threshold_factor = 1.0\n    # Example: Good fit is when remaining capacity is > 1 * item size and <= 3 * item size.\n    good_threshold_factor = 3.0\n\n    # Weights for each category. Higher weights mean higher priority.\n    # Order: Perfect > Tight > Good > Loose\n    perfect_weight = 10.0\n    tight_weight = 8.0\n    good_weight = 5.0\n    loose_weight = 2.0\n\n    # Scaling factors for scores within categories to ensure scores decrease\n    # as remaining capacity increases within a category.\n    # These are generally inverse relationships, adjusted for non-zero denominators.\n    tight_score_scale = 5.0\n    good_score_scale = 3.0\n    loose_score_scale = 1.0\n\n    # Exploration factor: adds a small random boost to all fitting bins.\n    # Higher values encourage more exploration of different packing options.\n    exploration_factor = 0.15\n\n    # --- Scoring Logic ---\n    tight_threshold = item * tight_threshold_factor\n    good_threshold = item * good_threshold_factor\n\n    # Initialize score components\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    good_fit_scores = np.zeros_like(remaining_after_fit)\n    loose_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fit\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = perfect_weight\n\n    # 2. Tight Fit (0 < remaining_after_fit <= tight_threshold)\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    if np.any(tight_mask):\n        # Score decreases as remaining_after_fit increases\n        tight_fit_scores[tight_mask] = tight_weight / (1.0 + remaining_after_fit[tight_mask] * (tight_score_scale / tight_threshold))\n\n    # 3. Good Fit (tight_threshold < remaining_after_fit <= good_threshold)\n    good_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold)\n    if np.any(good_mask):\n        # Score decreases, but less steeply than tight fits\n        good_fit_scores[good_mask] = good_weight / (1.0 + remaining_after_fit[good_mask] * (good_score_scale / good_threshold))\n\n    # 4. Loose Fit (remaining_after_fit > good_threshold)\n    loose_mask = (remaining_after_fit > good_threshold)\n    if np.any(loose_mask):\n        # Minimal score to encourage exploration, decreases slowly\n        loose_fit_scores[loose_mask] = loose_weight / (1.0 + remaining_after_fit[loose_mask] * (loose_score_scale / (bins_remain_cap.max() - item + 1e-9))) # Normalize by max possible remaining\n\n    # Combine scores with weights\n    combined_scores = (\n        perfect_fit_scores +\n        tight_fit_scores +\n        good_fit_scores +\n        loose_fit_scores\n    )\n\n    # Add exploration component\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign calculated scores to the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 0,
    "obj": 4.527323494216204,
    "SLOC": 47.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved hybrid priority function for online Bin Packing Problem (BPP).\n    This version strictly prioritizes perfect fits, then tight fits (remaining capacity\n    close to the item size), and then \"best fit\" style remaining capacity, while\n    still allowing for exploration.\n\n    Scoring Logic:\n    1. Perfect Fit: remaining capacity is zero. Highest priority.\n    2. Tight Fit: remaining capacity is positive but less than or equal to the item size.\n       Higher priority than other fits, scaled inversely with remaining space.\n    3. Best Fit (remaining): remaining capacity is greater than the item size.\n       Priority decreases as remaining capacity increases.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components\n    epsilon = 1e-9  # For handling perfect fits and avoiding division by zero\n\n    # Initialize scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    best_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fit: Highest priority.\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 100.0  # High fixed score for perfect fits\n\n    # 2. Tight Fit: Prioritize bins that leave little room after packing,\n    #    specifically when remaining capacity is <= item size.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= item)\n    # Score decreases as remaining_after_fit increases within the tight range.\n    # Use inverse relationship: 1 / (1 + remaining_space). A larger remaining space means lower score.\n    # Adding a small constant to the denominator to avoid issues if remaining_after_fit is very close to 0.\n    tight_fit_scores[tight_mask] = 10.0 / (1.0 + remaining_after_fit[tight_mask])\n\n    # 3. Best Fit (remaining): For bins where remaining capacity is > item size.\n    #    Priority decreases as remaining capacity increases.\n    best_fit_mask = (remaining_after_fit > item)\n    # Use a decaying function. (1 / (1 + remaining_space)).\n    # This gives higher scores to bins with less remaining space among this category.\n    best_fit_scores[best_fit_mask] = 5.0 / (1.0 + remaining_after_fit[best_fit_mask])\n\n    # Combine scores using weights to reflect the priority order: Perfect > Tight > Best Fit\n    combined_scores = (\n        perfect_fit_scores * 1.0 +  # Max weight for perfect fits\n        tight_fit_scores * 0.7 +    # Significant weight for tight fits\n        best_fit_scores * 0.3       # Lower weight for general best fits\n    )\n\n    # Add a small random component for exploration to all fitting bins\n    # This helps in breaking ties and exploring less obvious choices occasionally.\n    exploration_factor = 0.05\n    # Scale random score by the maximum possible score to maintain relative priorities.\n    max_possible_score = 100.0 + (10.0 / (1.0 + epsilon)) * 0.7 + (5.0 / (1.0 + item)) * 0.3\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * max_possible_score\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 1,
    "obj": 2.911846828879143,
    "SLOC": 29.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem,\n    prioritizing exact fits, then tighter fits, and penalizing overly large\n    remaining capacities. Includes a small random component for exploration.\n\n    Scoring logic:\n    1. Exact Fit: Highest priority (e.g., score of 1.0).\n    2. Tight Fit: Prioritize bins leaving minimal remaining capacity (e.g., inverse of remaining capacity).\n    3. Moderate Fit: Prioritize bins leaving some space, but less than loose fits.\n    4. Loose Fit: Lowest priority, but still assign a small positive score.\n    5. Exploration: Add a small random value to break ties and encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components based on remaining capacity after fit.\n    epsilon = 1e-9\n\n    # 1. Exact Fit: Highest priority\n    # Bins where remaining capacity is practically zero after fitting the item.\n    exact_fit_mask = (remaining_after_fit < epsilon)\n    priorities[can_fit_mask][exact_fit_mask] = 1.0\n\n    # 2. Tight Fit: Prioritize bins leaving minimal remaining capacity\n    # Remaining capacity is small but positive. Score is inversely proportional to remaining capacity.\n    tight_fit_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= item * 0.5) # Threshold for \"tight\"\n    # Use a scaled inverse to give higher scores to smaller remaining capacities.\n    # Add a small constant to the denominator to avoid division by zero and to\n    # differentiate scores for very small remaining capacities.\n    priorities[can_fit_mask][tight_fit_mask] = 0.8 / (remaining_after_fit[tight_fit_mask] + epsilon)\n\n    # 3. Moderate Fit: Prioritize bins leaving some space, but not excessive.\n    # Remaining capacity is larger than tight fit threshold.\n    moderate_fit_mask = (remaining_after_fit > item * 0.5) & (remaining_after_fit <= item * 2.0) # Threshold for \"moderate\"\n    # Lower scores than tight fits, still inversely related to remaining capacity.\n    priorities[can_fit_mask][moderate_fit_mask] = 0.4 / (remaining_after_fit[moderate_fit_mask] + epsilon)\n\n    # 4. Loose Fit: Lowest priority, but still assign a small positive score.\n    # Remaining capacity is significantly larger than the item.\n    loose_fit_mask = (remaining_after_fit > item * 2.0)\n    # Assign a small constant score to encourage exploration of these bins if others are not ideal.\n    priorities[can_fit_mask][loose_fit_mask] = 0.1\n\n    # 5. Exploration: Add a small random component to break ties and encourage exploration.\n    exploration_factor = 0.05 # Reduced exploration factor\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    priorities[can_fit_mask] += random_scores\n\n    # Ensure no score exceeds the highest priority (e.g., 1.0 plus random)\n    priorities[can_fit_mask] = np.minimum(priorities[can_fit_mask], 1.0 + exploration_factor)\n\n    return priorities",
    "response_id": 2,
    "obj": 73.39449541284404,
    "SLOC": 23.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined strategy.\n\n    This strategy prioritizes bins that are a \"good fit\" for the item,\n    meaning the remaining capacity after placing the item is small but not\n    excessively so (to avoid over-packing). It also gives a slight bonus\n    for bins that become exactly full.\n\n    The priority is calculated as:\n    1. For bins that can fit the item:\n       - Calculate `remaining_after_fit = bins_remain_cap - item`.\n       - If `remaining_after_fit` is very close to zero (perfect fit), assign a high score.\n       - If `remaining_after_fit` is small but positive (tight fit), assign a high score,\n         inversely proportional to `remaining_after_fit`.\n       - If `remaining_after_fit` is larger, assign a lower score.\n       - Penalize bins that become *too* full after placing the item, e.g.,\n         if `remaining_after_fit` is negative (which shouldn't happen if `can_fit_mask` is correct,\n         but as a conceptual extension).\n\n    A scoring function is designed to favor smaller `remaining_after_fit`,\n    with a special high score for `remaining_after_fit` close to zero,\n    and a decay for larger `remaining_after_fit`.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    epsilon = 1e-9  # For handling near-zero remaining capacities\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # If no bin can fit, return scores that reflect no valid placement\n        return scores\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Priority Calculation:\n    # We want higher scores for smaller remaining_after_fit.\n    # Exact fits (remaining_after_fit near 0) should have the highest priority.\n    # Tight fits (small positive remaining_after_fit) should be next.\n    # Loose fits (larger remaining_after_fit) should have lower priority.\n\n    # Strategy: Use a score that is inversely proportional to (remaining_after_fit + epsilon)\n    # to favor smaller values. Add a bonus for exact fits.\n    # Let's use `1.0 / (remaining_after_fit + epsilon)` as a base.\n    # For exact fits (remaining_after_fit near 0), this value will be large.\n    # For tight fits, it will be slightly smaller.\n    # For loose fits, it will be much smaller.\n\n    # A potential issue: very small remaining_after_fit could lead to huge scores.\n    # We can cap the score or use a function that saturates.\n    # Alternatively, we can define categories.\n\n    # Let's try a tiered approach:\n    # 1. Perfect/Exact Fit: remaining_after_fit < epsilon\n    # 2. Tight Fit: epsilon <= remaining_after_fit <= item_size * tightness_factor\n    # 3. Good Fit: item_size * tightness_factor < remaining_after_fit <= item_size * good_factor\n    # 4. Loose Fit: remaining_after_fit > item_size * good_factor\n\n    # Scoring:\n    # Perfect Fit: Highest score (e.g., 100)\n    # Tight Fit: High score, inversely proportional to remaining_after_fit. Add a small penalty for being *too* tight.\n    # Good Fit: Medium score, inversely proportional to remaining_after_fit.\n    # Loose Fit: Low score.\n\n    # Defining factors for categorization\n    tightness_factor = 1.5  # Bins remaining capacity up to 1.5 * item size are considered \"tight\"\n    good_fit_factor = 3.0   # Bins remaining capacity up to 3.0 * item size are considered \"good\"\n\n    # Calculate base score for all fitting bins: inverse of remaining capacity + epsilon\n    # This favors smaller remaining capacity.\n    # Adding `epsilon` to avoid division by zero and ensure even zero remaining gets a score.\n    base_scores = 1.0 / (remaining_after_fit + epsilon)\n\n    # Adjust scores based on categories:\n    # Perfect fits get a significant bonus.\n    # Tight fits get a good score.\n    # Good fits get a moderate score.\n    # Loose fits get a low score.\n\n    # Create score adjustments for each category\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    tight_fit_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= tightness_factor * item)\n    good_fit_mask = (remaining_after_fit > tightness_factor * item) & (remaining_after_fit <= good_fit_factor * item)\n    loose_fit_mask = (remaining_after_fit > good_fit_factor * item)\n\n    # Assign base scores and then modify for category\n    category_scores = np.zeros_like(remaining_after_fit)\n\n    # Perfect Fit: Highest priority\n    category_scores[perfect_fit_mask] = 100.0\n    # Add the base score here to give some preference within perfect fits if epsilon is not exactly 0\n    category_scores[perfect_fit_mask] += base_scores[perfect_fit_mask]\n\n    # Tight Fit: Prioritize, but scale down from perfect.\n    # Use base score and scale it. A factor of 0.7 for example.\n    category_scores[tight_fit_mask] = base_scores[tight_fit_mask] * 0.8\n\n    # Good Fit: Lower priority than tight.\n    category_scores[good_fit_mask] = base_scores[good_fit_mask] * 0.4\n\n    # Loose Fit: Lowest priority.\n    category_scores[loose_fit_mask] = base_scores[loose_fit_mask] * 0.1\n\n    # Ensure perfect fits remain dominant, even if base_scores are low for other categories.\n    # If remaining_after_fit is very small, base_scores can be very large.\n    # We need to ensure that smaller *positive* remaining_after_fit is better.\n    # The current `base_scores = 1.0 / (remaining_after_fit + epsilon)` already does this.\n\n    # Let's refine the scoring for tight and good fits to be more directly based on remaining capacity.\n    # We want smaller remaining_after_fit to be better.\n    # For tight fits: Priority = C1 - C2 * remaining_after_fit\n    # For good fits: Priority = C3 - C4 * remaining_after_fit (with C3, C4 smaller than C1, C2)\n\n    # Let's use a simple piecewise scoring:\n    final_fitting_scores = np.zeros_like(remaining_after_fit)\n\n    # Perfect Fit: Very high score for bins that leave almost no space.\n    perfect_fit_bonus = 1000.0\n    final_fitting_scores[perfect_fit_mask] = perfect_fit_bonus + (epsilon - remaining_after_fit[perfect_fit_mask])\n\n    # Tight Fit: Prefer smaller remaining capacity. A linear decay from a high value.\n    # Let's set a maximum score for tight fits and linearly decrease it.\n    max_tight_score = 500.0\n    # Scale remaining_after_fit relative to item size for linear decay.\n    # The slope determines how quickly priority drops.\n    # We want priority to be high when remaining_after_fit is small, and lower as it approaches tightness_factor * item.\n    slope_tight = (max_tight_score - 50.0) / (tightness_factor * item + epsilon) # Ensure slope is reasonable\n    final_fitting_scores[tight_fit_mask] = max_tight_score - slope_tight * remaining_after_fit[tight_fit_mask]\n\n    # Good Fit: Similar logic but with lower scores and potentially shallower slope.\n    max_good_score = 100.0\n    slope_good = (max_good_score - 10.0) / (good_fit_factor * item - tightness_factor * item + epsilon)\n    final_fitting_scores[good_fit_mask] = max_good_score - slope_good * remaining_after_fit[good_fit_mask]\n\n    # Loose Fit: Very low score, possibly just a small constant.\n    final_fitting_scores[loose_fit_mask] = 10.0 - (remaining_after_fit[loose_fit_mask] / (item + epsilon)) * 5.0 # Penalize larger remaining\n\n    # Clip scores to be non-negative and ensure they don't go below a minimum.\n    final_fitting_scores = np.maximum(final_fitting_scores, 0.1) # Ensure some minimal priority\n\n    # Assign the computed priorities to the fitting bins\n    scores[can_fit_mask] = final_fitting_scores\n\n    return scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 35.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem.\n\n    This heuristic aims to balance several objectives:\n    1. **Tight Fit (Best Fit):** Prioritize bins that leave the minimum remaining capacity\n       after packing the item. This minimizes wasted space in the short term.\n    2. **Avoid Over-Saturation (Penalty):** Penalize bins that will have very little\n       remaining capacity after packing. This prevents a bin from becoming unusable\n       for even small future items.\n    3. **Encourage Exploration (Boost):** Provide a slight boost to bins that will have\n       a moderate amount of remaining capacity. This encourages utilizing a wider\n       range of bins, potentially leading to better overall packing.\n\n    The function calculates priority scores for bins that can fit the item. Bins that\n    cannot fit the item receive a score of 0.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element is the remaining capacity\n                         of a bin.\n\n    Returns:\n        A numpy array of the same size as `bins_remain_cap`, containing the priority\n        score for each bin. Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the current item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item, return all zeros.\n\n    # Get the remaining capacities of bins that can fit the item\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Priority Components ---\n\n    # 1. Tight Fit Score (Inverse of remaining capacity + epsilon to avoid division by zero)\n    # Higher score for smaller remaining_after_fit.\n    tight_fit_scores = 1.0 / (remaining_after_fit + 1e-9)\n\n    # 2. Over-Saturation Penalty\n    # Penalize bins where remaining_after_fit is very small.\n    # Define \"very small\" as a fraction of the item size, e.g., less than 10% of item size.\n    # The penalty should be more severe for smaller remaining capacities.\n    penalty_threshold = 0.1 * item\n    penalty_scores = np.zeros_like(fitting_bins_caps)\n\n    # Apply penalty to bins that are nearly full\n    nearly_full_mask = (remaining_after_fit > 0) & (remaining_after_fit <= penalty_threshold)\n    if np.any(nearly_full_mask):\n        # Calculate penalty: -1 for the smallest remaining capacity, 0 for the threshold.\n        # This penalizes bins that are *really* full more heavily.\n        penalty_scores[nearly_full_mask] = -1.0 * (1.0 - (remaining_after_fit[nearly_full_mask] / penalty_threshold))\n\n    # 3. Exploration Boost\n    # Boost bins that leave a moderate amount of space. This space should be\n    # at least the size of the item itself, but not excessively large.\n    # Let's define the boost range from `item` to `2 * item` remaining capacity.\n    boost_min_remaining = item\n    boost_max_remaining = 3 * item  # Tunable parameter\n    exploration_scores = np.zeros_like(fitting_bins_caps)\n\n    boost_mask = (remaining_after_fit > boost_min_remaining) & (remaining_after_fit <= boost_max_remaining)\n    if np.any(boost_mask):\n        # The boost is highest when remaining_after_fit is close to boost_min_remaining\n        # and decreases as it approaches boost_max_remaining.\n        # Normalize the remaining capacity within the boost range.\n        normalized_remaining = (remaining_after_fit[boost_mask] - boost_min_remaining) / (boost_max_remaining - boost_min_remaining)\n        # Invert the normalized value to give higher boost to smaller remaining capacities in this range.\n        exploration_scores[boost_mask] = 0.5 * (1.0 - normalized_remaining) # Tunable boost strength\n\n    # --- Combine Scores ---\n    # Assign weights to balance the strategies.\n    # Tight fit is the primary driver, penalty reduces priority for near-full bins,\n    # exploration boost slightly increases priority for moderately spacious bins.\n    combined_scores = (1.0 * tight_fit_scores) + penalty_scores + exploration_scores\n\n    # Assign the calculated scores to the corresponding bins in the main priorities array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 24.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response5.txt_stdout.txt",
    "code_path": "problem_iter6_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for online Bin Packing Problem,\n    prioritizing tight fits and using simpler, well-defined thresholds.\n\n    The function assigns scores to bins based on how well they fit an item:\n    1. Perfect Fit: Bin's remaining capacity is exactly zero after packing. Highest priority.\n    2. Tight Fit: Bin's remaining capacity after packing is small (<= item size). High priority.\n    3. Moderate Fit: Bin's remaining capacity after packing is larger than item size but not excessively so (<= 2 * item size). Medium priority.\n    4. Loose Fit: Bin's remaining capacity after packing is large (> 2 * item size). Lowest priority.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for the corresponding bin. Higher scores indicate\n        higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds for categorizing fits relative to the item size\n    epsilon = 1e-9  # For floating-point comparisons, especially for perfect fits\n    tight_threshold = item\n    moderate_threshold = 2.0 * item\n\n    # Initialize scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    moderate_fit_scores = np.zeros_like(remaining_after_fit)\n    loose_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # Calculate scores for each category:\n    # Perfect Fit: Highest score, indicating minimal waste.\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 10.0\n\n    # Tight Fit: Prioritize bins that leave little remaining capacity after packing.\n    # Score is inversely proportional to the remaining capacity, encouraging fuller bins.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    tight_fit_scores[tight_mask] = 5.0 / (1.0 + remaining_after_fit[tight_mask])\n\n    # Moderate Fit: Bins that leave a moderate amount of space.\n    # Score decreases as remaining capacity increases, but less steeply than tight fits.\n    moderate_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= moderate_threshold)\n    moderate_fit_scores[moderate_mask] = 2.0 / (1.0 + remaining_after_fit[moderate_mask])\n\n    # Loose Fit: Bins that leave a significant amount of space.\n    # These are less preferred, so they receive a low base score.\n    loose_mask = (remaining_after_fit > moderate_threshold)\n    loose_fit_scores[loose_mask] = 1.0 / (1.0 + remaining_after_fit[loose_mask])\n\n    # Combine scores using weights to reflect the priority order: Perfect > Tight > Moderate > Loose.\n    # Weights are tuned to emphasize tighter fits.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.8 +\n        moderate_fit_scores * 0.5 +\n        loose_fit_scores * 0.2\n    )\n\n    # Add a small stochastic component for exploration.\n    # This helps in occasional selection of less optimal bins, potentially leading to better overall packing.\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 5,
    "obj": 4.038691663342641,
    "SLOC": 35.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response6.txt_stdout.txt",
    "code_path": "problem_iter6_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved hybrid priority function for online Bin Packing Problem.\n    This version refines the scoring by categorizing fits and using a more\n    nuanced approach to score within categories, while also incorporating\n    an element of randomness for exploration.\n\n    Categories and Scoring Logic:\n    1. Perfect Fit (remaining_after_fit = 0): Highest priority. Score is a high constant.\n    2. Tight Fit (0 < remaining_after_fit <= item): Prioritize bins that leave minimal space.\n       Score is inversely proportional to remaining capacity, scaled for high importance.\n    3. Moderate Fit (item < remaining_after_fit <= 2*item): Prioritize bins that leave some space,\n       but not too much. Score is inversely proportional to remaining capacity, with a moderate scale.\n    4. Loose Fit (remaining_after_fit > 2*item): Lowest priority among fitting bins.\n       Score is inversely proportional to remaining capacity, scaled low, to still encourage\n       using larger bins if no better options exist, but with less preference.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Get remaining capacities only for bins that can fit the item\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Scoring Logic ---\n    epsilon = 1e-9 # For handling perfect fits and numerical stability\n\n    # Define score components\n    scores = np.zeros_like(remaining_after_fit, dtype=float)\n\n    # Category 1: Perfect Fit (remaining_after_fit is almost zero)\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    scores[perfect_fit_mask] = 100.0 # Highest priority\n\n    # Category 2: Tight Fit (0 < remaining_after_fit <= item)\n    tight_fit_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= item)\n    if np.any(tight_fit_mask):\n        # Prioritize smaller remaining capacity within this category\n        # Higher score for smaller denominator (1 + remaining)\n        scores[tight_fit_mask] = 10.0 / (1.0 + remaining_after_fit[tight_fit_mask])\n\n    # Category 3: Moderate Fit (item < remaining_after_fit <= 2*item)\n    moderate_fit_mask = (remaining_after_fit > item) & (remaining_after_fit <= 2.0 * item)\n    if np.any(moderate_fit_mask):\n        # Moderate priority, still inversely proportional to remaining capacity\n        scores[moderate_fit_mask] = 5.0 / (1.0 + remaining_after_fit[moderate_fit_mask])\n\n    # Category 4: Loose Fit (remaining_after_fit > 2*item)\n    loose_fit_mask = (remaining_after_fit > 2.0 * item)\n    if np.any(loose_fit_mask):\n        # Lower priority, but still inversely proportional\n        scores[loose_fit_mask] = 1.0 / (1.0 + remaining_after_fit[loose_fit_mask])\n\n    # --- Exploration Component ---\n    exploration_factor = 0.05 # Small random noise to encourage exploring different bins\n    random_scores = np.random.rand(len(remaining_after_fit)) * exploration_factor * (1 + scores) # Scale noise with existing score\n    \n    # Add exploration to all fitting bins\n    scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = scores\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 26.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response7.txt_stdout.txt",
    "code_path": "problem_iter6_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem.\n    This version focuses on prioritizing bins that offer a tight fit without\n    over-packing, while also considering bins that leave a moderate amount of space.\n    It introduces a penalty for bins that become excessively full after packing,\n    making them prone to waste.\n\n    Scoring logic:\n    1. Perfect Fit: Highest priority.\n    2. Tight Fit (leaves minimal positive remaining capacity): High priority,\n       inversely proportional to remaining capacity.\n    3. Good Fit (leaves moderate remaining capacity): Moderate priority,\n       prioritizing bins that leave less space within this category.\n    4. Loose Fit (leaves large remaining capacity): Lowest priority among fitting bins.\n\n    A penalty is applied to bins where the remaining capacity after packing is\n    very small (e.g., less than 10% of the item size or a small absolute value),\n    as these are prone to over-packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define constants for scoring and penalty\n    epsilon = 1e-9  # For considering near-zero remaining capacity\n    \n    # Penalty threshold: If remaining capacity is less than this, apply a penalty.\n    # This is set to be a fraction of the item size, to avoid over-packing\n    # relative to the item being placed. A small absolute fallback is also considered.\n    penalty_threshold_relative = 0.1 * item\n    penalty_threshold_absolute = 0.05  # Ensure a minimum penalty threshold\n    penalty_threshold = max(penalty_threshold_relative, penalty_threshold_absolute)\n\n    # Calculate base scores, favoring smaller remaining capacity.\n    # Use a function like 1/(1+x) which gives higher scores for smaller x.\n    # Add epsilon to denominator to prevent division by zero.\n    base_scores = 1.0 / (1.0 + remaining_after_fit + epsilon)\n\n    # Calculate penalty scores for bins that are too full.\n    # The penalty is higher when remaining_after_fit is smaller (closer to zero).\n    # Penalize bins where remaining_after_fit < penalty_threshold.\n    penalty_scores = np.zeros_like(remaining_after_fit)\n    too_full_mask = remaining_after_fit < penalty_threshold\n    \n    # The penalty magnitude should be inversely proportional to how far above\n    # the threshold the remaining capacity is. For values below the threshold,\n    # a larger \"deficit\" leads to a higher penalty.\n    # Scale penalty to be significant but not overwhelming.\n    penalty_magnitude_scale = 0.7 # Controls how strongly the penalty affects the score.\n    if np.any(too_full_mask):\n        penalty_scores[too_full_mask] = penalty_magnitude_scale * (\n            1.0 - (remaining_after_fit[too_full_mask] / penalty_threshold)\n        )\n\n    # Combine base scores with penalties. A higher base score (good fit) is reduced\n    # if the bin is deemed \"too full\".\n    combined_scores = base_scores - penalty_scores\n\n    # Ensure scores are non-negative.\n    combined_scores = np.maximum(0, combined_scores)\n\n    # Further refinement: Add a slight boost to bins that are \"just right\" -\n    # not perfectly full, but with a small positive remaining capacity.\n    # This encourages leaving a small, usable gap.\n    # Define a target \"ideal\" remaining capacity, e.g., a small fraction of the item.\n    ideal_remaining_target = 0.2 * item\n    ideal_remaining_target = max(ideal_remaining_target, epsilon * 10) # Ensure it's positive and small\n\n    # A Gaussian-like boost centered around the ideal target could work.\n    # For simplicity, let's add a small boost if remaining_after_fit is close to ideal.\n    boost_factor = 0.1\n    # Boost for bins that are close to the ideal remaining capacity.\n    # The closer, the higher the boost.\n    boost_mask = np.abs(remaining_after_fit - ideal_remaining_target) < (ideal_remaining_target * 0.5)\n    \n    if np.any(boost_mask):\n        boost_scores = boost_factor * (1.0 - np.abs(remaining_after_fit[boost_mask] - ideal_remaining_target) / (ideal_remaining_target * 0.5))\n        combined_scores[boost_mask] += boost_scores\n\n\n    # Add a small random perturbation for exploration and tie-breaking.\n    exploration_noise_scale = 0.05\n    exploration_noise = np.random.normal(0, exploration_noise_scale, len(fitting_bins_caps))\n    combined_scores += exploration_noise\n    \n    # Ensure final priorities are non-negative after adding noise.\n    combined_scores = np.maximum(0, combined_scores)\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 7,
    "obj": 19.525329078579972,
    "SLOC": 36.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response8.txt_stdout.txt",
    "code_path": "problem_iter6_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem.\n    This version prioritizes tight fits, penalizes wasted space effectively,\n    and uses adaptive thresholds to better handle varying item and bin sizes.\n\n    The priority is calculated as follows:\n    1. Bins that cannot fit the item get a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.\n       b. Tight Fits (remaining capacity after packing is small): High priority,\n          inversely proportional to the remaining capacity. This encourages filling\n          bins as much as possible.\n       c. Moderate Fits: Priority decreases as remaining capacity increases,\n          but at a slower rate than tight fits.\n       d. Wasteful Fits (remaining capacity after packing is large): Significantly\n          penalized to discourage using bins that would leave substantial empty space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds adaptively\n    epsilon = 1e-9\n    \n    # Threshold for \"tight\" fits: remaining space is less than the item size.\n    # This encourages using bins that are already somewhat filled.\n    tight_fit_threshold = item\n\n    # Threshold for \"wasteful\" fits: remaining space is significantly larger than item size.\n    # A good heuristic is to consider bins where the remaining space is more than, say,\n    # twice the item size, or a significant fraction of the *potential* remaining space\n    # if a large item were placed. Let's use a factor of the item size.\n    # We also consider the maximum possible remaining capacity for normalization.\n    max_potential_remaining = np.max(bins_remain_cap) - item if np.max(bins_remain_cap) >= item else 0\n    \n    # A threshold that is sensitive to item size and bin capacity.\n    # If bins are generally large, we might tolerate larger remaining gaps for non-wasteful bins.\n    # Let's use a blend: it's \"wasteful\" if remaining_after_fit is large relative to item size,\n    # OR if it's a large fraction of the *total* capacity.\n    # For simplicity and directness, we'll use a threshold relative to item size,\n    # but also consider how much space is left relative to the bin's *initial* capacity\n    # (which we don't have here). So, relying on remaining_after_fit is key.\n    # Let's consider `remaining_after_fit > C * item` and `remaining_after_fit > D * max_potential_remaining`.\n    # For this version, let's simplify the \"wasteful\" threshold to focus on the remaining space\n    # relative to the item size, aiming to avoid bins that are still mostly empty.\n    # A threshold like 3 * item size seems reasonable to start.\n    wasteful_threshold = 3.0 * item\n\n    # Calculate scores\n    scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = 1000.0\n\n    # 2. Tight Fits: High priority, inversely proportional to remaining capacity\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    # Use a steep decay function like 1/(1+x) or 1/(1+x^2)\n    scores[tight_mask] = 50.0 / (1.0 + remaining_after_fit[tight_mask] * 5.0) # Scaled to give good range\n\n    # 3. Moderate Fits: Priority decreases with remaining capacity, but less steeply\n    moderate_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)\n    # A less steep decay, e.g., 1/(1+sqrt(x)) or 1/(1+x^0.7)\n    scores[moderate_mask] = 20.0 / (1.0 + np.sqrt(remaining_after_fit[moderate_mask]))\n\n    # 4. Wasteful Fits: Significantly penalized\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Penalize based on how much excess space is left.\n    # The penalty should be substantial to deter selection.\n    # We can use a linear penalty that starts at 0 at the threshold and increases.\n    # Penalty = P * (remaining_after_fit - wasteful_threshold) / (max_possible_remaining + epsilon)\n    # Normalize penalty by item size to keep it somewhat scale-invariant.\n    penalty_factor = 5.0 # Controls the magnitude of the penalty\n    scores[wasteful_mask] = 10.0 / (1.0 + remaining_after_fit[wasteful_mask] / item) # Start with a base score, then penalize\n    penalty = penalty_factor * (remaining_after_fit[wasteful_mask] - wasteful_threshold) / (item + epsilon)\n    scores[wasteful_mask] -= penalty\n\n    # Ensure scores are non-negative\n    scores[scores < 0] = 0\n\n    # Add a small random jitter for exploration to prevent all scores from being identical\n    # for multiple bins with similar fit characteristics.\n    exploration_factor = 0.05\n    jitter = np.random.rand(len(scores)) * exploration_factor * np.max(scores + epsilon)\n    final_scores = scores + jitter\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 8,
    "obj": 2.2736338252891857,
    "SLOC": 31.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response9.txt_stdout.txt",
    "code_path": "problem_iter6_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved hybrid priority function for online Bin Packing Problem.\n    This version prioritizes perfect fits, then tight fits, and finally good fits,\n    while incorporating an exploration mechanism.\n\n    Priority Hierarchy:\n    1. Perfect Fit: Bin's remaining capacity is exactly zero after placement. Highest priority.\n    2. Tight Fit: Bin's remaining capacity after placement is small (<= item size). High priority, inversely proportional to remaining capacity.\n    3. Good Fit: Bin's remaining capacity after placement is moderate (> item size and <= 2 * item size). Medium priority, inversely proportional to remaining capacity.\n    4. Loose Fit: Bin's remaining capacity after placement is large (> 2 * item size). Lowest priority among fitting bins, but still offers a base score.\n\n    An exploration bonus is added to all bins that can fit the item to encourage\n    diversification and avoid getting stuck in local optima.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.\n\n    Returns:\n        A NumPy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n        Bins that cannot fit the item will have a priority score of 0.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Tolerance for floating-point comparisons, especially for perfect fits\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item, return all zeros\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define scoring for different fit categories\n    perfect_fit_score = 100.0\n    tight_fit_base_score = 10.0\n    good_fit_base_score = 5.0\n    loose_fit_base_score = 1.0\n\n    # Thresholds for categorizing fits relative to the item size\n    tight_threshold = item\n    good_threshold = 2.0 * item\n\n    # Calculate scores for fitting bins\n    scores = np.zeros_like(fitting_bins_caps, dtype=float)\n\n    # 1. Perfect Fit: Highest priority\n    perfect_mask = np.abs(remaining_after_fit) < epsilon\n    scores[perfect_mask] = perfect_fit_score\n\n    # 2. Tight Fit: Prioritize bins that leave little room after the perfect fits are handled.\n    # Score is inversely proportional to remaining capacity to favor tighter packing.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    if np.any(tight_mask):\n        scores[tight_mask] = tight_fit_base_score / (1.0 + remaining_after_fit[tight_mask])\n\n    # 3. Good Fit: Bins that fit the item but leave more space than tight fits.\n    # Score is also inversely proportional but with a lower base score.\n    good_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold)\n    if np.any(good_mask):\n        scores[good_mask] = good_fit_base_score / (1.0 + remaining_after_fit[good_mask])\n\n    # 4. Loose Fit: Bins that fit the item but leave a significant amount of space.\n    # These get a minimal score to still be considered if other options are worse.\n    loose_mask = remaining_after_fit > good_threshold\n    if np.any(loose_mask):\n        scores[loose_mask] = loose_fit_base_score / (1.0 + remaining_after_fit[loose_mask])\n\n    # Add a small, uniform exploration bonus to all fitting bins to encourage diversity.\n    # This is a fixed small value added to all fitting bins, making them slightly\n    # more likely to be chosen and breaking ties.\n    exploration_bonus = 0.1\n    scores += exploration_bonus\n\n    # Assign calculated scores to the 'priorities' array for the fitting bins\n    priorities[can_fit_mask] = scores\n\n    return priorities",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 32.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem,\n    focusing on tighter fits and stronger penalties for wasted space.\n\n    Priority calculation:\n    1. Bins that cannot fit the item get a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.\n       b. Tight Fits (small remaining capacity): High priority, decreasing quadratically\n          with remaining capacity to favor very snug fits.\n       c. Moderate Fits (medium remaining capacity): Moderate priority, decreasing\n          linearly with remaining capacity.\n       d. Wasteful Fits (large remaining capacity): Significantly penalized to strongly\n          discourage selection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds adaptively based on item size\n    epsilon = 1e-9\n    \n    # Threshold for \"tight\" fits: remaining space is close to zero.\n    # Let's define tight as less than or equal to 10% of the item size.\n    tight_fit_threshold = 0.1 * item\n\n    # Threshold for \"wasteful\" fits: remaining space is significantly larger than item size.\n    # Let's define wasteful as more than 2 times the item size.\n    wasteful_threshold = 2.0 * item\n\n    # Calculate scores\n    scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = 100.0\n\n    # 2. Tight Fits: High priority, decreasing quadratically with remaining capacity\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    # Score: higher for smaller remaining_after_fit\n    # Using 1 / (1 + k*x^2) where k=5 to emphasize very small remaining spaces.\n    scores[tight_mask] = 80.0 * (1.0 / (1.0 + 5.0 * remaining_after_fit[tight_mask]**2))\n\n    # 3. Moderate Fits: Priority decreases linearly with remaining capacity\n    moderate_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)\n    # Score: higher for smaller remaining_after_fit\n    # Using 1 / (1 + k*x) where k=1 for a linear decay.\n    scores[moderate_mask] = 50.0 * (1.0 / (1.0 + remaining_after_fit[moderate_mask]))\n\n    # 4. Wasteful Fits: Significantly penalized\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Penalize based on how much excess space is left relative to item size.\n    # The penalty should be substantial to deter selection.\n    # Penalty = base_penalty + factor * (excess_space / item_size)\n    # The score will be negative.\n    scores[wasteful_mask] = -10.0 - 15.0 * (remaining_after_fit[wasteful_mask] / (item + epsilon))\n\n    # Ensure scores are non-negative for non-penalized categories, though wasteful can be negative.\n    # Scores for perfect, tight, moderate should ideally stay positive.\n    scores[tight_mask & (scores < 0)] = 0 # Should not happen with current formula, but good safety.\n    scores[moderate_mask & (scores < 0)] = 0\n\n    # Add a small random jitter for exploration. This helps break ties and explore.\n    exploration_factor = 0.05 # Jitter is 5% of the maximum possible score range (approx).\n    # Max score is 100, min can be negative. Let's base jitter on potential positive range.\n    max_positive_score = 100.0\n    jitter = np.random.rand(len(scores)) * exploration_factor * max_positive_score\n    final_scores = scores + jitter\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 0,
    "obj": 4.427602712405275,
    "SLOC": 29.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response1.txt_stdout.txt",
    "code_path": "problem_iter7_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for the online Bin Packing Problem.\n    This version prioritizes perfect fits, then tight fits, and penalizes\n    bins that leave a disproportionately large amount of space unused relative\n    to their original remaining capacity.\n\n    The priority for a fitting bin is calculated based on:\n    1. Minimizing the absolute remaining space.\n    2. Maximizing the efficiency of the fit (item size relative to bin's initial remaining capacity).\n    3. Penalizing bins where the final remaining space is a large proportion of the initial remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # For numerical stability\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Extract capacities and calculate remaining space for fitting bins\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Scoring Calculation ---\n    scores_for_fitting_bins = np.zeros_like(fitting_bins_caps, dtype=float)\n\n    # 1. Perfect Fits: Highest priority\n    perfect_mask = remaining_after_fit < epsilon\n    scores_for_fitting_bins[perfect_mask] = 1000.0\n\n    # 2. Other Fits: Combine minimizing remaining space, efficiency, and waste penalty\n    non_perfect_mask = ~perfect_mask\n    \n    if np.any(non_perfect_mask):\n        # Get data for non-perfect fits\n        rem_non_perfect = remaining_after_fit[non_perfect_mask]\n        orig_rem_non_perfect = fitting_bins_caps[non_perfect_mask]\n\n        # Base score: Inversely proportional to absolute remaining space (favors tighter fits)\n        # E.g., 1 / (rem_i + epsilon)\n        base_score_tightness = 1.0 / (rem_non_perfect + epsilon)\n\n        # Efficiency factor: Item size relative to bin's initial remaining capacity.\n        # High value means item uses a good portion of the available space in that bin.\n        # E.g., item / orig_rem_i\n        efficiency_factor = item / orig_rem_non_perfect\n\n        # Waste ratio: Proportion of bin's initial remaining capacity left unused.\n        # E.g., rem_i / orig_rem_i. We want to penalize high values of this.\n        waste_ratio = rem_non_perfect / orig_rem_non_perfect\n\n        # Combine scores:\n        # Start with tightness score, boost with efficiency, then penalize waste.\n        # Weights and thresholds are tunable parameters.\n        \n        # Tunable parameters:\n        efficiency_weight = 1.0\n        waste_penalty_weight = 10.0\n        waste_threshold_ratio = 0.3 # Penalize if more than 30% of bin's initial capacity is left.\n\n        # Calculate scores for non-perfect fits\n        scores_non_perfect = (base_score_tightness * (1.0 + efficiency_factor * efficiency_weight) - \n                              waste_penalty_weight * np.maximum(0, waste_ratio - waste_threshold_ratio))\n        \n        # Ensure scores are non-negative\n        scores_non_perfect[scores_non_perfect < 0] = 0\n        \n        # Assign these scores to the correct positions in scores_for_fitting_bins\n        scores_for_fitting_bins[non_perfect_mask] = scores_non_perfect\n\n    # Assign calculated scores to the original priorities array\n    priorities[can_fit_mask] = scores_for_fitting_bins\n\n    # Add a small random jitter for exploration to break ties and encourage diversity\n    # Jitter is proportional to the average score magnitude to be effective across scales.\n    # Ensure jitter is not too aggressive.\n    average_score = np.mean(priorities[priorities > 0] + epsilon) if np.any(priorities > 0) else 1.0\n    exploration_factor = 0.05 # 5% of average score magnitude\n    jitter = np.random.rand(num_bins) * exploration_factor * average_score\n    \n    # Apply jitter only to bins that can fit the item and have a non-zero priority already.\n    # This prevents introducing spurious priorities for bins that cannot fit.\n    jitter_mask = can_fit_mask # + (priorities > 0) # Consider jittering non-fitting bins too if we want to break ties for them for some reason\n    priorities[jitter_mask] += jitter[jitter_mask]\n    \n    # Ensure no negative priorities after jitter (should not happen with current logic, but good practice)\n    priorities[priorities < 0] = 0\n\n    return priorities",
    "response_id": 1,
    "obj": 16.623454327881937,
    "SLOC": 34.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response2.txt_stdout.txt",
    "code_path": "problem_iter7_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem.\n    This version prioritizes perfect fits, then tight fits, penalizes wasted space,\n    and incorporates an adaptive penalty for suboptimal fits. It also adds a\n    small stochastic element for exploration.\n\n    The priority is calculated as follows:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity is exactly 0 after packing): Highest priority.\n       b. Tight Fits (remaining capacity is small): High priority, inversely proportional\n          to the remaining capacity. Encourages filling bins.\n       c. Moderate Fits: Priority decreases as remaining capacity increases, but less\n          steeply than tight fits.\n       d. Wasteful Fits (remaining capacity is large): Penalized, with the penalty\n          increasing with the amount of wasted space.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: An array of the remaining capacities of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element is the\n        priority score for the corresponding bin. Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds adaptively.\n    # Epsilon for floating point comparisons\n    epsilon = 1e-9\n\n    # Threshold for \"tight\" fits: remaining space is less than or equal to the item size.\n    # This prioritizes bins that are already somewhat full.\n    tight_fit_threshold = item\n\n    # Threshold for \"wasteful\" fits: remaining space is significantly larger than item size.\n    # Let's define this as more than twice the item size. This is a tunable parameter.\n    wasteful_threshold = 2.0 * item\n\n    # Calculate scores for fitting bins\n    scores = np.zeros_like(remaining_after_fit, dtype=float)\n\n    # 1. Perfect Fits: Highest priority. Assign a very high fixed score.\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = 1000.0\n\n    # 2. Tight Fits: High priority, inversely proportional to remaining capacity.\n    # Using a function like 1/(1+x) or e^(-kx) gives a decreasing priority.\n    # Scale it to provide a good range relative to perfect fits.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    scores[tight_mask] = 500.0 / (1.0 + remaining_after_fit[tight_mask] * 2.0)\n\n    # 3. Moderate Fits: Priority decreases as remaining capacity increases, but less steeply.\n    # This is for bins that aren't perfect or tight, but not overly wasteful.\n    moderate_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)\n    scores[moderate_mask] = 100.0 / (1.0 + np.sqrt(remaining_after_fit[moderate_mask]))\n\n    # 4. Wasteful Fits: Significantly penalized.\n    # The penalty increases with the excess space.\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # We want to strongly discourage these. The penalty should grow faster than linear.\n    # A quadratic or exponential penalty could be used. Here, we use a factor\n    # that grows with the ratio of wasted space to the item size.\n    penalty_factor = 5.0  # Controls the severity of the penalty\n    scores[wasteful_mask] = 50.0 / (1.0 + remaining_after_fit[wasteful_mask] / item) # Base score for wasteful\n    penalty = penalty_factor * (remaining_after_fit[wasteful_mask] - wasteful_threshold) / (item + epsilon)\n    scores[wasteful_mask] -= penalty\n\n    # Ensure scores are non-negative. If a penalty made a score negative, clamp it to 0.\n    scores[scores < 0] = 0\n\n    # Add a small random jitter for exploration. This helps break ties and\n    # explore potentially suboptimal but beneficial placements in the long run.\n    exploration_strength = 0.05  # Controls the magnitude of the random jitter\n    jitter = np.random.uniform(-exploration_strength, exploration_strength, size=scores.shape) * (np.max(scores) + epsilon)\n    final_scores = scores + jitter\n\n    # Update the priorities array with the calculated scores for the fitting bins\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 2,
    "obj": 5.454726765057843,
    "SLOC": 30.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response3.txt_stdout.txt",
    "code_path": "problem_iter7_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for the online Bin Packing Problem,\n    prioritizing perfect fits, tight fits, and bins that are already more filled,\n    while penalizing wasted space.\n\n    The priority for each bin is calculated based on the remaining capacity\n    after placing the item, and an additional bonus for bins that are already\n    mostly full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate remaining capacity in fitting bins after placing the item\n    fitting_bins_original_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_original_caps - item\n\n    # Define thresholds relative to the item size\n    tight_threshold_ratio = 0.2\n    good_threshold_ratio = 1.0\n    wasteful_threshold_ratio = 3.0\n\n    tight_threshold = item * tight_threshold_ratio\n    good_threshold = item * good_threshold_ratio\n    wasteful_threshold = item * wasteful_threshold_ratio\n\n    # Base scores for different fit types\n    perfect_score_base = 1000.0\n    tight_score_base = 700.0\n    good_score_base = 400.0\n    wasteful_score_base = 100.0\n    very_wasteful_score_base = 20.0\n\n    # Fill-up bonus factor (encourages using bins that are already mostly full)\n    fill_up_bonus_tight = 200.0\n    fill_up_bonus_good = 100.0\n    fill_up_bonus_wasteful = 20.0\n    fill_up_bonus_very_wasteful = 5.0\n\n    scores = np.zeros_like(remaining_after_fit, dtype=float)\n\n    # Calculate scores for fitting bins\n    for i, r_after in enumerate(remaining_after_fit):\n        original_cap = fitting_bins_original_caps[i]\n\n        # Fill-up bonus: Higher for bins that are already more full\n        # We use 1 / (original_capacity + epsilon) to give higher bonus to smaller capacity bins\n        fill_up_bonus = 0.0\n        if original_cap > epsilon: # Avoid division by zero if bin is theoretically full\n            fill_up_bonus = 1.0 / (original_cap + epsilon)\n\n        if r_after < epsilon:  # Perfect Fit\n            scores[i] = perfect_score_base\n            # Add a small fill-up bonus even for perfect fits, favoring bins that were initially smaller\n            scores[i] += fill_up_bonus * 10.0 # Slightly higher bonus for perfect fits\n\n        elif r_after <= tight_threshold:  # Tight Fit\n            # Score decreases linearly from base to 0 as remaining space increases up to threshold\n            score_decay = max(0.0, 1.0 - r_after / (tight_threshold + epsilon))\n            scores[i] = tight_score_base * score_decay + fill_up_bonus * fill_up_bonus_tight\n\n        elif r_after <= good_threshold:  # Good Fit\n            score_decay = max(0.0, 1.0 - r_after / (good_threshold + epsilon))\n            scores[i] = good_score_base * score_decay + fill_up_bonus * fill_up_bonus_good\n\n        elif r_after <= wasteful_threshold:  # Wasteful Fit\n            score_decay = max(0.0, 1.0 - r_after / (wasteful_threshold + epsilon))\n            scores[i] = wasteful_score_base * score_decay + fill_up_bonus * fill_up_bonus_wasteful\n\n        else:  # Very Wasteful Fit\n            # Penalize large remaining space more strongly\n            scores[i] = very_wasteful_score_base / (1.0 + r_after / (item + epsilon)) + fill_up_bonus * fill_up_bonus_very_wasteful\n\n    # Ensure scores are non-negative\n    scores[scores < 0] = 0\n\n    # Add a small random jitter for exploration to break ties and encourage exploration\n    # The jitter is a small fraction of the maximum possible score to avoid overriding\n    # meaningful score differences. Max possible score could be around 1000 + large fill-up bonus.\n    # Let's assume max score from bases is ~1000. Max fill-up bonus could be ~200.\n    # So max_potential_score ~ 1200.\n    max_score_estimate = 1200.0\n    exploration_factor = 0.05 # 5% of max score estimate\n    jitter = np.random.uniform(0, max_score_estimate * exploration_factor, size=len(scores))\n    final_scores = scores + jitter\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 3,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997054600681 seconds"
  },
  {
    "stdout_filepath": "problem_iter7_response4.txt_stdout.txt",
    "code_path": "problem_iter7_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an adaptive priority function for the online Bin Packing Problem.\n    This version prioritizes bins that leave minimal remaining capacity,\n    with an adaptive penalty for bins that would leave significantly large gaps.\n\n    Priority is calculated as follows:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fit: Highest priority.\n       b. Tight Fits: High priority, inversely proportional to remaining capacity.\n       c. Moderate Fits: Priority decreases as remaining capacity increases.\n       d. Wasteful Fits: Significantly penalized, especially when remaining capacity\n          is large relative to the item size or typical bin sizes.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Higher score means higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Find bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Adaptive Thresholds and Scaling ---\n    # Calculate a reference for \"tightness\" and \"wastefulness\"\n    # If all fitting bins have very similar remaining capacity, the notion of \"tight\" or \"wasteful\"\n    # is less meaningful relative to other options.\n    # We can use the item size as a primary reference, but also consider the distribution of remaining capacities.\n\n    epsilon = 1e-9  # For numerical stability\n\n    # Define thresholds relative to item size and range of remaining capacities.\n    # This aims to be adaptive to the scale of the problem.\n\n    # Threshold for what is considered a \"tight\" fit.\n    # If remaining capacity is less than 10% of item size, consider it very tight.\n    tight_threshold = item * 0.1\n\n    # Threshold for what is considered \"wasteful\".\n    # If remaining capacity is more than 2x item size, it might be wasteful.\n    # Also consider if remaining capacity is very large compared to current bin capacity.\n    # For simplicity here, we'll use a threshold relative to item size.\n    wasteful_threshold = item * 2.0\n\n    # Calculate a base score for all fitting bins, primarily favoring minimal remaining space.\n    # Using 1 / (slack + epsilon) ensures smaller slack gets higher score.\n    base_scores = 1.0 / (remaining_after_fit + epsilon)\n\n    # Apply modifiers based on fit type:\n    # - Boost for tight fits\n    # - Penalize wasteful fits\n\n    # Initialize scores for fitting bins\n    calculated_scores = np.copy(base_scores)\n\n    # 1. Perfect Fits: Maximize priority.\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    calculated_scores[perfect_fit_mask] = 1e6  # Assign a very high score\n\n    # 2. Tight Fits: Boost the base score.\n    # Condition: Remaining space is small (e.g., less than item/2 or a small fraction of bin cap)\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    # Apply a boost factor, stronger for smaller remaining space.\n    # Example: boost = 2.0 * (1 - remaining_after_fit / (tight_threshold + epsilon))\n    # A simpler boost: multiply by a factor for tight fits.\n    calculated_scores[tight_mask] *= 2.0  # Boost for tight fits\n\n    # 3. Wasteful Fits: Penalize the score.\n    # Condition: Remaining space is large (e.g., more than 2x item size)\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Apply a penalty factor. The penalty should increase with remaining space.\n    # Example penalty: score *= (1.0 - 0.5 * (remaining_after_fit - wasteful_threshold) / (item + epsilon))\n    # Ensure penalty doesn't make score negative.\n    penalty_factor = 0.5\n    penalty_amount = penalty_factor * np.maximum(0, remaining_after_fit[wasteful_mask] - wasteful_threshold) / (item + epsilon)\n    calculated_scores[wasteful_mask] *= np.maximum(0.1, 1.0 - penalty_amount) # Ensure score doesn't drop too low, e.g., below 0.1 multiplier\n\n    # Ensure scores are non-negative and not excessively large if not perfect fit.\n    calculated_scores[calculated_scores < 0] = 0\n    # Normalize scores to a reasonable range if desired, but usually relative ranking is enough.\n    # Let's ensure they are within a reasonable bounds.\n    # Max score for non-perfect fits should be lower than perfect fit.\n    max_non_perfect_score = np.max(calculated_scores[~perfect_fit_mask]) if np.any(~perfect_fit_mask) else 0\n    if max_non_perfect_score > 0:\n        calculated_scores[perfect_fit_mask] = np.maximum(calculated_scores[perfect_fit_mask], max_non_perfect_score * 10) # Ensure perfect is significantly higher\n\n\n    # Add a small amount of random jitter for exploration.\n    # This helps break ties and explore slightly suboptimal choices occasionally.\n    exploration_factor = 0.01 # Small fraction of the average score\n    avg_score = np.mean(calculated_scores[np.isfinite(calculated_scores)]) if np.any(np.isfinite(calculated_scores)) else 1.0\n    jitter = np.random.uniform(-exploration_factor * avg_score, exploration_factor * avg_score, size=calculated_scores.shape)\n    final_scores_for_fitting_bins = calculated_scores + jitter\n    final_scores_for_fitting_bins[final_scores_for_fitting_bins < 0] = 0 # Ensure jitter doesn't create negative scores\n\n    # Assign scores back to the original priority array\n    priorities[fitting_bins_indices] = final_scores_for_fitting_bins\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 33.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  }
]