```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements an improved priority function for the online Bin Packing Problem.
    This version prioritizes tight fits, penalizes wasted space effectively,
    and uses adaptive thresholds to better handle varying item and bin sizes.

    The priority is calculated as follows:
    1. Bins that cannot fit the item get a priority of 0.
    2. For bins that can fit the item:
       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.
       b. Tight Fits (remaining capacity after packing is small): High priority,
          inversely proportional to the remaining capacity. This encourages filling
          bins as much as possible.
       c. Moderate Fits: Priority decreases as remaining capacity increases,
          but at a slower rate than tight fits.
       d. Wasteful Fits (remaining capacity after packing is large): Significantly
          penalized to discourage using bins that would leave substantial empty space.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher score indicates a higher priority.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    fitting_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    # Define thresholds adaptively
    epsilon = 1e-9
    
    # Threshold for "tight" fits: remaining space is less than the item size.
    # This encourages using bins that are already somewhat filled.
    tight_fit_threshold = item

    # Threshold for "wasteful" fits: remaining space is significantly larger than item size.
    # A good heuristic is to consider bins where the remaining space is more than, say,
    # twice the item size, or a significant fraction of the *potential* remaining space
    # if a large item were placed. Let's use a factor of the item size.
    # We also consider the maximum possible remaining capacity for normalization.
    max_potential_remaining = np.max(bins_remain_cap) - item if np.max(bins_remain_cap) >= item else 0
    
    # A threshold that is sensitive to item size and bin capacity.
    # If bins are generally large, we might tolerate larger remaining gaps for non-wasteful bins.
    # Let's use a blend: it's "wasteful" if remaining_after_fit is large relative to item size,
    # OR if it's a large fraction of the *total* capacity.
    # For simplicity and directness, we'll use a threshold relative to item size,
    # but also consider how much space is left relative to the bin's *initial* capacity
    # (which we don't have here). So, relying on remaining_after_fit is key.
    # Let's consider `remaining_after_fit > C * item` and `remaining_after_fit > D * max_potential_remaining`.
    # For this version, let's simplify the "wasteful" threshold to focus on the remaining space
    # relative to the item size, aiming to avoid bins that are still mostly empty.
    # A threshold like 3 * item size seems reasonable to start.
    wasteful_threshold = 3.0 * item

    # Calculate scores
    scores = np.zeros_like(remaining_after_fit)

    # 1. Perfect Fits: Highest priority
    perfect_mask = (remaining_after_fit < epsilon)
    scores[perfect_mask] = 1000.0

    # 2. Tight Fits: High priority, inversely proportional to remaining capacity
    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)
    # Use a steep decay function like 1/(1+x) or 1/(1+x^2)
    scores[tight_mask] = 50.0 / (1.0 + remaining_after_fit[tight_mask] * 5.0) # Scaled to give good range

    # 3. Moderate Fits: Priority decreases with remaining capacity, but less steeply
    moderate_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)
    # A less steep decay, e.g., 1/(1+sqrt(x)) or 1/(1+x^0.7)
    scores[moderate_mask] = 20.0 / (1.0 + np.sqrt(remaining_after_fit[moderate_mask]))

    # 4. Wasteful Fits: Significantly penalized
    wasteful_mask = (remaining_after_fit > wasteful_threshold)
    # Penalize based on how much excess space is left.
    # The penalty should be substantial to deter selection.
    # We can use a linear penalty that starts at 0 at the threshold and increases.
    # Penalty = P * (remaining_after_fit - wasteful_threshold) / (max_possible_remaining + epsilon)
    # Normalize penalty by item size to keep it somewhat scale-invariant.
    penalty_factor = 5.0 # Controls the magnitude of the penalty
    scores[wasteful_mask] = 10.0 / (1.0 + remaining_after_fit[wasteful_mask] / item) # Start with a base score, then penalize
    penalty = penalty_factor * (remaining_after_fit[wasteful_mask] - wasteful_threshold) / (item + epsilon)
    scores[wasteful_mask] -= penalty

    # Ensure scores are non-negative
    scores[scores < 0] = 0

    # Add a small random jitter for exploration to prevent all scores from being identical
    # for multiple bins with similar fit characteristics.
    exploration_factor = 0.05
    jitter = np.random.rand(len(scores)) * exploration_factor * np.max(scores + epsilon)
    final_scores = scores + jitter

    # Assign the calculated scores to the corresponding bins in the original priority array
    priorities[can_fit_mask] = final_scores

    return priorities
```
