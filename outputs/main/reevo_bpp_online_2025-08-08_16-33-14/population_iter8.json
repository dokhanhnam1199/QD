[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an advanced, adaptive priority function for the online Bin Packing Problem.\n    This version dynamically adjusts thresholds and scoring based on the item size\n    and the distribution of remaining capacities in the bins to favor tighter fits\n    and penalize wasted space more effectively.\n\n    Priority calculation:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity is negligible): Highest priority.\n       b. Tight Fits (remaining capacity is small relative to item): High priority,\n          inversely proportional to the remaining capacity.\n       c. Moderate Fits (remaining capacity is moderate): Priority decreases linearly\n          with increasing remaining capacity.\n       d. Wasteful Fits (remaining capacity is large relative to item): Significantly\n          penalized, with the penalty increasing with the amount of excess space.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Higher score means higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    epsilon = 1e-9  # For numerical stability and to avoid division by zero\n\n    # --- Adaptive Thresholds and Scoring ---\n\n    # 1. Perfect Fits: Highest priority\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    # Assign a very high, fixed score to perfect fits.\n    perfect_scores = np.full(np.sum(perfect_fit_mask), 1e9)\n\n    # For non-perfect fits, calculate scores based on remaining capacity\n    non_perfect_mask = ~perfect_fit_mask\n    if np.any(non_perfect_mask):\n        non_perfect_remaining = remaining_after_fit[non_perfect_mask]\n\n        # Define adaptive thresholds relative to item size for better adaptation\n        # \"Tight\" fit: remaining space is small compared to the item.\n        # e.g., less than 15% of the item size.\n        tight_threshold = item * 0.15\n        # \"Wasteful\" fit: remaining space is large compared to the item.\n        # e.g., more than 1.5 times the item size.\n        wasteful_threshold = item * 1.5\n\n        # Calculate a base score that favors smaller remaining capacity\n        # Using a form like 1 / (remaining + small_constant)\n        base_scores = 1.0 / (non_perfect_remaining + epsilon)\n\n        # Initialize scores for non-perfect fits\n        calculated_non_perfect_scores = np.copy(base_scores)\n\n        # Apply modifiers based on fit type:\n\n        # 2. Tight Fits: Boost the base score.\n        # If remaining capacity is less than or equal to the tight threshold.\n        tight_fit_mask_subset = (non_perfect_remaining <= tight_threshold)\n        # Boost score quadratically as remaining capacity gets closer to zero.\n        # This gives higher priority to even tighter fits within the \"tight\" category.\n        boost_factor_tight = 5.0 * (1.0 - non_perfect_remaining[tight_fit_mask_subset] / (tight_threshold + epsilon))\n        calculated_non_perfect_scores[tight_fit_mask_subset] *= (1.0 + boost_factor_tight)\n\n        # 3. Moderate Fits: Use the base score, potentially scaled.\n        # These are bins where remaining capacity is between tight_threshold and wasteful_threshold.\n        moderate_fit_mask_subset = (non_perfect_remaining > tight_threshold) & (non_perfect_remaining <= wasteful_threshold)\n        # For moderate fits, the base score is already good. We can scale it slightly,\n        # or just let it be. Let's slightly boost based on how \"moderate\" it is.\n        moderate_boost = 1.0 + 0.5 * (wasteful_threshold - non_perfect_remaining[moderate_fit_mask_subset]) / (wasteful_threshold - tight_threshold + epsilon)\n        calculated_non_perfect_scores[moderate_fit_mask_subset] *= moderate_boost\n\n\n        # 4. Wasteful Fits: Penalize the score.\n        # If remaining capacity is greater than the wasteful threshold.\n        wasteful_fit_mask_subset = (non_perfect_remaining > wasteful_threshold)\n        # Penalize more heavily as the remaining space increases.\n        # The penalty should be proportional to how much \"excess\" space there is.\n        # Penalty = 1.0 - k * (excess_space / item)\n        penalty_strength = 0.8  # How aggressively we penalize\n        excess_space_ratio = (non_perfect_remaining[wasteful_fit_mask_subset] - wasteful_threshold) / (item + epsilon)\n        penalty_factor = penalty_strength * excess_space_ratio\n        # Ensure the penalty doesn't make the score extremely negative,\n        # and doesn't go below a minimum positive value if that's desired.\n        # We will cap the multiplier to prevent scores from becoming too small or negative.\n        # Minimum multiplier of 0.1 means the score can be at most 10% of the base.\n        calculated_non_perfect_scores[wasteful_fit_mask_subset] *= np.maximum(0.1, 1.0 - penalty_factor)\n\n        # Ensure scores are non-negative\n        calculated_non_perfect_scores[calculated_non_perfect_scores < 0] = 0\n\n        # Combine perfect and non-perfect scores\n        all_scores_for_fitting_bins = np.zeros_like(remaining_after_fit)\n        all_scores_for_fitting_bins[perfect_fit_mask] = perfect_scores\n        all_scores_for_fitting_bins[non_perfect_mask] = calculated_non_perfect_scores\n\n        # Normalize scores to prevent potential overflow and ensure relative scale is maintained.\n        # Max score can be 1e9 for perfect fits.\n        # For other scores, ensure they are significantly lower than perfect fits but still meaningful.\n        max_non_perfect_score = np.max(all_scores_for_fitting_bins[non_perfect_mask]) if np.any(non_perfect_mask) else 0\n        if max_non_perfect_score > 0:\n            all_scores_for_fitting_bins[non_perfect_mask] /= max_non_perfect_score # Normalize non-perfect scores to a max of 1\n            all_scores_for_fitting_bins[non_perfect_mask] *= (1e9 / 10.0) # Scale them to be high but less than perfect\n\n        # Add a small random jitter for exploration\n        # Jitter is a small percentage of the current score to encourage diversity in selection.\n        jitter_strength = 0.05 # 5% of the current score\n        jitter = np.random.normal(0, jitter_strength, size=all_scores_for_fitting_bins.shape) * all_scores_for_fitting_bins\n        final_scores_for_fitting_bins = all_scores_for_fitting_bins + jitter\n        final_scores_for_fitting_bins[final_scores_for_fitting_bins < 0] = 0 # Ensure no negative scores due to jitter\n\n    else: # Only perfect fits exist\n        final_scores_for_fitting_bins = perfect_scores\n\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[fitting_bins_indices] = final_scores_for_fitting_bins\n\n    return priorities",
    "response_id": 0,
    "obj": 4.068607897885915,
    "SLOC": 46.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an advanced priority function for the online Bin Packing Problem,\n    dynamically adjusting priorities based on item size and bin remaining capacities.\n    It strongly penalizes waste, rewards snug fits quadratically, and uses adaptive thresholds.\n\n    Priority calculation:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is ~0): Highest priority.\n       b. Tight Fits (small remaining capacity): High priority, decreasing quadratically\n          with remaining capacity to strongly favor very snug fits.\n       c. Moderate Fits (medium remaining capacity): Moderate priority, decreasing linearly\n          with remaining capacity.\n       d. Wasteful Fits (large remaining capacity): Significantly penalized based on the\n          magnitude of wasted space relative to the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds adaptively based on item size to better differentiate fits.\n    # A small epsilon for floating point comparisons.\n    epsilon = 1e-9\n    \n    # Threshold for \"tight\" fits: remaining space is very small relative to item size.\n    # Let's define tight as remaining space <= 5% of the item size.\n    tight_fit_threshold = 0.05 * item\n\n    # Threshold for \"wasteful\" fits: remaining space is significantly larger than item size.\n    # Let's define wasteful as remaining space > 1.5 times the item size.\n    wasteful_threshold = 1.5 * item\n\n    # Calculate scores for bins that can fit the item\n    scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority. A score significantly higher than others.\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = 100.0\n\n    # 2. Tight Fits: High priority, decreasing quadratically with remaining capacity.\n    # This strongly favors bins that are almost full after packing.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    # Score: uses 1 / (1 + k*x^2) where k=10 to emphasize very small remaining spaces.\n    # Adding epsilon to denominator to avoid division by zero for extremely small values.\n    scores[tight_mask] = 90.0 * (1.0 / (1.0 + 10.0 * remaining_after_fit[tight_mask]**2))\n\n    # 3. Moderate Fits: Moderate priority, decreasing linearly with remaining capacity.\n    # This rewards bins that have a reasonable amount of space left.\n    moderate_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)\n    # Score: uses 1 / (1 + k*x) where k=1 for a linear decay.\n    scores[moderate_mask] = 70.0 * (1.0 / (1.0 + remaining_after_fit[moderate_mask]))\n\n    # 4. Wasteful Fits: Significantly penalized.\n    # These are bins where the remaining space is disproportionately large compared to the item.\n    # The penalty should be substantial to strongly discourage their selection.\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Penalty is proportional to how much larger the remaining space is than the item.\n    # The score becomes negative, indicating a low priority.\n    # Ensure item + epsilon in denominator to avoid division by zero if item is zero (though unlikely for BPP).\n    scores[wasteful_mask] = -20.0 - 30.0 * (remaining_after_fit[wasteful_mask] / (item + epsilon))\n\n    # Add a small random jitter for exploration. This helps break ties and encourages\n    # exploration of slightly less optimal bins, preventing getting stuck in local optima.\n    exploration_factor = 0.08 # Jitter is 8% of the max possible positive score range.\n    max_positive_score = 100.0 # Base jitter on the highest possible positive score.\n    jitter = np.random.rand(len(scores)) * exploration_factor * max_positive_score\n    final_scores = scores + jitter\n\n    # Ensure scores for non-wasteful categories remain non-negative after jitter.\n    # This is a safeguard; the formulas are designed to produce positive scores.\n    final_scores[tight_mask] = np.maximum(final_scores[tight_mask], 0)\n    final_scores[moderate_mask] = np.maximum(final_scores[moderate_mask], 0)\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 1,
    "obj": 3.9888312724371757,
    "SLOC": 28.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem,\n    focusing on prioritizing tight fits, penalizing wasted space effectively,\n    and using adaptive thresholds based on item size and bin capacities.\n\n    The priority is calculated as follows:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.\n       b. Tight Fits (remaining capacity after packing is small and positive):\n          High priority, inversely proportional to the remaining capacity. This\n          encourages filling bins as much as possible.\n       c. Good Fits (remaining capacity after packing is moderate): Priority\n          decreases as remaining capacity increases, but at a slower rate than\n          tight fits.\n       d. Wasteful Fits (remaining capacity after packing is large):\n          Significantly penalized to strongly discourage using bins that would\n          leave substantial empty space. The penalty increases with the amount\n          of wasted space relative to the item size.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.\n\n    Returns:\n        A NumPy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds adaptively, primarily based on item size for relative comparison.\n    epsilon = 1e-9  # Tolerance for floating-point comparisons\n\n    # Threshold for \"tight\" fits: remaining space is less than the item size.\n    # This encourages using bins that are already somewhat filled.\n    tight_fit_threshold = item\n\n    # Threshold for \"wasteful\" fits: remaining space is significantly larger than item size.\n    # Using a factor of the item size helps in relative comparison across different item sizes.\n    # A factor of 3.0 means if the remaining space is more than 3 times the item size, it's wasteful.\n    wasteful_threshold = 3.0 * item\n\n    # --- Scoring Logic ---\n    scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority. Assign a very high score.\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = 1000.0\n\n    # 2. Tight Fits: High priority, inversely proportional to remaining capacity.\n    # Use a steep decay function, e.g., 1/(1+x), scaled to provide a good range.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    # Scale factor for the reciprocal to modulate the steepness of the priority drop-off.\n    scores[tight_mask] = 50.0 / (1.0 + remaining_after_fit[tight_mask] * 4.0)\n\n    # 3. Good Fits: Priority decreases with remaining capacity, but less steeply.\n    # These are bins that fit, but are not \"tight\" and not yet \"wasteful\".\n    good_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)\n    # Use a less steep decay, like 1/(1+sqrt(x)), to retain more relative priority.\n    scores[good_mask] = 25.0 / (1.0 + np.sqrt(remaining_after_fit[good_mask]))\n\n    # 4. Wasteful Fits: Significantly penalized.\n    # These bins have remaining space significantly larger than the item.\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Penalize based on how much excess space is left, normalized by item size.\n    # A linear or exponential penalty can be used. Here, we use a rational function\n    # that decreases rapidly as remaining_after_fit increases.\n    # The penalty is subtracted from a base score to ensure that even wasteful bins\n    # that *could* fit still get a non-zero (though low) initial score before penalty.\n    base_wasteful_score = 10.0\n    penalty_strength = 2.0  # Controls how aggressively large remaining capacities are penalized.\n    scores[wasteful_mask] = base_wasteful_score / (1.0 + penalty_strength * (remaining_after_fit[wasteful_mask] / item))\n\n    # Ensure all calculated scores are non-negative.\n    scores[scores < 0] = 0\n\n    # Add a small amount of random jitter to scores of bins with very similar calculated priorities.\n    # This helps to break ties randomly and can improve exploration without a strict exploration bonus.\n    exploration_jitter_scale = 0.01  # Controls the magnitude of the jitter relative to max possible score.\n    max_potential_score = 1000.0 # An estimate of the highest possible score.\n    jitter = np.random.uniform(-exploration_jitter_scale * max_potential_score, exploration_jitter_scale * max_potential_score, size=len(scores))\n    final_scores = scores + jitter\n\n    # Ensure jitter doesn't make scores negative.\n    final_scores[final_scores < 0] = 0\n\n    # Assign the calculated scores to the corresponding bins in the original priority array.\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 2,
    "obj": 1.406063023534107,
    "SLOC": 30.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem (BPP).\n    This version strictly prioritizes perfect fits, then tight fits, and uses a\n    consistent decay for other fits, with a small stochastic element for exploration.\n\n    Scoring Logic:\n    1. Perfect Fit: remaining capacity is zero after packing. Highest priority.\n    2. Tight Fit: remaining capacity is positive but less than or equal to a small threshold\n       (e.g., a fraction of the bin capacity or a fixed small value). Prioritizes bins\n       that are nearly full but not perfectly fit.\n    3. Other Fits: For remaining bins, priority decreases as the remaining capacity increases.\n       This encourages using bins that are less full.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: An array of the remaining capacities of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element is the\n        priority score for the corresponding bin. Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components\n    epsilon = 1e-9  # For handling perfect fits and avoiding division by zero\n\n    # Threshold for \"tight\" fits: a small remaining capacity.\n    # This can be a fraction of the bin's capacity or a fixed small value.\n    # Let's use a small fraction of the item size as a heuristic for tightness.\n    tight_threshold = item * 0.1\n    if tight_threshold < epsilon * 10: # Ensure it's not too small\n        tight_threshold = epsilon * 10\n\n    # Initialize scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    other_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fit: Highest priority.\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 100.0  # High fixed score for perfect fits\n\n    # 2. Tight Fit: Prioritize bins that leave little room after packing,\n    #    specifically when remaining capacity is positive but small.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    # Score decreases as remaining_after_fit increases within the tight range.\n    # Use a function like 1/(1+x).\n    tight_fit_scores[tight_mask] = 50.0 / (1.0 + remaining_after_fit[tight_mask] * 5) # Scale for higher priority\n\n    # 3. Other Fits: For bins where remaining capacity is greater than the tight threshold.\n    #    Priority decreases as remaining capacity increases.\n    other_mask = (remaining_after_fit > tight_threshold)\n    # Use a decaying function. 1 / (1 + x).\n    other_fit_scores[other_mask] = 10.0 / (1.0 + remaining_after_fit[other_mask] * 2) # Lower base score, decay\n\n    # Combine scores using weights to reflect the priority order: Perfect > Tight > Other\n    combined_scores = (\n        perfect_fit_scores * 1.0 +  # Max weight for perfect fits\n        tight_fit_scores * 0.8 +    # Significant weight for tight fits\n        other_fit_scores * 0.4      # Lower weight for general fits\n    )\n\n    # Add a small random component for exploration to all fitting bins\n    exploration_factor = 0.05\n    max_possible_score = 100.0 + (50.0 / (1.0 + epsilon)) * 0.8 + (10.0 / (1.0 + tight_threshold)) * 0.4\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * max_possible_score\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 3,
    "obj": 4.836457917830076,
    "SLOC": 32.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for online Bin Packing Problem,\n    prioritizing tighter fits and using a weighted combination of fit categories.\n\n    The function assigns scores to bins based on how well they fit an item:\n    1. Perfect Fit: Bin's remaining capacity is exactly zero after packing. Highest priority.\n    2. Tight Fit: Bin's remaining capacity after packing is small (<= item size). High priority.\n    3. Moderate Fit: Bin's remaining capacity after packing is larger than item size but not excessively so (<= 2 * item size). Medium priority.\n    4. Loose Fit: Bin's remaining capacity after packing is large (> 2 * item size). Lowest priority.\n\n    The scoring is refined by:\n    - Prioritizing tighter fits more strongly.\n    - Using a weighted combination of scores from different fit categories.\n    - Tuning scaling factors for better discrimination between categories.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for the corresponding bin. Higher scores indicate\n        higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds for categorizing fits relative to the item size\n    epsilon = 1e-9  # For floating-point comparisons, especially for perfect fits\n    tight_threshold = item\n    moderate_threshold = 2.0 * item\n\n    # Initialize scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    moderate_fit_scores = np.zeros_like(remaining_after_fit)\n    loose_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # Calculate scores for each category with adjusted scaling:\n    # Perfect Fit: Highest score, indicating minimal waste.\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 10.0  # Strongest priority\n\n    # Tight Fit: Prioritize bins that leave little remaining capacity after packing.\n    # Score is inversely proportional to the remaining capacity, encouraging fuller bins.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    # Scaled by 1 + remaining capacity, higher score for smaller remaining capacity\n    tight_fit_scores[tight_mask] = 5.0 / (1.0 + remaining_after_fit[tight_mask]) \n\n    # Moderate Fit: Bins that leave a moderate amount of space.\n    # Score decreases as remaining capacity increases, but less steeply than tight fits.\n    moderate_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= moderate_threshold)\n    moderate_fit_scores[moderate_mask] = 3.0 / (1.0 + remaining_after_fit[moderate_mask]) \n\n    # Loose Fit: Bins that leave a significant amount of space.\n    # These are less preferred, so they receive a low base score.\n    loose_mask = (remaining_after_fit > moderate_threshold)\n    loose_fit_scores[loose_mask] = 1.5 / (1.0 + remaining_after_fit[loose_mask])\n\n    # Combine scores using weights to reflect the priority order: Perfect > Tight > Moderate > Loose.\n    # Weights are tuned to emphasize tighter fits more significantly.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.8 +\n        moderate_fit_scores * 0.4 +\n        loose_fit_scores * 0.1\n    )\n\n    # Add a small stochastic component for exploration.\n    # This helps in occasional selection of less optimal bins, potentially leading to better overall packing.\n    # The exploration factor is kept small to not override the primary scoring logic.\n    exploration_factor = 0.03\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 34.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for the online Bin Packing Problem (BPP).\n    This version focuses on a clear hierarchy: perfect fits first, then bins\n    that leave minimal remaining capacity (tight fits), followed by general\n    best-fit strategy, with an added component for exploring less-filled bins\n    to potentially improve future packing.\n\n    Scoring Logic:\n    1. Perfect Fit: remaining capacity is zero (within epsilon). Highest priority.\n    2. Tight Fit: remaining capacity is positive but less than the item size.\n       Priority is inversely proportional to the remaining space.\n    3. Loose Fit: remaining capacity is greater than or equal to the item size.\n       Priority is inversely proportional to the remaining space, but with a\n       lower base value than tight fits.\n    4. Exploration Component: A small, scaled random value is added to all\n       eligible bins to encourage exploration of less-filled bins.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Higher score means higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    epsilon = 1e-9  # For numerical stability and checking perfect fits\n\n    # Initialize scores for the fitting bins\n    scores = np.zeros_like(remaining_after_fit)\n\n    # --- Define score components for different fit types ---\n\n    # 1. Perfect Fit: Assign a very high, distinct score.\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    scores[perfect_fit_mask] = 1e6\n\n    # 2. Tight Fit: remaining_after_fit is positive but small relative to item.\n    #    Let's define \"tight\" as remaining space < item * 0.5 (half the item size).\n    tight_fit_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit < item * 0.5)\n    # Score inversely proportional to remaining space. Add epsilon to avoid division by zero.\n    scores[tight_fit_mask] = 100.0 / (remaining_after_fit[tight_fit_mask] + epsilon)\n\n    # 3. Loose Fit: remaining_after_fit >= item * 0.5\n    loose_fit_mask = (remaining_after_fit >= item * 0.5)\n    # Score inversely proportional to remaining space, but with a lower base magnitude.\n    scores[loose_fit_mask] = 50.0 / (remaining_after_fit[loose_fit_mask] + epsilon)\n\n    # --- Add Exploration Component ---\n    # A small random value to encourage exploration.\n    # Scale it based on the typical range of scores to maintain relative priorities.\n    # Find a reference score magnitude (e.g., max score from non-perfect fits).\n    non_perfect_scores = scores[~perfect_fit_mask]\n    max_non_perfect_score = np.max(non_perfect_scores) if np.any(non_perfect_scores) else 50.0 # Default if only perfect fits exist\n\n    # Exploration factor: small percentage of the max non-perfect score\n    exploration_factor = 0.1\n    random_jitter = np.random.uniform(0, exploration_factor * max_non_perfect_score, size=scores.shape)\n\n    # Add jitter, ensuring it doesn't reduce the priority of perfect fits significantly\n    # and is applied only to non-perfect fits to keep perfect fits dominant.\n    scores[~perfect_fit_mask] += random_jitter[~perfect_fit_mask]\n\n    # Ensure scores are non-negative\n    scores[scores < 0] = 0\n\n    # Assign calculated scores back to the original priority array\n    priorities[fitting_bins_indices] = scores\n\n    return priorities",
    "response_id": 5,
    "obj": 4.038691663342641,
    "SLOC": 25.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem (BPP).\n\n    This heuristic aims to balance several strategic objectives:\n    1.  **Tight Fit (Best Fit principle):** Prioritize bins that leave the minimum\n        remaining capacity after packing the item. This aims to minimize immediate\n        wasted space. The priority is inversely proportional to the remaining capacity.\n    2.  **Avoid Over-Saturation (Penalty):** Penalize bins that will have very little\n        remaining capacity after packing. This aims to prevent a bin from becoming\n        too full too quickly, leaving it unusable for even small future items. The\n        penalty is stronger for bins that become almost completely full.\n    3.  **Encourage Exploration (Boost):** Provide a slight boost to bins that will\n        have a moderate amount of remaining capacity. This encourages utilizing a\n        wider range of bins, potentially leading to better overall packing by\n        distributing items more evenly. The boost is applied to bins that will\n        have remaining capacity between `item` and `k * item` (e.g., k=2).\n\n    The function calculates priority scores only for bins that can fit the item.\n    Bins that cannot fit the item receive a score of 0.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element is the remaining capacity\n                         of a bin.\n\n    Returns:\n        A numpy array of the same size as `bins_remain_cap`, containing the priority\n        score for each bin. Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the current item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item, return all zeros.\n\n    # Get the remaining capacities of bins that can fit the item\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Calculate Priority Components ---\n\n    # 1. Tight Fit Score: Prioritize bins with less remaining space.\n    # Use 1 / (remaining_capacity + epsilon) to give higher scores to smaller remainders.\n    # Epsilon prevents division by zero for perfect fits.\n    tight_fit_scores = 1.0 / (remaining_after_fit + 1e-9)\n\n    # 2. Over-Saturation Penalty: Penalize bins that become nearly full.\n    # Define a threshold for \"nearly full\", e.g., remaining capacity < 0.1 * item.\n    # The penalty should be more aggressive for smaller remaining capacities.\n    penalty_threshold = 0.1 * item\n    penalty_scores = np.zeros_like(fitting_bins_caps)\n\n    # Apply penalty to bins where remaining capacity is positive but very small\n    nearly_full_mask = (remaining_after_fit > 0) & (remaining_after_fit <= penalty_threshold)\n    if np.any(nearly_full_mask):\n        # Linear penalty: closer to 0 remaining capacity = higher penalty (more negative score)\n        # Max penalty (-1.0) for remaining_after_fit=0, min penalty (0.0) for remaining_after_fit=penalty_threshold\n        penalty_scores[nearly_full_mask] = -1.0 * (1.0 - (remaining_after_fit[nearly_full_mask] / penalty_threshold))\n\n    # 3. Exploration Boost: Encourage bins that leave a moderate amount of space.\n    # Define a range for moderate remaining space, e.g., item <= remaining < 2 * item.\n    # This aims to avoid overly tight fits (handled by tight_fit_scores) and\n    # overly spacious fits (which might be better for larger items).\n    boost_min_remaining = item\n    boost_max_remaining = 2.0 * item  # Tunable parameter for boost range\n    exploration_scores = np.zeros_like(fitting_bins_caps)\n\n    # Apply boost to bins within the moderate range\n    boost_mask = (remaining_after_fit > boost_min_remaining) & (remaining_after_fit <= boost_max_remaining)\n    if np.any(boost_mask):\n        # Boost is highest for remaining_after_fit close to boost_min_remaining\n        # and decreases as it approaches boost_max_remaining.\n        # Normalize remaining capacity within the boost range [0, 1]\n        normalized_remaining = (remaining_after_fit[boost_mask] - boost_min_remaining) / (boost_max_remaining - boost_min_remaining)\n        # Apply a decreasing boost function, e.g., linear decay\n        exploration_scores[boost_mask] = 0.2 * (1.0 - normalized_remaining) # Tunable boost strength (e.g., 0.2)\n\n    # --- Combine Scores with Weights ---\n    # Weights can be tuned to prioritize different strategies.\n    # Tight fit is primary, penalty is secondary, boost is tertiary.\n    weight_tight_fit = 1.0\n    weight_penalty = 1.0 # Penalty is naturally negative, so its weight affects magnitude\n    weight_exploration = 1.0\n\n    combined_scores = (weight_tight_fit * tight_fit_scores) + \\\n                      (weight_penalty * penalty_scores) + \\\n                      (weight_exploration * exploration_scores)\n\n    # Assign the calculated scores back to the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 29.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem (BPP).\n    This version strongly emphasizes perfect fits, penalizes significant wasted space,\n    and uses adaptive thresholds that are more sensitive to the item size and\n    the distribution of remaining capacities.\n\n    The priority for each bin is calculated as follows:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is ~0): Receive the highest\n          priority score, indicating minimal waste.\n       b. Tight Fits (remaining capacity after packing is small, relative to item size):\n          Receive high priority. The priority is inversely proportional to the\n          remaining capacity, encouraging fuller bins.\n       c. Moderate Fits (remaining capacity is larger than tight but not yet wasteful):\n          Receive medium priority, with a decay that is less steep than tight fits.\n       d. Wasteful Fits (remaining capacity is significantly large, relative to item size):\n          Receive a heavily penalized score to strongly discourage their selection.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for the corresponding bin. Higher scores indicate\n        higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds adaptively and with strong emphasis on item size\n    epsilon = 1e-9  # For floating-point comparisons\n\n    # Threshold for \"perfect\" fit: remaining capacity is effectively zero.\n    perfect_fit_threshold = epsilon\n\n    # Threshold for \"tight\" fit: remaining capacity is small, ideally less than or equal to item size.\n    # This promotes filling bins as much as possible.\n    tight_fit_threshold = item\n\n    # Threshold for \"wasteful\" fit: remaining capacity is large.\n    # We define \"large\" relative to the item size to make it adaptive.\n    # A good heuristic is remaining space being significantly more than the item size.\n    # Let's use 2 * item size as a starting point for \"wasteful\".\n    wasteful_threshold = 2.0 * item\n\n    # Calculate scores for the fitting bins\n    scores = np.zeros_like(remaining_after_fit)\n\n    # Category 1: Perfect Fits (Highest Priority)\n    perfect_mask = (remaining_after_fit <= perfect_fit_threshold)\n    scores[perfect_mask] = 1000.0  # Assign a very high score\n\n    # Category 2: Tight Fits (High Priority)\n    # These bins leave a small amount of space, ideally close to 0 but not perfect.\n    # Priority is inversely proportional to remaining capacity to favor fuller bins.\n    tight_mask = (remaining_after_fit > perfect_fit_threshold) & (remaining_after_fit <= tight_fit_threshold)\n    # Using a function like 1/(1+x) or similar, scaled for a good range.\n    # Smaller remaining_after_fit should yield higher scores.\n    scores[tight_mask] = 50.0 / (1.0 + (remaining_after_fit[tight_mask] / item) * 2.0)\n\n    # Category 3: Moderate Fits (Medium Priority)\n    # These bins leave more space than tight fits but are not yet considered wasteful.\n    # Priority decays more slowly than for tight fits.\n    moderate_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)\n    # Using a function like 1/(1+sqrt(x)) or similar.\n    scores[moderate_mask] = 20.0 / (1.0 + np.sqrt(remaining_after_fit[moderate_mask] / item))\n\n    # Category 4: Wasteful Fits (Low Priority / Penalized)\n    # These bins leave a large amount of unused space.\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Penalize these bins significantly. The penalty should increase with excess space.\n    # The score will be a base score minus a penalty that grows with excess capacity.\n    # We want to strongly discourage these.\n    base_score_wasteful = 5.0 # Small base score for potentially needing a new bin later\n    penalty_factor = 15.0 # Controls how aggressively wasteful bins are penalized\n    # Normalize penalty by item size to maintain some scale invariance.\n    penalty = penalty_factor * (remaining_after_fit[wasteful_mask] - wasteful_threshold) / (item + epsilon)\n    scores[wasteful_mask] = base_score_wasteful - penalty\n\n    # Ensure all scores are non-negative\n    scores[scores < 0] = 0\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = scores\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 28.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem,\n    prioritizing exact fits, then tighter fits, and penalizing overly large\n    remaining capacities. Includes a small random component for exploration.\n\n    Scoring logic:\n    1. Exact Fit: Highest priority (large positive score).\n    2. Tight Fit: Prioritize bins leaving minimal remaining capacity (decreasing positive score).\n    3. Moderate Fit: Prioritize bins leaving some space, but less than loose fits (lower positive score).\n    4. Loose Fit: Lowest priority, but still assign a small positive score.\n    5. Exploration: Add a small random component to break ties and encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    epsilon = 1e-9  # For handling near-zero remaining capacities\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return scores  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define scoring tiers and parameters\n    perfect_fit_threshold = epsilon\n    tight_fit_threshold = item * 1.5  # Bins where remaining is up to 1.5 * item size\n    moderate_fit_threshold = item * 3.0 # Bins where remaining is up to 3.0 * item size\n\n    # Base scores for different tiers\n    perfect_fit_score = 1000.0\n    tight_fit_base_score = 500.0\n    moderate_fit_base_score = 100.0\n    loose_fit_base_score = 10.0\n\n    # Calculate priority for fitting bins\n    fitting_scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Exact Fit\n    exact_fit_mask = (remaining_after_fit < perfect_fit_threshold)\n    fitting_scores[exact_fit_mask] = perfect_fit_score + (perfect_fit_threshold - remaining_after_fit[exact_fit_mask])\n\n    # 2. Tight Fit\n    tight_fit_mask = (remaining_after_fit >= perfect_fit_threshold) & (remaining_after_fit <= tight_fit_threshold)\n    # Linear decrease in score with increasing remaining capacity within this range\n    # The slope should ensure that as remaining_after_fit approaches tight_fit_threshold, the score approaches a lower value.\n    # Let's aim for a score of ~tight_fit_base_score/2 at the threshold.\n    score_decay_tight = (tight_fit_base_score - loose_fit_base_score) / (tight_fit_threshold - perfect_fit_threshold + epsilon)\n    fitting_scores[tight_fit_mask] = tight_fit_base_score - score_decay_tight * (remaining_after_fit[tight_fit_mask] - perfect_fit_threshold)\n\n    # 3. Moderate Fit\n    moderate_fit_mask = (remaining_after_fit > tight_fit_threshold) & (remaining_after_fit <= moderate_fit_threshold)\n    score_decay_moderate = (moderate_fit_base_score - loose_fit_base_score) / (moderate_fit_threshold - tight_fit_threshold + epsilon)\n    fitting_scores[moderate_fit_mask] = moderate_fit_base_score - score_decay_moderate * (remaining_after_fit[moderate_fit_mask] - tight_fit_threshold)\n\n    # 4. Loose Fit\n    loose_fit_mask = (remaining_after_fit > moderate_fit_threshold)\n    # Score decreases linearly but at a slower rate, also penalizing very large remaining capacities.\n    score_decay_loose = loose_fit_base_score / (item + epsilon) # A simple decay factor\n    fitting_scores[loose_fit_mask] = loose_fit_base_score - score_decay_loose * (remaining_after_fit[loose_fit_mask] - moderate_fit_threshold)\n\n    # Ensure scores are non-negative and have a minimum positive value\n    fitting_scores = np.maximum(fitting_scores, 0.1)\n\n    # 5. Exploration: Add a small random component\n    exploration_factor = 0.05  # Small random noise to break ties\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * (fitting_scores.max() - fitting_scores.min() + epsilon)\n    fitting_scores += random_scores\n\n    # Assign the computed priorities to the fitting bins\n    scores[can_fit_mask] = fitting_scores\n\n    return scores",
    "response_id": 8,
    "obj": 4.038691663342641,
    "SLOC": 34.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for the online Bin Packing Problem.\n    This version aims for more nuanced prioritization by tuning thresholds,\n    decay functions, and penalty factors, while maintaining the core logic\n    of favoring tight fits and penalizing waste.\n\n    Priority Calculation:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is near zero): Highest priority.\n       b. Tight Fits (remaining capacity after packing is small and positive):\n          High priority, with a rapidly decreasing score as remaining capacity grows.\n          This encourages filling bins as much as possible without leaving\n          trivial amounts of space.\n       c. Moderate Fits (remaining capacity is larger but not excessively so):\n          Medium priority, with a slower decay than tight fits. This allows\n          selection of bins that are not optimally filled but are still\n          reasonable choices.\n       d. Wasteful Fits (remaining capacity is significantly larger than the item):\n          Heavily penalized. The penalty increases with the amount of excess\n          space, strongly discouraging the selection of bins with substantial\n          unused capacity.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for the corresponding bin. Higher scores indicate\n        higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Tuned Parameters ---\n    epsilon = 1e-9  # For floating-point comparisons\n\n    # Thresholds:\n    # 'tight_fit_max_rem': Max remaining capacity to be considered a \"tight fit\".\n    # A value close to 'item' or slightly larger to allow for slight overfill due to rounding or\n    # to encourage using bins that have *just enough* space. Let's set it to 1.2 * item.\n    tight_fit_max_rem = 1.2 * item\n\n    # 'moderate_fit_max_rem': Max remaining capacity for a \"moderate fit\".\n    # Anything above this, but still able to fit the item, is considered \"wasteful\".\n    # This threshold should be significantly larger than 'tight_fit_max_rem'.\n    # Let's set it to 2.5 * item, aiming to penalize bins that leave more than double\n    # the item's space empty.\n    moderate_fit_max_rem = 2.5 * item\n\n    # Score weights and decay factors:\n    perfect_fit_score = 100.0\n    tight_fit_base_score = 60.0\n    tight_fit_decay_factor = 2.0 # Steeper decay for tight fits\n    moderate_fit_base_score = 30.0\n    moderate_fit_decay_factor = 0.7 # Slower decay for moderate fits\n    wasteful_penalty_factor = 15.0 # How strongly we penalize wasteful fits\n\n    # Calculate scores for fitting bins\n    scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = perfect_fit_score\n\n    # 2. Tight Fits: High priority, steep decay\n    tight_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= tight_fit_max_rem)\n    # Using a function like `base / (1 + k*x^p)` where p > 1 for steep decay.\n    scores[tight_mask] = tight_fit_base_score / (1.0 + tight_fit_decay_factor * (remaining_after_fit[tight_mask] / item)**2)\n\n    # 3. Moderate Fits: Medium priority, slower decay\n    moderate_mask = (remaining_after_fit > tight_fit_max_rem) & (remaining_after_fit <= moderate_fit_max_rem)\n    # Using a function like `base / (1 + k*x^p)` where p < 1 or p=1 for slower decay.\n    scores[moderate_mask] = moderate_fit_base_score / (1.0 + (remaining_after_fit[moderate_mask] / item)**0.8)\n\n    # 4. Wasteful Fits: Heavily penalized\n    wasteful_mask = (remaining_after_fit > moderate_fit_max_rem)\n    # Penalize based on how much \"excess\" space beyond the moderate threshold is left.\n    # The penalty should reduce the score significantly.\n    # Penalty = factor * (excess_space / item)\n    excess_space = remaining_after_fit[wasteful_mask] - moderate_fit_max_rem\n    penalty = wasteful_penalty_factor * (excess_space / item)\n    # Start with a base score (lower than moderate) and subtract penalty.\n    # Or, directly calculate a negative score or very low positive score.\n    # Let's assign a base score and then apply a penalty that can make it negative.\n    wasteful_base_score = 5.0\n    scores[wasteful_mask] = wasteful_base_score - penalty\n\n    # Ensure scores are non-negative. Any score calculated to be negative becomes 0.\n    scores[scores < 0] = 0\n\n    # Add a small, scaled random jitter for exploration.\n    # This helps break ties between bins with very similar priority scores.\n    # The jitter magnitude is relative to the maximum possible score to ensure it has an effect.\n    max_possible_score = perfect_fit_score\n    exploration_factor = 0.03 # Reduced exploration to prioritize deterministic logic\n    jitter = np.random.rand(len(scores)) * exploration_factor * max_possible_score\n    final_scores = scores + jitter\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 9,
    "obj": 4.038691663342641,
    "SLOC": 37.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]