```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a hybrid strategy.

    This strategy prioritizes bins that offer a "tight fit" (minimizing leftover capacity)
    while also encouraging exploration by giving a slight boost to bins that are not too full,
    leaving more room for potentially larger future items. It also introduces a mechanism
    to avoid bins that are *too* close to being full, which might prevent fitting
    future items of moderate size.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Determine which bins can fit the item
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit, return all zeros

    fitting_bins_caps = bins_remain_cap[can_fit_mask]

    # Strategy 1: Tight Fit - prioritize bins that will have the least remaining capacity.
    # This aims to minimize waste. We want smaller remaining capacity to get higher scores.
    # Adding 1.0 to the denominator avoids division by zero and scales scores to be positive.
    remaining_after_fit = fitting_bins_caps - item
    tight_fit_scores = 1.0 / (1.0 + remaining_after_fit)

    # Strategy 2: Room for Future Items - prioritize bins that have substantial remaining capacity,
    # but not so much that they are inefficiently used by this item.
    # This prevents over-prioritizing bins that are almost empty.
    # We define "good room" as having remaining capacity that is significantly larger than the item,
    # but not excessively large. A simple heuristic could be remaining capacity in the middle range.
    # Let's consider bins with remaining capacity greater than item * 2 but less than bin_capacity / 2.
    # This is a tunable parameter. For simplicity here, let's boost bins that have
    # a moderate amount of remaining space after fitting.
    # A bin with remaining capacity = item is the "tightest" fit, score = 1.
    # A bin with remaining capacity = item * 2 is a "good fit", score is lower.
    # We can inversely relate to remaining_after_fit, but ensure it's not too large.
    # Let's create a score that is higher for intermediate remaining capacities.
    # For example, a quadratic function peaking at some intermediate remaining capacity.
    # A simpler approach: slightly boost bins that aren't *just* barely fitting.
    # Let's give a slight positive score for bins that have remaining_after_fit > 0.
    # This is to encourage using bins that have some "slack".
    exploration_boost = 0.1  # Small boost for having some remaining space
    exploration_scores = np.zeros_like(fitting_bins_caps)
    exploration_scores[remaining_after_fit > 0] = exploration_boost

    # Strategy 3: Avoid Over-filling "Almost Full" Bins -
    # Slightly penalize bins that would become *extremely* full if the item is added,
    # if they were already very close to capacity.
    # This is to prevent situations where a bin is filled to 99% with a small item,
    # making it impossible to fit even a moderately sized future item.
    # Let's define "almost full" as remaining_after_fit < a small epsilon.
    # The penalty should be proportional to how "full" it gets.
    epsilon = 0.05 # A small threshold for "almost full"
    penalty_factor = 0.5
    penalty_scores = np.zeros_like(fitting_bins_caps)
    almost_full_condition = (remaining_after_fit < epsilon) & (fitting_bins_caps > epsilon) # Ensure it's not an empty bin
    # Penalize more if the remaining capacity after fit is very small
    penalty_scores[almost_full_condition] = -penalty_factor * (epsilon - remaining_after_fit[almost_full_condition]) / epsilon


    # Combine scores. Prioritize tight fits, give a small boost for having room, and penalize very tight fits.
    # Weights are chosen heuristically.
    combined_scores = (0.8 * tight_fit_scores) + (0.2 * exploration_scores) + penalty_scores

    # Assign the calculated scores to the corresponding bins
    priorities[can_fit_mask] = combined_scores

    # Ensure bins that cannot fit have a priority of 0 (already handled by initialization and mask)

    return priorities
```
