```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements an advanced, adaptive priority function for the online Bin Packing Problem.
    This version dynamically adjusts thresholds and scoring based on the item size
    and the distribution of remaining capacities in the bins to favor tighter fits
    and penalize wasted space more effectively.

    Priority calculation:
    1. Bins that cannot fit the item receive a priority of 0.
    2. For bins that can fit the item:
       a. Perfect Fits (remaining capacity is negligible): Highest priority.
       b. Tight Fits (remaining capacity is small relative to item): High priority,
          inversely proportional to the remaining capacity.
       c. Moderate Fits (remaining capacity is moderate): Priority decreases linearly
          with increasing remaining capacity.
       d. Wasteful Fits (remaining capacity is large relative to item): Significantly
          penalized, with the penalty increasing with the amount of excess space.

    Args:
        item: Size of the item to be packed.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin. Higher score means higher priority.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros(num_bins, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item
    fitting_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    epsilon = 1e-9  # For numerical stability and to avoid division by zero

    # --- Adaptive Thresholds and Scoring ---

    # 1. Perfect Fits: Highest priority
    perfect_fit_mask = (remaining_after_fit < epsilon)
    # Assign a very high, fixed score to perfect fits.
    perfect_scores = np.full(np.sum(perfect_fit_mask), 1e9)

    # For non-perfect fits, calculate scores based on remaining capacity
    non_perfect_mask = ~perfect_fit_mask
    if np.any(non_perfect_mask):
        non_perfect_remaining = remaining_after_fit[non_perfect_mask]

        # Define adaptive thresholds relative to item size for better adaptation
        # "Tight" fit: remaining space is small compared to the item.
        # e.g., less than 15% of the item size.
        tight_threshold = item * 0.15
        # "Wasteful" fit: remaining space is large compared to the item.
        # e.g., more than 1.5 times the item size.
        wasteful_threshold = item * 1.5

        # Calculate a base score that favors smaller remaining capacity
        # Using a form like 1 / (remaining + small_constant)
        base_scores = 1.0 / (non_perfect_remaining + epsilon)

        # Initialize scores for non-perfect fits
        calculated_non_perfect_scores = np.copy(base_scores)

        # Apply modifiers based on fit type:

        # 2. Tight Fits: Boost the base score.
        # If remaining capacity is less than or equal to the tight threshold.
        tight_fit_mask_subset = (non_perfect_remaining <= tight_threshold)
        # Boost score quadratically as remaining capacity gets closer to zero.
        # This gives higher priority to even tighter fits within the "tight" category.
        boost_factor_tight = 5.0 * (1.0 - non_perfect_remaining[tight_fit_mask_subset] / (tight_threshold + epsilon))
        calculated_non_perfect_scores[tight_fit_mask_subset] *= (1.0 + boost_factor_tight)

        # 3. Moderate Fits: Use the base score, potentially scaled.
        # These are bins where remaining capacity is between tight_threshold and wasteful_threshold.
        moderate_fit_mask_subset = (non_perfect_remaining > tight_threshold) & (non_perfect_remaining <= wasteful_threshold)
        # For moderate fits, the base score is already good. We can scale it slightly,
        # or just let it be. Let's slightly boost based on how "moderate" it is.
        moderate_boost = 1.0 + 0.5 * (wasteful_threshold - non_perfect_remaining[moderate_fit_mask_subset]) / (wasteful_threshold - tight_threshold + epsilon)
        calculated_non_perfect_scores[moderate_fit_mask_subset] *= moderate_boost


        # 4. Wasteful Fits: Penalize the score.
        # If remaining capacity is greater than the wasteful threshold.
        wasteful_fit_mask_subset = (non_perfect_remaining > wasteful_threshold)
        # Penalize more heavily as the remaining space increases.
        # The penalty should be proportional to how much "excess" space there is.
        # Penalty = 1.0 - k * (excess_space / item)
        penalty_strength = 0.8  # How aggressively we penalize
        excess_space_ratio = (non_perfect_remaining[wasteful_fit_mask_subset] - wasteful_threshold) / (item + epsilon)
        penalty_factor = penalty_strength * excess_space_ratio
        # Ensure the penalty doesn't make the score extremely negative,
        # and doesn't go below a minimum positive value if that's desired.
        # We will cap the multiplier to prevent scores from becoming too small or negative.
        # Minimum multiplier of 0.1 means the score can be at most 10% of the base.
        calculated_non_perfect_scores[wasteful_fit_mask_subset] *= np.maximum(0.1, 1.0 - penalty_factor)

        # Ensure scores are non-negative
        calculated_non_perfect_scores[calculated_non_perfect_scores < 0] = 0

        # Combine perfect and non-perfect scores
        all_scores_for_fitting_bins = np.zeros_like(remaining_after_fit)
        all_scores_for_fitting_bins[perfect_fit_mask] = perfect_scores
        all_scores_for_fitting_bins[non_perfect_mask] = calculated_non_perfect_scores

        # Normalize scores to prevent potential overflow and ensure relative scale is maintained.
        # Max score can be 1e9 for perfect fits.
        # For other scores, ensure they are significantly lower than perfect fits but still meaningful.
        max_non_perfect_score = np.max(all_scores_for_fitting_bins[non_perfect_mask]) if np.any(non_perfect_mask) else 0
        if max_non_perfect_score > 0:
            all_scores_for_fitting_bins[non_perfect_mask] /= max_non_perfect_score # Normalize non-perfect scores to a max of 1
            all_scores_for_fitting_bins[non_perfect_mask] *= (1e9 / 10.0) # Scale them to be high but less than perfect

        # Add a small random jitter for exploration
        # Jitter is a small percentage of the current score to encourage diversity in selection.
        jitter_strength = 0.05 # 5% of the current score
        jitter = np.random.normal(0, jitter_strength, size=all_scores_for_fitting_bins.shape) * all_scores_for_fitting_bins
        final_scores_for_fitting_bins = all_scores_for_fitting_bins + jitter
        final_scores_for_fitting_bins[final_scores_for_fitting_bins < 0] = 0 # Ensure no negative scores due to jitter

    else: # Only perfect fits exist
        final_scores_for_fitting_bins = perfect_scores


    # Assign the calculated scores to the corresponding bins in the original priority array
    priorities[fitting_bins_indices] = final_scores_for_fitting_bins

    return priorities
```
