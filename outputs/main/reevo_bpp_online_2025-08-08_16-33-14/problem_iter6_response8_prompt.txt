{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements a more sophisticated hybrid priority function for online Bin Packing Problem.\n    This version refines the scoring by categorizing fits and using a combination of\n    inverse remaining capacity and a penalty for bins that are too empty.\n\n    The strategy is as follows:\n    1. Perfect Fit: Highest priority (remaining capacity is zero).\n    2. Tight Fit: High priority (remaining capacity is small, but positive).\n    3. Good Fit: Moderate priority (remaining capacity is larger, but not excessively so).\n    4. Loose Fit: Lower priority (remaining capacity is very large).\n\n    It also incorporates a penalty for bins that are \"too empty\" to encourage\n    packing items into bins that are already somewhat utilized, thus avoiding\n    fragmentation and the creation of too many bins with large remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)  # Initialize with negative infinity\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components based on remaining capacity after fit\n    epsilon = 1e-9  # Small value to handle exact fits and avoid division by zero\n\n    # --- Scoring components ---\n\n    # 1. Best Fit Component: Prioritize bins with minimal remaining capacity after fitting.\n    # Higher score for smaller `remaining_after_fit`.\n    best_fit_score_component = 1.0 / (remaining_after_fit + epsilon)\n\n    # 2. \"Too Empty\" Penalty Component: Penalize bins that would remain very empty.\n    # This discourages placing an item in a bin where it takes up only a tiny fraction of space.\n    # The penalty is higher for bins that are *more* empty relative to their total capacity\n    # (or a \"reasonable\" capacity threshold).\n    # Let's define \"too empty\" as having remaining capacity > threshold.\n    # A reasonable threshold could be related to the item size or bin capacity.\n    # Here, we use a threshold relative to the item size to encourage using partially filled bins.\n    # A bin that remains \"too empty\" (e.g., remaining capacity is a large multiple of item size)\n    # should have a lower score.\n    # We want to *subtract* from the priority if it's too empty.\n\n    # Threshold for \"too empty\": if remaining capacity is more than X times the item size.\n    # This encourages filling bins more.\n    too_empty_threshold_factor = 4.0\n    too_empty_threshold = item * too_empty_threshold_factor\n\n    # Calculate a penalty factor. Higher penalty for larger remaining capacity beyond the threshold.\n    # Using a sigmoid-like function or a simple inverse relation.\n    # Penalty is 0 if remaining_after_fit <= too_empty_threshold.\n    # Penalty increases as remaining_after_fit increases beyond the threshold.\n    # We want to subtract a value that gets larger as it becomes \"too empty\".\n    # A simple approach: penalize bins where remaining_after_fit is large.\n    # Normalize remaining capacity to a scale, e.g., max possible remaining capacity.\n    # A simpler approach for now: penalize based on the absolute value of remaining_after_fit.\n    # Or, more effectively, penalize based on the *ratio* of remaining_after_fit to the bin's original capacity.\n    # However, we don't have original capacity here. Let's use remaining_after_fit directly.\n\n    # Create a penalty based on how much `remaining_after_fit` exceeds `too_empty_threshold`.\n    # We use a small positive value for bins that are not too empty to avoid issues.\n    # For bins that are too empty, we want a penalty that grows.\n    # Example penalty: `max(0, remaining_after_fit - too_empty_threshold) / (item + epsilon)`\n    # This penalizes bins that leave a lot of space.\n\n    penalty_component = np.maximum(0, remaining_after_fit - too_empty_threshold) / (item + epsilon)\n\n    # Combine the components.\n    # We want to prioritize best fit and *deprioritize* too empty bins.\n    # So, the penalty should subtract from the score.\n    # We can scale the penalty component to control its impact.\n    penalty_weight = 0.5  # Tunable parameter to control how strongly we penalize \"too empty\" bins\n\n    # Initial combined score\n    combined_scores = best_fit_score_component - penalty_weight * penalty_component\n\n    # --- Prioritization based on specific fit types (can refine the combined score) ---\n    # We can boost scores for perfect fits and tight fits, and potentially\n    # reduce scores for very loose fits before applying the penalty.\n\n    # Perfect fit boost: Very high priority\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    combined_scores[perfect_fit_mask] = np.maximum(combined_scores[perfect_fit_mask], 100.0)\n\n    # Tight fit boost: High priority, e.g., remaining capacity <= item size.\n    tight_fit_threshold = item\n    tight_fit_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    # Boost tight fits slightly more if they are not already extremely high from best fit.\n    combined_scores[tight_fit_mask] = np.maximum(combined_scores[tight_fit_mask], combined_scores[tight_fit_mask] * 1.5)\n\n    # Loose fit reduction: Reduce scores for bins that are very loose.\n    # If remaining capacity is very large (e.g., > 5*item), reduce their priority.\n    loose_fit_threshold = item * 5.0\n    loose_fit_mask = (remaining_after_fit > loose_fit_threshold)\n    combined_scores[loose_fit_mask] *= 0.7 # Reduce priority for loose fits\n\n\n    # Add a small random component for exploration to all fitting bins\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements an enhanced priority function for online Bin Packing Problem.\n    This version uses a combination of 'best fit' and 'first fit' tendencies,\n    incorporating a penalty for bins that leave an excessive amount of remaining space.\n    It also includes a stronger emphasis on perfect fits and a more nuanced\n    scoring for near-perfect fits.\n\n    The priority is calculated as follows:\n    1. Bins that cannot fit the item get a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.\n       b. Near-Perfect Fits (remaining capacity after packing is small): High priority,\n          inversely proportional to the remaining capacity.\n       c. Other Fits: Priority decreases as the remaining capacity increases,\n          with a steeper drop-off for larger remaining capacities.\n       d. A \"wastefulness\" penalty is applied to bins that leave a lot of space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components and thresholds\n    epsilon = 1e-9\n    # Threshold for \"near-perfect\" fits - e.g., leaving space less than 10% of bin capacity\n    # or less than item size, whichever is smaller and positive.\n    near_perfect_threshold = min(0.1 * bins_remain_cap.max(), item) if bins_remain_cap.max() > 0 else item\n    # Threshold for \"wasteful\" bins - e.g., leaving space more than 50% of bin capacity\n    # or more than 2 * item size.\n    wasteful_threshold = max(0.5 * bins_remain_cap.max(), 2.0 * item) if bins_remain_cap.max() > 0 else 2.0 * item\n\n    # Calculate base scores\n    base_scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    base_scores[perfect_mask] = 1000.0\n\n    # 2. Near-Perfect Fits: High priority, inversely proportional to remaining capacity\n    near_perfect_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= near_perfect_threshold)\n    # Use a concave function to give diminishing returns as remaining capacity increases\n    # Ensure we don't divide by zero or get excessively large numbers.\n    base_scores[near_perfect_mask] = 50.0 / (1.0 + remaining_after_fit[near_perfect_mask] * 10.0)\n\n    # 3. Other Fits: Priority decreases with remaining capacity\n    other_mask = ~perfect_mask & ~near_perfect_mask\n    # A function that decreases rapidly for larger gaps.\n    # We want to favor bins that leave less space.\n    # (1 / (1 + x)) or (1 / (1 + x^2)) are good candidates.\n    # Let's use a slightly more aggressive decay for larger gaps.\n    # Add a small constant to avoid division by zero if remaining_after_fit is 0\n    # (though perfect_mask should handle this).\n    base_scores[other_mask] = 10.0 / (1.0 + remaining_after_fit[other_mask]**1.5)\n\n    # 4. Wastefulness Penalty: Reduce priority for bins that leave too much space\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Apply a penalty that is proportional to how much they exceed the wasteful threshold.\n    penalty = 5.0 * (remaining_after_fit[wasteful_mask] - wasteful_threshold) / (fitting_bins_caps[wasteful_mask] + epsilon)\n    base_scores[wasteful_mask] -= penalty\n\n    # Ensure scores are not negative (though penalty is designed not to make them so easily)\n    base_scores[base_scores < 0] = 0\n\n    # Add a small random component for exploration to all fitting bins\n    # This helps in escaping local optima and exploring different packing configurations.\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * np.max(base_scores + epsilon)\n    final_scores = base_scores + random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities\n\n[Reflection]\nPrioritize tight fits, penalize wasted space, and use adaptive thresholds.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}