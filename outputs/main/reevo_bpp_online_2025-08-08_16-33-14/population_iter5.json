[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined hybrid strategy.\n\n    This strategy refines the 'Best Fit' and 'Almost Full' criteria.\n    It prioritizes bins that have a remaining capacity closest to the item size (Best Fit).\n    It also favors bins that are \"tightly packed\" after the item is placed, meaning\n    the remaining capacity is small. A small additive factor is used to provide\n    higher priority to bins that become exactly full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # If no bin can fit, return scores that reflect no valid placement\n        return scores\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Criterion 1: Best Fit - prioritize bins that will have the least remaining capacity\n    # after the item is placed. This means minimizing (bins_remain_cap - item).\n    # Higher score for smaller (bins_remain_cap - item).\n    # To ensure bins that become exactly full (remaining capacity = 0) get the highest\n    # priority among fitting bins, we can use a score that is the negative of the\n    # remaining capacity after fitting.\n    # Score = -(remaining_capacity_after_fit)\n    # This naturally gives 0 for exact fits, and negative scores for bins with residual space.\n    remaining_after_fit = fitting_bins_caps - item\n    best_fit_priority = -remaining_after_fit\n\n    # Criterion 2: Tight Packing - Prioritize bins that are already quite full,\n    # such that placing the item makes them *even more* tightly packed.\n    # This can be thought of as favoring bins where the current remaining capacity\n    # is only slightly larger than the item size.\n    # A simpler interpretation aligning with \"closeness to full\" after fit:\n    # We already captured this with Best Fit.\n    # Let's refine: prioritize bins that, after placing the item, leave very little space.\n    # The `best_fit_priority` already does this.\n\n    # Let's introduce a small bonus for exact fits to ensure they are strongly preferred.\n    # If remaining_after_fit is 0, the best_fit_priority is 0.\n    # We can add a small epsilon to it for exact fits.\n    # A small epsilon added to the \"best fit\" score for exact fits.\n    # This ensures exact fits are slightly preferred over bins that leave a tiny bit of space.\n    epsilon_for_exact_fit = 1e-6\n    tight_packing_priority = best_fit_priority + (best_fit_priority == 0) * epsilon_for_exact_fit\n\n    # Combine criteria: Primarily Best Fit, with a slight boost for exact fits.\n    # Since `best_fit_priority` already sorts correctly (higher for smaller remaining),\n    # and exact fits have the highest score (0), the `tight_packing_priority`\n    # directly reflects the desired ordering.\n\n    # Assign the computed priorities to the fitting bins\n    scores[can_fit_mask] = tight_packing_priority\n\n    # Non-fitting bins remain at -np.inf, ensuring they are never chosen if a fit exists.\n\n    return scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a more sophisticated hybrid priority function for online Bin Packing Problem.\n    This version refines the scoring by categorizing fits and using a combination of\n    inverse remaining capacity and a penalty for bins that are too empty.\n\n    The strategy is as follows:\n    1. Perfect Fit: Highest priority (remaining capacity is zero).\n    2. Tight Fit: High priority (remaining capacity is small, but positive).\n    3. Good Fit: Moderate priority (remaining capacity is larger, but not excessively so).\n    4. Loose Fit: Lower priority (remaining capacity is very large).\n\n    It also incorporates a penalty for bins that are \"too empty\" to encourage\n    packing items into bins that are already somewhat utilized, thus avoiding\n    fragmentation and the creation of too many bins with large remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)  # Initialize with negative infinity\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components based on remaining capacity after fit\n    epsilon = 1e-9  # Small value to handle exact fits and avoid division by zero\n\n    # --- Scoring components ---\n\n    # 1. Best Fit Component: Prioritize bins with minimal remaining capacity after fitting.\n    # Higher score for smaller `remaining_after_fit`.\n    best_fit_score_component = 1.0 / (remaining_after_fit + epsilon)\n\n    # 2. \"Too Empty\" Penalty Component: Penalize bins that would remain very empty.\n    # This discourages placing an item in a bin where it takes up only a tiny fraction of space.\n    # The penalty is higher for bins that are *more* empty relative to their total capacity\n    # (or a \"reasonable\" capacity threshold).\n    # Let's define \"too empty\" as having remaining capacity > threshold.\n    # A reasonable threshold could be related to the item size or bin capacity.\n    # Here, we use a threshold relative to the item size to encourage using partially filled bins.\n    # A bin that remains \"too empty\" (e.g., remaining capacity is a large multiple of item size)\n    # should have a lower score.\n    # We want to *subtract* from the priority if it's too empty.\n\n    # Threshold for \"too empty\": if remaining capacity is more than X times the item size.\n    # This encourages filling bins more.\n    too_empty_threshold_factor = 4.0\n    too_empty_threshold = item * too_empty_threshold_factor\n\n    # Calculate a penalty factor. Higher penalty for larger remaining capacity beyond the threshold.\n    # Using a sigmoid-like function or a simple inverse relation.\n    # Penalty is 0 if remaining_after_fit <= too_empty_threshold.\n    # Penalty increases as remaining_after_fit increases beyond the threshold.\n    # We want to subtract a value that gets larger as it becomes \"too empty\".\n    # A simple approach: penalize bins where remaining_after_fit is large.\n    # Normalize remaining capacity to a scale, e.g., max possible remaining capacity.\n    # A simpler approach for now: penalize based on the absolute value of remaining_after_fit.\n    # Or, more effectively, penalize based on the *ratio* of remaining_after_fit to the bin's original capacity.\n    # However, we don't have original capacity here. Let's use remaining_after_fit directly.\n\n    # Create a penalty based on how much `remaining_after_fit` exceeds `too_empty_threshold`.\n    # We use a small positive value for bins that are not too empty to avoid issues.\n    # For bins that are too empty, we want a penalty that grows.\n    # Example penalty: `max(0, remaining_after_fit - too_empty_threshold) / (item + epsilon)`\n    # This penalizes bins that leave a lot of space.\n\n    penalty_component = np.maximum(0, remaining_after_fit - too_empty_threshold) / (item + epsilon)\n\n    # Combine the components.\n    # We want to prioritize best fit and *deprioritize* too empty bins.\n    # So, the penalty should subtract from the score.\n    # We can scale the penalty component to control its impact.\n    penalty_weight = 0.5  # Tunable parameter to control how strongly we penalize \"too empty\" bins\n\n    # Initial combined score\n    combined_scores = best_fit_score_component - penalty_weight * penalty_component\n\n    # --- Prioritization based on specific fit types (can refine the combined score) ---\n    # We can boost scores for perfect fits and tight fits, and potentially\n    # reduce scores for very loose fits before applying the penalty.\n\n    # Perfect fit boost: Very high priority\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    combined_scores[perfect_fit_mask] = np.maximum(combined_scores[perfect_fit_mask], 100.0)\n\n    # Tight fit boost: High priority, e.g., remaining capacity <= item size.\n    tight_fit_threshold = item\n    tight_fit_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    # Boost tight fits slightly more if they are not already extremely high from best fit.\n    combined_scores[tight_fit_mask] = np.maximum(combined_scores[tight_fit_mask], combined_scores[tight_fit_mask] * 1.5)\n\n    # Loose fit reduction: Reduce scores for bins that are very loose.\n    # If remaining capacity is very large (e.g., > 5*item), reduce their priority.\n    loose_fit_threshold = item * 5.0\n    loose_fit_mask = (remaining_after_fit > loose_fit_threshold)\n    combined_scores[loose_fit_mask] *= 0.7 # Reduce priority for loose fits\n\n\n    # Add a small random component for exploration to all fitting bins\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 29.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit Decreasing-like strategy.\n\n    This heuristic prioritizes bins that can fit the item and, among those,\n    prioritizes bins that will have the least remaining capacity *after*\n    placing the item. This aims to pack items tightly and minimize wasted space.\n\n    The priority is calculated as: 1 / (1 + remaining_capacity_after_placement).\n    This formula gives higher priority to bins where the remaining capacity\n    after placing the item is smaller.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity for bins that can fit the item\n    # If an item cannot fit, the remaining capacity is effectively infinite in terms of priority.\n    # For fitting bins, calculate the remaining capacity after placement.\n    remaining_after_placement = np.where(can_fit_mask, bins_remain_cap - item, np.inf)\n\n    # To prioritize bins with minimal remaining capacity after placement,\n    # we use the inverse of (1 + remaining_capacity_after_placement).\n    # Adding 1 ensures the denominator is always at least 1, and the inverse\n    # means smaller remaining capacities get higher priorities.\n    # np.inf will result in a priority of 0, correctly indicating these bins are not preferred.\n    # Use a small epsilon for numerical stability if remaining_after_placement can be very close to zero.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Avoid division by zero for bins that can fit.\n    # If remaining_after_placement is 0, the priority should be maximal.\n    # The current formula 1 / (1 + 0) = 1, which is correct.\n    # For bins that cannot fit, remaining_after_placement is np.inf, resulting in 0 priority.\n    fit_mask_valid = can_fit_mask # Mask for bins that can fit\n    if np.any(fit_mask_valid):\n        priorities[fit_mask_valid] = 1.0 / (1.0 + remaining_after_placement[fit_mask_valid])\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem,\n    prioritizing perfect fits, then tight fits, and categorizing other fits based on thresholds.\n\n    This version aims to achieve a balance between filling bins tightly and leaving\n    sufficient space for future items by using distinct scoring for different\n    remaining capacity scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define scoring weights and thresholds for different fit categories.\n    # These values are heuristic and can be tuned for performance.\n    epsilon = 1e-9  # To handle perfect fits and avoid division by zero\n    perfect_fit_score = 10.0\n    tight_fit_weight = 0.8\n    tight_threshold = item * 0.1  # Up to 10% of item size remaining\n    good_fit_weight = 0.5\n    good_threshold = item * 0.5  # Up to 50% of item size remaining\n    loose_fit_weight = 0.2\n\n    # Calculate scores for each fitting bin\n    scores = np.zeros_like(fitting_bins_caps)\n\n    # Perfect Fit: Highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = perfect_fit_score\n\n    # Tight Fit: Prioritize bins that leave very little but non-zero space.\n    tight_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= tight_threshold)\n    scores[tight_mask] = tight_fit_weight / (1.0 + remaining_after_fit[tight_mask])\n\n    # Good Fit: Prioritize bins that leave a moderate amount of space.\n    good_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold)\n    scores[good_mask] = good_fit_weight / (1.0 + remaining_after_fit[good_mask])\n\n    # Loose Fit: Bins with significant remaining space, lower priority.\n    loose_mask = (remaining_after_fit > good_threshold)\n    scores[loose_mask] = loose_fit_weight / (1.0 + remaining_after_fit[loose_mask])\n\n    # Assign the calculated scores to the original priority array\n    priorities[can_fit_mask] = scores\n\n    return priorities",
    "response_id": 3,
    "obj": 4.198244914240141,
    "SLOC": 27.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid strategy.\n\n    This strategy prioritizes bins that offer a \"tight fit\" (minimizing leftover capacity)\n    while also encouraging exploration by giving a slight boost to bins that are not too full,\n    leaving more room for potentially larger future items. It also introduces a mechanism\n    to avoid bins that are *too* close to being full, which might prevent fitting\n    future items of moderate size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Determine which bins can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit, return all zeros\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Strategy 1: Tight Fit - prioritize bins that will have the least remaining capacity.\n    # Higher score for smaller remaining capacity. Adding a small constant to the denominator\n    # to ensure positivity and avoid division by zero. The `1.0 +` acts as a baseline score.\n    tight_fit_scores = 1.0 / (1.0 + remaining_after_fit)\n\n    # Strategy 2: Exploration Boost - encourage bins that have a moderate amount of leftover space.\n    # This helps avoid \"over-filling\" bins too aggressively with small items, potentially\n    # leaving them less useful for future, larger items.\n    # We define \"moderate\" leftover space as being greater than a small epsilon,\n    # but not excessively large. For simplicity, we'll give a small constant boost if\n    # there's any positive remaining space, making it slightly more attractive than\n    # a bin that would be filled to exact capacity (if that were possible).\n    # The boost should be less than the tight_fit_score gain from reducing remaining space.\n    exploration_boost_amount = 0.1\n    exploration_scores = np.zeros_like(fitting_bins_caps)\n    # Boost bins that have some room, but not bins that are exactly filled.\n    exploration_scores[remaining_after_fit > 1e-6] = exploration_boost_amount\n\n\n    # Strategy 3: Penalty for Over-tightness - discourage bins that would become\n    # extremely full, leaving very little room for future items.\n    # This penalty is applied when `remaining_after_fit` is very small, indicating\n    # a nearly full bin. The penalty is higher the closer it is to zero remaining space.\n    # A threshold is used to define \"too tight\".\n    overtight_threshold = 0.1 # A small fraction of the item size, or absolute small value\n    overtight_penalty_scale = 0.5 # How strongly to penalize over-tightness\n    overtight_penalty = np.zeros_like(fitting_bins_caps)\n\n    # Apply penalty if remaining capacity is less than the threshold\n    penalty_mask = remaining_after_fit < overtight_threshold\n    # The penalty is proportional to how much less than the threshold it is.\n    # Normalize the penalty to be between 0 and overtight_penalty_scale.\n    overtight_penalty[penalty_mask] = overtight_penalty_scale * (overtight_threshold - remaining_after_fit[penalty_mask]) / overtight_threshold\n\n    # Combine scores:\n    # Weight tight_fit_scores more heavily, add exploration boost, and subtract overtight penalty.\n    # The goal is to achieve a balance: prioritize tightest fits, but not at the expense\n    # of creating unusable bins with minimal remaining space.\n    # Weights are heuristic and can be tuned.\n    tight_fit_weight = 0.7\n    exploration_weight = 0.3\n\n    combined_scores = (tight_fit_weight * tight_fit_scores) + (exploration_weight * exploration_scores) - overtight_penalty\n\n    # Assign the calculated scores to the corresponding bins\n    priorities[can_fit_mask] = combined_scores\n\n    # Ensure priorities are non-negative. While the logic above should generally produce\n    # positive scores, it's good practice to clip any potential negatives.\n    priorities[can_fit_mask] = np.maximum(0, priorities[can_fit_mask])\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 23.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for online Bin Packing Problem.\n    This version prioritizes tight fits by favoring bins that leave minimal\n    remaining capacity, but introduces a penalty for bins that would be *too* full,\n    meaning the remaining capacity is very close to zero. It categorizes fits\n    to assign different levels of priority.\n\n    Scoring logic:\n    1. Perfect Fit (remaining capacity is effectively zero): High priority.\n    2. Tight Fit (remaining capacity is small but positive): Moderate to high priority,\n       inversely proportional to remaining capacity.\n    3. Good Fit (remaining capacity is moderate): Lower priority, inversely proportional\n       to remaining capacity.\n    4. Loose Fit (remaining capacity is large): Lowest priority among fitting bins.\n\n    A penalty is applied to 'tight' and 'perfect' fits if the remaining capacity\n    is below a certain small threshold, discouraging over-packing that might\n    make subsequent small items unplaceable.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define constants for scoring and penalty\n    epsilon = 1e-6  # For considering near-zero remaining capacity\n    # Threshold for applying the \"too full\" penalty.\n    # This is a small absolute value, intended to avoid situations where\n    # only a tiny sliver of space remains.\n    too_full_threshold = 0.1 * item  # e.g., 10% of item size or a small absolute value\n\n    # Calculate base scores favoring smaller remaining capacity\n    # Use 1/(1+x) which is high for small x and decreases as x increases.\n    # Add epsilon to denominator to prevent division by zero.\n    base_scores = 1.0 / (1.0 + remaining_after_fit + epsilon)\n\n    # Apply penalty for bins that become \"too full\" after packing\n    # The penalty is higher when remaining_after_fit is smaller (closer to zero)\n    # Penalize bins where remaining_after_fit < too_full_threshold\n    penalty_scores = np.zeros_like(remaining_after_fit)\n    too_full_mask = remaining_after_fit < too_full_threshold\n    # The penalty should be proportional to how much below the threshold it is.\n    # We scale it to ensure it can significantly reduce the priority.\n    penalty_scores[too_full_mask] = (too_full_threshold - remaining_after_fit[too_full_mask]) / too_full_threshold\n    \n    # Combine base scores with penalties.\n    # A higher base score (good fit) is reduced if the bin is too full.\n    # We want to subtract the penalty. The multiplier (e.g., 0.8) controls the penalty strength.\n    combined_scores = base_scores - (0.8 * penalty_scores)\n\n    # Normalize scores to ensure they are non-negative and have a meaningful range.\n    # Cap scores at 0 to avoid negative priorities.\n    priorities[can_fit_mask] = np.maximum(0, combined_scores)\n\n    # Further refinement: Add a small boost for bins that are \"just right\"\n    # rather than perfectly full or very loose.\n    # This is a more subtle adjustment than the penalty.\n    # Let's define a target remaining capacity, e.g., a small fraction of the bin capacity\n    # or a small absolute value.\n    # For simplicity, let's use a similar logic as the penalty but as a boost.\n    # Bins with remaining capacity slightly above zero (but not too full) might get a small boost.\n    # A Gaussian-like function centered around a small positive value could work.\n    # For this iteration, let's stick to the penalty on \"too full\" as the primary refinement.\n\n    # Optionally, add a small random perturbation for exploration/tie-breaking\n    exploration_noise = np.random.normal(0, 0.05, len(fitting_bins_caps))\n    priorities[can_fit_mask] += exploration_noise\n    # Ensure priorities remain non-negative after adding noise\n    priorities[can_fit_mask] = np.maximum(0, priorities[can_fit_mask])\n\n\n    # Ensure bins that cannot fit have a priority of 0 (already handled by initialization)\n    # priorities[~can_fit_mask] = 0\n\n    return priorities",
    "response_id": 5,
    "obj": 17.191862784204236,
    "SLOC": 21.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an enhanced priority function for online Bin Packing Problem.\n    This version uses a combination of 'best fit' and 'first fit' tendencies,\n    incorporating a penalty for bins that leave an excessive amount of remaining space.\n    It also includes a stronger emphasis on perfect fits and a more nuanced\n    scoring for near-perfect fits.\n\n    The priority is calculated as follows:\n    1. Bins that cannot fit the item get a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.\n       b. Near-Perfect Fits (remaining capacity after packing is small): High priority,\n          inversely proportional to the remaining capacity.\n       c. Other Fits: Priority decreases as the remaining capacity increases,\n          with a steeper drop-off for larger remaining capacities.\n       d. A \"wastefulness\" penalty is applied to bins that leave a lot of space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components and thresholds\n    epsilon = 1e-9\n    # Threshold for \"near-perfect\" fits - e.g., leaving space less than 10% of bin capacity\n    # or less than item size, whichever is smaller and positive.\n    near_perfect_threshold = min(0.1 * bins_remain_cap.max(), item) if bins_remain_cap.max() > 0 else item\n    # Threshold for \"wasteful\" bins - e.g., leaving space more than 50% of bin capacity\n    # or more than 2 * item size.\n    wasteful_threshold = max(0.5 * bins_remain_cap.max(), 2.0 * item) if bins_remain_cap.max() > 0 else 2.0 * item\n\n    # Calculate base scores\n    base_scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    base_scores[perfect_mask] = 1000.0\n\n    # 2. Near-Perfect Fits: High priority, inversely proportional to remaining capacity\n    near_perfect_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= near_perfect_threshold)\n    # Use a concave function to give diminishing returns as remaining capacity increases\n    # Ensure we don't divide by zero or get excessively large numbers.\n    base_scores[near_perfect_mask] = 50.0 / (1.0 + remaining_after_fit[near_perfect_mask] * 10.0)\n\n    # 3. Other Fits: Priority decreases with remaining capacity\n    other_mask = ~perfect_mask & ~near_perfect_mask\n    # A function that decreases rapidly for larger gaps.\n    # We want to favor bins that leave less space.\n    # (1 / (1 + x)) or (1 / (1 + x^2)) are good candidates.\n    # Let's use a slightly more aggressive decay for larger gaps.\n    # Add a small constant to avoid division by zero if remaining_after_fit is 0\n    # (though perfect_mask should handle this).\n    base_scores[other_mask] = 10.0 / (1.0 + remaining_after_fit[other_mask]**1.5)\n\n    # 4. Wastefulness Penalty: Reduce priority for bins that leave too much space\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Apply a penalty that is proportional to how much they exceed the wasteful threshold.\n    penalty = 5.0 * (remaining_after_fit[wasteful_mask] - wasteful_threshold) / (fitting_bins_caps[wasteful_mask] + epsilon)\n    base_scores[wasteful_mask] -= penalty\n\n    # Ensure scores are not negative (though penalty is designed not to make them so easily)\n    base_scores[base_scores < 0] = 0\n\n    # Add a small random component for exploration to all fitting bins\n    # This helps in escaping local optima and exploring different packing configurations.\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * np.max(base_scores + epsilon)\n    final_scores = base_scores + random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities",
    "response_id": 6,
    "obj": 4.028719585161557,
    "SLOC": 28.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an improved hybrid strategy.\n\n    This strategy prioritizes bins that offer a tight fit (minimizing leftover capacity)\n    while also considering bins that leave a moderate amount of space for future, potentially\n    larger items. It aims to balance exploiting near-perfect fits with exploring options that\n    maintain flexibility. A bias is introduced to favor bins that are not nearly full to\n    encourage a more even distribution of items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the current item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Strategy 1: Tight Fit (Best Fit)\n    # Calculate the capacity remaining *after* placing the item. We want to minimize this.\n    remaining_after_fit = fitting_bins_caps - item\n    # Score: Higher score for smaller remaining_after_fit. Add epsilon for stability.\n    best_fit_score = 1.0 / (1.0 + remaining_after_fit + 1e-9)\n\n    # Strategy 2: Moderate Space Preference\n    # This strategy aims to favor bins that leave a \"useful\" amount of space,\n    # not too little (already covered by best_fit_score) and not too much.\n    # A common heuristic is to prefer bins that were already somewhat full,\n    # as filling them further is more efficient than filling nearly empty bins.\n    # We'll use a score that rewards bins that have more capacity initially,\n    # scaled by the overall maximum capacity to normalize.\n    # This encourages using bins that are already partially filled.\n    max_cap_overall = np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1.0\n    # Score increases with initial bin capacity, encouraging use of less empty bins.\n    space_preference_score = fitting_bins_caps / max_cap_overall\n\n    # Combine strategies using a weighted sum.\n    # Prioritize tight fits (best_fit_score) with a secondary preference\n    # for bins that are not nearly empty (space_preference_score).\n    # The weight (0.3 here) balances these two objectives. A higher weight\n    # means more emphasis on leaving space/using less full bins.\n    weight_space_preference = 0.3\n    combined_score_subset = best_fit_score + weight_space_preference * space_preference_score\n\n    # Assign the calculated scores to the corresponding bins\n    priorities[can_fit_mask] = combined_score_subset\n\n    # Ensure bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities",
    "response_id": 7,
    "obj": 78.34064619066615,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid strategy.\n\n    This strategy prioritizes bins that offer a \"tight fit\" (minimizing leftover capacity),\n    while also encouraging exploration by giving a slight boost to bins that are not too full,\n    leaving more room for potentially larger future items. It also introduces a mechanism\n    to avoid bins that are *too* close to being full, which might prevent fitting\n    future items of moderate size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Determine which bins can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit, return all zeros\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Strategy 1: Tight Fit (Best Fit heuristic)\n    # Prioritize bins that will have the least remaining capacity after packing.\n    remaining_after_fit = fitting_bins_caps - item\n    # Higher score for smaller remaining_after_fit. Adding 1.0 prevents division by zero.\n    tight_fit_scores = 1.0 / (1.0 + remaining_after_fit)\n\n    # Strategy 2: Encouraging Exploration / Avoiding Over-saturation\n    # Boost bins that have a \"good amount\" of remaining space, but not too much.\n    # This helps to keep some bins with ample space open for potentially larger future items.\n    # We define \"good amount\" as being larger than the item itself, but not exceeding a certain fraction of the bin's total capacity.\n    # Let's also slightly penalize bins that are *too* close to being full (e.g., remaining_after_fit < 0.1 * item),\n    # as these might become unusable for many future items.\n\n    # Calculate a penalty for bins that are almost full\n    # Penalty is higher for smaller remaining capacities.\n    almost_full_penalty_threshold = 0.1 * item\n    penalty_scores = np.zeros_like(fitting_bins_caps)\n    # Apply penalty if remaining capacity is small and positive\n    nearly_full_mask = (remaining_after_fit > 0) & (remaining_after_fit <= almost_full_penalty_threshold)\n    # The penalty is inversely proportional to how close it is to the threshold, scaled.\n    # We want a larger negative score for smaller `remaining_after_fit`.\n    penalty_scores[nearly_full_mask] = -0.5 * (1 - (remaining_after_fit[nearly_full_mask] / almost_full_penalty_threshold))\n\n    # Add a small boost for bins with moderate remaining capacity (encourages exploration).\n    # Bins with remaining capacity significantly larger than the item but not excessively large.\n    # Let's say remaining capacity is between 1x and 5x the item size.\n    exploration_boost_min = item\n    exploration_boost_max = 5 * item\n    exploration_mask = (remaining_after_fit > exploration_boost_min) & (remaining_after_fit <= exploration_boost_max)\n    exploration_scores = np.zeros_like(fitting_bins_caps)\n    # Boost is higher for capacity closer to `exploration_boost_min`.\n    exploration_scores[exploration_mask] = 0.1 * (1 - (remaining_after_fit[exploration_mask] - exploration_boost_min) / (exploration_boost_max - exploration_boost_min))\n\n\n    # Combine scores: Prioritize tight fit, apply penalty for nearly full bins, and add exploration boost.\n    # Weights are chosen to balance these strategies.\n    combined_scores = (0.8 * tight_fit_scores) + penalty_scores + exploration_scores\n\n    # Assign the calculated scores to the corresponding bins\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved hybrid priority function for online Bin Packing Problem.\n    This version refines the scoring by prioritizing perfect fits, then tight fits,\n    and then good fits, while still allowing for exploration.\n\n    Categories:\n    1. Perfect Fit: remaining capacity is zero. Highest priority.\n    2. Tight Fit: remaining capacity is small, specifically <= item size. High priority.\n    3. Good Fit: remaining capacity is moderate, specifically > item size but <= 2 * item size. Medium priority.\n    4. Loose Fit: remaining capacity is large, specifically > 2 * item size. Lower priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components based on remaining capacity after fit\n    epsilon = 1e-9  # For handling perfect fits and avoiding division by zero\n\n    # Initialize scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    good_fit_scores = np.zeros_like(remaining_after_fit)\n    loose_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # Thresholds for categorizing fits (relative to item size)\n    tight_threshold = item\n    good_threshold = 2.0 * item\n\n    # Assign scores based on categories, prioritizing perfect > tight > good > loose\n    # Perfect Fit: Highest score.\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 100.0\n\n    # Tight Fit: Prioritize bins that leave little room, scaled inversely with remaining space.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    # Score decreases as remaining_after_fit increases within the tight range.\n    tight_fit_scores[tight_mask] = 10.0 / (1.0 + remaining_after_fit[tight_mask])\n\n    # Good Fit: Prioritize bins that leave a moderate amount of room, scaled less aggressively.\n    good_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold)\n    # Score decreases as remaining_after_fit increases within the good range.\n    good_fit_scores[good_mask] = 5.0 / (1.0 + remaining_after_fit[good_mask])\n\n    # Loose Fit: Lowest priority among fitting bins, provide minimal boost for exploration.\n    loose_mask = (remaining_after_fit > good_threshold)\n    loose_fit_scores[loose_mask] = 1.0 / (1.0 + remaining_after_fit[loose_mask])\n\n    # Combine scores using weights to reflect the priority order\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.7 +\n        good_fit_scores * 0.4 +\n        loose_fit_scores * 0.1\n    )\n\n    # Add a small random component for exploration to all fitting bins\n    # This helps in breaking ties and exploring less obvious choices occasionally.\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 9,
    "obj": 4.01874750698045,
    "SLOC": 35.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for the online Bin Packing Problem,\n    focusing on a more nuanced \"best fit\" strategy with penalized over-fitting.\n\n    The function categorizes bins based on their remaining capacity relative to the item size:\n    1. Perfect Fit: Remaining capacity is zero (or very close to it). Highest priority.\n    2. Tight Fit: Remaining capacity is positive but not excessively large. Prioritized by\n       how little space is left (closer to zero is better).\n    3. Moderate Fit: Remaining capacity is larger, but still leaves a \"reasonable\" amount\n       of space. These bins are prioritized less than tight fits, but more than loose fits.\n    4. Loose Fit: Remaining capacity is very large. Lowest priority among fitting bins,\n       with a small bonus to encourage exploration of potentially useful large spaces.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the current item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Epsilon for handling floating-point comparisons, especially for perfect fits.\n    epsilon = 1e-6\n\n    # --- Scoring Components ---\n    # We aim to create scores where higher values mean higher priority.\n\n    # Perfect Fit: Highest priority. Give a large, fixed score.\n    perfect_fit_score_value = 100.0\n    perfect_mask = (remaining_after_fit < epsilon)\n    priorities[can_fit_mask][perfect_mask] = perfect_fit_score_value\n\n    # Tight Fit: Bins where remaining capacity is positive but small.\n    # These are good candidates for \"best fit\".\n    # Prioritize bins that leave LESS remaining space (closer to zero).\n    # Use a score that is inversely proportional to remaining capacity,\n    # but avoid division by zero by adding 1.\n    # Penalize bins that leave *too much* space within this \"tight\" category.\n    # We define \"tight\" as remaining_after_fit <= item size.\n    tight_threshold = item\n    tight_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= tight_threshold)\n    if np.any(tight_mask):\n        # Score is inversely proportional to remaining space.\n        # Add a small constant to avoid division by zero if remaining_after_fit is exactly 0 (though epsilon handles this)\n        # Higher score for smaller remaining_after_fit.\n        tight_scores = 1.0 / (remaining_after_fit[tight_mask] + epsilon)\n        # Scale these scores to be lower than perfect fits, but still high.\n        priorities[can_fit_mask][tight_mask] += tight_scores * 5.0 # Scaled down\n\n    # Moderate Fit: Bins where remaining capacity is larger than \"tight\" but not excessively so.\n    # We want to encourage fits that leave *some* room, but not vast amounts.\n    # Let's define \"moderate\" as remaining_after_fit > item size and up to, say, 2*item size.\n    moderate_threshold = 2.0 * item\n    moderate_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= moderate_threshold)\n    if np.any(moderate_mask):\n        # Score inversely proportional to remaining space, but with a smaller weight.\n        # This encourages using bins that don't leave *too much* excess.\n        moderate_scores = 1.0 / (remaining_after_fit[moderate_mask] + epsilon)\n        # Scale these scores lower than tight fits.\n        priorities[can_fit_mask][moderate_mask] += moderate_scores * 2.0 # Scaled down further\n\n    # Loose Fit: Bins with very large remaining capacity.\n    # These are least preferred for \"best fit\" but might be needed.\n    # Give them a very low priority, but a small positive score for exploration.\n    # Define \"loose\" as remaining_after_fit > 2*item size.\n    loose_mask = (remaining_after_fit > moderate_threshold)\n    if np.any(loose_mask):\n        # Give a small constant boost to these bins.\n        # Could also use an inverse relationship scaled very low.\n        loose_scores = 0.1 # Small constant boost for exploration\n        priorities[can_fit_mask][loose_mask] += loose_scores\n\n    # --- Adjustments and Exploration ---\n    # Add a small stochastic component to all fitting bins to encourage exploration\n    # and break ties. The factor should be small enough not to override deterministic preferences.\n    exploration_noise_factor = 0.05\n    if np.any(can_fit_mask):\n        noise = np.random.rand(len(fitting_bins_caps)) * exploration_noise_factor\n        priorities[can_fit_mask] += noise\n\n    # Ensure no negative priorities and normalize if needed (optional, but good practice for some algorithms)\n    priorities = np.maximum(priorities, 0)\n\n    # For bins that cannot fit the item, their priority remains 0.\n    return priorities",
    "response_id": 0,
    "obj": 73.00558436378142,
    "SLOC": 33.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an improved priority function for online Bin Packing Problem,\n    incorporating a refined strategy for penalizing overly tight bins and\n    categorizing fits with adaptive scoring.\n\n    The strategy aims to:\n    1. Favor bins that leave minimal remaining capacity (tight fit), but\n       avoid bins that become *too* full after the item is placed.\n    2. Categorize fits into 'perfect', 'tight', 'good', and 'loose' with\n       decreasing priority.\n    3. Use adaptive scoring that scales with the item size and remaining capacity,\n       while also introducing a penalty for \"almost perfect\" fits that leave\n       very little room.\n    4. Include a small stochastic element for exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define scoring parameters and thresholds\n    epsilon = 1e-9  # For perfect fits and to avoid division by zero\n\n    # Thresholds: these are relative to the item size.\n    # A bin is considered \"tight\" if remaining capacity after fitting is\n    # between epsilon and ~1 * item_size.\n    # A bin is \"good\" if remaining capacity is between ~1 * item_size and ~3 * item_size.\n    # Bins with capacity > 3 * item_size are \"loose\".\n    tight_upper_bound_factor = 1.0\n    good_upper_bound_factor = 3.0\n\n    # Scoring logic:\n    # We want smaller remaining_after_fit to be better.\n    # A penalty is introduced for extremely small remaining capacities (overly tight).\n    # The base score will be inversely proportional to remaining_after_fit,\n    # with a penalty term for very small remaining capacities.\n\n    # Calculate a base score that favors smaller remaining capacity.\n    # Add 1 to denominator to avoid division by zero and to ensure a base score.\n    base_scores = 1.0 / (1.0 + remaining_after_fit)\n\n    # Penalty for being \"too tight\":\n    # If remaining_after_fit is very small (e.g., < epsilon * some_factor),\n    # we might want to reduce its priority.\n    # Let's define \"overly tight\" as remaining capacity < item_size / 5.\n    overly_tight_threshold = item / 5.0\n    overly_tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit < overly_tight_threshold)\n\n    # Assign higher scores to categories that fit well, but penalize overly tight fits.\n    # Perfect Fit: highest score\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_scores = np.full_like(remaining_after_fit, 10.0)\n\n    # Tight Fit: prioritize but not as much as perfect.\n    tight_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= tight_upper_bound_factor * item)\n    # Use inverse relationship with a penalty for being too tight\n    tight_scores = base_scores[tight_mask]\n    tight_scores[remaining_after_fit[tight_mask] < overly_tight_threshold] *= 0.5 # Penalty for too tight\n\n    # Good Fit: Moderate priority, still favors less remaining capacity\n    good_mask = (remaining_after_fit > tight_upper_bound_factor * item) & (remaining_after_fit <= good_upper_bound_factor * item)\n    good_scores = base_scores[good_mask] * 0.7 # Lower weight for good fits\n\n    # Loose Fit: Lowest priority among fitting bins\n    loose_mask = (remaining_after_fit > good_upper_bound_factor * item)\n    loose_scores = base_scores[loose_mask] * 0.3 # Even lower weight\n\n    # Combine scores for fitting bins\n    combined_scores = np.zeros_like(remaining_after_fit)\n\n    combined_scores[perfect_mask] = perfect_scores[perfect_mask]\n    \n    # Assign to the correct indices within the fitting_bins_scores\n    # Using indices to map back to the original fitting_bins_caps\n    fitting_indices = np.arange(len(fitting_bins_caps))\n\n    indices_tight = fitting_indices[tight_mask]\n    combined_scores[indices_tight] = tight_scores\n\n    indices_good = fitting_indices[good_mask]\n    combined_scores[indices_good] = good_scores\n\n    indices_loose = fitting_indices[loose_mask]\n    combined_scores[indices_loose] = loose_scores\n\n    # Add a small random component for exploration to all fitting bins\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Normalize scores to be within a reasonable range, e.g., 0 to 1\n    # This can help in comparing scores across different item sizes if needed.\n    if combined_scores.size > 0:\n        min_score = np.min(combined_scores)\n        max_score = np.max(combined_scores)\n        if max_score - min_score > epsilon:\n            combined_scores = (combined_scores - min_score) / (max_score - min_score)\n        else:\n            combined_scores = np.ones_like(combined_scores) * 0.5 # Handle case where all scores are same\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 1,
    "obj": 4.357798165137619,
    "SLOC": 45.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem,\n    incorporating a more nuanced scoring system based on fit tightness\n    and penalizing overly large remaining capacities.\n\n    Scoring logic:\n    1. Perfect Fit: Highest priority.\n    2. Tight Fit: Prioritize bins leaving minimal remaining capacity (but not zero).\n    3. Moderate Fit: Prioritize bins leaving some space but not excessive.\n    4. Loose Fit: Least priority, but still assign a small score to encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components based on remaining capacity after fit.\n    # A small epsilon to differentiate from true zero for perfect fits.\n    epsilon = 1e-9\n\n    # Thresholds for categorizing fits (relative to item size for better scaling)\n    # Bins with remaining_after_fit < epsilon are perfect fits.\n    # Bins with epsilon <= remaining_after_fit <= item are tight fits.\n    # Bins with item < remaining_after_fit <= 2*item are moderate fits.\n    # Bins with remaining_after_fit > 2*item are loose fits.\n\n    # Score for perfect fits (highest priority)\n    perfect_fit_score_val = 10.0\n    perfect_mask = (remaining_after_fit < epsilon)\n    priorities[can_fit_mask][perfect_mask] = perfect_fit_score_val\n\n    # Score for tight fits (prioritize smaller remaining capacity)\n    tight_fit_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= item)\n    # Inverse relationship with remaining capacity, scaled to avoid large values.\n    # Adding 1 to denominator to prevent division by zero if remaining_after_fit is exactly 0 (handled by epsilon).\n    # The larger the remaining_after_fit, the lower the score.\n    priorities[can_fit_mask][tight_fit_mask] = 5.0 / (1.0 + remaining_after_fit[tight_fit_mask])\n\n    # Score for moderate fits (prefer smaller remaining capacity within this range)\n    moderate_fit_mask = (remaining_after_fit > item) & (remaining_after_fit <= 2.0 * item)\n    # Similar inverse relationship, but with a lower base score than tight fits.\n    priorities[can_fit_mask][moderate_fit_mask] = 2.0 / (1.0 + remaining_after_fit[moderate_fit_mask])\n\n    # Score for loose fits (penalize very large remaining capacities)\n    loose_fit_mask = (remaining_after_fit > 2.0 * item)\n    # Assign a very small positive score to encourage exploration, but less than tighter fits.\n    # This score decreases rapidly as remaining capacity increases.\n    priorities[can_fit_mask][loose_fit_mask] = 0.5 / (1.0 + remaining_after_fit[loose_fit_mask])\n\n    # Add a small random component for exploration. This helps to break ties and\n    # explore different bin choices when scores are very similar.\n    exploration_factor = 0.1\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    priorities[can_fit_mask] += random_scores\n\n    return priorities",
    "response_id": 2,
    "obj": 73.5939369764659,
    "SLOC": 23.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem,\n    incorporating a more nuanced approach to bin selection.\n\n    The function categorizes potential bins based on how tightly an item fits,\n    assigning scores that reflect desirability. It prioritizes bins that result\n    in minimal remaining capacity after packing, but with a dampening effect\n    for extremely tight fits that might be suboptimal in the long run.\n\n    Categories and scoring logic:\n    1. Perfect Fit: Remaining capacity is exactly zero. Highest priority.\n    2. Tight Fit: Remaining capacity is positive but small (e.g., less than or equal to the item size).\n                   Prioritized, with higher scores for smaller remaining capacities.\n    3. Good Fit: Remaining capacity is moderate. These bins are still useful,\n                  but less so than tight fits. Scores decrease as remaining capacity increases.\n    4. Loose Fit: Remaining capacity is large. Lowest priority among fitting bins,\n                  offering a minimal score to encourage exploration.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n        Bins that cannot fit the item will have a score of 0.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define scoring parameters and thresholds. These are heuristic and can be tuned.\n    epsilon = 1e-9  # For handling floating-point comparisons, especially for perfect fits.\n\n    # Thresholds for categorizing fits (relative to item size or a fixed value)\n    # A bin is a \"tight fit\" if remaining capacity is <= item size.\n    tight_threshold = item\n    # A bin is a \"good fit\" if remaining capacity is within a certain range,\n    # e.g., up to a multiple of the item size, but not excessively large.\n    # We might want to avoid bins that leave *too* much space, as they might be \"wasted\".\n    # Let's define a \"good\" range that isn't too large.\n    good_threshold_upper = item * 2.5  # Example: remaining capacity up to 2.5 times item size\n\n    # --- Scoring Logic ---\n    # We want to prioritize smaller remaining capacities (better fits).\n    # Use an inverse relationship, but introduce a damping factor for very small\n    # remaining capacities to avoid overly penalizing bins that are *almost* full\n    # but not quite, which might be slightly less optimal than a perfect fit but still good.\n\n    # Perfect Fit (remaining_after_fit is essentially 0)\n    perfect_fit_scores = np.where(remaining_after_fit < epsilon, 10.0, 0.0)\n\n    # Tight Fit (0 < remaining_after_fit <= tight_threshold)\n    # Prioritize bins that leave less residual space.\n    # The inverse of remaining_after_fit gives a higher score for smaller values.\n    # Add 1 to denominator to prevent division by zero and to give a boost.\n    tight_fit_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    tight_fit_scores = np.where(tight_fit_mask, 5.0 / (1.0 + remaining_after_fit), 0.0)\n\n    # Good Fit (tight_threshold < remaining_after_fit <= good_threshold_upper)\n    # These are still good fits, but less optimal than tight fits.\n    # The score should be lower than tight fits and decrease as remaining capacity increases.\n    good_fit_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold_upper)\n    # Slightly penalize larger remaining capacities within this \"good\" range.\n    good_fit_scores = np.where(good_fit_mask, 2.0 / (1.0 + remaining_after_fit * 0.5), 0.0) # Scale down impact\n\n    # Loose Fit (remaining_after_fit > good_threshold_upper)\n    # These bins have a lot of remaining space. Assign a low score.\n    # This encourages using these bins only when better options are not available.\n    loose_fit_mask = (remaining_after_fit > good_threshold_upper)\n    loose_fit_scores = np.where(loose_fit_mask, 0.5 / (1.0 + remaining_after_fit * 0.1), 0.0) # Minimal score\n\n\n    # Combine scores with weights. Weights reflect the priority order: Perfect > Tight > Good > Loose.\n    # These weights can be adjusted for different strategies.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.9 +  # Slightly reduce weight for tight fits compared to perfect\n        good_fit_scores * 0.6 +   # Moderate weight for good fits\n        loose_fit_scores * 0.3    # Low weight for loose fits\n    )\n\n    # --- Exploration Component ---\n    # Add a small random value to all fitting bins to introduce a stochastic element\n    # and prevent deterministic behavior which can sometimes lead to suboptimal choices.\n    # This can help break ties and explore alternative packing options.\n    exploration_factor = 0.15 # Increased exploration factor slightly\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n\n    priorities[can_fit_mask] = combined_scores + random_scores\n\n    return priorities",
    "response_id": 3,
    "obj": 4.038691663342641,
    "SLOC": 29.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem,\n    incorporating stochasticity and explicit penalization of overly large remaining capacities.\n\n    The function categorizes fits and assigns scores:\n    1. Perfect Fit: Highest score, zero remaining capacity.\n    2. Tight Fit: High score, remaining capacity is small but positive and not exceeding item size.\n    3. Good Fit: Moderate score, remaining capacity is larger than item size but not excessively so.\n    4. Overly Loose Fit: Low score, remaining capacity is very large, potentially indicating wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds for categorizing fits. These are relative to the bin's *original* capacity\n    # to better capture \"overly loose\" fits, not just relative to the item.\n    # This approach aims to keep bins that are \"nearly full\" but not \"nearly empty\" after packing.\n\n    # Threshold for 'tight' fit: bin remaining capacity should be very small relative to bin's total capacity.\n    # Let's consider a bin \"tight\" if its remaining capacity after fitting is less than 10% of its *original* capacity.\n    # We need the original capacity. For simplicity in this function, we'll use remaining_after_fit,\n    # but a more robust version might have access to original bin capacities or a constant bin size.\n    # For now, let's stick to thresholds relative to the *item size* but with a clearer distinction for \"overly loose\".\n\n    epsilon = 1e-9 # For perfect fits\n    tight_fit_upper_bound = item * 1.5 # Bin should not have much more than item size left.\n    overly_loose_threshold = item * 5.0 # A bin that has 5x item size left is considered \"overly loose\".\n\n    # Scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    good_fit_scores = np.zeros_like(remaining_after_fit)\n    overly_loose_scores = np.zeros_like(remaining_after_fit)\n\n    # Assign scores\n    # Perfect Fit: highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 10.0\n\n    # Tight Fit: Prioritize bins that leave little room. Higher score for smaller remaining capacity.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_upper_bound)\n    # Use inverse of remaining capacity, scaled to avoid very large values for small remaining capacities.\n    tight_fit_scores[tight_mask] = 5.0 / (1.0 + remaining_after_fit[tight_mask] * 0.5)\n\n    # Good Fit: Bins with moderate remaining space.\n    good_mask = (remaining_after_fit > tight_fit_upper_bound) & (remaining_after_fit <= overly_loose_threshold)\n    # Penalize larger remaining capacities within this \"good\" range.\n    good_fit_scores[good_mask] = 2.0 / (1.0 + remaining_after_fit[good_mask] * 0.1)\n\n    # Overly Loose Fit: Penalize bins that leave excessively large remaining capacity.\n    overly_loose_mask = (remaining_after_fit > overly_loose_threshold)\n    # Assign a significantly lower score, possibly negative, or a very small positive one to just indicate it's usable.\n    # We will use a small positive score to differentiate from non-fitting bins but still make them less desirable.\n    overly_loose_scores[overly_loose_mask] = 0.1 / (1.0 + remaining_after_fit[overly_loose_mask] * 0.01)\n\n\n    # Combine scores with weights. Weights reflect preference: Perfect > Tight > Good > Overly Loose.\n    # The weights are heuristic and can be tuned.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.8 +\n        good_fit_scores * 0.5 +\n        overly_loose_scores * 0.1\n    )\n\n    # Add a small stochastic component for exploration to all fitting bins.\n    # This helps in diversifying bin choices and potentially finding better solutions.\n    exploration_factor = 0.15\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * (1.0 + np.log1p(remaining_after_fit))\n    # Scaling random scores slightly with remaining capacity can encourage exploration of less full bins.\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 4,
    "obj": 4.15835660151576,
    "SLOC": 35.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]