```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements a more sophisticated hybrid priority function for online Bin Packing Problem.
    This version refines the scoring by categorizing fits and using a combination of
    inverse remaining capacity and a penalty for bins that are too empty.

    The strategy is as follows:
    1. Perfect Fit: Highest priority (remaining capacity is zero).
    2. Tight Fit: High priority (remaining capacity is small, but positive).
    3. Good Fit: Moderate priority (remaining capacity is larger, but not excessively so).
    4. Loose Fit: Lower priority (remaining capacity is very large).

    It also incorporates a penalty for bins that are "too empty" to encourage
    packing items into bins that are already somewhat utilized, thus avoiding
    fragmentation and the creation of too many bins with large remaining capacities.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher score indicates a higher priority.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)  # Initialize with negative infinity

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    fitting_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    # Define score components based on remaining capacity after fit
    epsilon = 1e-9  # Small value to handle exact fits and avoid division by zero

    # --- Scoring components ---

    # 1. Best Fit Component: Prioritize bins with minimal remaining capacity after fitting.
    # Higher score for smaller `remaining_after_fit`.
    best_fit_score_component = 1.0 / (remaining_after_fit + epsilon)

    # 2. "Too Empty" Penalty Component: Penalize bins that would remain very empty.
    # This discourages placing an item in a bin where it takes up only a tiny fraction of space.
    # The penalty is higher for bins that are *more* empty relative to their total capacity
    # (or a "reasonable" capacity threshold).
    # Let's define "too empty" as having remaining capacity > threshold.
    # A reasonable threshold could be related to the item size or bin capacity.
    # Here, we use a threshold relative to the item size to encourage using partially filled bins.
    # A bin that remains "too empty" (e.g., remaining capacity is a large multiple of item size)
    # should have a lower score.
    # We want to *subtract* from the priority if it's too empty.

    # Threshold for "too empty": if remaining capacity is more than X times the item size.
    # This encourages filling bins more.
    too_empty_threshold_factor = 4.0
    too_empty_threshold = item * too_empty_threshold_factor

    # Calculate a penalty factor. Higher penalty for larger remaining capacity beyond the threshold.
    # Using a sigmoid-like function or a simple inverse relation.
    # Penalty is 0 if remaining_after_fit <= too_empty_threshold.
    # Penalty increases as remaining_after_fit increases beyond the threshold.
    # We want to subtract a value that gets larger as it becomes "too empty".
    # A simple approach: penalize bins where remaining_after_fit is large.
    # Normalize remaining capacity to a scale, e.g., max possible remaining capacity.
    # A simpler approach for now: penalize based on the absolute value of remaining_after_fit.
    # Or, more effectively, penalize based on the *ratio* of remaining_after_fit to the bin's original capacity.
    # However, we don't have original capacity here. Let's use remaining_after_fit directly.

    # Create a penalty based on how much `remaining_after_fit` exceeds `too_empty_threshold`.
    # We use a small positive value for bins that are not too empty to avoid issues.
    # For bins that are too empty, we want a penalty that grows.
    # Example penalty: `max(0, remaining_after_fit - too_empty_threshold) / (item + epsilon)`
    # This penalizes bins that leave a lot of space.

    penalty_component = np.maximum(0, remaining_after_fit - too_empty_threshold) / (item + epsilon)

    # Combine the components.
    # We want to prioritize best fit and *deprioritize* too empty bins.
    # So, the penalty should subtract from the score.
    # We can scale the penalty component to control its impact.
    penalty_weight = 0.5  # Tunable parameter to control how strongly we penalize "too empty" bins

    # Initial combined score
    combined_scores = best_fit_score_component - penalty_weight * penalty_component

    # --- Prioritization based on specific fit types (can refine the combined score) ---
    # We can boost scores for perfect fits and tight fits, and potentially
    # reduce scores for very loose fits before applying the penalty.

    # Perfect fit boost: Very high priority
    perfect_fit_mask = (remaining_after_fit < epsilon)
    combined_scores[perfect_fit_mask] = np.maximum(combined_scores[perfect_fit_mask], 100.0)

    # Tight fit boost: High priority, e.g., remaining capacity <= item size.
    tight_fit_threshold = item
    tight_fit_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)
    # Boost tight fits slightly more if they are not already extremely high from best fit.
    combined_scores[tight_fit_mask] = np.maximum(combined_scores[tight_fit_mask], combined_scores[tight_fit_mask] * 1.5)

    # Loose fit reduction: Reduce scores for bins that are very loose.
    # If remaining capacity is very large (e.g., > 5*item), reduce their priority.
    loose_fit_threshold = item * 5.0
    loose_fit_mask = (remaining_after_fit > loose_fit_threshold)
    combined_scores[loose_fit_mask] *= 0.7 # Reduce priority for loose fits


    # Add a small random component for exploration to all fitting bins
    exploration_factor = 0.05
    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor
    combined_scores += random_scores

    # Assign the calculated scores to the corresponding bins in the original priority array
    priorities[can_fit_mask] = combined_scores

    return priorities
```
