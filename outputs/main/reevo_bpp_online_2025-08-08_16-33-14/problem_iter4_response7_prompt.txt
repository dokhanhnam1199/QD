{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid strategy.\n\n    This strategy prioritizes bins that offer a tight fit (minimizing leftover capacity)\n    while also considering bins that leave sufficient space for future, potentially larger items.\n    It aims to balance exploiting near-perfect fits with exploring options that maintain\n    flexibility. A small bias is introduced to favor bins that are less utilized,\n    thereby encouraging a more even distribution of items and avoiding premature\n    filling of a few bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the current item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Strategy 1: Prioritize tight fits (Best Fit)\n    # Calculate remaining capacity after placing the item. We want to minimize this.\n    remaining_after_fit = fitting_bins_caps - item\n    # Invert the remaining capacity and add 1 to avoid division by zero and to\n    # ensure higher scores for smaller remaining capacities.\n    best_fit_scores = 1.0 / (1.0 + remaining_after_fit)\n\n    # Strategy 2: Favor bins that leave more space (Worst Fit tendency for future)\n    # This aims to keep bins with larger remaining capacities open for larger items.\n    # We want to prioritize bins with higher remaining capacity among those that can fit the item.\n    # Adding a small epsilon to avoid division by zero if fitting_bins_caps is 0 (though unlikely here due to can_fit_mask).\n    # We scale this by a factor to balance it with best_fit_scores.\n    # Using a log scale can help compress large differences and prevent extreme values.\n    # Using max capacity as a reference point for scaling.\n    max_cap_overall = np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1.0\n    space_for_future_scores = np.log1p(fitting_bins_caps / max_cap_overall) * 0.5 # Log scale, scaled down\n\n    # Strategy 3: Introduce a slight bias towards less utilized bins to encourage diversity\n    # Calculate the proportion of capacity used in bins that can fit the item.\n    # Higher proportion means more utilized. We want to slightly penalize these.\n    # Or, equivalently, reward bins with more remaining capacity (less utilized).\n    # Let's rethink: We want to favor bins that are NOT nearly full, to leave space.\n    # So, we want to prioritize bins that have *more* remaining capacity *among those that can fit*.\n    # This is somewhat captured by space_for_future_scores.\n    # A simpler approach: penalize bins that are *very* full.\n    # Let's use a term that increases as remaining_after_fit gets closer to 0.\n    # Instead, let's favor bins that are less full to encourage distribution.\n    # So, we want to boost priority for bins with larger remaining capacity.\n    # This is already handled by space_for_future_scores.\n\n    # Let's combine Best Fit with a preference for bins that leave *reasonable* space,\n    # but not excessively large gaps that might be wasted.\n    # We can use a Gaussian-like function centered slightly away from zero remaining capacity.\n    # Or simply, combine Best Fit with a factor that prefers bins with more room, but not excessively so.\n\n    # Let's refine the combination:\n    # Primary: Best Fit (minimizing remaining space)\n    # Secondary: Favor bins that leave a moderate amount of space.\n    # Calculate a score that peaks when remaining_after_fit is moderate (e.g., item_size).\n    # This means the bin capacity was ~2*item_size.\n    # We want to encourage fits where remaining_after_fit is not too small (handled by BF)\n    # and not too large.\n\n    # A simpler approach for diversity/exploration without explicit randomness:\n    # Prioritize bins that are not *too* close to full, but also not *too* empty.\n    # Let's try a score that favors bins with remaining capacity between X and Y.\n    # This can be complex.\n\n    # Let's stick to a combination of tight fits and a slight preference for\n    # bins that still have a good amount of capacity left for future items.\n    # Combine Best Fit with a scaled version of remaining capacity.\n    # Higher remaining capacity = higher score (but this can contradict best fit).\n\n    # Let's try a weighted sum favoring best fit, but giving a boost to bins\n    # that are not too full and not too empty.\n    # Consider the 'slack' or 'unfilled' capacity in a fitting bin.\n    # We want to minimize (fitting_bins_caps - item) but also not\n    # pick bins that are almost empty if a tighter fit exists.\n\n    # Revised combination:\n    # - Prioritize tightest fits (minimize `remaining_after_fit`).\n    # - Add a slight bonus for bins that are not *nearly* full, to leave more room.\n    # This means for `remaining_after_fit`, smaller is better, but we might\n    # slightly penalize the absolute minimum if it's extremely close to zero.\n\n    # Let's use a score that is high for small `remaining_after_fit`,\n    # but perhaps has a slight decay if `remaining_after_fit` is very, very small.\n    # Or, a score that rewards `remaining_after_fit` up to a certain point, then decays.\n    # A Gaussian-like function centered at a moderate `remaining_after_fit` could work.\n    # e.g., exp(-(remaining_after_fit - target_slack)^2 / sigma^2)\n\n    # Let's try a simpler hybrid:\n    # Score = (Best Fit Score) + (Bonus for leaving reasonable space)\n    # Best Fit Score: 1 / (1 + remaining_after_fit)\n    # Bonus for leaving space: A function that increases with `fitting_bins_caps` up to a point.\n    # Let's try `np.tanh(fitting_bins_caps / max_cap_overall)` as a bonus.\n    # This would boost bins that are less full.\n\n    # Combine Best Fit with a preference for bins with more remaining capacity\n    # among those that can fit the item. This is to preserve larger bins for larger items.\n    # A simple linear scaling of remaining capacity (normalized).\n    # Higher remaining capacity should get a higher score here.\n    # Let's use remaining_after_fit scaled.\n\n    # Combined score:\n    # We want to maximize tight fits AND maximize remaining capacity among fitting bins.\n    # This is a multi-objective problem. A common approach is a weighted sum.\n    # We can define two components and sum them.\n\n    # Component 1: Tightness (Higher is better for smaller remaining_after_fit)\n    tightness_score = 1.0 / (1.0 + remaining_after_fit + 1e-9) # Add epsilon for stability\n\n    # Component 2: Space Preservation (Higher is better for larger remaining_after_fit)\n    # This is counter to tightness. Let's reframe.\n    # We want to *minimize* remaining_after_fit.\n    # Let's consider the 'quality' of the fit. A perfect fit (remaining_after_fit = 0) is good.\n    # A fit that leaves a lot of space might be good for future items.\n\n    # Let's prioritize bins that are almost full, as this is a common greedy heuristic.\n    # If a bin is almost full, placing an item there might be efficient.\n    # However, the reflection asks to balance this with leaving room.\n\n    # Let's try a score that is high when remaining_after_fit is small (best fit),\n    # but also adds a term that prefers bins that are not completely empty after the fit.\n    # This encourages packing items into bins that already have some content.\n\n    # Consider `remaining_after_fit`. We want to be small.\n    # Let's create a score that rewards small values of `remaining_after_fit`,\n    # but perhaps with a slight bonus for the *second* best fit if the best fit is *too* tight\n    # (i.e., leaves almost no room). This encourages diversity.\n\n    # Revised Strategy:\n    # 1. Primary goal: Minimize `remaining_after_fit` (Best Fit).\n    # 2. Secondary goal: If there are multiple bins with very small `remaining_after_fit`,\n    #    prefer the one that leaves a bit more space to avoid \"over-packing\".\n    #    This can be achieved by slightly penalizing `remaining_after_fit` values close to zero.\n\n    # Let's create a score that peaks when `remaining_after_fit` is close to zero but not exactly zero.\n    # This is tricky. A simple inverse is fine for best fit.\n\n    # Let's combine Best Fit with a penalty for leaving too much room.\n    # `best_fit_scores` already prioritizes minimal remaining capacity.\n    # If `fitting_bins_caps` are large, `remaining_after_fit` will also be large.\n    # `best_fit_scores` will be small for these. So it naturally penalizes leaving too much room.\n\n    # How to balance \"tight fits\" with \"leaving room for future items\"?\n    # If we have item sizes {0.6, 0.6, 0.2, 0.2, 0.2} and bin capacity 1.0.\n    # Item 0.6: Fit into bin 1. Remaining cap: [0.4].\n    # Item 0.6: Fit into bin 2. Remaining cap: [0.4, 0.4].\n    # Item 0.2:\n    #   Bin 1: remaining_after_fit = 0.4 - 0.2 = 0.2. Best fit score = 1/(1+0.2) = 0.833\n    #   Bin 2: remaining_after_fit = 0.4 - 0.2 = 0.2. Best fit score = 1/(1+0.2) = 0.833\n    #   If there's another bin with capacity 1.0 (Bin 3): remaining_after_fit = 1.0 - 0.2 = 0.8. Best fit score = 1/(1+0.8) = 0.555\n    # The current `best_fit_scores` would favor Bin 1 or 2.\n\n    # Let's try to add a component that favors bins that are not nearly empty *after* fitting.\n    # This means we want `remaining_after_fit` to be not too large.\n    # So, we want to minimize `remaining_after_fit` and also minimize `remaining_after_fit` again?\n    # This implies a preference for the absolute best fit.\n\n    # The reflection suggests:\n    # - Prioritize tight fits by minimizing leftover capacity. (This is Best Fit).\n    # - Explore diverse bin selection strategies.\n    # - Balance exploiting near-perfect fits with exploring options that leave room for future items.\n\n    # To balance, we can't just do pure Best Fit.\n    # Let's create a score that is sensitive to the *magnitude* of the remaining capacity.\n    # A function that is high for `remaining_after_fit` near 0, but also high for\n    # `remaining_after_fit` that is still significant (but not excessive).\n\n    # Let's try a score based on the ratio of remaining capacity to item size.\n    # `fitting_bins_caps / item`.\n    # A ratio close to 1 means `fitting_bins_caps` is just slightly larger than `item`.\n    # We want `fitting_bins_caps` to be just slightly larger than `item`.\n    # `fitting_bins_caps - item` should be small.\n\n    # Consider the 'gap' relative to the bin capacity.\n    # `remaining_after_fit / fitting_bins_caps`. We want this to be small.\n    # So, `1.0 / (1.0 + remaining_after_fit / fitting_bins_caps)` as a score.\n    # This is essentially `fitting_bins_caps / (fitting_bins_caps + fitting_bins_caps - item)`\n    # = `fitting_bins_caps / (2 * fitting_bins_caps - item)`.\n\n    # Let's combine Best Fit with a factor that favors bins with moderate remaining space.\n    # `best_fit_scores = 1.0 / (1.0 + remaining_after_fit)`\n    # We want to add a bonus if `remaining_after_fit` is not too small AND not too large.\n    # A Gaussian-like function could work.\n    # Let target_slack be `item * 0.5` (a moderate slack).\n    # Slack score = exp(-(remaining_after_fit - target_slack)**2 / sigma**2)\n    # This might be too complex.\n\n    # Simpler approach:\n    # Combine Best Fit with a term that boosts bins with larger remaining capacity.\n    # This encourages leaving bins less full.\n    # But \"leaving room for future items\" can also mean packing smaller items into\n    # bins that already have some capacity, rather than opening a new bin.\n\n    # Let's try a weighted sum:\n    # `priority = w1 * best_fit_score + w2 * preference_for_more_space`\n    # `best_fit_score`: `1.0 / (1.0 + remaining_after_fit)` (higher is better)\n    # `preference_for_more_space`: `fitting_bins_caps` (higher is better)\n    # We need to normalize `fitting_bins_caps`.\n    # Let's use `fitting_bins_caps / max_cap_overall`.\n\n    # Let's weight Best Fit more heavily, and add a scaled remaining capacity component.\n    # The goal is to be greedy (best fit) but also to keep options open.\n    # A bin that is 70% full and can fit the item, leaving it 85% full, might be better\n    # than a bin that is 10% full and can fit the item, leaving it 30% full.\n    # This depends on the item size.\n\n    # Let's focus on minimizing the *waste* created by the current item placement.\n    # Waste = `remaining_after_fit`. We want to minimize this.\n    # But \"leaving room for future items\" suggests that sometimes a slightly larger `remaining_after_fit`\n    # might be preferable if it's a more balanced use of space.\n\n    # Consider the state of the bin itself: `fitting_bins_caps`.\n    # A bin that is `0.8` capacity and fits `0.2` item (leaves `0.6`) is different from\n    # a bin that is `0.3` capacity and fits `0.2` item (leaves `0.1`).\n    # The first case leaves more absolute space.\n\n    # Let's try a score that combines the inverse of remaining capacity (for tight fits)\n    # with the remaining capacity itself (to favor bins with more space).\n    # We can use a quadratic function to capture this preference for moderate slack.\n    # Score = -(remaining_after_fit - slack_target)^2\n    # This would peak at `slack_target`.\n\n    # Let's try a simpler weighted sum:\n    # Prioritize bins that result in minimum remaining capacity.\n    # Also, give a slight boost to bins that have more capacity to begin with (among fitting bins).\n    # This encourages spreading items.\n\n    # `best_fit_metric = -remaining_after_fit` (we want to maximize this, i.e., minimize remaining_after_fit)\n    # `space_metric = fitting_bins_caps` (we want to maximize this)\n\n    # Combine these: `score = weight_bf * (-remaining_after_fit) + weight_space * fitting_bins_caps`\n    # Need to normalize `fitting_bins_caps` and ensure the scale of `remaining_after_fit` is handled.\n    # Using `1.0 / (1.0 + remaining_after_fit)` handles the scale for BF.\n    # For space, `fitting_bins_caps / max_cap_overall` is a good normalized metric.\n\n    # Let's try:\n    # Score = (1 - alpha) * (1.0 / (1.0 + remaining_after_fit)) + alpha * (fitting_bins_caps / max_cap_overall)\n    # This would prioritize best fit, but with a tendency to favor bins that are less full.\n    # If `alpha` is small, it's mostly best fit. If `alpha` is large, it favors less full bins.\n\n    # Let's use `alpha = 0.3` to give a significant but secondary preference for leaving space.\n    alpha = 0.3\n    max_cap_overall = np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1.0\n\n    # Best Fit component: Higher score for smaller `remaining_after_fit`.\n    best_fit_component = 1.0 / (1.0 + remaining_after_fit + 1e-9)\n\n    # Space preservation component: Higher score for larger `fitting_bins_caps`.\n    # Normalize by the maximum capacity to get a relative measure.\n    space_component = fitting_bins_caps / max_cap_overall\n\n    # Combine components with weights.\n    # The reflection asks to balance exploiting near-perfect fits with exploring options that leave room.\n    # This suggests a preference for moderate slack, not just minimum or maximum.\n    # The current combination prioritizes tight fits, and then favors bins that are less full overall.\n    # This might push items to less utilized bins even if a tighter fit exists elsewhere.\n\n    # Let's refine the 'leaving room' aspect.\n    # We want to avoid bins that become *too* empty after fitting.\n    # So, we want `remaining_after_fit` not to be too large.\n    # This means `fitting_bins_caps` should not be excessively larger than `item`.\n\n    # Let's try a score that is high when `remaining_after_fit` is small, but also\n    # penalizes cases where `fitting_bins_caps` is much larger than `item`.\n    # This means we want `fitting_bins_caps` to be slightly larger than `item`.\n\n    # Consider the ratio `fitting_bins_caps / item`.\n    # We want this ratio to be close to 1.\n    # A score like `1.0 / (1.0 + abs(fitting_bins_caps / item - 1.0))` might work.\n    # This favors fits where the bin capacity is just slightly larger than the item.\n    # This implicitly means `remaining_after_fit` is small.\n\n    # Let's go back to a simpler, effective heuristic:\n    # Prioritize bins that minimize remaining capacity.\n    # If there are ties, or near-ties, consider which bin has more residual capacity.\n    # This leads to a weighted combination of minimizing remaining capacity and maximizing remaining capacity.\n\n    # Let's try a metric that favors bins that are \"almost full\" but not completely.\n    # This is a form of \"first fit decreasing\" or \"best fit\" strategy.\n    # For online, we adapt.\n\n    # Let's try a score that is high for tight fits, and a secondary measure that\n    # favors bins that are not too empty.\n    # `best_fit_score`: `1 / (1 + remaining_after_fit)`\n    # `not_too_empty_score`: `tanh(fitting_bins_caps / max_cap_overall)` - this favors bins that were initially more full.\n\n    # How about: Maximize the utility of the bin.\n    # Utility can be related to how \"full\" the bin becomes.\n    # We want to reach a state where bins are filled efficiently.\n\n    # Let's try a compromise:\n    # Priority is mainly determined by Best Fit.\n    # A secondary factor that slightly boosts bins that are not nearly empty *after* the fit.\n    # This means `remaining_after_fit` shouldn't be extremely small, but also not too large.\n\n    # Consider `remaining_after_fit`.\n    # Best Fit: High score for small values.\n    # Leaving room: High score for large values.\n    # Balance: High score for moderate values.\n\n    # Let's try a simple scoring function that rewards tightness but doesn't completely ignore\n    # bins that leave more room.\n\n    # Score = `best_fit_score` + `slack_bonus`\n    # `best_fit_score`: `1.0 / (1.0 + remaining_after_fit + 1e-9)`\n    # `slack_bonus`: This should be higher for `remaining_after_fit` that is not too small,\n    #                but also not excessively large.\n    # Let's use `np.tanh(remaining_after_fit / max_cap_overall)` as a bonus.\n    # This bonus increases with remaining capacity.\n    # This combination would favor tight fits that also happen to have more initial capacity.\n\n    # The reflection emphasizes \"balancing exploiting near-perfect fits with exploring options that leave room\".\n    # This suggests that a slightly less perfect fit that leaves more room might be preferred over an extremely tight fit.\n\n    # Let's try a metric that is high when `remaining_after_fit` is small, but not extremely small.\n    # And also not extremely large.\n    # Example: item=0.5, bin_caps=[0.6, 0.8, 1.0]\n    #   Bin 1: rem_after_fit = 0.1. BF = 1/1.1 = 0.909\n    #   Bin 2: rem_after_fit = 0.3. BF = 1/1.3 = 0.769\n    #   Bin 3: rem_after_fit = 0.5. BF = 1/1.5 = 0.667\n    # Best fit picks Bin 1.\n    # If we want to leave more room, maybe Bin 2 is good.\n\n    # Let's try a score that is a weighted sum of the negative remaining capacity (to maximize)\n    # and the negative squared remaining capacity (to penalize larger remaining capacity).\n    # Score = `w1 * (-remaining_after_fit)` + `w2 * (-remaining_after_fit**2)`\n    # This would strongly favor small `remaining_after_fit`.\n\n    # Alternative: A penalty for both small and large remaining capacity.\n    # Minimize `(remaining_after_fit - target_slack)**2`.\n    # This means maximizing `-(remaining_after_fit - target_slack)**2`.\n    # This function peaks at `target_slack`.\n\n    # Let `target_slack` be `item * 0.2` (a small slack).\n    # score = np.exp(-(remaining_after_fit - item * 0.2)**2 / (item * 0.5)**2)\n    # This would favor fits leaving ~0.2 item size as remainder.\n\n    # Let's try a simpler approach based on the reflection:\n    # Prioritize tight fits (minimize `remaining_after_fit`).\n    # Also, consider bins that leave \"room for future items\".\n    # This could mean bins that still have a significant amount of capacity left.\n\n    # Let's use a score that is primarily best-fit, but with a boost for bins\n    # that have a moderate amount of remaining capacity *after* the item is placed.\n    # A bin that has 0.1 remaining is very tight. A bin with 0.5 remaining might be too much.\n    # A bin with 0.2-0.3 remaining might be a good compromise.\n\n    # Score = `best_fit_score` + `slack_preference`\n    # `best_fit_score = 1.0 / (1.0 + remaining_after_fit + 1e-9)`\n    # `slack_preference`: a function that is high for `remaining_after_fit` in a certain range.\n    # Let's use a simple linear increase for `slack_preference` but capped.\n    # Prefer bins with more remaining capacity (among fitting bins) but with diminishing returns.\n\n    # Let's combine `best_fit_score` with `fitting_bins_caps`.\n    # `combined_score = best_fit_score * (1 + 0.2 * (fitting_bins_caps / max_cap_overall))`\n    # This gives a boost to bins that were initially more full.\n\n    # Let's re-read the reflection: \"Balance exploiting near-perfect fits with exploring options that leave room for future items.\"\n    # This means we don't always pick the absolute best fit.\n    # We want a score that is high for `remaining_after_fit` close to 0, but also for `remaining_after_fit` that is moderately larger.\n\n    # Consider a score function `f(r)` where `r` is `remaining_after_fit`.\n    # `f(r)` should be high for small `r`, but also for moderate `r`.\n    # A possible function: `r` itself (favors large remaining) AND `1/(1+r)` (favors small remaining).\n    # Weighted sum: `w1 * (1/(1+r)) + w2 * r`.\n    # `w1` should be larger for tight fits. `w2` for leaving room.\n\n    # Let's try:\n    # Score = (1-beta) * (1 / (1 + remaining_after_fit)) + beta * (remaining_after_fit / max_cap_overall)\n    # Here, `remaining_after_fit` is scaled to be comparable.\n    # If `beta` is small, it's mostly best fit.\n    # If `beta` is large, it favors bins that leave more space.\n    # This still doesn't capture \"moderate slack\".\n\n    # Let's use a score that rewards tightness, and also rewards bins that were initially less full.\n    # The logic is: a tight fit into a bin that is already somewhat full is good.\n    # A tight fit into a very empty bin is also okay.\n    # The problem is picking between a tight fit and a looser fit that leaves more room.\n\n    # Let's try a weighted combination of two preferences:\n    # 1. Minimizing remaining capacity: `score1 = 1.0 / (1.0 + remaining_after_fit + 1e-9)`\n    # 2. Maximizing the remaining capacity *after* the fit, normalized: `score2 = fitting_bins_caps / max_cap_overall`\n    # The reflection suggests balancing these.\n    # `final_score = (1 - weight) * score1 + weight * score2`\n    # If `weight` is small, we lean towards best fit.\n    # If `weight` is large, we lean towards leaving more space.\n\n    # Let's consider `weight = 0.4`. This gives a significant preference for leaving more space.\n    weight = 0.4\n    score1 = 1.0 / (1.0 + remaining_after_fit + 1e-9)\n    score2 = fitting_bins_caps / max_cap_overall\n\n    # A potential issue: if `fitting_bins_caps` are very close to each other, `score2` differences will be small.\n    # If `remaining_after_fit` values are very close, `score1` differences will be small.\n\n    # Let's try to introduce a \"quality\" measure of the fit.\n    # Quality = `1.0 - remaining_after_fit / fitting_bins_caps` (proportion of bin used)\n    # We want this to be high.\n    # `quality_score = fitting_bins_caps - remaining_after_fit` -> which is `item`? No.\n    # `quality_score = item / fitting_bins_caps`\n\n    # Let's try a combination that favors tight fits, but penalizes fits that leave *very little* or *excessive* space.\n    # Score = `-(remaining_after_fit - slack_target)^2`\n    # Let `slack_target = item * 0.2` (a small slack).\n    # This function peaks when remaining_after_fit is `item * 0.2`.\n    # This favors fits where the bin was about `item + item*0.2 = 1.2 * item` capacity.\n\n    # Let's try this:\n    # Score = `1.0 / (1.0 + remaining_after_fit)`  (Best Fit)\n    # Add a term that slightly favors bins that are not \"too full\" after the fit.\n    # This means `remaining_after_fit` shouldn't be too small.\n    # But it also shouldn't be too large.\n\n    # Final attempt: Combine Best Fit with a preference for bins that leave a moderate amount of space.\n    # The overall goal is to reduce the number of bins.\n    # Tight fits are good for this.\n    # Leaving room is good if it means future items can be packed more efficiently.\n\n    # Let's simplify the \"leaving room\" aspect: prioritize bins that are not almost full.\n    # Among the fitting bins, we want to pick one that minimizes `remaining_after_fit`,\n    # but if there are multiple bins with similar `remaining_after_fit`, pick the one\n    # that was initially less full (i.e., had more `fitting_bins_caps`).\n\n    # `best_fit_score = 1.0 / (1.0 + remaining_after_fit + 1e-9)`\n    # `less_full_bonus = fitting_bins_caps / max_cap_overall`\n    # `combined_score = best_fit_score + 0.2 * less_full_bonus`\n    # This seems reasonable: prioritize tight fits, with a secondary preference for less full bins.\n    # The weight 0.2 can be tuned.\n\n    # Let's try this combination.\n    combined_scores_subset = (1.0 / (1.0 + remaining_after_fit + 1e-9)) + \\\n                             0.2 * (fitting_bins_caps / max_cap_overall)\n\n    # Assign the calculated scores to the corresponding bins\n    priorities[can_fit_mask] = combined_scores_subset\n\n    # Ensure bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using an improved hybrid strategy.\n\n    This strategy enhances the \"Best Fit\" by considering the \"waste\" more directly.\n    It also introduces a \"Diversity\" factor to prefer bins that have more space\n    remaining after the item is placed, aiming to leave larger contiguous spaces\n    for potentially larger future items. A small stochastic element is kept for\n    exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Determine which bins can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit, return all zeros\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Strategy 1: Best Fit (Minimized Waste)\n    # Calculate the remaining capacity after fitting the item.\n    # Higher priority for bins with smaller remaining capacity (less waste).\n    waste = fitting_bins_caps - item\n    # Use a value that increases as waste decreases. Adding 1 to avoid division by zero.\n    best_fit_scores = 1.0 / (1.0 + waste)\n\n    # Strategy 2: Diversity (Maximized Remaining Space after fit)\n    # Prioritize bins that leave more space after packing the item.\n    # This is beneficial for consolidating smaller items and leaving larger\n    # contiguous spaces for potentially larger future items.\n    # We want to maximize (fitting_bins_caps - item). Higher score for larger values.\n    # Normalize to prevent extreme values and ensure it plays well with best_fit_scores.\n    # Add a small epsilon to avoid log(0) or division by zero if fitting_bins_caps - item is 0.\n    max_possible_remaining = np.max(bins_remain_cap) - item if np.max(bins_remain_cap) >= item else 1\n    diversity_scores = np.log1p(waste) / np.log1p(max_possible_remaining) if max_possible_remaining > 0 else np.zeros_like(waste)\n\n\n    # Strategy 3: Exploration (Stochastic Element)\n    # Add a small random component to encourage trying different bins.\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n\n    # Combine scores. Prioritize bins that are a good fit AND leave good remaining space.\n    # The weights are tuned to balance the two primary strategies.\n    # We normalize the scores before combining to ensure they are on a similar scale.\n    # Normalizing best_fit_scores: higher is better (less waste)\n    # Normalizing diversity_scores: higher is better (more remaining space)\n\n    # Normalize best_fit_scores (higher is better, closer to 1)\n    if np.max(best_fit_scores) > 0:\n        normalized_best_fit = best_fit_scores / np.max(best_fit_scores)\n    else:\n        normalized_best_fit = best_fit_scores\n\n    # Normalize diversity_scores (higher is better)\n    if np.max(diversity_scores) > 0:\n        normalized_diversity = diversity_scores / np.max(diversity_scores)\n    else:\n        normalized_diversity = diversity_scores\n\n    # Weighted sum of normalized scores\n    combined_scores = (0.6 * normalized_best_fit) + (0.4 * normalized_diversity) + random_scores\n\n    # Assign the calculated scores to the corresponding bins\n    priorities[can_fit_mask] = combined_scores\n\n    # Ensure bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Reflection]\nPrioritize tight fits, balance with leaving space, consider bin fullness, and use weighted sums.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}