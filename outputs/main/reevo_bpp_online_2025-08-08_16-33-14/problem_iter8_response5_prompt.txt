{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements an adaptive priority function for the online Bin Packing Problem.\n    This version prioritizes bins that leave minimal remaining capacity,\n    with an adaptive penalty for bins that would leave significantly large gaps.\n\n    Priority is calculated as follows:\n    1. Bins that cannot fit the item receive a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fit: Highest priority.\n       b. Tight Fits: High priority, inversely proportional to remaining capacity.\n       c. Moderate Fits: Priority decreases as remaining capacity increases.\n       d. Wasteful Fits: Significantly penalized, especially when remaining capacity\n          is large relative to the item size or typical bin sizes.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Higher score means higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Find bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # --- Adaptive Thresholds and Scaling ---\n    # Calculate a reference for \"tightness\" and \"wastefulness\"\n    # If all fitting bins have very similar remaining capacity, the notion of \"tight\" or \"wasteful\"\n    # is less meaningful relative to other options.\n    # We can use the item size as a primary reference, but also consider the distribution of remaining capacities.\n\n    epsilon = 1e-9  # For numerical stability\n\n    # Define thresholds relative to item size and range of remaining capacities.\n    # This aims to be adaptive to the scale of the problem.\n\n    # Threshold for what is considered a \"tight\" fit.\n    # If remaining capacity is less than 10% of item size, consider it very tight.\n    tight_threshold = item * 0.1\n\n    # Threshold for what is considered \"wasteful\".\n    # If remaining capacity is more than 2x item size, it might be wasteful.\n    # Also consider if remaining capacity is very large compared to current bin capacity.\n    # For simplicity here, we'll use a threshold relative to item size.\n    wasteful_threshold = item * 2.0\n\n    # Calculate a base score for all fitting bins, primarily favoring minimal remaining space.\n    # Using 1 / (slack + epsilon) ensures smaller slack gets higher score.\n    base_scores = 1.0 / (remaining_after_fit + epsilon)\n\n    # Apply modifiers based on fit type:\n    # - Boost for tight fits\n    # - Penalize wasteful fits\n\n    # Initialize scores for fitting bins\n    calculated_scores = np.copy(base_scores)\n\n    # 1. Perfect Fits: Maximize priority.\n    perfect_fit_mask = (remaining_after_fit < epsilon)\n    calculated_scores[perfect_fit_mask] = 1e6  # Assign a very high score\n\n    # 2. Tight Fits: Boost the base score.\n    # Condition: Remaining space is small (e.g., less than item/2 or a small fraction of bin cap)\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    # Apply a boost factor, stronger for smaller remaining space.\n    # Example: boost = 2.0 * (1 - remaining_after_fit / (tight_threshold + epsilon))\n    # A simpler boost: multiply by a factor for tight fits.\n    calculated_scores[tight_mask] *= 2.0  # Boost for tight fits\n\n    # 3. Wasteful Fits: Penalize the score.\n    # Condition: Remaining space is large (e.g., more than 2x item size)\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Apply a penalty factor. The penalty should increase with remaining space.\n    # Example penalty: score *= (1.0 - 0.5 * (remaining_after_fit - wasteful_threshold) / (item + epsilon))\n    # Ensure penalty doesn't make score negative.\n    penalty_factor = 0.5\n    penalty_amount = penalty_factor * np.maximum(0, remaining_after_fit[wasteful_mask] - wasteful_threshold) / (item + epsilon)\n    calculated_scores[wasteful_mask] *= np.maximum(0.1, 1.0 - penalty_amount) # Ensure score doesn't drop too low, e.g., below 0.1 multiplier\n\n    # Ensure scores are non-negative and not excessively large if not perfect fit.\n    calculated_scores[calculated_scores < 0] = 0\n    # Normalize scores to a reasonable range if desired, but usually relative ranking is enough.\n    # Let's ensure they are within a reasonable bounds.\n    # Max score for non-perfect fits should be lower than perfect fit.\n    max_non_perfect_score = np.max(calculated_scores[~perfect_fit_mask]) if np.any(~perfect_fit_mask) else 0\n    if max_non_perfect_score > 0:\n        calculated_scores[perfect_fit_mask] = np.maximum(calculated_scores[perfect_fit_mask], max_non_perfect_score * 10) # Ensure perfect is significantly higher\n\n\n    # Add a small amount of random jitter for exploration.\n    # This helps break ties and explore slightly suboptimal choices occasionally.\n    exploration_factor = 0.01 # Small fraction of the average score\n    avg_score = np.mean(calculated_scores[np.isfinite(calculated_scores)]) if np.any(np.isfinite(calculated_scores)) else 1.0\n    jitter = np.random.uniform(-exploration_factor * avg_score, exploration_factor * avg_score, size=calculated_scores.shape)\n    final_scores_for_fitting_bins = calculated_scores + jitter\n    final_scores_for_fitting_bins[final_scores_for_fitting_bins < 0] = 0 # Ensure jitter doesn't create negative scores\n\n    # Assign scores back to the original priority array\n    priorities[fitting_bins_indices] = final_scores_for_fitting_bins\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements an improved hybrid priority function for online Bin Packing Problem (BPP).\n    This version strictly prioritizes perfect fits, then tight fits (remaining capacity\n    close to the item size), and then \"best fit\" style remaining capacity, while\n    still allowing for exploration.\n\n    Scoring Logic:\n    1. Perfect Fit: remaining capacity is zero. Highest priority.\n    2. Tight Fit: remaining capacity is positive but less than or equal to the item size.\n       Higher priority than other fits, scaled inversely with remaining space.\n    3. Best Fit (remaining): remaining capacity is greater than the item size.\n       Priority decreases as remaining capacity increases.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components\n    epsilon = 1e-9  # For handling perfect fits and avoiding division by zero\n\n    # Initialize scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    best_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fit: Highest priority.\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 100.0  # High fixed score for perfect fits\n\n    # 2. Tight Fit: Prioritize bins that leave little room after packing,\n    #    specifically when remaining capacity is <= item size.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= item)\n    # Score decreases as remaining_after_fit increases within the tight range.\n    # Use inverse relationship: 1 / (1 + remaining_space). A larger remaining space means lower score.\n    # Adding a small constant to the denominator to avoid issues if remaining_after_fit is very close to 0.\n    tight_fit_scores[tight_mask] = 10.0 / (1.0 + remaining_after_fit[tight_mask])\n\n    # 3. Best Fit (remaining): For bins where remaining capacity is > item size.\n    #    Priority decreases as remaining capacity increases.\n    best_fit_mask = (remaining_after_fit > item)\n    # Use a decaying function. (1 / (1 + remaining_space)).\n    # This gives higher scores to bins with less remaining space among this category.\n    best_fit_scores[best_fit_mask] = 5.0 / (1.0 + remaining_after_fit[best_fit_mask])\n\n    # Combine scores using weights to reflect the priority order: Perfect > Tight > Best Fit\n    combined_scores = (\n        perfect_fit_scores * 1.0 +  # Max weight for perfect fits\n        tight_fit_scores * 0.7 +    # Significant weight for tight fits\n        best_fit_scores * 0.3       # Lower weight for general best fits\n    )\n\n    # Add a small random component for exploration to all fitting bins\n    # This helps in breaking ties and exploring less obvious choices occasionally.\n    exploration_factor = 0.05\n    # Scale random score by the maximum possible score to maintain relative priorities.\n    max_possible_score = 100.0 + (10.0 / (1.0 + epsilon)) * 0.7 + (5.0 / (1.0 + item)) * 0.3\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor * max_possible_score\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Reflection]\nPrioritize perfect fits, use tiered scoring, and introduce controlled exploration.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}