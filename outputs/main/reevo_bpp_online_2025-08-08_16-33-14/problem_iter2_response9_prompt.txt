{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    The Sigmoid Fit Score prioritizes bins that are a \"good fit\" for the item,\n    meaning they have a remaining capacity that is slightly larger than the item's size.\n    This helps to minimize wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Ensure item size is positive\n    item = max(0.0, item)\n\n    # Calculate the difference between bin remaining capacity and item size\n    diffs = bins_remain_cap - item\n\n    # We want to prioritize bins where diffs are small and positive (good fit)\n    # and penalize bins that are too small (negative diffs) or too large (large positive diffs).\n    # A sigmoid function can map these differences to a priority score between 0 and 1.\n    # We can shift and scale the differences to center the \"ideal fit\" around 0.\n    # A reasonable approach is to use the item size as a scaling factor for the difference.\n\n    # Avoid division by zero if item is 0, and handle cases where bins_remain_cap might be 0\n    # Use a small epsilon to prevent division by zero issues\n    epsilon = 1e-9\n    scaled_diffs = np.where(bins_remain_cap > epsilon, diffs / bins_remain_cap, -1.0)\n\n    # The sigmoid function is 1 / (1 + exp(-x)).\n    # We want a higher score for smaller positive differences (closer to 0).\n    # A negative scaled difference means the bin is too small.\n    # A large positive scaled difference means the bin has a lot of excess capacity.\n    # We can use a transformation of the scaled difference that is high around 0 and decreases\n    # as the difference becomes more positive or more negative.\n    # A simple approach is to use exp(-abs(scaled_diffs)).\n    # However, to leverage the \"good fit\" idea more directly, we can aim for a peak near diff=0.\n    # A modified sigmoid could work: sigmoid(k * (ideal_fit_capacity - remaining_capacity))\n    # Let's reframe: we want to maximize the value for bins where remaining_capacity is close to item size.\n\n    # Strategy: Prioritize bins that have *just enough* capacity.\n    # This means a positive difference that is as small as possible.\n    # Bins that are too small (negative difference) should have a low priority.\n    # Bins that have a lot of excess capacity (large positive difference) should also have lower priority than a \"just fit\".\n\n    # Let's try a sigmoid centered around an \"ideal\" fit where the remaining capacity is item + some small buffer.\n    # Or, more directly, penalize large positive differences.\n\n    # Consider diffs:\n    # diff < 0: Bin too small. Low priority.\n    # diff = 0: Perfect fit. High priority.\n    # diff > 0: Bin has excess capacity.\n    #   - Small diff > 0: Good fit. High priority.\n    #   - Large diff > 0: Wasteful. Lower priority than good fit.\n\n    # A function that peaks at diff = 0 and drops off as |diff| increases.\n    # exp(-abs(diffs)) might work, but let's try something more sigmoid-like.\n\n    # Sigmoid applied to negative differences to boost near-zero differences.\n    # We want to map diffs to a [0, 1] range where higher is better.\n    # For diffs < 0 (too small), priority should be near 0.\n    # For diffs >= 0 (sufficient capacity), priority should be higher, peaking near diff=0.\n\n    # A shifted and scaled sigmoid:\n    # Let's center the sigmoid around 0, so sigmoid(0) = 0.5.\n    # We can adjust the steepness (k) and the midpoint.\n    # The input to sigmoid could be related to diffs.\n    # We want higher priority for diffs closer to 0.\n\n    # Let's try mapping diffs to a range where the most desirable values are between 0 and a small positive number.\n    # We can transform diffs into something that reaches its maximum when diff is small and positive.\n\n    # Option 1: Focus on the \"tight fit\" aspect.\n    # Prioritize bins where capacity is slightly larger than the item.\n    # This means maximizing a function that is high for small positive diffs and lower for negative diffs or large positive diffs.\n    # We can use a sigmoid on the *negative* of the difference, scaled appropriately.\n    # `sigmoid(k * (item - bin_remain_cap))` might work, but it penalizes bins that are too small too heavily.\n\n    # Let's try a combination:\n    # 1. Filter out bins that are too small (capacity < item). Give them a very low priority.\n    # 2. For bins that are large enough (capacity >= item), use a sigmoid that peaks when capacity is just slightly larger than item.\n\n    # Using the remaining capacity directly, we want to be closer to `item`.\n    # Let's scale the differences by the item size to make it relative.\n    # `scaled_relative_diffs = diffs / (item + epsilon)`\n    # A sigmoid on negative scaled diffs: `1 / (1 + exp(-k * scaled_relative_diffs))`\n    # This will be high if `scaled_relative_diffs` is positive and small.\n\n    # Sigmoid function: sigmoid(x) = 1 / (1 + exp(-x))\n    # We want a higher score when `bins_remain_cap` is just above `item`.\n    # Let `x = -(bins_remain_cap - item) / item`  (this is `(item - bins_remain_cap) / item`)\n    # If `bins_remain_cap` is slightly larger than `item`, `item - bins_remain_cap` is small negative, so `x` is small positive. Sigmoid is near 0.5.\n    # If `bins_remain_cap` is much larger than `item`, `item - bins_remain_cap` is large negative, so `x` is large positive. Sigmoid is near 1. This is not what we want.\n\n    # Let's reconsider the goal: \"good fit\" implies the remaining capacity is just enough.\n    # This suggests we want `bins_remain_cap` to be close to `item`.\n    # If `bins_remain_cap < item`, it's unusable. Priority 0.\n    # If `bins_remain_cap == item`, it's a perfect fit. High priority.\n    # If `bins_remain_cap > item`, there's waste. Priority decreases as waste increases.\n\n    # Let's try mapping `bins_remain_cap` to a priority.\n    # Bins with `bins_remain_cap < item` get priority 0.\n    # Bins with `bins_remain_cap >= item` get a score based on how close `bins_remain_cap` is to `item`.\n    # A suitable function for this could be `exp(-k * (bins_remain_cap - item))` where k is a positive constant.\n    # This function is 1 when `bins_remain_cap == item` and decreases as `bins_remain_cap` increases.\n\n    # We can normalize `bins_remain_cap` and `item` relative to a hypothetical bin capacity or maximum possible item size.\n    # For simplicity, let's work with the absolute differences and a sigmoid transformation.\n\n    # Let's use a sigmoid on a transformation of `diffs`.\n    # We want higher priority for `diffs` near zero and positive.\n    # Consider `sigmoid(k * (max_reasonable_waste - diffs))`.\n    # If `diffs` is negative (too small), this will be `sigmoid(k * (max_reasonable_waste - neg_value))`, which is large. This is also not ideal.\n\n    # Let's use a sigmoid to map `diffs` to a range.\n    # We want `diffs` to be small and positive for high priority.\n    # `sigmoid(constant - k * diffs)`:\n    #   - If diffs is small positive, `k * diffs` is small positive, `constant - k*diffs` is large. Sigmoid is near 1.\n    #   - If diffs is large positive, `k * diffs` is large positive, `constant - k*diffs` is small negative. Sigmoid is near 0.\n    #   - If diffs is negative, `k * diffs` is small negative, `constant - k*diffs` is large positive. Sigmoid is near 1.\n\n    # This means we need to specifically handle the `diffs < 0` case.\n\n    # Let's filter out invalid bins first.\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins_mask):\n        valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        valid_diffs = valid_bins_remain_cap - item\n\n        # We want to prioritize smaller `valid_diffs`.\n        # Let's use a sigmoid that maps small positive numbers to high values and larger positive numbers to lower values.\n        # `sigmoid(k * (A - x))` where `x` is `valid_diffs`. We want `A` to represent an ideal surplus.\n        # A simple choice is to center it around 0 or a small positive value.\n\n        # Let's scale the differences relative to the item size to handle varying item scales.\n        # `scaled_valid_diffs = valid_diffs / (item + epsilon)`\n        # Now, we want `scaled_valid_diffs` to be close to 0.\n        # Let's use `sigmoid(k * (-scaled_valid_diffs))`.\n        # If `scaled_valid_diffs` is small positive (good fit), `-scaled_valid_diffs` is small negative. Sigmoid is < 0.5.\n        # If `scaled_valid_diffs` is near 0 (perfect fit), `-scaled_valid_diffs` is near 0. Sigmoid is 0.5.\n        # If `scaled_valid_diffs` is large positive (wasteful), `-scaled_valid_diffs` is large negative. Sigmoid is near 0.\n        # This is also not quite right.\n\n        # Let's re-frame for \"Sigmoid Fit Score\": prioritize bins that are a \"close fit\".\n        # A close fit means `bins_remain_cap` is close to `item`.\n        # Let `score = sigmoid(alpha - beta * abs(bins_remain_cap - item))`\n        # This score peaks when `abs(bins_remain_cap - item)` is minimal.\n        # However, we must also account for `bins_remain_cap < item`.\n\n        # A more common Sigmoid Fit strategy aims to find a bin whose remaining capacity is just enough.\n        # If `remaining_capacity < item`, priority is 0.\n        # If `remaining_capacity >= item`, the priority is `sigmoid((bin_capacity - item) / bin_capacity)` or similar.\n\n        # Let's try this: a higher priority for bins that have a smaller proportion of wasted space.\n        # Wasted space proportion: `(bins_remain_cap - item) / bins_remain_cap` for valid bins.\n        # We want to maximize this value, meaning minimize `(item / bins_remain_cap)`.\n        # Let `ratio = item / valid_bins_remain_cap`. We want to maximize `1 - ratio`.\n        # A higher value for `1-ratio` means `ratio` is smaller, i.e., `item` is smaller relative to `bins_remain_cap`.\n        # This means a lot of wasted space. This is counter-intuitive to \"fit score\".\n\n        # The \"fit\" part usually refers to the item filling up the bin as much as possible.\n        # This means prioritizing bins where `item / bins_remain_cap` is close to 1.\n        # This implies `bins_remain_cap` is close to `item`.\n\n        # Let's try this formulation for valid bins:\n        # Prioritize bins where `bins_remain_cap` is close to `item`.\n        # The input to the sigmoid should be high when `bins_remain_cap` is close to `item` (and >= item).\n        # Let `x = (bins_remain_cap - item)`.\n        # We want high scores for small positive `x`.\n        # `sigmoid(k * (some_value - x))`. If `some_value` is 0, we get `sigmoid(-k*x)`.\n        # If x is small positive, -kx is small negative, sigmoid < 0.5.\n        # If x is 0, sigmoid is 0.5.\n        # If x is large positive, -kx is large negative, sigmoid near 0.\n        # This prioritizes exact fits.\n\n        # We can shift the sigmoid: `sigmoid(k * (C - x))` where C is some desired surplus.\n        # Or, we can use `sigmoid(k * (-x))` and then `1 - sigmoid(-k * x)` which is `sigmoid(k*x)`.\n        # `sigmoid(k * x)`:\n        #   - x small positive (good fit): sigmoid near 0.5\n        #   - x zero (perfect fit): sigmoid is 0.5\n        #   - x large positive (wasteful): sigmoid near 1\n        # This seems to prioritize larger remaining capacities.\n\n        # Let's try a sigmoid on the inverse of the relative waste:\n        # `relative_waste = (bins_remain_cap - item) / bins_remain_cap`\n        # `inverse_relative_waste = bins_remain_cap / (bins_remain_cap - item)` if diff > 0.\n        # We want to maximize `item / bins_remain_cap`.\n\n        # Sigmoid Fit typically means making `bins_remain_cap` just slightly larger than `item`.\n        # Let `f(capacity) = sigmoid(k * (item - capacity))`. This maps values smaller than `item` to high priority, which is wrong.\n\n        # Let's map `bins_remain_cap` for `valid_bins_mask` to priorities.\n        # Consider the distance from a \"perfect\" fit.\n        # `distance_from_perfect = valid_bins_remain_cap - item`\n        # We want this distance to be small.\n        # A sigmoid centered around 0: `sigmoid(k * (-distance_from_perfect))`\n        # If distance is 0, input is 0, output is 0.5.\n        # If distance is small positive, input is small negative, output < 0.5.\n        # If distance is large positive, input is large negative, output ~ 0.\n        # This prioritizes bins that are too small.\n\n        # How about scaling the difference relative to the item?\n        # `scaled_diff = (valid_bins_remain_cap - item) / (item + epsilon)`\n        # We want this to be small and positive.\n        # Use `sigmoid(k * (C - scaled_diff))` where C is a small positive constant.\n        # Let C = 0.1 (allow up to 10% surplus).\n        # Let k = 10 (steepness).\n\n        # `sigmoid(10 * (0.1 - scaled_diff))`\n        # If `scaled_diff` = 0 (perfect fit), input is 10 * 0.1 = 1. Sigmoid = 0.73.\n        # If `scaled_diff` = 0.1 (10% surplus), input is 10 * (0.1 - 0.1) = 0. Sigmoid = 0.5.\n        # If `scaled_diff` = 0.2 (20% surplus), input is 10 * (0.1 - 0.2) = -1. Sigmoid = 0.27.\n        # If `scaled_diff` = -0.05 (item is 5% larger than capacity, effectively this is a small fit for item's perspective, but our `valid_bins_mask` prevents this)\n        # Let's re-evaluate `valid_bins_mask = bins_remain_cap >= item`.\n        # So `valid_diffs >= 0`, and `scaled_diff >= 0`.\n\n        # We want high priority for small `scaled_diff`.\n        # Use `sigmoid(k * (max_desired_scaled_diff - scaled_diff))`\n        # Let `max_desired_scaled_diff = 0.2` (allow up to 20% surplus)\n        # Let `k = 10`\n\n        # `sigmoid(10 * (0.2 - scaled_diff))`\n        # If `scaled_diff` = 0 (perfect fit), input is 10 * 0.2 = 2. Sigmoid = 0.88.\n        # If `scaled_diff` = 0.1 (10% surplus), input is 10 * (0.2 - 0.1) = 1. Sigmoid = 0.73.\n        # If `scaled_diff` = 0.2 (20% surplus), input is 10 * (0.2 - 0.2) = 0. Sigmoid = 0.5.\n        # If `scaled_diff` = 0.3 (30% surplus), input is 10 * (0.2 - 0.3) = -1. Sigmoid = 0.27.\n\n        # This looks reasonable. It prioritizes bins that have a smaller surplus relative to the item size.\n        # The `max_desired_scaled_diff` parameter controls how much surplus is tolerated before priority drops significantly.\n\n        # Let's refine this: the sigmoid argument should probably be based on the *ratio* of item to capacity for a direct \"filling\" measure.\n        # If `bins_remain_cap` is slightly larger than `item`, the ratio `item / bins_remain_cap` is close to 1.\n        # Let's try mapping this ratio to priority.\n        # `ratio = item / valid_bins_remain_cap`\n        # We want to maximize this ratio, but ensure `ratio <= 1`.\n        # `sigmoid(k * (ratio - 1))` would map ratios slightly less than 1 to values < 0.5, and ratios close to 0 to values near 0.\n        # `sigmoid(k * (1 - ratio))` would map ratios slightly less than 1 to values > 0.5, and ratios close to 0 to values near 1.\n\n        # The latter is closer to our goal: prioritizing bins that are \"filled\" more.\n        # `sigmoid(k * (1 - item / valid_bins_remain_cap))`\n        # If `valid_bins_remain_cap` is just above `item`, `item / valid_bins_remain_cap` is slightly less than 1.\n        # `1 - (slightly less than 1)` is small positive. Sigmoid is > 0.5.\n        # If `valid_bins_remain_cap` is much larger than `item`, `item / valid_bins_remain_cap` is small positive.\n        # `1 - (small positive)` is close to 1. Sigmoid is near 1. This means it prioritizes large empty bins!\n\n        # Okay, let's go back to `scaled_diff = (valid_bins_remain_cap - item) / (item + epsilon)`.\n        # We want small positive `scaled_diff`.\n        # `sigmoid(k * (MAX_SURPLUS_RATIO - scaled_diff))`\n        # `MAX_SURPLUS_RATIO` can be a tunable parameter, e.g., 0.1 for 10% surplus.\n\n        MAX_SURPLUS_RATIO = 0.2  # Allow up to 20% of item size as surplus\n        STEEPNESS = 10.0         # Controls how quickly priority drops after MAX_SURPLUS_RATIO\n\n        # Calculate scaled differences for valid bins\n        # Using item size for scaling helps normalize the surplus\n        scaled_valid_diffs = valid_diffs / (item + epsilon)\n\n        # Apply the sigmoid transformation\n        # The argument is `STEEPNESS * (MAX_SURPLUS_RATIO - scaled_valid_diffs)`\n        # This will yield high values for `scaled_valid_diffs` close to 0 and less than `MAX_SURPLUS_RATIO`.\n        # It will yield lower values for `scaled_valid_diffs` larger than `MAX_SURPLUS_RATIO`.\n        sigmoid_input = STEEPNESS * (MAX_SURPLUS_RATIO - scaled_valid_diffs)\n        \n        # Ensure that we don't get numerically unstable values for sigmoid input\n        sigmoid_input = np.clip(sigmoid_input, -20, 20) # To prevent overflow in exp\n\n        priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_input))\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes bins that can fit the item, and among those,\n    it prefers bins that will have the least remaining capacity after packing\n    the item (i.e., aiming for a tighter fit). If an item doesn't fit into any\n    bin, all priorities are 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Find bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # For bins that can fit, calculate a \"tightness\" score.\n    # A higher score means a tighter fit (less remaining capacity).\n    # We use the negative of remaining capacity after packing, so larger negative numbers (tighter fit) become higher priority.\n    # To ensure positive priorities for max-heap selection, we can invert the measure.\n    # A good approach is to assign a large positive value to bins that can fit and then penalize them based on remaining capacity.\n    # Let's assign a base priority if it fits, and then a bonus for a tighter fit.\n    # Option 1: Inverse remaining capacity (higher means better fit)\n    # To avoid division by zero, add a small epsilon or handle 0 remaining capacity specifically.\n    # If remaining capacity is 0, this is the best fit.\n\n    # Calculate remaining capacity after packing the item\n    remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n\n    # The priority should be higher for bins that result in less remaining capacity.\n    # A simple inverse relationship could work: higher remaining capacity means lower priority.\n    # To make it work with typical maximization heuristics (higher score = better),\n    # we can use something like 1 / (1 + remaining_capacity).\n    # Or, a large constant minus remaining capacity. Let's use the latter for simplicity and to avoid division by small numbers.\n    # We want the smallest remaining capacity to have the highest priority.\n    # Let's assign a priority inversely proportional to the remaining capacity + a small epsilon to avoid division by zero.\n    # A simpler approach that favors tighter fits is to assign a high score to bins that leave less space.\n\n    # Assign a base priority if it fits, then subtract the remaining space to favor tighter fits.\n    # The larger the value, the higher the priority.\n    # Let's use a strategy where a tighter fit gets a higher priority.\n    # We can assign a value related to the 'goodness' of the fit.\n    # For example, the inverse of the remaining capacity, but that can lead to huge values.\n    # A common approach is to simply prioritize bins that result in the smallest leftover space.\n    # So, for bins that can fit: priority = - (remaining_capacity_after_packing)\n    # To ensure positive scores for maximization, we can add a large constant.\n    # Let's use the reciprocal of the remaining capacity after packing, plus a base value.\n\n    # Calculate remaining capacities *after* placing the item\n    remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n\n    # Higher priority for smaller remaining capacity.\n    # Use the negative of remaining capacity, and add a constant to make it positive.\n    # The value `bins_remain_cap[can_fit_mask].max()` serves as a large constant.\n    # This means bins that become nearly full (small `remaining_after_packing`) get higher priority.\n    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask].max() - remaining_after_packing\n\n    # If there are bins with exactly 0 remaining capacity after packing, they should have the absolute highest priority.\n    # Let's boost their priority.\n    exact_fit_mask = (remaining_after_packing == 0)\n    if np.any(exact_fit_mask):\n        # Add an extra large value to exact fits\n        priorities[can_fit_mask][exact_fit_mask] += 1e9\n\n    return priorities\n\n[Reflection]\nPrioritize tight fits, penalize large surpluses. Handle infeasible bins explicitly.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}