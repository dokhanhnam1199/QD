{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements an improved priority function for online Bin Packing Problem.\n    This version prioritizes tight fits by favoring bins that leave minimal\n    remaining capacity, but introduces a penalty for bins that would be *too* full,\n    meaning the remaining capacity is very close to zero. It categorizes fits\n    to assign different levels of priority.\n\n    Scoring logic:\n    1. Perfect Fit (remaining capacity is effectively zero): High priority.\n    2. Tight Fit (remaining capacity is small but positive): Moderate to high priority,\n       inversely proportional to remaining capacity.\n    3. Good Fit (remaining capacity is moderate): Lower priority, inversely proportional\n       to remaining capacity.\n    4. Loose Fit (remaining capacity is large): Lowest priority among fitting bins.\n\n    A penalty is applied to 'tight' and 'perfect' fits if the remaining capacity\n    is below a certain small threshold, discouraging over-packing that might\n    make subsequent small items unplaceable.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define constants for scoring and penalty\n    epsilon = 1e-6  # For considering near-zero remaining capacity\n    # Threshold for applying the \"too full\" penalty.\n    # This is a small absolute value, intended to avoid situations where\n    # only a tiny sliver of space remains.\n    too_full_threshold = 0.1 * item  # e.g., 10% of item size or a small absolute value\n\n    # Calculate base scores favoring smaller remaining capacity\n    # Use 1/(1+x) which is high for small x and decreases as x increases.\n    # Add epsilon to denominator to prevent division by zero.\n    base_scores = 1.0 / (1.0 + remaining_after_fit + epsilon)\n\n    # Apply penalty for bins that become \"too full\" after packing\n    # The penalty is higher when remaining_after_fit is smaller (closer to zero)\n    # Penalize bins where remaining_after_fit < too_full_threshold\n    penalty_scores = np.zeros_like(remaining_after_fit)\n    too_full_mask = remaining_after_fit < too_full_threshold\n    # The penalty should be proportional to how much below the threshold it is.\n    # We scale it to ensure it can significantly reduce the priority.\n    penalty_scores[too_full_mask] = (too_full_threshold - remaining_after_fit[too_full_mask]) / too_full_threshold\n    \n    # Combine base scores with penalties.\n    # A higher base score (good fit) is reduced if the bin is too full.\n    # We want to subtract the penalty. The multiplier (e.g., 0.8) controls the penalty strength.\n    combined_scores = base_scores - (0.8 * penalty_scores)\n\n    # Normalize scores to ensure they are non-negative and have a meaningful range.\n    # Cap scores at 0 to avoid negative priorities.\n    priorities[can_fit_mask] = np.maximum(0, combined_scores)\n\n    # Further refinement: Add a small boost for bins that are \"just right\"\n    # rather than perfectly full or very loose.\n    # This is a more subtle adjustment than the penalty.\n    # Let's define a target remaining capacity, e.g., a small fraction of the bin capacity\n    # or a small absolute value.\n    # For simplicity, let's use a similar logic as the penalty but as a boost.\n    # Bins with remaining capacity slightly above zero (but not too full) might get a small boost.\n    # A Gaussian-like function centered around a small positive value could work.\n    # For this iteration, let's stick to the penalty on \"too full\" as the primary refinement.\n\n    # Optionally, add a small random perturbation for exploration/tie-breaking\n    exploration_noise = np.random.normal(0, 0.05, len(fitting_bins_caps))\n    priorities[can_fit_mask] += exploration_noise\n    # Ensure priorities remain non-negative after adding noise\n    priorities[can_fit_mask] = np.maximum(0, priorities[can_fit_mask])\n\n\n    # Ensure bins that cannot fit have a priority of 0 (already handled by initialization)\n    # priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements a hybrid priority function for online Bin Packing Problem.\n    This version refines the scoring by categorizing fits:\n    1. Perfect Fit (zero remaining capacity).\n    2. Tight Fit (remaining capacity <= item size).\n    3. Good Fit (remaining capacity > item size but not excessively large).\n    4. Loose Fit (remaining capacity is very large).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components based on remaining capacity after fit\n    # We want to prioritize smaller remaining_after_fit.\n    # Add a small epsilon to avoid division by zero for perfect fits.\n    epsilon = 1e-9\n\n    # Scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    good_fit_scores = np.zeros_like(remaining_after_fit)\n    loose_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # Thresholds for 'good fit' and 'loose fit'\n    # Threshold 1: Maximum remaining capacity for a 'tight' fit (relative to item size)\n    tight_threshold = item\n    # Threshold 2: Maximum remaining capacity for a 'good' fit (relative to item size)\n    # This aims to leave a decent amount of space, e.g., up to 3 times the item size.\n    good_threshold = 3.0 * item\n\n    # Assign scores based on categories\n    # Perfect Fit: highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 10.0\n\n    # Tight Fit: prioritize bins that leave little room but not zero\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    tight_fit_scores[tight_mask] = 5.0 / (1.0 + remaining_after_fit[tight_mask]) # Scaled best-fit\n\n    # Good Fit: prioritize bins that leave a moderate amount of room\n    # This encourages leaving space for future items.\n    good_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold)\n    # For good fits, we want remaining_after_fit to be as small as possible within this range.\n    # We can use a inverse relationship, but scaled differently.\n    good_fit_scores[good_mask] = 2.0 / (1.0 + remaining_after_fit[good_mask])\n\n    # Loose Fit: lowest priority among fitting bins, provide minimal boost for exploration\n    loose_mask = (remaining_after_fit > good_threshold)\n    loose_fit_scores[loose_mask] = 0.5 / (1.0 + remaining_after_fit[loose_mask])\n\n    # Combine scores. Weights are heuristic and can be tuned.\n    # Prioritize perfect > tight > good > loose.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.8 +\n        good_fit_scores * 0.5 +\n        loose_fit_scores * 0.2\n    )\n\n    # Add a small random component for exploration to all fitting bins\n    exploration_factor = 0.1\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Reflection]\nPrioritize tight fits, penalize over-packing, use category-based scoring, and add exploration.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}