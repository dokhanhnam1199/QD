{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid strategy.\n\n    This strategy prioritizes bins that can fit the item. Among those that can fit,\n    it favors bins that are closer to being full (i.e., have less remaining capacity\n    after fitting the item). This is a greedy approach that tries to leave larger\n    gaps in other bins for potentially larger future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize scores. Bins that cannot fit will have a very low score.\n    # We use a large negative number to ensure they are ranked last.\n    scores = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, calculate a score.\n    # We want to prioritize bins that have less remaining capacity after the item is placed.\n    # The \"remaining capacity after fit\" is (bins_remain_cap - item).\n    # To prioritize smaller remaining capacities, we can use the negative of this value.\n    # Alternatively, to use a \"goodness\" score where higher is better, we can use\n    # the inverse of the remaining capacity *after* the item is placed, plus a small\n    # epsilon to avoid division by zero and to ensure that bins that become exactly full\n    # get a high score.\n    # A simple approach is to use `bins_remain_cap - item`, and we want to minimize this value.\n    # To convert this into a \"priority\" where higher is better, we can use its negative.\n    # A common heuristic for \"best fit\" is to find the bin with the minimum `bins_remain_cap - item`.\n    # So, a higher priority should be given to smaller values of `bins_remain_cap - item`.\n    # Let's assign a score that is the negative of the remaining capacity *after* fitting.\n    # This means bins that have `bins_remain_cap - item == 0` will have a score of 0.\n    # Bins that have `bins_remain_cap - item == X` will have a score of -X.\n    # This naturally prioritizes exact fits (score 0) over bins with remaining space.\n    scores[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    # To make these scores more \"softmax-friendly\" or generally interpretable as positive\n    # priorities, we can shift them so that the minimum possible score (if we consider\n    # all possible remaining capacities) maps to a small positive value.\n    # The smallest `bins_remain_cap - item` could be 0. The largest would depend on\n    # the initial bin capacities and item sizes.\n    # A simpler approach that directly reflects the \"best fit\" idea is to assign a\n    # score that is higher for bins closer to fitting the item.\n    # Let's re-evaluate: we want to prioritize bins where `bins_remain_cap - item` is small.\n    # The smaller `bins_remain_cap - item` is, the higher the priority.\n    # So, a simple monotonic transformation that maps smaller `bins_remain_cap - item`\n    # to larger priority values is desired.\n    # Using `1.0 / (bins_remain_cap[can_fit_mask] - item + epsilon)` achieves this,\n    # as seen in `priority_v1`. This also provides a \"soft\" prioritization.\n\n    # Let's refine the reflection: \"Prioritize fits, then closeness to full.\"\n    # \"Closeness to full\" means minimizing the *remaining* capacity.\n    # For a bin `b` with remaining capacity `c_b`, and an item `i` of size `s_i`:\n    # If `c_b >= s_i`, the bin can fit.\n    # The \"closeness to full\" after fitting is `c_b - s_i`. We want to minimize this.\n    # So, priority should be higher when `c_b - s_i` is smaller.\n\n    # Let's try a simple assignment:\n    # For bins that can fit, score = -(bins_remain_cap - item)\n    # This means:\n    # - Exact fit (remaining capacity after fit = 0) gets score 0.\n    # - Bin with remaining capacity after fit = 1 gets score -1.\n    # - Bin with remaining capacity after fit = 10 gets score -10.\n    # This correctly prioritizes exact fits (0 > -1 > -10).\n\n    scores[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    # If we want to ensure that even non-fitting bins have a chance to be selected\n    # (though with very low priority), we could assign a small negative value to them.\n    # However, for typical online bin packing, if an item cannot fit anywhere,\n    # a new bin must be opened. So, prioritizing only fitting bins is correct.\n    # The current `scores` array has `-np.inf` for non-fitting bins.\n\n    # The problem asks for a priority *score* for each bin.\n    # The previous \"Better code\" used softmax to convert scores into probabilities.\n    # The reflection suggests prioritizing fits, then closeness to full.\n    # A simple way to achieve this without softmax (if softmax is not strictly required by the prompt)\n    # is to directly return scores that reflect this preference.\n\n    # Let's consider a scenario:\n    # item = 5\n    # bins_remain_cap = [10, 6, 5, 12]\n    #\n    # Bin 0: can fit, remaining after fit = 10 - 5 = 5. Score = -5\n    # Bin 1: can fit, remaining after fit = 6 - 5 = 1. Score = -1\n    # Bin 2: can fit, remaining after fit = 5 - 5 = 0. Score = 0\n    # Bin 3: can fit, remaining after fit = 12 - 5 = 7. Score = -7\n    #\n    # Scores: [-5, -1, 0, -7]\n    # The highest score (0) is for bin 2 (exact fit).\n    # The next highest (-1) is for bin 1 (closest to full after fit).\n    # This aligns with the reflection.\n\n    # The question is what the output *should* be. If it's a direct priority score\n    # that will be used in a `max()` function to select the bin, then these negative\n    # scores work. If it's for a probabilistic selection (like softmax), then\n    # `priority_v1` is more appropriate. The prompt says \"the bin with the highest priority score will be selected\".\n    # This implies a deterministic selection based on the highest score.\n\n    # Therefore, the `scores` computed above directly serve as priority scores.\n    # No need for softmax if the selection is deterministic.\n\n    # Let's ensure that the priority scores are easily distinguishable and\n    # that non-fitting bins are clearly lower.\n    # Using `-np.inf` for non-fitting bins is good.\n    # For fitting bins, `-(bins_remain_cap - item)` works.\n\n    # Consider numerical stability and range of values.\n    # If `bins_remain_cap - item` can be very large, the negative scores will be very small (large negative).\n    # This is fine for direct comparison.\n\n    # Let's make it slightly more robust by ensuring non-fitting bins get a clearly worse score\n    # than any possible fitting bin score.\n    # The minimum possible value for `bins_remain_cap - item` is 0. So the maximum score is 0.\n    # Any score less than 0 is worse. So `-np.inf` for non-fitting bins is appropriate.\n\n    # The current implementation `scores[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)`\n    # directly implements the \"prioritize fits, then closeness to full\" by assigning\n    # higher scores to bins with smaller remaining capacity after fitting the item.\n\n    # Let's consider the case where the item is larger than any bin's capacity.\n    # `can_fit_mask` would be all `False`. `scores` would remain all `-np.inf`.\n    # This correctly indicates no valid placement.\n\n    # Final check of the strategy:\n    # 1. Prioritize bins that *can* fit the item. (Handled by `can_fit_mask` and initial `-np.inf`)\n    # 2. Among those that can fit, prioritize bins that are \"closer to full\".\n    #    \"Closer to full\" after placing the item means `bins_remain_cap - item` is minimized.\n    #    So, we want to assign higher priority when `bins_remain_cap - item` is small.\n    #    Our score `-(bins_remain_cap - item)` does exactly this:\n    #    - If `bins_remain_cap - item = 0` (exact fit), score is 0 (highest).\n    #    - If `bins_remain_cap - item = 1`, score is -1.\n    #    - If `bins_remain_cap - item = 5`, score is -5.\n    #    This order `0 > -1 > -5` matches the desired priority.\n\n    # This looks like a solid implementation of the described strategy.\n\n    return scores\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid strategy.\n\n    This strategy combines the \"Best Fit\" approach (minimizing remaining capacity)\n    with a stochastic element to encourage exploration of less obviously optimal bins.\n    It also prioritizes bins that are \"almost full\" to potentially group smaller items\n    more efficiently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Determine which bins can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit, return all zeros\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Strategy 1: Best Fit - prioritize bins that will have the least remaining capacity\n    # This is a common greedy strategy for BPP.\n    remaining_after_fit = fitting_bins_caps - item\n    # We want to minimize remaining_after_fit, so higher priority for smaller remaining capacity.\n    # Add a small constant to avoid division by zero if remaining_after_fit is 0.\n    best_fit_scores = 1.0 / (1.0 + remaining_after_fit)\n\n    # Strategy 2: \"Almost Full\" bins - prioritize bins that are very close to being full\n    # This can help consolidate smaller items and leave larger capacities open.\n    # We define \"almost full\" as having a remaining capacity between 0 and a small threshold.\n    almost_full_threshold = 0.1 * np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0.1\n    almost_full_mask_subset = (fitting_bins_caps > 0) & (fitting_bins_caps <= almost_full_threshold)\n    almost_full_scores = np.zeros_like(fitting_bins_caps)\n    almost_full_scores[almost_full_mask_subset] = 0.5 # Assign a moderate priority\n\n    # Strategy 3: Exploration - add a small random component to encourage trying different bins\n    # This is inspired by exploration in reinforcement learning.\n    exploration_factor = 0.1\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n\n    # Combine scores. A bin is good if it's a good best-fit OR it's almost full.\n    # We use a weighted sum, prioritizing best fit more.\n    combined_scores = (0.7 * best_fit_scores) + (0.3 * almost_full_scores) + random_scores\n\n    # Assign the calculated scores to the corresponding bins\n    priorities[can_fit_mask] = combined_scores\n\n    # Ensure bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Reflection]\nConsider stochasticity, combining multiple criteria, and fine-tuning weights for better results.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}