```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements an enhanced priority function for online Bin Packing Problem,
    focusing on a more adaptive and nuanced scoring mechanism.

    This version aims to balance the "best fit" principle with a consideration
    for future packing flexibility. It categorizes potential bins and assigns
    scores that reflect desirability, with tunable parameters.

    Categories and scoring logic:
    1. Perfect Fit: Remaining capacity is virtually zero. Highest priority.
    2. Tight Fit: Remaining capacity is small, close to zero but positive.
                   Prioritized highly, score decreases as remaining capacity increases.
    3. Good Fit: Remaining capacity is moderate, offering a reasonable space for future items.
                   Scores decrease, but at a slower rate than tight fits.
    4. Loose Fit: Remaining capacity is large. Lowest priority among fitting bins,
                   but still offers a small score to encourage exploration.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array where each element represents the
                         remaining capacity of a bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        is the priority score for placing the item in the corresponding bin.
        Bins that cannot fit the item will have a score of 0.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item
    fitting_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    # --- Tunable Parameters ---
    # Epsilon for floating-point comparisons (perfect fit)
    epsilon = 1e-9

    # Thresholds for categorizing fits relative to item size.
    # These can be adjusted for different problem instances.
    # Example: Tight fit is when remaining capacity is <= 1 * item size.
    tight_threshold_factor = 1.0
    # Example: Good fit is when remaining capacity is > 1 * item size and <= 3 * item size.
    good_threshold_factor = 3.0

    # Weights for each category. Higher weights mean higher priority.
    # Order: Perfect > Tight > Good > Loose
    perfect_weight = 10.0
    tight_weight = 8.0
    good_weight = 5.0
    loose_weight = 2.0

    # Scaling factors for scores within categories to ensure scores decrease
    # as remaining capacity increases within a category.
    # These are generally inverse relationships, adjusted for non-zero denominators.
    tight_score_scale = 5.0
    good_score_scale = 3.0
    loose_score_scale = 1.0

    # Exploration factor: adds a small random boost to all fitting bins.
    # Higher values encourage more exploration of different packing options.
    exploration_factor = 0.15

    # --- Scoring Logic ---
    tight_threshold = item * tight_threshold_factor
    good_threshold = item * good_threshold_factor

    # Initialize score components
    perfect_fit_scores = np.zeros_like(remaining_after_fit)
    tight_fit_scores = np.zeros_like(remaining_after_fit)
    good_fit_scores = np.zeros_like(remaining_after_fit)
    loose_fit_scores = np.zeros_like(remaining_after_fit)

    # 1. Perfect Fit
    perfect_mask = (remaining_after_fit < epsilon)
    perfect_fit_scores[perfect_mask] = perfect_weight

    # 2. Tight Fit (0 < remaining_after_fit <= tight_threshold)
    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)
    if np.any(tight_mask):
        # Score decreases as remaining_after_fit increases
        tight_fit_scores[tight_mask] = tight_weight / (1.0 + remaining_after_fit[tight_mask] * (tight_score_scale / tight_threshold))

    # 3. Good Fit (tight_threshold < remaining_after_fit <= good_threshold)
    good_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold)
    if np.any(good_mask):
        # Score decreases, but less steeply than tight fits
        good_fit_scores[good_mask] = good_weight / (1.0 + remaining_after_fit[good_mask] * (good_score_scale / good_threshold))

    # 4. Loose Fit (remaining_after_fit > good_threshold)
    loose_mask = (remaining_after_fit > good_threshold)
    if np.any(loose_mask):
        # Minimal score to encourage exploration, decreases slowly
        loose_fit_scores[loose_mask] = loose_weight / (1.0 + remaining_after_fit[loose_mask] * (loose_score_scale / (bins_remain_cap.max() - item + 1e-9))) # Normalize by max possible remaining

    # Combine scores with weights
    combined_scores = (
        perfect_fit_scores +
        tight_fit_scores +
        good_fit_scores +
        loose_fit_scores
    )

    # Add exploration component
    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor
    combined_scores += random_scores

    # Assign calculated scores to the original priority array
    priorities[can_fit_mask] = combined_scores

    return priorities
```
