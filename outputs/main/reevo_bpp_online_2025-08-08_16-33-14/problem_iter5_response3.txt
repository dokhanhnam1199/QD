```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements a refined priority function for online Bin Packing Problem,
    incorporating a more nuanced approach to bin selection.

    The function categorizes potential bins based on how tightly an item fits,
    assigning scores that reflect desirability. It prioritizes bins that result
    in minimal remaining capacity after packing, but with a dampening effect
    for extremely tight fits that might be suboptimal in the long run.

    Categories and scoring logic:
    1. Perfect Fit: Remaining capacity is exactly zero. Highest priority.
    2. Tight Fit: Remaining capacity is positive but small (e.g., less than or equal to the item size).
                   Prioritized, with higher scores for smaller remaining capacities.
    3. Good Fit: Remaining capacity is moderate. These bins are still useful,
                  but less so than tight fits. Scores decrease as remaining capacity increases.
    4. Loose Fit: Remaining capacity is large. Lowest priority among fitting bins,
                  offering a minimal score to encourage exploration.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array where each element represents the
                         remaining capacity of a bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        is the priority score for placing the item in the corresponding bin.
        Bins that cannot fit the item will have a score of 0.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item
    fitting_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    # Define scoring parameters and thresholds. These are heuristic and can be tuned.
    epsilon = 1e-9  # For handling floating-point comparisons, especially for perfect fits.

    # Thresholds for categorizing fits (relative to item size or a fixed value)
    # A bin is a "tight fit" if remaining capacity is <= item size.
    tight_threshold = item
    # A bin is a "good fit" if remaining capacity is within a certain range,
    # e.g., up to a multiple of the item size, but not excessively large.
    # We might want to avoid bins that leave *too* much space, as they might be "wasted".
    # Let's define a "good" range that isn't too large.
    good_threshold_upper = item * 2.5  # Example: remaining capacity up to 2.5 times item size

    # --- Scoring Logic ---
    # We want to prioritize smaller remaining capacities (better fits).
    # Use an inverse relationship, but introduce a damping factor for very small
    # remaining capacities to avoid overly penalizing bins that are *almost* full
    # but not quite, which might be slightly less optimal than a perfect fit but still good.

    # Perfect Fit (remaining_after_fit is essentially 0)
    perfect_fit_scores = np.where(remaining_after_fit < epsilon, 10.0, 0.0)

    # Tight Fit (0 < remaining_after_fit <= tight_threshold)
    # Prioritize bins that leave less residual space.
    # The inverse of remaining_after_fit gives a higher score for smaller values.
    # Add 1 to denominator to prevent division by zero and to give a boost.
    tight_fit_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)
    tight_fit_scores = np.where(tight_fit_mask, 5.0 / (1.0 + remaining_after_fit), 0.0)

    # Good Fit (tight_threshold < remaining_after_fit <= good_threshold_upper)
    # These are still good fits, but less optimal than tight fits.
    # The score should be lower than tight fits and decrease as remaining capacity increases.
    good_fit_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold_upper)
    # Slightly penalize larger remaining capacities within this "good" range.
    good_fit_scores = np.where(good_fit_mask, 2.0 / (1.0 + remaining_after_fit * 0.5), 0.0) # Scale down impact

    # Loose Fit (remaining_after_fit > good_threshold_upper)
    # These bins have a lot of remaining space. Assign a low score.
    # This encourages using these bins only when better options are not available.
    loose_fit_mask = (remaining_after_fit > good_threshold_upper)
    loose_fit_scores = np.where(loose_fit_mask, 0.5 / (1.0 + remaining_after_fit * 0.1), 0.0) # Minimal score


    # Combine scores with weights. Weights reflect the priority order: Perfect > Tight > Good > Loose.
    # These weights can be adjusted for different strategies.
    combined_scores = (
        perfect_fit_scores * 1.0 +
        tight_fit_scores * 0.9 +  # Slightly reduce weight for tight fits compared to perfect
        good_fit_scores * 0.6 +   # Moderate weight for good fits
        loose_fit_scores * 0.3    # Low weight for loose fits
    )

    # --- Exploration Component ---
    # Add a small random value to all fitting bins to introduce a stochastic element
    # and prevent deterministic behavior which can sometimes lead to suboptimal choices.
    # This can help break ties and explore alternative packing options.
    exploration_factor = 0.15 # Increased exploration factor slightly
    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor

    priorities[can_fit_mask] = combined_scores + random_scores

    return priorities
```
