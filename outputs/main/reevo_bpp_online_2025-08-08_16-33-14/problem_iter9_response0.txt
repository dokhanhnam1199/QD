```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements an advanced priority function for the online Bin Packing Problem,
    incorporating quadratic rewards for snugness, adaptive thresholds, and
    dynamic scaling for a more nuanced bin selection.

    The priority is calculated as follows:
    1. Bins that cannot fit the item receive a priority of 0.
    2. For bins that can fit the item:
       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.
       b. Tight Fits (remaining capacity is small): Priority is quadratically
          proportional to the inverse of the remaining capacity. This strongly
          rewards near-perfect fits.
       c. Good Fits (remaining capacity is moderate): Priority decreases
          logarithmically as remaining capacity increases. This provides a
          smoother decay than tight fits.
       d. Wasteful Fits (remaining capacity is large): Penalized, with the
          penalty increasing with the ratio of remaining capacity to item size.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.

    Returns:
        A NumPy array of the same size as bins_remain_cap, where each element
        represents the priority score for placing the item in the corresponding bin.
        Higher scores indicate higher priority.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_caps = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_caps - item

    # Define thresholds adaptively. These are relative to the item size.
    epsilon = 1e-9  # Tolerance for floating-point comparisons

    # Threshold for "tight" fits: remaining space is less than 20% of item size.
    tight_fit_threshold = 0.2 * item

    # Threshold for "wasteful" fits: remaining space is more than 150% of item size.
    wasteful_threshold = 1.5 * item

    # --- Scoring Logic ---
    scores = np.zeros_like(remaining_after_fit)

    # 1. Perfect Fits: Highest priority.
    perfect_mask = (remaining_after_fit < epsilon)
    scores[perfect_mask] = 1000.0

    # 2. Tight Fits: Quadratically reward snugness.
    # Priority ~ 1 / (remaining_after_fit^2) for small remaining_after_fit.
    # Add epsilon to denominator to avoid division by zero and scale for range.
    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)
    # Quadratic term for snugness, scaled for appropriate priority values.
    scores[tight_mask] = 200.0 / (remaining_after_fit[tight_mask]**2 + epsilon)

    # 3. Good Fits: Logarithmic decay for moderate remaining space.
    # These bins are not tight but also not wasteful.
    good_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)
    # Logarithmic decay: priority decreases slower as remaining capacity grows.
    # Using log1p for numerical stability and to avoid log(0). Scaled for range.
    scores[good_mask] = 100.0 - 50.0 * np.log1p(remaining_after_fit[good_mask] / item)

    # 4. Wasteful Fits: Penalized based on excess capacity.
    # These bins have remaining space significantly larger than the item.
    wasteful_mask = (remaining_after_fit > wasteful_threshold)
    # Penalty based on the ratio of remaining capacity to item size.
    # The penalty should be significant. Using a scaled inverse ratio.
    # The base score is low to reflect the inefficiency.
    base_wasteful_score = 5.0
    penalty_strength = 3.0  # Controls how strongly large remaining capacities are penalized.
    scores[wasteful_mask] = base_wasteful_score / (1.0 + penalty_strength * (remaining_after_fit[wasteful_mask] / item))

    # Ensure all calculated scores are non-negative.
    scores[scores < 0] = 0

    # Introduce exploration by adding a small amount of noise.
    # The noise scale can be adapted based on the current state of the bins,
    # e.g., if all bins have very similar priorities. For simplicity, a fixed
    # small scale is used here.
    exploration_jitter_scale = 0.02  # Small jitter to encourage exploration
    max_possible_score_estimate = 1000.0 # Max score for perfect fit
    jitter = np.random.uniform(-exploration_jitter_scale * max_possible_score_estimate,
                               exploration_jitter_scale * max_possible_score_estimate,
                               size=len(scores))
    final_scores = scores + jitter

    # Ensure jitter does not result in negative priorities.
    final_scores[final_scores < 0] = 0

    # Assign the calculated scores to the corresponding bins in the original priority array.
    priorities[can_fit_mask] = final_scores

    return priorities
```
