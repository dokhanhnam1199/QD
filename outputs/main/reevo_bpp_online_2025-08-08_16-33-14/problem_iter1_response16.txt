```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Sigmoid Fit Score.

    The Sigmoid Fit Score prioritizes bins that are a "good fit" for the item,
    meaning they have a remaining capacity that is slightly larger than the item's size.
    This helps to minimize wasted space.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Ensure item size is positive
    item = max(0.0, item)

    # Calculate the difference between bin remaining capacity and item size
    diffs = bins_remain_cap - item

    # We want to prioritize bins where diffs are small and positive (good fit)
    # and penalize bins that are too small (negative diffs) or too large (large positive diffs).
    # A sigmoid function can map these differences to a priority score between 0 and 1.
    # We can shift and scale the differences to center the "ideal fit" around 0.
    # A reasonable approach is to use the item size as a scaling factor for the difference.

    # Avoid division by zero if item is 0, and handle cases where bins_remain_cap might be 0
    # Use a small epsilon to prevent division by zero issues
    epsilon = 1e-9
    scaled_diffs = np.where(bins_remain_cap > epsilon, diffs / bins_remain_cap, -1.0)

    # The sigmoid function is 1 / (1 + exp(-x)).
    # We want a higher score for smaller positive differences (closer to 0).
    # A negative scaled difference means the bin is too small.
    # A large positive scaled difference means the bin has a lot of excess capacity.
    # We can use a transformation of the scaled difference that is high around 0 and decreases
    # as the difference becomes more positive or more negative.
    # A simple approach is to use exp(-abs(scaled_diffs)).
    # However, to leverage the "good fit" idea more directly, we can aim for a peak near diff=0.
    # A modified sigmoid could work: sigmoid(k * (ideal_fit_capacity - remaining_capacity))
    # Let's reframe: we want to maximize the value for bins where remaining_capacity is close to item size.

    # Strategy: Prioritize bins that have *just enough* capacity.
    # This means a positive difference that is as small as possible.
    # Bins that are too small (negative difference) should have a low priority.
    # Bins that have a lot of excess capacity (large positive difference) should also have lower priority than a "just fit".

    # Let's try a sigmoid centered around an "ideal" fit where the remaining capacity is item + some small buffer.
    # Or, more directly, penalize large positive differences.

    # Consider diffs:
    # diff < 0: Bin too small. Low priority.
    # diff = 0: Perfect fit. High priority.
    # diff > 0: Bin has excess capacity.
    #   - Small diff > 0: Good fit. High priority.
    #   - Large diff > 0: Wasteful. Lower priority than good fit.

    # A function that peaks at diff = 0 and drops off as |diff| increases.
    # exp(-abs(diffs)) might work, but let's try something more sigmoid-like.

    # Sigmoid applied to negative differences to boost near-zero differences.
    # We want to map diffs to a [0, 1] range where higher is better.
    # For diffs < 0 (too small), priority should be near 0.
    # For diffs >= 0 (sufficient capacity), priority should be higher, peaking near diff=0.

    # A shifted and scaled sigmoid:
    # Let's center the sigmoid around 0, so sigmoid(0) = 0.5.
    # We can adjust the steepness (k) and the midpoint.
    # The input to sigmoid could be related to diffs.
    # We want higher priority for diffs closer to 0.

    # Let's try mapping diffs to a range where the most desirable values are between 0 and a small positive number.
    # We can transform diffs into something that reaches its maximum when diff is small and positive.

    # Option 1: Focus on the "tight fit" aspect.
    # Prioritize bins where capacity is slightly larger than the item.
    # This means maximizing a function that is high for small positive diffs and lower for negative diffs or large positive diffs.
    # We can use a sigmoid on the *negative* of the difference, scaled appropriately.
    # `sigmoid(k * (item - bin_remain_cap))` might work, but it penalizes bins that are too small too heavily.

    # Let's try a combination:
    # 1. Filter out bins that are too small (capacity < item). Give them a very low priority.
    # 2. For bins that are large enough (capacity >= item), use a sigmoid that peaks when capacity is just slightly larger than item.

    # Using the remaining capacity directly, we want to be closer to `item`.
    # Let's scale the differences by the item size to make it relative.
    # `scaled_relative_diffs = diffs / (item + epsilon)`
    # A sigmoid on negative scaled diffs: `1 / (1 + exp(-k * scaled_relative_diffs))`
    # This will be high if `scaled_relative_diffs` is positive and small.

    # Sigmoid function: sigmoid(x) = 1 / (1 + exp(-x))
    # We want a higher score when `bins_remain_cap` is just above `item`.
    # Let `x = -(bins_remain_cap - item) / item`  (this is `(item - bins_remain_cap) / item`)
    # If `bins_remain_cap` is slightly larger than `item`, `item - bins_remain_cap` is small negative, so `x` is small positive. Sigmoid is near 0.5.
    # If `bins_remain_cap` is much larger than `item`, `item - bins_remain_cap` is large negative, so `x` is large positive. Sigmoid is near 1. This is not what we want.

    # Let's reconsider the goal: "good fit" implies the remaining capacity is just enough.
    # This suggests we want `bins_remain_cap` to be close to `item`.
    # If `bins_remain_cap < item`, it's unusable. Priority 0.
    # If `bins_remain_cap == item`, it's a perfect fit. High priority.
    # If `bins_remain_cap > item`, there's waste. Priority decreases as waste increases.

    # Let's try mapping `bins_remain_cap` to a priority.
    # Bins with `bins_remain_cap < item` get priority 0.
    # Bins with `bins_remain_cap >= item` get a score based on how close `bins_remain_cap` is to `item`.
    # A suitable function for this could be `exp(-k * (bins_remain_cap - item))` where k is a positive constant.
    # This function is 1 when `bins_remain_cap == item` and decreases as `bins_remain_cap` increases.

    # We can normalize `bins_remain_cap` and `item` relative to a hypothetical bin capacity or maximum possible item size.
    # For simplicity, let's work with the absolute differences and a sigmoid transformation.

    # Let's use a sigmoid on a transformation of `diffs`.
    # We want higher priority for `diffs` near zero and positive.
    # Consider `sigmoid(k * (max_reasonable_waste - diffs))`.
    # If `diffs` is negative (too small), this will be `sigmoid(k * (max_reasonable_waste - neg_value))`, which is large. This is also not ideal.

    # Let's use a sigmoid to map `diffs` to a range.
    # We want `diffs` to be small and positive for high priority.
    # `sigmoid(constant - k * diffs)`:
    #   - If diffs is small positive, `k * diffs` is small positive, `constant - k*diffs` is large. Sigmoid is near 1.
    #   - If diffs is large positive, `k * diffs` is large positive, `constant - k*diffs` is small negative. Sigmoid is near 0.
    #   - If diffs is negative, `k * diffs` is small negative, `constant - k*diffs` is large positive. Sigmoid is near 1.

    # This means we need to specifically handle the `diffs < 0` case.

    # Let's filter out invalid bins first.
    valid_bins_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap)

    if np.any(valid_bins_mask):
        valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]
        valid_diffs = valid_bins_remain_cap - item

        # We want to prioritize smaller `valid_diffs`.
        # Let's use a sigmoid that maps small positive numbers to high values and larger positive numbers to lower values.
        # `sigmoid(k * (A - x))` where `x` is `valid_diffs`. We want `A` to represent an ideal surplus.
        # A simple choice is to center it around 0 or a small positive value.

        # Let's scale the differences relative to the item size to handle varying item scales.
        # `scaled_valid_diffs = valid_diffs / (item + epsilon)`
        # Now, we want `scaled_valid_diffs` to be close to 0.
        # Let's use `sigmoid(k * (-scaled_valid_diffs))`.
        # If `scaled_valid_diffs` is small positive (good fit), `-scaled_valid_diffs` is small negative. Sigmoid is < 0.5.
        # If `scaled_valid_diffs` is near 0 (perfect fit), `-scaled_valid_diffs` is near 0. Sigmoid is 0.5.
        # If `scaled_valid_diffs` is large positive (wasteful), `-scaled_valid_diffs` is large negative. Sigmoid is near 0.
        # This is also not quite right.

        # Let's re-frame for "Sigmoid Fit Score": prioritize bins that are a "close fit".
        # A close fit means `bins_remain_cap` is close to `item`.
        # Let `score = sigmoid(alpha - beta * abs(bins_remain_cap - item))`
        # This score peaks when `abs(bins_remain_cap - item)` is minimal.
        # However, we must also account for `bins_remain_cap < item`.

        # A more common Sigmoid Fit strategy aims to find a bin whose remaining capacity is just enough.
        # If `remaining_capacity < item`, priority is 0.
        # If `remaining_capacity >= item`, the priority is `sigmoid((bin_capacity - item) / bin_capacity)` or similar.

        # Let's try this: a higher priority for bins that have a smaller proportion of wasted space.
        # Wasted space proportion: `(bins_remain_cap - item) / bins_remain_cap` for valid bins.
        # We want to maximize this value, meaning minimize `(item / bins_remain_cap)`.
        # Let `ratio = item / valid_bins_remain_cap`. We want to maximize `1 - ratio`.
        # A higher value for `1-ratio` means `ratio` is smaller, i.e., `item` is smaller relative to `bins_remain_cap`.
        # This means a lot of wasted space. This is counter-intuitive to "fit score".

        # The "fit" part usually refers to the item filling up the bin as much as possible.
        # This means prioritizing bins where `item / bins_remain_cap` is close to 1.
        # This implies `bins_remain_cap` is close to `item`.

        # Let's try this formulation for valid bins:
        # Prioritize bins where `bins_remain_cap` is close to `item`.
        # The input to the sigmoid should be high when `bins_remain_cap` is close to `item` (and >= item).
        # Let `x = (bins_remain_cap - item)`.
        # We want high scores for small positive `x`.
        # `sigmoid(k * (some_value - x))`. If `some_value` is 0, we get `sigmoid(-k*x)`.
        # If x is small positive, -kx is small negative, sigmoid < 0.5.
        # If x is 0, sigmoid is 0.5.
        # If x is large positive, -kx is large negative, sigmoid near 0.
        # This prioritizes exact fits.

        # We can shift the sigmoid: `sigmoid(k * (C - x))` where C is some desired surplus.
        # Or, we can use `sigmoid(k * (-x))` and then `1 - sigmoid(-k * x)` which is `sigmoid(k*x)`.
        # `sigmoid(k * x)`:
        #   - x small positive (good fit): sigmoid near 0.5
        #   - x zero (perfect fit): sigmoid is 0.5
        #   - x large positive (wasteful): sigmoid near 1
        # This seems to prioritize larger remaining capacities.

        # Let's try a sigmoid on the inverse of the relative waste:
        # `relative_waste = (bins_remain_cap - item) / bins_remain_cap`
        # `inverse_relative_waste = bins_remain_cap / (bins_remain_cap - item)` if diff > 0.
        # We want to maximize `item / bins_remain_cap`.

        # Sigmoid Fit typically means making `bins_remain_cap` just slightly larger than `item`.
        # Let `f(capacity) = sigmoid(k * (item - capacity))`. This maps values smaller than `item` to high priority, which is wrong.

        # Let's map `bins_remain_cap` for `valid_bins_mask` to priorities.
        # Consider the distance from a "perfect" fit.
        # `distance_from_perfect = valid_bins_remain_cap - item`
        # We want this distance to be small.
        # A sigmoid centered around 0: `sigmoid(k * (-distance_from_perfect))`
        # If distance is 0, input is 0, output is 0.5.
        # If distance is small positive, input is small negative, output < 0.5.
        # If distance is large positive, input is large negative, output ~ 0.
        # This prioritizes bins that are too small.

        # How about scaling the difference relative to the item?
        # `scaled_diff = (valid_bins_remain_cap - item) / (item + epsilon)`
        # We want this to be small and positive.
        # Use `sigmoid(k * (C - scaled_diff))` where C is a small positive constant.
        # Let C = 0.1 (allow up to 10% surplus).
        # Let k = 10 (steepness).

        # `sigmoid(10 * (0.1 - scaled_diff))`
        # If `scaled_diff` = 0 (perfect fit), input is 10 * 0.1 = 1. Sigmoid = 0.73.
        # If `scaled_diff` = 0.1 (10% surplus), input is 10 * (0.1 - 0.1) = 0. Sigmoid = 0.5.
        # If `scaled_diff` = 0.2 (20% surplus), input is 10 * (0.1 - 0.2) = -1. Sigmoid = 0.27.
        # If `scaled_diff` = -0.05 (item is 5% larger than capacity, effectively this is a small fit for item's perspective, but our `valid_bins_mask` prevents this)
        # Let's re-evaluate `valid_bins_mask = bins_remain_cap >= item`.
        # So `valid_diffs >= 0`, and `scaled_diff >= 0`.

        # We want high priority for small `scaled_diff`.
        # Use `sigmoid(k * (max_desired_scaled_diff - scaled_diff))`
        # Let `max_desired_scaled_diff = 0.2` (allow up to 20% surplus)
        # Let `k = 10`

        # `sigmoid(10 * (0.2 - scaled_diff))`
        # If `scaled_diff` = 0 (perfect fit), input is 10 * 0.2 = 2. Sigmoid = 0.88.
        # If `scaled_diff` = 0.1 (10% surplus), input is 10 * (0.2 - 0.1) = 1. Sigmoid = 0.73.
        # If `scaled_diff` = 0.2 (20% surplus), input is 10 * (0.2 - 0.2) = 0. Sigmoid = 0.5.
        # If `scaled_diff` = 0.3 (30% surplus), input is 10 * (0.2 - 0.3) = -1. Sigmoid = 0.27.

        # This looks reasonable. It prioritizes bins that have a smaller surplus relative to the item size.
        # The `max_desired_scaled_diff` parameter controls how much surplus is tolerated before priority drops significantly.

        # Let's refine this: the sigmoid argument should probably be based on the *ratio* of item to capacity for a direct "filling" measure.
        # If `bins_remain_cap` is slightly larger than `item`, the ratio `item / bins_remain_cap` is close to 1.
        # Let's try mapping this ratio to priority.
        # `ratio = item / valid_bins_remain_cap`
        # We want to maximize this ratio, but ensure `ratio <= 1`.
        # `sigmoid(k * (ratio - 1))` would map ratios slightly less than 1 to values < 0.5, and ratios close to 0 to values near 0.
        # `sigmoid(k * (1 - ratio))` would map ratios slightly less than 1 to values > 0.5, and ratios close to 0 to values near 1.

        # The latter is closer to our goal: prioritizing bins that are "filled" more.
        # `sigmoid(k * (1 - item / valid_bins_remain_cap))`
        # If `valid_bins_remain_cap` is just above `item`, `item / valid_bins_remain_cap` is slightly less than 1.
        # `1 - (slightly less than 1)` is small positive. Sigmoid is > 0.5.
        # If `valid_bins_remain_cap` is much larger than `item`, `item / valid_bins_remain_cap` is small positive.
        # `1 - (small positive)` is close to 1. Sigmoid is near 1. This means it prioritizes large empty bins!

        # Okay, let's go back to `scaled_diff = (valid_bins_remain_cap - item) / (item + epsilon)`.
        # We want small positive `scaled_diff`.
        # `sigmoid(k * (MAX_SURPLUS_RATIO - scaled_diff))`
        # `MAX_SURPLUS_RATIO` can be a tunable parameter, e.g., 0.1 for 10% surplus.

        MAX_SURPLUS_RATIO = 0.2  # Allow up to 20% of item size as surplus
        STEEPNESS = 10.0         # Controls how quickly priority drops after MAX_SURPLUS_RATIO

        # Calculate scaled differences for valid bins
        # Using item size for scaling helps normalize the surplus
        scaled_valid_diffs = valid_diffs / (item + epsilon)

        # Apply the sigmoid transformation
        # The argument is `STEEPNESS * (MAX_SURPLUS_RATIO - scaled_valid_diffs)`
        # This will yield high values for `scaled_valid_diffs` close to 0 and less than `MAX_SURPLUS_RATIO`.
        # It will yield lower values for `scaled_valid_diffs` larger than `MAX_SURPLUS_RATIO`.
        sigmoid_input = STEEPNESS * (MAX_SURPLUS_RATIO - scaled_valid_diffs)
        
        # Ensure that we don't get numerically unstable values for sigmoid input
        sigmoid_input = np.clip(sigmoid_input, -20, 20) # To prevent overflow in exp

        priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_input))

    return priorities

```
