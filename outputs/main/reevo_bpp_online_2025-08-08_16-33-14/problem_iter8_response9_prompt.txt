{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements an improved priority function for online Bin Packing Problem,\n    prioritizing tight fits and using simpler, well-defined thresholds.\n\n    The function assigns scores to bins based on how well they fit an item:\n    1. Perfect Fit: Bin's remaining capacity is exactly zero after packing. Highest priority.\n    2. Tight Fit: Bin's remaining capacity after packing is small (<= item size). High priority.\n    3. Moderate Fit: Bin's remaining capacity after packing is larger than item size but not excessively so (<= 2 * item size). Medium priority.\n    4. Loose Fit: Bin's remaining capacity after packing is large (> 2 * item size). Lowest priority.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for the corresponding bin. Higher scores indicate\n        higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds for categorizing fits relative to the item size\n    epsilon = 1e-9  # For floating-point comparisons, especially for perfect fits\n    tight_threshold = item\n    moderate_threshold = 2.0 * item\n\n    # Initialize scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    moderate_fit_scores = np.zeros_like(remaining_after_fit)\n    loose_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # Calculate scores for each category:\n    # Perfect Fit: Highest score, indicating minimal waste.\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 10.0\n\n    # Tight Fit: Prioritize bins that leave little remaining capacity after packing.\n    # Score is inversely proportional to the remaining capacity, encouraging fuller bins.\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    tight_fit_scores[tight_mask] = 5.0 / (1.0 + remaining_after_fit[tight_mask])\n\n    # Moderate Fit: Bins that leave a moderate amount of space.\n    # Score decreases as remaining capacity increases, but less steeply than tight fits.\n    moderate_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= moderate_threshold)\n    moderate_fit_scores[moderate_mask] = 2.0 / (1.0 + remaining_after_fit[moderate_mask])\n\n    # Loose Fit: Bins that leave a significant amount of space.\n    # These are less preferred, so they receive a low base score.\n    loose_mask = (remaining_after_fit > moderate_threshold)\n    loose_fit_scores[loose_mask] = 1.0 / (1.0 + remaining_after_fit[loose_mask])\n\n    # Combine scores using weights to reflect the priority order: Perfect > Tight > Moderate > Loose.\n    # Weights are tuned to emphasize tighter fits.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.8 +\n        moderate_fit_scores * 0.5 +\n        loose_fit_scores * 0.2\n    )\n\n    # Add a small stochastic component for exploration.\n    # This helps in occasional selection of less optimal bins, potentially leading to better overall packing.\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements an improved priority function for the online Bin Packing Problem.\n    This version prioritizes tight fits, penalizes wasted space effectively,\n    and uses adaptive thresholds to better handle varying item and bin sizes.\n\n    The priority is calculated as follows:\n    1. Bins that cannot fit the item get a priority of 0.\n    2. For bins that can fit the item:\n       a. Perfect Fits (remaining capacity after packing is 0): Highest priority.\n       b. Tight Fits (remaining capacity after packing is small): High priority,\n          inversely proportional to the remaining capacity. This encourages filling\n          bins as much as possible.\n       c. Moderate Fits: Priority decreases as remaining capacity increases,\n          but at a slower rate than tight fits.\n       d. Wasteful Fits (remaining capacity after packing is large): Significantly\n          penalized to discourage using bins that would leave substantial empty space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates a higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define thresholds adaptively\n    epsilon = 1e-9\n    \n    # Threshold for \"tight\" fits: remaining space is less than the item size.\n    # This encourages using bins that are already somewhat filled.\n    tight_fit_threshold = item\n\n    # Threshold for \"wasteful\" fits: remaining space is significantly larger than item size.\n    # A good heuristic is to consider bins where the remaining space is more than, say,\n    # twice the item size, or a significant fraction of the *potential* remaining space\n    # if a large item were placed. Let's use a factor of the item size.\n    # We also consider the maximum possible remaining capacity for normalization.\n    max_potential_remaining = np.max(bins_remain_cap) - item if np.max(bins_remain_cap) >= item else 0\n    \n    # A threshold that is sensitive to item size and bin capacity.\n    # If bins are generally large, we might tolerate larger remaining gaps for non-wasteful bins.\n    # Let's use a blend: it's \"wasteful\" if remaining_after_fit is large relative to item size,\n    # OR if it's a large fraction of the *total* capacity.\n    # For simplicity and directness, we'll use a threshold relative to item size,\n    # but also consider how much space is left relative to the bin's *initial* capacity\n    # (which we don't have here). So, relying on remaining_after_fit is key.\n    # Let's consider `remaining_after_fit > C * item` and `remaining_after_fit > D * max_potential_remaining`.\n    # For this version, let's simplify the \"wasteful\" threshold to focus on the remaining space\n    # relative to the item size, aiming to avoid bins that are still mostly empty.\n    # A threshold like 3 * item size seems reasonable to start.\n    wasteful_threshold = 3.0 * item\n\n    # Calculate scores\n    scores = np.zeros_like(remaining_after_fit)\n\n    # 1. Perfect Fits: Highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    scores[perfect_mask] = 1000.0\n\n    # 2. Tight Fits: High priority, inversely proportional to remaining capacity\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_fit_threshold)\n    # Use a steep decay function like 1/(1+x) or 1/(1+x^2)\n    scores[tight_mask] = 50.0 / (1.0 + remaining_after_fit[tight_mask] * 5.0) # Scaled to give good range\n\n    # 3. Moderate Fits: Priority decreases with remaining capacity, but less steeply\n    moderate_mask = ~perfect_mask & ~tight_mask & (remaining_after_fit <= wasteful_threshold)\n    # A less steep decay, e.g., 1/(1+sqrt(x)) or 1/(1+x^0.7)\n    scores[moderate_mask] = 20.0 / (1.0 + np.sqrt(remaining_after_fit[moderate_mask]))\n\n    # 4. Wasteful Fits: Significantly penalized\n    wasteful_mask = (remaining_after_fit > wasteful_threshold)\n    # Penalize based on how much excess space is left.\n    # The penalty should be substantial to deter selection.\n    # We can use a linear penalty that starts at 0 at the threshold and increases.\n    # Penalty = P * (remaining_after_fit - wasteful_threshold) / (max_possible_remaining + epsilon)\n    # Normalize penalty by item size to keep it somewhat scale-invariant.\n    penalty_factor = 5.0 # Controls the magnitude of the penalty\n    scores[wasteful_mask] = 10.0 / (1.0 + remaining_after_fit[wasteful_mask] / item) # Start with a base score, then penalize\n    penalty = penalty_factor * (remaining_after_fit[wasteful_mask] - wasteful_threshold) / (item + epsilon)\n    scores[wasteful_mask] -= penalty\n\n    # Ensure scores are non-negative\n    scores[scores < 0] = 0\n\n    # Add a small random jitter for exploration to prevent all scores from being identical\n    # for multiple bins with similar fit characteristics.\n    exploration_factor = 0.05\n    jitter = np.random.rand(len(scores)) * exploration_factor * np.max(scores + epsilon)\n    final_scores = scores + jitter\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = final_scores\n\n    return priorities\n\n[Reflection]\nTune thresholds, decay functions, and penalty factors for better fit prioritization.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}