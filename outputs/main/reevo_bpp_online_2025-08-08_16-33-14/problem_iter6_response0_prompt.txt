{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements a refined priority function for online Bin Packing Problem,\n    incorporating a more nuanced approach to bin selection.\n\n    The function categorizes potential bins based on how tightly an item fits,\n    assigning scores that reflect desirability. It prioritizes bins that result\n    in minimal remaining capacity after packing, but with a dampening effect\n    for extremely tight fits that might be suboptimal in the long run.\n\n    Categories and scoring logic:\n    1. Perfect Fit: Remaining capacity is exactly zero. Highest priority.\n    2. Tight Fit: Remaining capacity is positive but small (e.g., less than or equal to the item size).\n                   Prioritized, with higher scores for smaller remaining capacities.\n    3. Good Fit: Remaining capacity is moderate. These bins are still useful,\n                  but less so than tight fits. Scores decrease as remaining capacity increases.\n    4. Loose Fit: Remaining capacity is large. Lowest priority among fitting bins,\n                  offering a minimal score to encourage exploration.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n        Bins that cannot fit the item will have a score of 0.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define scoring parameters and thresholds. These are heuristic and can be tuned.\n    epsilon = 1e-9  # For handling floating-point comparisons, especially for perfect fits.\n\n    # Thresholds for categorizing fits (relative to item size or a fixed value)\n    # A bin is a \"tight fit\" if remaining capacity is <= item size.\n    tight_threshold = item\n    # A bin is a \"good fit\" if remaining capacity is within a certain range,\n    # e.g., up to a multiple of the item size, but not excessively large.\n    # We might want to avoid bins that leave *too* much space, as they might be \"wasted\".\n    # Let's define a \"good\" range that isn't too large.\n    good_threshold_upper = item * 2.5  # Example: remaining capacity up to 2.5 times item size\n\n    # --- Scoring Logic ---\n    # We want to prioritize smaller remaining capacities (better fits).\n    # Use an inverse relationship, but introduce a damping factor for very small\n    # remaining capacities to avoid overly penalizing bins that are *almost* full\n    # but not quite, which might be slightly less optimal than a perfect fit but still good.\n\n    # Perfect Fit (remaining_after_fit is essentially 0)\n    perfect_fit_scores = np.where(remaining_after_fit < epsilon, 10.0, 0.0)\n\n    # Tight Fit (0 < remaining_after_fit <= tight_threshold)\n    # Prioritize bins that leave less residual space.\n    # The inverse of remaining_after_fit gives a higher score for smaller values.\n    # Add 1 to denominator to prevent division by zero and to give a boost.\n    tight_fit_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    tight_fit_scores = np.where(tight_fit_mask, 5.0 / (1.0 + remaining_after_fit), 0.0)\n\n    # Good Fit (tight_threshold < remaining_after_fit <= good_threshold_upper)\n    # These are still good fits, but less optimal than tight fits.\n    # The score should be lower than tight fits and decrease as remaining capacity increases.\n    good_fit_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold_upper)\n    # Slightly penalize larger remaining capacities within this \"good\" range.\n    good_fit_scores = np.where(good_fit_mask, 2.0 / (1.0 + remaining_after_fit * 0.5), 0.0) # Scale down impact\n\n    # Loose Fit (remaining_after_fit > good_threshold_upper)\n    # These bins have a lot of remaining space. Assign a low score.\n    # This encourages using these bins only when better options are not available.\n    loose_fit_mask = (remaining_after_fit > good_threshold_upper)\n    loose_fit_scores = np.where(loose_fit_mask, 0.5 / (1.0 + remaining_after_fit * 0.1), 0.0) # Minimal score\n\n\n    # Combine scores with weights. Weights reflect the priority order: Perfect > Tight > Good > Loose.\n    # These weights can be adjusted for different strategies.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.9 +  # Slightly reduce weight for tight fits compared to perfect\n        good_fit_scores * 0.6 +   # Moderate weight for good fits\n        loose_fit_scores * 0.3    # Low weight for loose fits\n    )\n\n    # --- Exploration Component ---\n    # Add a small random value to all fitting bins to introduce a stochastic element\n    # and prevent deterministic behavior which can sometimes lead to suboptimal choices.\n    # This can help break ties and explore alternative packing options.\n    exploration_factor = 0.15 # Increased exploration factor slightly\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n\n    priorities[can_fit_mask] = combined_scores + random_scores\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements a hybrid priority function for online Bin Packing Problem.\n    This version refines the scoring by categorizing fits:\n    1. Perfect Fit (zero remaining capacity).\n    2. Tight Fit (remaining capacity <= item size).\n    3. Good Fit (remaining capacity > item size but not excessively large).\n    4. Loose Fit (remaining capacity is very large).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define score components based on remaining capacity after fit\n    # We want to prioritize smaller remaining_after_fit.\n    # Add a small epsilon to avoid division by zero for perfect fits.\n    epsilon = 1e-9\n\n    # Scores for different fit categories\n    perfect_fit_scores = np.zeros_like(remaining_after_fit)\n    tight_fit_scores = np.zeros_like(remaining_after_fit)\n    good_fit_scores = np.zeros_like(remaining_after_fit)\n    loose_fit_scores = np.zeros_like(remaining_after_fit)\n\n    # Thresholds for 'good fit' and 'loose fit'\n    # Threshold 1: Maximum remaining capacity for a 'tight' fit (relative to item size)\n    tight_threshold = item\n    # Threshold 2: Maximum remaining capacity for a 'good' fit (relative to item size)\n    # This aims to leave a decent amount of space, e.g., up to 3 times the item size.\n    good_threshold = 3.0 * item\n\n    # Assign scores based on categories\n    # Perfect Fit: highest priority\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_fit_scores[perfect_mask] = 10.0\n\n    # Tight Fit: prioritize bins that leave little room but not zero\n    tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit <= tight_threshold)\n    tight_fit_scores[tight_mask] = 5.0 / (1.0 + remaining_after_fit[tight_mask]) # Scaled best-fit\n\n    # Good Fit: prioritize bins that leave a moderate amount of room\n    # This encourages leaving space for future items.\n    good_mask = (remaining_after_fit > tight_threshold) & (remaining_after_fit <= good_threshold)\n    # For good fits, we want remaining_after_fit to be as small as possible within this range.\n    # We can use a inverse relationship, but scaled differently.\n    good_fit_scores[good_mask] = 2.0 / (1.0 + remaining_after_fit[good_mask])\n\n    # Loose Fit: lowest priority among fitting bins, provide minimal boost for exploration\n    loose_mask = (remaining_after_fit > good_threshold)\n    loose_fit_scores[loose_mask] = 0.5 / (1.0 + remaining_after_fit[loose_mask])\n\n    # Combine scores. Weights are heuristic and can be tuned.\n    # Prioritize perfect > tight > good > loose.\n    combined_scores = (\n        perfect_fit_scores * 1.0 +\n        tight_fit_scores * 0.8 +\n        good_fit_scores * 0.5 +\n        loose_fit_scores * 0.2\n    )\n\n    # Add a small random component for exploration to all fitting bins\n    exploration_factor = 0.1\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Reflection]\nTune thresholds, weights, and exploration strategy for better bin packing.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}