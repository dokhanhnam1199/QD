{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements an improved priority function for online Bin Packing Problem,\n    incorporating a refined strategy for penalizing overly tight bins and\n    categorizing fits with adaptive scoring.\n\n    The strategy aims to:\n    1. Favor bins that leave minimal remaining capacity (tight fit), but\n       avoid bins that become *too* full after the item is placed.\n    2. Categorize fits into 'perfect', 'tight', 'good', and 'loose' with\n       decreasing priority.\n    3. Use adaptive scoring that scales with the item size and remaining capacity,\n       while also introducing a penalty for \"almost perfect\" fits that leave\n       very little room.\n    4. Include a small stochastic element for exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_caps - item\n\n    # Define scoring parameters and thresholds\n    epsilon = 1e-9  # For perfect fits and to avoid division by zero\n\n    # Thresholds: these are relative to the item size.\n    # A bin is considered \"tight\" if remaining capacity after fitting is\n    # between epsilon and ~1 * item_size.\n    # A bin is \"good\" if remaining capacity is between ~1 * item_size and ~3 * item_size.\n    # Bins with capacity > 3 * item_size are \"loose\".\n    tight_upper_bound_factor = 1.0\n    good_upper_bound_factor = 3.0\n\n    # Scoring logic:\n    # We want smaller remaining_after_fit to be better.\n    # A penalty is introduced for extremely small remaining capacities (overly tight).\n    # The base score will be inversely proportional to remaining_after_fit,\n    # with a penalty term for very small remaining capacities.\n\n    # Calculate a base score that favors smaller remaining capacity.\n    # Add 1 to denominator to avoid division by zero and to ensure a base score.\n    base_scores = 1.0 / (1.0 + remaining_after_fit)\n\n    # Penalty for being \"too tight\":\n    # If remaining_after_fit is very small (e.g., < epsilon * some_factor),\n    # we might want to reduce its priority.\n    # Let's define \"overly tight\" as remaining capacity < item_size / 5.\n    overly_tight_threshold = item / 5.0\n    overly_tight_mask = (remaining_after_fit > epsilon) & (remaining_after_fit < overly_tight_threshold)\n\n    # Assign higher scores to categories that fit well, but penalize overly tight fits.\n    # Perfect Fit: highest score\n    perfect_mask = (remaining_after_fit < epsilon)\n    perfect_scores = np.full_like(remaining_after_fit, 10.0)\n\n    # Tight Fit: prioritize but not as much as perfect.\n    tight_mask = (remaining_after_fit >= epsilon) & (remaining_after_fit <= tight_upper_bound_factor * item)\n    # Use inverse relationship with a penalty for being too tight\n    tight_scores = base_scores[tight_mask]\n    tight_scores[remaining_after_fit[tight_mask] < overly_tight_threshold] *= 0.5 # Penalty for too tight\n\n    # Good Fit: Moderate priority, still favors less remaining capacity\n    good_mask = (remaining_after_fit > tight_upper_bound_factor * item) & (remaining_after_fit <= good_upper_bound_factor * item)\n    good_scores = base_scores[good_mask] * 0.7 # Lower weight for good fits\n\n    # Loose Fit: Lowest priority among fitting bins\n    loose_mask = (remaining_after_fit > good_upper_bound_factor * item)\n    loose_scores = base_scores[loose_mask] * 0.3 # Even lower weight\n\n    # Combine scores for fitting bins\n    combined_scores = np.zeros_like(remaining_after_fit)\n\n    combined_scores[perfect_mask] = perfect_scores[perfect_mask]\n    \n    # Assign to the correct indices within the fitting_bins_scores\n    # Using indices to map back to the original fitting_bins_caps\n    fitting_indices = np.arange(len(fitting_bins_caps))\n\n    indices_tight = fitting_indices[tight_mask]\n    combined_scores[indices_tight] = tight_scores\n\n    indices_good = fitting_indices[good_mask]\n    combined_scores[indices_good] = good_scores\n\n    indices_loose = fitting_indices[loose_mask]\n    combined_scores[indices_loose] = loose_scores\n\n    # Add a small random component for exploration to all fitting bins\n    exploration_factor = 0.05\n    random_scores = np.random.rand(len(fitting_bins_caps)) * exploration_factor\n    combined_scores += random_scores\n\n    # Normalize scores to be within a reasonable range, e.g., 0 to 1\n    # This can help in comparing scores across different item sizes if needed.\n    if combined_scores.size > 0:\n        min_score = np.min(combined_scores)\n        max_score = np.max(combined_scores)\n        if max_score - min_score > epsilon:\n            combined_scores = (combined_scores - min_score) / (max_score - min_score)\n        else:\n            combined_scores = np.ones_like(combined_scores) * 0.5 # Handle case where all scores are same\n\n    # Assign the calculated scores to the corresponding bins in the original priority array\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined hybrid strategy.\n\n    This strategy refines the 'Best Fit' and 'Almost Full' criteria.\n    It prioritizes bins that have a remaining capacity closest to the item size (Best Fit).\n    It also favors bins that are \"tightly packed\" after the item is placed, meaning\n    the remaining capacity is small. A small additive factor is used to provide\n    higher priority to bins that become exactly full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # If no bin can fit, return scores that reflect no valid placement\n        return scores\n\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Criterion 1: Best Fit - prioritize bins that will have the least remaining capacity\n    # after the item is placed. This means minimizing (bins_remain_cap - item).\n    # Higher score for smaller (bins_remain_cap - item).\n    # To ensure bins that become exactly full (remaining capacity = 0) get the highest\n    # priority among fitting bins, we can use a score that is the negative of the\n    # remaining capacity after fitting.\n    # Score = -(remaining_capacity_after_fit)\n    # This naturally gives 0 for exact fits, and negative scores for bins with residual space.\n    remaining_after_fit = fitting_bins_caps - item\n    best_fit_priority = -remaining_after_fit\n\n    # Criterion 2: Tight Packing - Prioritize bins that are already quite full,\n    # such that placing the item makes them *even more* tightly packed.\n    # This can be thought of as favoring bins where the current remaining capacity\n    # is only slightly larger than the item size.\n    # A simpler interpretation aligning with \"closeness to full\" after fit:\n    # We already captured this with Best Fit.\n    # Let's refine: prioritize bins that, after placing the item, leave very little space.\n    # The `best_fit_priority` already does this.\n\n    # Let's introduce a small bonus for exact fits to ensure they are strongly preferred.\n    # If remaining_after_fit is 0, the best_fit_priority is 0.\n    # We can add a small epsilon to it for exact fits.\n    # A small epsilon added to the \"best fit\" score for exact fits.\n    # This ensures exact fits are slightly preferred over bins that leave a tiny bit of space.\n    epsilon_for_exact_fit = 1e-6\n    tight_packing_priority = best_fit_priority + (best_fit_priority == 0) * epsilon_for_exact_fit\n\n    # Combine criteria: Primarily Best Fit, with a slight boost for exact fits.\n    # Since `best_fit_priority` already sorts correctly (higher for smaller remaining),\n    # and exact fits have the highest score (0), the `tight_packing_priority`\n    # directly reflects the desired ordering.\n\n    # Assign the computed priorities to the fitting bins\n    scores[can_fit_mask] = tight_packing_priority\n\n    # Non-fitting bins remain at -np.inf, ensuring they are never chosen if a fit exists.\n\n    return scores\n\n[Reflection]\nPrioritize tight fits, penalize over-full bins, and offer small bonuses for exact fits.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}