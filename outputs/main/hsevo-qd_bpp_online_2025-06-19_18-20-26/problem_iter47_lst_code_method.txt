{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing, incorporating dynamic adaptation,\n    multi-factor integration, and problem state awareness. It addresses limitations in prior\n    versions by dynamically adjusting penalties and bonuses based on overall bin utilization,\n    item size relative to bin capacity, and the resulting waste.  This version includes a mechanism for diversification to escape local optima and an adaptive bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    overall_utilization = 1 - np.mean(bins_remain_cap / max_bin_cap)\n\n    # Best-Fit with Adaptive Sensitivity\n    size_diff = bins_remain_cap - item\n    best_fit_scale = 1.2 + 0.8 * overall_utilization  # Dynamically adjust based on utilization\n    priorities[valid_bins] += best_fit_scale / (size_diff[valid_bins] + 0.0001)**1.5\n\n    # Waste Minimization with Dynamic Penalties\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-7 * waste_ratio)\n    large_waste_penalty = np.exp(-4 / waste_ratio) #Inverted to give exponentially decaying penalty for large waste\n    waste_penalty_weight = 0.6 + 0.4 * overall_utilization  # Increase penalty with higher utilization\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * waste_penalty_weight\n\n    # Bin Balancing with Adaptive Adjustment\n    utilization = 1 - (bins_remain_cap / max_bin_cap)\n    extreme_utilization_penalty = np.zeros_like(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 14 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus with Dynamic Scaling based on item size and overall utilization\n    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / max_bin_cap - 0.1))\n    fullness_bonus_scale = (1 - overall_utilization) * (item / max_bin_cap)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.5 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.8 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    else:\n        priorities[valid_bins] += 0.3 * fullness_bonus[valid_bins] * fullness_bonus_scale\n\n    # Bin Activation Bonus for Large Items with Utilization Awareness\n    if item > 0.6 * max_bin_cap:\n        empty_bin_bonus = np.exp(-2 * utilization)\n        #Scale activation bonus to be stronger if bins are empty\n        activation_bonus_scale = 1.5 + 2*(1-overall_utilization)\n        priorities[valid_bins] += activation_bonus_scale * empty_bin_bonus[valid_bins]\n\n    #Diversification Heuristic (Escape Local Optima)\n    if np.random.rand() < 0.05: #5% chance of diversifying\n        priorities[valid_bins] += np.random.normal(0, 0.1, np.sum(valid_bins)) #Add small random noise\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing, incorporating dynamic adaptation,\n    multi-factor integration, and problem state awareness. It addresses limitations in prior\n    versions by dynamically adjusting penalties and bonuses based on overall bin utilization,\n    item size relative to bin capacity, and the resulting waste.  This version includes a mechanism for diversification to escape local optima and an adaptive bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    overall_utilization = 1 - np.mean(bins_remain_cap / max_bin_cap)\n\n    # Best-Fit with Adaptive Sensitivity\n    size_diff = bins_remain_cap - item\n    best_fit_scale = 1.2 + 0.8 * overall_utilization  # Dynamically adjust based on utilization\n    priorities[valid_bins] += best_fit_scale / (size_diff[valid_bins] + 0.0001)**1.5\n\n    # Waste Minimization with Dynamic Penalties\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-7 * waste_ratio)\n    large_waste_penalty = np.exp(-4 / waste_ratio) #Inverted to give exponentially decaying penalty for large waste\n    waste_penalty_weight = 0.6 + 0.4 * overall_utilization  # Increase penalty with higher utilization\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * waste_penalty_weight\n\n    # Bin Balancing with Adaptive Adjustment\n    utilization = 1 - (bins_remain_cap / max_bin_cap)\n    extreme_utilization_penalty = np.zeros_like(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 14 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus with Dynamic Scaling based on item size and overall utilization\n    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / max_bin_cap - 0.1))\n    fullness_bonus_scale = (1 - overall_utilization) * (item / max_bin_cap)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.5 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.8 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    else:\n        priorities[valid_bins] += 0.3 * fullness_bonus[valid_bins] * fullness_bonus_scale\n\n    # Bin Activation Bonus for Large Items with Utilization Awareness\n    if item > 0.6 * max_bin_cap:\n        empty_bin_bonus = np.exp(-2 * utilization)\n        #Scale activation bonus to be stronger if bins are empty\n        activation_bonus_scale = 1.5 + 2*(1-overall_utilization)\n        priorities[valid_bins] += activation_bonus_scale * empty_bin_bonus[valid_bins]\n\n    #Diversification Heuristic (Escape Local Optima)\n    if np.random.rand() < 0.05: #5% chance of diversifying\n        priorities[valid_bins] += np.random.normal(0, 0.1, np.sum(valid_bins)) #Add small random noise\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing, incorporating dynamic adaptation,\n    multi-factor integration, and problem state awareness. It addresses limitations in prior\n    versions by dynamically adjusting penalties and bonuses based on overall bin utilization,\n    item size relative to bin capacity, and the resulting waste.  This version includes a mechanism for diversification to escape local optima and an adaptive bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    overall_utilization = 1 - np.mean(bins_remain_cap / max_bin_cap)\n\n    # Best-Fit with Adaptive Sensitivity\n    size_diff = bins_remain_cap - item\n    best_fit_scale = 1.2 + 0.8 * overall_utilization  # Dynamically adjust based on utilization\n    priorities[valid_bins] += best_fit_scale / (size_diff[valid_bins] + 0.0001)**1.5\n\n    # Waste Minimization with Dynamic Penalties\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-7 * waste_ratio)\n    large_waste_penalty = np.exp(-4 / waste_ratio) #Inverted to give exponentially decaying penalty for large waste\n    waste_penalty_weight = 0.6 + 0.4 * overall_utilization  # Increase penalty with higher utilization\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * waste_penalty_weight\n\n    # Bin Balancing with Adaptive Adjustment\n    utilization = 1 - (bins_remain_cap / max_bin_cap)\n    extreme_utilization_penalty = np.zeros_like(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 14 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus with Dynamic Scaling based on item size and overall utilization\n    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / max_bin_cap - 0.1))\n    fullness_bonus_scale = (1 - overall_utilization) * (item / max_bin_cap)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.5 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.8 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    else:\n        priorities[valid_bins] += 0.3 * fullness_bonus[valid_bins] * fullness_bonus_scale\n\n    # Bin Activation Bonus for Large Items with Utilization Awareness\n    if item > 0.6 * max_bin_cap:\n        empty_bin_bonus = np.exp(-2 * utilization)\n        #Scale activation bonus to be stronger if bins are empty\n        activation_bonus_scale = 1.5 + 2*(1-overall_utilization)\n        priorities[valid_bins] += activation_bonus_scale * empty_bin_bonus[valid_bins]\n\n    #Diversification Heuristic (Escape Local Optima)\n    if np.random.rand() < 0.05: #5% chance of diversifying\n        priorities[valid_bins] += np.random.normal(0, 0.1, np.sum(valid_bins)) #Add small random noise\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n\n    This version incorporates adaptive parameter tuning and dynamic waste\n    thresholding for improved performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization: Discourage very small waste, adaptive threshold\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Dynamically adjust the small waste penalty strength based on item size.\n    waste_penalty_strength = 10 + 5 * item  # Larger items, stronger penalty for small waste\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.  Adaptive range.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        #Adaptive balancing: the closer to 0.5, the stronger the penalty\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n    fullness_threshold = 0.1  # Bins within 10% of being full receive bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    # Edge Case Handling: If all bins are nearly full, prioritize the one with the most remaining capacity\n    if np.all(bins_remain_cap[valid_bins] <= 0.1 * np.max(bins_remain_cap)):\n        priorities[valid_bins] += 10 * bins_remain_cap[valid_bins] # Prioritize largest remaining\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n\n    This version incorporates adaptive parameter tuning and dynamic waste\n    thresholding for improved performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization: Discourage very small waste, adaptive threshold\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Dynamically adjust the small waste penalty strength based on item size.\n    waste_penalty_strength = 10 + 5 * item  # Larger items, stronger penalty for small waste\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.  Adaptive range.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        #Adaptive balancing: the closer to 0.5, the stronger the penalty\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n    fullness_threshold = 0.1  # Bins within 10% of being full receive bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    # Edge Case Handling: If all bins are nearly full, prioritize the one with the most remaining capacity\n    if np.all(bins_remain_cap[valid_bins] <= 0.1 * np.max(bins_remain_cap)):\n        priorities[valid_bins] += 10 * bins_remain_cap[valid_bins] # Prioritize largest remaining\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, adaptive bin balancing, and fullness bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization)\n    \n    # Adaptive Waste Penalty Adjustment\n    if item > 0.5: # large item\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, \n                 size_diff_epsilon: float = 0.0004973923711338349,\n                 waste_penalty_base: float = 5.468478104408493,\n                 waste_penalty_multiplier: float = 13.38944774829674,\n                 extreme_utilization_threshold_low: float = 0.33963284414439665,\n                 extreme_utilization_threshold_high: float = 0.8362854997802416,\n                 extreme_utilization_penalty_low_multiplier: float = 10.315888762295863,\n                 extreme_utilization_penalty_high_multiplier: float = 11.796404081271609,\n                 extreme_utilization_penalty_mid_multiplier: float = 13.98241267866572,\n                 fullness_bonus_exponent: float = 3.181974175037097,\n                 bonus_strength_base: float = 2.3328187802706704,\n                 bonus_strength_multiplier: float = 4.443975905618798) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, waste minimization, bin balancing, and adaptive weights based on problem state.\n    Prioritizes bins dynamically for effective online bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive Best-Fit\n    size_diff = bins_remain_cap - item\n    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)\n    granularity_factor = np.mean(capacity_ratio)\n    priorities[valid_bins] += (1 / (size_diff[valid_bins] + size_diff_epsilon)**(granularity_factor + 1))\n\n    # Dynamic Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]\n    item_size_factor = item / np.max(bins_remain_cap)\n    waste_penalty_strength = waste_penalty_base + waste_penalty_multiplier * item_size_factor\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    if overall_utilization < extreme_utilization_threshold_low:\n        extreme_utilization_penalty = extreme_utilization_penalty_low_multiplier * np.abs(utilization - 0.2)\n    elif overall_utilization > extreme_utilization_threshold_high:\n        extreme_utilization_penalty = extreme_utilization_penalty_high_multiplier * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = extreme_utilization_penalty_mid_multiplier * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_level = 1 - capacity_ratio\n    fullness_bonus = np.exp(-fullness_bonus_exponent * np.abs(fullness_level - 1))\n    bonus_strength = bonus_strength_base + bonus_strength_multiplier * item_size_factor\n    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, \n                 size_diff_epsilon: float = 0.0004973923711338349,\n                 waste_penalty_base: float = 5.468478104408493,\n                 waste_penalty_multiplier: float = 13.38944774829674,\n                 extreme_utilization_threshold_low: float = 0.33963284414439665,\n                 extreme_utilization_threshold_high: float = 0.8362854997802416,\n                 extreme_utilization_penalty_low_multiplier: float = 10.315888762295863,\n                 extreme_utilization_penalty_high_multiplier: float = 11.796404081271609,\n                 extreme_utilization_penalty_mid_multiplier: float = 13.98241267866572,\n                 fullness_bonus_exponent: float = 3.181974175037097,\n                 bonus_strength_base: float = 2.3328187802706704,\n                 bonus_strength_multiplier: float = 4.443975905618798) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, waste minimization, bin balancing, and adaptive weights based on problem state.\n    Prioritizes bins dynamically for effective online bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive Best-Fit\n    size_diff = bins_remain_cap - item\n    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)\n    granularity_factor = np.mean(capacity_ratio)\n    priorities[valid_bins] += (1 / (size_diff[valid_bins] + size_diff_epsilon)**(granularity_factor + 1))\n\n    # Dynamic Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]\n    item_size_factor = item / np.max(bins_remain_cap)\n    waste_penalty_strength = waste_penalty_base + waste_penalty_multiplier * item_size_factor\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    if overall_utilization < extreme_utilization_threshold_low:\n        extreme_utilization_penalty = extreme_utilization_penalty_low_multiplier * np.abs(utilization - 0.2)\n    elif overall_utilization > extreme_utilization_threshold_high:\n        extreme_utilization_penalty = extreme_utilization_penalty_high_multiplier * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = extreme_utilization_penalty_mid_multiplier * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_level = 1 - capacity_ratio\n    fullness_bonus = np.exp(-fullness_bonus_exponent * np.abs(fullness_level - 1))\n    bonus_strength = bonus_strength_base + bonus_strength_multiplier * item_size_factor\n    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An adaptive priority function that dynamically adjusts its strategy based on\n    the item size relative to bin capacities and the overall bin utilization.\n    It prioritizes bins considering best-fit, waste minimization, bin balancing,\n    and a dynamic bonus for almost-full bins, with adaptive weight adjustments.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Overall utilization of the bins\n    total_capacity = np.sum(bins_remain_cap) + np.sum(bins_remain_cap[~valid_bins] + item) * np.sum(bins_remain_cap >= item)\n    overall_utilization = 1 - np.sum(bins_remain_cap) / total_capacity if total_capacity > 0 else 0\n\n    # Item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.sum(bins_remain_cap > 0) > 0 else 1 # Avoid zero division\n    item_size_ratio = item / avg_bin_capacity\n\n    # Best-Fit component with adaptive scaling\n    size_diff = bins_remain_cap - item\n    best_fit_priority = 1.0 / (size_diff[valid_bins] + 0.0001)**2\n    priorities[valid_bins] += best_fit_priority * (1 + overall_utilization) #Scale by fill level\n\n    # Waste Minimization: Discourage very small waste dynamically\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty * (1 - overall_utilization) #Scale by fill level\n\n    # Bin Balancing using utilization, adaptively adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins] * (1 + item_size_ratio) #Scale by item size\n\n    # Adaptive bonus for bins close to full, with dynamic weighting\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n     # Item size adjustment: Small items get more bonus\n    item_size_bonus_multiplier = 1 + (1 - item_size_ratio)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins] * item_size_bonus_multiplier\n\n    # Edge case handling: If no bin is suitable, slightly relax best-fit preference\n    if np.all(priorities == -np.inf):\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        valid_bins = bins_remain_cap > 0\n        if np.any(valid_bins):\n            size_diff = bins_remain_cap - item\n            size_diff[size_diff < 0] = np.inf  # Consider the overflow when calculating the best-fit\n            priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**0.5 # Relaxed exponent\n        else: # Very rare case: All bins are full\n            priorities = np.ones_like(bins_remain_cap) #All bins have equal priority\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that combines best-fit,\n    waste management, bin balancing, and learning components with adaptive\n    weighting based on real-time feedback and historical performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit Component with adaptive granularity\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # 2. Waste Minimization with dynamic penalty adjustment\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-15 * remaining_after_fit * item) # Increased sensitivity\n\n    # Adaptive penalty based on waste ratio and item size\n    penalty_weight = 1.0\n    if item > 0.5:  # Penalize small waste more for large items\n        penalty_weight = 2.0\n    elif item < 0.2: # Relax the small waste penalty for small items\n        penalty_weight = 0.5\n\n    priorities[valid_bins] -= penalty_weight * small_waste_penalty\n\n    # 3. Bin Balancing using utilization and overall utilization with adaptive target\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic target utilization based on overall utilization\n    target_utilization = 0.5\n    if overall_utilization < 0.3:\n        target_utilization = 0.2\n    elif overall_utilization > 0.7:\n        target_utilization = 0.8\n\n    extreme_utilization_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive component with dynamic bonus based on remaining capacity\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_weight = 1.0\n\n    # Adjust bonus weight based on overall utilization and item size\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n\n    # 5. Item-Size-Aware Adjustment: Favor bins that tightly fit larger items\n    if item > 0.6:\n      tight_fit_bonus = np.exp(-20*(bins_remain_cap[valid_bins]-item)**2)\n      priorities[valid_bins] += 0.7 * tight_fit_bonus # Encourage tight fits\n\n    # 6. Normalize priorities to avoid domination by any single factor\n    max_priority = np.max(priorities[np.isfinite(priorities)])\n    min_priority = np.min(priorities[np.isfinite(priorities)])\n\n    if max_priority > min_priority:\n        priorities[np.isfinite(priorities)] = (priorities[np.isfinite(priorities)] - min_priority) / (max_priority - min_priority)\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A refined priority function that focuses on dynamically adjusting\n    the best-fit and waste minimization aspects based on overall\n    bin utilization. It also adds a mechanism to occasionally open new bins\n    even when existing ones have space, promoting exploration and potentially\n    avoiding local optima.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf  # Invalidate bins that can't fit the item\n\n    # Best-Fit component: Prioritize bins with minimal remaining space\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001) #avoid division by zero\n\n    # Waste Minimization: Penalize small waste, dynamically adjusted\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    overall_utilization = np.mean(1 - (bins_remain_cap / np.max(bins_remain_cap))) if bins_remain_cap.size > 0 else 0\n    waste_penalty_factor = 5 + 10 * overall_utilization  # Adjust penalty based on fill level\n    small_waste_penalty = np.exp(-waste_penalty_factor * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Dynamic Bin Balancing: Adjust encouragement/discouragement of filling\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    bin_balancing_factor = 10  # Adjust the strength of bin balancing\n\n    if overall_utilization < 0.4:\n        extreme_utilization_penalty = bin_balancing_factor * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = bin_balancing_factor * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = bin_balancing_factor * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Exploration: Introduce a small probability of using a new bin\n    # even if existing bins have space.\n    exploration_probability = 0.01  #tune\n    if np.random.rand() < exploration_probability:\n        priorities[:] = -np.inf\n        #find the index of smallest remaining capacity.\n        smallest_cap_index = np.argmin(bins_remain_cap)\n        priorities[smallest_cap_index] = 1 #set only it to valid\n        valid_bins[smallest_cap_index] = True #need this to avoid runtime error\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                size_diff_epsilon: float = 0.0004976631192414565,\n                small_waste_penalty_factor: float = 13.759620087105052,\n                extreme_utilization_penalty_factor: float = 10.96255884116071,\n                target_utilization: float = 0.2781292500038949) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        size_diff_epsilon: A small constant added to size_diff to avoid division by zero.\n        small_waste_penalty_factor: Factor to control the strength of the small waste penalty.\n        extreme_utilization_penalty_factor: Factor to control the strength of the extreme utilization penalty.\n        target_utilization: The target utilization level (fraction full) for balancing.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + size_diff_epsilon)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-small_waste_penalty_factor * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = extreme_utilization_penalty_factor * np.abs(utilization - target_utilization) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics, with refinements over v1:\n\n    1. **Best Fit Decreasing (BFD) Emphasis:**  Prioritizes bins that offer the *tightest* fit\n       for the current item, more aggressively than v1. Aims for optimal space utilization\n       in each bin, reducing fragmentation.\n\n    2.  **Waste Minimization (Adaptive):**  Penalizes small waste, but the penalty *scales*\n        with item size.  Large items creating small waste are penalized more heavily, as\n        that waste is harder to fill later.\n\n    3.  **Bin Balancing (Dynamic):**  Adjusts the utilization penalty based on the *overall*\n        fill level of all bins. If bins are generally empty, encourages filling them more;\n        if bins are generally full, focuses on avoiding small waste.\n\n    4. **Penalty for Over-Utilized Bins:** Add a bigger penalty if bins are almost full before placing the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Best Fit Decreasing Emphasis\n    size_diff = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Prioritize tight fits *much* more strongly than v1.\n    priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**2  # Squaring makes the difference more pronounced\n\n    # 2. Waste Minimization (Adaptive)\n    remaining_after_fit = bins_remain_cap - item\n    # Penalty scales with item size. Larger item = greater waste penalty\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Balancing (Dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Fraction full\n    overall_utilization = np.mean(utilization)  # Average fill level of all bins.\n\n    # Adjust penalty based on overall utilization.\n    if overall_utilization < 0.3: # If bins are generally empty.\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2) # Aim for 20% utilization.\n    elif overall_utilization > 0.7: # If bins are generally full.\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) # Aim for 80% utilization and avoid small waste\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Default penalty, same as v1.\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Penalty for Over-Utilized Bins:\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap) # Remaining cap is less than 10% of max cap\n    priorities[almost_full & valid_bins] -= 20 # Large penalty for almost full bins.\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function that adapts to the problem state by\n    analyzing bin capacity distribution and item size relative to bin sizes.\n    It uses a multi-faceted approach combining best-fit, waste minimization,\n    and bin balancing with dynamically adjusted weights.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adaptive Granularity:\n    #   - Emphasize finer granularity when bins are mostly empty; coarser when mostly full.\n    size_diff = bins_remain_cap - item\n    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)\n    granularity_factor = np.mean(capacity_ratio)  # Dynamic granularity adjustment\n    priorities[valid_bins] += (1 / (size_diff[valid_bins] + 0.0001)**(granularity_factor + 1))\n\n    # 2. Dynamic Waste Minimization:\n    #   - Adjust the small waste penalty based on item size and remaining capacity.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]\n    item_size_factor = item / np.max(bins_remain_cap)  # Normalize item size\n\n    waste_penalty_strength = 5 + 10 * item_size_factor  # Stronger penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # 3. Bin Balancing with Capacity Distribution Awareness:\n    #   - Instead of a single overall utilization, consider the distribution of bin capacities.\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    capacity_std = np.std(bins_remain_cap)  # Measure capacity variance\n    capacity_mean = np.mean(bins_remain_cap)\n\n    #   - Adjust balancing based on capacity distribution.\n    if capacity_std < 0.1 * capacity_mean:  # Bins are relatively uniform\n        balancing_strength = 10  # Strong balancing\n    else:\n        balancing_strength = 5  # Moderate balancing\n\n    #   - More penalty for bins that are too full or empty\n    extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive Fullness Bonus:\n    #   - Bonus for bins that are close to full, adjusted based on remaining capacity.\n    fullness_level = 1 - capacity_ratio\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Close to full = high bonus\n    bonus_strength = 1 + 5 * item_size_factor  # Larger items, higher bonus\n\n    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))\n\n    # 5. Edge Case Handling:  Favor bins close to full if item is large relative to available space\n    large_item_threshold = 0.75  # Item size relative to bin capacity\n\n    if item_size_factor > large_item_threshold:\n        almost_full_bins = bins_remain_cap >= item\n        almost_full_bins = np.logical_and(almost_full_bins, bins_remain_cap < (item + 0.1 * np.max(bins_remain_cap)) )\n        priorities[almost_full_bins] += 10 # Strong encouragement for nearly full bins to take large items\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + 0.0001)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that adapts based on\n    bin fill levels, item sizes, and waste characteristics. It aims to\n    balance best-fit, waste minimization, and bin utilization, while\n    dynamically adjusting parameters based on problem state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # --- Best-Fit Component with Size-Aware Adjustment ---\n    size_diff = bins_remain_cap - item\n    # Normalize size difference by item size for relative fit\n    normalized_size_diff = size_diff / item\n    priorities[valid_bins] += 1.0 / (normalized_size_diff[valid_bins]**2 + 0.0001)\n\n\n    # --- Waste Minimization with Dynamic Waste Threshold ---\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Adaptive waste threshold based on item size (e.g., no waste > item/2)\n    waste_threshold = item / 2.0\n    waste_penalty_factor = 5.0  # Adjust penalty strength\n    waste_penalty = np.where(remaining_after_fit > 0, np.exp(waste_penalty_factor * (remaining_after_fit - waste_threshold)), 0)\n    priorities[valid_bins] -= waste_penalty\n\n    # --- Bin Balancing and Utilization-Based Adjustment ---\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic bin balancing based on overall utilization\n    utilization_penalty_factor = 10.0  # Adjust penalty strength\n\n    if overall_utilization < 0.4:\n        # Encourage filling bins if overall utilization is low\n        target_utilization = 0.6\n    elif overall_utilization > 0.6:\n        # Discourage filling if bins are already full\n        target_utilization = 0.4\n    else:\n        target_utilization = 0.5\n\n    utilization_penalty = utilization_penalty_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # --- Item-Size-Aware Fullness Bonus ---\n    fullness_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Closer to full = higher bonus\n\n    # Adjust bonus based on item size and overall utilization\n    bonus_weight = (1 - overall_utilization) * (item / np.max(bins_remain_cap))  # Larger items get larger weight\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that adapts based on\n    bin fill levels, item sizes, and waste characteristics. It aims to\n    balance best-fit, waste minimization, and bin utilization, while\n    dynamically adjusting parameters based on problem state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # --- Best-Fit Component with Size-Aware Adjustment ---\n    size_diff = bins_remain_cap - item\n    # Normalize size difference by item size for relative fit\n    normalized_size_diff = size_diff / item\n    priorities[valid_bins] += 1.0 / (normalized_size_diff[valid_bins]**2 + 0.0001)\n\n\n    # --- Waste Minimization with Dynamic Waste Threshold ---\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Adaptive waste threshold based on item size (e.g., no waste > item/2)\n    waste_threshold = item / 2.0\n    waste_penalty_factor = 5.0  # Adjust penalty strength\n    waste_penalty = np.where(remaining_after_fit > 0, np.exp(waste_penalty_factor * (remaining_after_fit - waste_threshold)), 0)\n    priorities[valid_bins] -= waste_penalty\n\n    # --- Bin Balancing and Utilization-Based Adjustment ---\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic bin balancing based on overall utilization\n    utilization_penalty_factor = 10.0  # Adjust penalty strength\n\n    if overall_utilization < 0.4:\n        # Encourage filling bins if overall utilization is low\n        target_utilization = 0.6\n    elif overall_utilization > 0.6:\n        # Discourage filling if bins are already full\n        target_utilization = 0.4\n    else:\n        target_utilization = 0.5\n\n    utilization_penalty = utilization_penalty_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # --- Item-Size-Aware Fullness Bonus ---\n    fullness_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Closer to full = higher bonus\n\n    # Adjust bonus based on item size and overall utilization\n    bonus_weight = (1 - overall_utilization) * (item / np.max(bins_remain_cap))  # Larger items get larger weight\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A refined priority function for online bin packing, incorporating dynamic\n    weighting based on fill levels, waste minimization, and bin balancing,\n    with enhancements for robustness and adaptability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adjusted Sensitivity:\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.001)**1.5 # Reduced exponent sensitivity\n\n    # 2. Dynamic Waste Minimization:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / np.max(bins_remain_cap)\n    waste_penalty = np.exp(5 * (waste_ratio - 0.25))  # Peak penalty around 25% waste\n    priorities[valid_bins] -= waste_penalty\n\n    # 3. Enhanced Bin Balancing with Adaptive Targets:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    target_utilization = 0.6  # Start with a moderate target\n\n    # Adjust the target utilization based on overall fill level:\n    if overall_utilization < 0.4:\n        target_utilization = 0.8  # Encourage higher filling if bins are sparse\n    elif overall_utilization > 0.8:\n        target_utilization = 0.3 # Keep adding new bins if we already have a lot of bins filled\n\n    balance_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= balance_penalty[valid_bins]\n    # 4. Adaptive Fullness Bonus with Sigmoid Weighting\n    fullness_level = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Max bonus for nearly full bins\n\n    # Sigmoid function to dynamically scale the bonus\n    sigmoid_weight = 1 / (1 + np.exp(10 * (overall_utilization - 0.5))) #sharp transition around 0.5\n    priorities[valid_bins] += 2 * sigmoid_weight * fullness_bonus[valid_bins]\n\n    # 5. Add a small randomization to break ties\n    priorities[valid_bins] += np.random.normal(0, 0.001, size=np.sum(valid_bins))\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines FFD approximation, waste minimization, and capacity ratio.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    # FFD Approximation + Capacity Ratio\n    ratios = item / bins_remain_cap\n    priorities[valid_bins] = -np.log(ratios[valid_bins]) / (np.abs(bins_remain_cap[valid_bins] - item) + 0.0001) #Higher priority to close size\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}