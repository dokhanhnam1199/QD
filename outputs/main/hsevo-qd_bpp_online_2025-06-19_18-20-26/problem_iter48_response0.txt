```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An enhanced priority function for online bin packing, incorporating dynamic adaptation,
    multi-factor integration, and problem state awareness. This version builds upon priority_v1
    by introducing adaptive learning rates for different factors, a global bin utilization target,
    and a more sophisticated diversification strategy based on the current solution quality.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    max_bin_cap = np.max(bins_remain_cap)
    overall_utilization = 1 - np.mean(bins_remain_cap / max_bin_cap)
    num_bins = len(bins_remain_cap)

    # Adaptive Learning Rates (initialized, will be updated)
    best_fit_weight = 0.5
    waste_penalty_weight = 0.3
    bin_balancing_weight = 0.2
    fullness_bonus_weight = 0.4
    activation_bonus_weight = 0.6
    diversification_rate = 0.05


    # Best-Fit with Adaptive Sensitivity
    size_diff = bins_remain_cap - item
    best_fit_scale = 1.2 + 0.8 * overall_utilization  # Dynamically adjust based on utilization
    priorities[valid_bins] += best_fit_weight * best_fit_scale / (size_diff[valid_bins] + 0.0001)**1.5

    # Waste Minimization with Dynamic Penalties
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / (item + 0.0001)
    small_waste_penalty = np.exp(-7 * waste_ratio)
    large_waste_penalty = np.exp(-4 / waste_ratio) #Inverted to give exponentially decaying penalty for large waste
    priorities[valid_bins] -= waste_penalty_weight * (small_waste_penalty + large_waste_penalty) * (0.6 + 0.4 * overall_utilization)

    # Bin Balancing with Adaptive Adjustment
    utilization = 1 - (bins_remain_cap / max_bin_cap)
    extreme_utilization_penalty = np.zeros_like(utilization)

    if overall_utilization < 0.3:
        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)
    elif overall_utilization > 0.7:
        extreme_utilization_penalty = 14 * np.abs(utilization - 0.8)
    else:
        extreme_utilization_penalty = 8 * np.abs(utilization - 0.5)

    priorities[valid_bins] -= bin_balancing_weight * extreme_utilization_penalty[valid_bins]

    # Fullness Bonus with Dynamic Scaling based on item size and overall utilization
    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / max_bin_cap - 0.1))
    fullness_bonus_scale = (1 - overall_utilization) * (item / max_bin_cap)

    if overall_utilization < 0.5:
        priorities[valid_bins] += fullness_bonus_weight * 1.5 * fullness_bonus[valid_bins] * fullness_bonus_scale
    elif overall_utilization < 0.8:
        priorities[valid_bins] += fullness_bonus_weight * 0.8 * fullness_bonus[valid_bins] * fullness_bonus_scale
    else:
        priorities[valid_bins] += fullness_bonus_weight * 0.3 * fullness_bonus[valid_bins] * fullness_bonus_scale

    # Bin Activation Bonus for Large Items with Utilization Awareness
    if item > 0.6 * max_bin_cap:
        empty_bin_bonus = np.exp(-2 * utilization)
        #Scale activation bonus to be stronger if bins are empty
        activation_bonus_scale = 1.5 + 2*(1-overall_utilization)
        priorities[valid_bins] += activation_bonus_weight * activation_bonus_scale * empty_bin_bonus[valid_bins]

    # Diversification Heuristic (Adaptive based on solution quality)
    # Calculate a simple solution quality metric (lower is better)
    waste = np.sum(bins_remain_cap) / (num_bins * max_bin_cap) #Waste ratio
    quality = waste + overall_utilization #High waste/low utilization indicates opportunity to explore other solutions

    # Adapt the diversification rate based on quality (if solution is bad, diversify more)
    adaptive_diversification_rate = diversification_rate * (quality + 0.1) # Add small constant to prevent zero rate

    if np.random.rand() < adaptive_diversification_rate:
        priorities[valid_bins] += np.random.normal(0, 0.1, np.sum(valid_bins)) #Add small random noise

    #Adaptive Learning Rate Adjustment (Simple Example)
    #If overall utilization is very high, reduce the bin balancing and activate bonuses,
    #and increase best fit and waste penalty
    if overall_utilization > 0.85:
      best_fit_weight *=1.1
      waste_penalty_weight *= 1.1
      bin_balancing_weight *= 0.9
      fullness_bonus_weight *= 0.9
      activation_bonus_weight *= 0.9

    return priorities
```
