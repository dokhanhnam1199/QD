```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Enhanced priority: Dynamic strategy based on item size and bin utilization."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # Best-Fit component with item-size awareness
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2

    # Waste Minimization with scaling relative to item size
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_penalty_strength = 10 + 5 * item
    waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)
    priorities[valid_bins] -= waste_penalty

    # Dynamic Bin Balancing based on overall utilization
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    if overall_utilization < 0.3:
        utilization_penalty = 5 * np.abs(utilization - 0.2)
    elif overall_utilization > 0.7:
        utilization_penalty = 15 * np.abs(utilization - 0.8)
    else:
        utilization_penalty = 10 * np.abs(utilization - 0.5)
    priorities[valid_bins] -= utilization_penalty[valid_bins]

    # Over-utilization Penalty for almost-full bins.
    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)
    priorities[almost_full & valid_bins] -= 20

    # Adaptive bonus for almost full bins based on overall util.
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))
    if overall_utilization < 0.5:
        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)
    elif overall_utilization < 0.8:
        priorities[valid_bins] += fullness_bonus[valid_bins] * (1 - overall_utilization)
    else:
        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)

    return priorities
```
