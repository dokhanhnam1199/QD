```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An adaptive priority function for online bin packing, focusing on
    dynamic adjustment of weights and incorporating bin diversity.

    It dynamically adjusts weights and incorporates bin diversity, making it adaptable
    to different scenarios in online bin packing, by using dynamic weight adjustments and diversity incentive.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit Component (Adjusted for Item Size)
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**1.5 * (1 / (item + 0.1)) #item size affects best fit

    # 2. Waste Minimization (Adaptive Penalty)
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    avg_remaining = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0
    waste_penalty_strength = np.clip(1 - avg_remaining, 0.1, 1.0)  #adjusting waste penalty
    small_waste_penalty = np.exp(-15 * remaining_after_fit * item * waste_penalty_strength)
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing (Utilization-Based)
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)
    balancing_factor = 10

    if overall_utilization < 0.4:
        extreme_utilization_penalty = balancing_factor * np.abs(utilization - 0.2)
    elif overall_utilization > 0.75:
        extreme_utilization_penalty = balancing_factor * 1.5 * np.abs(utilization - 0.8)
    else:
        extreme_utilization_penalty = balancing_factor * np.abs(utilization - 0.5)
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # 4. Diversity Incentive
    bin_std = np.std(bins_remain_cap)
    diversity_bonus = np.exp(-0.5 * (bins_remain_cap - np.mean(bins_remain_cap))**2 / (bin_std**2 + 0.0001))
    if overall_utilization < 0.6:
        priorities[valid_bins] += 0.5 * diversity_bonus[valid_bins] * (1 - overall_utilization)
    else:
         priorities[valid_bins] += 0.2 * diversity_bonus[valid_bins] * (1 - overall_utilization)

    # 5. Near-Full Bonus (Adaptive Weighting)
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))
    bonus_strength = 2.5
    if overall_utilization < 0.5:
        priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - overall_utilization)
    elif overall_utilization < 0.8:
        priorities[valid_bins] += 0.8 * bonus_strength * fullness_bonus[valid_bins] * (1 - overall_utilization)
    else:
        priorities[valid_bins] += 0.3 * bonus_strength * fullness_bonus[valid_bins] * (1 - overall_utilization)

    return priorities
```
