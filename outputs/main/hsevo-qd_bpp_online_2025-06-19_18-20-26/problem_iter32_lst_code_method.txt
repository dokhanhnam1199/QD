{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n\n    This version incorporates adaptive parameter tuning and dynamic waste\n    thresholding for improved performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization: Discourage very small waste, adaptive threshold\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Dynamically adjust the small waste penalty strength based on item size.\n    waste_penalty_strength = 10 + 5 * item  # Larger items, stronger penalty for small waste\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.  Adaptive range.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        #Adaptive balancing: the closer to 0.5, the stronger the penalty\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n    fullness_threshold = 0.1  # Bins within 10% of being full receive bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    # Edge Case Handling: If all bins are nearly full, prioritize the one with the most remaining capacity\n    if np.all(bins_remain_cap[valid_bins] <= 0.1 * np.max(bins_remain_cap)):\n        priorities[valid_bins] += 10 * bins_remain_cap[valid_bins] # Prioritize largest remaining\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n\n    This version incorporates adaptive parameter tuning and dynamic waste\n    thresholding for improved performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization: Discourage very small waste, adaptive threshold\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Dynamically adjust the small waste penalty strength based on item size.\n    waste_penalty_strength = 10 + 5 * item  # Larger items, stronger penalty for small waste\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.  Adaptive range.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        #Adaptive balancing: the closer to 0.5, the stronger the penalty\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n    fullness_threshold = 0.1  # Bins within 10% of being full receive bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    # Edge Case Handling: If all bins are nearly full, prioritize the one with the most remaining capacity\n    if np.all(bins_remain_cap[valid_bins] <= 0.1 * np.max(bins_remain_cap)):\n        priorities[valid_bins] += 10 * bins_remain_cap[valid_bins] # Prioritize largest remaining\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n\n    This version incorporates adaptive parameter tuning and dynamic waste\n    thresholding for improved performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization: Discourage very small waste, adaptive threshold\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Dynamically adjust the small waste penalty strength based on item size.\n    waste_penalty_strength = 10 + 5 * item  # Larger items, stronger penalty for small waste\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.  Adaptive range.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        #Adaptive balancing: the closer to 0.5, the stronger the penalty\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n    fullness_threshold = 0.1  # Bins within 10% of being full receive bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    # Edge Case Handling: If all bins are nearly full, prioritize the one with the most remaining capacity\n    if np.all(bins_remain_cap[valid_bins] <= 0.1 * np.max(bins_remain_cap)):\n        priorities[valid_bins] += 10 * bins_remain_cap[valid_bins] # Prioritize largest remaining\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, adaptive bin balancing, and fullness bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization)\n    \n    # Adaptive Waste Penalty Adjustment\n    if item > 0.5: # large item\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, waste minimization, bin balancing, and dynamic adjustments.\n    It adapts weights based on bin fill levels and item size, handling edge cases.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit with emphasis on closer sizes\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: adaptive penalty\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit)\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n    # Bin Balancing: dynamic adjustment\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive bonus for nearly full bins\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n\n    # Bin Activation for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, waste minimization, bin balancing, and dynamic adjustments.\n    It adapts weights based on bin fill levels and item size, handling edge cases.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit with emphasis on closer sizes\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: adaptive penalty\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit)\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n    # Bin Balancing: dynamic adjustment\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive bonus for nearly full bins\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n\n    # Bin Activation for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that dynamically adjusts\n    its behavior based on the item size relative to the average remaining\n    bin capacity, incorporating best-fit, waste minimization, bin balancing,\n    and dynamic adjustment of weights to promote robustness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive weighting based on item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap)\n    item_ratio = item / avg_bin_capacity\n\n    # Best-Fit component, scaled dynamically.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += (1.0 / (size_diff[valid_bins] + 0.0001)**2) * (1 + item_ratio)\n\n    # Waste Minimization: Discourage very small waste, dynamically penalized.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty_factor = 10 + 5 * item_ratio  # Higher penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_factor * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization: Dynamically adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic Bin Balancing with sharper penalties\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.2) * (1 + item_ratio)  # Encourage filling more aggressively\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 20 * np.abs(utilization - 0.8) * (1 + item_ratio) #Discourage further filling more aggressively\n    else:\n        extreme_utilization_penalty = 12 * np.abs(utilization - 0.5) * (1 + item_ratio)  #Balance, more sensitive\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Bonus to bins close to full, dynamically adjusted.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_scaling = 2 * (1 - overall_utilization) * (1 + item_ratio)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += bonus_scaling * fullness_bonus[valid_bins]\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  0.75 * bonus_scaling * fullness_bonus[valid_bins]  #Reduced bonus compared to v1\n    else:\n        priorities[valid_bins] += 0.25 * bonus_scaling * fullness_bonus[valid_bins] #further reduced bonus\n\n    # Edge Case Handling: Favor bins close to item size, but not too close to full capacity\n    close_to_item = np.abs(bins_remain_cap - item) / item\n    close_to_full = bins_remain_cap / np.max(bins_remain_cap)\n\n    edge_case_bonus = np.exp(-5 * close_to_item)  * (close_to_full > 0.1) # boost bins with remain capacity close to item and not close to full\n    priorities[valid_bins] += 0.5 * edge_case_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that dynamically adjusts\n    its behavior based on the item size relative to the average remaining\n    bin capacity, incorporating best-fit, waste minimization, bin balancing,\n    and dynamic adjustment of weights to promote robustness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive weighting based on item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap)\n    item_ratio = item / avg_bin_capacity\n\n    # Best-Fit component, scaled dynamically.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += (1.0 / (size_diff[valid_bins] + 0.0001)**2) * (1 + item_ratio)\n\n    # Waste Minimization: Discourage very small waste, dynamically penalized.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty_factor = 10 + 5 * item_ratio  # Higher penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_factor * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization: Dynamically adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic Bin Balancing with sharper penalties\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.2) * (1 + item_ratio)  # Encourage filling more aggressively\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 20 * np.abs(utilization - 0.8) * (1 + item_ratio) #Discourage further filling more aggressively\n    else:\n        extreme_utilization_penalty = 12 * np.abs(utilization - 0.5) * (1 + item_ratio)  #Balance, more sensitive\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Bonus to bins close to full, dynamically adjusted.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_scaling = 2 * (1 - overall_utilization) * (1 + item_ratio)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += bonus_scaling * fullness_bonus[valid_bins]\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  0.75 * bonus_scaling * fullness_bonus[valid_bins]  #Reduced bonus compared to v1\n    else:\n        priorities[valid_bins] += 0.25 * bonus_scaling * fullness_bonus[valid_bins] #further reduced bonus\n\n    # Edge Case Handling: Favor bins close to item size, but not too close to full capacity\n    close_to_item = np.abs(bins_remain_cap - item) / item\n    close_to_full = bins_remain_cap / np.max(bins_remain_cap)\n\n    edge_case_bonus = np.exp(-5 * close_to_item)  * (close_to_full > 0.1) # boost bins with remain capacity close to item and not close to full\n    priorities[valid_bins] += 0.5 * edge_case_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that dynamically adjusts\n    its behavior based on the item size relative to the average remaining\n    bin capacity, incorporating best-fit, waste minimization, bin balancing,\n    and dynamic adjustment of weights to promote robustness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive weighting based on item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap)\n    item_ratio = item / avg_bin_capacity\n\n    # Best-Fit component, scaled dynamically.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += (1.0 / (size_diff[valid_bins] + 0.0001)**2) * (1 + item_ratio)\n\n    # Waste Minimization: Discourage very small waste, dynamically penalized.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty_factor = 10 + 5 * item_ratio  # Higher penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_factor * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization: Dynamically adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic Bin Balancing with sharper penalties\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.2) * (1 + item_ratio)  # Encourage filling more aggressively\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 20 * np.abs(utilization - 0.8) * (1 + item_ratio) #Discourage further filling more aggressively\n    else:\n        extreme_utilization_penalty = 12 * np.abs(utilization - 0.5) * (1 + item_ratio)  #Balance, more sensitive\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Bonus to bins close to full, dynamically adjusted.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_scaling = 2 * (1 - overall_utilization) * (1 + item_ratio)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += bonus_scaling * fullness_bonus[valid_bins]\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  0.75 * bonus_scaling * fullness_bonus[valid_bins]  #Reduced bonus compared to v1\n    else:\n        priorities[valid_bins] += 0.25 * bonus_scaling * fullness_bonus[valid_bins] #further reduced bonus\n\n    # Edge Case Handling: Favor bins close to item size, but not too close to full capacity\n    close_to_item = np.abs(bins_remain_cap - item) / item\n    close_to_full = bins_remain_cap / np.max(bins_remain_cap)\n\n    edge_case_bonus = np.exp(-5 * close_to_item)  * (close_to_full > 0.1) # boost bins with remain capacity close to item and not close to full\n    priorities[valid_bins] += 0.5 * edge_case_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, fullness bonus, and item-size-aware penalty adjustments.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization (adaptive)\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing (dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus (adaptive)\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item size aware waste penalty adjustment\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    # Over-utilization Penalty (adaptive)\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Introduce a new adaptive parameter based on item size relative to bin capacity\n    item_ratio = item / np.max(bins_remain_cap)\n    if item_ratio > 0.6: # Item is relatively large\n        # Further discourage small waste in nearly full bins to avoid creating unusable bins\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins # less than 20% capacity\n        priorities[nearly_full] -= 10 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, fullness bonus, and item-size-aware penalty adjustments.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization (adaptive)\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing (dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus (adaptive)\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item size aware waste penalty adjustment\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    # Over-utilization Penalty (adaptive)\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Introduce a new adaptive parameter based on item size relative to bin capacity\n    item_ratio = item / np.max(bins_remain_cap)\n    if item_ratio > 0.6: # Item is relatively large\n        # Further discourage small waste in nearly full bins to avoid creating unusable bins\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins # less than 20% capacity\n        priorities[nearly_full] -= 10 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that combines best-fit,\n    waste management, bin balancing, and learning components with adaptive\n    weighting based on real-time feedback and historical performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit Component with adaptive granularity\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # 2. Waste Minimization with dynamic penalty adjustment\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-15 * remaining_after_fit * item) # Increased sensitivity\n\n    # Adaptive penalty based on waste ratio and item size\n    penalty_weight = 1.0\n    if item > 0.5:  # Penalize small waste more for large items\n        penalty_weight = 2.0\n    elif item < 0.2: # Relax the small waste penalty for small items\n        penalty_weight = 0.5\n\n    priorities[valid_bins] -= penalty_weight * small_waste_penalty\n\n    # 3. Bin Balancing using utilization and overall utilization with adaptive target\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic target utilization based on overall utilization\n    target_utilization = 0.5\n    if overall_utilization < 0.3:\n        target_utilization = 0.2\n    elif overall_utilization > 0.7:\n        target_utilization = 0.8\n\n    extreme_utilization_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive component with dynamic bonus based on remaining capacity\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_weight = 1.0\n\n    # Adjust bonus weight based on overall utilization and item size\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n\n    # 5. Item-Size-Aware Adjustment: Favor bins that tightly fit larger items\n    if item > 0.6:\n      tight_fit_bonus = np.exp(-20*(bins_remain_cap[valid_bins]-item)**2)\n      priorities[valid_bins] += 0.7 * tight_fit_bonus # Encourage tight fits\n\n    # 6. Normalize priorities to avoid domination by any single factor\n    max_priority = np.max(priorities[np.isfinite(priorities)])\n    min_priority = np.min(priorities[np.isfinite(priorities)])\n\n    if max_priority > min_priority:\n        priorities[np.isfinite(priorities)] = (priorities[np.isfinite(priorities)] - min_priority) / (max_priority - min_priority)\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                size_diff_epsilon: float = 0.0004976631192414565,\n                small_waste_penalty_factor: float = 13.759620087105052,\n                extreme_utilization_penalty_factor: float = 10.96255884116071,\n                target_utilization: float = 0.2781292500038949) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        size_diff_epsilon: A small constant added to size_diff to avoid division by zero.\n        small_waste_penalty_factor: Factor to control the strength of the small waste penalty.\n        extreme_utilization_penalty_factor: Factor to control the strength of the extreme utilization penalty.\n        target_utilization: The target utilization level (fraction full) for balancing.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + size_diff_epsilon)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-small_waste_penalty_factor * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = extreme_utilization_penalty_factor * np.abs(utilization - target_utilization) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics, with refinements over v1:\n\n    1. **Best Fit Decreasing (BFD) Emphasis:**  Prioritizes bins that offer the *tightest* fit\n       for the current item, more aggressively than v1. Aims for optimal space utilization\n       in each bin, reducing fragmentation.\n\n    2.  **Waste Minimization (Adaptive):**  Penalizes small waste, but the penalty *scales*\n        with item size.  Large items creating small waste are penalized more heavily, as\n        that waste is harder to fill later.\n\n    3.  **Bin Balancing (Dynamic):**  Adjusts the utilization penalty based on the *overall*\n        fill level of all bins. If bins are generally empty, encourages filling them more;\n        if bins are generally full, focuses on avoiding small waste.\n\n    4. **Penalty for Over-Utilized Bins:** Add a bigger penalty if bins are almost full before placing the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Best Fit Decreasing Emphasis\n    size_diff = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Prioritize tight fits *much* more strongly than v1.\n    priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**2  # Squaring makes the difference more pronounced\n\n    # 2. Waste Minimization (Adaptive)\n    remaining_after_fit = bins_remain_cap - item\n    # Penalty scales with item size. Larger item = greater waste penalty\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Balancing (Dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Fraction full\n    overall_utilization = np.mean(utilization)  # Average fill level of all bins.\n\n    # Adjust penalty based on overall utilization.\n    if overall_utilization < 0.3: # If bins are generally empty.\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2) # Aim for 20% utilization.\n    elif overall_utilization > 0.7: # If bins are generally full.\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) # Aim for 80% utilization and avoid small waste\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Default penalty, same as v1.\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Penalty for Over-Utilized Bins:\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap) # Remaining cap is less than 10% of max cap\n    priorities[almost_full & valid_bins] -= 20 # Large penalty for almost full bins.\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + 0.0001)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that adapts based on\n    bin fill levels, item sizes, and waste characteristics. It aims to\n    balance best-fit, waste minimization, and bin utilization, while\n    dynamically adjusting parameters based on problem state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # --- Best-Fit Component with Size-Aware Adjustment ---\n    size_diff = bins_remain_cap - item\n    # Normalize size difference by item size for relative fit\n    normalized_size_diff = size_diff / item\n    priorities[valid_bins] += 1.0 / (normalized_size_diff[valid_bins]**2 + 0.0001)\n\n\n    # --- Waste Minimization with Dynamic Waste Threshold ---\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Adaptive waste threshold based on item size (e.g., no waste > item/2)\n    waste_threshold = item / 2.0\n    waste_penalty_factor = 5.0  # Adjust penalty strength\n    waste_penalty = np.where(remaining_after_fit > 0, np.exp(waste_penalty_factor * (remaining_after_fit - waste_threshold)), 0)\n    priorities[valid_bins] -= waste_penalty\n\n    # --- Bin Balancing and Utilization-Based Adjustment ---\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic bin balancing based on overall utilization\n    utilization_penalty_factor = 10.0  # Adjust penalty strength\n\n    if overall_utilization < 0.4:\n        # Encourage filling bins if overall utilization is low\n        target_utilization = 0.6\n    elif overall_utilization > 0.6:\n        # Discourage filling if bins are already full\n        target_utilization = 0.4\n    else:\n        target_utilization = 0.5\n\n    utilization_penalty = utilization_penalty_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # --- Item-Size-Aware Fullness Bonus ---\n    fullness_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Closer to full = higher bonus\n\n    # Adjust bonus based on item size and overall utilization\n    bonus_weight = (1 - overall_utilization) * (item / np.max(bins_remain_cap))  # Larger items get larger weight\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A refined priority function for online bin packing, incorporating dynamic\n    weighting based on fill levels, waste minimization, and bin balancing,\n    with enhancements for robustness and adaptability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adjusted Sensitivity:\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.001)**1.5 # Reduced exponent sensitivity\n\n    # 2. Dynamic Waste Minimization:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / np.max(bins_remain_cap)\n    waste_penalty = np.exp(5 * (waste_ratio - 0.25))  # Peak penalty around 25% waste\n    priorities[valid_bins] -= waste_penalty\n\n    # 3. Enhanced Bin Balancing with Adaptive Targets:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    target_utilization = 0.6  # Start with a moderate target\n\n    # Adjust the target utilization based on overall fill level:\n    if overall_utilization < 0.4:\n        target_utilization = 0.8  # Encourage higher filling if bins are sparse\n    elif overall_utilization > 0.8:\n        target_utilization = 0.3 # Keep adding new bins if we already have a lot of bins filled\n\n    balance_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= balance_penalty[valid_bins]\n    # 4. Adaptive Fullness Bonus with Sigmoid Weighting\n    fullness_level = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Max bonus for nearly full bins\n\n    # Sigmoid function to dynamically scale the bonus\n    sigmoid_weight = 1 / (1 + np.exp(10 * (overall_utilization - 0.5))) #sharp transition around 0.5\n    priorities[valid_bins] += 2 * sigmoid_weight * fullness_bonus[valid_bins]\n\n    # 5. Add a small randomization to break ties\n    priorities[valid_bins] += np.random.normal(0, 0.001, size=np.sum(valid_bins))\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component. This version incorporates a more nuanced\n    approach to bin balancing and waste management.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with bias towards more full bins (tunable exponent).\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**1.5 # Adjusted exponent\n\n    # Waste Minimization with dynamic penalty adjustment:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    waste_penalty_strength = 5.0 # Base waste penalty strength\n    if np.mean(bins_remain_cap) > 0.7: # Bins are relatively full\n        waste_penalty_strength = 10.0 # Increase penalty if bins are full\n\n    small_waste_penalty = np.exp(-waste_penalty_strength * waste_ratio)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing with a dynamic target utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    \n    # Dynamic target utilization:\n    target_utilization = 0.5\n    if overall_utilization < 0.4:\n        target_utilization = 0.6 #Encourage filling\n    elif overall_utilization > 0.6:\n        target_utilization = 0.4 #Discourage filling\n\n    #Adjust the scaling factor dynamically based on remaining bin capacities\n    scaling_factor = 10.0\n    if np.mean(bins_remain_cap) > 0.8:\n        scaling_factor = 20.0 # More aggressive balancing at high fill levels\n    elif np.mean(bins_remain_cap) < 0.2:\n        scaling_factor = 5.0 # Less aggressive balancing when bins are empty\n\n    extreme_utilization_penalty = scaling_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus with dynamic weighting:\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_weight = 1.0\n\n    if overall_utilization < 0.5:\n        bonus_weight = 2.0 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1.0 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n    \n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    # Add a small random component to break ties and encourage exploration\n    priorities[valid_bins] += 0.0001 * np.random.rand(np.sum(valid_bins))\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}