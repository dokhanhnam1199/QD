```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A dynamically adapting priority function for online bin packing that incorporates
    best-fit, waste minimization, bin balancing, a learning component based on bin
    utilization history, and robust handling of edge cases.  Weights and penalties
    are dynamically adjusted based on the real-time state of the bins.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # Best-Fit component with a small bias towards fuller bins.  Normalization helps
    # prevent this from dominating too early.
    size_diff = bins_remain_cap - item
    best_fit_priority = 1.0 / (size_diff[valid_bins] + 0.0001)
    best_fit_priority = best_fit_priority / np.max(best_fit_priority) # Normalize
    priorities[valid_bins] += best_fit_priority

    # Waste Minimization: Discourage very small waste.  Adaptive penalty strength.
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / item
    waste_penalty = np.exp(-5 * waste_ratio)
    priorities[valid_bins] -= waste_penalty

    # Bin Balancing and Utilization:
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    # Dynamic balancing based on fill level.  Increased magnitude.
    if overall_utilization < 0.4:  # Encourage filling
        balance_penalty = 10 * np.abs(utilization - 0.3)
    elif overall_utilization > 0.6: # Discourage further filling
        balance_penalty = 20 * np.abs(utilization - 0.7)
    else:                           # Balance
        balance_penalty = 15 * np.abs(utilization - 0.5)
    priorities[valid_bins] -= balance_penalty[valid_bins]


    # Adaptive "Almost Full" Bonus:  Emphasize near-full bins, adaptively weighted.
    fullness_level = bins_remain_cap / np.max(bins_remain_cap)
    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 0)) # Closer to 0
    fullness_bonus = fullness_bonus / np.max(fullness_bonus) # Normalize bonus

    if overall_utilization < 0.5:
        bonus_weight = 2 * (1 - overall_utilization)
    elif overall_utilization < 0.8:
        bonus_weight = (1 - overall_utilization)
    else:
        bonus_weight = 0.5 * (1 - overall_utilization)

    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]

    #Robust Edge-case Handling: If all bins are almost full, use best-fit less aggressively
    if np.all(bins_remain_cap < item * 1.1) and np.any(valid_bins):
        priorities[valid_bins] +=  0.1 * best_fit_priority # Smaller boost
    #Computational Considerations:  All operations are vectorized, scaling well with bin count

    return priorities
```
