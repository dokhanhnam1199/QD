```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Dynamically adapts bin packing strategy based on item size, bin utilization, and waste.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    max_cap = np.max(bins_remain_cap)
    overall_utilization = 1 - np.mean(bins_remain_cap / max_cap)

    # Best-Fit with dynamic size difference scaling
    size_diff = bins_remain_cap - item
    size_diff_penalty = 1.2 / (size_diff[valid_bins] + 0.0001)**1.5
    if item > 0.5 * max_cap:
        size_diff_penalty *= 1.5  # Prioritize tighter fits for larger items
    priorities[valid_bins] += size_diff_penalty

    # Waste Minimization with adaptive scaling based on utilization
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / item
    small_waste_penalty = np.exp(-7 * waste_ratio)
    large_waste_penalty = np.exp(-4 / waste_ratio)  # Inverse for large waste
    waste_penalty = (small_waste_penalty + large_waste_penalty) * 0.6

    if overall_utilization < 0.4:
        waste_penalty *= 0.7 # relaxed penalty if bins are not fully used
    elif overall_utilization > 0.8:
        waste_penalty *= 1.3 # increased penalty when most bins are highly utilized
    priorities[valid_bins] -= waste_penalty
    

    # Bin Balancing with Exploration Bonus and adaptive threshold
    bin_utilization = 1 - bins_remain_cap / max_cap
    utilization_diff = np.abs(bin_utilization - overall_utilization)
    
    if overall_utilization < 0.3:
        utilization_penalty = 5 * utilization_diff
    elif overall_utilization > 0.7:
        utilization_penalty = 14 * utilization_diff
    else:
        utilization_penalty = 8 * utilization_diff

    priorities[valid_bins] -= utilization_penalty[valid_bins]
    
    # Encouraging exploration when bins are similar
    if np.std(bins_remain_cap) < 0.1 * max_cap:
      priorities[valid_bins] += 0.5 * np.random.rand(np.sum(valid_bins))

    # Near-Full Bin Bonus with Adaptive Scaling
    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / max_cap - 0.1))
    fullness_bonus_scale = 1 - overall_utilization
    if item > 0.7 * max_cap:
        fullness_bonus_scale = 0.5 # reduce if large item

    priorities[valid_bins] += 1.5 * fullness_bonus[valid_bins] * fullness_bonus_scale * (item / max_cap)
    

    # Bin Activation Bonus for Large Items with dynamic strength
    if item > 0.6 * max_cap:
        empty_bin_bonus = np.exp(-2 * bin_utilization)
        bonus_strength = 1.5 + 0.8 * (item/max_cap)
        priorities[valid_bins] += bonus_strength * empty_bin_bonus[valid_bins]
    

    # Penalty for bins with very small remaining capacity to avoid tiny fragments
    tiny_fragment_threshold = 0.1 * max_cap
    tiny_fragment_penalty = np.where(bins_remain_cap[valid_bins] < tiny_fragment_threshold, 2 * (tiny_fragment_threshold - bins_remain_cap[valid_bins]), 0)
    priorities[valid_bins] -= tiny_fragment_penalty

    return priorities
```
