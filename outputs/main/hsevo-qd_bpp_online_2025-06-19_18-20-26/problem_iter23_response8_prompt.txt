{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, waste minimization, bin balancing, fullness bonus, and item-size-aware penalty adjustments.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization (adaptive)\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing (dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus (adaptive)\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item size aware waste penalty adjustment\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    # Over-utilization Penalty (adaptive)\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Introduce a new adaptive parameter based on item size relative to bin capacity\n    item_ratio = item / np.max(bins_remain_cap)\n    if item_ratio > 0.6: # Item is relatively large\n        # Further discourage small waste in nearly full bins to avoid creating unusable bins\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins # less than 20% capacity\n        priorities[nearly_full] -= 10 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A refined priority function for online bin packing, incorporating dynamic\n    weighting based on fill levels, waste minimization, and bin balancing,\n    with enhancements for robustness and adaptability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adjusted Sensitivity:\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.001)**1.5 # Reduced exponent sensitivity\n\n    # 2. Dynamic Waste Minimization:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / np.max(bins_remain_cap)\n    waste_penalty = np.exp(5 * (waste_ratio - 0.25))  # Peak penalty around 25% waste\n    priorities[valid_bins] -= waste_penalty\n\n    # 3. Enhanced Bin Balancing with Adaptive Targets:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    target_utilization = 0.6  # Start with a moderate target\n\n    # Adjust the target utilization based on overall fill level:\n    if overall_utilization < 0.4:\n        target_utilization = 0.8  # Encourage higher filling if bins are sparse\n    elif overall_utilization > 0.8:\n        target_utilization = 0.3 # Keep adding new bins if we already have a lot of bins filled\n\n    balance_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= balance_penalty[valid_bins]\n    # 4. Adaptive Fullness Bonus with Sigmoid Weighting\n    fullness_level = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Max bonus for nearly full bins\n\n    # Sigmoid function to dynamically scale the bonus\n    sigmoid_weight = 1 / (1 + np.exp(10 * (overall_utilization - 0.5))) #sharp transition around 0.5\n    priorities[valid_bins] += 2 * sigmoid_weight * fullness_bonus[valid_bins]\n\n    # 5. Add a small randomization to break ties\n    priorities[valid_bins] += np.random.normal(0, 0.001, size=np.sum(valid_bins))\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (10th), we see (1st) uses dynamic waste management, bin balancing and learning components; (10th) uses FFD approximation, waste minimization, and bin utilization balance. (1st) adjusts weights dynamically based on overall fill level while (10th) uses fixed parameters.\n*   Comparing (2nd) vs (19th), we see (2nd) incorporates adaptive waste penalty adjustment based on item size and overall utilization, while (19th) sticks to basic waste minimization.\n*   Comparing (3rd) vs (14th), we see (3rd) uses adaptive parameter tuning and dynamic waste thresholding, (14th) employs basic FFD approximation, waste minimization and bin utilization.\n*   Comparing (4th) vs (15th), we see (4th) introduces a bin activation strategy and normalizes waste by item size, while (15th) uses the same basic heuristic as (14th)\n*   Comparing (11th) vs (20th), we see (11th) has best fit emphasis, adaptive waste minimization, dynamic bin balancing, penalty for over-utilized bins while (20th) has capacity ratio.\n*   Comparing (1st) vs (2nd), we see (1st) emphasizes dynamic parameter adjustments, and a learning component; (2nd) introduces item size aware waste penalty\n*   Comparing (3rd) vs (4th), we see (3rd) features adaptive thresholding and edge case handling for nearly full bins, while (4th) incorporates bin activation and discourages both small and large waste with normalization.\n*   Comparing (second worst) vs (worst), we see (19th) combines FFD approximation, waste minimization and capacity ratio; (20th) has capacity ratio.\n*   Overall: Better heuristics incorporate dynamic adjustments based on overall fill levels, item sizes, and potential waste. They include a combination of best-fit considerations with waste minimization and bin balancing. The best heuristics feature edge case handling and adaptive parameter tuning, while less effective heuristics rely on simpler, static rules.\n- \nOkay, here's a redefined approach to \"Current Self-Reflection,\" designed to avoid the pitfalls of \"Ineffective Self-Reflection,\" and to guide the design of better heuristics.\n\n*   **Keywords:** Dynamic adaptation, state-awareness, multi-objective, normalization, feedback-driven, robust edge-case handling, computational efficiency.\n\n*   **Advice:** Design heuristics that actively monitor problem state and dynamically adjust parameters (weights, penalties, strategies) accordingly. Combine multiple objectives (e.g., best-fit *and* waste reduction) via adaptive weighting. Incorporate feedback loops (e.g. historical performance).\n\n*   **Avoid:** Static parameter tuning, reliance on single strategies, neglecting edge cases, excessive complexity without commensurate performance gains, ignoring computational cost.\n\n*   **Explanation:** Move beyond static rules. Focus on heuristics that *learn* and adapt within the problem-solving process. Normalizing objectives prevents domination and ensures fair consideration. Prioritize computationally efficient adaptation mechanisms.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}