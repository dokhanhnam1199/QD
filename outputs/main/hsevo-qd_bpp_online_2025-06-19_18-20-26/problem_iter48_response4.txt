```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An enhanced priority function for online bin packing, building upon v1 with a focus on
    proactive bin management, adaptive exploration/exploitation, and refined waste minimization.
    It incorporates dynamic scaling of all components based on real-time statistics of item sizes
    and bin utilization, leading to better overall packing efficiency.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    max_bin_cap = np.max(bins_remain_cap)
    overall_utilization = 1 - np.mean(bins_remain_cap / max_bin_cap)

    # Adaptive Item Size Statistics
    # Track the average and variance of item sizes seen so far. Use a moving average.
    # (This is just a placeholder; in a real online setting, this would be updated iteratively.)
    avg_item_size = 0.4 * max_bin_cap  # Example: Assume items around 40% bin size
    item_size_variance = 0.1 * max_bin_cap #Example: Assume variance of 10%
    # Best-Fit with Adaptive Sensitivity based on Item Size Stats
    size_diff = bins_remain_cap - item
    best_fit_scale = 1.0 + 1.0 * overall_utilization #Adjusted to reduce scaling
    best_fit_scale += 0.5 * (item - avg_item_size) / item_size_variance  # Adjust based on item size relative to average
    priorities[valid_bins] += best_fit_scale / (size_diff[valid_bins] + 0.0001)**1.2 #Reduced the exponent

    # Waste Minimization with Dynamic Penalties & a Threshold
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / item
    small_waste_penalty = np.exp(-7 * waste_ratio)
    large_waste_penalty = np.exp(-4 / waste_ratio) #Inverted to give exponentially decaying penalty for large waste
    waste_penalty_weight = 0.5 + 0.5 * overall_utilization  # Increase penalty with higher utilization
    waste_threshold = 0.2* item  #Only penalize bins with more than 20% waste, relative to item size.
    waste_mask = remaining_after_fit > waste_threshold
    priorities[valid_bins[waste_mask]] -= (small_waste_penalty[waste_mask] + large_waste_penalty[waste_mask]) * waste_penalty_weight

    # Bin Balancing with Adaptive Adjustment, focusing on emptying bins
    utilization = 1 - (bins_remain_cap / max_bin_cap)
    extreme_utilization_penalty = np.zeros_like(utilization)

    if overall_utilization < 0.3:
         extreme_utilization_penalty = 7 * np.abs(utilization - 0.1) #Push to empty bins
    elif overall_utilization > 0.7:
        extreme_utilization_penalty = 10 * np.abs(utilization - 0.9) #push towards full bins
    else:
        extreme_utilization_penalty = 4 * np.abs(utilization - 0.5)

    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # Fullness Bonus with Dynamic Scaling based on item size, overall utilization, and variance
    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / max_bin_cap - 0.1))
    fullness_bonus_scale = (1 - overall_utilization) * (item / max_bin_cap)

    # Modulate the fullness bonus based on item size variance
    fullness_bonus_scale *= (1 - np.abs(item - avg_item_size) / (3 * item_size_variance + 0.0001))

    if overall_utilization < 0.5:
        priorities[valid_bins] += 1.6 * fullness_bonus[valid_bins] * fullness_bonus_scale
    elif overall_utilization < 0.8:
        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * fullness_bonus_scale
    else:
        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * fullness_bonus_scale

    # Bin Activation Bonus for Large Items with Utilization Awareness, stronger activation
    if item > 0.6 * max_bin_cap:
        empty_bin_bonus = np.exp(-2 * utilization)
        #Scale activation bonus to be stronger if bins are empty
        activation_bonus_scale = 2.0 + 3*(1-overall_utilization)
        priorities[valid_bins] += activation_bonus_scale * empty_bin_bonus[valid_bins]

    # Proactive Bin Management (Empty Bin Preference)
    # Preferentially select empty or near-empty bins for smaller items
    if item < 0.3 * max_bin_cap:
        empty_bin_threshold = 0.1 * max_bin_cap
        empty_bin_mask = bins_remain_cap > (max_bin_cap - empty_bin_threshold)
        priorities[empty_bin_mask] += 2.5  # Strong preference for empty bins

    #Adaptive Diversification Heuristic (Escape Local Optima), reduced frequency
    diversification_prob = 0.03 + 0.02 * overall_utilization #increase diversification with higher utilization
    if np.random.rand() < diversification_prob: #5% chance of diversifying
        priorities[valid_bins] += np.random.normal(0, 0.07, np.sum(valid_bins)) #Add small random noise, reduced magnitude

    return priorities
```
