```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A more sophisticated priority function for online bin packing.
    This version incorporates adaptive learning through dynamic weight adjustments,
    considers item size relative to bin capacity, includes a fragmentation penalty,
    and employs a bin homogeneity bonus. It also manages edge cases and computational cost.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit Component (Normalized):
    size_diff = bins_remain_cap - item
    normalized_size_diff = size_diff / np.max(bins_remain_cap) # Normalizing improves robustness
    priorities[valid_bins] += 1.0 / (normalized_size_diff[valid_bins] + 0.0001)**2 # Prevent division by zero

    # 2. Waste Minimization with Adaptive Threshold:
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]  # Ratio of waste to bin size
    overall_fill_ratio = 1 - np.mean(bins_remain_cap) / np.max(bins_remain_cap)

    #Dynamically adjust the threshold for waste penalty
    waste_threshold = 0.1 + 0.1 * overall_fill_ratio # Waste becomes more important as bins fill
    small_waste_penalty = np.where(waste_ratio < waste_threshold, np.exp(-10 * waste_ratio), 0) # Penalize only small wastes
    priorities[valid_bins] -= small_waste_penalty


    # 3. Fragmentation Penalty: Discourage leaving small spaces in bins
    avg_item_size = item #Avergae item sizes
    fragmentation_threshold = 0.3 * avg_item_size  # Dynamic threshold based on average item size
    fragmentation_penalty = np.where(remaining_after_fit < fragmentation_threshold, 2 * np.exp(-5 * remaining_after_fit /fragmentation_threshold) , 0)
    priorities[valid_bins] -= fragmentation_penalty

    # 4. Bin Homogeneity Bonus: Encourage bins to contain items of similar size.
    # (Simplification: Assume item size represents the "type" of item)
    bin_similarity = np.zeros_like(bins_remain_cap)
    for i in range(len(bins_remain_cap)):
        if valid_bins[i]:
            bin_similarity[i] = np.exp(-np.abs(bins_remain_cap[i] - item) / np.max(bins_remain_cap))
    priorities[valid_bins] += 0.5* bin_similarity[valid_bins]

    # 5. Bin Balancing with Adaptive Weights:
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    # Adaptive bin balancing based on fill level
    if overall_utilization < 0.3:
        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling
    elif overall_utilization > 0.7:
        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)  # Discourage filling
    else:
        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Balance
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]


    # 6. Encourage using new bins when bins are too full (exploring option to avoid local optimum)
    new_bin_bonus = 0
    if overall_utilization > 0.9:
         new_bin_bonus = 10 #High bonus

    return priorities
```
