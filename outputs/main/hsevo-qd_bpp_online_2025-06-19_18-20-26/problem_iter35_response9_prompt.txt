{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A priority function for online bin packing that combines best-fit,\n    waste minimization, bin balancing, and an adaptive component.  It dynamically\n    adjusts the weights of different factors based on the fill level of the bins and\n    the size of the current item.  This version introduces a bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a bias towards more full bins (tuned).\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: Discourage very small and very large waste.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)  # Normalize by item size\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit) #Added to discourage very large waste\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)  # Discourage further filling\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)  # Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization and item size.\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n\n\n    #Bin Activation Strategy:  Prioritize empty or near-empty bins for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)  #High bonus for emptier bins\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A dynamic priority function that adapts to the problem state by\n    analyzing bin capacity distribution and item size relative to bin sizes.\n    It uses a multi-faceted approach combining best-fit, waste minimization,\n    and bin balancing with dynamically adjusted weights.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adaptive Granularity:\n    #   - Emphasize finer granularity when bins are mostly empty; coarser when mostly full.\n    size_diff = bins_remain_cap - item\n    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)\n    granularity_factor = np.mean(capacity_ratio)  # Dynamic granularity adjustment\n    priorities[valid_bins] += (1 / (size_diff[valid_bins] + 0.0001)**(granularity_factor + 1))\n\n    # 2. Dynamic Waste Minimization:\n    #   - Adjust the small waste penalty based on item size and remaining capacity.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]\n    item_size_factor = item / np.max(bins_remain_cap)  # Normalize item size\n\n    waste_penalty_strength = 5 + 10 * item_size_factor  # Stronger penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # 3. Bin Balancing with Capacity Distribution Awareness:\n    #   - Instead of a single overall utilization, consider the distribution of bin capacities.\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    capacity_std = np.std(bins_remain_cap)  # Measure capacity variance\n    capacity_mean = np.mean(bins_remain_cap)\n\n    #   - Adjust balancing based on capacity distribution.\n    if capacity_std < 0.1 * capacity_mean:  # Bins are relatively uniform\n        balancing_strength = 10  # Strong balancing\n    else:\n        balancing_strength = 5  # Moderate balancing\n\n    #   - More penalty for bins that are too full or empty\n    extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive Fullness Bonus:\n    #   - Bonus for bins that are close to full, adjusted based on remaining capacity.\n    fullness_level = 1 - capacity_ratio\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Close to full = high bonus\n    bonus_strength = 1 + 5 * item_size_factor  # Larger items, higher bonus\n\n    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))\n\n    # 5. Edge Case Handling:  Favor bins close to full if item is large relative to available space\n    large_item_threshold = 0.75  # Item size relative to bin capacity\n\n    if item_size_factor > large_item_threshold:\n        almost_full_bins = bins_remain_cap >= item\n        almost_full_bins = np.logical_and(almost_full_bins, bins_remain_cap < (item + 0.1 * np.max(bins_remain_cap)) )\n        priorities[almost_full_bins] += 10 # Strong encouragement for nearly full bins to take large items\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines multiple factors like best-fit, waste minimization, bin balancing, and fullness bonus with dynamic adjustments, whereas the worst only considers the ratio of item size to remaining bin capacity.\n(2nd best) vs (second worst) shows similar differences. Comparing (1st) vs (2nd), we see that (1st) introduces an adaptive waste penalty adjustment and a penalty for over-utilized bins, making it slightly more sophisticated than (2nd), (3rd) vs (4th) shows that (3rd) incorporates utilization awareness into its waste minimization component through `waste_penalty_factor`.\nComparing (second worst) vs (worst), we see very similar approaches, with minor variations in how the ratio is handled. Overall: The better heuristics involve a more complex and adaptive combination of factors, especially regarding dynamic waste management, bin balancing, and fullness bonuses, with the parameters of these factors often depending on overall bin utilization and item sizes. The worst perform much simpler calculations using ratios.\n- \nOkay, let's redefine \"Current self-reflection\" for designing better heuristics, focusing on actionable insights and avoiding the pitfalls of ineffective reflection.\n\nHere's a breakdown:\n\n*   **Keywords:** Adaptive, Dynamic, Multifaceted, State-Aware, Evaluation Metrics, Iterative Refinement.\n\n*   **Advice:** Design heuristics as learning systems. Incorporate feedback loops using clearly defined evaluation metrics at each step to refine parameters and strategies. Think of heuristics as \"policies\" that adapt to different problem stages or instances.\n\n*   **Avoid:** Vague statements about \"combining factors\" without specifying *how* the combination happens, focusing solely on existing strategies without exploring new combinations, ignoring the computational cost of adaptation.\n\n*   **Explanation:** Effective self-reflection involves quantifying the impact of design choices on heuristic performance. It uses data-driven evaluation to iteratively refine the heuristic's behavior. The reflection is not merely descriptive (\"combine multiple factors\") but prescriptive (\"adjust weight X based on performance metric Y\").\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}