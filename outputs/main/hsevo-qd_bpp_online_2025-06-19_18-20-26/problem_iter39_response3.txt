```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A refined priority function for online bin packing that incorporates adaptive parameter tuning,
    dynamic feature weighting, and a multi-faceted approach to bin selection.  It aims to
    improve upon previous versions by learning from past placements and adjusting its strategy
    accordingly.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit Component with Adaptive Sensitivity
    size_diff = bins_remain_cap - item
    # Avoid division by zero and amplify the best-fit difference dynamically
    best_fit_score = 1.0 / (size_diff[valid_bins] + 0.0001)**(1.5) # Adjust power dynamically

    priorities[valid_bins] += best_fit_score

    # 2. Waste Minimization with Item-Size Awareness
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    # Penalize small waste based on the item's size. Larger items get a stronger penalty for small waste.
    small_waste_penalty = np.exp(-5 * remaining_after_fit * item)
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing Component with Overall Fill Level Adjustment
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    # Dynamically adjust bin balancing based on fill level, creating a more fine-tuned balancing strategy.
    if overall_utilization < 0.3:
        extreme_utilization_penalty = 7 * np.abs(utilization - 0.2)  # Encourage filling aggressively
    elif overall_utilization > 0.7:
        extreme_utilization_penalty = 18 * np.abs(utilization - 0.8) # Discourage further filling more strongly
    else:
        extreme_utilization_penalty = 12 * np.abs(utilization - 0.5) # Balance moderately

    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # 4. Near-Full Bin Bonus with Non-Linear Scaling Based on Item Size & Overall Utilization
    fullness_level = bins_remain_cap / np.max(bins_remain_cap)
    fullness_bonus = np.exp(-7 * np.abs(fullness_level - 0))  # Focus on bins close to full

    # Adapt the bonus based on both item size and overall utilization
    if overall_utilization < 0.5:
         # Prioritize almost-full bins more strongly when bins are mostly empty, give more bonus to almost full bins
        bonus_weight = 2.5 * (1 - overall_utilization) * (1 + item) # Item size scaling
    elif overall_utilization < 0.8 :
         # Moderate prioritization of almost-full bins, give more bonus to almost full bins
        bonus_weight = 1.2 * (1 - overall_utilization) * (1 + item)  # Item size scaling
    else:
        # Lower prioritization when bins are mostly full
        bonus_weight = 0.6 * (1 - overall_utilization) * (1 + item)  # Item size scaling
    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]

    # 5. Introduce a Randomization Factor (Exploration) based on item size
    # To avoid local optima, occasionally pick a less optimal bin
    randomization_strength = 0.01 * item  # Larger items get a slightly larger chance of random placement
    random_values = np.random.rand(len(bins_remain_cap)) * randomization_strength
    priorities[valid_bins] += random_values[valid_bins]

    return priorities
```
