{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, adaptive fullness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap)))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced priority function using best-fit, waste minimization, \n    dynamic bin balancing, and adaptive fullness bonus.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap)))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n\n    This version incorporates adaptive parameter tuning and dynamic waste\n    thresholding for improved performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization: Discourage very small waste, adaptive threshold\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Dynamically adjust the small waste penalty strength based on item size.\n    waste_penalty_strength = 10 + 5 * item  # Larger items, stronger penalty for small waste\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.  Adaptive range.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        #Adaptive balancing: the closer to 0.5, the stronger the penalty\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n    fullness_threshold = 0.1  # Bins within 10% of being full receive bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    # Edge Case Handling: If all bins are nearly full, prioritize the one with the most remaining capacity\n    if np.all(bins_remain_cap[valid_bins] <= 0.1 * np.max(bins_remain_cap)):\n        priorities[valid_bins] += 10 * bins_remain_cap[valid_bins] # Prioritize largest remaining\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive waste management, bin balancing, and item-size awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Adaptive Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty_strength = 10 + 5 * item\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Dynamic Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_threshold = 0.1\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item-size aware adjustment and small-waste penalty\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins\n        priorities[nearly_full] -= 5 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, adaptive bin balancing, and fullness bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization)\n    \n    # Adaptive Waste Penalty Adjustment\n    if item > 0.5: # large item\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that combines best-fit,\n    waste minimization, bin balancing, and an adaptive component.  It dynamically\n    adjusts the weights of different factors based on the fill level of the bins and\n    the size of the current item.  This version introduces a bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a bias towards more full bins (tuned).\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: Discourage very small and very large waste.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)  # Normalize by item size\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit) #Added to discourage very large waste\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)  # Discourage further filling\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)  # Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization and item size.\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n\n\n    #Bin Activation Strategy:  Prioritize empty or near-empty bins for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)  #High bonus for emptier bins\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins. This version includes\n    a more sophisticated waste penalty and dynamic adjustment of the best-fit component.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive Best-Fit:\n    # Adjust the strength of best-fit based on the item size relative to average bin capacity.\n    avg_bin_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0\n    best_fit_strength = 1.0 + 2.0 * (item / avg_bin_capacity)  # Stronger for larger items\n\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += best_fit_strength / (size_diff[valid_bins] + 0.0001)**2\n\n\n    # Enhanced Waste Minimization:  Discourage small waste and encourage almost full bins\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Sigmoid-shaped penalty to aggressively penalize very small waste\n    waste_penalty_scale = 10.0\n    waste_penalty = 1.0 / (1 + np.exp(waste_penalty_scale * (remaining_after_fit - 0.05)))  # Push for less than 5% waste\n\n    priorities[valid_bins] -= waste_penalty\n\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component:  Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An adaptive priority function that dynamically adjusts its strategy based on\n    the item size relative to bin capacities and the overall bin utilization.\n    It prioritizes bins considering best-fit, waste minimization, bin balancing,\n    and a dynamic bonus for almost-full bins, with adaptive weight adjustments.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Overall utilization of the bins\n    total_capacity = np.sum(bins_remain_cap) + np.sum(bins_remain_cap[~valid_bins] + item) * np.sum(bins_remain_cap >= item)\n    overall_utilization = 1 - np.sum(bins_remain_cap) / total_capacity if total_capacity > 0 else 0\n\n    # Item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.sum(bins_remain_cap > 0) > 0 else 1 # Avoid zero division\n    item_size_ratio = item / avg_bin_capacity\n\n    # Best-Fit component with adaptive scaling\n    size_diff = bins_remain_cap - item\n    best_fit_priority = 1.0 / (size_diff[valid_bins] + 0.0001)**2\n    priorities[valid_bins] += best_fit_priority * (1 + overall_utilization) #Scale by fill level\n\n    # Waste Minimization: Discourage very small waste dynamically\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty * (1 - overall_utilization) #Scale by fill level\n\n    # Bin Balancing using utilization, adaptively adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins] * (1 + item_size_ratio) #Scale by item size\n\n    # Adaptive bonus for bins close to full, with dynamic weighting\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n     # Item size adjustment: Small items get more bonus\n    item_size_bonus_multiplier = 1 + (1 - item_size_ratio)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins] * item_size_bonus_multiplier\n\n    # Edge case handling: If no bin is suitable, slightly relax best-fit preference\n    if np.all(priorities == -np.inf):\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        valid_bins = bins_remain_cap > 0\n        if np.any(valid_bins):\n            size_diff = bins_remain_cap - item\n            size_diff[size_diff < 0] = np.inf  # Consider the overflow when calculating the best-fit\n            priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**0.5 # Relaxed exponent\n        else: # Very rare case: All bins are full\n            priorities = np.ones_like(bins_remain_cap) #All bins have equal priority\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that dynamically adjusts\n    its behavior based on the item size relative to the average remaining\n    bin capacity, incorporating best-fit, waste minimization, bin balancing,\n    and dynamic adjustment of weights to promote robustness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive weighting based on item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap)\n    item_ratio = item / avg_bin_capacity\n\n    # Best-Fit component, scaled dynamically.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += (1.0 / (size_diff[valid_bins] + 0.0001)**2) * (1 + item_ratio)\n\n    # Waste Minimization: Discourage very small waste, dynamically penalized.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty_factor = 10 + 5 * item_ratio  # Higher penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_factor * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization: Dynamically adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic Bin Balancing with sharper penalties\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.2) * (1 + item_ratio)  # Encourage filling more aggressively\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 20 * np.abs(utilization - 0.8) * (1 + item_ratio) #Discourage further filling more aggressively\n    else:\n        extreme_utilization_penalty = 12 * np.abs(utilization - 0.5) * (1 + item_ratio)  #Balance, more sensitive\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Bonus to bins close to full, dynamically adjusted.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_scaling = 2 * (1 - overall_utilization) * (1 + item_ratio)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += bonus_scaling * fullness_bonus[valid_bins]\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  0.75 * bonus_scaling * fullness_bonus[valid_bins]  #Reduced bonus compared to v1\n    else:\n        priorities[valid_bins] += 0.25 * bonus_scaling * fullness_bonus[valid_bins] #further reduced bonus\n\n    # Edge Case Handling: Favor bins close to item size, but not too close to full capacity\n    close_to_item = np.abs(bins_remain_cap - item) / item\n    close_to_full = bins_remain_cap / np.max(bins_remain_cap)\n\n    edge_case_bonus = np.exp(-5 * close_to_item)  * (close_to_full > 0.1) # boost bins with remain capacity close to item and not close to full\n    priorities[valid_bins] += 0.5 * edge_case_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive best-fit, dynamic bin balancing, waste control. Scales penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit: Prioritize tight fits.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Adaptive Waste Minimization: Scale penalty with item size.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= waste_penalty\n\n    # Dynamic Bin Balancing based on overall utilization.\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # Over-utilization Penalty: Large penalty for almost-full bins.\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Adaptive bonus for almost full bins based on overall util.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, fullness bonus, and item-size-aware penalty adjustments.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization (adaptive)\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing (dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus (adaptive)\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item size aware waste penalty adjustment\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    # Over-utilization Penalty (adaptive)\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Introduce a new adaptive parameter based on item size relative to bin capacity\n    item_ratio = item / np.max(bins_remain_cap)\n    if item_ratio > 0.6: # Item is relatively large\n        # Further discourage small waste in nearly full bins to avoid creating unusable bins\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins # less than 20% capacity\n        priorities[nearly_full] -= 10 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive best-fit, dynamic bin balancing, waste control. Scales penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit: Prioritize tight fits.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Adaptive Waste Minimization: Scale penalty with item size.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= waste_penalty\n\n    # Dynamic Bin Balancing based on overall utilization.\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # Over-utilization Penalty: Large penalty for almost-full bins.\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Adaptive bonus for almost full bins based on overall util.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                size_diff_epsilon: float = 0.0004976631192414565,\n                small_waste_penalty_factor: float = 13.759620087105052,\n                extreme_utilization_penalty_factor: float = 10.96255884116071,\n                target_utilization: float = 0.2781292500038949) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        size_diff_epsilon: A small constant added to size_diff to avoid division by zero.\n        small_waste_penalty_factor: Factor to control the strength of the small waste penalty.\n        extreme_utilization_penalty_factor: Factor to control the strength of the extreme utilization penalty.\n        target_utilization: The target utilization level (fraction full) for balancing.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + size_diff_epsilon)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-small_waste_penalty_factor * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = extreme_utilization_penalty_factor * np.abs(utilization - target_utilization) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics, with refinements over v1:\n\n    1. **Best Fit Decreasing (BFD) Emphasis:**  Prioritizes bins that offer the *tightest* fit\n       for the current item, more aggressively than v1. Aims for optimal space utilization\n       in each bin, reducing fragmentation.\n\n    2.  **Waste Minimization (Adaptive):**  Penalizes small waste, but the penalty *scales*\n        with item size.  Large items creating small waste are penalized more heavily, as\n        that waste is harder to fill later.\n\n    3.  **Bin Balancing (Dynamic):**  Adjusts the utilization penalty based on the *overall*\n        fill level of all bins. If bins are generally empty, encourages filling them more;\n        if bins are generally full, focuses on avoiding small waste.\n\n    4. **Penalty for Over-Utilized Bins:** Add a bigger penalty if bins are almost full before placing the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Best Fit Decreasing Emphasis\n    size_diff = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Prioritize tight fits *much* more strongly than v1.\n    priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**2  # Squaring makes the difference more pronounced\n\n    # 2. Waste Minimization (Adaptive)\n    remaining_after_fit = bins_remain_cap - item\n    # Penalty scales with item size. Larger item = greater waste penalty\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Balancing (Dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Fraction full\n    overall_utilization = np.mean(utilization)  # Average fill level of all bins.\n\n    # Adjust penalty based on overall utilization.\n    if overall_utilization < 0.3: # If bins are generally empty.\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2) # Aim for 20% utilization.\n    elif overall_utilization > 0.7: # If bins are generally full.\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) # Aim for 80% utilization and avoid small waste\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Default penalty, same as v1.\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Penalty for Over-Utilized Bins:\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap) # Remaining cap is less than 10% of max cap\n    priorities[almost_full & valid_bins] -= 20 # Large penalty for almost full bins.\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics, with refinements over v1:\n\n    1. **Best Fit Decreasing (BFD) Emphasis:**  Prioritizes bins that offer the *tightest* fit\n       for the current item, more aggressively than v1. Aims for optimal space utilization\n       in each bin, reducing fragmentation.\n\n    2.  **Waste Minimization (Adaptive):**  Penalizes small waste, but the penalty *scales*\n        with item size.  Large items creating small waste are penalized more heavily, as\n        that waste is harder to fill later.\n\n    3.  **Bin Balancing (Dynamic):**  Adjusts the utilization penalty based on the *overall*\n        fill level of all bins. If bins are generally empty, encourages filling them more;\n        if bins are generally full, focuses on avoiding small waste.\n\n    4. **Penalty for Over-Utilized Bins:** Add a bigger penalty if bins are almost full before placing the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Best Fit Decreasing Emphasis\n    size_diff = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Prioritize tight fits *much* more strongly than v1.\n    priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**2  # Squaring makes the difference more pronounced\n\n    # 2. Waste Minimization (Adaptive)\n    remaining_after_fit = bins_remain_cap - item\n    # Penalty scales with item size. Larger item = greater waste penalty\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Balancing (Dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Fraction full\n    overall_utilization = np.mean(utilization)  # Average fill level of all bins.\n\n    # Adjust penalty based on overall utilization.\n    if overall_utilization < 0.3: # If bins are generally empty.\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2) # Aim for 20% utilization.\n    elif overall_utilization > 0.7: # If bins are generally full.\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) # Aim for 80% utilization and avoid small waste\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Default penalty, same as v1.\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Penalty for Over-Utilized Bins:\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap) # Remaining cap is less than 10% of max cap\n    priorities[almost_full & valid_bins] -= 20 # Large penalty for almost full bins.\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that adapts based on\n    bin fill levels, item sizes, and waste characteristics. It aims to\n    balance best-fit, waste minimization, and bin utilization, while\n    dynamically adjusting parameters based on problem state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # --- Best-Fit Component with Size-Aware Adjustment ---\n    size_diff = bins_remain_cap - item\n    # Normalize size difference by item size for relative fit\n    normalized_size_diff = size_diff / item\n    priorities[valid_bins] += 1.0 / (normalized_size_diff[valid_bins]**2 + 0.0001)\n\n\n    # --- Waste Minimization with Dynamic Waste Threshold ---\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Adaptive waste threshold based on item size (e.g., no waste > item/2)\n    waste_threshold = item / 2.0\n    waste_penalty_factor = 5.0  # Adjust penalty strength\n    waste_penalty = np.where(remaining_after_fit > 0, np.exp(waste_penalty_factor * (remaining_after_fit - waste_threshold)), 0)\n    priorities[valid_bins] -= waste_penalty\n\n    # --- Bin Balancing and Utilization-Based Adjustment ---\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic bin balancing based on overall utilization\n    utilization_penalty_factor = 10.0  # Adjust penalty strength\n\n    if overall_utilization < 0.4:\n        # Encourage filling bins if overall utilization is low\n        target_utilization = 0.6\n    elif overall_utilization > 0.6:\n        # Discourage filling if bins are already full\n        target_utilization = 0.4\n    else:\n        target_utilization = 0.5\n\n    utilization_penalty = utilization_penalty_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # --- Item-Size-Aware Fullness Bonus ---\n    fullness_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Closer to full = higher bonus\n\n    # Adjust bonus based on item size and overall utilization\n    bonus_weight = (1 - overall_utilization) * (item / np.max(bins_remain_cap))  # Larger items get larger weight\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A refined priority function for online bin packing, incorporating dynamic\n    weighting based on fill levels, waste minimization, and bin balancing,\n    with enhancements for robustness and adaptability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adjusted Sensitivity:\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.001)**1.5 # Reduced exponent sensitivity\n\n    # 2. Dynamic Waste Minimization:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / np.max(bins_remain_cap)\n    waste_penalty = np.exp(5 * (waste_ratio - 0.25))  # Peak penalty around 25% waste\n    priorities[valid_bins] -= waste_penalty\n\n    # 3. Enhanced Bin Balancing with Adaptive Targets:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    target_utilization = 0.6  # Start with a moderate target\n\n    # Adjust the target utilization based on overall fill level:\n    if overall_utilization < 0.4:\n        target_utilization = 0.8  # Encourage higher filling if bins are sparse\n    elif overall_utilization > 0.8:\n        target_utilization = 0.3 # Keep adding new bins if we already have a lot of bins filled\n\n    balance_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= balance_penalty[valid_bins]\n    # 4. Adaptive Fullness Bonus with Sigmoid Weighting\n    fullness_level = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Max bonus for nearly full bins\n\n    # Sigmoid function to dynamically scale the bonus\n    sigmoid_weight = 1 / (1 + np.exp(10 * (overall_utilization - 0.5))) #sharp transition around 0.5\n    priorities[valid_bins] += 2 * sigmoid_weight * fullness_bonus[valid_bins]\n\n    # 5. Add a small randomization to break ties\n    priorities[valid_bins] += np.random.normal(0, 0.001, size=np.sum(valid_bins))\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component. This version incorporates a more nuanced\n    approach to bin balancing and waste management.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with bias towards more full bins (tunable exponent).\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**1.5 # Adjusted exponent\n\n    # Waste Minimization with dynamic penalty adjustment:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    waste_penalty_strength = 5.0 # Base waste penalty strength\n    if np.mean(bins_remain_cap) > 0.7: # Bins are relatively full\n        waste_penalty_strength = 10.0 # Increase penalty if bins are full\n\n    small_waste_penalty = np.exp(-waste_penalty_strength * waste_ratio)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing with a dynamic target utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    \n    # Dynamic target utilization:\n    target_utilization = 0.5\n    if overall_utilization < 0.4:\n        target_utilization = 0.6 #Encourage filling\n    elif overall_utilization > 0.6:\n        target_utilization = 0.4 #Discourage filling\n\n    #Adjust the scaling factor dynamically based on remaining bin capacities\n    scaling_factor = 10.0\n    if np.mean(bins_remain_cap) > 0.8:\n        scaling_factor = 20.0 # More aggressive balancing at high fill levels\n    elif np.mean(bins_remain_cap) < 0.2:\n        scaling_factor = 5.0 # Less aggressive balancing when bins are empty\n\n    extreme_utilization_penalty = scaling_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus with dynamic weighting:\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_weight = 1.0\n\n    if overall_utilization < 0.5:\n        bonus_weight = 2.0 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1.0 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n    \n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    # Add a small random component to break ties and encourage exploration\n    priorities[valid_bins] += 0.0001 * np.random.rand(np.sum(valid_bins))\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines FFD approximation, waste minimization, and capacity ratio.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    # FFD Approximation + Capacity Ratio\n    ratios = item / bins_remain_cap\n    priorities[valid_bins] = -np.log(ratios[valid_bins]) / (np.abs(bins_remain_cap[valid_bins] - item) + 0.0001) #Higher priority to close size\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}