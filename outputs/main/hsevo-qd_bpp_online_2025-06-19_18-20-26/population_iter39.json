[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + 0.0001)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities",
    "response_id": 7,
    "tryHS": true,
    "obj": 3.7295572397287686,
    "SLOC": 13.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 167.37179237410948,
    "mi": 76.13698564126598,
    "token_count": 155.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines FFD approximation, waste minimization, and capacity ratio.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    # FFD Approximation + Capacity Ratio\n    ratios = item / bins_remain_cap\n    priorities[valid_bins] = -np.log(ratios[valid_bins]) / (np.abs(bins_remain_cap[valid_bins] - item) + 0.0001) #Higher priority to close size\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 100.07820003461549,
    "mi": 92.3648299544325,
    "token_count": 113.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics, with refinements over v1:\n\n    1. **Best Fit Decreasing (BFD) Emphasis:**  Prioritizes bins that offer the *tightest* fit\n       for the current item, more aggressively than v1. Aims for optimal space utilization\n       in each bin, reducing fragmentation.\n\n    2.  **Waste Minimization (Adaptive):**  Penalizes small waste, but the penalty *scales*\n        with item size.  Large items creating small waste are penalized more heavily, as\n        that waste is harder to fill later.\n\n    3.  **Bin Balancing (Dynamic):**  Adjusts the utilization penalty based on the *overall*\n        fill level of all bins. If bins are generally empty, encourages filling them more;\n        if bins are generally full, focuses on avoiding small waste.\n\n    4. **Penalty for Over-Utilized Bins:** Add a bigger penalty if bins are almost full before placing the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Best Fit Decreasing Emphasis\n    size_diff = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Prioritize tight fits *much* more strongly than v1.\n    priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**2  # Squaring makes the difference more pronounced\n\n    # 2. Waste Minimization (Adaptive)\n    remaining_after_fit = bins_remain_cap - item\n    # Penalty scales with item size. Larger item = greater waste penalty\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Balancing (Dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Fraction full\n    overall_utilization = np.mean(utilization)  # Average fill level of all bins.\n\n    # Adjust penalty based on overall utilization.\n    if overall_utilization < 0.3: # If bins are generally empty.\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2) # Aim for 20% utilization.\n    elif overall_utilization > 0.7: # If bins are generally full.\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) # Aim for 80% utilization and avoid small waste\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Default penalty, same as v1.\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Penalty for Over-Utilized Bins:\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap) # Remaining cap is less than 10% of max cap\n    priorities[almost_full & valid_bins] -= 20 # Large penalty for almost full bins.\n\n    return priorities",
    "response_id": 1,
    "tryHS": true,
    "obj": 2.7223773434383682,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 417.82238611206157,
    "mi": 70.28388722131405,
    "token_count": 254.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_hs2.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                size_diff_epsilon: float = 0.0004976631192414565,\n                small_waste_penalty_factor: float = 13.759620087105052,\n                extreme_utilization_penalty_factor: float = 10.96255884116071,\n                target_utilization: float = 0.2781292500038949) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        size_diff_epsilon: A small constant added to size_diff to avoid division by zero.\n        small_waste_penalty_factor: Factor to control the strength of the small waste penalty.\n        extreme_utilization_penalty_factor: Factor to control the strength of the extreme utilization penalty.\n        target_utilization: The target utilization level (fraction full) for balancing.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + size_diff_epsilon)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-small_waste_penalty_factor * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = extreme_utilization_penalty_factor * np.abs(utilization - target_utilization) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 2.293577981651376,
    "SLOC": 18.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 201.90890672641936,
    "mi": 73.0359418375799,
    "token_count": 193.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive waste minimization, bin balancing, and fullness bonus with dynamic adjustments.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Adaptive Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item) # larger items, bigger penalty\n\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization)\n    \n    # Adaptive Waste Penalty Adjustment (Item size aware)\n    if item > 0.5: # large item\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    # Penalty for Over-Utilized Bins:\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap) # Remaining cap is less than 10% of max cap\n    priorities[almost_full & valid_bins] -= 20 # Large penalty for almost full bins.\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 1.3063422417231776,
    "SLOC": 21.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 481.14531818330875,
    "mi": 74.51436575562471,
    "token_count": 248.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization:  Discourage very small waste\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component:  Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 26.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 714.0,
    "mi": 76.47779028612874,
    "token_count": 331.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced priority function using best-fit, waste minimization, \n    dynamic bin balancing, and adaptive fullness bonus.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap)))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 201.90890672641936,
    "mi": 81.02705531297208,
    "token_count": 174.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response3.txt_stdout.txt",
    "code_path": "problem_iter9_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins.\n\n    This version incorporates adaptive parameter tuning and dynamic waste\n    thresholding for improved performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a small bias towards more full bins.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization: Discourage very small waste, adaptive threshold\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Dynamically adjust the small waste penalty strength based on item size.\n    waste_penalty_strength = 10 + 5 * item  # Larger items, stronger penalty for small waste\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.  Adaptive range.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        #Adaptive balancing: the closer to 0.5, the stronger the penalty\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n    fullness_threshold = 0.1  # Bins within 10% of being full receive bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    # Edge Case Handling: If all bins are nearly full, prioritize the one with the most remaining capacity\n    if np.all(bins_remain_cap[valid_bins] <= 0.1 * np.max(bins_remain_cap)):\n        priorities[valid_bins] += 10 * bins_remain_cap[valid_bins] # Prioritize largest remaining\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 34.0,
    "cyclomatic_complexity": 8.0,
    "halstead": 1123.9411016428899,
    "mi": 72.98556551981902,
    "token_count": 486.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, adaptive bin balancing, and fullness bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization)\n    \n    # Adaptive Waste Penalty Adjustment\n    if item > 0.5: # large item\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 27.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 690.6867720048776,
    "mi": 72.10964508066633,
    "token_count": 324.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that combines best-fit,\n    waste management, bin balancing, and learning components with adaptive\n    weighting based on real-time feedback and historical performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit Component with adaptive granularity\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # 2. Waste Minimization with dynamic penalty adjustment\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-15 * remaining_after_fit * item) # Increased sensitivity\n\n    # Adaptive penalty based on waste ratio and item size\n    penalty_weight = 1.0\n    if item > 0.5:  # Penalize small waste more for large items\n        penalty_weight = 2.0\n    elif item < 0.2: # Relax the small waste penalty for small items\n        penalty_weight = 0.5\n\n    priorities[valid_bins] -= penalty_weight * small_waste_penalty\n\n    # 3. Bin Balancing using utilization and overall utilization with adaptive target\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic target utilization based on overall utilization\n    target_utilization = 0.5\n    if overall_utilization < 0.3:\n        target_utilization = 0.2\n    elif overall_utilization > 0.7:\n        target_utilization = 0.8\n\n    extreme_utilization_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive component with dynamic bonus based on remaining capacity\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_weight = 1.0\n\n    # Adjust bonus weight based on overall utilization and item size\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n\n    # 5. Item-Size-Aware Adjustment: Favor bins that tightly fit larger items\n    if item > 0.6:\n      tight_fit_bonus = np.exp(-20*(bins_remain_cap[valid_bins]-item)**2)\n      priorities[valid_bins] += 0.7 * tight_fit_bonus # Encourage tight fits\n\n    # 6. Normalize priorities to avoid domination by any single factor\n    max_priority = np.max(priorities[np.isfinite(priorities)])\n    min_priority = np.min(priorities[np.isfinite(priorities)])\n\n    if max_priority > min_priority:\n        priorities[np.isfinite(priorities)] = (priorities[np.isfinite(priorities)] - min_priority) / (max_priority - min_priority)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 1.8847227762265748,
    "SLOC": 41.0,
    "cyclomatic_complexity": 9.0,
    "halstead": 854.8148496111509,
    "mi": 71.52025154971288,
    "token_count": 460.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response3.txt_stdout.txt",
    "code_path": "problem_iter15_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A refined priority function for online bin packing, incorporating dynamic\n    weighting based on fill levels, waste minimization, and bin balancing,\n    with enhancements for robustness and adaptability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adjusted Sensitivity:\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.001)**1.5 # Reduced exponent sensitivity\n\n    # 2. Dynamic Waste Minimization:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / np.max(bins_remain_cap)\n    waste_penalty = np.exp(5 * (waste_ratio - 0.25))  # Peak penalty around 25% waste\n    priorities[valid_bins] -= waste_penalty\n\n    # 3. Enhanced Bin Balancing with Adaptive Targets:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    target_utilization = 0.6  # Start with a moderate target\n\n    # Adjust the target utilization based on overall fill level:\n    if overall_utilization < 0.4:\n        target_utilization = 0.8  # Encourage higher filling if bins are sparse\n    elif overall_utilization > 0.8:\n        target_utilization = 0.3 # Keep adding new bins if we already have a lot of bins filled\n\n    balance_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= balance_penalty[valid_bins]\n    # 4. Adaptive Fullness Bonus with Sigmoid Weighting\n    fullness_level = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Max bonus for nearly full bins\n\n    # Sigmoid function to dynamically scale the bonus\n    sigmoid_weight = 1 / (1 + np.exp(10 * (overall_utilization - 0.5))) #sharp transition around 0.5\n    priorities[valid_bins] += 2 * sigmoid_weight * fullness_bonus[valid_bins]\n\n    # 5. Add a small randomization to break ties\n    priorities[valid_bins] += np.random.normal(0, 0.001, size=np.sum(valid_bins))\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 26.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 515.5128409106879,
    "mi": 73.22059112622787,
    "token_count": 311.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, fullness bonus, and item-size-aware penalty adjustments.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization (adaptive)\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing (dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus (adaptive)\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item size aware waste penalty adjustment\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    # Over-utilization Penalty (adaptive)\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Introduce a new adaptive parameter based on item size relative to bin capacity\n    item_ratio = item / np.max(bins_remain_cap)\n    if item_ratio > 0.6: # Item is relatively large\n        # Further discourage small waste in nearly full bins to avoid creating unusable bins\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins # less than 20% capacity\n        priorities[nearly_full] -= 10 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 1.3063422417231776,
    "SLOC": 19.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 267.35288832599804,
    "mi": 81.57963207298465,
    "token_count": 219.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that combines best-fit,\n    waste minimization, bin balancing, and an adaptive component.  It dynamically\n    adjusts the weights of different factors based on the fill level of the bins and\n    the size of the current item.  This version introduces a bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a bias towards more full bins (tuned).\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: Discourage very small and very large waste.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)  # Normalize by item size\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit) #Added to discourage very large waste\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)  # Discourage further filling\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)  # Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization and item size.\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n\n\n    #Bin Activation Strategy:  Prioritize empty or near-empty bins for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)  #High bonus for emptier bins\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 1.0071798962903893,
    "SLOC": 31.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 893.4536344224329,
    "mi": 73.65715298771948,
    "token_count": 432.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response5.txt_stdout.txt",
    "code_path": "problem_iter20_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, adaptive fullness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap)))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 39.0,
    "cyclomatic_complexity": 9.0,
    "halstead": 1200.9928228209899,
    "mi": 70.6556751905319,
    "token_count": 511.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response1.txt_stdout.txt",
    "code_path": "problem_iter21_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An adaptive priority function that dynamically adjusts its strategy based on\n    the item size relative to bin capacities and the overall bin utilization.\n    It prioritizes bins considering best-fit, waste minimization, bin balancing,\n    and a dynamic bonus for almost-full bins, with adaptive weight adjustments.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Overall utilization of the bins\n    total_capacity = np.sum(bins_remain_cap) + np.sum(bins_remain_cap[~valid_bins] + item) * np.sum(bins_remain_cap >= item)\n    overall_utilization = 1 - np.sum(bins_remain_cap) / total_capacity if total_capacity > 0 else 0\n\n    # Item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.sum(bins_remain_cap > 0) > 0 else 1 # Avoid zero division\n    item_size_ratio = item / avg_bin_capacity\n\n    # Best-Fit component with adaptive scaling\n    size_diff = bins_remain_cap - item\n    best_fit_priority = 1.0 / (size_diff[valid_bins] + 0.0001)**2\n    priorities[valid_bins] += best_fit_priority * (1 + overall_utilization) #Scale by fill level\n\n    # Waste Minimization: Discourage very small waste dynamically\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty * (1 - overall_utilization) #Scale by fill level\n\n    # Bin Balancing using utilization, adaptively adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins] * (1 + item_size_ratio) #Scale by item size\n\n    # Adaptive bonus for bins close to full, with dynamic weighting\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n     # Item size adjustment: Small items get more bonus\n    item_size_bonus_multiplier = 1 + (1 - item_size_ratio)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins] * item_size_bonus_multiplier\n\n    # Edge case handling: If no bin is suitable, slightly relax best-fit preference\n    if np.all(priorities == -np.inf):\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        valid_bins = bins_remain_cap > 0\n        if np.any(valid_bins):\n            size_diff = bins_remain_cap - item\n            size_diff[size_diff < 0] = np.inf  # Consider the overflow when calculating the best-fit\n            priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**0.5 # Relaxed exponent\n        else: # Very rare case: All bins are full\n            priorities = np.ones_like(bins_remain_cap) #All bins have equal priority\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 1.0470682090147587,
    "SLOC": 28.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 840.8905232169438,
    "mi": 74.15810086834435,
    "token_count": 406.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response3.txt_stdout.txt",
    "code_path": "problem_iter23_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, waste minimization, bin balancing, and dynamic adjustments.\n    It adapts weights based on bin fill levels and item size, handling edge cases.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit with emphasis on closer sizes\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: adaptive penalty\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit)\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n    # Bin Balancing: dynamic adjustment\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive bonus for nearly full bins\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n\n    # Bin Activation for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 1.0071798962903893,
    "SLOC": 21.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 393.0790765418854,
    "mi": 75.12911686253278,
    "token_count": 237.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response2.txt_stdout.txt",
    "code_path": "problem_iter24_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that adapts based on\n    bin fill levels, item sizes, and waste characteristics. It aims to\n    balance best-fit, waste minimization, and bin utilization, while\n    dynamically adjusting parameters based on problem state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # --- Best-Fit Component with Size-Aware Adjustment ---\n    size_diff = bins_remain_cap - item\n    # Normalize size difference by item size for relative fit\n    normalized_size_diff = size_diff / item\n    priorities[valid_bins] += 1.0 / (normalized_size_diff[valid_bins]**2 + 0.0001)\n\n\n    # --- Waste Minimization with Dynamic Waste Threshold ---\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Adaptive waste threshold based on item size (e.g., no waste > item/2)\n    waste_threshold = item / 2.0\n    waste_penalty_factor = 5.0  # Adjust penalty strength\n    waste_penalty = np.where(remaining_after_fit > 0, np.exp(waste_penalty_factor * (remaining_after_fit - waste_threshold)), 0)\n    priorities[valid_bins] -= waste_penalty\n\n    # --- Bin Balancing and Utilization-Based Adjustment ---\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic bin balancing based on overall utilization\n    utilization_penalty_factor = 10.0  # Adjust penalty strength\n\n    if overall_utilization < 0.4:\n        # Encourage filling bins if overall utilization is low\n        target_utilization = 0.6\n    elif overall_utilization > 0.6:\n        # Discourage filling if bins are already full\n        target_utilization = 0.4\n    else:\n        target_utilization = 0.5\n\n    utilization_penalty = utilization_penalty_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # --- Item-Size-Aware Fullness Bonus ---\n    fullness_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Closer to full = higher bonus\n\n    # Adjust bonus based on item size and overall utilization\n    bonus_weight = (1 - overall_utilization) * (item / np.max(bins_remain_cap))  # Larger items get larger weight\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 6.0,
    "halstead": 720.805885899824,
    "mi": 77.5501271955363,
    "token_count": 345.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response3.txt_stdout.txt",
    "code_path": "problem_iter26_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, and adaptive fullness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component (similar to FFD approximation)\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Adaptive Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    overall_utilization = np.mean(1 - (bins_remain_cap / np.max(bins_remain_cap)))\n    waste_penalty_factor = 10 * (1 + overall_utilization)  # Adjust based on overall utilization\n    small_waste_penalty = np.exp(-waste_penalty_factor * remaining_after_fit * item) #item aware and utilization aware\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) # Penalize bins that have utilization far from 0.5 (half full)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap)))\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 36.0,
    "cyclomatic_complexity": 8.0,
    "halstead": 1080.3016444496104,
    "mi": 67.7054551757189,
    "token_count": 454.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter27_response4.txt_stdout.txt",
    "code_path": "problem_iter27_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that dynamically adjusts\n    its behavior based on the item size relative to the average remaining\n    bin capacity, incorporating best-fit, waste minimization, bin balancing,\n    and dynamic adjustment of weights to promote robustness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive weighting based on item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap)\n    item_ratio = item / avg_bin_capacity\n\n    # Best-Fit component, scaled dynamically.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += (1.0 / (size_diff[valid_bins] + 0.0001)**2) * (1 + item_ratio)\n\n    # Waste Minimization: Discourage very small waste, dynamically penalized.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty_factor = 10 + 5 * item_ratio  # Higher penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_factor * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization and overall utilization: Dynamically adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic Bin Balancing with sharper penalties\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.2) * (1 + item_ratio)  # Encourage filling more aggressively\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 20 * np.abs(utilization - 0.8) * (1 + item_ratio) #Discourage further filling more aggressively\n    else:\n        extreme_utilization_penalty = 12 * np.abs(utilization - 0.5) * (1 + item_ratio)  #Balance, more sensitive\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Bonus to bins close to full, dynamically adjusted.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_scaling = 2 * (1 - overall_utilization) * (1 + item_ratio)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += bonus_scaling * fullness_bonus[valid_bins]\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  0.75 * bonus_scaling * fullness_bonus[valid_bins]  #Reduced bonus compared to v1\n    else:\n        priorities[valid_bins] += 0.25 * bonus_scaling * fullness_bonus[valid_bins] #further reduced bonus\n\n    # Edge Case Handling: Favor bins close to item size, but not too close to full capacity\n    close_to_item = np.abs(bins_remain_cap - item) / item\n    close_to_full = bins_remain_cap / np.max(bins_remain_cap)\n\n    edge_case_bonus = np.exp(-5 * close_to_item)  * (close_to_full > 0.1) # boost bins with remain capacity close to item and not close to full\n    priorities[valid_bins] += 0.5 * edge_case_bonus[valid_bins]\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 1.0869565217391397,
    "SLOC": 34.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1180.7647140463193,
    "mi": 73.368720497872,
    "token_count": 443.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response4.txt_stdout.txt",
    "code_path": "problem_iter29_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, bin balancing, and adaptive bonus.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing using utilization\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic bin balancing\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive bonus for almost-full bins\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 23.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 363.55973856504056,
    "mi": 71.4549904794808,
    "token_count": 241.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter30_response0.txt_stdout.txt",
    "code_path": "problem_iter30_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component. This version incorporates a more nuanced\n    approach to bin balancing and waste management.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with bias towards more full bins (tunable exponent).\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**1.5 # Adjusted exponent\n\n    # Waste Minimization with dynamic penalty adjustment:\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    waste_penalty_strength = 5.0 # Base waste penalty strength\n    if np.mean(bins_remain_cap) > 0.7: # Bins are relatively full\n        waste_penalty_strength = 10.0 # Increase penalty if bins are full\n\n    small_waste_penalty = np.exp(-waste_penalty_strength * waste_ratio)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing with a dynamic target utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    \n    # Dynamic target utilization:\n    target_utilization = 0.5\n    if overall_utilization < 0.4:\n        target_utilization = 0.6 #Encourage filling\n    elif overall_utilization > 0.6:\n        target_utilization = 0.4 #Discourage filling\n\n    #Adjust the scaling factor dynamically based on remaining bin capacities\n    scaling_factor = 10.0\n    if np.mean(bins_remain_cap) > 0.8:\n        scaling_factor = 20.0 # More aggressive balancing at high fill levels\n    elif np.mean(bins_remain_cap) < 0.2:\n        scaling_factor = 5.0 # Less aggressive balancing when bins are empty\n\n    extreme_utilization_penalty = scaling_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus with dynamic weighting:\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_weight = 1.0\n\n    if overall_utilization < 0.5:\n        bonus_weight = 2.0 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1.0 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n    \n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    # Add a small random component to break ties and encourage exploration\n    priorities[valid_bins] += 0.0001 * np.random.rand(np.sum(valid_bins))\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.367770243318703,
    "SLOC": 36.0,
    "cyclomatic_complexity": 7.0,
    "halstead": 1273.7831785421156,
    "mi": 70.8110431095427,
    "token_count": 476.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter32_response6.txt_stdout.txt",
    "code_path": "problem_iter32_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive waste management, bin balancing, and item-size awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Adaptive Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty_strength = 10 + 5 * item\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Dynamic Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        balancing_strength = 10 + 5 * abs(overall_utilization - 0.5)\n        extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_threshold = 0.1\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item-size aware adjustment and small-waste penalty\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins\n        priorities[nearly_full] -= 5 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 0.8875149581172807,
    "SLOC": 38.0,
    "cyclomatic_complexity": 8.0,
    "halstead": 1527.946756958329,
    "mi": 66.65773726667774,
    "token_count": 529.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter33_response3.txt_stdout.txt",
    "code_path": "problem_iter33_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function that adapts to the problem state by\n    analyzing bin capacity distribution and item size relative to bin sizes.\n    It uses a multi-faceted approach combining best-fit, waste minimization,\n    and bin balancing with dynamically adjusted weights.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adaptive Granularity:\n    #   - Emphasize finer granularity when bins are mostly empty; coarser when mostly full.\n    size_diff = bins_remain_cap - item\n    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)\n    granularity_factor = np.mean(capacity_ratio)  # Dynamic granularity adjustment\n    priorities[valid_bins] += (1 / (size_diff[valid_bins] + 0.0001)**(granularity_factor + 1))\n\n    # 2. Dynamic Waste Minimization:\n    #   - Adjust the small waste penalty based on item size and remaining capacity.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]\n    item_size_factor = item / np.max(bins_remain_cap)  # Normalize item size\n\n    waste_penalty_strength = 5 + 10 * item_size_factor  # Stronger penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # 3. Bin Balancing with Capacity Distribution Awareness:\n    #   - Instead of a single overall utilization, consider the distribution of bin capacities.\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    capacity_std = np.std(bins_remain_cap)  # Measure capacity variance\n    capacity_mean = np.mean(bins_remain_cap)\n\n    #   - Adjust balancing based on capacity distribution.\n    if capacity_std < 0.1 * capacity_mean:  # Bins are relatively uniform\n        balancing_strength = 10  # Strong balancing\n    else:\n        balancing_strength = 5  # Moderate balancing\n\n    #   - More penalty for bins that are too full or empty\n    extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive Fullness Bonus:\n    #   - Bonus for bins that are close to full, adjusted based on remaining capacity.\n    fullness_level = 1 - capacity_ratio\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Close to full = high bonus\n    bonus_strength = 1 + 5 * item_size_factor  # Larger items, higher bonus\n\n    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))\n\n    # 5. Edge Case Handling:  Favor bins close to full if item is large relative to available space\n    large_item_threshold = 0.75  # Item size relative to bin capacity\n\n    if item_size_factor > large_item_threshold:\n        almost_full_bins = bins_remain_cap >= item\n        almost_full_bins = np.logical_and(almost_full_bins, bins_remain_cap < (item + 0.1 * np.max(bins_remain_cap)) )\n        priorities[almost_full_bins] += 10 # Strong encouragement for nearly full bins to take large items\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 3.709613083366578,
    "SLOC": 21.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 633.5916718909912,
    "mi": 74.73050172963595,
    "token_count": 320.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter35_response1.txt_stdout.txt",
    "code_path": "problem_iter35_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive best-fit, dynamic bin balancing, waste control. Scales penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit: Prioritize tight fits.\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Adaptive Waste Minimization: Scale penalty with item size.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= waste_penalty\n\n    # Dynamic Bin Balancing based on overall utilization.\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # Over-utilization Penalty: Large penalty for almost-full bins.\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Adaptive bonus for almost full bins based on overall util.\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 1.3063422417231776,
    "SLOC": 31.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 799.4671255356087,
    "mi": 72.71133500664065,
    "token_count": 361.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter36_response0.txt_stdout.txt",
    "code_path": "problem_iter36_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins. This version includes\n    a more sophisticated waste penalty and dynamic adjustment of the best-fit component.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive Best-Fit:\n    # Adjust the strength of best-fit based on the item size relative to average bin capacity.\n    avg_bin_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0\n    best_fit_strength = 1.0 + 2.0 * (item / avg_bin_capacity)  # Stronger for larger items\n\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += best_fit_strength / (size_diff[valid_bins] + 0.0001)**2\n\n\n    # Enhanced Waste Minimization:  Discourage small waste and encourage almost full bins\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Sigmoid-shaped penalty to aggressively penalize very small waste\n    waste_penalty_scale = 10.0\n    waste_penalty = 1.0 / (1 + np.exp(waste_penalty_scale * (remaining_after_fit - 0.05)))  # Push for less than 5% waste\n\n    priorities[valid_bins] -= waste_penalty\n\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component:  Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 1.0271240526525796,
    "SLOC": 23.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 641.2080923804407,
    "mi": 81.03931218720587,
    "token_count": 284.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter38_response1.txt_stdout.txt",
    "code_path": "problem_iter38_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, waste minimization, bin balancing, and adaptive weights based on problem state.\n    Prioritizes bins dynamically for effective online bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive Best-Fit\n    size_diff = bins_remain_cap - item\n    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)\n    granularity_factor = np.mean(capacity_ratio)\n    priorities[valid_bins] += (1 / (size_diff[valid_bins] + 0.0001)**(granularity_factor + 1))\n\n    # Dynamic Waste Minimization\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]\n    item_size_factor = item / np.max(bins_remain_cap)\n    waste_penalty_strength = 5 + 10 * item_size_factor\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive Fullness Bonus\n    fullness_level = 1 - capacity_ratio\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))\n    bonus_strength = 1 + 5 * item_size_factor\n    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 1.0670123653769492,
    "SLOC": 21.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 389.9215698394069,
    "mi": 80.17391897006937,
    "token_count": 241.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter39_response4.txt_stdout.txt",
    "code_path": "problem_iter39_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A dynamic priority function for online bin packing that combines best-fit,\n    waste management, bin balancing, a learning component, and considers item sizes.\n    It prioritizes bins based on a weighted combination of factors, including\n    space utilization, waste minimization, bin balancing, item size influence,\n    and dynamic weight adjustments based on fill level and item size distribution.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit component with a dynamic bias towards fuller bins\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # 2. Waste Minimization: Discourage very small waste, consider item size\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # 3. Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # 4. Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) # Discourage further filling\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) # Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 5. Adaptive component: Add a bonus to bins close to full\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)  # more bonus to almost full bins\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += fullness_bonus[valid_bins] * (1 - overall_utilization)  # more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)  # even lower bonus\n    \n    # 6. Item Size Consideration: Penalize bins with remaining capacity close to item size\n    # if the item is relatively large.\n\n    normalized_item_size = item / np.max(bins_remain_cap)\n    if normalized_item_size > 0.5:\n        close_fit_penalty = np.exp(-20 * np.abs(bins_remain_cap[valid_bins] - item) / np.max(bins_remain_cap))\n        priorities[valid_bins] -= 2 * close_fit_penalty * normalized_item_size\n    \n    # 7. Dynamic Adjustment of Best-Fit Weight Based on Item Size\n    best_fit_weight = 1.0\n    if normalized_item_size > 0.7:\n        best_fit_weight = 0.5 #reduce weight\n    elif normalized_item_size < 0.3:\n        best_fit_weight = 1.5\n    \n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += best_fit_weight / (size_diff[valid_bins] + 0.0001)**2\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 0.9274032708416502,
    "SLOC": 37.0,
    "cyclomatic_complexity": 8.0,
    "halstead": 1055.353632766602,
    "mi": 72.52188391544468,
    "token_count": 449.0,
    "exec_success": true
  }
]