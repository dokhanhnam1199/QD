```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Enhanced priority function that incorporates dynamic adaptation, multi-factor integration,
    and problem state awareness for improved bin packing.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # Best-Fit with Dynamic Size Difference Adjustment
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.3 / (size_diff[valid_bins] + 0.0001)**1.6  # Increased exponent and factor

    # Waste Minimization with Adaptive Waste Thresholds
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    mean_remaining = np.mean(bins_remain_cap)
    waste_threshold_small = 0.1 * mean_remaining  # Adaptive threshold
    waste_threshold_large = 0.6 * mean_remaining

    small_waste_penalty = np.where(remaining_after_fit < waste_threshold_small,
                                   np.exp(-8 * remaining_after_fit / item), 0)
    large_waste_penalty = np.where(remaining_after_fit > waste_threshold_large,
                                   np.exp(-3 * item / remaining_after_fit), 0)
    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.7

    # Bin Balancing with Problem State Awareness
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)
    max_bin_capacity = np.max(bins_remain_cap)

    if overall_utilization < 0.35:
        extreme_utilization_penalty = 6 * np.abs(utilization - 0.25)  # Tuned parameters
    elif overall_utilization > 0.75:
        extreme_utilization_penalty = 15 * np.abs(utilization - 0.85)  # Tuned parameters
    else:
        extreme_utilization_penalty = 9 * np.abs(utilization - 0.55)  # Tuned parameters
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # Adaptive Bonus for Nearly Full Bins
    fullness_target = 0.15  # Target fullness for bonus
    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / max_bin_capacity - fullness_target))

    if overall_utilization < 0.55:
        priorities[valid_bins] += 1.6 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item / max_bin_capacity) # Tuned parameters
    elif overall_utilization < 0.85:
        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item / max_bin_capacity) # Tuned parameters
    else:
        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item / max_bin_capacity) # Tuned parameters

    # Bin Activation with Dynamic Threshold for Large Items
    large_item_threshold = 0.55 * max_bin_capacity  # Reduced threshold
    if item > large_item_threshold:
        empty_bin_bonus = np.exp(-1.8 * utilization)
        priorities[valid_bins] += 1.6 * empty_bin_bonus[valid_bins]

    # Diversification: Random Noise Injection (exploration)
    if np.random.rand() < 0.05:  # 5% probability of exploration
        priorities[valid_bins] += np.random.normal(0, 0.1, np.sum(valid_bins))

    return priorities
```
