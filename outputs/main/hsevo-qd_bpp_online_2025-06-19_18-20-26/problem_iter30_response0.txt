```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An enhanced priority function for online bin packing that combines
    best-fit considerations with dynamic waste management, bin balancing,
    and a learning component. This version incorporates a more nuanced
    approach to bin balancing and waste management.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # Best-Fit component with bias towards more full bins (tunable exponent).
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**1.5 # Adjusted exponent

    # Waste Minimization with dynamic penalty adjustment:
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / item
    waste_penalty_strength = 5.0 # Base waste penalty strength
    if np.mean(bins_remain_cap) > 0.7: # Bins are relatively full
        waste_penalty_strength = 10.0 # Increase penalty if bins are full

    small_waste_penalty = np.exp(-waste_penalty_strength * waste_ratio)
    priorities[valid_bins] -= small_waste_penalty

    # Bin Balancing with a dynamic target utilization:
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)
    
    # Dynamic target utilization:
    target_utilization = 0.5
    if overall_utilization < 0.4:
        target_utilization = 0.6 #Encourage filling
    elif overall_utilization > 0.6:
        target_utilization = 0.4 #Discourage filling

    #Adjust the scaling factor dynamically based on remaining bin capacities
    scaling_factor = 10.0
    if np.mean(bins_remain_cap) > 0.8:
        scaling_factor = 20.0 # More aggressive balancing at high fill levels
    elif np.mean(bins_remain_cap) < 0.2:
        scaling_factor = 5.0 # Less aggressive balancing when bins are empty

    extreme_utilization_penalty = scaling_factor * np.abs(utilization - target_utilization)
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # Adaptive Fullness Bonus with dynamic weighting:
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))
    bonus_weight = 1.0

    if overall_utilization < 0.5:
        bonus_weight = 2.0 * (1 - overall_utilization)
    elif overall_utilization < 0.8:
        bonus_weight = 1.0 * (1 - overall_utilization)
    else:
        bonus_weight = 0.5 * (1 - overall_utilization)
    
    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]

    # Add a small random component to break ties and encourage exploration
    priorities[valid_bins] += 0.0001 * np.random.rand(np.sum(valid_bins))

    return priorities
```
