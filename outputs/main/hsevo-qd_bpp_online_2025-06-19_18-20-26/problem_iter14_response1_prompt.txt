{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A dynamic priority function for online bin packing that combines best-fit,\n    waste management, bin balancing, and learning components with adaptive\n    weighting based on real-time feedback and historical performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit Component with adaptive granularity\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # 2. Waste Minimization with dynamic penalty adjustment\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-15 * remaining_after_fit * item) # Increased sensitivity\n\n    # Adaptive penalty based on waste ratio and item size\n    penalty_weight = 1.0\n    if item > 0.5:  # Penalize small waste more for large items\n        penalty_weight = 2.0\n    elif item < 0.2: # Relax the small waste penalty for small items\n        penalty_weight = 0.5\n\n    priorities[valid_bins] -= penalty_weight * small_waste_penalty\n\n    # 3. Bin Balancing using utilization and overall utilization with adaptive target\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic target utilization based on overall utilization\n    target_utilization = 0.5\n    if overall_utilization < 0.3:\n        target_utilization = 0.2\n    elif overall_utilization > 0.7:\n        target_utilization = 0.8\n\n    extreme_utilization_penalty = 10 * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive component with dynamic bonus based on remaining capacity\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    bonus_weight = 1.0\n\n    # Adjust bonus weight based on overall utilization and item size\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n\n    # 5. Item-Size-Aware Adjustment: Favor bins that tightly fit larger items\n    if item > 0.6:\n      tight_fit_bonus = np.exp(-20*(bins_remain_cap[valid_bins]-item)**2)\n      priorities[valid_bins] += 0.7 * tight_fit_bonus # Encourage tight fits\n\n    # 6. Normalize priorities to avoid domination by any single factor\n    max_priority = np.max(priorities[np.isfinite(priorities)])\n    min_priority = np.min(priorities[np.isfinite(priorities)])\n\n    if max_priority > min_priority:\n        priorities[np.isfinite(priorities)] = (priorities[np.isfinite(priorities)] - min_priority) / (max_priority - min_priority)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                size_diff_epsilon: float = 0.0004976631192414565,\n                small_waste_penalty_factor: float = 13.759620087105052,\n                extreme_utilization_penalty_factor: float = 10.96255884116071,\n                target_utilization: float = 0.2781292500038949) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics:\n\n    1.  **First Fit Decreasing (FFD) Approximation:** Bins closer in size to the item\n        (but still large enough) get higher priority.  This approximates the FFD\n        algorithm which is known to be reasonably effective.\n\n    2.  **Waste Minimization:**  Penalizes bins where the item leaves a very small\n        remaining capacity (high waste). This is crucial in online scenarios where\n        future items might fit perfectly into larger waste spaces.\n\n    3.  **Bin Utilization Balance:** Bins that are very empty or almost full are\n        slightly penalized to encourage mid-range utilization, promoting a more\n        balanced distribution of items across bins. This aims to avoid creating\n        bins that are almost full with one item.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        size_diff_epsilon: A small constant added to size_diff to avoid division by zero.\n        small_waste_penalty_factor: Factor to control the strength of the small waste penalty.\n        extreme_utilization_penalty_factor: Factor to control the strength of the extreme utilization penalty.\n        target_utilization: The target utilization level (fraction full) for balancing.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. First Fit Decreasing Approximation (size proximity)\n    size_diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (size_diff + size_diff_epsilon)  # Avoid division by zero and give preference to bins closest to item size. Small constant added to size_diff\n\n    # Consider only bins with sufficient capacity\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 2. Waste Minimization Penalty\n    remaining_after_fit = bins_remain_cap - item\n    small_waste_penalty = np.exp(-small_waste_penalty_factor * remaining_after_fit)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Utilization Balance Penalty (U-shaped utilization preference)\n    utilization = (1 - (bins_remain_cap / np.max(bins_remain_cap)))  # Fraction full, range [0, 1] where 1 is empty and 0 is full\n    extreme_utilization_penalty = extreme_utilization_penalty_factor * np.abs(utilization - target_utilization) # Penalize bins that have utilization far from 0.5 (half full)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see the best heuristic incorporates best-fit, waste minimization, bin balancing and adaptive bonus and the worst one only uses log ratios.\n*   (2nd) vs (19th): Similar to above.\n*   Comparing (1st) vs (2nd), the best heuristic includes dynamic waste management, adaptive parameter tuning and edge case handling while the second one does not. The first one also dynamically adjusts the small waste penalty strength based on item size.\n*   (3rd) vs (4th): The third one incorporates an adaptive waste penalty adjustment for large items when the overall utilization is high.\n*   Comparing (second worst) vs (worst), the second worst has the same implementation but more import statements.\n*   Comparing (15th) vs (16th): (15th) adds a penalty for over-utilized bins, scaling waste minimization with item size and dynamic bin balancing while (16th) lacks these features. (16th) also has a simpler waste minimization calculation without scaling with item size. (16th) has no dynamic adjustment in bin balancing\n*   Comparing (1st) vs (6th): The first heuristic incorporates dynamic waste management and adaptive tuning and adaptive waste thresholding while the other includes dynamic penalty adjustment, adaptive weighting and normalization. The first one incorporates Edge Case Handling while the (6th) one has Item-Size-Aware Adjustment.\n*   (10th) vs (11th): The tenth one is the same as the eleventh.\n*   Overall: The better heuristics include more adaptive components (dynamic waste management, adaptive parameter tuning, adaptive weighting), handle edge cases, and normalize priorities to prevent single factor domination. Simpler heuristics primarily rely on basic best-fit and waste minimization, lacking dynamic adjustments.\n- \nOkay, let's refine \"Current Self-Reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection\" and aiming for actionable insights.\n\n*   **Keywords:** Adaptive heuristics, dynamic adjustment, multiple factors, robust handling, normalization, scaling, feedback.\n*   **Advice:** Design heuristics that dynamically adapt to problem state through feedback mechanisms. Integrate relevant factors with thoughtful weighting and normalization.\n*   **Avoid:** Generic statements about \"best-fit strategies\" without specifying *how* they adapt or integrate. Avoid focusing solely on bin packing specifics if you seek general principles.\n*   **Explanation:** Move beyond simply *stating* the need for adaptation; focus on the *mechanisms* by which adaptation happens (e.g., real-time performance data, input characteristics). Prioritize adaptability and robust handling.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}