{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    An enhanced priority function for online bin packing, incorporating dynamic adaptation,\n    multi-factor integration, and problem state awareness. It addresses limitations in prior\n    versions by dynamically adjusting penalties and bonuses based on overall bin utilization,\n    item size relative to bin capacity, and the resulting waste.  This version includes a mechanism for diversification to escape local optima and an adaptive bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    overall_utilization = 1 - np.mean(bins_remain_cap / max_bin_cap)\n\n    # Best-Fit with Adaptive Sensitivity\n    size_diff = bins_remain_cap - item\n    best_fit_scale = 1.2 + 0.8 * overall_utilization  # Dynamically adjust based on utilization\n    priorities[valid_bins] += best_fit_scale / (size_diff[valid_bins] + 0.0001)**1.5\n\n    # Waste Minimization with Dynamic Penalties\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / item\n    small_waste_penalty = np.exp(-7 * waste_ratio)\n    large_waste_penalty = np.exp(-4 / waste_ratio) #Inverted to give exponentially decaying penalty for large waste\n    waste_penalty_weight = 0.6 + 0.4 * overall_utilization  # Increase penalty with higher utilization\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * waste_penalty_weight\n\n    # Bin Balancing with Adaptive Adjustment\n    utilization = 1 - (bins_remain_cap / max_bin_cap)\n    extreme_utilization_penalty = np.zeros_like(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 14 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 8 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus with Dynamic Scaling based on item size and overall utilization\n    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / max_bin_cap - 0.1))\n    fullness_bonus_scale = (1 - overall_utilization) * (item / max_bin_cap)\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.5 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.8 * fullness_bonus[valid_bins] * fullness_bonus_scale\n    else:\n        priorities[valid_bins] += 0.3 * fullness_bonus[valid_bins] * fullness_bonus_scale\n\n    # Bin Activation Bonus for Large Items with Utilization Awareness\n    if item > 0.6 * max_bin_cap:\n        empty_bin_bonus = np.exp(-2 * utilization)\n        #Scale activation bonus to be stronger if bins are empty\n        activation_bonus_scale = 1.5 + 2*(1-overall_utilization)\n        priorities[valid_bins] += activation_bonus_scale * empty_bin_bonus[valid_bins]\n\n    #Diversification Heuristic (Escape Local Optima)\n    if np.random.rand() < 0.05: #5% chance of diversifying\n        priorities[valid_bins] += np.random.normal(0, 0.1, np.sum(valid_bins)) #Add small random noise\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    An adaptive priority function that dynamically adjusts its strategy based on\n    the item size relative to bin capacities and the overall bin utilization.\n    It prioritizes bins considering best-fit, waste minimization, bin balancing,\n    and a dynamic bonus for almost-full bins, with adaptive weight adjustments.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Overall utilization of the bins\n    total_capacity = np.sum(bins_remain_cap) + np.sum(bins_remain_cap[~valid_bins] + item) * np.sum(bins_remain_cap >= item)\n    overall_utilization = 1 - np.sum(bins_remain_cap) / total_capacity if total_capacity > 0 else 0\n\n    # Item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.sum(bins_remain_cap > 0) > 0 else 1 # Avoid zero division\n    item_size_ratio = item / avg_bin_capacity\n\n    # Best-Fit component with adaptive scaling\n    size_diff = bins_remain_cap - item\n    best_fit_priority = 1.0 / (size_diff[valid_bins] + 0.0001)**2\n    priorities[valid_bins] += best_fit_priority * (1 + overall_utilization) #Scale by fill level\n\n    # Waste Minimization: Discourage very small waste dynamically\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty * (1 - overall_utilization) #Scale by fill level\n\n    # Bin Balancing using utilization, adaptively adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins] * (1 + item_size_ratio) #Scale by item size\n\n    # Adaptive bonus for bins close to full, with dynamic weighting\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n     # Item size adjustment: Small items get more bonus\n    item_size_bonus_multiplier = 1 + (1 - item_size_ratio)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins] * item_size_bonus_multiplier\n\n    # Edge case handling: If no bin is suitable, slightly relax best-fit preference\n    if np.all(priorities == -np.inf):\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        valid_bins = bins_remain_cap > 0\n        if np.any(valid_bins):\n            size_diff = bins_remain_cap - item\n            size_diff[size_diff < 0] = np.inf  # Consider the overflow when calculating the best-fit\n            priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**0.5 # Relaxed exponent\n        else: # Very rare case: All bins are full\n            priorities = np.ones_like(bins_remain_cap) #All bins have equal priority\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see that the best heuristic uses a combination of best-fit, waste minimization, bin balancing, and adaptive weights, while the worst uses only the ratio of item size to remaining bin capacity.\n*   Comparing (2nd) vs (19th), we see that the second-best heuristic incorporates adaptive adjustments and problem-state awareness. In contrast, the second-worst heuristic combines FFD approximation, waste minimization, and capacity ratio but lacks adaptive weighting.\n*   Comparing (1st) vs (2nd), we don't see any differences because they're exactly the same.\n*   Comparing (3rd) vs (4th), we don't see any differences because they're exactly the same.\n*   Comparing (second worst) vs (worst), we see that the second worst adds waste minimization. Overall: adaptive weights and dynamic adjustments based on problem state appear crucial for superior performance. Best-fit, waste minimization, and bin balancing are common components. Simpler heuristics that only consider capacity ratios tend to perform worse. Furthermore, edge case handling and diversification are also valuable. Normalizing the final priorities is important for stable and comparable results.\n- \nOkay, let's refine \"Current Self-Reflection\" to design better heuristics, focusing on actionability and avoiding the pitfalls of ineffective reflections. We'll structure this to be immediately useful for design.\n\n*   **Keywords:** Problem state awareness, dynamic adaptation, feedback integration, multi-faceted evaluation.\n\n*   **Advice:** Focus on creating heuristics that *actively monitor* the problem state (e.g., bin utilization distribution, item size statistics, solution progress) and *dynamically adjust* their behavior based on this information. Build in mechanisms for the heuristic to \"learn\" during its execution and modify its strategy accordingly. Use multi-faceted evaluation of solutions, not just single metrics.\n\n*   **Avoid:** Vague statements about \"considering multiple factors\" or \"handling edge cases\" without specifying *how* this will be achieved. Avoid simply reiterating known strategies without proposing novel adaptations or combinations. Avoid superficial mentions of \"dynamic adjustment\" without detailing the specific adaptation mechanisms.\n\n*   **Explanation:** The key to effective self-reflection for heuristic design is to move beyond general principles and focus on concrete mechanisms for observation, adaptation, and evaluation. Aim to design heuristics that are genuinely *responsive* to the evolving problem state, not just statically defined with a few adjustable parameters.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}