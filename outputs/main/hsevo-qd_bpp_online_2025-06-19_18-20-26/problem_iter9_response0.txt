```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A refined priority function for online bin packing, incorporating dynamic
    parameter adjustment, improved waste management, and adaptive bin balancing
    based on real-time performance. It prioritizes bins based on a weighted
    combination of factors, with weights dynamically adjusted based on the
    overall fill level of the bins and a moving average of bin utilization.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit Component with Dynamic Sensitivity:
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**1.5  # Adjusted exponent

    # 2. Enhanced Waste Minimization:  Adaptive penalty for small waste
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_threshold = 0.1  # Dynamic waste threshold based on item size, can make it item * 0.2
    small_waste_penalty = np.where(remaining_after_fit < waste_threshold,
                                   np.exp(-20 * remaining_after_fit / (item + 0.001)),
                                   0)  # Higher penalty for very small waste
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing with Adaptive Utilization Targets:
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    # Dynamic target utilization based on a simple moving average
    if not hasattr(priority_v2, "utilization_history"):
        priority_v2.utilization_history = [overall_utilization] * 5  # Initialize history

    priority_v2.utilization_history.append(overall_utilization)
    if len(priority_v2.utilization_history) > 5:
        priority_v2.utilization_history.pop(0)  # Keep a fixed-size history
    moving_avg_utilization = np.mean(priority_v2.utilization_history)

    target_utilization = 0.6 if item > 0.5 else 0.7 #item size based target

    if moving_avg_utilization < 0.4:
        extreme_utilization_penalty = 5 * np.abs(utilization - target_utilization)  # Encourage filling
    elif moving_avg_utilization > 0.8:
        extreme_utilization_penalty = 10 * np.abs(utilization - target_utilization) # Discourage further filling
    else:
        extreme_utilization_penalty = 8 * np.abs(utilization - target_utilization)  # Balance
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # 4. Adaptive Fullness Bonus with Dynamic Weighting:
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))

    if moving_avg_utilization < 0.5:
        bonus_weight = 2 * (1 - moving_avg_utilization)
    elif moving_avg_utilization < 0.8:
        bonus_weight = (1 - moving_avg_utilization)
    else:
        bonus_weight = 0.5 * (1 - moving_avg_utilization)

    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]

    #5. Item Size Consideration
    if item > 0.7:
      priorities[valid_bins] -= 0.5 * (1 - bins_remain_cap[valid_bins]) #favor bins with larger remaining cap
    elif item < 0.3:
      priorities[valid_bins] += 0.3 * (bins_remain_cap[valid_bins]) #favor bins with smaller remaining cap


    return priorities
```
