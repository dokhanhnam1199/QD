{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A priority function for online bin packing that combines best-fit,\n    waste minimization, bin balancing, and an adaptive component.  It dynamically\n    adjusts the weights of different factors based on the fill level of the bins and\n    the size of the current item.  This version introduces a bin activation strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component with a bias towards more full bins (tuned).\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: Discourage very small and very large waste.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)  # Normalize by item size\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit) #Added to discourage very large waste\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)  # Discourage further filling\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)  # Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component: Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization and item size.\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap)) # Adjusted bonus\n\n\n    #Bin Activation Strategy:  Prioritize empty or near-empty bins for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)  #High bonus for emptier bins\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates several heuristics, with refinements over v1:\n\n    1. **Best Fit Decreasing (BFD) Emphasis:**  Prioritizes bins that offer the *tightest* fit\n       for the current item, more aggressively than v1. Aims for optimal space utilization\n       in each bin, reducing fragmentation.\n\n    2.  **Waste Minimization (Adaptive):**  Penalizes small waste, but the penalty *scales*\n        with item size.  Large items creating small waste are penalized more heavily, as\n        that waste is harder to fill later.\n\n    3.  **Bin Balancing (Dynamic):**  Adjusts the utilization penalty based on the *overall*\n        fill level of all bins. If bins are generally empty, encourages filling them more;\n        if bins are generally full, focuses on avoiding small waste.\n\n    4. **Penalty for Over-Utilized Bins:** Add a bigger penalty if bins are almost full before placing the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Best Fit Decreasing Emphasis\n    size_diff = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Prioritize tight fits *much* more strongly than v1.\n    priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**2  # Squaring makes the difference more pronounced\n\n    # 2. Waste Minimization (Adaptive)\n    remaining_after_fit = bins_remain_cap - item\n    # Penalty scales with item size. Larger item = greater waste penalty\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty[valid_bins]\n\n    # 3. Bin Balancing (Dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Fraction full\n    overall_utilization = np.mean(utilization)  # Average fill level of all bins.\n\n    # Adjust penalty based on overall utilization.\n    if overall_utilization < 0.3: # If bins are generally empty.\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2) # Aim for 20% utilization.\n    elif overall_utilization > 0.7: # If bins are generally full.\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) # Aim for 80% utilization and avoid small waste\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Default penalty, same as v1.\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Penalty for Over-Utilized Bins:\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap) # Remaining cap is less than 10% of max cap\n    priorities[almost_full & valid_bins] -= 20 # Large penalty for almost full bins.\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (10th), we see (1st) uses dynamic waste management, bin balancing and learning components; (10th) uses FFD approximation, waste minimization, and bin utilization balance. (1st) adjusts weights dynamically based on overall fill level while (10th) uses fixed parameters.\n*   Comparing (2nd) vs (19th), we see (2nd) incorporates adaptive waste penalty adjustment based on item size and overall utilization, while (19th) sticks to basic waste minimization.\n*   Comparing (3rd) vs (14th), we see (3rd) uses adaptive parameter tuning and dynamic waste thresholding, (14th) employs basic FFD approximation, waste minimization and bin utilization.\n*   Comparing (4th) vs (15th), we see (4th) introduces a bin activation strategy and normalizes waste by item size, while (15th) uses the same basic heuristic as (14th)\n*   Comparing (11th) vs (20th), we see (11th) has best fit emphasis, adaptive waste minimization, dynamic bin balancing, penalty for over-utilized bins while (20th) has capacity ratio.\n*   Comparing (1st) vs (2nd), we see (1st) emphasizes dynamic parameter adjustments, and a learning component; (2nd) introduces item size aware waste penalty\n*   Comparing (3rd) vs (4th), we see (3rd) features adaptive thresholding and edge case handling for nearly full bins, while (4th) incorporates bin activation and discourages both small and large waste with normalization.\n*   Comparing (second worst) vs (worst), we see (19th) combines FFD approximation, waste minimization and capacity ratio; (20th) has capacity ratio.\n*   Overall: Better heuristics incorporate dynamic adjustments based on overall fill levels, item sizes, and potential waste. They include a combination of best-fit considerations with waste minimization and bin balancing. The best heuristics feature edge case handling and adaptive parameter tuning, while less effective heuristics rely on simpler, static rules.\n- \nOkay, here's a redefined approach to \"Current Self-Reflection,\" designed to avoid the pitfalls of \"Ineffective Self-Reflection,\" and to guide the design of better heuristics.\n\n*   **Keywords:** Dynamic adaptation, state-awareness, multi-objective, normalization, feedback-driven, robust edge-case handling, computational efficiency.\n\n*   **Advice:** Design heuristics that actively monitor problem state and dynamically adjust parameters (weights, penalties, strategies) accordingly. Combine multiple objectives (e.g., best-fit *and* waste reduction) via adaptive weighting. Incorporate feedback loops (e.g. historical performance).\n\n*   **Avoid:** Static parameter tuning, reliance on single strategies, neglecting edge cases, excessive complexity without commensurate performance gains, ignoring computational cost.\n\n*   **Explanation:** Move beyond static rules. Focus on heuristics that *learn* and adapt within the problem-solving process. Normalizing objectives prevents domination and ensures fair consideration. Prioritize computationally efficient adaptation mechanisms.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}