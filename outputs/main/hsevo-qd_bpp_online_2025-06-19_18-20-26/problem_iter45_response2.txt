```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Enhanced priority function combining best-fit, waste minimization, bin balancing,
    dynamic adjustments, and learning mechanisms.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # Best-Fit with dynamic scaling based on item size
    size_diff = bins_remain_cap - item
    scale_factor = 1.0 + 2 * (item / np.max(bins_remain_cap))
    priorities[valid_bins] += scale_factor / (size_diff[valid_bins] + 0.0001)**1.5

    # Waste Minimization: adaptive penalty with feedback
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    small_waste_penalty = np.exp(-7 * remaining_after_fit / item)
    large_waste_penalty = np.exp(-4 * item / remaining_after_fit)

    # Reduce penalty if bins are generally very full
    avg_remaining = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else np.mean(bins_remain_cap) if bins_remain_cap.size > 0 else 0
    waste_reduction_factor = np.clip(avg_remaining / (np.max(bins_remain_cap) * 0.3), 0, 1)  # Reduce penalty when avg is low

    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.6 * (1 - waste_reduction_factor)

    # Bin Balancing: dynamic adjustment with exploration factor
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)
    exploration_factor = 0.1 * np.random.rand()  # Add a small random exploration factor

    if overall_utilization < 0.3:
        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)
    elif overall_utilization > 0.7:
        extreme_utilization_penalty = 14 * np.abs(utilization - 0.8)
    else:
        extreme_utilization_penalty = 8 * np.abs(utilization - 0.5)

    priorities[valid_bins] -= (extreme_utilization_penalty[valid_bins] * (1 - exploration_factor))

    # Adaptive bonus for nearly full bins, modified to avoid local minima
    fullness_bonus = np.exp(-3 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))

    if overall_utilization < 0.5:
        bonus_scaling = 1.5
    elif overall_utilization < 0.8:
        bonus_scaling = 0.8
    else:
        bonus_scaling = 0.3

    # Introduce item size-dependent bonus
    item_size_impact = np.clip(item / np.max(bins_remain_cap), 0.1, 1.0)
    priorities[valid_bins] += bonus_scaling * fullness_bonus[valid_bins] * (1 - overall_utilization) * item_size_impact * (1 + exploration_factor * 0.5)


    # Bin Activation for large items, adjusted for bin diversity
    if item > 0.6 * np.max(bins_remain_cap):
        empty_bin_bonus = np.exp(-2 * utilization)
        # Increase bonus if bins have diverse capacities
        capacity_std = np.std(bins_remain_cap)
        diversity_bonus = 1 + np.clip(capacity_std / np.max(bins_remain_cap), 0, 0.5)

        priorities[valid_bins] += 1.5 * empty_bin_bonus[valid_bins] * diversity_bonus * (1+exploration_factor*0.3)

    # Edge case handling: very small items
    if item < 0.05 * np.max(bins_remain_cap):
        # Encourage filling bins to avoid extreme fragmentation
        utilization_bonus = np.exp(-5 * (1 - utilization))
        priorities[valid_bins] += 0.5 * utilization_bonus[valid_bins]

    return priorities
```
