```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A refined priority function for online bin packing, incorporating
    dynamic weighting, fragmentation avoidance, and adaptive penalties
    based on fill level and item size. This version aims to address
    potential issues with `priority_v1` by refining the bin balancing
    and waste minimization strategies.  It also includes a component to
    incentivize the creation of bins suitable for future (potentially larger) items.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit with Adaptive Sharpness:
    size_diff = bins_remain_cap - item
    # Make the best-fit more or less aggressive depending on the item size.
    # Larger items get a more pronounced best-fit preference.
    best_fit_factor = 1.0 + (item / np.max(bins_remain_cap))
    priorities[valid_bins] += best_fit_factor / (size_diff[valid_bins] + 0.0001)**2

    # 2. Fragmentation Avoidance & Waste Minimization:
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    # Increased penalty for creating very small waste, adjusted by item size.
    waste_penalty_strength = 5 + (item * 5)  # Larger items, bigger penalty for tiny waste.
    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing with Dynamic Range Adjustment:
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    # Dynamically adjust bin balancing based on fill level, but more smoothly.
    # The target utilization range shifts slightly depending on the item size.
    target_utilization = 0.5 + (item / (2 * np.max(bins_remain_cap))) # Shift Target slightly based on item size
    utilization_difference = np.abs(utilization - target_utilization)
    # Stronger balancing force, but less extreme penalties.
    balancing_strength = 12
    extreme_utilization_penalty = balancing_strength * utilization_difference
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # 4. Future Item Accommodation Bonus:
    # Incentivize leaving enough space for a "reasonable" future item.
    average_item_size = np.mean(bins_remain_cap[bins_remain_cap < np.max(bins_remain_cap)]) if np.any(bins_remain_cap < np.max(bins_remain_cap)) else 0.0 #Prevent crash
    future_item_size = min(0.5 * np.max(bins_remain_cap), average_item_size * 1.5) #reasonable future item size, but prevent large values if average is zero due to empty bins
    space_for_future = bins_remain_cap[valid_bins] - item
    future_item_bonus = np.where(space_for_future >= future_item_size, 0.2, 0.0)  # Small bonus if space available.

    priorities[valid_bins] += future_item_bonus


    # 5. Overall Utilization Based Adjustment:
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0)) #Same Fullness bonus as v1 but with adaptive Utilization scalar.

    if overall_utilization < 0.5:
        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)
    elif overall_utilization < 0.8 :
         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)
    else:
        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization)
    return priorities
```
