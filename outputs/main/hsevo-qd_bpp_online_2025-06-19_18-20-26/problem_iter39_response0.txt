```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An adaptive priority function for online bin packing that learns from
    the item sizes and bin utilization. It combines best-fit, waste
    minimization, bin balancing, and item-aware strategies with dynamic
    parameter adjustments based on the distribution of item sizes seen so far.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit component (refined): Prioritize bins closer to item size
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (np.abs(size_diff[valid_bins]) + 0.0001)**1.5 #emphasize closer fit

    # 2. Waste Minimization (adaptive penalty for small waste):
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    #Adaptive penalty based on item size
    small_waste_threshold = 0.1 * item  # Dynamic threshold relative to item size
    waste_penalty_strength = 5.0 # Penalty scaling factor

    small_waste_penalty = np.where(remaining_after_fit > 0, np.exp(-waste_penalty_strength * remaining_after_fit / small_waste_threshold), 0) #Scale by small_waste_threshold
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing (Dynamic adjustment based on utilization)
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    # Dynamically adjust bin balancing based on fill level, and also penalize almost empty bins
    if overall_utilization < 0.3:
        extreme_utilization_penalty = 5 * np.abs(utilization - 0.3)  # Encourage filling
    elif overall_utilization > 0.7:
        extreme_utilization_penalty = 15 * np.abs(utilization - 0.7)  # Discourage further filling
    else:
        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)  # Balance
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # Penalize almost empty bins if overall utilization is high.
    if overall_utilization > 0.6:
      empty_bin_penalty = np.exp(-5 * utilization) # penalize bins that are close to empty
      priorities[valid_bins] -= 2* empty_bin_penalty[valid_bins]



    # 4. Item-Aware Strategy (Dynamic adjustment based on item size)
    # Prioritize bins based on how well the item "fits" relative to bin size
    relative_item_size = item / np.max(bins_remain_cap)  # Normalized item size
    fit_score = np.exp(-5 * np.abs(bins_remain_cap[valid_bins]/ np.max(bins_remain_cap) - relative_item_size))
    priorities[valid_bins] += fit_score # Higher score for better fit

    # 5. Adaptive Fullness Bonus (Adjust bonus based on fill level and item size)
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap)))

    if overall_utilization < 0.5:
        bonus_multiplier = 2 * (1 - overall_utilization)
    elif overall_utilization < 0.8:
        bonus_multiplier = (1 - overall_utilization)
    else:
        bonus_multiplier = 0.5 * (1 - overall_utilization)

    priorities[valid_bins] += bonus_multiplier * fullness_bonus[valid_bins] * (1 - relative_item_size) #scale bonus by relative item size



    return priorities
```
