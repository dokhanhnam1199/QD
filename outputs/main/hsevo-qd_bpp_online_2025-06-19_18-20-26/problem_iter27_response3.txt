```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An enhanced priority function for online bin packing that incorporates
    adaptive strategies and dynamic weighting for improved performance.

    This version aims to refine the balance between best-fit, waste management,
    and bin utilization, while also adding a penalty for creating too many
    near-empty bins early on. It uses a more robust normalization approach
    and addresses potential edge cases more explicitly.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit with Refined Tie-Breaking:  Favor bins closer to item size
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**1.5  # Emphasize smaller differences

    # 2. Waste Minimization with Dynamic Penalty Adjustment: Discourage small waste, but adaptively
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    # Modulate the small waste penalty based on how full the bins generally are
    avg_fill = np.mean(1 - (bins_remain_cap / np.max(bins_remain_cap)))
    waste_penalty_strength = 10 * (1 + avg_fill)  # Increase penalty if bins are generally full
    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing with Adaptive Target Utilization:  Encourage bins to converge to a target utilization level
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))

    # Define a target utilization level that adapts based on overall fill
    if avg_fill < 0.4:
        target_utilization = 0.5
    elif avg_fill > 0.7:
        target_utilization = 0.85
    else:
        target_utilization = 0.7

    # Apply a penalty for deviating from the target utilization
    utilization_diff = np.abs(utilization - target_utilization)
    utilization_penalty = 5 * utilization_diff**2  # Quadratic penalty for stronger effect
    priorities[valid_bins] -= utilization_penalty[valid_bins]

    # 4. Early-Stage Empty Bin Penalty:  Discourage creating too many near-empty bins early on
    num_empty_bins = np.sum(bins_remain_cap == np.max(bins_remain_cap))
    if avg_fill < 0.2 and num_empty_bins > 2:
        priorities[valid_bins] -= 2  # Mild penalty for using new bins too early

    # 5. Fullness Bonus with Adaptive Weight: Encourage filling bins nearing capacity.
    fullness_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1)) # Exponentional bonus
    #Dynamically weighting the bonus based on the overall fill level
    if avg_fill < 0.5:
         priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1-avg_fill)
    elif avg_fill < 0.8:
        priorities[valid_bins] += fullness_bonus[valid_bins] * (1-avg_fill)
    else:
        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1-avg_fill)

    return priorities
```
