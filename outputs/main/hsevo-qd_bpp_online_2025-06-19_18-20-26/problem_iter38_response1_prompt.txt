{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    An enhanced priority function for online bin packing that combines\n    best-fit considerations with dynamic waste management, bin balancing,\n    and a learning component.  It prioritizes bins based on a weighted\n    combination of several factors, including space utilization,\n    waste minimization, and bin balancing.  The weights are adjusted\n    dynamically based on the overall fill level of the bins. This version includes\n    a more sophisticated waste penalty and dynamic adjustment of the best-fit component.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Adaptive Best-Fit:\n    # Adjust the strength of best-fit based on the item size relative to average bin capacity.\n    avg_bin_capacity = np.mean(bins_remain_cap[valid_bins]) if np.any(valid_bins) else 1.0\n    best_fit_strength = 1.0 + 2.0 * (item / avg_bin_capacity)  # Stronger for larger items\n\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += best_fit_strength / (size_diff[valid_bins] + 0.0001)**2\n\n\n    # Enhanced Waste Minimization:  Discourage small waste and encourage almost full bins\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Sigmoid-shaped penalty to aggressively penalize very small waste\n    waste_penalty_scale = 10.0\n    waste_penalty = 1.0 / (1 + np.exp(waste_penalty_scale * (remaining_after_fit - 0.05)))  # Push for less than 5% waste\n\n    priorities[valid_bins] -= waste_penalty\n\n\n    # Bin Balancing using utilization and overall utilization:\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamically adjust bin balancing based on fill level.\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)  # Encourage filling\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8) #Discourage further filling\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5) #Balance\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive component:  Add a bonus to bins close to full\n    # Weight the bonus dynamically based on overall utilization\n\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    elif overall_utilization < 0.8 :\n         priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A dynamic priority function that adapts to the problem state by\n    analyzing bin capacity distribution and item size relative to bin sizes.\n    It uses a multi-faceted approach combining best-fit, waste minimization,\n    and bin balancing with dynamically adjusted weights.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # 1. Best-Fit with Adaptive Granularity:\n    #   - Emphasize finer granularity when bins are mostly empty; coarser when mostly full.\n    size_diff = bins_remain_cap - item\n    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)\n    granularity_factor = np.mean(capacity_ratio)  # Dynamic granularity adjustment\n    priorities[valid_bins] += (1 / (size_diff[valid_bins] + 0.0001)**(granularity_factor + 1))\n\n    # 2. Dynamic Waste Minimization:\n    #   - Adjust the small waste penalty based on item size and remaining capacity.\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]\n    item_size_factor = item / np.max(bins_remain_cap)  # Normalize item size\n\n    waste_penalty_strength = 5 + 10 * item_size_factor  # Stronger penalty for larger items\n    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # 3. Bin Balancing with Capacity Distribution Awareness:\n    #   - Instead of a single overall utilization, consider the distribution of bin capacities.\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    capacity_std = np.std(bins_remain_cap)  # Measure capacity variance\n    capacity_mean = np.mean(bins_remain_cap)\n\n    #   - Adjust balancing based on capacity distribution.\n    if capacity_std < 0.1 * capacity_mean:  # Bins are relatively uniform\n        balancing_strength = 10  # Strong balancing\n    else:\n        balancing_strength = 5  # Moderate balancing\n\n    #   - More penalty for bins that are too full or empty\n    extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # 4. Adaptive Fullness Bonus:\n    #   - Bonus for bins that are close to full, adjusted based on remaining capacity.\n    fullness_level = 1 - capacity_ratio\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Close to full = high bonus\n    bonus_strength = 1 + 5 * item_size_factor  # Larger items, higher bonus\n\n    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))\n\n    # 5. Edge Case Handling:  Favor bins close to full if item is large relative to available space\n    large_item_threshold = 0.75  # Item size relative to bin capacity\n\n    if item_size_factor > large_item_threshold:\n        almost_full_bins = bins_remain_cap >= item\n        almost_full_bins = np.logical_and(almost_full_bins, bins_remain_cap < (item + 0.1 * np.max(bins_remain_cap)) )\n        priorities[almost_full_bins] += 10 # Strong encouragement for nearly full bins to take large items\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses a combination of best-fit, waste minimization, bin balancing, and fullness bonus, while the worst only considers the ratio of item size to bin capacity. The better heuristics incorporate adaptive components and dynamic adjustments based on overall bin utilization and item size.\n\nComparing (2nd best) vs (second worst), we see similar trends as (1st) vs (20th). The second-best heuristic also employs a combination of best-fit, waste minimization, bin balancing, and fullness bonus, and it includes adaptive weight adjustments. In contrast, the second worst (19th) only considers item size ratios and waste minimization, lacking bin balancing and dynamic adaptation.\n\nComparing (1st) vs (2nd), we see that they are identical. This suggests that the performance difference lies in other parts of the bin-packing algorithm, or that the test cases don't distinguish these two heuristics.\n\nComparing (3rd) vs (4th), they are identical. This could indicate code duplication, or simply that the changes between them have no effect on the test dataset.\n\nComparing (second worst) vs (worst), we see that the 19th includes waste minimization while the 20th does not.\n\nOverall:\n\nThe successful heuristics combine multiple factors (best-fit, waste minimization, bin balancing, fullness), and dynamically adjust weights based on bin utilization, item sizes, and/or capacity distribution. Less successful heuristics are simpler, focusing only on a subset of these factors, and without dynamic adjustments. Edge case handling is also important (handling nearly full bins or cases where no bin is suitable).\nThe ranking suggests that a good heuristic should aim for a balance between different objectives instead of focusing too much on a single criterion. Also, adaptability, and edge case handling are key.\n- \nOkay, let's refine \"Current Self-Reflection\" for designing better heuristics, focusing on avoiding pitfalls.\n\nHere's a redefined approach:\n\n*   **Keywords:** Adaptive, Dynamic, Multifaceted, Problem State, Edge Cases, Normalization, Performance Feedback, Exploration vs. Exploitation, Computational Cost.\n\n*   **Advice:** Develop heuristics that actively learn and adapt to the problem instance *during* execution. Experiment with diverse features (e.g., item size distributions, bin utilization). Integrate performance feedback loops to continuously refine parameter weights. Employ both exploration and exploitation for better results.\n\n*   **Avoid:** Static parameters, reliance solely on single strategies, ignoring edge cases, premature simplification, and neglecting computational cost.\n\n*   **Explanation:** Effective heuristic design is an iterative process. Start with a robust, multifaceted heuristic, and refine it using real-time feedback. Dynamic adaptation allows the heuristic to tailor its behavior to the specific problem instance, avoiding the limitations of static or overly simplistic approaches.\n\n**Step-by-step thought process summary**\n1.  **Start with Keywords:** Identify the most crucial elements: Adaptability, dynamism, and considering the problem state.\n2.  **Provide Specific Advice:** Go beyond general statements. Suggest active learning, feature experimentation, and feedback loops.\n3.  **List What to Avoid:** Explicitly state what hinders good heuristic design (static parameters, ignoring edge cases, etc.).\n4.  **Summarize with Explanation:** Concisely explain the rationale behind the advice. Emphasize the iterative and adaptive nature of the process.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}