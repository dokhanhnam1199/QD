{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines best-fit, waste minimization, bin balancing, and dynamic adjustments.\n    It adapts weights based on bin fill levels and item size, handling edge cases.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit with emphasis on closer sizes\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.5 / (size_diff[valid_bins] + 0.0001)**1.8\n\n    # Waste Minimization: adaptive penalty\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-8 * remaining_after_fit / item)\n    large_waste_penalty = np.exp(-5 * item / remaining_after_fit)\n    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * 0.75\n\n    # Bin Balancing: dynamic adjustment\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 6 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 13 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 9 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Adaptive bonus for nearly full bins\n    fullness_bonus = np.exp(-4 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0.1))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 1.8 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] += 0.9 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n    else:\n        priorities[valid_bins] += 0.4 * fullness_bonus[valid_bins] * (1 - overall_utilization) * (item/ np.max(bins_remain_cap))\n\n    # Bin Activation for large items\n    if item > 0.6 * np.max(bins_remain_cap):\n        empty_bin_bonus = np.exp(-2 * utilization)\n        priorities[valid_bins] += 2 * empty_bin_bonus[valid_bins]\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, waste minimization, bin balancing, fullness bonus, and item-size-aware penalty adjustments.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Best-Fit component\n    size_diff = bins_remain_cap - item\n    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2\n\n    # Waste Minimization (adaptive)\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty\n\n    # Bin Balancing (dynamic)\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]\n\n    # Fullness Bonus (adaptive)\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n\n    if overall_utilization < 0.5:\n        priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        priorities[valid_bins] +=  fullness_bonus[valid_bins] * (1 - overall_utilization)\n    else:\n        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)\n\n    # Item size aware waste penalty adjustment\n    if item > 0.5:\n        if overall_utilization > 0.6:\n            priorities[valid_bins] -= 2 * small_waste_penalty # penalize small waste more when bins are full\n\n    # Over-utilization Penalty (adaptive)\n    almost_full = (bins_remain_cap - item) < 0.1 * np.max(bins_remain_cap)\n    priorities[almost_full & valid_bins] -= 20\n\n    # Introduce a new adaptive parameter based on item size relative to bin capacity\n    item_ratio = item / np.max(bins_remain_cap)\n    if item_ratio > 0.6: # Item is relatively large\n        # Further discourage small waste in nearly full bins to avoid creating unusable bins\n        nearly_full = (bins_remain_cap < 0.2 * np.max(bins_remain_cap)) & valid_bins # less than 20% capacity\n        priorities[nearly_full] -= 10 * small_waste_penalty[bins_remain_cap[valid_bins] < 0.2 * np.max(bins_remain_cap)]\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic involves a complex combination of best-fit, waste minimization, bin balancing, and adaptive bonuses, while the worst is a simple logarithmic ratio. (2nd best) vs (second worst) shows a similar trend, with the adaptive components being absent in the second worst. Comparing (1st) vs (2nd), we see the docstrings are almost exactly identical, indicating that the difference lies within minor implementation details or parameter choices. (3rd) vs (4th) reveals a shift towards including item-size awareness, suggesting this is a key improvement. Comparing (second worst) vs (worst), we see the simple calculation based on log ratios struggles in performance due to lack of waste management and bin balancing. Overall: Better heuristics incorporate multiple factors and adapt their behavior based on the current state of the bins and the item being packed. Adaptive weighting, dynamic waste thresholding, and item-size awareness are recurring themes in the top-performing heuristics.\n- \nOkay, let's redefine self-reflection for better heuristic design, specifically avoiding the pitfalls outlined in \"Ineffective Self-Reflection\":\n\n*   **Keywords:** Problem State, Dynamic Adaptation, Granularity, Performance Evaluation, Edge Case Analysis.\n\n*   **Advice:** Prioritize fine-grained problem state analysis to inform dynamic parameter adjustments. Implement a robust performance evaluation framework with edge case testing and performance metrics.\n\n*   **Avoid:** Overly simplistic combinations of known strategies without problem-state awareness. Avoid fixed penalties or bonuses without dynamic adjustment.\n\n*   **Explanation:** Focus on designing heuristics that intelligently react to nuances in the problem instance. Test comprehensively and avoid pre-determined weights.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}