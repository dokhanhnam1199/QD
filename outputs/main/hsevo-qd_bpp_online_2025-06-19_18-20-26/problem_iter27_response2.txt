```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A refined priority function that dynamically adjusts to problem state.
    It prioritizes bins considering best-fit, waste minimization,
    bin balancing, and a learning component, with dynamic weight adjustments
    based on fill level and item size relative to bin capacity. Aims for
    robustness and efficiency.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit component with refined size difference handling.
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2

    # 2. Waste Minimization (enhanced): Penalize both very small and very large waste.
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    # Sigmoid function to penalize small wastes more aggressively when bins are empty
    waste_penalty = np.exp(-5 * remaining_after_fit / (bins_remain_cap[valid_bins] + 0.0001))
    priorities[valid_bins] -= waste_penalty

    # Large Waste penalty. More penalization when item size is small compare to remaining capacities
    large_waste_penalty = np.exp(-2 * item / (remaining_after_fit + 0.0001))
    priorities[valid_bins] -= large_waste_penalty

    # 3. Bin Balancing (adaptive): Adjust target utilization based on overall fill level.
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    if overall_utilization < 0.3:
        target_utilization = 0.2  # Encourage filling empty bins.
    elif overall_utilization > 0.7:
        target_utilization = 0.8  # Discourage filling almost full bins.
    else:
        target_utilization = 0.5  # Balance bins near half-full.

    # Dynamic bin balancing penalty, scaled by how far we are from the target.
    bin_balancing_penalty = 10 * np.abs(utilization - target_utilization)
    priorities[valid_bins] -= bin_balancing_penalty[valid_bins]

    # 4. Adaptive Fullness Bonus: Favor bins closer to full, adjusted by utilization.
    fullness_ratio = bins_remain_cap / np.max(bins_remain_cap)
    fullness_bonus = np.exp(-5 * np.abs(fullness_ratio - 0)) # Near full bonus
    if overall_utilization < 0.5:
        bonus_weight = 2 * (1 - overall_utilization)
    elif overall_utilization < 0.8:
        bonus_weight = (1 - overall_utilization)
    else:
        bonus_weight = 0.5 * (1 - overall_utilization)

    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]

    # 5. Item Size consideration : Larger items are given a bonus for better placement
    item_size_bonus = np.exp(-item) #Give a bonus for larger items

    priorities[valid_bins] += 0.5 * item_size_bonus #Adding the bonus to priorities

    return priorities
```
