```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A dynamic priority function that adapts to the problem state by
    analyzing bin capacity distribution and item size relative to bin sizes.
    It uses a multi-faceted approach combining best-fit, waste minimization,
    and bin balancing with dynamically adjusted weights.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit with Adaptive Granularity:
    #   - Emphasize finer granularity when bins are mostly empty; coarser when mostly full.
    size_diff = bins_remain_cap - item
    capacity_ratio = bins_remain_cap / np.max(bins_remain_cap)
    granularity_factor = np.mean(capacity_ratio)  # Dynamic granularity adjustment
    priorities[valid_bins] += (1 / (size_diff[valid_bins] + 0.0001)**(granularity_factor + 1))

    # 2. Dynamic Waste Minimization:
    #   - Adjust the small waste penalty based on item size and remaining capacity.
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / bins_remain_cap[valid_bins]
    item_size_factor = item / np.max(bins_remain_cap)  # Normalize item size

    waste_penalty_strength = 5 + 10 * item_size_factor  # Stronger penalty for larger items
    small_waste_penalty = np.exp(-waste_penalty_strength * remaining_after_fit * item)
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing with Capacity Distribution Awareness:
    #   - Instead of a single overall utilization, consider the distribution of bin capacities.
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    capacity_std = np.std(bins_remain_cap)  # Measure capacity variance
    capacity_mean = np.mean(bins_remain_cap)

    #   - Adjust balancing based on capacity distribution.
    if capacity_std < 0.1 * capacity_mean:  # Bins are relatively uniform
        balancing_strength = 10  # Strong balancing
    else:
        balancing_strength = 5  # Moderate balancing

    #   - More penalty for bins that are too full or empty
    extreme_utilization_penalty = balancing_strength * np.abs(utilization - 0.5)
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # 4. Adaptive Fullness Bonus:
    #   - Bonus for bins that are close to full, adjusted based on remaining capacity.
    fullness_level = 1 - capacity_ratio
    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Close to full = high bonus
    bonus_strength = 1 + 5 * item_size_factor  # Larger items, higher bonus

    priorities[valid_bins] += bonus_strength * fullness_bonus[valid_bins] * (1 - np.mean(utilization))

    # 5. Edge Case Handling:  Favor bins close to full if item is large relative to available space
    large_item_threshold = 0.75  # Item size relative to bin capacity

    if item_size_factor > large_item_threshold:
        almost_full_bins = bins_remain_cap >= item
        almost_full_bins = np.logical_and(almost_full_bins, bins_remain_cap < (item + 0.1 * np.max(bins_remain_cap)) )
        priorities[almost_full_bins] += 10 # Strong encouragement for nearly full bins to take large items

    return priorities
```
