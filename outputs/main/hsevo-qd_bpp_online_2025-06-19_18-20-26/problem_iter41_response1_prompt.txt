{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    An adaptive priority function that dynamically adjusts its strategy based on\n    the item size relative to bin capacities and the overall bin utilization.\n    It prioritizes bins considering best-fit, waste minimization, bin balancing,\n    and a dynamic bonus for almost-full bins, with adaptive weight adjustments.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # Overall utilization of the bins\n    total_capacity = np.sum(bins_remain_cap) + np.sum(bins_remain_cap[~valid_bins] + item) * np.sum(bins_remain_cap >= item)\n    overall_utilization = 1 - np.sum(bins_remain_cap) / total_capacity if total_capacity > 0 else 0\n\n    # Item size relative to average bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.sum(bins_remain_cap > 0) > 0 else 1 # Avoid zero division\n    item_size_ratio = item / avg_bin_capacity\n\n    # Best-Fit component with adaptive scaling\n    size_diff = bins_remain_cap - item\n    best_fit_priority = 1.0 / (size_diff[valid_bins] + 0.0001)**2\n    priorities[valid_bins] += best_fit_priority * (1 + overall_utilization) #Scale by fill level\n\n    # Waste Minimization: Discourage very small waste dynamically\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    small_waste_penalty = np.exp(-10 * remaining_after_fit * item)\n    priorities[valid_bins] -= small_waste_penalty * (1 - overall_utilization) #Scale by fill level\n\n    # Bin Balancing using utilization, adaptively adjusted\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    if overall_utilization < 0.3:\n        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)\n    elif overall_utilization > 0.7:\n        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)\n    else:\n        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)\n    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins] * (1 + item_size_ratio) #Scale by item size\n\n    # Adaptive bonus for bins close to full, with dynamic weighting\n    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))\n    if overall_utilization < 0.5:\n        bonus_weight = 2 * (1 - overall_utilization)\n    elif overall_utilization < 0.8:\n        bonus_weight = 1 * (1 - overall_utilization)\n    else:\n        bonus_weight = 0.5 * (1 - overall_utilization)\n\n     # Item size adjustment: Small items get more bonus\n    item_size_bonus_multiplier = 1 + (1 - item_size_ratio)\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins] * item_size_bonus_multiplier\n\n    # Edge case handling: If no bin is suitable, slightly relax best-fit preference\n    if np.all(priorities == -np.inf):\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        valid_bins = bins_remain_cap > 0\n        if np.any(valid_bins):\n            size_diff = bins_remain_cap - item\n            size_diff[size_diff < 0] = np.inf  # Consider the overflow when calculating the best-fit\n            priorities[valid_bins] = 1.0 / (size_diff[valid_bins] + 0.0001)**0.5 # Relaxed exponent\n        else: # Very rare case: All bins are full\n            priorities = np.ones_like(bins_remain_cap) #All bins have equal priority\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A dynamic priority function for online bin packing that adapts based on\n    bin fill levels, item sizes, and waste characteristics. It aims to\n    balance best-fit, waste minimization, and bin utilization, while\n    dynamically adjusting parameters based on problem state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    priorities[~valid_bins] = -np.inf\n\n    # --- Best-Fit Component with Size-Aware Adjustment ---\n    size_diff = bins_remain_cap - item\n    # Normalize size difference by item size for relative fit\n    normalized_size_diff = size_diff / item\n    priorities[valid_bins] += 1.0 / (normalized_size_diff[valid_bins]**2 + 0.0001)\n\n\n    # --- Waste Minimization with Dynamic Waste Threshold ---\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    # Adaptive waste threshold based on item size (e.g., no waste > item/2)\n    waste_threshold = item / 2.0\n    waste_penalty_factor = 5.0  # Adjust penalty strength\n    waste_penalty = np.where(remaining_after_fit > 0, np.exp(waste_penalty_factor * (remaining_after_fit - waste_threshold)), 0)\n    priorities[valid_bins] -= waste_penalty\n\n    # --- Bin Balancing and Utilization-Based Adjustment ---\n    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    overall_utilization = np.mean(utilization)\n\n    # Dynamic bin balancing based on overall utilization\n    utilization_penalty_factor = 10.0  # Adjust penalty strength\n\n    if overall_utilization < 0.4:\n        # Encourage filling bins if overall utilization is low\n        target_utilization = 0.6\n    elif overall_utilization > 0.6:\n        # Discourage filling if bins are already full\n        target_utilization = 0.4\n    else:\n        target_utilization = 0.5\n\n    utilization_penalty = utilization_penalty_factor * np.abs(utilization - target_utilization)\n    priorities[valid_bins] -= utilization_penalty[valid_bins]\n\n    # --- Item-Size-Aware Fullness Bonus ---\n    fullness_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    fullness_bonus = np.exp(-5 * np.abs(fullness_level - 1))  # Closer to full = higher bonus\n\n    # Adjust bonus based on item size and overall utilization\n    bonus_weight = (1 - overall_utilization) * (item / np.max(bins_remain_cap))  # Larger items get larger weight\n\n    priorities[valid_bins] += bonus_weight * fullness_bonus[valid_bins]\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st incorporates best-fit, waste minimization, bin balancing, and adaptive fullness, while the 20th only uses a ratio of item size to bin capacity. (2nd best) vs (19th), the second best uses best-fit, waste minimization, dynamic bin balancing, and adaptive fullness bonus, while the 19th only uses FFD approximation and waste minimization. Comparing (1st) vs (2nd), we see similar functionality but the comments are more descriptive in the second heuristic. Comparing (3rd) vs (4th), both combine best-fit considerations with dynamic waste management, bin balancing, and learning, however, the third makes small adjustments to the best-fit to encourage more full bins. Comparing (second worst) vs (worst), the second worst implements waste minimization, first fit approximation, and bin balancing, while the worst one just implements a ratio. Overall: the better heuristics include more components such as best-fit, waste minimization, bin balancing and fullness, while the worse heuristics only consider a few components. Better heuristics use adaptive methods to dynamically adjust their weighting and parameters. Better heuristics include comprehensive edge case handling.\n- \nOkay, I understand. To redefine \"Current self-reflection\" for designing better bin packing heuristics, focusing on *avoiding* the pitfalls illustrated in the \"Ineffective self-reflection\" examples, we need a more targeted and insightful approach. Here's a breakdown:\n\n*   **Keywords:** *Systematic Exploration*, *Quantitative Evaluation*, *Iterative Refinement*, *Problem-Specific Adaptation*, *Performance Bottleneck Analysis*.\n\n*   **Advice:** Focus on designing experiments to *quantitatively* measure the impact of each component of your heuristic. Then prioritize adapting components that most improve performance. Design explicit tests to identify weakness and improve that part.\n\n*   **Avoid:** Vague statements about \"combining factors,\" \"adaptive parameters,\" or \"handling edge cases\" without specific plans for implementation, evaluation, or iteration. Also, avoid focusing on \"multiple relevant factors\". Also, *avoid* intuitive judgements over empirical data.\n\n*   **Explanation:** Instead of generally saying \"use adaptive parameters,\" define *how* the parameters will be adapted (e.g., a specific formula based on bin fill ratios), *why* that specific adaptation is expected to improve performance (a hypothesis), and *how* you will measure whether the adaptation actually achieves its goal (a controlled experiment).\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}