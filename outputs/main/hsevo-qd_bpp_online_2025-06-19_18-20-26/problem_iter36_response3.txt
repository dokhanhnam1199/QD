```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A further enhanced priority function that incorporates adaptive weights
    based on real-time bin utilization statistics and item size. It also
    introduces a bin-homogeneity component to encourage similar-sized
    items within the same bin, and a "look-ahead" penalty to prevent
    overfilling bins that might be suitable for larger items later.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit with Dynamic Item-Size Adjustment: Favor tighter fits,
    # adjusted by item size relative to bin capacity.
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += (1.0 / (size_diff[valid_bins] + 0.0001)**2) * (1 - (item / np.max(bins_remain_cap)))

    # 2. Waste Minimization with Threshold: Penalize small waste, but only
    # if above a dynamically adjusted threshold.
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_threshold = 0.1 * np.max(bins_remain_cap)  # 10% of max capacity
    small_waste_penalty = np.where(remaining_after_fit < waste_threshold,
                                     np.exp(-10 * remaining_after_fit * item),
                                     0)
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing with Adaptive Range: Encourage balanced utilization,
    # adjusting the target utilization range based on overall fill level.
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    if overall_utilization < 0.3:
        target_utilization = 0.4  # Encourage filling
    elif overall_utilization > 0.7:
        target_utilization = 0.6  # Discourage further filling
    else:
        target_utilization = 0.5  # Balance

    utilization_penalty = 10 * np.abs(utilization - target_utilization)
    priorities[valid_bins] -= utilization_penalty[valid_bins]

    # 4. Bin Homogeneity: Reward bins with items of similar size.
    # (Requires some "memory" of items already in the bin, which we'll simulate)
    # Assuming a simple average of existing item sizes. Replace with actual bin item data if available.
    avg_item_size = np.mean(1 - utilization[valid_bins]) * np.max(bins_remain_cap) if any(valid_bins) else 0 #Simulate item size based on utilization
    homogeneity_bonus = np.exp(-2 * np.abs(item - avg_item_size) / np.max(bins_remain_cap))
    priorities[valid_bins] += 0.5 * homogeneity_bonus

    # 5. Look-Ahead Penalty: Discourage filling bins too much, anticipating larger items.
    #  Penalize bins where remaining capacity is slightly larger than the current item.
    look_ahead_threshold = 1.5 * item #A magic number to prevent the bin from filling if a slightly bigger item comes along
    look_ahead_penalty = np.where((bins_remain_cap[valid_bins] > item) & (bins_remain_cap[valid_bins] < look_ahead_threshold),
                                  0.8* (bins_remain_cap[valid_bins] - item)/look_ahead_threshold,
                                  0) #Proportional to the wasted capacity
    priorities[valid_bins] -= look_ahead_penalty

    # 6. Adaptive Fullness Bonus (refined): Stronger bonus for *nearly* full bins,
    # especially when utilization is low.  Reduced bonus when utilization is high.
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap)))

    if overall_utilization < 0.5:
        priorities[valid_bins] += 3 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins
    elif overall_utilization < 0.8 :
         priorities[valid_bins] +=  1.5* fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins
    else:
        priorities[valid_bins] += 0.2 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus

    return priorities
```
