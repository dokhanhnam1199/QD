```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A refined priority function for online bin packing that dynamically adjusts
    its behavior based on the problem state. It prioritizes bins considering
    space utilization, waste minimization, bin balancing, fragmentation, and
    a learning component. Weights are dynamically adjusted based on the
    overall fill level of the bins and the distribution of item sizes.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit component with noise injection for exploration
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 1.0 / (size_diff[valid_bins] + 0.0001)**2 + np.random.normal(0, 0.01, size=np.sum(valid_bins))


    # 2. Waste Minimization: Discourage small and encourage mid-sized waste
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_score = np.exp(-20 * np.abs(remaining_after_fit - item/2))  # Ideal waste around half the item size
    priorities[valid_bins] += waste_score



    # 3. Bin Balancing and Overall Utilization awareness.
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)


    if overall_utilization < 0.3:
        # Encourage filling, prioritize almost-full bins slightly more
        extreme_utilization_penalty = 5 * np.abs(utilization - 0.2)
        priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    elif overall_utilization > 0.7:
        # Discourage further filling; prioritize balancing heavily
        extreme_utilization_penalty = 15 * np.abs(utilization - 0.8)
        priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]


    else:
        # Balance utilization
        extreme_utilization_penalty = 10 * np.abs(utilization - 0.5)
        priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]




    # 4. Fragmentation avoidance (discourage creating tiny gaps)
    fragmentation_penalty = np.exp(-50 * remaining_after_fit * (1 - remaining_after_fit))
    priorities[valid_bins] -= fragmentation_penalty


    # 5. Adaptive component - Fullness Bonus
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0))

    if overall_utilization < 0.5:
         priorities[valid_bins] += 2 * fullness_bonus[valid_bins] * (1 - overall_utilization)  # More bonus to almost full bins
    elif overall_utilization < 0.8:
        priorities[valid_bins] += fullness_bonus[valid_bins] * (1 - overall_utilization)  # Bonus to almost full bins
    else:
        priorities[valid_bins] += 0.5 * fullness_bonus[valid_bins] * (1 - overall_utilization)  # Lower bonus


    # 6. Item-Size Aware Adjustment - Encourage packing similar-sized items
    average_item_size = np.mean(1 - bins_remain_cap[bins_remain_cap < np.max(bins_remain_cap)]) # average item size in non-empty bins
    similarity_bonus = np.exp(-10 * np.abs(item - average_item_size)) if average_item_size > 0 else 0
    if average_item_size > 0 and item < 0.5: #only apply if avg_item size is valid and item is not too big
        priorities[valid_bins] += similarity_bonus

    return priorities
```
