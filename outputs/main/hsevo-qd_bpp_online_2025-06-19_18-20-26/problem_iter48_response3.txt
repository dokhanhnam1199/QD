```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An enhanced priority function for online bin packing, incorporating dynamic adaptation,
    multi-factor integration, and problem state awareness. This version introduces several key improvements
    over v1, including a more sophisticated assessment of bin suitability based on the item's relative size,
    a proactive mechanism to balance bin utilization and prevent premature saturation of bins, and a refined
    diversification strategy that considers the current packing state. This function also includes a bin 'retirement'
    mechanism and introduces a bin adjacency score.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    max_bin_cap = np.max(bins_remain_cap)
    overall_utilization = 1 - np.mean(bins_remain_cap / max_bin_cap)

    # 1. Best-Fit with Item-Aware Scaling: Adjust sensitivity based on item size.
    size_diff = bins_remain_cap - item
    item_size_ratio = item / max_bin_cap
    best_fit_scale = 1.0 + 1.5 * item_size_ratio  # Larger items prioritize tighter fits more
    priorities[valid_bins] += best_fit_scale / (size_diff[valid_bins] + 0.0001)**1.5

    # 2. Waste Minimization with Dynamic Penalties and Waste Threshold:
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    waste_ratio = remaining_after_fit / max_bin_cap  # Normalize waste by bin capacity
    small_waste_penalty = np.exp(-5 * waste_ratio)
    large_waste_penalty = np.exp(-3 / (waste_ratio + 0.0001))
    waste_penalty_weight = 0.5 + 0.5 * overall_utilization
    priorities[valid_bins] -= (small_waste_penalty + large_waste_penalty) * waste_penalty_weight

    # 3. Bin Balancing with Proactive Thresholding: Prevent early saturation.
    utilization = 1 - (bins_remain_cap / max_bin_cap)
    full_bin_threshold = 0.9  #Bins with utilization above this threshold are penalized more heavily
    overfull_penalty = 0
    if overall_utilization > 0.6:  #Only apply balancing when nearing capacity
         overfull_penalty = 100*(utilization > full_bin_threshold) # drastically penalize bins that are too full
    priorities -= overfull_penalty

    extreme_utilization_penalty = np.zeros_like(utilization)
    if overall_utilization < 0.3:
        extreme_utilization_penalty = 4 * np.abs(utilization - 0.2)
    elif overall_utilization > 0.7:
        extreme_utilization_penalty = 12 * np.abs(utilization - 0.8)
    else:
        extreme_utilization_penalty = 7 * np.abs(utilization - 0.5)
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # 4. Fullness Bonus with Item Size and Utilization Dependency
    fullness_bonus = np.exp(-2 * np.abs(bins_remain_cap / max_bin_cap - 0.1))
    fullness_bonus_scale = (1 - overall_utilization) * (item / max_bin_cap)

    if overall_utilization < 0.5:
        priorities[valid_bins] += 1.3 * fullness_bonus[valid_bins] * fullness_bonus_scale
    elif overall_utilization < 0.8:
        priorities[valid_bins] += 0.7 * fullness_bonus[valid_bins] * fullness_bonus_scale
    else:
        priorities[valid_bins] += 0.2 * fullness_bonus[valid_bins] * fullness_bonus_scale

    # 5. Bin Activation Bonus adjusted for item size
    if item > 0.5 * max_bin_cap:  # Increased threshold
        empty_bin_bonus = np.exp(-1.5 * utilization)
        activation_bonus_scale = 1.3 + 1.8 * (1 - overall_utilization)
        priorities[valid_bins] += activation_bonus_scale * empty_bin_bonus[valid_bins]

    # 6. Diversification Heuristic with State Awareness
    if np.random.rand() < 0.03:  # Reduced frequency, but now state-aware
        diversity_strength = 0.05 + 0.1 * overall_utilization  # Diversify more as bins fill
        priorities[valid_bins] += np.random.normal(0, diversity_strength, np.sum(valid_bins))

    # 7. Bin Adjacency Score: Encourages filling bins that are "next to" each other in utilization
    if len(bins_remain_cap) > 1:
        utilization_diffs = np.abs(np.diff(bins_remain_cap))
        adjacency_score = np.zeros_like(bins_remain_cap)
        adjacency_score[:-1] += np.exp(-5 * utilization_diffs)  # Higher score for similar bins
        adjacency_score[1:] += np.exp(-5 * utilization_diffs)
        priorities += 0.1 * adjacency_score  #Scale down influence

    return priorities
```
