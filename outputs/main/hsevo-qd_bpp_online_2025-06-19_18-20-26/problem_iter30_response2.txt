```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    An advanced priority function for online bin packing that dynamically adapts
    to the problem state by adjusting parameters and combining multiple relevant
    factors (e.g., best-fit, waste minimization, bin balancing, and fragmentation
    avoidance) with a refined learning component.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap >= item
    priorities[~valid_bins] = -np.inf

    # 1. Best-Fit component (refined): Prioritize bins with minimal waste
    size_diff = bins_remain_cap - item
    priorities[valid_bins] += 10.0 / (size_diff[valid_bins] + 0.0001)**1.5 # Increased impact

    # 2. Waste Minimization (refined): Discourage very small waste, more aggressively.
    remaining_after_fit = bins_remain_cap[valid_bins] - item
    small_waste_penalty = np.exp(-15 * remaining_after_fit * item) #Stronger penalty
    priorities[valid_bins] -= small_waste_penalty

    # 3. Bin Balancing using utilization and overall utilization (refined):
    utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))
    overall_utilization = np.mean(utilization)

    # Dynamically adjust bin balancing based on fill level. More aggressive balancing.
    if overall_utilization < 0.2:
        extreme_utilization_penalty = 10 * np.abs(utilization - 0.15)  # Encourage filling
    elif overall_utilization > 0.8:
        extreme_utilization_penalty = 20 * np.abs(utilization - 0.85) #Discourage further filling
    else:
        extreme_utilization_penalty = 12 * np.abs(utilization - 0.5) #Balance
    priorities[valid_bins] -= extreme_utilization_penalty[valid_bins]

    # 4. Fragmentation Avoidance: Discourage creating bins with small remaining capacity
    #    if overall utilization is low, favor leaving more space.

    if overall_utilization < 0.4:
        fragmentation_penalty = np.exp(-5 * bins_remain_cap[valid_bins])
        priorities[valid_bins] -= 0.5* fragmentation_penalty
    elif overall_utilization > 0.6:
         fragmentation_penalty = np.exp(-10 * bins_remain_cap[valid_bins])
         priorities[valid_bins] -= 0.1* fragmentation_penalty #Less penalty when bins are full

    # 5. Adaptive component: Add a bonus to bins close to full, more adaptive weight.
    fullness_bonus = np.exp(-5 * np.abs(bins_remain_cap / np.max(bins_remain_cap) - 0)) #bonus to near full
    if overall_utilization < 0.5:
        priorities[valid_bins] += 2.5 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins
    elif overall_utilization < 0.8 :
         priorities[valid_bins] +=  1.2 * fullness_bonus[valid_bins] * (1 - overall_utilization) #more bonus to almost full bins
    else:
        priorities[valid_bins] += 0.6 * fullness_bonus[valid_bins] *(1 - overall_utilization) #even lower bonus


    # 6. Exploration/Diversification: Occasionally prioritize less-full bins to avoid local optima
    if np.random.rand() < 0.05:  # 5% chance of exploration
        priorities[valid_bins] += 0.1 * (1 - utilization[valid_bins])

    return priorities
```
