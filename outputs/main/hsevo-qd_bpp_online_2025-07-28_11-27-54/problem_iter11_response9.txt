```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive item-size classification with smooth Gaussian scoring for large items.
    
    Small items use exponential Worst Fit; large items use normalized leftover targeting
    moderate fit (0.35Ã—item) via squared exponential scoring to reduce fragmentation.
    """
    THRESHOLD = 0.5  # Dynamic item size classification boundary
    valid_mask = bins_remain_cap >= item
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    if not np.any(valid_mask):
        return priorities
    
    leftover = bins_remain_cap[valid_mask] - item
    
    if item <= THRESHOLD:
        # Prioritize largest bins for small items using exponential amplification
        priorities[valid_mask] = np.exp(bins_remain_cap[valid_mask])  # Smooth Worst Fit
    else:
        # Target moderate normalized leftover for large items using Gaussian kernel
        normalized_left = leftover / item  # Contextualize leftover relative to item size
        diff = normalized_left - 0.35     # Target moderate leftover (v1's moderate threshold)
        priorities[valid_mask] = np.exp(- (diff ** 2) * 5)  # Sharpened smooth scoring peak
    
    return priorities
```
