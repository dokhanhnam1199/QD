```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Dynamic item-bin statistics blending with adaptive fragmentation avoidance.
    
    Combines item-relative Worst/Best Fit strategies using exponential scoring.
    Key innovations:
    - Dynamic item classification via mean remaining capacity (mu)
    - Adaptive penalty scaling by 1/mu for contextual normalization
    - Fragmentation penalty for residuals < 20% of item size
    - Smooth exponential blending of residual minimization and fragment avoidance
    """
    epsilon = 1e-8
    
    # Contextual statistics
    mu = np.mean(bins_remain_cap)
    penalty_factor = 1.0 / (mu + epsilon)  # Scale penalties by average bin density
    
    # Dynamic item classification
    is_small_item = item <= mu
    
    # Fragmentation threshold relative to item size
    frag_threshold = item * 0.2
    residual = bins_remain_cap - item
    valid_mask = residual >= 0
    
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    if np.any(valid_mask):
        # Fragmentation penalty calculation
        delta = np.clip(frag_threshold - residual, 0.0, None)
        
        if is_small_item:
            # Small item strategy: Amplify Worst Fit with fragment avoidance
            # Score = exp(remaining_cap * penalty - fragment_penalty)
            exponent = (bins_remain_cap - delta) * penalty_factor
            scores[valid_mask] = np.exp(exponent[valid_mask])
        else:
            # Large item strategy: Prioritize tight fits with fragment avoidance
            # Score = exp(-(residual + fragment_penalty) * penalty)
            exponent = -(residual + delta) * penalty_factor
            scores[valid_mask] = np.exp(exponent[valid_mask])
    
    return scores
```
