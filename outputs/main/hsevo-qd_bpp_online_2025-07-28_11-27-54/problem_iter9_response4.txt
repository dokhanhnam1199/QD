```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority scores using a blended heuristic with exponential scoring and fragmentation penalties.
    
    Bins that can fit the item are scored by a combination of residual tightness and underfill penalties.
    Continuity-preserving functions ensure smooth adaptability across scenarios.
    
    Design:
    - Primary term: exp(-R / T) rewards tight fits using dynamic thermal scaling T.
    - Secondary penalty: exp(-remaining_cap / T) penalizes bins with larger remaining capacities.
    - Thermal scaling T uses mean residual capacity of feasible bins for contextual adaptation.
    - Multiplicative blending ensures continuous interaction between components.
    """
    can_fit = bins_remain_cap >= item
    feasible_mask = can_fit & (bins_remain_cap >= 0)  # Ensure bins have non-negative capacity
    
    if not np.any(feasible_mask):
        return np.full_like(bins_remain_cap, -np.inf)
    
    # Dynamic thermal scaling factor T: average remaining capacity of feasible bins
    feasible_rc = bins_remain_cap[feasible_mask]
    T = feasible_rc.mean()
    T = max(T, 1e-8)  # Avoid division by zero in case all feasible bins have zero remaining capacity
    
    # Compute residual after placement
    R = bins_remain_cap - item
    R = np.clip(R, 0, None)  # R is non-negative for feasible bins, clip negative values to 0 (shouldn't happen)
    
    # Primary component: exponential reward for tight fit (small R relative to T)
    primary = np.exp(- R / T)
    
    # Secondary penalty: exponential decay with bin's remaining capacity to penalize underfilled bins
    secondary = np.exp(- bins_remain_cap / T)
    
    # Combined score: product of primary and secondary preserves continuity
    blended = primary * secondary
    
    # Apply feasibility mask: non-feasible bins have -inf
    final_score = np.where(feasible_mask, blended, -np.inf)
    
    return final_score
```
