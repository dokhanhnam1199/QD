```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines exponential fit penalties with z-score density rewards, adaptive scaling by item size and bin statistics.
    
    Uses item-normalized residuals for scale invariance, smooth density rewards via z-scores, and logistic blending
    weighted by coefficient of variation to balance space efficiency and bin density consolidation.
    """
    EPS = 1e-8
    feasible = bins_remain_cap >= item
    
    if not np.any(feasible):
        return -np.inf * np.ones_like(bins_remain_cap)
    
    # Residuals and bin statistics
    r = bins_remain_cap - item
    feasible_r = r[feasible]
    mu, sigma = np.mean(bins_remain_cap), np.std(bins_remain_cap)
    cv = sigma / (mu + EPS)
    
    # Item-relative fit penalty (normalized residual)
    normalized_residual = feasible_r / (item + EPS)
    fit_component = np.exp(-normalized_residual * (1 + cv))  # Stronger fit emphasis with higher variance
    
    # Density reward via z-score regularization
    z = (feasible_r - mu) / (sigma + EPS)
    density_component = np.exp(-np.abs(z))  # Linear z-score penalty for smoothness
    
    # Adaptive weight with logistic cv scaling
    blend_weight = 1 / (1 + np.exp(-2 * cv))  # Sharper transition for weight sensitivity
    
    combined = blend_weight * fit_component + (1 - blend_weight) * density_component
    
    # Final score construction
    scores = np.full_like(bins_remain_cap, -np.inf)
    scores[feasible] = combined
    return scores
```
