```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive scoring combining fit ratio, leftover penalty, and bin capacity scaling.
    
    Uses harmonic mean for item size classification. Large items use exponential fit+penalty,
    while small items prefer underfilled bins with smooth scaling. Soft penalties for 
    invalid bins to maintain feasibility continuity.
    """
    if len(bins_remain_cap) == 0:
        return np.array([])
    
    can_fit = bins_remain_cap >= item
    eps = 1e-9

    # Adaptive item classification using harmonic mean of remaining capacities
    harmonic_mean = len(bins_remain_cap) / (np.sum(1.0 / (bins_remain_cap + eps)) + eps)
    is_large = item > (harmonic_mean * 0.85)  # Tighter threshold for large items

    fit_ratio = item / (bins_remain_cap + eps)
    leftover = bins_remain_cap - item

    if is_large:
        # Prioritize bins that maximize fit_ratio with aggressive exponential weighting
        fit_component = np.exp(3.0 * fit_ratio)  # Higher exponent for large items
        penalty_component = np.exp(-0.9 * leftover)  # Stronger leftover penalty
        score = fit_component * penalty_component
    else:
        # Blend capacity scaling with residual minimization for small items
        mean_remaining = bins_remain_cap.mean()
        capacity_scaling = np.sqrt(bins_remain_cap / (mean_remaining + eps))  # Sublinear scaling
        fit_component = np.exp(0.5 * fit_ratio)  # Mild reward for partial fills
        penalty_component = np.exp(-0.4 * leftover)
        score = capacity_scaling * fit_component * penalty_component

    # Soft penalty instead of -inf for invalid bins (maintains gradient continuity)
    invalid_score = -1e10
    return np.where(can_fit, score, invalid_score)
```
