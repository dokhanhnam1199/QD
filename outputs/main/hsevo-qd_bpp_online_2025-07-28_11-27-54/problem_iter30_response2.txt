```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority scores for bins using dynamic statistical adaptation and smooth exponential blending.
    
    Combines asymptotically scaled residual minimization with secondary density penalties via inverse sparsity
    weighting and z-score clustering adjustments. Uses exponential penalty terms for mathematical continuity
    and adaptive scaling relative to item size harmonics.
    
    Args:
        item: Size of the item to be packed.
        bins_remain_cap: Array of remaining capacities for each bin.
    
    Returns:
        Array of priority scores for each bin.
    """
    # Feasibility masking
    feasible_mask = bins_remain_cap >= item
    if not np.any(feasible_mask):
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    # Statistical context parameters
    mean_cap = np.mean(bins_remain_cap)
    std_cap = np.std(bins_remain_cap)
    
    # Primary residual minimization term
    residual = bins_remain_cap - item
    scaled_residual = residual / (item + std_cap + 1e-8)  # Asymptotic normalization
    residual_term = np.exp(-2 * np.abs(scaled_residual))  # Smooth exponential penalty
    
    # Secondary density penalty term
    sparsity_penalty = 1.0 / (bins_remain_cap + 1e-8)  # Inverse proportionality to bin sparsity
    z_score = (bins_remain_cap - mean_cap) / (std_cap + 1e-8)
    z_adjustment = np.exp(-np.abs(z_score) / (std_cap + 1e-8))  # Adaptive clustering toward mean
    density_term = sparsity_penalty * z_adjustment
    
    # Composite priority score with numerical stability
    priority_scores = residual_term * density_term + 1e-12
    
    # Apply strict feasibility masking
    return np.where(feasible_mask, priority_scores, -np.inf)
```
