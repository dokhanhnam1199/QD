```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive logistic-blended exponential scoring with CV-weighted objectives.
    
    Combines Worst Fit (exp(cv*capacity)) for small items and Best Fit (exp(-cv*leftover))
    for large items using logistic transition. Uses coefficient of variation (CV) to
    dynamically scale scoring sensitivity based on bin capacity distribution.
    """
    valid_mask = bins_remain_cap >= item
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    # Statistical context analysis
    mu = np.mean(bins_remain_cap)
    sigma = np.std(bins_remain_cap)
    epsilon = 1e-8
    cv = sigma / (mu + epsilon)  # Coefficient of variation for adaptive scaling
    
    # Smooth transition threshold (mean capacity) with logistic blending
    threshold = mu
    temperature = max(np.std(bins_remain_cap), 0.1)  # Dynamic smoothing factor
    blend_weight = 1 / (1 + np.exp((item - threshold) / (temperature + epsilon)))
    
    # Feasible bin calculations
    feasible_caps = bins_remain_cap[valid_mask]
    if not np.any(valid_mask):
        return priorities
    
    # Small item objective: Worst Fit amplified by CV
    small_scores = np.exp(cv * feasible_caps)
    
    # Large item objective: Best Fit with CV-weighted leftover penalty
    leftover = feasible_caps - item
    large_scores = np.exp(- (1 + cv) * leftover)
    
    # Multi-objective blending
    blended_scores = blend_weight * small_scores + (1 - blend_weight) * large_scores
    priorities[valid_mask] = blended_scores
    
    return priorities
```
