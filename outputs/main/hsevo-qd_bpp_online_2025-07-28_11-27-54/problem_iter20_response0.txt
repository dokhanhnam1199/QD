```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Priority heuristic combining dynamic bin statistics with item-relative rewards.
    
    Uses adaptive thresholds (mean+std) and smooth penalties from v0, augmented with
    item-aware exponential rewards (v1-inspired) to prioritize fits where remaining space
    is small relative to item size. Balances residual minimization, fragmentation
    avoidance, and contextual adaptivity through multi-objective blending.
    """
    feasible = bins_remain_cap >= item
    if not feasible.any():
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    r = bins_remain_cap - item
    feasible_r = r[feasible]
    
    mu = feasible_r.mean()
    std = feasible_r.std()
    eps = 1e-9
    tau = mu + std + eps
    
    # Core components from v0
    beta = item / tau
    residual_objective = -r
    penalty_term = np.exp(-r / tau)
    fragmentation_objective = -beta * penalty_term
    
    # Item-relative reward (smooth v1-inspired component)
    with np.errstate(divide='ignore', invalid='ignore'):
        item_rel_scale = r / (item + eps)
    item_relative_reward = np.exp(-item_rel_scale)  # High reward for small r/item ratios
    
    # Multi-objective combination
    score = residual_objective + fragmentation_objective + item_relative_reward
    
    return np.where(feasible, score, -np.inf).astype(np.float64)
```
