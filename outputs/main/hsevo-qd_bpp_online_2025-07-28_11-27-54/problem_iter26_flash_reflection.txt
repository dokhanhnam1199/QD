**Analysis:**  
Comparing (1st) vs (17th-18th): Top heuristics use adaptive statistical weights (mean, std, logistic balance) for multi-objective blending, while worst ones return flat scores (no prioritization).  
(2nd) vs (19th-20th): Better heuristics use dynamic thresholds (e.g., item-to-capacity ratios) and exponential penalties, while lower-ranked ones rely on static σ-based thresholds with less contextual adaptivity.  
(3rd) vs (11th-16th): Smooth exponential scoring (3rd) outperforms discrete tiered scoring (11th-16th) by avoiding abrupt thresholds and enabling gradient-based bin selection.  
(4th) vs (5th): Dynamic median-based blending (4th) balances residual minimization and fragmentation avoidance more robustly than fixed thresholds.  
(6th-7th) vs (8th-10th): Heuristics combining residual objectives with item-relative rewards (e.g., r/item normalization) adapt better to varying item sizes than单一 penalty terms.  

**Experience:**  
Prioritize continuous adaptive weights over discrete tiers. Blend residual minimization with density-based rewards using statistical context (mean, std). Use smooth exponential penalties and item-relative scaling to avoid fragmentation. Avoid flat scores or rigid thresholds.