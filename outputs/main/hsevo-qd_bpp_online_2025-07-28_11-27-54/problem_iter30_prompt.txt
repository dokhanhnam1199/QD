{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\nCurrent heuristics:\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority scores for bins using a Best Fit heuristic.\n    \n    Bins that can fit the item are scored by how little space remains after placement.\n    Bins that cannot fit the item receive a very low priority score.\n    \n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    fit_scores = item - bins_remain_cap  # Higher score for bins with less remaining space after placement\n    return np.where(can_fit, fit_scores, -np.inf)\n\nNow, think outside the box write a mutated function `priority_v2` better than current version.\nYou can use some hints below:\n- \n- Keywords: Dynamic statistical adaptation (mean, std, quantiles), Landau notation asymptoic weighting, smooth exponential/transcendental blending, asymptotic penalty scaling  \n- Advice: Use contextually scaled residual minimization with smooth penalty exponentiation, secondary density penalties via inverse proportionality to bin sparsity, adaptive standardization of weights towards item size harmonics, and rigorous feasibility masking (-\u221e on invalids).  \n- Avoid: Fixed thresholds, dynamic thresholds tied purely to bin stats (e.g., mean/\u03bc+\u03c3), single objective dominance, and any step functions.  \n- Explanation: Dynamic statistical adaptation with smooth exponential blending avoids rigid thresholds while ensuring mathematical continuity. Secondary density penalties balance exploration and packing efficiency. Landau notation asymptotic weighting improves robustness to scale variations, and strict feasibility masking ensures only valid actions are considered.\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}