{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority scores using adaptive item size classification and smooth scoring.\"\"\"\n    can_fit = bins_remain_cap >= item\n    if len(bins_remain_cap) == 0:\n        return np.array([])\n    \n    # Dynamic item size classification based on harmonic mean of remaining capacities\n    eps = 1e-9\n    harmonic_mean = len(bins_remain_cap) / (np.sum(1.0 / (bins_remain_cap + eps)))\n    is_large = item > (harmonic_mean * 0.8)  # Adaptive threshold with margin\n    \n    # Smooth scoring with secondary tie-breaker\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fit_ratio = item / (bins_remain_cap + eps)  # Primary term: fill ratio\n        underfill_penalty = bins_remain_cap - item  # Secondary term: leftover space\n        underfill_penalty = np.clip(underfill_penalty, 0, None)\n        \n        # Smooth exponential weighting of terms\n        fit_component = np.exp(fit_ratio * 2) * can_fit\n        penalty_component = np.exp(-underfill_penalty * 0.5) * can_fit\n        \n        # Adaptive strategy blending\n        if is_large:\n            score = fit_component * penalty_component\n        else:\n            # Prefer underutilized bins with smooth capacity scaling\n            capacity_scaling = bins_remain_cap / (bins_remain_cap.mean() + eps)\n            score = (1.0 + capacity_scaling) * penalty_component\n    \n    return np.where(can_fit, score, -np.inf)\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins using a thresholded categorical heuristic.\n    \n    Bins that can fit the item are scored in discrete tiers based on normalized\n    remaining space after placement. Thresholds are anchored to item size for\n    contextual adaptability without instability from continuous scoring.\n    \n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Contextual thresholds based on item size\n    tight_threshold = 0.15 * item\n    moderate_threshold = 0.4 * item\n\n    # Identify viable bins and compute post-placement space\n    can_fit = bins_remain_cap >= item\n    remaining_after = bins_remain_cap - item\n\n    # Initialize scores with -inf for invalid bins\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Tier 1: Tight fit (minimal leftover space)\n    tight_mask = can_fit & (remaining_after <= tight_threshold)\n    # Tier 2: Moderate fit (small leftover space)\n    mod_mask = can_fit & (remaining_after > tight_threshold) & (remaining_after <= moderate_threshold)\n    # Tier 3: Loose fit (significant leftover space)\n    loose_mask = can_fit & (remaining_after > moderate_threshold)\n\n    # Assign discrete priority scores\n    scores[tight_mask] = 3\n    scores[mod_mask] = 2\n    scores[loose_mask] = 1\n\n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see sophisticated dynamic threshold blending with exponential penalties vs zero scoring; (2nd) vs (19th) shows adaptive item classification vs no prioritization; (1st) vs (2nd) reveals residual-fragmentation tradeoff vs item-size-dependent strategy; (11th) vs (16th) highlights categorical thresholds vs flat scoring; (6th) vs (15th) demonstrates harmonic mean adaptation vs rigid tiers. Top heuristics use context-aware blending, continuous scoring, and multi-objective optimization, while lower ones lack adaptability or nuance.\n- \nKeywords: Contextual Adaptation, Smooth Multi-Objective Blending, Feasibility Masks, Continuity-Driven Scoring  \n**Advice**: Use dynamically contextual thresholds based on item/bin size ratios and distribution statistics, blend smoothed exponential scoring with adaptive penalties (e.g., residual minimization + fragmentation avoidance), enforce feasibility masks (-\u221e for invalid bins) to prune invalid actions.  \n**Avoid**: Static thresholds, step functions/discrete scoring, zero-based fallbacks, or fixed priority rules.  \n**Explanation**: Mathematical continuity and context-aware adaptation prevent abrupt decisions, feasibility masking ensures valid placements, and smooth multi-objective blending balances competing goals (e.g., fit quality vs. bin underfill) to maintain optimization stability and reduce fragmentation.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}