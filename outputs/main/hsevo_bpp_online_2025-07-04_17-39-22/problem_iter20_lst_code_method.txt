{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.42930164155899714,\n                small_fragment_penalty: float = 0.972137924647054,\n                large_capacity_threshold_ratio: float = 2.8187542828129244,\n                large_capacity_bonus: float = 1.9645257536386707,\n                base_exploration_noise: float = 0.03304726537524623,\n                num_feasible_bins_threshold: int = 8.767972008397969,\n                exploitation_bonus: float = 0.03824933698367995,\n                exploration_noise: float = 0.1843279331231594,\n                fragment_penalty_threshold_ratio: float = 0.4881732906738122,\n                fragment_penalty_factor: float = 0.35444206464132066,\n                bin_utilization_exponent: float = 2.6384245424129045,\n                item_size_threshold_ratio: float = 0.40827293751380256,\n                large_item_bonus: float = 0.10347161476939143,\n                bin_fullness_threshold: float = 0.5591415246263047,\n                full_bin_bonus: float = 0.15134896160709246) -> np.ndarray:\n    \"\"\"Calculate bin priorities, balancing bin utilization, fragmentation, and exploration.\"\"\"\n\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n\n        bin_fullness = 1 - (feasible_bins_remain_cap / (bins_remain_cap[feasible_mask]))\n\n        full_bin_mask = bin_fullness > bin_fullness_threshold\n        priorities[feasible_mask][full_bin_mask] *= (1 + full_bin_bonus)\n\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_utilization_exponent: float = 2.0,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_bonus: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent  # Increased impact of utilization\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Bonus for placing large items in well-utilized bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7 # consider a bin well-utilized if 70% filled with new item\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities, balancing bin utilization, fragmentation, and exploration.\"\"\"\n\n    small_fragment_threshold_ratio: float = 0.2\n    small_fragment_penalty: float = 0.3\n    large_capacity_threshold_ratio: float = 1.8\n    large_capacity_bonus: float = 1.5\n    base_exploration_noise: float = 0.04\n    num_feasible_bins_threshold: int = 5\n    exploitation_bonus: float = 0.04\n    exploration_noise: float = 0.06\n    fragment_penalty_threshold_ratio: float = 0.3\n    fragment_penalty_factor: float = 0.6\n    bin_utilization_exponent: float = 2.0\n    item_size_threshold_ratio: float = 0.5\n    large_item_bonus: float = 0.1\n    bin_fullness_threshold: float = 0.8\n    full_bin_bonus: float = 0.1\n\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n\n        bin_fullness = 1 - (feasible_bins_remain_cap / (bins_remain_cap[feasible_mask]))\n\n        full_bin_mask = bin_fullness > bin_fullness_threshold\n        priorities[feasible_mask][full_bin_mask] *= (1 + full_bin_bonus)\n\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins, combining capacity ratio,\n    fragment avoidance, bin balancing, and adaptive randomness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Non-linear scaling to favor well-utilized bins\n        bin_utilization_exponent = 1.5\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Fragment avoidance relative to bin size and item size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        small_fragment_mask_item_relative = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask_item_relative] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins, combining capacity ratio,\n    fragment avoidance, bin balancing, and adaptive randomness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Non-linear scaling to favor well-utilized bins\n        bin_utilization_exponent = 1.5\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Fragment avoidance relative to bin size and item size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        small_fragment_mask_item_relative = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask_item_relative] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins, combining capacity ratio,\n    fragment avoidance, bin balancing, and adaptive randomness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Non-linear scaling to favor well-utilized bins\n        bin_utilization_exponent = 1.5\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Fragment avoidance relative to bin size and item size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        small_fragment_mask_item_relative = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask_item_relative] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized waste and bin utilization with exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    feasible_bins_remain_cap = bins_remain_cap[valid_bins]\n\n    # Normalized Waste Score (Core Intuition)\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    normalized_waste = remaining_capacity_after_fit / (item + feasible_bins_remain_cap) # normalized by both item and remaining capacity\n    priorities[valid_bins] = -normalized_waste # smaller waste better\n\n    # Bin Utilization Bonus (Exploitation)\n    utilization = item / feasible_bins_remain_cap\n    priorities[valid_bins] += utilization**2  # Non-linear\n\n    #Adaptive noise for Exploration\n    num_valid_bins = np.sum(valid_bins)\n    noise_scale = 0.01 if num_valid_bins > 3 else 0.07\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Edge Case Handling: Small Fragments Penalty\n    small_fragment_threshold = 0.2 * item\n    small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < small_fragment_threshold)\n    priorities[valid_bins][small_fragment_mask] -= 0.1 # Penalize small waste\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.2,\n                small_fragment_penalty: float = 0.3,\n                large_capacity_threshold_ratio: float = 1.5,\n                large_capacity_bonus: float = 1.2,\n                base_exploration_noise: float = 0.05,\n                num_feasible_bins_threshold: int = 4,\n                exploitation_bonus: float = 0.05,\n                exploration_noise: float = 0.1,\n                fragment_penalty_threshold_ratio: float = 0.3,\n                fragment_penalty_factor: float = 0.7,\n                bin_utilization_exponent: float = 2.0,\n                item_size_threshold_ratio: float = 0.6,\n                large_item_bonus: float = 0.15,\n                almost_full_threshold_ratio: float = 0.9,\n                almost_full_bonus: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n        almost_full_threshold_ratio: Threshold ratio for considering a bin almost full.\n        almost_full_bonus: Bonus for placing item in an almost full bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Core: Bin Utilization\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Edge Case: Small Fragments\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Edge Case: Large Capacity\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Adaptive Exploration/Exploitation\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # Exploit\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:  # Explore\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        # Dynamic Fragment Penalty\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n        # Bonus for Large Items in Well-Utilized Bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n        # Bonus for Almost Full Bins\n        almost_full_mask = remaining_capacity_after_fit < (bins_remain_cap.max() * (1-almost_full_threshold_ratio))\n        priorities[feasible_mask][almost_full_mask] *= (1 + almost_full_bonus)\n\n        # Base exploration noise\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.2,\n                small_fragment_penalty: float = 0.3,\n                large_capacity_threshold_ratio: float = 1.5,\n                large_capacity_bonus: float = 1.2,\n                base_exploration_noise: float = 0.05,\n                num_feasible_bins_threshold: int = 4,\n                exploitation_bonus: float = 0.05,\n                exploration_noise: float = 0.1,\n                fragment_penalty_threshold_ratio: float = 0.3,\n                fragment_penalty_factor: float = 0.7,\n                bin_utilization_exponent: float = 2.0,\n                item_size_threshold_ratio: float = 0.6,\n                large_item_bonus: float = 0.15,\n                almost_full_threshold_ratio: float = 0.9,\n                almost_full_bonus: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n        almost_full_threshold_ratio: Threshold ratio for considering a bin almost full.\n        almost_full_bonus: Bonus for placing item in an almost full bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Core: Bin Utilization\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Edge Case: Small Fragments\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Edge Case: Large Capacity\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Adaptive Exploration/Exploitation\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # Exploit\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:  # Explore\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        # Dynamic Fragment Penalty\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n        # Bonus for Large Items in Well-Utilized Bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n        # Bonus for Almost Full Bins\n        almost_full_mask = remaining_capacity_after_fit < (bins_remain_cap.max() * (1-almost_full_threshold_ratio))\n        priorities[feasible_mask][almost_full_mask] *= (1 + almost_full_bonus)\n\n        # Base exploration noise\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on occupancy, item fit, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = 1 - occupation_ratio\n\n    # Fit bonus (favor tighter fits)\n    fit_bonus = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Adaptive exploration noise\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes simplicity and adaptivity.  The core is based on\n    normalized remaining waste if the item is placed in the bin.  Edge cases\n    (small fragments, nearly-full bins) are handled explicitly and smoothly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max() #Assumes all bins have the same capacity\n\n    # Infeasible bins get zero priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = 0.0\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n\n        # Core Heuristic: Normalized Waste (lower is better)\n        normalized_waste = remaining_capacity_after_fit / bin_capacity\n        priorities[feasible_mask] = 1.0 - normalized_waste  # Convert to a higher-is-better priority\n\n        # Edge Case 1: Small Fragment Penalty (smoothly applied)\n        small_fragment_threshold = 0.2 * item # Relative to item size\n        small_fragment_penalty = 0.5 # Reduce priority by this much\n\n        small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < small_fragment_threshold)\n        fragment_penalty_factor = remaining_capacity_after_fit[small_fragment_mask] / small_fragment_threshold\n        priorities[feasible_mask][small_fragment_mask] *= (1.0 - fragment_penalty_factor * small_fragment_penalty)\n\n        # Edge Case 2: Near-Full Bin Bonus (smoothly applied)\n        near_full_threshold = 0.9 * bin_capacity #Relative to bin capacity.\n        near_full_bonus = 0.1 #Increase priority by this much.\n\n        near_full_mask = feasible_bins_remain_cap - item > 0  # Check for valid indices before using the mask\n        near_full_mask = near_full_mask & (feasible_bins_remain_cap > near_full_threshold)\n        priorities[feasible_mask][near_full_mask] *= (1.0 + near_full_bonus)\n\n        # Adaptivity: Exploration Noise (proportional to remaining bins)\n        num_feasible = np.sum(feasible_mask)\n        exploration_noise_scale = 0.05\n        exploration_noise = np.random.normal(0, exploration_noise_scale * (1.0 - (num_feasible / len(bins_remain_cap))), size=len(priorities))\n        priorities += exploration_noise\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on occupancy, item fit, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = 1 - occupation_ratio\n\n    # Fit bonus (favor tighter fits)\n    fit_bonus = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Adaptive exploration noise\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, bin utilization, and adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n    is_used_bonus = (bin_utilization > 0).astype(float)\n    capacity_ratio = item / bins_remain_cap\n    capacity_ratio = np.clip(capacity_ratio, a_min=0, a_max=1)\n\n    num_feasible_bins = np.sum(feasible_bins)\n    noise_scale = 0.01 if num_feasible_bins > 0 else 0.05\n\n    if num_feasible_bins > 3:\n        bin_utilization_exponent = 2.0\n        priorities[feasible_bins] = 0.5 * waste_normalized[feasible_bins] + 0.3 * is_used_bonus[feasible_bins] + 0.2 * (capacity_ratio[feasible_bins]**bin_utilization_exponent) + np.random.normal(0, noise_scale, size=num_feasible_bins)\n    else:\n        priorities[feasible_bins] = 0.6 * waste_normalized[feasible_bins] + 0.4 * is_used_bonus[feasible_bins] + np.random.normal(0, noise_scale, size=num_feasible_bins)\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, bin utilization, and adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n    is_used_bonus = (bin_utilization > 0).astype(float)\n    capacity_ratio = item / bins_remain_cap\n    capacity_ratio = np.clip(capacity_ratio, a_min=0, a_max=1)\n\n    num_feasible_bins = np.sum(feasible_bins)\n    noise_scale = 0.01 if num_feasible_bins > 0 else 0.05\n\n    if num_feasible_bins > 3:\n        bin_utilization_exponent = 2.0\n        priorities[feasible_bins] = 0.5 * waste_normalized[feasible_bins] + 0.3 * is_used_bonus[feasible_bins] + 0.2 * (capacity_ratio[feasible_bins]**bin_utilization_exponent) + np.random.normal(0, noise_scale, size=num_feasible_bins)\n    else:\n        priorities[feasible_bins] = 0.6 * waste_normalized[feasible_bins] + 0.4 * is_used_bonus[feasible_bins] + np.random.normal(0, noise_scale, size=num_feasible_bins)\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version focuses on simplicity, adaptability, and balancing exploration/exploitation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    num_feasible = np.sum(feasible_mask)\n\n    if num_feasible > 0:\n        # Core heuristic: Normalized remaining capacity *after* placement.  Lower is better.\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        normalized_waste = remaining_capacity_after_fit / bins_remain_cap.max()  # Normalize by max bin size for consistency\n\n        # Assign initial priorities based on normalized waste (invert, smaller waste = higher priority)\n        priorities[feasible_mask] = 1.0 - np.clip(normalized_waste, 0, 1)\n\n        # Adaptive Exploration/Exploitation: Adjust randomness based on the number of options.\n        if num_feasible <= 3: # Increased exploration when few options exist\n            exploration_noise_scale = 0.15 # Higher exploration noise\n        elif num_feasible > 5: # Focus on exploitation when multiple bins are feasible\n            exploration_noise_scale = 0.01\n        else:\n            exploration_noise_scale = 0.05 # medium exploration\n\n        priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n        # Edge Case Handling:\n        #   1. Discourage tiny fragments.\n        tiny_fragment_threshold = 0.05 * bins_remain_cap.max() # Dynamic threshold\n        tiny_fragment_penalty = 0.5\n\n        tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < tiny_fragment_threshold)\n        priorities[feasible_mask][tiny_fragment_mask] *= tiny_fragment_penalty  # Apply penalty\n\n        # 2. Encourage filling nearly full bins to completion.\n        nearly_full_threshold = 0.9 * bins_remain_cap.max()\n        nearly_full_bonus = 0.1\n\n        nearly_full_mask = (bins_remain_cap >= nearly_full_threshold) & feasible_mask\n        priorities[nearly_full_mask] += nearly_full_bonus\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version focuses on simplicity, adaptability, and balancing exploration/exploitation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    num_feasible = np.sum(feasible_mask)\n\n    if num_feasible > 0:\n        # Core heuristic: Normalized remaining capacity *after* placement.  Lower is better.\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        normalized_waste = remaining_capacity_after_fit / bins_remain_cap.max()  # Normalize by max bin size for consistency\n\n        # Assign initial priorities based on normalized waste (invert, smaller waste = higher priority)\n        priorities[feasible_mask] = 1.0 - np.clip(normalized_waste, 0, 1)\n\n        # Adaptive Exploration/Exploitation: Adjust randomness based on the number of options.\n        if num_feasible <= 3: # Increased exploration when few options exist\n            exploration_noise_scale = 0.15 # Higher exploration noise\n        elif num_feasible > 5: # Focus on exploitation when multiple bins are feasible\n            exploration_noise_scale = 0.01\n        else:\n            exploration_noise_scale = 0.05 # medium exploration\n\n        priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n        # Edge Case Handling:\n        #   1. Discourage tiny fragments.\n        tiny_fragment_threshold = 0.05 * bins_remain_cap.max() # Dynamic threshold\n        tiny_fragment_penalty = 0.5\n\n        tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < tiny_fragment_threshold)\n        priorities[feasible_mask][tiny_fragment_mask] *= tiny_fragment_penalty  # Apply penalty\n\n        # 2. Encourage filling nearly full bins to completion.\n        nearly_full_threshold = 0.9 * bins_remain_cap.max()\n        nearly_full_bonus = 0.1\n\n        nearly_full_mask = (bins_remain_cap >= nearly_full_threshold) & feasible_mask\n        priorities[nearly_full_mask] += nearly_full_bonus\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max()  # Assuming all bins have the same capacity\n\n    # Infeasible bins get negative infinity priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Feasible bins\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        \n        # Core heuristic: Normalized waste (lower is better, so use inverse)\n        normalized_waste = remaining_capacity_after_fit / bin_capacity\n        priorities[feasible_mask] = 1 / (1e-6 + normalized_waste) # adding small constant to prevent division by zero\n\n        # Adjustments:\n        # 1. Encourage filling bins well (but not perfectly)\n        utilization = item / (bin_capacity - remaining_capacity_after_fit) # item size divided by original bin capacity\n        priorities[feasible_mask] += np.clip(utilization, 0, 0.95) # clip to avoid prioritizing completely full bins\n\n        # 2. Discourage small fragments (graded penalty)\n        small_fragment_threshold = 0.1 * bin_capacity\n        small_fragment_penalty = np.where(remaining_capacity_after_fit < small_fragment_threshold,\n                                            -0.5 * (1 - (remaining_capacity_after_fit / small_fragment_threshold)),\n                                            0)\n        priorities[feasible_mask] += small_fragment_penalty\n\n        # 3. Encourage placing large items in bins with enough remaining capacity to avoid excessive fragmentation of other items.\n        large_item_threshold = 0.75 * bin_capacity\n        if item > large_item_threshold:\n            sufficient_capacity_bonus = np.where(remaining_capacity_after_fit > 0.2 * bin_capacity,\n                                                0.2, # Bonus for sufficient capacity\n                                                0)\n            priorities[feasible_mask] += sufficient_capacity_bonus\n        \n\n        # 4. Exploration: Adaptive noise based on number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible <= 3:\n             priorities[feasible_mask] += np.random.normal(0, 0.1, size=num_feasible)\n        else:\n            priorities[feasible_mask] += np.random.normal(0, 0.01, size=num_feasible)\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, bin utilization, and adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n    is_used_bonus = (bin_utilization > 0).astype(float)\n    capacity_ratio = item / bins_remain_cap\n    capacity_ratio = np.clip(capacity_ratio, a_min=0, a_max=1)\n\n    num_feasible_bins = np.sum(feasible_bins)\n    noise_scale = 0.01 if num_feasible_bins > 0 else 0.05\n\n    if num_feasible_bins > 3:\n        bin_utilization_exponent = 2.0\n        priorities[feasible_bins] = 0.5 * waste_normalized[feasible_bins] + 0.3 * is_used_bonus[feasible_bins] + 0.2 * (capacity_ratio[feasible_bins]**bin_utilization_exponent) + np.random.normal(0, noise_scale, size=num_feasible_bins)\n    else:\n        priorities[feasible_bins] = 0.6 * waste_normalized[feasible_bins] + 0.4 * is_used_bonus[feasible_bins] + np.random.normal(0, noise_scale, size=num_feasible_bins)\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized capacity ratio, fragment avoidance, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Optimal space\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Adaptive randomness\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering utilization, waste, and adaptive exploration.\n    Combines normalized waste and utilization with exploration based on bin state.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    if not np.any(can_fit):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[can_fit]\n\n    utilization = item / feasible_bins_remain_cap\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9)  # Prevent division by zero\n\n    bin_utilization = (feasible_bins_remain_cap - waste) / (bins_remain_cap[can_fit] + item)  # corrected bin util calculation\n\n    priorities[can_fit] = 0.7 * utilization - 0.3 * waste_normalized  # Adjusted weights\n\n    num_feasible = np.sum(can_fit)\n    if num_feasible > 5:\n        priorities[can_fit] *= (1 + 0.02 * utilization) # Favor bins that are already relatively full\n\n    exploration_rate = 0.01 + 0.03 * (1 - (np.mean(bins_remain_cap[can_fit]) / np.max(bins_remain_cap))) if np.sum(can_fit) > 0 else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_item_size = np.mean(bins_remain_cap[can_fit]) / 10 if np.any(can_fit) else 0.1\n    future_fit_penalty = np.where(waste < small_item_size, -0.1, 0)\n    priorities[can_fit] += future_fit_penalty\n\n    # NEW:  Penalty for placing large items in relatively empty bins\n    item_size_threshold_ratio = 0.5\n    large_item_penalty = 0.2\n    bin_size = bins_remain_cap + item  # Approximate original bin size.\n    large_item_mask = item / bin_size[can_fit] > item_size_threshold_ratio\n    bin_utilization_threshold = 0.75\n    empty_bin_mask = bin_utilization < (1 - bin_utilization_threshold) # consider bins less than (1 - bin_utilization_threshold) utilized as relatively empty\n    priorities[can_fit][large_item_mask & empty_bin_mask] *= (1 - large_item_penalty) # Penalize placing large items in almost empty bins.\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}