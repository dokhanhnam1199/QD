[
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores, adaptive randomness, balance occupancy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio, penalize low fill\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = occupation_ratio\n\n    # Tighter fit bonus\n    fit_bonus = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Avoid small fragments relative to item\n    remaining_capacity_after_fit = bins_remain_cap[feasible_bins] - item\n    small_fragment_mask_item_relative = remaining_capacity_after_fit < (item * 0.1)\n    priorities[feasible_bins][small_fragment_mask_item_relative] *= 0.75\n\n    # Adaptive noise\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    \n    # Scale noise with occupancy\n    avg_occupancy = np.mean(1 - occupation_ratio) if len(occupation_ratio) > 0 else 0\n    noise_scale += 0.01 * (1 - avg_occupancy)\n\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 149.05265257279618,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response1.txt_stdout.txt",
    "code_path": "problem_iter20_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on capacity ratio, fragment avoidance, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_mask = bins_remain_cap >= item\n    priorities[~feasible_mask] = -np.inf\n\n    if np.sum(feasible_mask) == 0:\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    capacity_ratio = item / feasible_bins_remain_cap\n    priorities[feasible_mask] = capacity_ratio\n\n    # Fragment avoidance: Discourage small fragments\n    small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n    priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n    # Optimal space: Prioritize bins where the remaining space is suitable.\n    optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n    priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n    # Adaptive exploration: Noise scales with bin utilization.\n    max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap)) if np.max(bins_remain_cap) > 0 else 0\n    randomness_scale = 0.01 + (0.04 * max_capacity_used)\n    priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.108496210610296,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response2.txt_stdout.txt",
    "code_path": "problem_iter20_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic balancing utilization, waste, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    feasible_caps = bins_remain_cap[feasible_bins]\n    remaining_after_fit = feasible_caps - item\n    utilization = item / feasible_caps\n    normalized_waste = remaining_after_fit / (item + feasible_caps)\n\n    priorities[feasible_bins] = utilization**1.5 - normalized_waste #Balance act\n\n    #Adaptive exploration\n    num_feasible = np.sum(feasible_bins)\n    exploration_scale = 0.01 if num_feasible > 3 else 0.05\n    priorities += np.random.normal(0, exploration_scale, size=len(priorities))\n\n    # Fragment penalty (adaptive)\n    frag_threshold = 0.15 * item  # Dynamic threshold\n    small_frag = (remaining_after_fit > 0) & (remaining_after_fit < frag_threshold)\n    priorities[feasible_bins][small_frag] -= 0.08 # Reduce priority\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response3.txt_stdout.txt",
    "code_path": "problem_iter20_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive bin selection: combines normalized waste, bin utilization, and controlled exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf #Or zero\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    bin_capacity = bins_remain_cap.max()\n\n    waste_normalized = waste / bin_capacity\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n\n    bin_utilization = (bins_remain_cap - waste) / bin_capacity\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n\n    # Prioritize bins that are already somewhat full\n    utilization_bonus = 0.2 * bin_utilization\n\n    # Discourage creating very small fragments.\n    fragment_penalty_threshold = 0.1 * item #Relative to item size\n    fragment_penalty = np.where(waste < fragment_penalty_threshold, 0.3, 0)\n\n    #Adaptive exploration noise\n    num_feasible_bins = np.sum(feasible_bins)\n    exploration_scale = 0.02 * (1 - (num_feasible_bins / len(bins_remain_cap))) #Scale down noise if most bins are viable\n    noise = np.random.normal(0, exploration_scale, size=len(bins_remain_cap))\n\n    priorities[feasible_bins] = (1 - waste_normalized[feasible_bins]) + utilization_bonus[feasible_bins] - fragment_penalty[feasible_bins] + noise[feasible_bins]\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 5.963302752293574,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response4.txt_stdout.txt",
    "code_path": "problem_iter20_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, utilization, and adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if not np.any(feasible_mask):\n        return priorities\n\n    # Core: Normalized waste *after* placement\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    normalized_waste = remaining_capacity_after_fit / bins_remain_cap.max()\n    priorities[feasible_mask] = 1.0 - np.clip(normalized_waste, 0, 1)\n\n    num_feasible = np.sum(feasible_mask)\n\n    # Adaptive exploration\n    if num_feasible <= 3:\n        exploration_noise_scale = 0.15\n    elif num_feasible > 5:\n        exploration_noise_scale = 0.01\n    else:\n        exploration_noise_scale = 0.05\n\n    priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n    # Discourage tiny fragments\n    tiny_fragment_threshold = 0.05 * bins_remain_cap.max()\n    tiny_fragment_penalty = 0.5\n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < tiny_fragment_threshold)\n    priorities[feasible_mask][tiny_fragment_mask] *= tiny_fragment_penalty\n\n    # Encourage filling nearly full bins\n    nearly_full_threshold = 0.9 * bins_remain_cap.max()\n    nearly_full_bonus = 0.1\n    nearly_full_mask = (bins_remain_cap >= nearly_full_threshold) & feasible_mask\n    priorities[nearly_full_mask] += nearly_full_bonus\n\n    # Large item in empty bin penalty\n    item_size_threshold_ratio = 0.5\n    large_item_penalty = 0.2\n    bin_size = bins_remain_cap + item\n    large_item_mask = item / bin_size[feasible_mask] > item_size_threshold_ratio\n    bin_utilization = (bins_remain_cap[feasible_mask] - remaining_capacity_after_fit) / bin_size[feasible_mask]\n    empty_bin_mask = bin_utilization < 0.25  # Lower threshold for empty\n    priorities[feasible_mask][large_item_mask & empty_bin_mask] *= (1 - large_item_penalty)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.0885520542481055,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response5.txt_stdout.txt",
    "code_path": "problem_iter20_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic balancing utilization, fragmentation, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n    num_feasible = np.sum(feasible_mask)\n\n    if num_feasible > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / bins_remain_cap.max()\n\n        priorities[feasible_mask] = capacity_ratio**2  # Bin utilization\n\n        # Adaptive exploration\n        if num_feasible <= 3:\n            exploration_noise_scale = 0.15\n        elif num_feasible > 5:\n            exploration_noise_scale = 0.01\n        else:\n            exploration_noise_scale = 0.05\n        priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n        # Fragmentation penalty\n        tiny_fragment_threshold = 0.05 * bins_remain_cap.max()\n        tiny_fragment_penalty = 0.5\n        tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < tiny_fragment_threshold)\n        priorities[feasible_mask][tiny_fragment_mask] *= tiny_fragment_penalty\n\n        # Encourage filling\n        nearly_full_threshold = 0.9 * bins_remain_cap.max()\n        nearly_full_bonus = 0.1\n        nearly_full_mask = (bins_remain_cap >= nearly_full_threshold) & feasible_mask\n        priorities[nearly_full_mask] += nearly_full_bonus\n\n        # large item encouragement\n        if item > bins_remain_cap.max() * 0.5:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= 1.1\n\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 146.27044276027124,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response6.txt_stdout.txt",
    "code_path": "problem_iter20_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins balancing utilization, fragmentation, exploration, and item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio**2.0 #Bin Utilization, tuned exponent\n\n        #Small Fragments.\n        small_fragment_threshold = 0.2 * item\n        small_fragment_mask = remaining_capacity_after_fit > 0  & (remaining_capacity_after_fit < small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] *= 0.3  #Small Fragment Penalty\n\n        #Large capacity bonus\n        large_capacity_threshold = 1.5 * item\n        large_capacity_mask = remaining_capacity_after_fit > large_capacity_threshold\n        priorities[feasible_mask][large_capacity_mask] *= 1.2 #Large Capacity Bonus\n\n        #Adaptive exploration\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 4:\n            priorities[feasible_mask] *= (1 + 0.05 * capacity_ratio) #Exploitation\n        else:\n            priorities += np.random.normal(0, 0.1, size=len(priorities)) #Exploration\n\n        #Dynamic fragment penalty\n        fragment_penalty_threshold = 0.3 * item\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * 0.7)\n\n        #Large item bonus\n        if item > bins_remain_cap.max() * 0.6:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + 0.15) #Large item placed in well-utilized bin\n\n        #Almost full bonus\n        almost_full_threshold = bins_remain_cap.max() * 0.1\n        almost_full_mask = remaining_capacity_after_fit < almost_full_threshold #using rem_cap after fit\n        priorities[feasible_mask][almost_full_mask] *= (1 + 0.2) #Almost full bonus\n        \n        priorities += np.random.normal(0, 0.05, size=len(priorities)) #Base exploration noise\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.01874750698045,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response7.txt_stdout.txt",
    "code_path": "problem_iter20_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority function balancing utilization, fragmentation, and exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max()\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / bin_capacity # Use bin_capacity for ratio\n\n        # Core: Bin Utilization (similar to v0, but using bin_capacity)\n        priorities[feasible_mask] = capacity_ratio**2\n\n        # Fragment penalty (v0 style, but adapted)\n        fragment_threshold = 0.2 * bin_capacity\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= 0.7\n\n        # Encourage almost full bins (v0 style)\n        almost_full_threshold = 0.9 * bin_capacity\n        almost_full_mask = remaining_capacity_after_fit < (bin_capacity - almost_full_threshold)\n        priorities[feasible_mask][almost_full_mask] *= 1.2\n\n        # Large item bonus (v1 style, adaptively scaled)\n        large_item_threshold = 0.7 * bin_capacity\n        if item > large_item_threshold:\n            sufficient_capacity_bonus = np.where(remaining_capacity_after_fit > 0.1 * bin_capacity, 0.15, 0) #Slightly adjusted parameters\n            priorities[feasible_mask] += sufficient_capacity_bonus\n\n        # Adaptive Exploration (Combines elements of both)\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible <= 3: # More exploration when few choices\n            priorities += np.random.normal(0, 0.1, size=len(priorities))\n        else:  # Less exploration, more exploitation\n             priorities[feasible_mask] *= (1 + 0.05 * capacity_ratio) # V0 Exploitation\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.47746310331074,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response8.txt_stdout.txt",
    "code_path": "problem_iter20_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities using capacity ratio and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_bins]\n    capacity_ratio = item / feasible_bins_remain_cap\n\n    # Prioritize bins based on capacity ratio with non-linear scaling\n    bin_utilization_exponent = 1.5\n    priorities[feasible_bins] = capacity_ratio**bin_utilization_exponent\n\n    # Adaptive randomness: scale with the average fill level of bins\n    avg_fill_level = np.mean(capacity_ratio) if np.sum(feasible_bins) > 0 else 0.0\n    randomness_scale = 0.01 + (0.04 * avg_fill_level)\n    priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n    # Fragment avoidance: penalize bins that will have very small remaining capacity\n    remaining_capacity_after_fit = bins_remain_cap[feasible_bins] - item\n    small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_bins] * 0.05)\n    priorities[feasible_bins][small_fragment_mask] *= 0.75\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response9.txt_stdout.txt",
    "code_path": "problem_iter20_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering occupancy, fit, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio, favor higher occupancy\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = 1 - occupation_ratio\n\n    # Fit bonus (favor tighter fits, but not too tight)\n    remaining_space = bins_remain_cap[feasible_bins] - item\n    fit_bonus = np.exp(-np.abs(remaining_space) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Adaptive exploration noise based on num of feasible bins\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Small fragment penalty\n    small_fragment_threshold = item * 0.2  # Example threshold\n    small_fragment_penalty = -0.1\n    small_fragment_bins = (remaining_space > 0) & (remaining_space < small_fragment_threshold)\n    priorities[feasible_bins][small_fragment_bins] += small_fragment_penalty\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response0.txt_stdout.txt",
    "code_path": "problem_iter21_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version focuses on a more adaptive approach, balancing bin utilization,\n    fragmentation avoidance, and exploration based on the current state.  It\n    aims for a simpler core with more adaptive elements.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap  # Bin utilization ratio\n\n        # Base priority: Bin utilization (higher is better)\n        priorities[feasible_mask] = capacity_ratio**2  # Emphasize higher utilization\n\n        # Fragmentation avoidance: Adaptive penalty\n        fragment_threshold = 0.2 * item  # 20% of item size\n        fragment_penalty = np.where(\n            remaining_capacity_after_fit < fragment_threshold,\n            -0.5 * (fragment_threshold - remaining_capacity_after_fit) / fragment_threshold, # Graded penalty\n            0\n        )\n        priorities[feasible_mask] += fragment_penalty\n\n\n        # Encourage filling up the bin if item fills a big chunk of it\n        large_item_fit = 0.75\n        large_fit_bonus = 0.2\n        large_fit_mask = capacity_ratio > large_item_fit\n        priorities[feasible_mask][large_fit_mask] += large_fit_bonus\n\n        # Exploration/Exploitation balance: Adaptive noise\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible <= 3: # Few options - explore more\n             exploration_noise = 0.1\n        else:\n             exploration_noise = 0.025\n\n        priorities[feasible_mask] += np.random.normal(0, exploration_noise, size=len(feasible_bins_remain_cap))\n\n\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 5.903470283207025,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response1.txt_stdout.txt",
    "code_path": "problem_iter21_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for the online bin packing problem that balances bin utilization,\n    fragmentation avoidance, and exploration/exploitation with adaptive elements.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max() #introduce total bin capacity parameter.\n\n    # 1. Feasibility check: Disqualify bins that can't fit the item.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    num_feasible = np.sum(feasible_mask)\n\n    if num_feasible == 0:\n        return priorities # If no feasible bins, early return.\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n\n    # 2. Primary Metric: Bin Utilization (Ratio of item size to remaining capacity).\n    utilization_ratio = item / feasible_bins_remain_cap\n    priorities[feasible_mask] = utilization_ratio**2  # Emphasize higher utilization.\n\n    # 3. Fragmentation Avoidance: Penalize bins that would lead to small remaining fragments.\n    fragment_threshold_ratio = 0.2 #Fraction of total bin capacity.\n    small_fragment_threshold = bin_capacity * fragment_threshold_ratio #Scale penalty based on total bin capacity.\n\n    small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < small_fragment_threshold)\n    fragment_penalty = 0.5 # Penalty factor\n    priorities[feasible_mask][small_fragment_mask] *= (1 - fragment_penalty * (remaining_capacity_after_fit[small_fragment_mask] / small_fragment_threshold))\n\n    # 4. Exploration/Exploitation Balance: Adaptive noise injection based on available choices.\n    if num_feasible > 3:  # Exploit when several choices are available.\n        priorities[feasible_mask] += 0.05 * utilization_ratio #Favor bins that are already relatively full.\n    else:  # Explore more when few choices exist.\n        priorities[feasible_mask] += np.random.normal(0, 0.1, size=num_feasible)\n\n    # 5. Large Item Consideration: Give a bonus to well-utilized bins if item is large\n    large_item_threshold_ratio = 0.6\n    if item > bin_capacity * large_item_threshold_ratio:\n         well_utilized_ratio = 0.8\n         well_utilized_mask = utilization_ratio > well_utilized_ratio\n         priorities[feasible_mask][well_utilized_mask] *= 1.1\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response2.txt_stdout.txt",
    "code_path": "problem_iter21_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version focuses on a more adaptive approach, balancing bin utilization,\n    fragmentation avoidance, and exploration based on the problem state.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_mask = bins_remain_cap >= item\n    num_feasible = np.sum(feasible_mask)\n\n    # Infeasible bins get a very low priority\n    priorities[~feasible_mask] = -np.inf\n\n    if num_feasible > 0:\n        feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        utilization_ratio = item / feasible_bins_remain_cap\n\n        # Base priority: Bin utilization. Prioritize bins that will be well-utilized.\n        priorities[feasible_mask] = utilization_ratio\n\n        # Fragmentation avoidance: Penalize bins that will result in small fragments,\n        # but adapt the penalty based on the item size.  Larger items can tolerate\n        # slightly larger fragments without severe penalty.\n        fragment_threshold = item * 0.2  # 20% of item size\n        small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_threshold)\n        fragment_penalty = 0.5  # Adjust as needed\n        priorities[feasible_mask][small_fragment_mask] *= (1 - fragment_penalty * (remaining_capacity_after_fit[small_fragment_mask] / fragment_threshold))\n\n        # Exploration/Exploitation balance: Adjust randomness based on the number of feasible bins.\n        if num_feasible <= 3:  # Fewer options: explore more\n            exploration_noise = 0.1\n        else:  # More options: exploit more\n            exploration_noise = 0.02\n\n        priorities[feasible_mask] += np.random.normal(0, exploration_noise, size=num_feasible)\n\n        # Large item bonus, if it's going into a mostly-full bin\n        if item > np.mean(bins_remain_cap) * 0.7:  # A \"large\" item\n            mostly_full_mask = utilization_ratio > 0.8  # bin becomes mostly full\n            large_item_bonus = 0.15\n            priorities[feasible_mask][mostly_full_mask] *= (1 + large_item_bonus)\n\n        # Encourage filling bins close to full. Reduce impact of exploration\n        # on very full bins.\n        nearly_full_mask = utilization_ratio > 0.9\n        if np.any(nearly_full_mask):\n            priorities[feasible_mask][nearly_full_mask] *= (1 + (1 - exploration_noise))\n            # Reduce noise to let these bins get picked.\n            priorities[nearly_full_mask] += np.random.normal(0, exploration_noise * 0.1, size = np.sum(nearly_full_mask)) # tiny noise\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response3.txt_stdout.txt",
    "code_path": "problem_iter21_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This version focuses on a more adaptive and balanced approach:\n    - Prioritizes bins with a \"good fit\" (not too tight, not too loose).\n    - Adapts exploration/exploitation based on bin availability and item size.\n    - Simpler fragment penalty.\n    - Avoids hardcoded constants where possible, favoring ratios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap  # How full will the bin be?\n\n        # 1. \"Good Fit\" Score:  Ideal utilization is around 70-90%.\n        utilization_score = np.exp(-((capacity_ratio - 0.8) ** 2) / 0.05)  # Gaussian-like curve, peak at 0.8\n        priorities[feasible_mask] += utilization_score\n\n        # 2.  Fragment Penalty: Simple penalty if space is left, but not too harsh if it's a tiny fragment.\n        fragment_ratio = remaining_capacity_after_fit / bins_remain_cap[feasible_mask] # Fraction of space wasted.\n        priorities[feasible_mask] -= np.clip(fragment_ratio * 0.5, 0, 0.5)  # Max penalty of 0.5, proportional to waste.\n\n        # 3. Adaptive Exploration/Exploitation:  Fewer options -> more explore.  Larger Item -> more exploit.\n        num_feasible = np.sum(feasible_mask)\n        exploration_factor = min(1.0, 5.0 / (num_feasible + 1e-6)) # Scale exploration to available bins\n        exploration_noise = 0.05 * exploration_factor\n        priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        exploitation_factor = min(1.0, item) # Scale exploitation to item size.\n        priorities[feasible_mask] += capacity_ratio * 0.1 * exploitation_factor\n\n        # 4. Favor placing larger items early\n        if item > np.mean(bins_remain_cap) * 0.5 and len(bins_remain_cap) > 10:\n              priorities[feasible_mask] += 0.1\n\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 6.212604706820897,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response4.txt_stdout.txt",
    "code_path": "problem_iter21_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for bins based on remaining capacity and item size,\n    aiming for a balance between bin utilization and avoiding excessive fragmentation.\n\n    Args:\n        item (float): Size of the item to be packed.\n        bins_remain_cap (np.ndarray): Array of remaining capacities for each bin.\n\n    Returns:\n        np.ndarray: Priority scores for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities  # All bins are infeasible\n\n    # Initialize priorities for feasible bins based on remaining capacity ratio.\n    capacity_ratios = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = capacity_ratios # Base priority: favor tighter fits\n\n    # Add a small bonus to bins that can accommodate the item well (moderate waste).\n    moderate_waste = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins] < 0.3\n    priorities[feasible_bins][moderate_waste] += 0.1  # Encourage efficient packing\n\n    # Penalize bins that lead to small fragments (avoid fragmentation).\n    fragment_size = bins_remain_cap[feasible_bins] - item\n    small_fragment = (fragment_size / item) < 0.2\n    priorities[feasible_bins][small_fragment] -= 0.2  # Discourage small fragments\n\n    # Introduce some randomness for exploration (especially when many bins are feasible).\n    num_feasible = np.sum(feasible_bins)\n    if num_feasible > 3:\n        priorities[feasible_bins] += np.random.normal(0, 0.05, size=np.sum(feasible_bins))\n    else:\n        priorities[feasible_bins] += np.random.normal(0, 0.1, size=np.sum(feasible_bins)) # More exploration\n\n    # If the item is large, slightly prefer bins with more remaining capacity.\n    if item > np.mean(bins_remain_cap):\n        priorities[feasible_bins] += bins_remain_cap[feasible_bins] / np.max(bins_remain_cap) * 0.05 # Slight preference\n    \n    # Set the priority of infeasible bins to -inf\n    priorities[~feasible_bins] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.208216992421225,
    "exec_success": true
  }
]