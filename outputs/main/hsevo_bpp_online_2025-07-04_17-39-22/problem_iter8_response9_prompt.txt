{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                small_fragment_penalty: float = 0.7894409446208984, large_capacity_threshold: float = 4.30068414158377,\n                large_capacity_bonus: float = 1.0143294610094642, base_randomness_std: float = 0.03281434669683145,\n                feasible_bins_threshold: int = 8.658039267680126, exploitation_bonus: float = 0.07729920473685242,\n                exploration_randomness_std: float = 0.03973695860881252) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold: Threshold relative to item size below which a fragment is considered small.\n        small_fragment_penalty: Multiplier to reduce priority if a small fragment would be created.\n        large_capacity_threshold: Threshold relative to item size above which remaining capacity is considered large.\n        large_capacity_bonus: Multiplier to increase priority if remaining capacity is large.\n        base_randomness_std: Standard deviation of the base random noise added to priorities.\n        feasible_bins_threshold: Number of feasible bins above which exploitation is favored over exploration.\n        exploitation_bonus: Bonus added to priority based on capacity ratio when exploiting.\n        exploration_randomness_std: Standard deviation of random noise added to priorities when exploring.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_randomness_std, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_randomness_std, size=len(priorities)) # Higher randomness\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic with dynamic penalties and bonuses.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    remaining_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n    \n    # Dynamic weighting based on item size and remaining capacity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_after_fit / (item + 1e-9))\n\n    # Adaptive penalty for almost full bins\n    too_full_mask = feasible_mask & (remaining_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5 \n\n    # Bonus for nearly perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2\n\n    # Adaptive Randomization\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Waste Normalization\n    waste_norm = remaining_after_fit / (bins_remain_cap[feasible_mask] + item + 1e-9)\n    priorities[feasible_mask] -= 0.1 * np.clip(waste_norm, 0, 1)\n\n    priorities /= (item + 1e-9)\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first prioritizes capacity ratio, small fragment avoidance, and large capacity bonus, along with adaptive exploration/exploitation based on the number of feasible bins. The last one combines fit score, normalized waste, and randomness. Comparing (2nd) vs (19th), the second allows for fine-grained control over various aspects like fragment thresholds and penalties, and adaptive randomness. The last function in the list is rather basic, only looking at waste, fit, and a bit of noise. Comparing (1st) vs (2nd), the 1st uses hardcoded values while the 2nd exposes hyperparameters for tuning, allowing for more flexibility. (3rd) vs (4th) shows that the 3rd version incorporates an adaptive penalty for near-full bins, encourages packing items of similar sizes, dynamic noise injection. (second worst) vs (worst) indicates the second worst approach attempts waste normalization and bin utilization; the worst approach focuses on fit, remaining capacity, and randomness in a more direct manner. Overall: The better heuristics have more adaptive strategies (adaptive exploration/exploitation, dynamic penalties/bonuses based on bin utilization, remaining capacity, or item size). They also try to balance multiple factors (fit, waste, fullness) and introduce randomness for exploration. The poorer heuristics often use simpler combinations of fit, waste, and randomness, without adapting to the state of the bins.\n- \nOkay, let's redefine \"Current Self-Reflection\" to focus on designing better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection,\" and building on the provided ideas.\n\nHere's a revised approach, aimed at generating more actionable advice:\n\n*   **Keywords:** Adaptive parameters, exploration-exploitation balance, edge case handling, hyperparameter tuning, problem state awareness.\n\n*   **Advice:** Design heuristics that dynamically adjust their behavior based on real-time problem characteristics. Focus on creating tunable parameters that influence the balance between exploration and exploitation.\n\n*   **Avoid:** Overly complex formulas that obscure interpretability, neglecting edge cases.\n\n*   **Explanation:** Prioritize heuristics that \"sense\" the problem state (e.g., bin fill levels) and respond accordingly. This allows for tailored behavior, avoiding rigid rules that perform poorly in certain scenarios.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}