{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines capacity ratio, fragment avoidance, bin balancing, and adaptive randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance relative to bin size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_occupation_threshold: float = 0.75,\n                occupation_bonus: float = 0.15) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_occupation_threshold: Threshold for bin occupation ratio above which a bonus is applied.\n        occupation_bonus: Bonus factor for bins with high occupation.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / (feasible_bins_remain_cap + item) #changed from item/feasible_bins_remain_cap to normalize\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Encourage bins that are already highly occupied\n        bin_occupation_ratios = (bins_remain_cap[feasible_mask] + item - remaining_capacity_after_fit) / (bins_remain_cap[feasible_mask] + item) # Calculate bin occupation ratio\n        occupied_bin_mask = bin_occupation_ratios > bin_occupation_threshold\n        priorities[feasible_mask][occupied_bin_mask] *= (1 + occupation_bonus)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st includes `bin_utilization_exponent`, `item_size_threshold_ratio`, and `large_item_bonus` whereas 20th does not. The 1st calculates `capacity_ratio = item / feasible_bins_remain_cap`, whereas the 20th uses `capacity_ratio = item / (feasible_bins_remain_cap + item)`. The first utilizes `capacity_ratio**bin_utilization_exponent` to encourage bins that fit items well, providing non-linear scaling. The 20th uses `priorities[feasible_mask] = capacity_ratio`.\n\nComparing (2nd) vs (19th), we see that the 2nd includes `bin_utilization_exponent`, `item_size_threshold_ratio`, and `large_item_bonus` whereas 19th does not. The 2nd calculates `capacity_ratio = item / feasible_bins_remain_cap`, whereas the 19th uses `capacity_ratio = item / (feasible_bins_remain_cap + item)`.\n\nComparing (3rd) vs (4th), the 3rd introduces `well_utilized_threshold` as the threshold for bin utilization and changes the way it is calculated in a bonus condition. 3rd also includes more arguments such as `well_utilized_threshold`.\n\nComparing (2nd worst) vs (worst), 19th and 20th are identical.\n\nOverall: The top performing heuristics include `bin_utilization_exponent`, `item_size_threshold_ratio`, and `large_item_bonus`. They normalize the capacity ratio by `item / feasible_bins_remain_cap`. An important aspect of better heuristics is the non-linear scaling of the capacity ratio with a `bin_utilization_exponent`. The adaptive adjustment of exploration vs. exploitation based on the number of feasible bins is also a critical feature.\n- \nOkay, I'm ready to craft some truly effective self-reflection guidelines for heuristic design! Let's get that $999K!\n\nHere's a redefined \"Current Self-Reflection\" avoiding the pitfalls of \"Ineffective Self-Reflection\":\n\n*   **Keywords:** Simplicity, Adaptivity, Balance, Core Intuition, Iterative Refinement.\n\n*   **Advice:** Begin with a simple, interpretable core heuristic grounded in problem-specific intuition (e.g., normalized waste).\n\n*   **Avoid:** Over-complexity, premature optimization, ignoring edge cases (small fragments, near-full bins).\n\n*   **Explanation:** Prioritize a clear, understandable core. Add complexity gradually, validating each addition. Balance exploration (randomness) and exploitation (greediness) adaptively. Explicitly handle edge cases and parameter tuning should be done carefully, to allow adapting heuristic behavior to new problem instances.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}