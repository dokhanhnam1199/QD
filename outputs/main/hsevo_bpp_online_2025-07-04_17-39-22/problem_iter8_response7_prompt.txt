{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Dynamically combines fullness and waste, with noise and infeasibility mask.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n\n        relative_fullness = 1 - remaining_capacities_can_fit #Assume bin capacity is 1.\n\n        priorities[can_fit] = -waste_normalized + relative_fullness\n\n        # Boost bins with smaller remaining capacity after placement\n        remaining_after_placement = remaining_capacities_can_fit - item\n        remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n        priority_boost = np.exp(-5 * remaining_after_placement) #Scale remaining capacity\n        priorities[can_fit] += priority_boost\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins balancing utilization, fragmentation, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_after_fit = bins_remain_cap[feasible_mask] - item\n    utilization = item / bins_remain_cap[feasible_mask]\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap))\n    priorities[feasible_mask] = utilization * np.exp(-5 * remaining_after_fit / (item + 1e-9)) * (1 - fullness_ratio)\n\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first prioritizes capacity ratio, small fragment avoidance, and large capacity bonus, along with adaptive exploration/exploitation based on the number of feasible bins. The last one combines fit score, normalized waste, and randomness. Comparing (2nd) vs (19th), the second allows for fine-grained control over various aspects like fragment thresholds and penalties, and adaptive randomness. The last function in the list is rather basic, only looking at waste, fit, and a bit of noise. Comparing (1st) vs (2nd), the 1st uses hardcoded values while the 2nd exposes hyperparameters for tuning, allowing for more flexibility. (3rd) vs (4th) shows that the 3rd version incorporates an adaptive penalty for near-full bins, encourages packing items of similar sizes, dynamic noise injection. (second worst) vs (worst) indicates the second worst approach attempts waste normalization and bin utilization; the worst approach focuses on fit, remaining capacity, and randomness in a more direct manner. Overall: The better heuristics have more adaptive strategies (adaptive exploration/exploitation, dynamic penalties/bonuses based on bin utilization, remaining capacity, or item size). They also try to balance multiple factors (fit, waste, fullness) and introduce randomness for exploration. The poorer heuristics often use simpler combinations of fit, waste, and randomness, without adapting to the state of the bins.\n- \nOkay, let's redefine \"Current Self-Reflection\" to focus on designing better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection,\" and building on the provided ideas.\n\nHere's a revised approach, aimed at generating more actionable advice:\n\n*   **Keywords:** Adaptive parameters, exploration-exploitation balance, edge case handling, hyperparameter tuning, problem state awareness.\n\n*   **Advice:** Design heuristics that dynamically adjust their behavior based on real-time problem characteristics. Focus on creating tunable parameters that influence the balance between exploration and exploitation.\n\n*   **Avoid:** Overly complex formulas that obscure interpretability, neglecting edge cases.\n\n*   **Explanation:** Prioritize heuristics that \"sense\" the problem state (e.g., bin fill levels) and respond accordingly. This allows for tailored behavior, avoiding rigid rules that perform poorly in certain scenarios.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}