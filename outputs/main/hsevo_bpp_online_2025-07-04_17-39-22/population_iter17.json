[
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, bin utilization, and adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n    is_used_bonus = (bin_utilization > 0).astype(float)\n    capacity_ratio = item / bins_remain_cap\n    capacity_ratio = np.clip(capacity_ratio, a_min=0, a_max=1)\n\n    num_feasible_bins = np.sum(feasible_bins)\n    noise_scale = 0.01 if num_feasible_bins > 0 else 0.05\n\n    if num_feasible_bins > 3:\n        bin_utilization_exponent = 2.0\n        priorities[feasible_bins] = 0.5 * waste_normalized[feasible_bins] + 0.3 * is_used_bonus[feasible_bins] + 0.2 * (capacity_ratio[feasible_bins]**bin_utilization_exponent) + np.random.normal(0, noise_scale, size=num_feasible_bins)\n    else:\n        priorities[feasible_bins] = 0.6 * waste_normalized[feasible_bins] + 0.4 * is_used_bonus[feasible_bins] + np.random.normal(0, noise_scale, size=num_feasible_bins)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic balancing bin utilization, waste, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    if not np.any(feasible_mask):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n    capacity_ratio = item / feasible_bins_remain_cap\n    bin_utilization_exponent = 2.0\n    priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9)\n\n    priorities[feasible_mask] = 0.7*capacity_ratio - 0.3*waste_normalized # Adjust weights\n\n    num_feasible = np.sum(feasible_mask)\n    if num_feasible > 5:\n        priorities[feasible_mask] *= (1 + 0.03 * capacity_ratio)\n\n    exploration_rate = 0.01 + 0.03 * (1 - np.mean(bins_remain_cap[feasible_mask]) / np.max(bins_remain_cap)) if np.any(feasible_mask) else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_fragment_threshold_ratio = 0.2\n    small_fragment_penalty = 0.3\n    small_fragment_mask = waste < (item * small_fragment_threshold_ratio)\n    priorities[feasible_mask][small_fragment_mask] *= (1 - small_fragment_penalty)\n\n    item_size_threshold_ratio = 0.5\n    large_item_bonus = 0.1\n    if item > bins_remain_cap.max() * item_size_threshold_ratio:\n        well_utilized_mask = capacity_ratio > 0.7\n        priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, utilization, exploration, and fragment handling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Normalized capacity ratio (fit score)\n    feasible_bins_remain_cap = bins_remain_cap[valid_bins]\n    capacity_ratio = item / feasible_bins_remain_cap  # Normalize by remaining capacity\n    bin_utilization_exponent = 2.0  # Emphasize near-full bins\n    priorities[valid_bins] = capacity_ratio**bin_utilization_exponent\n\n\n    # Fragment penalty\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    fragment_threshold_ratio = 0.2 #tuned value\n    small_fragment_mask = remaining_capacity_after_fit < (item * fragment_threshold_ratio)\n    fragment_penalty = 0.7\n    priorities[valid_bins][small_fragment_mask] *= fragment_penalty\n\n    # Exploration noise\n    num_valid_bins = np.sum(valid_bins)\n    exploration_noise_scale = 0.01 if num_valid_bins > 3 else 0.05  # Reduce noise if many options\n    priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.01874750698045,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins, combining capacity ratio,\n    fragment avoidance, bin balancing, and adaptive randomness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Non-linear scaling to favor well-utilized bins\n        bin_utilization_exponent = 1.5\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Fragment avoidance relative to bin size and item size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        small_fragment_mask_item_relative = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask_item_relative] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, waste normalization, and adaptive noise with bin utilization exponent.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible = item > bins_remain_cap\n    priorities[infeasible] = -np.inf\n\n    feasible = ~infeasible\n    remaining_capacities = bins_remain_cap[feasible]\n\n    if len(remaining_capacities) > 0:\n        capacity_ratio = item / remaining_capacities\n        bin_utilization_exponent = 2.0  # Example exponent, can be tuned\n\n        priorities[feasible] = capacity_ratio**bin_utilization_exponent\n\n        waste = remaining_capacities - item\n        waste = np.clip(waste, a_min=0, a_max=None)\n        waste_normalized = waste / bins_remain_cap[feasible]\n\n        priorities[feasible] -= 0.5 * waste_normalized\n\n        # Adaptive noise based on remaining cap\n        num_feasible = np.sum(feasible)\n        noise_scale = 1e-6 * np.mean(bins_remain_cap) if num_feasible > 0 else 1e-5 * np.mean(bins_remain_cap)\n\n        noise = np.random.normal(0, noise_scale, len(priorities))\n        priorities += noise\n\n        #Bin usage bonus\n        bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n        is_used_bonus = (bin_utilization > 0).astype(float)\n        priorities += 0.1 * is_used_bonus  # Encourage using partially filled bins\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response5.txt_stdout.txt",
    "code_path": "problem_iter17_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized waste and bin utilization with exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    feasible_bins_remain_cap = bins_remain_cap[valid_bins]\n\n    # Normalized Waste Score (Core Intuition)\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    normalized_waste = remaining_capacity_after_fit / (item + feasible_bins_remain_cap) # normalized by both item and remaining capacity\n    priorities[valid_bins] = -normalized_waste # smaller waste better\n\n    # Bin Utilization Bonus (Exploitation)\n    utilization = item / feasible_bins_remain_cap\n    priorities[valid_bins] += utilization**2  # Non-linear\n\n    #Adaptive noise for Exploration\n    num_valid_bins = np.sum(valid_bins)\n    noise_scale = 0.01 if num_valid_bins > 3 else 0.07\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Edge Case Handling: Small Fragments Penalty\n    small_fragment_threshold = 0.2 * item\n    small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < small_fragment_threshold)\n    priorities[valid_bins][small_fragment_mask] -= 0.1 # Penalize small waste\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response6.txt_stdout.txt",
    "code_path": "problem_iter17_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized capacity ratio, fragment avoidance, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Optimal space\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Adaptive randomness\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.0885520542481055,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response7.txt_stdout.txt",
    "code_path": "problem_iter17_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on occupancy, item fit, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = 1 - occupation_ratio\n\n    # Fit bonus (favor tighter fits)\n    fit_bonus = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Adaptive exploration noise\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response8.txt_stdout.txt",
    "code_path": "problem_iter17_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities, balancing bin utilization, fragmentation, and exploration.\"\"\"\n\n    small_fragment_threshold_ratio: float = 0.2\n    small_fragment_penalty: float = 0.3\n    large_capacity_threshold_ratio: float = 1.8\n    large_capacity_bonus: float = 1.5\n    base_exploration_noise: float = 0.04\n    num_feasible_bins_threshold: int = 5\n    exploitation_bonus: float = 0.04\n    exploration_noise: float = 0.06\n    fragment_penalty_threshold_ratio: float = 0.3\n    fragment_penalty_factor: float = 0.6\n    bin_utilization_exponent: float = 2.0\n    item_size_threshold_ratio: float = 0.5\n    large_item_bonus: float = 0.1\n    bin_fullness_threshold: float = 0.8\n    full_bin_bonus: float = 0.1\n\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n\n        bin_fullness = 1 - (feasible_bins_remain_cap / (bins_remain_cap[feasible_mask]))\n\n        full_bin_mask = bin_fullness > bin_fullness_threshold\n        priorities[feasible_mask][full_bin_mask] *= (1 + full_bin_bonus)\n\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 3.9090546469884373,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering utilization, waste, and adaptive exploration.\n    Combines normalized waste and utilization with exploration based on bin state.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    if not np.any(can_fit):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[can_fit]\n\n    utilization = item / feasible_bins_remain_cap\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9)  # Prevent division by zero\n\n    bin_utilization = (feasible_bins_remain_cap - waste) / (bins_remain_cap[can_fit] + item)  # corrected bin util calculation\n\n    priorities[can_fit] = 0.7 * utilization - 0.3 * waste_normalized  # Adjusted weights\n\n    num_feasible = np.sum(can_fit)\n    if num_feasible > 5:\n        priorities[can_fit] *= (1 + 0.02 * utilization) # Favor bins that are already relatively full\n\n    exploration_rate = 0.01 + 0.03 * (1 - (np.mean(bins_remain_cap[can_fit]) / np.max(bins_remain_cap))) if np.sum(can_fit) > 0 else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_item_size = np.mean(bins_remain_cap[can_fit]) / 10 if np.any(can_fit) else 0.1\n    future_fit_penalty = np.where(waste < small_item_size, -0.1, 0)\n    priorities[can_fit] += future_fit_penalty\n\n    # NEW:  Penalty for placing large items in relatively empty bins\n    item_size_threshold_ratio = 0.5\n    large_item_penalty = 0.2\n    bin_size = bins_remain_cap + item  # Approximate original bin size.\n    large_item_mask = item / bin_size[can_fit] > item_size_threshold_ratio\n    bin_utilization_threshold = 0.75\n    empty_bin_mask = bin_utilization < (1 - bin_utilization_threshold) # consider bins less than (1 - bin_utilization_threshold) utilized as relatively empty\n    priorities[can_fit][large_item_mask & empty_bin_mask] *= (1 - large_item_penalty) # Penalize placing large items in almost empty bins.\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.1284403669724865,
    "exec_success": true
  }
]