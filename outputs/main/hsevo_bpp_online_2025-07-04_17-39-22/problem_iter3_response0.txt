```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    This version introduces a more adaptive priority scheme that considers both
    relative capacity usage and absolute remaining space, while also penalizing
    bins that become too full after placement. It incorporates a more robust
    randomization strategy and a scaling factor based on the item size.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Infeasibility check (same as v1)
    infeasible_mask = bins_remain_cap < item
    priorities[infeasible_mask] = -np.inf

    feasible_mask = ~infeasible_mask
    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item
    capacity_ratio = item / bins_remain_cap[feasible_mask]

    # Priority based on capacity ratio and remaining space (modified from v1)
    # Scale the remaining capacity penalty by the item size.  Larger items mean
    # a larger remaining space is acceptable.
    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))

    # Penalty for bins that are too full (adaptive penalty)
    # If the remaining capacity is less than 10% of the bin size, penalize
    # This encourages the algorithm to find better fitting bins early on.
    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])
    priorities[too_full_mask] -= 0.5  # Significantly reduce priority

    # Bonus for almost perfect fit
    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)
    priorities[almost_perfect_mask] += 0.2 # Slightly increase priority, avoid zero capacity

    # Adaptive Randomization (scaled by item size)
    # The amount of noise added depends on item size. Larger items may require more exploration
    random_scale = 0.01 * item
    priorities += np.random.normal(0, random_scale, size=len(priorities))

    # Scale priorities to prevent potential overflow issues and improve exploration
    priorities /= (item + 1e-9)  # Prevent division by zero
    
    return priorities
```
