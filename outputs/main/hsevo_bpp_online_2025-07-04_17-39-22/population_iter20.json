[
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores, adaptive randomness, balance occupancy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio, penalize low fill\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = occupation_ratio\n\n    # Tighter fit bonus\n    fit_bonus = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Avoid small fragments relative to item\n    remaining_capacity_after_fit = bins_remain_cap[feasible_bins] - item\n    small_fragment_mask_item_relative = remaining_capacity_after_fit < (item * 0.1)\n    priorities[feasible_bins][small_fragment_mask_item_relative] *= 0.75\n\n    # Adaptive noise\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    \n    # Scale noise with occupancy\n    avg_occupancy = np.mean(1 - occupation_ratio) if len(occupation_ratio) > 0 else 0\n    noise_scale += 0.01 * (1 - avg_occupancy)\n\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 149.05265257279618,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response1.txt_stdout.txt",
    "code_path": "problem_iter20_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on capacity ratio, fragment avoidance, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_mask = bins_remain_cap >= item\n    priorities[~feasible_mask] = -np.inf\n\n    if np.sum(feasible_mask) == 0:\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    capacity_ratio = item / feasible_bins_remain_cap\n    priorities[feasible_mask] = capacity_ratio\n\n    # Fragment avoidance: Discourage small fragments\n    small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n    priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n    # Optimal space: Prioritize bins where the remaining space is suitable.\n    optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n    priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n    # Adaptive exploration: Noise scales with bin utilization.\n    max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap)) if np.max(bins_remain_cap) > 0 else 0\n    randomness_scale = 0.01 + (0.04 * max_capacity_used)\n    priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.108496210610296,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response2.txt_stdout.txt",
    "code_path": "problem_iter20_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic balancing utilization, waste, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    feasible_caps = bins_remain_cap[feasible_bins]\n    remaining_after_fit = feasible_caps - item\n    utilization = item / feasible_caps\n    normalized_waste = remaining_after_fit / (item + feasible_caps)\n\n    priorities[feasible_bins] = utilization**1.5 - normalized_waste #Balance act\n\n    #Adaptive exploration\n    num_feasible = np.sum(feasible_bins)\n    exploration_scale = 0.01 if num_feasible > 3 else 0.05\n    priorities += np.random.normal(0, exploration_scale, size=len(priorities))\n\n    # Fragment penalty (adaptive)\n    frag_threshold = 0.15 * item  # Dynamic threshold\n    small_frag = (remaining_after_fit > 0) & (remaining_after_fit < frag_threshold)\n    priorities[feasible_bins][small_frag] -= 0.08 # Reduce priority\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response3.txt_stdout.txt",
    "code_path": "problem_iter20_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive bin selection: combines normalized waste, bin utilization, and controlled exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf #Or zero\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    bin_capacity = bins_remain_cap.max()\n\n    waste_normalized = waste / bin_capacity\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n\n    bin_utilization = (bins_remain_cap - waste) / bin_capacity\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n\n    # Prioritize bins that are already somewhat full\n    utilization_bonus = 0.2 * bin_utilization\n\n    # Discourage creating very small fragments.\n    fragment_penalty_threshold = 0.1 * item #Relative to item size\n    fragment_penalty = np.where(waste < fragment_penalty_threshold, 0.3, 0)\n\n    #Adaptive exploration noise\n    num_feasible_bins = np.sum(feasible_bins)\n    exploration_scale = 0.02 * (1 - (num_feasible_bins / len(bins_remain_cap))) #Scale down noise if most bins are viable\n    noise = np.random.normal(0, exploration_scale, size=len(bins_remain_cap))\n\n    priorities[feasible_bins] = (1 - waste_normalized[feasible_bins]) + utilization_bonus[feasible_bins] - fragment_penalty[feasible_bins] + noise[feasible_bins]\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 5.963302752293574,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response4.txt_stdout.txt",
    "code_path": "problem_iter20_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, utilization, and adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if not np.any(feasible_mask):\n        return priorities\n\n    # Core: Normalized waste *after* placement\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    normalized_waste = remaining_capacity_after_fit / bins_remain_cap.max()\n    priorities[feasible_mask] = 1.0 - np.clip(normalized_waste, 0, 1)\n\n    num_feasible = np.sum(feasible_mask)\n\n    # Adaptive exploration\n    if num_feasible <= 3:\n        exploration_noise_scale = 0.15\n    elif num_feasible > 5:\n        exploration_noise_scale = 0.01\n    else:\n        exploration_noise_scale = 0.05\n\n    priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n    # Discourage tiny fragments\n    tiny_fragment_threshold = 0.05 * bins_remain_cap.max()\n    tiny_fragment_penalty = 0.5\n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < tiny_fragment_threshold)\n    priorities[feasible_mask][tiny_fragment_mask] *= tiny_fragment_penalty\n\n    # Encourage filling nearly full bins\n    nearly_full_threshold = 0.9 * bins_remain_cap.max()\n    nearly_full_bonus = 0.1\n    nearly_full_mask = (bins_remain_cap >= nearly_full_threshold) & feasible_mask\n    priorities[nearly_full_mask] += nearly_full_bonus\n\n    # Large item in empty bin penalty\n    item_size_threshold_ratio = 0.5\n    large_item_penalty = 0.2\n    bin_size = bins_remain_cap + item\n    large_item_mask = item / bin_size[feasible_mask] > item_size_threshold_ratio\n    bin_utilization = (bins_remain_cap[feasible_mask] - remaining_capacity_after_fit) / bin_size[feasible_mask]\n    empty_bin_mask = bin_utilization < 0.25  # Lower threshold for empty\n    priorities[feasible_mask][large_item_mask & empty_bin_mask] *= (1 - large_item_penalty)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.0885520542481055,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response5.txt_stdout.txt",
    "code_path": "problem_iter20_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic balancing utilization, fragmentation, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n    num_feasible = np.sum(feasible_mask)\n\n    if num_feasible > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / bins_remain_cap.max()\n\n        priorities[feasible_mask] = capacity_ratio**2  # Bin utilization\n\n        # Adaptive exploration\n        if num_feasible <= 3:\n            exploration_noise_scale = 0.15\n        elif num_feasible > 5:\n            exploration_noise_scale = 0.01\n        else:\n            exploration_noise_scale = 0.05\n        priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n        # Fragmentation penalty\n        tiny_fragment_threshold = 0.05 * bins_remain_cap.max()\n        tiny_fragment_penalty = 0.5\n        tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < tiny_fragment_threshold)\n        priorities[feasible_mask][tiny_fragment_mask] *= tiny_fragment_penalty\n\n        # Encourage filling\n        nearly_full_threshold = 0.9 * bins_remain_cap.max()\n        nearly_full_bonus = 0.1\n        nearly_full_mask = (bins_remain_cap >= nearly_full_threshold) & feasible_mask\n        priorities[nearly_full_mask] += nearly_full_bonus\n\n        # large item encouragement\n        if item > bins_remain_cap.max() * 0.5:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= 1.1\n\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 146.27044276027124,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response6.txt_stdout.txt",
    "code_path": "problem_iter20_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins balancing utilization, fragmentation, exploration, and item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio**2.0 #Bin Utilization, tuned exponent\n\n        #Small Fragments.\n        small_fragment_threshold = 0.2 * item\n        small_fragment_mask = remaining_capacity_after_fit > 0  & (remaining_capacity_after_fit < small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] *= 0.3  #Small Fragment Penalty\n\n        #Large capacity bonus\n        large_capacity_threshold = 1.5 * item\n        large_capacity_mask = remaining_capacity_after_fit > large_capacity_threshold\n        priorities[feasible_mask][large_capacity_mask] *= 1.2 #Large Capacity Bonus\n\n        #Adaptive exploration\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 4:\n            priorities[feasible_mask] *= (1 + 0.05 * capacity_ratio) #Exploitation\n        else:\n            priorities += np.random.normal(0, 0.1, size=len(priorities)) #Exploration\n\n        #Dynamic fragment penalty\n        fragment_penalty_threshold = 0.3 * item\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * 0.7)\n\n        #Large item bonus\n        if item > bins_remain_cap.max() * 0.6:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + 0.15) #Large item placed in well-utilized bin\n\n        #Almost full bonus\n        almost_full_threshold = bins_remain_cap.max() * 0.1\n        almost_full_mask = remaining_capacity_after_fit < almost_full_threshold #using rem_cap after fit\n        priorities[feasible_mask][almost_full_mask] *= (1 + 0.2) #Almost full bonus\n        \n        priorities += np.random.normal(0, 0.05, size=len(priorities)) #Base exploration noise\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.01874750698045,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response7.txt_stdout.txt",
    "code_path": "problem_iter20_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority function balancing utilization, fragmentation, and exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max()\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / bin_capacity # Use bin_capacity for ratio\n\n        # Core: Bin Utilization (similar to v0, but using bin_capacity)\n        priorities[feasible_mask] = capacity_ratio**2\n\n        # Fragment penalty (v0 style, but adapted)\n        fragment_threshold = 0.2 * bin_capacity\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= 0.7\n\n        # Encourage almost full bins (v0 style)\n        almost_full_threshold = 0.9 * bin_capacity\n        almost_full_mask = remaining_capacity_after_fit < (bin_capacity - almost_full_threshold)\n        priorities[feasible_mask][almost_full_mask] *= 1.2\n\n        # Large item bonus (v1 style, adaptively scaled)\n        large_item_threshold = 0.7 * bin_capacity\n        if item > large_item_threshold:\n            sufficient_capacity_bonus = np.where(remaining_capacity_after_fit > 0.1 * bin_capacity, 0.15, 0) #Slightly adjusted parameters\n            priorities[feasible_mask] += sufficient_capacity_bonus\n\n        # Adaptive Exploration (Combines elements of both)\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible <= 3: # More exploration when few choices\n            priorities += np.random.normal(0, 0.1, size=len(priorities))\n        else:  # Less exploration, more exploitation\n             priorities[feasible_mask] *= (1 + 0.05 * capacity_ratio) # V0 Exploitation\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.47746310331074,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response8.txt_stdout.txt",
    "code_path": "problem_iter20_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities using capacity ratio and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_bins]\n    capacity_ratio = item / feasible_bins_remain_cap\n\n    # Prioritize bins based on capacity ratio with non-linear scaling\n    bin_utilization_exponent = 1.5\n    priorities[feasible_bins] = capacity_ratio**bin_utilization_exponent\n\n    # Adaptive randomness: scale with the average fill level of bins\n    avg_fill_level = np.mean(capacity_ratio) if np.sum(feasible_bins) > 0 else 0.0\n    randomness_scale = 0.01 + (0.04 * avg_fill_level)\n    priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n    # Fragment avoidance: penalize bins that will have very small remaining capacity\n    remaining_capacity_after_fit = bins_remain_cap[feasible_bins] - item\n    small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_bins] * 0.05)\n    priorities[feasible_bins][small_fragment_mask] *= 0.75\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response9.txt_stdout.txt",
    "code_path": "problem_iter20_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering occupancy, fit, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio, favor higher occupancy\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = 1 - occupation_ratio\n\n    # Fit bonus (favor tighter fits, but not too tight)\n    remaining_space = bins_remain_cap[feasible_bins] - item\n    fit_bonus = np.exp(-np.abs(remaining_space) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Adaptive exploration noise based on num of feasible bins\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Small fragment penalty\n    small_fragment_threshold = item * 0.2  # Example threshold\n    small_fragment_penalty = -0.1\n    small_fragment_bins = (remaining_space > 0) & (remaining_space < small_fragment_threshold)\n    priorities[feasible_bins][small_fragment_bins] += small_fragment_penalty\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  }
]