[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, utilization, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Fit score\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / (item + 1e-9))\n    priorities[valid_bins] = fit_score[valid_bins]\n\n    # Bin utilization bonus\n    utilization = item / bins_remain_cap[valid_bins]\n    priorities[valid_bins] += utilization\n\n    # Adaptive noise based on number of valid bins\n    num_valid_bins = np.sum(valid_bins)\n    noise_scale = 0.005 if num_valid_bins > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Encourage bins with mid-level remaining capacities\n    remaining_capacity_after_fit = bins_remain_cap[valid_bins] - item\n    medium_capacity_mask = (remaining_capacity_after_fit >= (item * 0.2)) & (remaining_capacity_after_fit <= (item * 1.5))\n    priorities[valid_bins][medium_capacity_mask] *= 1.1  # Slightly favor medium capacity\n\n    # Exploration bonus if very few bins\n    exploration_prob = 0.3 if num_valid_bins < 3 else 0.1\n    if np.random.rand() < exploration_prob:\n        random_scale = 0.1 * item\n        priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.1284403669724865,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratio, fragment avoidance, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_capacities = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_capacities - item\n        capacity_ratio = item / feasible_capacities\n\n        priorities[feasible_mask] = capacity_ratio\n\n        small_fragment_threshold = 0.05\n        small_fragment_mask = remaining_capacity_after_fit < (feasible_capacities * small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask]) if feasible_capacities.size else 0\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap)) if bins_remain_cap.size else 0\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n             priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio) if capacity_ratio.size else 0\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.068607897885915,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, waste, adaptive noise based on bin state.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    if not np.any(can_fit):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[can_fit]\n\n    utilization = item / feasible_bins_remain_cap\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9) # Prevent division by zero\n\n    bin_utilization = (feasible_bins_remain_cap - waste) / (feasible_bins_remain_cap + 1e-9) #bin utilization for available bins only.\n    is_used_bonus = (bin_utilization > 0).astype(float) # Bin Utilization bonus\n\n    priorities[can_fit] = 0.6*utilization - 0.4*waste_normalized + 0.2 * is_used_bonus #Weighted sum of utilization and normalized waste\n\n    num_feasible = np.sum(can_fit)\n    if num_feasible > 5:\n         priorities[can_fit] *= (1 + 0.02 * utilization)\n\n    exploration_rate = 0.01 + 0.03 * (1 - (np.mean(bins_remain_cap[can_fit]) / np.max(bins_remain_cap))) if np.sum(can_fit) > 0 else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_item_size = np.mean(bins_remain_cap[can_fit])/10 if np.any(can_fit) else 0.1\n    future_fit_penalty = np.where(waste < small_item_size, -0.1 , 0)\n    priorities[can_fit] += future_fit_penalty\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.148384523334677,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, waste normalization, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible = item > bins_remain_cap\n    priorities[infeasible] = -np.inf\n\n    feasible = ~infeasible\n    remaining_capacities = bins_remain_cap[feasible]\n\n    if len(remaining_capacities) > 0:\n        utilization = item / remaining_capacities\n        waste = remaining_capacities - item\n        waste = np.clip(waste, a_min=0, a_max=None)\n        waste_normalized = waste / bins_remain_cap[feasible] # Normalize by original remaining capacity\n\n        priorities[feasible] = utilization - 0.5 * waste_normalized #Balance\n\n        # Adaptive noise\n        num_feasible = np.sum(feasible)\n        noise_scale = 1e-6 * np.mean(bins_remain_cap) if num_feasible > 0 else 1e-5 * np.mean(bins_remain_cap)\n\n        noise = np.random.normal(0, noise_scale, len(priorities))\n        priorities += noise\n\n        #Bin usage bonus\n        bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n        is_used_bonus = (bin_utilization > 0).astype(float)\n        priorities += 0.1 * is_used_bonus  # Encourage using partially filled bins\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratio, fragment avoidance, bin balancing, and adaptive randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance relative to bin size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.108496210610296,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, utilization, and adaptive exploration based on feasible bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf  # Infeasible bins\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    num_potential_bins = np.sum(potential_bins)\n    \n    # Adaptive noise scaling\n    noise_scale = 0.01 if num_potential_bins > 0 else 0.05\n\n    if num_potential_bins > 3:\n        #Emphasize filling bins well when there are many choices. Introduce exploration.\n        priorities = 0.6 * waste_normalized + 0.4 * is_used_bonus + 0.02 * (bin_utilization**2) + np.random.normal(0, noise_scale, size=len(priorities))\n    else:\n        #More exploration when fewer bins are available.\n        priorities = 0.6 * waste_normalized + 0.4 * is_used_bonus + np.random.normal(0, noise_scale, size=len(priorities))\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 3.9988033506182825,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratio, fragment avoidance, target utilization, and adaptive randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment Avoidance (relative to original bin size)\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Target Utilization\n        target_utilization = 0.75\n        utilization = (bins_remain_cap[feasible_mask] - remaining_capacity_after_fit) / bins_remain_cap[feasible_mask]\n        utilization_diff = np.abs(utilization - target_utilization)\n        priorities[feasible_mask] *= (1 - 0.1 * utilization_diff)\n\n        # Adaptive Randomness (based on max capacity used)\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.1284403669724865,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculates bin priorities considering fill ratio, fragmentation, and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n    \n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n\n    capacity_ratio = item / bins_remain_cap\n    capacity_ratio = np.clip(capacity_ratio, a_min=0, a_max=1) # Ensure ratio is bounded\n\n    # Fragmentation penalty: higher penalty for smaller waste\n    fragment_penalty = np.exp(-waste / (item * 0.5))  # Exponential penalty\n    fragment_penalty[~feasible_bins] = 1.0 #no penalty if infeasible\n\n    bin_utilization = (bins_remain_cap - waste) / (bins_remain_cap + 1e-9)\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n    \n    # Combine factors with weights, scaling with capacity ratio\n    priorities[feasible_bins] = (0.6 * capacity_ratio[feasible_bins] - 0.2 * fragment_penalty[feasible_bins] + 0.2 * bin_utilization[feasible_bins])\n\n    #Adaptive exploration with noise\n    num_feasible = np.sum(feasible_bins)\n    exploration_factor = min(0.1, 1 / (num_feasible + 1))\n\n    priorities += np.random.normal(0, exploration_factor, size=len(priorities))\n\n    # Additional penalty for bins with very little waste to avoid creating tiny fragments.\n    near_full_mask = waste < np.mean(bins_remain_cap) * 0.05 #Adaptive\n    priorities[feasible_bins & near_full_mask] -= 0.05\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.198244914240141,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Return priority score for each bin to pack the item into.\n    Combines capacity ratio, fragment avoidance, and adaptive exploration.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance relative to item size\n        small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask] *= 0.5\n\n        # Favor bins close to item size\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Dynamic fragment penalty\n        fragment_penalty_threshold = item * 0.2\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * 0.3)\n\n        # Adaptive Randomness: scaled to max capacity\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/Exploitation balance\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.11846828879138,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, bin utilization, adaptive noise, and a dynamic item penalty.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf  # Infeasible bins get negative infinity priority\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None) # Ensure waste is non-negative\n\n    waste_normalized = 1 - (waste / (bins_remain_cap + 1e-9)) # Normalize waste; prevent division by zero\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)  # Ensure normalized waste is within [0, 1]\n\n    bin_utilization = (bins_remain_cap - waste) / (bins_remain_cap + 1e-9) # Calculate bin utilization; prevent division by zero\n    is_used_bonus = (bin_utilization > 0).astype(float)  # Give a bonus to bins already in use\n\n    num_potential_bins = np.sum(potential_bins)\n    noise_scale = 0.01 if num_potential_bins > 0 else 0.05 # Smaller noise when good bins exist\n\n    # Adaptive noise and weights\n    if num_potential_bins > 3:  # More bins, emphasize exploitation\n        priorities = 0.7 * waste_normalized + 0.3 * is_used_bonus + 0.02 * (bin_utilization**2) + np.random.normal(0, noise_scale, size=len(priorities)) # Emphasize bin_utilization even more using power\n    else:  # Fewer bins, emphasize exploration\n        priorities = 0.7 * waste_normalized + 0.3 * is_used_bonus + np.random.normal(0, noise_scale, size=len(priorities)) # Standard noise for exploration\n    \n    small_item_size = np.mean(bins_remain_cap[bins_remain_cap>0])/10 if np.any(bins_remain_cap > 0) else 0.1\n    future_fit_penalty = np.where(waste < small_item_size, -0.1 , 0) # Add penalty when waste is less than small_item_size to avoid small fragments\n    priorities[potential_bins] += future_fit_penalty[potential_bins]\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.317909852413238,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response0.txt_stdout.txt",
    "code_path": "problem_iter15_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_occupation_exponent: float = 2.0,\n                item_size_relative_importance: float = 0.5) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_occupation_exponent: Exponent to adjust the impact of bin occupation ratio.\n        item_size_relative_importance: Relative importance of the item size when calculating the bin score\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n        \n        # Bin occupation ratio, raised to a power\n        bin_occupation_ratio = (feasible_bins_remain_cap - remaining_capacity_after_fit) / feasible_bins_remain_cap\n        priorities[feasible_mask] = np.power(bin_occupation_ratio, bin_occupation_exponent)\n        \n        # Adjust priority based on item size relative to bin capacity\n        priorities[feasible_mask] += item_size_relative_importance * capacity_ratio\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Adaptive exploration noise\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n            exploration_noise_level = base_exploration_noise / (1 + exploitation_bonus)\n        else:  # Fewer options, more exploration\n            exploration_noise_level = exploration_noise * (1 + exploitation_bonus)\n        priorities += np.random.normal(0, exploration_noise_level, size=len(priorities))\n\n        # Dynamic fragment penalty\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response1.txt_stdout.txt",
    "code_path": "problem_iter15_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_occupation_threshold: float = 0.75,\n                occupation_bonus: float = 0.15) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_occupation_threshold: Threshold for bin occupation ratio above which a bonus is applied.\n        occupation_bonus: Bonus factor for bins with high occupation.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / (feasible_bins_remain_cap + item) #changed from item/feasible_bins_remain_cap to normalize\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Encourage bins that are already highly occupied\n        bin_occupation_ratios = (bins_remain_cap[feasible_mask] + item - remaining_capacity_after_fit) / (bins_remain_cap[feasible_mask] + item) # Calculate bin occupation ratio\n        occupied_bin_mask = bin_occupation_ratios > bin_occupation_threshold\n        priorities[feasible_mask][occupied_bin_mask] *= (1 + occupation_bonus)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.597128041483859,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response2.txt_stdout.txt",
    "code_path": "problem_iter15_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_utilization_exponent: float = 2.0,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_bonus: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent  # Increased impact of utilization\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Bonus for placing large items in well-utilized bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7 # consider a bin well-utilized if 70% filled with new item\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 3.8891104906262464,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response3.txt_stdout.txt",
    "code_path": "problem_iter15_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_fullness_threshold: float = 0.8,\n                full_bin_bonus: float = 0.1,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_penalty: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_fullness_threshold: Threshold for considering a bin as full.\n        full_bin_bonus: Bonus for filling bins close to full.\n        item_size_threshold_ratio: Threshold ratio for considering an item as large.\n        large_item_penalty: Penalty for placing large items in bins with little remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # NEW: Bonus for filling bins that are already relatively full\n        bin_fullness = 1 - (feasible_bins_remain_cap / (feasible_bins_remain_cap + item)) # Current fullness ratio\n        full_bin_mask = bin_fullness > bin_fullness_threshold\n        priorities[feasible_mask][full_bin_mask] *= (1 + full_bin_bonus)\n\n        # NEW: Penalty for placing large items in bins that will have very little remaining capacity\n        is_large_item = item > (np.mean(bins_remain_cap[~infeasible_mask]) * item_size_threshold_ratio if np.sum(~infeasible_mask) > 0 else 0)\n        if is_large_item:\n             low_capacity_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n             priorities[feasible_mask][low_capacity_mask] *= (1 - large_item_penalty)\n\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response4.txt_stdout.txt",
    "code_path": "problem_iter15_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_utilization_threshold: float = 0.75,\n                utilization_bonus: float = 0.1,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_penalty: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_threshold: Threshold for bin utilization to apply bonus.\n        utilization_bonus: Bonus for bins exceeding the utilization threshold.\n        item_size_threshold_ratio: Threshold ratio for item size relative to bin capacity.\n        large_item_penalty: Penalty for placing large items in mostly empty bins.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # NEW: Bin Utilization Bonus\n        bin_size = bins_remain_cap + item #Approximate the original size of each bin.\n        utilization_ratio = (bin_size - feasible_bins_remain_cap) / bin_size[feasible_mask]\n        high_utilization_mask = utilization_ratio > bin_utilization_threshold\n        priorities[feasible_mask][high_utilization_mask] *= (1 + utilization_bonus)\n\n        # NEW: Penalty for placing large items in relatively empty bins\n        large_item_mask = item / bin_size[feasible_mask] > item_size_threshold_ratio\n        empty_bin_mask = utilization_ratio < (1 - bin_utilization_threshold) # consider bins less than (1 - bin_utilization_threshold) utilized as relatively empty\n        priorities[feasible_mask][large_item_mask & empty_bin_mask] *= (1 - large_item_penalty) # Penalize placing large items in almost empty bins.\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 3.9688871160749857,
    "exec_success": true
  }
]