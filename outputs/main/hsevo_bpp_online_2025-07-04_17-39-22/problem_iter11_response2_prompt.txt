{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                waste_normalized_weight: float = 0.9949753577776109,\n                is_used_bonus_weight: float = 0.3109911267994212,\n                noise_scale_potential_bins_exist: float = 0.05169531806696165,\n                noise_scale_potential_bins_not_exist: float = 0.06283601965620603) -> np.ndarray:\n    \"\"\"Adaptive priority: Combines waste normalization, fullness, and dynamic noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    # Dynamic noise based on number of potential bins\n    num_potential_bins = np.sum(potential_bins)\n    noise_scale = noise_scale_potential_bins_exist if num_potential_bins > 0 else noise_scale_potential_bins_not_exist  # Higher noise if no good bins\n    priorities = waste_normalized_weight * waste_normalized + is_used_bonus_weight * is_used_bonus + np.random.normal(0, noise_scale, size=len(priorities))\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic: Combines capacity ratio, fragment avoidance, and dynamic exploration-exploitation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    \n    if np.sum(feasible_mask) > 0:\n        remaining_after_fit = bins_remain_cap[feasible_mask] - item\n        capacity_ratio = item / bins_remain_cap[feasible_mask]\n        \n        # Base priority on capacity ratio\n        priorities[feasible_mask] = capacity_ratio\n\n        # Small fragment penalty\n        small_fragment_threshold = 0.2  # Tuneable\n        small_fragment_penalty = 0.7\n        small_fragment_mask = remaining_after_fit < (item * small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Large capacity bonus\n        large_capacity_threshold = 2.0 # Tuneable\n        large_capacity_bonus = 1.1\n        large_capacity_mask = remaining_after_fit > (item * large_capacity_threshold)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Adaptive exploration/exploitation\n        num_feasible = np.sum(feasible_mask)\n        exploration_prob = 0.3 if num_feasible < 3 else 0.1 # Tuneable\n        \n        if np.random.rand() < exploration_prob:\n            random_scale = 0.1 * item  #Tuneable\n            priorities += np.random.normal(0, random_scale, size=len(priorities))\n        else:\n            exploitation_bonus = 0.05 # Tuneable\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor full bins.\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines normalized waste and bin utilization with dynamic noise, while the worst focuses on capacity ratio, waste, and dynamic noise but adds a penalty for bins becoming nearly full, a bonus for perfect fills, and normalizes priorities.\n(2nd best) vs (2nd worst): the second best balances fit, waste, fullness, and randomness, boosting bins with smaller remaining capacity and using adaptive noise. The second worst, similar to the worst, includes capacity ratio, waste, dynamic noise, near-full bin discouragement, and encourages re-use of nearly full bins.\nComparing (1st) vs (2nd), we see that the best uses a simpler noise scaling strategy based on the number of potential bins, while the second best scales noise by the mean remaining capacity of potential bins.\n(3rd) vs (4th): these two are identical.\nComparing (2nd worst) vs (worst), we see the second worst offers more encouragement toward usage of bins already nearly full while the worst also has near full bin discourage. Overall:\n\n*   **Feature Importance:** The best heuristics prioritize normalized waste and bin utilization. Penalizing future waste and rewarding already utilized bins appears effective.\n*   **Noise Scaling:** Simpler noise scaling mechanisms tied directly to the number of viable bins perform better. Complex scaling with bin capacities may be less effective.\n*   **Over-Engineering:** The worst heuristics attempt too many adjustments (penalties/bonuses) based on fine-grained conditions (e.g., nearly full bins, perfect fills). This can lead to instability.\n*   **Balanced Approach:** Adaptive exploration and exploitation is important, but overemphasizing either can be detrimental. Adaptive randomness, controlled by average bin fill levels or number of feasible bins, are used to break the tie.\n- \nOkay, let's redefine \"Current Self-Reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection.\"\n\nHere's a revised approach focusing on iterative improvement and targeted adjustments:\n\n*   **Keywords:** Iterative refinement, targeted complexity, performance analysis, problem-specific adaptation.\n*   **Advice:** Focus on iterative development, rigorously testing each added complexity for tangible performance gains on diverse instances. Analyze performance bottlenecks and tailor adjustments accordingly.\n*   **Avoid:** Premature optimization, over-reliance on intuition without empirical validation, generic solutions failing to adapt to specific problem characteristics.\n*   **Explanation:** Prioritize data-driven decisions. Base heuristic refinement on performance evaluation against specific problem instances rather than assumptions. Complexity should only be added if demonstrably beneficial.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}