[
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, bin utilization, and adaptive exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf\n\n    if np.sum(feasible_bins) == 0:\n        return priorities\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    bin_utilization = np.clip(bin_utilization, a_min=0, a_max=1)\n    is_used_bonus = (bin_utilization > 0).astype(float)\n    capacity_ratio = item / bins_remain_cap\n    capacity_ratio = np.clip(capacity_ratio, a_min=0, a_max=1)\n\n    num_feasible_bins = np.sum(feasible_bins)\n    noise_scale = 0.01 if num_feasible_bins > 0 else 0.05\n\n    if num_feasible_bins > 3:\n        bin_utilization_exponent = 2.0\n        priorities[feasible_bins] = 0.5 * waste_normalized[feasible_bins] + 0.3 * is_used_bonus[feasible_bins] + 0.2 * (capacity_ratio[feasible_bins]**bin_utilization_exponent) + np.random.normal(0, noise_scale, size=num_feasible_bins)\n    else:\n        priorities[feasible_bins] = 0.6 * waste_normalized[feasible_bins] + 0.4 * is_used_bonus[feasible_bins] + np.random.normal(0, noise_scale, size=num_feasible_bins)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic balancing bin utilization, waste, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    if not np.any(feasible_mask):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n    capacity_ratio = item / feasible_bins_remain_cap\n    bin_utilization_exponent = 2.0\n    priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9)\n\n    priorities[feasible_mask] = 0.7*capacity_ratio - 0.3*waste_normalized # Adjust weights\n\n    num_feasible = np.sum(feasible_mask)\n    if num_feasible > 5:\n        priorities[feasible_mask] *= (1 + 0.03 * capacity_ratio)\n\n    exploration_rate = 0.01 + 0.03 * (1 - np.mean(bins_remain_cap[feasible_mask]) / np.max(bins_remain_cap)) if np.any(feasible_mask) else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_fragment_threshold_ratio = 0.2\n    small_fragment_penalty = 0.3\n    small_fragment_mask = waste < (item * small_fragment_threshold_ratio)\n    priorities[feasible_mask][small_fragment_mask] *= (1 - small_fragment_penalty)\n\n    item_size_threshold_ratio = 0.5\n    large_item_bonus = 0.1\n    if item > bins_remain_cap.max() * item_size_threshold_ratio:\n        well_utilized_mask = capacity_ratio > 0.7\n        priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, utilization, exploration, and fragment handling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Normalized capacity ratio (fit score)\n    feasible_bins_remain_cap = bins_remain_cap[valid_bins]\n    capacity_ratio = item / feasible_bins_remain_cap  # Normalize by remaining capacity\n    bin_utilization_exponent = 2.0  # Emphasize near-full bins\n    priorities[valid_bins] = capacity_ratio**bin_utilization_exponent\n\n\n    # Fragment penalty\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    fragment_threshold_ratio = 0.2 #tuned value\n    small_fragment_mask = remaining_capacity_after_fit < (item * fragment_threshold_ratio)\n    fragment_penalty = 0.7\n    priorities[valid_bins][small_fragment_mask] *= fragment_penalty\n\n    # Exploration noise\n    num_valid_bins = np.sum(valid_bins)\n    exploration_noise_scale = 0.01 if num_valid_bins > 3 else 0.05  # Reduce noise if many options\n    priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.01874750698045,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins, combining capacity ratio,\n    fragment avoidance, bin balancing, and adaptive randomness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Non-linear scaling to favor well-utilized bins\n        bin_utilization_exponent = 1.5\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Fragment avoidance relative to bin size and item size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        small_fragment_mask_item_relative = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask_item_relative] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, waste normalization, and adaptive noise with bin utilization exponent.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible = item > bins_remain_cap\n    priorities[infeasible] = -np.inf\n\n    feasible = ~infeasible\n    remaining_capacities = bins_remain_cap[feasible]\n\n    if len(remaining_capacities) > 0:\n        capacity_ratio = item / remaining_capacities\n        bin_utilization_exponent = 2.0  # Example exponent, can be tuned\n\n        priorities[feasible] = capacity_ratio**bin_utilization_exponent\n\n        waste = remaining_capacities - item\n        waste = np.clip(waste, a_min=0, a_max=None)\n        waste_normalized = waste / bins_remain_cap[feasible]\n\n        priorities[feasible] -= 0.5 * waste_normalized\n\n        # Adaptive noise based on remaining cap\n        num_feasible = np.sum(feasible)\n        noise_scale = 1e-6 * np.mean(bins_remain_cap) if num_feasible > 0 else 1e-5 * np.mean(bins_remain_cap)\n\n        noise = np.random.normal(0, noise_scale, len(priorities))\n        priorities += noise\n\n        #Bin usage bonus\n        bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n        is_used_bonus = (bin_utilization > 0).astype(float)\n        priorities += 0.1 * is_used_bonus  # Encourage using partially filled bins\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response5.txt_stdout.txt",
    "code_path": "problem_iter17_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized waste and bin utilization with exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    feasible_bins_remain_cap = bins_remain_cap[valid_bins]\n\n    # Normalized Waste Score (Core Intuition)\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    normalized_waste = remaining_capacity_after_fit / (item + feasible_bins_remain_cap) # normalized by both item and remaining capacity\n    priorities[valid_bins] = -normalized_waste # smaller waste better\n\n    # Bin Utilization Bonus (Exploitation)\n    utilization = item / feasible_bins_remain_cap\n    priorities[valid_bins] += utilization**2  # Non-linear\n\n    #Adaptive noise for Exploration\n    num_valid_bins = np.sum(valid_bins)\n    noise_scale = 0.01 if num_valid_bins > 3 else 0.07\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Edge Case Handling: Small Fragments Penalty\n    small_fragment_threshold = 0.2 * item\n    small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < small_fragment_threshold)\n    priorities[valid_bins][small_fragment_mask] -= 0.1 # Penalize small waste\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response6.txt_stdout.txt",
    "code_path": "problem_iter17_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized capacity ratio, fragment avoidance, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Optimal space\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Adaptive randomness\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.0885520542481055,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response7.txt_stdout.txt",
    "code_path": "problem_iter17_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on occupancy, item fit, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - 1e9\n\n    # Core: Bin occupancy ratio\n    occupation_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = 1 - occupation_ratio\n\n    # Fit bonus (favor tighter fits)\n    fit_bonus = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item) / (item + 1e-9))\n    priorities[feasible_bins] += fit_bonus * 0.2\n\n    # Adaptive exploration noise\n    num_feasible = np.sum(feasible_bins)\n    noise_scale = 0.005 if num_feasible > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response8.txt_stdout.txt",
    "code_path": "problem_iter17_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities, balancing bin utilization, fragmentation, and exploration.\"\"\"\n\n    small_fragment_threshold_ratio: float = 0.2\n    small_fragment_penalty: float = 0.3\n    large_capacity_threshold_ratio: float = 1.8\n    large_capacity_bonus: float = 1.5\n    base_exploration_noise: float = 0.04\n    num_feasible_bins_threshold: int = 5\n    exploitation_bonus: float = 0.04\n    exploration_noise: float = 0.06\n    fragment_penalty_threshold_ratio: float = 0.3\n    fragment_penalty_factor: float = 0.6\n    bin_utilization_exponent: float = 2.0\n    item_size_threshold_ratio: float = 0.5\n    large_item_bonus: float = 0.1\n    bin_fullness_threshold: float = 0.8\n    full_bin_bonus: float = 0.1\n\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n\n        bin_fullness = 1 - (feasible_bins_remain_cap / (bins_remain_cap[feasible_mask]))\n\n        full_bin_mask = bin_fullness > bin_fullness_threshold\n        priorities[feasible_mask][full_bin_mask] *= (1 + full_bin_bonus)\n\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities",
    "response_id": 8,
    "tryHS": true,
    "obj": 3.9090546469884373,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering utilization, waste, and adaptive exploration.\n    Combines normalized waste and utilization with exploration based on bin state.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    if not np.any(can_fit):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[can_fit]\n\n    utilization = item / feasible_bins_remain_cap\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9)  # Prevent division by zero\n\n    bin_utilization = (feasible_bins_remain_cap - waste) / (bins_remain_cap[can_fit] + item)  # corrected bin util calculation\n\n    priorities[can_fit] = 0.7 * utilization - 0.3 * waste_normalized  # Adjusted weights\n\n    num_feasible = np.sum(can_fit)\n    if num_feasible > 5:\n        priorities[can_fit] *= (1 + 0.02 * utilization) # Favor bins that are already relatively full\n\n    exploration_rate = 0.01 + 0.03 * (1 - (np.mean(bins_remain_cap[can_fit]) / np.max(bins_remain_cap))) if np.sum(can_fit) > 0 else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_item_size = np.mean(bins_remain_cap[can_fit]) / 10 if np.any(can_fit) else 0.1\n    future_fit_penalty = np.where(waste < small_item_size, -0.1, 0)\n    priorities[can_fit] += future_fit_penalty\n\n    # NEW:  Penalty for placing large items in relatively empty bins\n    item_size_threshold_ratio = 0.5\n    large_item_penalty = 0.2\n    bin_size = bins_remain_cap + item  # Approximate original bin size.\n    large_item_mask = item / bin_size[can_fit] > item_size_threshold_ratio\n    bin_utilization_threshold = 0.75\n    empty_bin_mask = bin_utilization < (1 - bin_utilization_threshold) # consider bins less than (1 - bin_utilization_threshold) utilized as relatively empty\n    priorities[can_fit][large_item_mask & empty_bin_mask] *= (1 - large_item_penalty) # Penalize placing large items in almost empty bins.\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.1284403669724865,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max()  # Assuming all bins have the same capacity\n\n    # Infeasible bins get negative infinity priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Feasible bins\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        \n        # Core heuristic: Normalized waste (lower is better, so use inverse)\n        normalized_waste = remaining_capacity_after_fit / bin_capacity\n        priorities[feasible_mask] = 1 / (1e-6 + normalized_waste) # adding small constant to prevent division by zero\n\n        # Adjustments:\n        # 1. Encourage filling bins well (but not perfectly)\n        utilization = item / (bin_capacity - remaining_capacity_after_fit) # item size divided by original bin capacity\n        priorities[feasible_mask] += np.clip(utilization, 0, 0.95) # clip to avoid prioritizing completely full bins\n\n        # 2. Discourage small fragments (graded penalty)\n        small_fragment_threshold = 0.1 * bin_capacity\n        small_fragment_penalty = np.where(remaining_capacity_after_fit < small_fragment_threshold,\n                                            -0.5 * (1 - (remaining_capacity_after_fit / small_fragment_threshold)),\n                                            0)\n        priorities[feasible_mask] += small_fragment_penalty\n\n        # 3. Encourage placing large items in bins with enough remaining capacity to avoid excessive fragmentation of other items.\n        large_item_threshold = 0.75 * bin_capacity\n        if item > large_item_threshold:\n            sufficient_capacity_bonus = np.where(remaining_capacity_after_fit > 0.2 * bin_capacity,\n                                                0.2, # Bonus for sufficient capacity\n                                                0)\n            priorities[feasible_mask] += sufficient_capacity_bonus\n        \n\n        # 4. Exploration: Adaptive noise based on number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible <= 3:\n             priorities[feasible_mask] += np.random.normal(0, 0.1, size=num_feasible)\n        else:\n            priorities[feasible_mask] += np.random.normal(0, 0.01, size=num_feasible)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response1.txt_stdout.txt",
    "code_path": "problem_iter18_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes simplicity and adaptivity.  The core is based on\n    normalized remaining waste if the item is placed in the bin.  Edge cases\n    (small fragments, nearly-full bins) are handled explicitly and smoothly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max() #Assumes all bins have the same capacity\n\n    # Infeasible bins get zero priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = 0.0\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n\n        # Core Heuristic: Normalized Waste (lower is better)\n        normalized_waste = remaining_capacity_after_fit / bin_capacity\n        priorities[feasible_mask] = 1.0 - normalized_waste  # Convert to a higher-is-better priority\n\n        # Edge Case 1: Small Fragment Penalty (smoothly applied)\n        small_fragment_threshold = 0.2 * item # Relative to item size\n        small_fragment_penalty = 0.5 # Reduce priority by this much\n\n        small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < small_fragment_threshold)\n        fragment_penalty_factor = remaining_capacity_after_fit[small_fragment_mask] / small_fragment_threshold\n        priorities[feasible_mask][small_fragment_mask] *= (1.0 - fragment_penalty_factor * small_fragment_penalty)\n\n        # Edge Case 2: Near-Full Bin Bonus (smoothly applied)\n        near_full_threshold = 0.9 * bin_capacity #Relative to bin capacity.\n        near_full_bonus = 0.1 #Increase priority by this much.\n\n        near_full_mask = feasible_bins_remain_cap - item > 0  # Check for valid indices before using the mask\n        near_full_mask = near_full_mask & (feasible_bins_remain_cap > near_full_threshold)\n        priorities[feasible_mask][near_full_mask] *= (1.0 + near_full_bonus)\n\n        # Adaptivity: Exploration Noise (proportional to remaining bins)\n        num_feasible = np.sum(feasible_mask)\n        exploration_noise_scale = 0.05\n        exploration_noise = np.random.normal(0, exploration_noise_scale * (1.0 - (num_feasible / len(bins_remain_cap))), size=len(priorities))\n        priorities += exploration_noise\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version focuses on simplicity, adaptability, and balancing exploration/exploitation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    num_feasible = np.sum(feasible_mask)\n\n    if num_feasible > 0:\n        # Core heuristic: Normalized remaining capacity *after* placement.  Lower is better.\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        normalized_waste = remaining_capacity_after_fit / bins_remain_cap.max()  # Normalize by max bin size for consistency\n\n        # Assign initial priorities based on normalized waste (invert, smaller waste = higher priority)\n        priorities[feasible_mask] = 1.0 - np.clip(normalized_waste, 0, 1)\n\n        # Adaptive Exploration/Exploitation: Adjust randomness based on the number of options.\n        if num_feasible <= 3: # Increased exploration when few options exist\n            exploration_noise_scale = 0.15 # Higher exploration noise\n        elif num_feasible > 5: # Focus on exploitation when multiple bins are feasible\n            exploration_noise_scale = 0.01\n        else:\n            exploration_noise_scale = 0.05 # medium exploration\n\n        priorities += np.random.normal(0, exploration_noise_scale, size=len(priorities))\n\n        # Edge Case Handling:\n        #   1. Discourage tiny fragments.\n        tiny_fragment_threshold = 0.05 * bins_remain_cap.max() # Dynamic threshold\n        tiny_fragment_penalty = 0.5\n\n        tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < tiny_fragment_threshold)\n        priorities[feasible_mask][tiny_fragment_mask] *= tiny_fragment_penalty  # Apply penalty\n\n        # 2. Encourage filling nearly full bins to completion.\n        nearly_full_threshold = 0.9 * bins_remain_cap.max()\n        nearly_full_bonus = 0.1\n\n        nearly_full_mask = (bins_remain_cap >= nearly_full_threshold) & feasible_mask\n        priorities[nearly_full_mask] += nearly_full_bonus\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response3.txt_stdout.txt",
    "code_path": "problem_iter18_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.2,\n                small_fragment_penalty: float = 0.3,\n                large_capacity_threshold_ratio: float = 1.5,\n                large_capacity_bonus: float = 1.2,\n                base_exploration_noise: float = 0.05,\n                num_feasible_bins_threshold: int = 4,\n                exploitation_bonus: float = 0.05,\n                exploration_noise: float = 0.1,\n                fragment_penalty_threshold_ratio: float = 0.3,\n                fragment_penalty_factor: float = 0.7,\n                bin_utilization_exponent: float = 2.0,\n                item_size_threshold_ratio: float = 0.6,\n                large_item_bonus: float = 0.15,\n                almost_full_threshold_ratio: float = 0.9,\n                almost_full_bonus: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n        almost_full_threshold_ratio: Threshold ratio for considering a bin almost full.\n        almost_full_bonus: Bonus for placing item in an almost full bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Core: Bin Utilization\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        # Edge Case: Small Fragments\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Edge Case: Large Capacity\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Adaptive Exploration/Exploitation\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # Exploit\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:  # Explore\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        # Dynamic Fragment Penalty\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n        # Bonus for Large Items in Well-Utilized Bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n        # Bonus for Almost Full Bins\n        almost_full_mask = remaining_capacity_after_fit < (bins_remain_cap.max() * (1-almost_full_threshold_ratio))\n        priorities[feasible_mask][almost_full_mask] *= (1 + almost_full_bonus)\n\n        # Base exploration noise\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap.max() # Assume all bins have the same capacity, and find what it is.\n\n    # Infeasible bin handling: set to negative infinity\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        \n        # Core heuristic: Normalized Remaining Waste (NRW).  Smaller is better.\n        normalized_waste = remaining_capacity_after_fit / bin_capacity\n        priorities[feasible_mask] = -normalized_waste # Larger negative value means higher priority (smaller waste)\n        \n        # Adaptivity: Bin Selection Pressure\n        num_feasible = np.sum(feasible_mask)\n        \n        if num_feasible > 3:\n            # Exploitation: Penalize bins with high normalized waste *more*.\n            priorities[feasible_mask] -= (normalized_waste**2) # Quadratic penalty for larger waste\n        else:\n            # Exploration: Add noise to encourage diversity\n            priorities += np.random.normal(0, 0.05, size=len(priorities))\n\n        # Edge case handling: Small fragment penalty\n        small_fragment_threshold = 0.15 * bin_capacity\n        small_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] -= 0.1  #Fixed penalty for small fragments.\n\n        # Edge case handling: Near-full bonus\n        near_full_threshold = 0.9 * bin_capacity\n        near_full_mask = bins_remain_cap[feasible_mask] > item and (bins_remain_cap[feasible_mask] - item) / bin_capacity < 0.1 # Fill bin to at least 90%.\n        \n        priorities[feasible_mask][near_full_mask] += 0.05 # Slight bonus if bin is almost full\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 47, in priority_v2\n    near_full_mask = bins_remain_cap[feasible_mask] > item and (bins_remain_cap[feasible_mask] - item) / bin_capacity < 0.1 # Fill bin to at least 90%.\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
  },
  {
    "stdout_filepath": "problem_iter19_response2.txt_stdout.txt",
    "code_path": "problem_iter19_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.42930164155899714,\n                small_fragment_penalty: float = 0.972137924647054,\n                large_capacity_threshold_ratio: float = 2.8187542828129244,\n                large_capacity_bonus: float = 1.9645257536386707,\n                base_exploration_noise: float = 0.03304726537524623,\n                num_feasible_bins_threshold: int = 8.767972008397969,\n                exploitation_bonus: float = 0.03824933698367995,\n                exploration_noise: float = 0.1843279331231594,\n                fragment_penalty_threshold_ratio: float = 0.4881732906738122,\n                fragment_penalty_factor: float = 0.35444206464132066,\n                bin_utilization_exponent: float = 2.6384245424129045,\n                item_size_threshold_ratio: float = 0.40827293751380256,\n                large_item_bonus: float = 0.10347161476939143,\n                bin_fullness_threshold: float = 0.5591415246263047,\n                full_bin_bonus: float = 0.15134896160709246) -> np.ndarray:\n    \"\"\"Calculate bin priorities, balancing bin utilization, fragmentation, and exploration.\"\"\"\n\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio)\n        else:\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities))\n\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n\n        bin_fullness = 1 - (feasible_bins_remain_cap / (bins_remain_cap[feasible_mask]))\n\n        full_bin_mask = bin_fullness > bin_fullness_threshold\n        priorities[feasible_mask][full_bin_mask] *= (1 + full_bin_bonus)\n\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities",
    "response_id": 2,
    "tryHS": true,
    "obj": 3.8891104906262464,
    "exec_success": true
  }
]