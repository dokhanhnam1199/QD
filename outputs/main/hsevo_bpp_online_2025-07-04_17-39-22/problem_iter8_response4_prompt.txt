{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask] *= 0.5\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * 2)\n        priorities[feasible_mask][large_capacity_mask] *= 1.1\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, 0.01, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + 0.01 * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, 0.05, size=len(priorities)) # Higher randomness\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several improvements:\n    1. Adaptive penalty for near-full bins:  A bin that's *almost* full but can't fit the item gets a moderate negative priority to discourage creating tiny fragments.\n    2. Encourages packing items of similar sizes together.\n    3. Dynamic noise injection based on bin utilization.\n    4. Considers bin fullness when prioritizing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bin handling: Hard constraint.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_capacities = bins_remain_cap[feasible_mask]\n    remaining_capacity_after_fit = feasible_capacities - item\n    capacity_ratio = item / feasible_capacities\n\n    # Near-full bin penalty:  Discourage tiny fragments.\n    near_full_threshold = 0.1  # Tune this; relative to bin size.  Bins with <10% of capacity remaining considered near full.\n    near_full_mask = (bins_remain_cap > 0) & (bins_remain_cap < item + near_full_threshold) & (~infeasible_mask)\n    priorities[near_full_mask] = -0.1  # Moderate negative priority, tunable.\n\n    # Encourage packing items of similar sizes by looking at average item sizes already in the bin.\n    # For simplicity, this is a placeholder for now as we don't have bin content information.\n    # In a real implementation, you'd need to track which items are in each bin.\n\n    # Core priority calculation:\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Bin fullness bonus:  Slightly prefer filling emptier bins *initially* (exploration), then switch to filling fuller bins (exploitation).\n    bin_fullness = 1 - bins_remain_cap / np.max(bins_remain_cap)  # Normalize bin fullness\n    priorities += 0.05 * bin_fullness # Added bonus to priorities\n\n    # Adaptive Noise Injection:  Add more noise when bins are relatively empty to promote exploration.\n    utilization = 1 - np.mean(bins_remain_cap / np.max(bins_remain_cap)) # Overall utilization.\n    noise_level = 0.01 * (1 - utilization)  # Higher noise when bins are emptier.\n    priorities += np.random.normal(0, noise_level, size=len(priorities))\n\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first prioritizes capacity ratio, small fragment avoidance, and large capacity bonus, along with adaptive exploration/exploitation based on the number of feasible bins. The last one combines fit score, normalized waste, and randomness. Comparing (2nd) vs (19th), the second allows for fine-grained control over various aspects like fragment thresholds and penalties, and adaptive randomness. The last function in the list is rather basic, only looking at waste, fit, and a bit of noise. Comparing (1st) vs (2nd), the 1st uses hardcoded values while the 2nd exposes hyperparameters for tuning, allowing for more flexibility. (3rd) vs (4th) shows that the 3rd version incorporates an adaptive penalty for near-full bins, encourages packing items of similar sizes, dynamic noise injection. (second worst) vs (worst) indicates the second worst approach attempts waste normalization and bin utilization; the worst approach focuses on fit, remaining capacity, and randomness in a more direct manner. Overall: The better heuristics have more adaptive strategies (adaptive exploration/exploitation, dynamic penalties/bonuses based on bin utilization, remaining capacity, or item size). They also try to balance multiple factors (fit, waste, fullness) and introduce randomness for exploration. The poorer heuristics often use simpler combinations of fit, waste, and randomness, without adapting to the state of the bins.\n- \nOkay, let's redefine \"Current Self-Reflection\" to focus on designing better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection,\" and building on the provided ideas.\n\nHere's a revised approach, aimed at generating more actionable advice:\n\n*   **Keywords:** Adaptive parameters, exploration-exploitation balance, edge case handling, hyperparameter tuning, problem state awareness.\n\n*   **Advice:** Design heuristics that dynamically adjust their behavior based on real-time problem characteristics. Focus on creating tunable parameters that influence the balance between exploration and exploitation.\n\n*   **Avoid:** Overly complex formulas that obscure interpretability, neglecting edge cases.\n\n*   **Explanation:** Prioritize heuristics that \"sense\" the problem state (e.g., bin fill levels) and respond accordingly. This allows for tailored behavior, avoiding rigid rules that perform poorly in certain scenarios.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}