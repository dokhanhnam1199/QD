[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculates bin priorities based on normalized waste and relative fullness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        relative_fullness = 1 - remaining_capacities_can_fit\n        priorities[can_fit] = -waste_normalized + relative_fullness\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization with a fullness preference.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf  # No fit, very low priority\n\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Assign infinite waste to infeasible bins\n    waste_normalized = np.clip(1 - (waste / bins_remain_cap), a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    priorities = waste_normalized + is_used_bonus\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on space utilization and fragmentation.\"\"\"\n    feasible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[~feasible_bins] = -np.inf\n\n    remaining_after_fit = bins_remain_cap[feasible_bins] - item\n    utilization = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = utilization\n\n    fragmentation_penalty = np.exp(-5 * remaining_after_fit)\n    priorities[feasible_bins] -= fragmentation_penalty\n\n    almost_full_bonus = np.exp(-10*np.abs(remaining_after_fit-0.1))\n    priorities[feasible_bins] += 0.1*almost_full_bonus\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 5.195452732349436,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on normalized waste and relative fullness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Prioritize bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        # Normalized waste: smaller waste = higher priority\n        waste = bins_remain_cap[fit_mask] - item\n        priorities[fit_mask] = 1 - (waste / bins_remain_cap[fit_mask])\n\n        # Encourage filling almost full bins\n        priorities[fit_mask] += (bins_remain_cap[fit_mask] / np.max(bins_remain_cap)) #relative fullness\n\n    else:\n        # If no bin fits, minimize overfill (last resort)\n        overfill = item - bins_remain_cap\n        priorities = -overfill / np.max(overfill) #Normalize\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 16, in priority_v2\n    # Boost bins with smaller remaining capacity\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n"
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized waste and relative fullness for priority.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        relative_fullness = 1 - remaining_capacities_can_fit\n        priorities[can_fit] = -waste_normalized + relative_fullness\n        fragmentation_penalty = np.exp(-5 * waste) #waste = remaining_after_fit\n\n        random_factor = 0.01 * np.random.rand(np.sum(can_fit))\n        priorities[can_fit] -= 0.1 * fragmentation_penalty + random_factor\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins based on remaining capacity and item size.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Normalized waste prioritization + Encourage fuller bins.\n    waste = bins_remain_cap[valid_bins] - item\n    waste_normalized = waste / bins_remain_cap[valid_bins]\n    priorities[valid_bins] = 1 - waste_normalized\n\n    # Boost bins with smaller remaining capacity\n    remaining_after_placement = bins_remain_cap[valid_bins] - item\n    remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n    priority_boost = np.exp(-remaining_after_placement)\n    priorities[valid_bins] *= priority_boost\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 29.60710011966495,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects: fit, remaining cap, utilization.\n    Normalizes values and uses weighted sum.\n    \"\"\"\n\n    fit_score = bins_remain_cap - item\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    remaining_cap_penalty = np.where(fit_score >= 0, np.exp(-5 * fit_score), 0)\n\n    utilization_priority = np.zeros_like(bins_remain_cap)\n    initial_capacity = bins_remain_cap + item\n    utilization_priority[fit_score>=0] = 1 / initial_capacity[fit_score>=0]\n\n    priorities = 0.7 * fit_priority + 0.2 * remaining_cap_penalty + 0.1 * utilization_priority\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized waste and relative fullness with a penalty for infeasible bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n\n        relative_fullness = 1 - remaining_capacities_can_fit #Assume bin capacity is 1.\n\n        priorities[can_fit] = -waste_normalized + relative_fullness\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit score, used bin bonus, and normalizes waste.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Disallow overfill\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Fit score\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / item)\n\n    # Used bin bonus\n    is_used_bonus = (bins_remain_cap < 1).astype(float)\n\n    priorities = fit_score + is_used_bonus\n\n    # Normalize waste\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] = priorities[fit_mask] / bins_remain_cap[fit_mask]\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of previous heuristics for improved bin packing.\"\"\"\n\n    # Calculate how much space would be left in each bin if the item were placed\n    fit_score = bins_remain_cap - item\n\n    # Prioritize bins where the item fits, penalize others harshly\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    # Normalize remaining capacity to a [0,1] scale, higher value for near-full bins\n    remaining_normalized = np.zeros_like(bins_remain_cap)\n    remaining_normalized[fit_score >= 0] = 1 - (fit_score[fit_score >= 0] / bins_remain_cap[fit_score >= 0])\n\n    # Combine fit proximity with remaining capacity using a weighted sum.\n    priorities = 0.8 * fit_priority + 0.2 * remaining_normalized\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces a more adaptive priority scheme that considers both\n    relative capacity usage and absolute remaining space, while also penalizing\n    bins that become too full after placement. It incorporates a more robust\n    randomization strategy and a scaling factor based on the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasibility check (same as v1)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Priority based on capacity ratio and remaining space (modified from v1)\n    # Scale the remaining capacity penalty by the item size.  Larger items mean\n    # a larger remaining space is acceptable.\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Penalty for bins that are too full (adaptive penalty)\n    # If the remaining capacity is less than 10% of the bin size, penalize\n    # This encourages the algorithm to find better fitting bins early on.\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5  # Significantly reduce priority\n\n    # Bonus for almost perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2 # Slightly increase priority, avoid zero capacity\n\n    # Adaptive Randomization (scaled by item size)\n    # The amount of noise added depends on item size. Larger items may require more exploration\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Scale priorities to prevent potential overflow issues and improve exploration\n    priorities /= (item + 1e-9)  # Prevent division by zero\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 14.978061428001602,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Encourage bins that fit the item well, but penalize almost-full bins more harshly.\n    # This is a more refined version of the original logic. We want to avoid creating tiny slivers of space.\n    # The exponential penalty is now stronger for very small remaining capacities.  Also, we consider the \"fullness\" of the bin *before* placing the item.\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap)) # added to ensure diversity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-10 * remaining_capacity_after_fit / (item + 1e-9)) * (1-fullness_ratio) # More agressive penalty\n\n    # Bonus for bins that are already relatively full, but not too full to cause tiny slivers. This encourages reuse.\n    # The bonus is scaled by the item size so that smaller items don't overly influence the choice.\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    # Add some randomness, but reduce its intensity\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 21.429996011168736,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Prioritize bins based on a combination of factors for feasible bins\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # 1. Capacity Ratio: Higher ratio means the item fills the bin more completely.\n    priority_capacity_ratio = capacity_ratio\n\n    # 2. Remaining Capacity: Moderate remaining capacity is better than very small or very large.\n    #    We use a Gaussian-like function to penalize extreme remaining capacities.\n    mean_remaining_capacity = item  # Target a remaining capacity close to the item size\n    std_dev_remaining_capacity = item / 2.0  # Adjust the spread as needed\n    priority_remaining_capacity = np.exp(-((remaining_capacity_after_fit - mean_remaining_capacity) ** 2) / (2 * std_dev_remaining_capacity ** 2))\n\n    # 3. Balancing Term: Encourages use of bins with already smaller remaining capacity, but not too small\n    priority_balance = 1.0 / (bins_remain_cap[feasible_mask] + 1e-9)\n\n    # Combine the priorities using a weighted sum or product.\n    priorities[feasible_mask] = (\n        0.5 * priority_capacity_ratio +\n        0.3 * priority_remaining_capacity +\n        0.2 * priority_balance\n    )\n\n    # Add a bit of randomness to break ties.  Reduce the magnitude.\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 6.441962504986052,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bin handling\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Feasible bin prioritization\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Modified priority calculation: combines capacity ratio and remaining capacity, with tunable parameters.\n    alpha = 1.0  # Weighting for capacity ratio\n    beta = 1.0  # Weighting for remaining capacity\n    gamma = 0.1 # Scaling factor for remaining capacity (avoid extreme values)\n\n\n    priorities[feasible_mask] = (alpha * capacity_ratio) - (beta * np.abs(remaining_capacity_after_fit) * gamma)\n\n    # Encourage \"almost full\" bins, but avoid tiny fragments. Add a bonus if the remaining capacity is below a threshold.\n    small_fragment_threshold = item * 0.2  # e.g., remaining space should be no more than 20% of item size\n\n    almost_full_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= small_fragment_threshold)\n    priorities[feasible_mask][almost_full_mask] += 0.5 # Boost priority for almost full bins\n\n    # Add scaled remaining capacity\n    priorities[feasible_mask] += bins_remain_cap[feasible_mask] * 0.01\n    # Introduce randomness, but reduce its magnitude\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # First Fit Decreasing inspired element - gives higher priority to bins where item fits best,\n    # with less remaining capacity.\n    priority_best_fit = 1.0 / (remaining_capacity_after_fit + 1e-9)\n\n    # Modified Capacity Ratio: Emphasize bins that are filled significantly\n    priority_capacity_ratio = capacity_ratio**2  # Squaring emphasizes higher ratios\n\n    # Combination of factors - weighted average\n    priorities[feasible_mask] = (0.6 * priority_best_fit + 0.4 * priority_capacity_ratio)\n\n    # Adaptive element: Reduce priority of bins that lead to very small fragments.\n    small_fragment_threshold = 0.1\n    small_fragment_penalty = -0.2\n    small_fragment_mask = remaining_capacity_after_fit < small_fragment_threshold\n    priorities[feasible_mask][small_fragment_mask] += small_fragment_penalty\n\n    # Stochasticity - Add small random component for exploration\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, cannot_fit_priority: float = -679.3102821986948, waste_normalized_weight: float = -1.1916383925943645, relative_fullness_weight: float = 1.5275096254137408) -> np.ndarray:\n    \"\"\"Calculates bin priorities based on normalized waste and relative fullness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = cannot_fit_priority\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        relative_fullness = 1 - remaining_capacities_can_fit\n        priorities[can_fit] = waste_normalized_weight * waste_normalized + relative_fullness_weight * relative_fullness\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "exec_success": true
  }
]