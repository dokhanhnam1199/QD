{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    # Encourage bins that fit the item *relatively* well (but not too perfectly, to avoid small remaining spaces).\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]  # ratio of item size to bin capacity\n\n    # Priority is high if the capacity ratio is high AND the remaining space is small *relative* to the item\n    # This favors using most of the bin's space without creating *very* small fragments.\n\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Introduce some randomness to break ties and explore the search space more effectively.\n    priorities += np.random.normal(0, 0.01, size=len(priorities))\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit score, used bin bonus, and normalizes waste.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Disallow overfill\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Fit score\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / item)\n\n    # Used bin bonus\n    is_used_bonus = (bins_remain_cap < 1).astype(float)\n\n    priorities = fit_score + is_used_bonus\n\n    # Normalize waste\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] = priorities[fit_mask] / bins_remain_cap[fit_mask]\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized waste and relative fullness with a penalty for infeasible bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n\n        relative_fullness = 1 - remaining_capacities_can_fit #Assume bin capacity is 1.\n\n        priorities[can_fit] = -waste_normalized + relative_fullness\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, cannot_fit_priority: float = -679.3102821986948, waste_normalized_weight: float = -1.1916383925943645, relative_fullness_weight: float = 1.5275096254137408) -> np.ndarray:\n    \"\"\"Calculates bin priorities based on normalized waste and relative fullness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = cannot_fit_priority\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        relative_fullness = 1 - remaining_capacities_can_fit\n        priorities[can_fit] = waste_normalized_weight * waste_normalized + relative_fullness_weight * relative_fullness\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization with a fullness preference.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf  # No fit, very low priority\n\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Assign infinite waste to infeasible bins\n    waste_normalized = np.clip(1 - (waste / bins_remain_cap), a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    priorities = waste_normalized + is_used_bonus\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of previous heuristics for improved bin packing.\"\"\"\n\n    # Calculate how much space would be left in each bin if the item were placed\n    fit_score = bins_remain_cap - item\n\n    # Prioritize bins where the item fits, penalize others harshly\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    # Normalize remaining capacity to a [0,1] scale, higher value for near-full bins\n    remaining_normalized = np.zeros_like(bins_remain_cap)\n    remaining_normalized[fit_score >= 0] = 1 - (fit_score[fit_score >= 0] / bins_remain_cap[fit_score >= 0])\n\n    # Combine fit proximity with remaining capacity using a weighted sum.\n    priorities = 0.8 * fit_priority + 0.2 * remaining_normalized\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines normalized waste and relative fullness for priority.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        relative_fullness = 1 - remaining_capacities_can_fit\n        priorities[can_fit] = -waste_normalized + relative_fullness\n        fragmentation_penalty = np.exp(-5 * waste) #waste = remaining_after_fit\n\n        random_factor = 0.01 * np.random.rand(np.sum(can_fit))\n        priorities[can_fit] -= 0.1 * fragmentation_penalty + random_factor\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of previous heuristics for improved bin packing.\"\"\"\n\n    # Calculate how much space would be left in each bin if the item were placed\n    fit_score = bins_remain_cap - item\n\n    # Prioritize bins where the item fits, penalize others harshly\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    # Normalize remaining capacity to a [0,1] scale, higher value for near-full bins\n    remaining_normalized = np.zeros_like(bins_remain_cap)\n    remaining_normalized[fit_score >= 0] = 1 - (fit_score[fit_score >= 0] / bins_remain_cap[fit_score >= 0])\n\n    # Combine fit proximity with remaining capacity using a weighted sum.\n    priorities = 0.8 * fit_priority + 0.2 * remaining_normalized\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on space utilization and fragmentation.\"\"\"\n    feasible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[~feasible_bins] = -np.inf\n\n    remaining_after_fit = bins_remain_cap[feasible_bins] - item\n    utilization = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = utilization\n\n    fragmentation_penalty = np.exp(-5 * remaining_after_fit)\n    priorities[feasible_bins] -= fragmentation_penalty\n\n    almost_full_bonus = np.exp(-10*np.abs(remaining_after_fit-0.1))\n    priorities[feasible_bins] += 0.1*almost_full_bonus\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on space utilization and fragmentation.\"\"\"\n    feasible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[~feasible_bins] = -np.inf\n\n    remaining_after_fit = bins_remain_cap[feasible_bins] - item\n    utilization = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] = utilization\n\n    fragmentation_penalty = np.exp(-5 * remaining_after_fit)\n    priorities[feasible_bins] -= fragmentation_penalty\n\n    almost_full_bonus = np.exp(-10*np.abs(remaining_after_fit-0.1))\n    priorities[feasible_bins] += 0.1*almost_full_bonus\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Prioritize bins based on a combination of factors for feasible bins\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # 1. Capacity Ratio: Higher ratio means the item fills the bin more completely.\n    priority_capacity_ratio = capacity_ratio\n\n    # 2. Remaining Capacity: Moderate remaining capacity is better than very small or very large.\n    #    We use a Gaussian-like function to penalize extreme remaining capacities.\n    mean_remaining_capacity = item  # Target a remaining capacity close to the item size\n    std_dev_remaining_capacity = item / 2.0  # Adjust the spread as needed\n    priority_remaining_capacity = np.exp(-((remaining_capacity_after_fit - mean_remaining_capacity) ** 2) / (2 * std_dev_remaining_capacity ** 2))\n\n    # 3. Balancing Term: Encourages use of bins with already smaller remaining capacity, but not too small\n    priority_balance = 1.0 / (bins_remain_cap[feasible_mask] + 1e-9)\n\n    # Combine the priorities using a weighted sum or product.\n    priorities[feasible_mask] = (\n        0.5 * priority_capacity_ratio +\n        0.3 * priority_remaining_capacity +\n        0.2 * priority_balance\n    )\n\n    # Add a bit of randomness to break ties.  Reduce the magnitude.\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Prioritize bins based on a combination of factors for feasible bins\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # 1. Capacity Ratio: Higher ratio means the item fills the bin more completely.\n    priority_capacity_ratio = capacity_ratio\n\n    # 2. Remaining Capacity: Moderate remaining capacity is better than very small or very large.\n    #    We use a Gaussian-like function to penalize extreme remaining capacities.\n    mean_remaining_capacity = item  # Target a remaining capacity close to the item size\n    std_dev_remaining_capacity = item / 2.0  # Adjust the spread as needed\n    priority_remaining_capacity = np.exp(-((remaining_capacity_after_fit - mean_remaining_capacity) ** 2) / (2 * std_dev_remaining_capacity ** 2))\n\n    # 3. Balancing Term: Encourages use of bins with already smaller remaining capacity, but not too small\n    priority_balance = 1.0 / (bins_remain_cap[feasible_mask] + 1e-9)\n\n    # Combine the priorities using a weighted sum or product.\n    priorities[feasible_mask] = (\n        0.5 * priority_capacity_ratio +\n        0.3 * priority_remaining_capacity +\n        0.2 * priority_balance\n    )\n\n    # Add a bit of randomness to break ties.  Reduce the magnitude.\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces a more adaptive priority scheme that considers both\n    relative capacity usage and absolute remaining space, while also penalizing\n    bins that become too full after placement. It incorporates a more robust\n    randomization strategy and a scaling factor based on the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasibility check (same as v1)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Priority based on capacity ratio and remaining space (modified from v1)\n    # Scale the remaining capacity penalty by the item size.  Larger items mean\n    # a larger remaining space is acceptable.\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Penalty for bins that are too full (adaptive penalty)\n    # If the remaining capacity is less than 10% of the bin size, penalize\n    # This encourages the algorithm to find better fitting bins early on.\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5  # Significantly reduce priority\n\n    # Bonus for almost perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2 # Slightly increase priority, avoid zero capacity\n\n    # Adaptive Randomization (scaled by item size)\n    # The amount of noise added depends on item size. Larger items may require more exploration\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Scale priorities to prevent potential overflow issues and improve exploration\n    priorities /= (item + 1e-9)  # Prevent division by zero\n    \n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces a more adaptive priority scheme that considers both\n    relative capacity usage and absolute remaining space, while also penalizing\n    bins that become too full after placement. It incorporates a more robust\n    randomization strategy and a scaling factor based on the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasibility check (same as v1)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Priority based on capacity ratio and remaining space (modified from v1)\n    # Scale the remaining capacity penalty by the item size.  Larger items mean\n    # a larger remaining space is acceptable.\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Penalty for bins that are too full (adaptive penalty)\n    # If the remaining capacity is less than 10% of the bin size, penalize\n    # This encourages the algorithm to find better fitting bins early on.\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5  # Significantly reduce priority\n\n    # Bonus for almost perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2 # Slightly increase priority, avoid zero capacity\n\n    # Adaptive Randomization (scaled by item size)\n    # The amount of noise added depends on item size. Larger items may require more exploration\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Scale priorities to prevent potential overflow issues and improve exploration\n    priorities /= (item + 1e-9)  # Prevent division by zero\n    \n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces a more adaptive priority scheme that considers both\n    relative capacity usage and absolute remaining space, while also penalizing\n    bins that become too full after placement. It incorporates a more robust\n    randomization strategy and a scaling factor based on the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasibility check (same as v1)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Priority based on capacity ratio and remaining space (modified from v1)\n    # Scale the remaining capacity penalty by the item size.  Larger items mean\n    # a larger remaining space is acceptable.\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Penalty for bins that are too full (adaptive penalty)\n    # If the remaining capacity is less than 10% of the bin size, penalize\n    # This encourages the algorithm to find better fitting bins early on.\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5  # Significantly reduce priority\n\n    # Bonus for almost perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2 # Slightly increase priority, avoid zero capacity\n\n    # Adaptive Randomization (scaled by item size)\n    # The amount of noise added depends on item size. Larger items may require more exploration\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Scale priorities to prevent potential overflow issues and improve exploration\n    priorities /= (item + 1e-9)  # Prevent division by zero\n    \n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Encourage bins that fit the item well, but penalize almost-full bins more harshly.\n    # This is a more refined version of the original logic. We want to avoid creating tiny slivers of space.\n    # The exponential penalty is now stronger for very small remaining capacities.  Also, we consider the \"fullness\" of the bin *before* placing the item.\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap)) # added to ensure diversity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-10 * remaining_capacity_after_fit / (item + 1e-9)) * (1-fullness_ratio) # More agressive penalty\n\n    # Bonus for bins that are already relatively full, but not too full to cause tiny slivers. This encourages reuse.\n    # The bonus is scaled by the item size so that smaller items don't overly influence the choice.\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    # Add some randomness, but reduce its intensity\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Encourage bins that fit the item well, but penalize almost-full bins more harshly.\n    # This is a more refined version of the original logic. We want to avoid creating tiny slivers of space.\n    # The exponential penalty is now stronger for very small remaining capacities.  Also, we consider the \"fullness\" of the bin *before* placing the item.\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap)) # added to ensure diversity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-10 * remaining_capacity_after_fit / (item + 1e-9)) * (1-fullness_ratio) # More agressive penalty\n\n    # Bonus for bins that are already relatively full, but not too full to cause tiny slivers. This encourages reuse.\n    # The bonus is scaled by the item size so that smaller items don't overly influence the choice.\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    # Add some randomness, but reduce its intensity\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Encourage bins that fit the item well, but penalize almost-full bins more harshly.\n    # This is a more refined version of the original logic. We want to avoid creating tiny slivers of space.\n    # The exponential penalty is now stronger for very small remaining capacities.  Also, we consider the \"fullness\" of the bin *before* placing the item.\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap)) # added to ensure diversity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-10 * remaining_capacity_after_fit / (item + 1e-9)) * (1-fullness_ratio) # More agressive penalty\n\n    # Bonus for bins that are already relatively full, but not too full to cause tiny slivers. This encourages reuse.\n    # The bonus is scaled by the item size so that smaller items don't overly influence the choice.\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    # Add some randomness, but reduce its intensity\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins based on remaining capacity and item size.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Normalized waste prioritization + Encourage fuller bins.\n    waste = bins_remain_cap[valid_bins] - item\n    waste_normalized = waste / bins_remain_cap[valid_bins]\n    priorities[valid_bins] = 1 - waste_normalized\n\n    # Boost bins with smaller remaining capacity\n    remaining_after_placement = bins_remain_cap[valid_bins] - item\n    remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n    priority_boost = np.exp(-remaining_after_placement)\n    priorities[valid_bins] *= priority_boost\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate priority scores for bins based on remaining capacity and item size.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Normalized waste prioritization + Encourage fuller bins.\n    waste = bins_remain_cap[valid_bins] - item\n    waste_normalized = waste / bins_remain_cap[valid_bins]\n    priorities[valid_bins] = 1 - waste_normalized\n\n    # Boost bins with smaller remaining capacity\n    remaining_after_placement = bins_remain_cap[valid_bins] - item\n    remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n    priority_boost = np.exp(-remaining_after_placement)\n    priorities[valid_bins] *= priority_boost\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}