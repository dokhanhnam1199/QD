```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.
    infeasible_mask = bins_remain_cap < item
    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.

    feasible_mask = ~infeasible_mask
    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]

    if np.sum(feasible_mask) > 0:
        remaining_capacity_after_fit = feasible_bins_remain_cap - item
        capacity_ratio = item / feasible_bins_remain_cap

        # Encourage bins that fit the item *relatively* well.
        # The more filled the bin is the higher the priority.
        priorities[feasible_mask] = capacity_ratio

        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.
        small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)
        priorities[feasible_mask][small_fragment_mask] *= 0.5

        # Slightly increase the priority of bins with large remaining capacity, but with diminishing returns
        large_capacity_mask = remaining_capacity_after_fit > (item * 2)
        priorities[feasible_mask][large_capacity_mask] *= (1 + 0.1 * np.tanh(remaining_capacity_after_fit[large_capacity_mask] / item))

        # Introduce some randomness to break ties and explore the search space more effectively.  Scale the randomness based on the number of feasible bins.
        num_feasible = np.sum(feasible_mask)
        if num_feasible > 0:
            randomness_scale = 0.01 if num_feasible > 5 else 0.05
            priorities[feasible_mask] += np.random.normal(0, randomness_scale, size=num_feasible)

        # Adaptive adjustment of exploration vs. exploitation
        # Based on the number of feasible bins and item size
        if num_feasible > 5:  # more options, more exploitation
            priorities[feasible_mask] *= (1 + 0.01 * capacity_ratio) # Favor bins that are already relatively full.
        else: # Fewer options, more exploration
            priorities += np.random.normal(0, 0.03, size=len(priorities)) # Moderate randomness

        # Prioritize bins with utilization close to a target value. This aims to balance bin utilization across the board.
        target_utilization = 0.75  # Tunable parameter
        utilization = (bins_remain_cap[feasible_mask] - remaining_capacity_after_fit) / bins_remain_cap[feasible_mask]

        utilization_diff = np.abs(utilization - target_utilization)
        priorities[feasible_mask] *= (1 - 0.1 * utilization_diff) # Penalize bins far from target utilization
    return priorities
```
