{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_utilization_exponent: float = 2.0,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_bonus: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent  # Increased impact of utilization\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Bonus for placing large items in well-utilized bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7 # consider a bin well-utilized if 70% filled with new item\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_utilization_exponent: float = 2.0,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_bonus: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent  # Increased impact of utilization\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Bonus for placing large items in well-utilized bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > 0.7 # consider a bin well-utilized if 70% filled with new item\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.346986667163704,\n                small_fragment_penalty: float = 0.4190359759850205,\n                large_capacity_threshold_ratio: float = 2.7031384516737686,\n                large_capacity_bonus: float = 1.9813896116671397,\n                base_exploration_noise: float = 0.028823608906231004,\n                num_feasible_bins_threshold: int = 2.0255155117080275,\n                exploitation_bonus: float = 0.05421990770665395,\n                exploration_noise: float = 0.05298529182157763,\n                fragment_penalty_threshold_ratio: float = 0.11922225060466518,\n                fragment_penalty_factor: float = 0.5225940780128404,\n                bin_utilization_exponent: float = 2.064764826224044,\n                item_size_threshold_ratio: float = 0.6917758396870513,\n                large_item_bonus: float = 0.43608541787463345,\n                well_utilized_threshold: float = 0.53968059375775) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_exponent: Exponent to control the impact of bin utilization on priority.\n        item_size_threshold_ratio: Threshold ratio for considering an item \"large.\"\n        large_item_bonus: Bonus applied when a large item is placed in a well-utilized bin.\n        well_utilized_threshold: Threshold for bin utilization to be considered well-utilized.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n        priorities[feasible_mask] = capacity_ratio**bin_utilization_exponent  # Increased impact of utilization\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Bonus for placing large items in well-utilized bins\n        if item > bins_remain_cap.max() * item_size_threshold_ratio:\n            well_utilized_mask = capacity_ratio > well_utilized_threshold # consider a bin well-utilized if filled over threshold ratio\n            priorities[feasible_mask][well_utilized_mask] *= (1 + large_item_bonus)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_utilization_threshold: float = 0.75,\n                utilization_bonus: float = 0.1,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_penalty: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_utilization_threshold: Threshold for bin utilization to apply bonus.\n        utilization_bonus: Bonus for bins exceeding the utilization threshold.\n        item_size_threshold_ratio: Threshold ratio for item size relative to bin capacity.\n        large_item_penalty: Penalty for placing large items in mostly empty bins.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # NEW: Bin Utilization Bonus\n        bin_size = bins_remain_cap + item #Approximate the original size of each bin.\n        utilization_ratio = (bin_size - feasible_bins_remain_cap) / bin_size[feasible_mask]\n        high_utilization_mask = utilization_ratio > bin_utilization_threshold\n        priorities[feasible_mask][high_utilization_mask] *= (1 + utilization_bonus)\n\n        # NEW: Penalty for placing large items in relatively empty bins\n        large_item_mask = item / bin_size[feasible_mask] > item_size_threshold_ratio\n        empty_bin_mask = utilization_ratio < (1 - bin_utilization_threshold) # consider bins less than (1 - bin_utilization_threshold) utilized as relatively empty\n        priorities[feasible_mask][large_item_mask & empty_bin_mask] *= (1 - large_item_penalty) # Penalize placing large items in almost empty bins.\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization, utilization, and adaptive exploration based on feasible bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf  # Infeasible bins\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    num_potential_bins = np.sum(potential_bins)\n    \n    # Adaptive noise scaling\n    noise_scale = 0.01 if num_potential_bins > 0 else 0.05\n\n    if num_potential_bins > 3:\n        #Emphasize filling bins well when there are many choices. Introduce exploration.\n        priorities = 0.6 * waste_normalized + 0.4 * is_used_bonus + 0.02 * (bin_utilization**2) + np.random.normal(0, noise_scale, size=len(priorities))\n    else:\n        #More exploration when fewer bins are available.\n        priorities = 0.6 * waste_normalized + 0.4 * is_used_bonus + np.random.normal(0, noise_scale, size=len(priorities))\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_fullness_threshold: float = 0.8,\n                full_bin_bonus: float = 0.1,\n                item_size_threshold_ratio: float = 0.5,\n                large_item_penalty: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_fullness_threshold: Threshold for considering a bin as full.\n        full_bin_bonus: Bonus for filling bins close to full.\n        item_size_threshold_ratio: Threshold ratio for considering an item as large.\n        large_item_penalty: Penalty for placing large items in bins with little remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # NEW: Bonus for filling bins that are already relatively full\n        bin_fullness = 1 - (feasible_bins_remain_cap / (feasible_bins_remain_cap + item)) # Current fullness ratio\n        full_bin_mask = bin_fullness > bin_fullness_threshold\n        priorities[feasible_mask][full_bin_mask] *= (1 + full_bin_bonus)\n\n        # NEW: Penalty for placing large items in bins that will have very little remaining capacity\n        is_large_item = item > (np.mean(bins_remain_cap[~infeasible_mask]) * item_size_threshold_ratio if np.sum(~infeasible_mask) > 0 else 0)\n        if is_large_item:\n             low_capacity_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n             priorities[feasible_mask][low_capacity_mask] *= (1 - large_item_penalty)\n\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, waste normalization, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible = item > bins_remain_cap\n    priorities[infeasible] = -np.inf\n\n    feasible = ~infeasible\n    remaining_capacities = bins_remain_cap[feasible]\n\n    if len(remaining_capacities) > 0:\n        utilization = item / remaining_capacities\n        waste = remaining_capacities - item\n        waste = np.clip(waste, a_min=0, a_max=None)\n        waste_normalized = waste / bins_remain_cap[feasible] # Normalize by original remaining capacity\n\n        priorities[feasible] = utilization - 0.5 * waste_normalized #Balance\n\n        # Adaptive noise\n        num_feasible = np.sum(feasible)\n        noise_scale = 1e-6 * np.mean(bins_remain_cap) if num_feasible > 0 else 1e-5 * np.mean(bins_remain_cap)\n\n        noise = np.random.normal(0, noise_scale, len(priorities))\n        priorities += noise\n\n        #Bin usage bonus\n        bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n        is_used_bonus = (bin_utilization > 0).astype(float)\n        priorities += 0.1 * is_used_bonus  # Encourage using partially filled bins\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_occupation_exponent: float = 2.0,\n                item_size_relative_importance: float = 0.5) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_occupation_exponent: Exponent to adjust the impact of bin occupation ratio.\n        item_size_relative_importance: Relative importance of the item size when calculating the bin score\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n        \n        # Bin occupation ratio, raised to a power\n        bin_occupation_ratio = (feasible_bins_remain_cap - remaining_capacity_after_fit) / feasible_bins_remain_cap\n        priorities[feasible_mask] = np.power(bin_occupation_ratio, bin_occupation_exponent)\n        \n        # Adjust priority based on item size relative to bin capacity\n        priorities[feasible_mask] += item_size_relative_importance * capacity_ratio\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Adaptive exploration noise\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n            exploration_noise_level = base_exploration_noise / (1 + exploitation_bonus)\n        else:  # Fewer options, more exploration\n            exploration_noise_level = exploration_noise * (1 + exploitation_bonus)\n        priorities += np.random.normal(0, exploration_noise_level, size=len(priorities))\n\n        # Dynamic fragment penalty\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_occupation_exponent: float = 2.0,\n                item_size_relative_importance: float = 0.5) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_occupation_exponent: Exponent to adjust the impact of bin occupation ratio.\n        item_size_relative_importance: Relative importance of the item size when calculating the bin score\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n        \n        # Bin occupation ratio, raised to a power\n        bin_occupation_ratio = (feasible_bins_remain_cap - remaining_capacity_after_fit) / feasible_bins_remain_cap\n        priorities[feasible_mask] = np.power(bin_occupation_ratio, bin_occupation_exponent)\n        \n        # Adjust priority based on item size relative to bin capacity\n        priorities[feasible_mask] += item_size_relative_importance * capacity_ratio\n\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Adaptive exploration noise\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n            exploration_noise_level = base_exploration_noise / (1 + exploitation_bonus)\n        else:  # Fewer options, more exploration\n            exploration_noise_level = exploration_noise * (1 + exploitation_bonus)\n        priorities += np.random.normal(0, exploration_noise_level, size=len(priorities))\n\n        # Dynamic fragment penalty\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor)\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratio, fragment avoidance, bin balancing, and adaptive randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance relative to bin size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratio, fragment avoidance, bin balancing, and adaptive randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance relative to bin size.\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Optimal space, prioritizing bins with space slightly larger than item.\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Bin balancing to discourage excessive empty space.\n        avg_bin_capacity = np.mean(bins_remain_cap[feasible_mask])\n        large_capacity_mask = remaining_capacity_after_fit > (avg_bin_capacity * 1.1)\n        priorities[feasible_mask][large_capacity_mask] *= 0.8\n\n        # Adaptive randomness scaled by max capacity used.\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/exploitation adjustment based on feasibility count.\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Return priority score for each bin to pack the item into.\n    Combines capacity ratio, fragment avoidance, and adaptive exploration.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment avoidance relative to item size\n        small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask] *= 0.5\n\n        # Favor bins close to item size\n        optimal_space_mask = (remaining_capacity_after_fit >= (item * 0.1)) & (remaining_capacity_after_fit <= (item * 1.25))\n        priorities[feasible_mask][optimal_space_mask] *= 1.2\n\n        # Dynamic fragment penalty\n        fragment_penalty_threshold = item * 0.2\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * 0.3)\n\n        # Adaptive Randomness: scaled to max capacity\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        # Exploration/Exploitation balance\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratio, fragment avoidance, target utilization, and adaptive randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment Avoidance (relative to original bin size)\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Target Utilization\n        target_utilization = 0.75\n        utilization = (bins_remain_cap[feasible_mask] - remaining_capacity_after_fit) / bins_remain_cap[feasible_mask]\n        utilization_diff = np.abs(utilization - target_utilization)\n        priorities[feasible_mask] *= (1 - 0.1 * utilization_diff)\n\n        # Adaptive Randomness (based on max capacity used)\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, utilization, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Fit score\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / (item + 1e-9))\n    priorities[valid_bins] = fit_score[valid_bins]\n\n    # Bin utilization bonus\n    utilization = item / bins_remain_cap[valid_bins]\n    priorities[valid_bins] += utilization\n\n    # Adaptive noise based on number of valid bins\n    num_valid_bins = np.sum(valid_bins)\n    noise_scale = 0.005 if num_valid_bins > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Encourage bins with mid-level remaining capacities\n    remaining_capacity_after_fit = bins_remain_cap[valid_bins] - item\n    medium_capacity_mask = (remaining_capacity_after_fit >= (item * 0.2)) & (remaining_capacity_after_fit <= (item * 1.5))\n    priorities[valid_bins][medium_capacity_mask] *= 1.1  # Slightly favor medium capacity\n\n    # Exploration bonus if very few bins\n    exploration_prob = 0.3 if num_valid_bins < 3 else 0.1\n    if np.random.rand() < exploration_prob:\n        random_scale = 0.1 * item\n        priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, utilization, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Fit score\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / (item + 1e-9))\n    priorities[valid_bins] = fit_score[valid_bins]\n\n    # Bin utilization bonus\n    utilization = item / bins_remain_cap[valid_bins]\n    priorities[valid_bins] += utilization\n\n    # Adaptive noise based on number of valid bins\n    num_valid_bins = np.sum(valid_bins)\n    noise_scale = 0.005 if num_valid_bins > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Encourage bins with mid-level remaining capacities\n    remaining_capacity_after_fit = bins_remain_cap[valid_bins] - item\n    medium_capacity_mask = (remaining_capacity_after_fit >= (item * 0.2)) & (remaining_capacity_after_fit <= (item * 1.5))\n    priorities[valid_bins][medium_capacity_mask] *= 1.1  # Slightly favor medium capacity\n\n    # Exploration bonus if very few bins\n    exploration_prob = 0.3 if num_valid_bins < 3 else 0.1\n    if np.random.rand() < exploration_prob:\n        random_scale = 0.1 * item\n        priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, utilization, and adaptive noise.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Fit score\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / (item + 1e-9))\n    priorities[valid_bins] = fit_score[valid_bins]\n\n    # Bin utilization bonus\n    utilization = item / bins_remain_cap[valid_bins]\n    priorities[valid_bins] += utilization\n\n    # Adaptive noise based on number of valid bins\n    num_valid_bins = np.sum(valid_bins)\n    noise_scale = 0.005 if num_valid_bins > 3 else 0.05\n    noise = np.random.normal(0, noise_scale, len(priorities))\n    priorities += noise\n\n    # Encourage bins with mid-level remaining capacities\n    remaining_capacity_after_fit = bins_remain_cap[valid_bins] - item\n    medium_capacity_mask = (remaining_capacity_after_fit >= (item * 0.2)) & (remaining_capacity_after_fit <= (item * 1.5))\n    priorities[valid_bins][medium_capacity_mask] *= 1.1  # Slightly favor medium capacity\n\n    # Exploration bonus if very few bins\n    exploration_prob = 0.3 if num_valid_bins < 3 else 0.1\n    if np.random.rand() < exploration_prob:\n        random_scale = 0.1 * item\n        priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, waste, adaptive noise based on bin state.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    if not np.any(can_fit):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[can_fit]\n\n    utilization = item / feasible_bins_remain_cap\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9) # Prevent division by zero\n\n    bin_utilization = (feasible_bins_remain_cap - waste) / (feasible_bins_remain_cap + 1e-9) #bin utilization for available bins only.\n    is_used_bonus = (bin_utilization > 0).astype(float) # Bin Utilization bonus\n\n    priorities[can_fit] = 0.6*utilization - 0.4*waste_normalized + 0.2 * is_used_bonus #Weighted sum of utilization and normalized waste\n\n    num_feasible = np.sum(can_fit)\n    if num_feasible > 5:\n         priorities[can_fit] *= (1 + 0.02 * utilization)\n\n    exploration_rate = 0.01 + 0.03 * (1 - (np.mean(bins_remain_cap[can_fit]) / np.max(bins_remain_cap))) if np.sum(can_fit) > 0 else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_item_size = np.mean(bins_remain_cap[can_fit])/10 if np.any(can_fit) else 0.1\n    future_fit_penalty = np.where(waste < small_item_size, -0.1 , 0)\n    priorities[can_fit] += future_fit_penalty\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, waste, adaptive noise based on bin state.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    if not np.any(can_fit):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[can_fit]\n\n    utilization = item / feasible_bins_remain_cap\n    waste = feasible_bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = waste / (feasible_bins_remain_cap + 1e-9) # Prevent division by zero\n\n    bin_utilization = (feasible_bins_remain_cap - waste) / (feasible_bins_remain_cap + 1e-9) #bin utilization for available bins only.\n    is_used_bonus = (bin_utilization > 0).astype(float) # Bin Utilization bonus\n\n    priorities[can_fit] = 0.6*utilization - 0.4*waste_normalized + 0.2 * is_used_bonus #Weighted sum of utilization and normalized waste\n\n    num_feasible = np.sum(can_fit)\n    if num_feasible > 5:\n         priorities[can_fit] *= (1 + 0.02 * utilization)\n\n    exploration_rate = 0.01 + 0.03 * (1 - (np.mean(bins_remain_cap[can_fit]) / np.max(bins_remain_cap))) if np.sum(can_fit) > 0 else 0.01\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities))\n\n    small_item_size = np.mean(bins_remain_cap[can_fit])/10 if np.any(can_fit) else 0.1\n    future_fit_penalty = np.where(waste < small_item_size, -0.1 , 0)\n    priorities[can_fit] += future_fit_penalty\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_occupation_threshold: float = 0.75,\n                occupation_bonus: float = 0.15) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_occupation_threshold: Threshold for bin occupation ratio above which a bonus is applied.\n        occupation_bonus: Bonus factor for bins with high occupation.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / (feasible_bins_remain_cap + item) #changed from item/feasible_bins_remain_cap to normalize\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Encourage bins that are already highly occupied\n        bin_occupation_ratios = (bins_remain_cap[feasible_mask] + item - remaining_capacity_after_fit) / (bins_remain_cap[feasible_mask] + item) # Calculate bin occupation ratio\n        occupied_bin_mask = bin_occupation_ratios > bin_occupation_threshold\n        priorities[feasible_mask][occupied_bin_mask] *= (1 + occupation_bonus)\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                small_fragment_threshold_ratio: float = 0.18466643198227367,\n                small_fragment_penalty: float = 0.27731097399017257,\n                large_capacity_threshold_ratio: float = 1.8626060346685316,\n                large_capacity_bonus: float = 1.4940231128487715,\n                base_exploration_noise: float = 0.03615474634440513,\n                num_feasible_bins_threshold: int = 5,\n                exploitation_bonus: float = 0.0388722336961404,\n                exploration_noise: float = 0.05315726236485679,\n                fragment_penalty_threshold_ratio: float = 0.29623738564910945,\n                fragment_penalty_factor: float = 0.6538117438072715,\n                bin_occupation_threshold: float = 0.75,\n                occupation_bonus: float = 0.15) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold_ratio: Threshold ratio for small fragment penalty.\n        small_fragment_penalty: Penalty factor for small fragments.\n        large_capacity_threshold_ratio: Threshold ratio for large capacity bonus.\n        large_capacity_bonus: Bonus factor for large capacity bins.\n        base_exploration_noise: Base exploration noise.\n        num_feasible_bins_threshold: Threshold for number of feasible bins to switch between exploration and exploitation.\n        exploitation_bonus: Bonus for exploitation when more than num_feasible_bins_threshold bins are feasible.\n        exploration_noise: Exploration noise when fewer than or equal to num_feasible_bins_threshold bins are feasible.\n        fragment_penalty_threshold_ratio: Threshold ratio for fragment penalty.\n        fragment_penalty_factor: Penalty factor for fragments.\n        bin_occupation_threshold: Threshold for bin occupation ratio above which a bonus is applied.\n        occupation_bonus: Bonus factor for bins with high occupation.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / (feasible_bins_remain_cap + item) #changed from item/feasible_bins_remain_cap to normalize\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold_ratio)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold_ratio)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_exploration_noise, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > num_feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_noise, size=len(priorities)) # Higher randomness\n\n        # NEW: Dynamic fragment penalty based on item size\n        fragment_penalty_threshold = item * fragment_penalty_threshold_ratio  # Adjust threshold relative to item size\n\n        fragment_penalty_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < fragment_penalty_threshold)\n        priorities[feasible_mask][fragment_penalty_mask] *= (1 - (remaining_capacity_after_fit[fragment_penalty_mask] / fragment_penalty_threshold) * fragment_penalty_factor) # Apply a graded penalty\n\n        # Encourage bins that are already highly occupied\n        bin_occupation_ratios = (bins_remain_cap[feasible_mask] + item - remaining_capacity_after_fit) / (bins_remain_cap[feasible_mask] + item) # Calculate bin occupation ratio\n        occupied_bin_mask = bin_occupation_ratios > bin_occupation_threshold\n        priorities[feasible_mask][occupied_bin_mask] *= (1 + occupation_bonus)\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}