{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces a more adaptive priority scheme that considers both\n    relative capacity usage and absolute remaining space, while also penalizing\n    bins that become too full after placement. It incorporates a more robust\n    randomization strategy and a scaling factor based on the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasibility check (same as v1)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Priority based on capacity ratio and remaining space (modified from v1)\n    # Scale the remaining capacity penalty by the item size.  Larger items mean\n    # a larger remaining space is acceptable.\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Penalty for bins that are too full (adaptive penalty)\n    # If the remaining capacity is less than 10% of the bin size, penalize\n    # This encourages the algorithm to find better fitting bins early on.\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5  # Significantly reduce priority\n\n    # Bonus for almost perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2 # Slightly increase priority, avoid zero capacity\n\n    # Adaptive Randomization (scaled by item size)\n    # The amount of noise added depends on item size. Larger items may require more exploration\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Scale priorities to prevent potential overflow issues and improve exploration\n    priorities /= (item + 1e-9)  # Prevent division by zero\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get negative infinity priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Encourage bins that fit the item well, but penalize almost-full bins more harshly.\n    # This is a more refined version of the original logic. We want to avoid creating tiny slivers of space.\n    # The exponential penalty is now stronger for very small remaining capacities.  Also, we consider the \"fullness\" of the bin *before* placing the item.\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap)) # added to ensure diversity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-10 * remaining_capacity_after_fit / (item + 1e-9)) * (1-fullness_ratio) # More agressive penalty\n\n    # Bonus for bins that are already relatively full, but not too full to cause tiny slivers. This encourages reuse.\n    # The bonus is scaled by the item size so that smaller items don't overly influence the choice.\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    # Add some randomness, but reduce its intensity\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st heuristic introduces randomness to break ties, while the 20th does not directly address tie-breaking, potentially leading to suboptimal solutions; (2nd best) vs (second worst) 2nd heuristic combines fit score and used bin bonus and normalizes waste, while heuristic 19th focuses on normalized waste and encourages fuller bins. The former could be better as It explicitly encourages re-using partially filled bins; Comparing (1st) vs (2nd), we see the 1st heuristic explicitly penalizes infeasible bins by assigning a very low priority to them. The 2nd heuristic does the same thing, both ensure that the algorithm avoids considering bins that cannot accommodate the item; (3rd) vs (4th), the 3rd heuristic calculates normalized waste and relative fullness without using fixed weights but hardcoded calculation, while the 4th uses weights that may have been optimized. This allows for better weighting between different factors; Comparing (second worst) vs (worst), we see that heuristic 19th includes a clipping function to ensure the remaining capacity after placement is no less than zero, while heuristic 20th does not have this clipping function. Overall:\n\n- The best heuristics incorporate randomness to avoid local optima.\n- Normalizing waste and rewarding fuller bins often lead to better results.\n- The use of an explicit infeasibility mask to avoid considering bins that are not feasible is critical.\n- Optimized weights provide the flexibility to find the best combination of factors.\n- It is important to clip the remaining capacity after placement to be no less than zero to avoid generating error.\n- Penalizing almost-full bins more harshly to avoid creating tiny slivers of space appears beneficial.\n- Scaling penalties and bonuses by item size allows for adaptive behavior.\n- \nOkay, let's redefine \"Current Self-Reflection\" to be more effective for heuristic design, keeping in mind the pitfalls of \"Ineffective Self-Reflection\" and aiming for actionable insights.\n\nHere's a revised approach:\n\n*   **Keywords:** Adaptive strategies, dynamic balance, constraint awareness, robustification.\n\n*   **Advice:** Focus on developing heuristics that *dynamically adapt* their behavior based on the current state of the bin packing problem. Consider adaptive weighting schemes and methods to intelligently switch between exploration and exploitation phases.\n\n*   **Avoid:** Overly simplistic, static approaches based solely on easily interpretable factors. Avoid premature optimization for speed at the expense of solution quality and flexibility. Don't rely *only* on penalizing infeasibility with -inf; seek methods to prevent infeasibility.\n\n*   **Explanation:** Effective heuristics need adaptability and robustness. Move beyond simple greediness and static parameters. Explicitly address constraint handling *before* infeasibility occurs, and allow the heuristic to adjust its strategies based on the problem's progress.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}