{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask] *= 0.5\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * 2)\n        priorities[feasible_mask][large_capacity_mask] *= 1.1\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, 0.01, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + 0.01 * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, 0.05, size=len(priorities)) # Higher randomness\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_fragment_threshold: float = 0.304623962297677,\n                small_fragment_penalty: float = 0.7894409446208984, large_capacity_threshold: float = 4.30068414158377,\n                large_capacity_bonus: float = 1.0143294610094642, base_randomness_std: float = 0.03281434669683145,\n                feasible_bins_threshold: int = 8.658039267680126, exploitation_bonus: float = 0.07729920473685242,\n                exploration_randomness_std: float = 0.03973695860881252) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold: Threshold relative to item size below which a fragment is considered small.\n        small_fragment_penalty: Multiplier to reduce priority if a small fragment would be created.\n        large_capacity_threshold: Threshold relative to item size above which remaining capacity is considered large.\n        large_capacity_bonus: Multiplier to increase priority if remaining capacity is large.\n        base_randomness_std: Standard deviation of the base random noise added to priorities.\n        feasible_bins_threshold: Number of feasible bins above which exploitation is favored over exploration.\n        exploitation_bonus: Bonus added to priority based on capacity ratio when exploiting.\n        exploration_randomness_std: Standard deviation of random noise added to priorities when exploring.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_randomness_std, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_randomness_std, size=len(priorities)) # Higher randomness\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several improvements:\n    1. Adaptive penalty for near-full bins:  A bin that's *almost* full but can't fit the item gets a moderate negative priority to discourage creating tiny fragments.\n    2. Encourages packing items of similar sizes together.\n    3. Dynamic noise injection based on bin utilization.\n    4. Considers bin fullness when prioritizing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bin handling: Hard constraint.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_capacities = bins_remain_cap[feasible_mask]\n    remaining_capacity_after_fit = feasible_capacities - item\n    capacity_ratio = item / feasible_capacities\n\n    # Near-full bin penalty:  Discourage tiny fragments.\n    near_full_threshold = 0.1  # Tune this; relative to bin size.  Bins with <10% of capacity remaining considered near full.\n    near_full_mask = (bins_remain_cap > 0) & (bins_remain_cap < item + near_full_threshold) & (~infeasible_mask)\n    priorities[near_full_mask] = -0.1  # Moderate negative priority, tunable.\n\n    # Encourage packing items of similar sizes by looking at average item sizes already in the bin.\n    # For simplicity, this is a placeholder for now as we don't have bin content information.\n    # In a real implementation, you'd need to track which items are in each bin.\n\n    # Core priority calculation:\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Bin fullness bonus:  Slightly prefer filling emptier bins *initially* (exploration), then switch to filling fuller bins (exploitation).\n    bin_fullness = 1 - bins_remain_cap / np.max(bins_remain_cap)  # Normalize bin fullness\n    priorities += 0.05 * bin_fullness # Added bonus to priorities\n\n    # Adaptive Noise Injection:  Add more noise when bins are relatively empty to promote exploration.\n    utilization = 1 - np.mean(bins_remain_cap / np.max(bins_remain_cap)) # Overall utilization.\n    noise_level = 0.01 * (1 - utilization)  # Higher noise when bins are emptier.\n    priorities += np.random.normal(0, noise_level, size=len(priorities))\n\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Dynamically combines fullness and waste, with noise and infeasibility mask.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n\n        relative_fullness = 1 - remaining_capacities_can_fit #Assume bin capacity is 1.\n\n        priorities[can_fit] = -waste_normalized + relative_fullness\n\n        # Boost bins with smaller remaining capacity after placement\n        remaining_after_placement = remaining_capacities_can_fit - item\n        remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n        priority_boost = np.exp(-5 * remaining_after_placement) #Scale remaining capacity\n        priorities[can_fit] += priority_boost\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, used bin bonus, normalized waste, and noise.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Fit score: exp distance\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / item)\n    priorities[valid_bins] = fit_score[valid_bins]\n\n    # Used bin bonus\n    is_used_bonus = (bins_remain_cap < 1).astype(float)\n    priorities += is_used_bonus\n\n    # Normalize waste\n    waste = bins_remain_cap[valid_bins] - item\n    waste_normalized = waste / bins_remain_cap[valid_bins]\n    priorities[valid_bins] -= waste_normalized # Subtract normalized waste\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n    \n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: Combines waste normalization, fullness, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    priorities = 0.7 * waste_normalized + 0.3 * is_used_bonus\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: Combines waste normalization, fullness, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    priorities = 0.7 * waste_normalized + 0.3 * is_used_bonus\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, used bin bonus, normalized waste, and noise.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Fit score: exp distance\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / item)\n    priorities[valid_bins] = fit_score[valid_bins]\n\n    # Used bin bonus\n    is_used_bonus = (bins_remain_cap < 1).astype(float)\n    priorities += is_used_bonus\n\n    # Normalize waste\n    waste = bins_remain_cap[valid_bins] - item\n    waste_normalized = waste / bins_remain_cap[valid_bins]\n    priorities[valid_bins] -= waste_normalized # Subtract normalized waste\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Dynamically combines fullness and waste, with noise and infeasibility mask.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n\n        relative_fullness = 1 - remaining_capacities_can_fit #Assume bin capacity is 1.\n\n        priorities[can_fit] = -waste_normalized + relative_fullness\n\n        # Boost bins with smaller remaining capacity after placement\n        remaining_after_placement = remaining_capacities_can_fit - item\n        remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n        priority_boost = np.exp(-5 * remaining_after_placement) #Scale remaining capacity\n        priorities[can_fit] += priority_boost\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: Combines waste normalization, fullness, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    priorities = 0.7 * waste_normalized + 0.3 * is_used_bonus\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive bin selection with waste penalization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    remaining_capacities_can_fit = bins_remain_cap[feasible_mask]\n    \n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        relative_fullness = 1 - remaining_capacities_can_fit / np.max(bins_remain_cap)\n        priorities[feasible_mask] = -waste_normalized + relative_fullness * 0.5 # Adjusted weight\n\n        fragmentation_penalty = np.exp(-5 * waste)\n        priorities[feasible_mask] -= 0.1 * fragmentation_penalty\n\n        # Adaptive reuse bonus\n        already_full_mask = (remaining_capacities_can_fit < 0.7 * np.max(bins_remain_cap)) & (remaining_capacities_can_fit > item)\n        priorities[feasible_mask][already_full_mask] += 0.1 * item * relative_fullness[already_full_mask]\n\n        priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins balancing utilization, fragmentation, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_after_fit = bins_remain_cap[feasible_mask] - item\n    utilization = item / bins_remain_cap[feasible_mask]\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap))\n    priorities[feasible_mask] = utilization * np.exp(-5 * remaining_after_fit / (item + 1e-9)) * (1 - fullness_ratio)\n\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins balancing utilization, fragmentation, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_after_fit = bins_remain_cap[feasible_mask] - item\n    utilization = item / bins_remain_cap[feasible_mask]\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap))\n    priorities[feasible_mask] = utilization * np.exp(-5 * remaining_after_fit / (item + 1e-9)) * (1 - fullness_ratio)\n\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic with dynamic penalties and bonuses.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    remaining_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n    \n    # Dynamic weighting based on item size and remaining capacity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_after_fit / (item + 1e-9))\n\n    # Adaptive penalty for almost full bins\n    too_full_mask = feasible_mask & (remaining_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5 \n\n    # Bonus for nearly perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2\n\n    # Adaptive Randomization\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Waste Normalization\n    waste_norm = remaining_after_fit / (bins_remain_cap[feasible_mask] + item + 1e-9)\n    priorities[feasible_mask] -= 0.1 * np.clip(waste_norm, 0, 1)\n\n    priorities /= (item + 1e-9)\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several improvements:\n    1.  Adaptive capacity ratio weighting.\n    2.  A penalty term for bins that become too full.\n    3.  Dynamic exploration/exploitation balance.\n    4.  Constraint anticipation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasibility mask\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Feasible bins\n    feasible_mask = ~infeasible_mask\n    feasible_caps = bins_remain_cap[feasible_mask]\n\n    if np.any(feasible_mask):  # Only proceed if there are feasible bins\n        remaining_capacity_after_fit = feasible_caps - item\n        capacity_ratio = item / feasible_caps\n\n        # Adaptive Capacity Ratio Weighting: Adjust importance based on average cap.\n        avg_cap = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0 # Avoid ZeroDivisionError, handle edge case\n        adaptive_weight = np.clip(avg_cap / (item + 1e-9), 0.1, 10) # Clip to avoid extreme weights\n        capacity_ratio_weighted = capacity_ratio * adaptive_weight\n\n        # Penalty for nearly full bins.  Higher penalty for smaller remaining space.\n        fullness_penalty = np.exp(-5 * remaining_capacity_after_fit / (item + 1e-9)) # Higher exponent for stronger penalty\n        priorities[feasible_mask] = capacity_ratio_weighted * (1 - fullness_penalty)  # Subtract penalty\n\n        # Dynamic Exploration/Exploitation:  Adjust randomness based on remaining bins.\n        num_empty_bins = np.sum(bins_remain_cap > 0.99) # Count bins that are almost empty (>.99 full capacity)\n        exploration_factor = np.clip(num_empty_bins / len(bins_remain_cap), 0.01, 0.1) # Avoid zero division, clip range\n\n        priorities += np.random.normal(0, exploration_factor, size=len(priorities))\n\n        # Constraint anticipation: Prefer bins that can accommodate at least a small *future* item\n        small_item_size = np.mean(bins_remain_cap[bins_remain_cap>0])/10 if np.any(bins_remain_cap > 0) else 0.1\n        future_fit_penalty = np.where(remaining_capacity_after_fit < small_item_size, -0.1 , 0)\n        priorities[feasible_mask] += future_fit_penalty # Apply slight penalty if doesn't fit small_item.\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority with capacity ratio, remaining space, and item-size scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    \n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n    \n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5\n\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2\n\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    priorities /= (item + 1e-9)\n    \n    # Bonus for bins that were nearly full before, promoting reuse\n    nearly_full_before_mask = feasible_mask & (bins_remain_cap[feasible_mask] < item * 1.1)\n    priorities[nearly_full_before_mask] += 0.1\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive bin selection: balance fit, capacity, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Capacity Ratio\n    priority_capacity_ratio = capacity_ratio\n\n    # Remaining Capacity (Gaussian-like)\n    mean_remaining_capacity = item\n    std_dev_remaining_capacity = item / 2.0\n    priority_remaining_capacity = np.exp(-((remaining_capacity_after_fit - mean_remaining_capacity) ** 2) / (2 * std_dev_remaining_capacity ** 2))\n\n    # Balancing Term\n    priority_balance = 1.0 / (bins_remain_cap[feasible_mask] + 1e-9)\n\n    priorities[feasible_mask] = (\n        0.5 * priority_capacity_ratio +\n        0.3 * priority_remaining_capacity +\n        0.2 * priority_balance\n    )\n\n    # Add randomness, scale with item size\n    priorities += np.random.normal(0, 0.005 * item, size=len(priorities))\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: combines normalized waste, fit score and randomness.\"\"\"\n\n    # Prioritize bins where the item fits, penalize others harshly\n    fit_score = bins_remain_cap - item\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    # Normalize remaining capacity\n    remaining_normalized = np.zeros_like(bins_remain_cap)\n    remaining_normalized[fit_score >= 0] = 1 - (fit_score[fit_score >= 0] / bins_remain_cap[fit_score >= 0])\n\n    # Combine fit proximity with remaining capacity, randomness\n    priorities = 0.7 * fit_priority + 0.3 * remaining_normalized + np.random.normal(0, 0.01, size=len(bins_remain_cap))\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: combines normalized waste, fit score and randomness.\"\"\"\n\n    # Prioritize bins where the item fits, penalize others harshly\n    fit_score = bins_remain_cap - item\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    # Normalize remaining capacity\n    remaining_normalized = np.zeros_like(bins_remain_cap)\n    remaining_normalized[fit_score >= 0] = 1 - (fit_score[fit_score >= 0] / bins_remain_cap[fit_score >= 0])\n\n    # Combine fit proximity with remaining capacity, randomness\n    priorities = 0.7 * fit_priority + 0.3 * remaining_normalized + np.random.normal(0, 0.01, size=len(bins_remain_cap))\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: combines normalized waste, fit score and randomness.\"\"\"\n\n    # Prioritize bins where the item fits, penalize others harshly\n    fit_score = bins_remain_cap - item\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    # Normalize remaining capacity\n    remaining_normalized = np.zeros_like(bins_remain_cap)\n    remaining_normalized[fit_score >= 0] = 1 - (fit_score[fit_score >= 0] / bins_remain_cap[fit_score >= 0])\n\n    # Combine fit proximity with remaining capacity, randomness\n    priorities = 0.7 * fit_priority + 0.3 * remaining_normalized + np.random.normal(0, 0.01, size=len(bins_remain_cap))\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}