```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Infeasible bin handling
    infeasible_mask = bins_remain_cap < item
    priorities[infeasible_mask] = -np.inf

    feasible_mask = ~infeasible_mask
    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]

    if np.sum(feasible_mask) > 0:
        remaining_capacity_after_fit = feasible_bins_remain_cap - item
        capacity_ratio = item / feasible_bins_remain_cap

        # Primary priority: Fill ratio
        priorities[feasible_mask] = capacity_ratio

        # Fragment penalty (adaptive)
        small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)
        priorities[feasible_mask][small_fragment_mask] *= 0.3  # Reduced penalty

        # Reward larger bins *less*, as we prioritize filling bins tightly, but avoid excessive fragmentation
        # We will consider bins with capcity > item * 1.5 to be a large bin
        large_capacity_mask = remaining_capacity_after_fit > (item * 1.5)
        priorities[feasible_mask][large_capacity_mask] *= 0.9 # slight penalty on large bins to prevent them from hogging items.

        # Introduce randomness - less agressive than v1.
        priorities += np.random.normal(0, 0.005, size=len(priorities))

        # Bin Diversity using bin utilization rate.
        bin_utilization = (1 - bins_remain_cap / np.max(bins_remain_cap)) # normalized to largest possible bin size
        priorities += 0.001 * bin_utilization # bias towards bins that are more utilized.
        # Adaptive Exploration / Exploitation
        num_feasible = np.sum(feasible_mask)
        if num_feasible > 5:
            priorities[feasible_mask] *= (1 + 0.01 * capacity_ratio)  # Stronger fill rate emphasis

        else:
            priorities += np.random.normal(0, 0.03, size=len(priorities))  # Increased randomness

        # Apply a tiny penalty to bins near full capacity to balance usage and prevent getting stuck.
        near_full_mask = remaining_capacity_after_fit < np.max(bins_remain_cap)*0.05
        priorities[feasible_mask][near_full_mask] *= 0.98


    return priorities
```
