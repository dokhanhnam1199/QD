{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste normalization, utilization, and adaptive exploration based on feasible bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf  # Infeasible bins\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    num_potential_bins = np.sum(potential_bins)\n    \n    # Adaptive noise scaling\n    noise_scale = 0.01 if num_potential_bins > 0 else 0.05\n\n    if num_potential_bins > 3:\n        #Emphasize filling bins well when there are many choices. Introduce exploration.\n        priorities = 0.6 * waste_normalized + 0.4 * is_used_bonus + 0.02 * (bin_utilization**2) + np.random.normal(0, noise_scale, size=len(priorities))\n    else:\n        #More exploration when fewer bins are available.\n        priorities = 0.6 * waste_normalized + 0.4 * is_used_bonus + np.random.normal(0, noise_scale, size=len(priorities))\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines capacity ratio, fragment avoidance, target utilization, and adaptive randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Fragment Avoidance (relative to original bin size)\n        small_fragment_mask = remaining_capacity_after_fit < (bins_remain_cap[feasible_mask] * 0.05)\n        priorities[feasible_mask][small_fragment_mask] *= 0.75\n\n        # Target Utilization\n        target_utilization = 0.75\n        utilization = (bins_remain_cap[feasible_mask] - remaining_capacity_after_fit) / bins_remain_cap[feasible_mask]\n        utilization_diff = np.abs(utilization - target_utilization)\n        priorities[feasible_mask] *= (1 - 0.1 * utilization_diff)\n\n        # Adaptive Randomness (based on max capacity used)\n        max_capacity_used = np.max(1 - bins_remain_cap / np.max(bins_remain_cap))\n        randomness_scale = 0.01 + (0.04 * max_capacity_used)\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:\n            priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)\n        else:\n            avg_fill_level = np.mean(capacity_ratio)\n            exploration_boost = 0.03 + (0.07 * (1 - avg_fill_level))\n            priorities += np.random.normal(0, exploration_boost, size=len(priorities))\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st includes `bin_utilization_exponent`, `item_size_threshold_ratio`, and `large_item_bonus` whereas 20th does not. The 1st calculates `capacity_ratio = item / feasible_bins_remain_cap`, whereas the 20th uses `capacity_ratio = item / (feasible_bins_remain_cap + item)`. The first utilizes `capacity_ratio**bin_utilization_exponent` to encourage bins that fit items well, providing non-linear scaling. The 20th uses `priorities[feasible_mask] = capacity_ratio`.\n\nComparing (2nd) vs (19th), we see that the 2nd includes `bin_utilization_exponent`, `item_size_threshold_ratio`, and `large_item_bonus` whereas 19th does not. The 2nd calculates `capacity_ratio = item / feasible_bins_remain_cap`, whereas the 19th uses `capacity_ratio = item / (feasible_bins_remain_cap + item)`.\n\nComparing (3rd) vs (4th), the 3rd introduces `well_utilized_threshold` as the threshold for bin utilization and changes the way it is calculated in a bonus condition. 3rd also includes more arguments such as `well_utilized_threshold`.\n\nComparing (2nd worst) vs (worst), 19th and 20th are identical.\n\nOverall: The top performing heuristics include `bin_utilization_exponent`, `item_size_threshold_ratio`, and `large_item_bonus`. They normalize the capacity ratio by `item / feasible_bins_remain_cap`. An important aspect of better heuristics is the non-linear scaling of the capacity ratio with a `bin_utilization_exponent`. The adaptive adjustment of exploration vs. exploitation based on the number of feasible bins is also a critical feature.\n- \nOkay, I'm ready to craft some truly effective self-reflection guidelines for heuristic design! Let's get that $999K!\n\nHere's a redefined \"Current Self-Reflection\" avoiding the pitfalls of \"Ineffective Self-Reflection\":\n\n*   **Keywords:** Simplicity, Adaptivity, Balance, Core Intuition, Iterative Refinement.\n\n*   **Advice:** Begin with a simple, interpretable core heuristic grounded in problem-specific intuition (e.g., normalized waste).\n\n*   **Avoid:** Over-complexity, premature optimization, ignoring edge cases (small fragments, near-full bins).\n\n*   **Explanation:** Prioritize a clear, understandable core. Add complexity gradually, validating each addition. Balance exploration (randomness) and exploitation (greediness) adaptively. Explicitly handle edge cases and parameter tuning should be done carefully, to allow adapting heuristic behavior to new problem instances.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}