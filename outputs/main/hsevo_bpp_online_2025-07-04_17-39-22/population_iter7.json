[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit, used bin bonus, normalized waste, and noise.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities - 1e9\n\n    # Fit score: exp distance\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / item)\n    priorities[valid_bins] = fit_score[valid_bins]\n\n    # Used bin bonus\n    is_used_bonus = (bins_remain_cap < 1).astype(float)\n    priorities += is_used_bonus\n\n    # Normalize waste\n    waste = bins_remain_cap[valid_bins] - item\n    waste_normalized = waste / bins_remain_cap[valid_bins]\n    priorities[valid_bins] -= waste_normalized # Subtract normalized waste\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Dynamically combines fullness and waste, with noise and infeasibility mask.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n\n        relative_fullness = 1 - remaining_capacities_can_fit #Assume bin capacity is 1.\n\n        priorities[can_fit] = -waste_normalized + relative_fullness\n\n        # Boost bins with smaller remaining capacity after placement\n        remaining_after_placement = remaining_capacities_can_fit - item\n        remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n        priority_boost = np.exp(-5 * remaining_after_placement) #Scale remaining capacity\n        priorities[can_fit] += priority_boost\n\n    #Add noise\n    noise = np.random.normal(0, 1e-6, len(priorities))\n    priorities += noise\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive capacity ratio, remaining space penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap))\n    priorities[feasible_mask] = capacity_ratio * np.exp(-10 * remaining_capacity_after_fit / (item + 1e-9)) * (1-fullness_ratio)\n\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n    \n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 53.260869565217405,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority with capacity ratio, remaining space, and item-size scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    \n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n    \n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5\n\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2\n\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    priorities /= (item + 1e-9)\n    \n    # Bonus for bins that were nearly full before, promoting reuse\n    nearly_full_before_mask = feasible_mask & (bins_remain_cap[feasible_mask] < item * 1.1)\n    priorities[nearly_full_before_mask] += 0.1\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 16.2644595133626,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: Combines waste normalization, fullness, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n    priorities[~potential_bins] = -np.inf\n\n    waste = bins_remain_cap - item\n    waste = np.clip(waste, a_min=0, a_max=None)\n    waste_normalized = 1 - (waste / bins_remain_cap)\n    waste_normalized = np.clip(waste_normalized, a_min=0, a_max=1)\n\n    bin_utilization = (bins_remain_cap - waste) / bins_remain_cap\n    is_used_bonus = (bin_utilization > 0).astype(float)\n\n    priorities = 0.7 * waste_normalized + 0.3 * is_used_bonus\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive priority: combines normalized waste, fit score and randomness.\"\"\"\n\n    # Prioritize bins where the item fits, penalize others harshly\n    fit_score = bins_remain_cap - item\n    fit_priority = np.where(fit_score >= 0, np.exp(-np.abs(fit_score)), -np.inf)\n\n    # Normalize remaining capacity\n    remaining_normalized = np.zeros_like(bins_remain_cap)\n    remaining_normalized[fit_score >= 0] = 1 - (fit_score[fit_score >= 0] / bins_remain_cap[fit_score >= 0])\n\n    # Combine fit proximity with remaining capacity, randomness\n    priorities = 0.7 * fit_priority + 0.3 * remaining_normalized + np.random.normal(0, 0.01, size=len(bins_remain_cap))\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 36.02911846828879,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive bin selection with waste penalization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    remaining_capacities_can_fit = bins_remain_cap[feasible_mask]\n    \n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        relative_fullness = 1 - remaining_capacities_can_fit / np.max(bins_remain_cap)\n        priorities[feasible_mask] = -waste_normalized + relative_fullness * 0.5 # Adjusted weight\n\n        fragmentation_penalty = np.exp(-5 * waste)\n        priorities[feasible_mask] -= 0.1 * fragmentation_penalty\n\n        # Adaptive reuse bonus\n        already_full_mask = (remaining_capacities_can_fit < 0.7 * np.max(bins_remain_cap)) & (remaining_capacities_can_fit > item)\n        priorities[feasible_mask][already_full_mask] += 0.1 * item * relative_fullness[already_full_mask]\n\n        priorities += np.random.normal(0, 0.005, size=len(priorities))\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.437574790586359,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic with dynamic penalties and bonuses.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    feasible_mask = ~infeasible_mask\n    remaining_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n    \n    # Dynamic weighting based on item size and remaining capacity\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_after_fit / (item + 1e-9))\n\n    # Adaptive penalty for almost full bins\n    too_full_mask = feasible_mask & (remaining_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5 \n\n    # Bonus for nearly perfect fit\n    almost_perfect_mask = feasible_mask & (remaining_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2\n\n    # Adaptive Randomization\n    random_scale = 0.01 * item\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Waste Normalization\n    waste_norm = remaining_after_fit / (bins_remain_cap[feasible_mask] + item + 1e-9)\n    priorities[feasible_mask] -= 0.1 * np.clip(waste_norm, 0, 1)\n\n    priorities /= (item + 1e-9)\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 13.382528919026731,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive bin selection: balance fit, capacity, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n\n    # Capacity Ratio\n    priority_capacity_ratio = capacity_ratio\n\n    # Remaining Capacity (Gaussian-like)\n    mean_remaining_capacity = item\n    std_dev_remaining_capacity = item / 2.0\n    priority_remaining_capacity = np.exp(-((remaining_capacity_after_fit - mean_remaining_capacity) ** 2) / (2 * std_dev_remaining_capacity ** 2))\n\n    # Balancing Term\n    priority_balance = 1.0 / (bins_remain_cap[feasible_mask] + 1e-9)\n\n    priorities[feasible_mask] = (\n        0.5 * priority_capacity_ratio +\n        0.3 * priority_remaining_capacity +\n        0.2 * priority_balance\n    )\n\n    # Add randomness, scale with item size\n    priorities += np.random.normal(0, 0.005 * item, size=len(priorities))\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 24.511368169126442,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins balancing utilization, fragmentation, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    remaining_after_fit = bins_remain_cap[feasible_mask] - item\n    utilization = item / bins_remain_cap[feasible_mask]\n\n    fullness_ratio = 1 - (bins_remain_cap[feasible_mask] / np.max(bins_remain_cap))\n    priorities[feasible_mask] = utilization * np.exp(-5 * remaining_after_fit / (item + 1e-9)) * (1 - fullness_ratio)\n\n    already_full_mask = (bins_remain_cap[feasible_mask] < 0.7 * np.max(bins_remain_cap)) & (bins_remain_cap[feasible_mask] > item)\n    priorities[feasible_mask][already_full_mask] += 0.1 * item\n\n    priorities += np.random.normal(0, 0.005, size=len(priorities))\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.946150777822112,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several enhancements:\n\n    1.  Adaptive weighting based on bin fullness: Prioritizes bins that are neither too full nor too empty.\n    2.  Constraint anticipation:  Uses a 'look-ahead' to estimate the effect of placing the item.\n    3.  Dynamic noise injection: Adds noise proportional to the number of bins with similar capacity.\n    4.  Robustness to edge cases: Addresses bins with almost exact fits and nearly empty bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    # Calculate remaining capacity after fitting the item in feasible bins\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n\n    # Calculate the capacity ratio for feasible bins\n    capacity_ratio = item / feasible_bins_remain_cap\n\n    # Adaptive weighting based on bin fullness: sigmoid function gives higher weight when bin is neither too full nor too empty.\n    fullness = 1 - (feasible_bins_remain_cap / np.max(bins_remain_cap)) #normalized bin fullness\n    fullness_weights = 1 / (1 + np.exp(-5 * (fullness - 0.5))) # Sigmoid, peaks around 0.5 fullness\n\n    # Constraint anticipation: Penalize bins if the remaining capacity after placement will be too small.\n    # This anticipates future difficulties by not leaving tiny, unusable spaces.\n    tiny_space_penalty = np.exp(-10 * remaining_capacity_after_fit / (item + 1e-9)) #High penalty if remaining space << item\n\n    # Main priority calculation, incorporating all factors:\n    priorities[feasible_mask] = fullness_weights * capacity_ratio * tiny_space_penalty\n\n    # Dynamic noise injection:  Add noise proportional to bins with similar capacities to encourage exploration and break ties\n    capacity_counts = np.bincount(bins_remain_cap.astype(int))  # Count of each capacity\n\n    noise_magnitude = 0.01 * np.array([capacity_counts[int(cap)] for cap in bins_remain_cap]) #Noise proportional to capacity count.\n    priorities += np.random.normal(0, noise_magnitude, size=len(priorities))\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 143.05943358595934,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version attempts to balance bin utilization and fragmentation avoidance\n    with an adaptive strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_cap = bins_remain_cap[feasible_mask]\n    remaining_capacity_after_fit = feasible_bins_cap - item\n\n    # Calculate bin utilization ratio. Higher is better, but not too high.\n    utilization_ratio = item / feasible_bins_cap\n\n    # Calculate remaining capacity ratio.\n    remaining_ratio = remaining_capacity_after_fit / feasible_bins_cap\n\n    # Adaptive weighting based on remaining capacity.\n    # If there is enough space in most bins, focus on consolidation\n    # If bins are getting full, focus on not making too many small gaps.\n    avg_remaining_cap = np.mean(bins_remain_cap[~infeasible_mask]) if np.any(~infeasible_mask) else 0\n\n    if avg_remaining_cap > 2 * item:  # Heuristic adjustment factor. This can be further refined/optimized\n\n        # Encourages filling bins with significant remaining capacity.\n        # Gives high priority to bins with good utilization and not too much fragmentation\n        priorities[feasible_mask] = utilization_ratio * np.exp(-remaining_ratio)\n    else:\n        # Bins are getting full, so avoid creating small fragments at all costs.\n        # Reduces the priority of bins that will have very small remaining capacity.\n        priorities[feasible_mask] = utilization_ratio * np.exp(-remaining_ratio * 10)  # Penalize more heavily\n        # slightly increased weight to high utilization\n\n    # Adding a small penalty for bins with very very little capacity left.\n    tiny_space_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < 0.1)\n\n    if np.any(tiny_space_mask):\n        priorities[feasible_mask][tiny_space_mask] -= 0.05 # Adaptive small penalty\n\n    # Introducing randomness to break ties and encourage exploration.\n    priorities += np.random.normal(0, 0.01, size=len(priorities))\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several improvements:\n    1. Adaptive penalty for near-full bins:  A bin that's *almost* full but can't fit the item gets a moderate negative priority to discourage creating tiny fragments.\n    2. Encourages packing items of similar sizes together.\n    3. Dynamic noise injection based on bin utilization.\n    4. Considers bin fullness when prioritizing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bin handling: Hard constraint.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_capacities = bins_remain_cap[feasible_mask]\n    remaining_capacity_after_fit = feasible_capacities - item\n    capacity_ratio = item / feasible_capacities\n\n    # Near-full bin penalty:  Discourage tiny fragments.\n    near_full_threshold = 0.1  # Tune this; relative to bin size.  Bins with <10% of capacity remaining considered near full.\n    near_full_mask = (bins_remain_cap > 0) & (bins_remain_cap < item + near_full_threshold) & (~infeasible_mask)\n    priorities[near_full_mask] = -0.1  # Moderate negative priority, tunable.\n\n    # Encourage packing items of similar sizes by looking at average item sizes already in the bin.\n    # For simplicity, this is a placeholder for now as we don't have bin content information.\n    # In a real implementation, you'd need to track which items are in each bin.\n\n    # Core priority calculation:\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Bin fullness bonus:  Slightly prefer filling emptier bins *initially* (exploration), then switch to filling fuller bins (exploitation).\n    bin_fullness = 1 - bins_remain_cap / np.max(bins_remain_cap)  # Normalize bin fullness\n    priorities += 0.05 * bin_fullness # Added bonus to priorities\n\n    # Adaptive Noise Injection:  Add more noise when bins are relatively empty to promote exploration.\n    utilization = 1 - np.mean(bins_remain_cap / np.max(bins_remain_cap)) # Overall utilization.\n    noise_level = 0.01 * (1 - utilization)  # Higher noise when bins are emptier.\n    priorities += np.random.normal(0, noise_level, size=len(priorities))\n\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several improvements:\n    1.  Adaptive capacity ratio weighting.\n    2.  A penalty term for bins that become too full.\n    3.  Dynamic exploration/exploitation balance.\n    4.  Constraint anticipation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasibility mask\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Feasible bins\n    feasible_mask = ~infeasible_mask\n    feasible_caps = bins_remain_cap[feasible_mask]\n\n    if np.any(feasible_mask):  # Only proceed if there are feasible bins\n        remaining_capacity_after_fit = feasible_caps - item\n        capacity_ratio = item / feasible_caps\n\n        # Adaptive Capacity Ratio Weighting: Adjust importance based on average cap.\n        avg_cap = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0 # Avoid ZeroDivisionError, handle edge case\n        adaptive_weight = np.clip(avg_cap / (item + 1e-9), 0.1, 10) # Clip to avoid extreme weights\n        capacity_ratio_weighted = capacity_ratio * adaptive_weight\n\n        # Penalty for nearly full bins.  Higher penalty for smaller remaining space.\n        fullness_penalty = np.exp(-5 * remaining_capacity_after_fit / (item + 1e-9)) # Higher exponent for stronger penalty\n        priorities[feasible_mask] = capacity_ratio_weighted * (1 - fullness_penalty)  # Subtract penalty\n\n        # Dynamic Exploration/Exploitation:  Adjust randomness based on remaining bins.\n        num_empty_bins = np.sum(bins_remain_cap > 0.99) # Count bins that are almost empty (>.99 full capacity)\n        exploration_factor = np.clip(num_empty_bins / len(bins_remain_cap), 0.01, 0.1) # Avoid zero division, clip range\n\n        priorities += np.random.normal(0, exploration_factor, size=len(priorities))\n\n        # Constraint anticipation: Prefer bins that can accommodate at least a small *future* item\n        small_item_size = np.mean(bins_remain_cap[bins_remain_cap>0])/10 if np.any(bins_remain_cap > 0) else 0.1\n        future_fit_penalty = np.where(remaining_capacity_after_fit < small_item_size, -0.1 , 0)\n        priorities[feasible_mask] += future_fit_penalty # Apply slight penalty if doesn't fit small_item.\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 14.030714000797772,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)\n        priorities[feasible_mask][small_fragment_mask] *= 0.5\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * 2)\n        priorities[feasible_mask][large_capacity_mask] *= 1.1\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, 0.01, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > 5:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + 0.01 * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, 0.05, size=len(priorities)) # Higher randomness\n    return priorities",
    "response_id": 4,
    "tryHS": true,
    "obj": 4.008775428799367,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_hs3.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_fragment_threshold: float = 0.304623962297677,\n                small_fragment_penalty: float = 0.7894409446208984, large_capacity_threshold: float = 4.30068414158377,\n                large_capacity_bonus: float = 1.0143294610094642, base_randomness_std: float = 0.03281434669683145,\n                feasible_bins_threshold: int = 8.658039267680126, exploitation_bonus: float = 0.07729920473685242,\n                exploration_randomness_std: float = 0.03973695860881252) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_fragment_threshold: Threshold relative to item size below which a fragment is considered small.\n        small_fragment_penalty: Multiplier to reduce priority if a small fragment would be created.\n        large_capacity_threshold: Threshold relative to item size above which remaining capacity is considered large.\n        large_capacity_bonus: Multiplier to increase priority if remaining capacity is large.\n        base_randomness_std: Standard deviation of the base random noise added to priorities.\n        feasible_bins_threshold: Number of feasible bins above which exploitation is favored over exploration.\n        exploitation_bonus: Bonus added to priority based on capacity ratio when exploiting.\n        exploration_randomness_std: Standard deviation of random noise added to priorities when exploring.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have enough capacity to accommodate the item. Otherwise the priority should be very low.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Make infeasible bins have the lowest priority.\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Encourage bins that fit the item *relatively* well.\n        # The more filled the bin is the higher the priority.\n\n        priorities[feasible_mask] = capacity_ratio\n\n        # Reduce the priority if the remaining space is too small *relative* to the item to avoid creating *very* small fragments.\n        small_fragment_mask = remaining_capacity_after_fit < (item * small_fragment_threshold)\n        priorities[feasible_mask][small_fragment_mask] *= small_fragment_penalty\n\n        # Slightly increase the priority of bins with large remaining capacity to diversify selection.\n        large_capacity_mask = remaining_capacity_after_fit > (item * large_capacity_threshold)\n        priorities[feasible_mask][large_capacity_mask] *= large_capacity_bonus\n\n        # Introduce some randomness to break ties and explore the search space more effectively.\n        priorities += np.random.normal(0, base_randomness_std, size=len(priorities))\n\n        # Adaptive adjustment of exploration vs. exploitation\n        # Based on the number of feasible bins\n        num_feasible = np.sum(feasible_mask)\n        if num_feasible > feasible_bins_threshold:  # more options, more exploitation\n            priorities[feasible_mask] *= (1 + exploitation_bonus * capacity_ratio) # Favor bins that are already relatively full.\n        else: # Fewer options, more exploration\n            priorities += np.random.normal(0, exploration_randomness_std, size=len(priorities)) # Higher randomness\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.01874750698045,
    "exec_success": true
  }
]