{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get a very low priority.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) > 0:\n        remaining_capacity_after_fit = feasible_bins_remain_cap - item\n        capacity_ratio = item / feasible_bins_remain_cap\n\n        # Primary priority: Fill bins well, but not too tightly.\n        priorities[feasible_mask] = capacity_ratio\n\n        # Penalize small fragments, but less harshly.\n        small_fragment_mask = remaining_capacity_after_fit < (item * 0.05)  # Even smaller fragment threshold\n        priorities[feasible_mask][small_fragment_mask] *= 0.7  # Reduced penalty\n\n        # Incentivize bins that are already relatively full (more exploitation).\n        full_bin_mask = capacity_ratio > 0.7\n        priorities[feasible_mask][full_bin_mask] *= 1.2\n\n        # Exploration bonus for bins with moderate remaining capacity. This encourages a mix of bin usage.\n        moderate_capacity_mask = (remaining_capacity_after_fit > (item * 0.5)) & (remaining_capacity_after_fit <= (item * 1.5))\n        priorities[feasible_mask][moderate_capacity_mask] *= 1.1\n\n        # Adaptive Randomness: Reduce randomness as bins fill up (more exploitation)\n        average_fill_level = np.mean(1 - bins_remain_cap / np.max(bins_remain_cap)) # crude estimate of overall fill-level\n        randomness_scale = max(0.01, 0.05 * (1 - average_fill_level))  # scale randomness down as bins get full\n        priorities += np.random.normal(0, randomness_scale, size=len(priorities))\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive priority: combines capacity ratio, waste, and dynamic noise.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mark infeasible bins\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    \n    # Calculate remaining capacity after fit for feasible bins\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_fit = bins_remain_cap[feasible_mask] - item\n    \n    # Calculate capacity ratio (item size / bin capacity)\n    capacity_ratio = item / bins_remain_cap[feasible_mask]\n    \n    # Core priority calculation: favor higher capacity ratios, penalize waste\n    priorities[feasible_mask] = capacity_ratio * np.exp(-remaining_capacity_after_fit / (item + 1e-9))\n\n    # Discourage bins that will become nearly full after item placement\n    too_full_mask = feasible_mask & (remaining_capacity_after_fit < 0.1 * bins_remain_cap[feasible_mask])\n    priorities[too_full_mask] -= 0.5\n    \n    # Give a bonus to bins that become almost perfectly full after placement\n    almost_perfect_mask = feasible_mask & (remaining_capacity_after_fit < 1e-6)\n    priorities[almost_perfect_mask] += 0.2\n    \n    # Adaptive random noise injection: scale noise with item size and # feasible bins\n    num_feasible = np.sum(feasible_mask)\n    random_scale = 0.01 * item * max(1, num_feasible) #Scale by number of feasible bins\n    priorities += np.random.normal(0, random_scale, size=len(priorities))\n\n    # Normalize priorities\n    priorities /= (item + 1e-9)\n    \n    # Encourage reuse of nearly full bins\n    nearly_full_before_mask = feasible_mask & (bins_remain_cap[feasible_mask] < item * 1.1)\n    priorities[nearly_full_before_mask] += 0.1\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines normalized waste and bin utilization with dynamic noise, while the worst focuses on capacity ratio, waste, and dynamic noise but adds a penalty for bins becoming nearly full, a bonus for perfect fills, and normalizes priorities.\n(2nd best) vs (2nd worst): the second best balances fit, waste, fullness, and randomness, boosting bins with smaller remaining capacity and using adaptive noise. The second worst, similar to the worst, includes capacity ratio, waste, dynamic noise, near-full bin discouragement, and encourages re-use of nearly full bins.\nComparing (1st) vs (2nd), we see that the best uses a simpler noise scaling strategy based on the number of potential bins, while the second best scales noise by the mean remaining capacity of potential bins.\n(3rd) vs (4th): these two are identical.\nComparing (2nd worst) vs (worst), we see the second worst offers more encouragement toward usage of bins already nearly full while the worst also has near full bin discourage. Overall:\n\n*   **Feature Importance:** The best heuristics prioritize normalized waste and bin utilization. Penalizing future waste and rewarding already utilized bins appears effective.\n*   **Noise Scaling:** Simpler noise scaling mechanisms tied directly to the number of viable bins perform better. Complex scaling with bin capacities may be less effective.\n*   **Over-Engineering:** The worst heuristics attempt too many adjustments (penalties/bonuses) based on fine-grained conditions (e.g., nearly full bins, perfect fills). This can lead to instability.\n*   **Balanced Approach:** Adaptive exploration and exploitation is important, but overemphasizing either can be detrimental. Adaptive randomness, controlled by average bin fill levels or number of feasible bins, are used to break the tie.\n- \nOkay, let's redefine \"Current Self-Reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection.\"\n\nHere's a revised approach focusing on iterative improvement and targeted adjustments:\n\n*   **Keywords:** Iterative refinement, targeted complexity, performance analysis, problem-specific adaptation.\n*   **Advice:** Focus on iterative development, rigorously testing each added complexity for tangible performance gains on diverse instances. Analyze performance bottlenecks and tailor adjustments accordingly.\n*   **Avoid:** Premature optimization, over-reliance on intuition without empirical validation, generic solutions failing to adapt to specific problem characteristics.\n*   **Explanation:** Prioritize data-driven decisions. Base heuristic refinement on performance evaluation against specific problem instances rather than assumptions. Complexity should only be added if demonstrably beneficial.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}