{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic: balances fit, waste, fullness, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    cannot_fit = item > bins_remain_cap\n    priorities[cannot_fit] = -np.inf\n\n    can_fit = ~cannot_fit\n    remaining_capacities_can_fit = bins_remain_cap[can_fit]\n\n    if len(remaining_capacities_can_fit) > 0:\n        waste = remaining_capacities_can_fit - item\n        waste_normalized = waste / remaining_capacities_can_fit\n        utilization = item / remaining_capacities_can_fit\n\n        priorities[can_fit] = utilization - waste_normalized\n\n        # Boost bins with smaller remaining capacity after placement\n        remaining_after_placement = remaining_capacities_can_fit - item\n        remaining_after_placement = np.clip(remaining_after_placement, a_min=0, a_max=None)\n        priority_boost = np.exp(-5 * remaining_after_placement)\n        priorities[can_fit] += 0.5* priority_boost\n\n        #Adaptive noise: reduce noise as bins get full.\n        noise_scale = np.mean(remaining_capacities_can_fit)\n        noise = np.random.normal(0, 1e-6 * noise_scale, len(priorities))\n        priorities += noise\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bin handling:\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    feasible_bins_remain_cap = bins_remain_cap[feasible_mask]\n\n    if np.sum(feasible_mask) == 0:\n        return priorities  # No feasible bins, all priorities remain at 0 (or -inf).\n\n    # Calculate initial capacity ratio:\n    capacity_ratio = item / feasible_bins_remain_cap\n\n    # Base priority on capacity ratio:\n    priorities[feasible_mask] = capacity_ratio\n\n    # Fragment avoidance:\n    remaining_capacity_after_fit = feasible_bins_remain_cap - item\n    small_fragment_mask = remaining_capacity_after_fit < (item * 0.1)\n    priorities[feasible_mask][small_fragment_mask] *= 0.3 # Reduced to 0.3 instead of 0.5 for stronger penalty\n\n    # Encourage bins that are not too full and not too empty, a more balanced selection\n    medium_capacity_mask = (remaining_capacity_after_fit >= (item * 0.2)) & (remaining_capacity_after_fit <= (item * 1.5))\n    priorities[feasible_mask][medium_capacity_mask] *= 1.2 # Slightly prefer bins with medium remaining capacity\n\n\n    # Adaptive exploration based on bin fill levels. This is more explicit\n    bin_fill_levels = 1 - (bins_remain_cap / np.max(bins_remain_cap)) # Normalize to 0-1, filled vs total\n    avg_fill_level = np.mean(bin_fill_levels[~np.isinf(bin_fill_levels)]) #Exclude -inf values\n    exploration_rate = 0.01 + 0.04 * (1 - avg_fill_level)  # Higher exploration when bins are less full\n\n\n    # Exploration noise:\n    priorities += np.random.normal(0, exploration_rate, size=len(priorities)) # Scales with global fill level.\n\n    # Dynamic exploitation adjustment based on feasible bin count\n    num_feasible = np.sum(feasible_mask)\n    if num_feasible > 5:\n        priorities[feasible_mask] *= (1 + 0.02 * capacity_ratio)  # More exploitation\n    else:\n        priorities += np.random.normal(0, 0.03, size=len(priorities)) # More exploration when limited choices.\n\n    # Penalize bins that are getting too full to avoid premature saturation\n    almost_full_mask = (bins_remain_cap < (0.2 * np.max(bins_remain_cap))) & feasible_mask\n    priorities[almost_full_mask] *= 0.7 # Reduced priority of almost full bins\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines normalized waste and bin utilization with dynamic noise, while the worst focuses on capacity ratio, waste, and dynamic noise but adds a penalty for bins becoming nearly full, a bonus for perfect fills, and normalizes priorities.\n(2nd best) vs (2nd worst): the second best balances fit, waste, fullness, and randomness, boosting bins with smaller remaining capacity and using adaptive noise. The second worst, similar to the worst, includes capacity ratio, waste, dynamic noise, near-full bin discouragement, and encourages re-use of nearly full bins.\nComparing (1st) vs (2nd), we see that the best uses a simpler noise scaling strategy based on the number of potential bins, while the second best scales noise by the mean remaining capacity of potential bins.\n(3rd) vs (4th): these two are identical.\nComparing (2nd worst) vs (worst), we see the second worst offers more encouragement toward usage of bins already nearly full while the worst also has near full bin discourage. Overall:\n\n*   **Feature Importance:** The best heuristics prioritize normalized waste and bin utilization. Penalizing future waste and rewarding already utilized bins appears effective.\n*   **Noise Scaling:** Simpler noise scaling mechanisms tied directly to the number of viable bins perform better. Complex scaling with bin capacities may be less effective.\n*   **Over-Engineering:** The worst heuristics attempt too many adjustments (penalties/bonuses) based on fine-grained conditions (e.g., nearly full bins, perfect fills). This can lead to instability.\n*   **Balanced Approach:** Adaptive exploration and exploitation is important, but overemphasizing either can be detrimental. Adaptive randomness, controlled by average bin fill levels or number of feasible bins, are used to break the tie.\n- \nOkay, let's redefine \"Current Self-Reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection.\"\n\nHere's a revised approach focusing on iterative improvement and targeted adjustments:\n\n*   **Keywords:** Iterative refinement, targeted complexity, performance analysis, problem-specific adaptation.\n*   **Advice:** Focus on iterative development, rigorously testing each added complexity for tangible performance gains on diverse instances. Analyze performance bottlenecks and tailor adjustments accordingly.\n*   **Avoid:** Premature optimization, over-reliance on intuition without empirical validation, generic solutions failing to adapt to specific problem characteristics.\n*   **Explanation:** Prioritize data-driven decisions. Base heuristic refinement on performance evaluation against specific problem instances rather than assumptions. Complexity should only be added if demonstrably beneficial.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}