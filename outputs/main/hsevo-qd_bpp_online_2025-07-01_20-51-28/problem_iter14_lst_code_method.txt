{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, capacity ratio, with handling for full bins and dynamic adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    avg_bin_capacity = np.mean(bins_remain_cap[valid_bins])\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        near_fit_ratio = item / remaining_cap\n        if near_fit_ratio >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / avg_bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio\n        priorities[i] += near_fit_ratio * capacity_ratio_weight\n\n    # If no possible bins are good, make all possible bins minimally acceptable.\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, capacity ratio, with handling for full bins and dynamic adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    avg_bin_capacity = np.mean(bins_remain_cap[valid_bins])\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        near_fit_ratio = item / remaining_cap\n        if near_fit_ratio >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / avg_bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio\n        priorities[i] += near_fit_ratio * capacity_ratio_weight\n\n    # If no possible bins are good, make all possible bins minimally acceptable.\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, capacity ratio, with handling for full bins and dynamic adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    avg_bin_capacity = np.mean(bins_remain_cap[valid_bins])\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        near_fit_ratio = item / remaining_cap\n        if near_fit_ratio >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / avg_bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio\n        priorities[i] += near_fit_ratio * capacity_ratio_weight\n\n    # If no possible bins are good, make all possible bins minimally acceptable.\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: \"Near Fit\" - Prefer bins where the item fills a significant portion\n    #  but doesn't overflow. We'll add a penalty for overflow later.\n    near_fit_threshold = 0.9  # Adjust this to fine-tune \"nearness\"\n    near_fit_bonus = 10.0 # Significant boost for near fits\n\n    # Heuristic 2: Avoid Fragmentation - Penalize bins that would become highly fragmented\n    fragmentation_penalty_exponent = 2 # Higher exponent means stronger penalty for fragmentation\n    small_fragment_threshold = 0.1 # What counts as a small fragment relative to bin size?\n    large_fragment_penalty = -5.0 # Subtract points for producing a very small remaining fragment\n    \n    # Heuristic 3: Try to completely fill\n    complete_fill_bonus = 20.0\n\n    # Handle cases where remaining capacity is zero to avoid division by zero and also not allow packing to filled bins\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    \n    possible_bins = bins_remain_cap >= item\n    \n    for i, remaining_cap in enumerate(bins_remain_cap):\n        \n        if remaining_cap < item: # Disqualify bins that are too small\n            priorities[i] = -np.inf # Significantly low priority (lower than zero) to disallow item placement\n            continue\n        \n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n        \n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:  #Compare against a base capacity\n                priorities[i] += large_fragment_penalty # Severe penalty\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering near-fit, fragmentation, capacity ratio, and bin state.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # Adaptive near-fit bonus\n    near_fit_threshold = 0.8\n    near_fit_bonus_base = 10.0\n    \n    # Adaptive fragmentation penalty\n    small_fragment_threshold = 0.2\n    large_fragment_penalty_base = -5.0\n    \n    capacity_ratio_weight = 2.0\n\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return priorities\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit - adaptive bonus\n        near_fit_ratio = item / remaining_cap\n        if near_fit_ratio >= near_fit_threshold:\n            priorities[i] += near_fit_bonus_base * (near_fit_ratio - near_fit_threshold) / (1 - near_fit_threshold)\n\n        # Fragmentation - adaptive penalty\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty_base * (small_fragment_threshold - (new_remaining / bins_remain_cap[0])) / small_fragment_threshold\n\n        # Capacity Ratio\n        priorities[i] += (item / remaining_cap) * capacity_ratio_weight\n        \n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, and a capacity ratio to prioritize bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0  # Weight for the capacity ratio\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio - more continuous measure of suitability\n        priorities[i] += (item / remaining_cap) * capacity_ratio_weight\n\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, and a capacity ratio to prioritize bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0  # Weight for the capacity ratio\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio - more continuous measure of suitability\n        priorities[i] += (item / remaining_cap) * capacity_ratio_weight\n\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, and a capacity ratio to prioritize bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0  # Weight for the capacity ratio\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio - more continuous measure of suitability\n        priorities[i] += (item / remaining_cap) * capacity_ratio_weight\n\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more adaptive priority function for online bin packing, combining near-fit,\n    fragmentation avoidance, fill level, and dynamic weight adjustments.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # --- Parameter Defaults (Tunable) ---\n    near_fit_threshold = 0.95  # Increased threshold\n    near_fit_bonus = 15.0  # Increased bonus\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -7.0  # Increased penalty\n    complete_fill_bonus = 25.0  # Increased bonus\n    capacity_ratio_weight = 3.0  # Increased weight\n    bin_utilization_weight = 1.5\n    empty_bin_penalty = -10.0\n\n    # --- Dynamic Adjustments ---\n    avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0 # Avoid division by zero\n    total_items_size = np.sum(item) if isinstance(item, np.ndarray) else item\n    \n    # Early stage: Emphasize near-fit and complete fills\n    if np.sum(bins_remain_cap) > 3 * total_items_size * avg_bin_capacity:\n        near_fit_bonus *= 1.2\n        complete_fill_bonus *= 1.3\n    # Late stage: Emphasize fragmentation avoidance\n    elif np.sum(bins_remain_cap) < total_items_size * avg_bin_capacity:\n        large_fragment_penalty *= 1.5\n\n    # --- Calculate Priorities ---\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf  # Impossible to fit\n            continue\n        \n        # Complete Fill Bonus\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n            continue  # Skip further calculations if perfectly filled.\n\n        # Near Fit\n        near_fit_ratio = item / remaining_cap\n        if near_fit_ratio >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / avg_bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio\n        priorities[i] += near_fit_ratio * capacity_ratio_weight\n\n        # Bin Utilization: Prefer bins that are already somewhat full\n        bin_utilization = (bins_remain_cap[i] - remaining_cap) / avg_bin_capacity if avg_bin_capacity > 0 else 0\n        priorities[i] += bin_utilization * bin_utilization_weight\n    \n    # Empty Bin Penalty: Discourage using empty bins unless necessary\n    empty_bins = bins_remain_cap == bins_remain_cap.max() # identify empty bins (or largest)\n    if np.any(empty_bins):\n        priorities[empty_bins] += empty_bin_penalty\n\n    # --- Handle Edge Cases: If no 'good' bins, make possible bins acceptable ---\n    possible_bins = bins_remain_cap >= item\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n    \n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more adaptive priority function for online bin packing, combining near-fit,\n    fragmentation avoidance, fill level, and dynamic weight adjustments.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # --- Parameter Defaults (Tunable) ---\n    near_fit_threshold = 0.95  # Increased threshold\n    near_fit_bonus = 15.0  # Increased bonus\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -7.0  # Increased penalty\n    complete_fill_bonus = 25.0  # Increased bonus\n    capacity_ratio_weight = 3.0  # Increased weight\n    bin_utilization_weight = 1.5\n    empty_bin_penalty = -10.0\n\n    # --- Dynamic Adjustments ---\n    avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0 # Avoid division by zero\n    total_items_size = np.sum(item) if isinstance(item, np.ndarray) else item\n    \n    # Early stage: Emphasize near-fit and complete fills\n    if np.sum(bins_remain_cap) > 3 * total_items_size * avg_bin_capacity:\n        near_fit_bonus *= 1.2\n        complete_fill_bonus *= 1.3\n    # Late stage: Emphasize fragmentation avoidance\n    elif np.sum(bins_remain_cap) < total_items_size * avg_bin_capacity:\n        large_fragment_penalty *= 1.5\n\n    # --- Calculate Priorities ---\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf  # Impossible to fit\n            continue\n        \n        # Complete Fill Bonus\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n            continue  # Skip further calculations if perfectly filled.\n\n        # Near Fit\n        near_fit_ratio = item / remaining_cap\n        if near_fit_ratio >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / avg_bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio\n        priorities[i] += near_fit_ratio * capacity_ratio_weight\n\n        # Bin Utilization: Prefer bins that are already somewhat full\n        bin_utilization = (bins_remain_cap[i] - remaining_cap) / avg_bin_capacity if avg_bin_capacity > 0 else 0\n        priorities[i] += bin_utilization * bin_utilization_weight\n    \n    # Empty Bin Penalty: Discourage using empty bins unless necessary\n    empty_bins = bins_remain_cap == bins_remain_cap.max() # identify empty bins (or largest)\n    if np.any(empty_bins):\n        priorities[empty_bins] += empty_bin_penalty\n\n    # --- Handle Edge Cases: If no 'good' bins, make possible bins acceptable ---\n    possible_bins = bins_remain_cap >= item\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n    \n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_capacity = bins_remain_cap[0] # Assuming all bins have same capacity\n\n\n    # Heuristic 1: \"Near Fit\" - Prefer bins where the item fills a significant portion\n    near_fit_threshold = 0.9\n    near_fit_bonus_base = 10.0\n\n    # Heuristic 2: Avoid Fragmentation - Penalize bins that would become highly fragmented\n    fragmentation_penalty_exponent = 2\n    small_fragment_threshold = 0.1\n    large_fragment_penalty_base = -5.0\n\n    # Heuristic 3: Try to completely fill\n    complete_fill_bonus_base = 20.0\n\n    # Heuristic 4: Balance utilization across bins.  Penalize bins that are already very full\n    # to promote spreading items across bins, especially when items are small.\n    utilization_penalty_exponent = 1 # Higher exponent means stronger penalty for high utilization\n    high_utilization_threshold = 0.75 #Consider a bin highly utilized above this value\n    high_utilization_penalty_factor = -2.0\n\n    # Heuristic 5: Reward bins that have been empty for a while (delayed first fit)\n    # This encourages usage of empty bins and reduces bin count.  This is very effective when items come sorted in decreasing order.\n    # This needs to be coupled with good exploration of existing bins though, to avoid wasting space when items become smaller\n    empty_bin_bonus_base = 5.0 #Give small boost for packing into completely empty bin. This has to be a small boost\n    \n    #Adaptive Weights\n    near_fit_bonus = near_fit_bonus_base * (1 + (1-item/bin_capacity)) #Scale down when item is small, scale up when item is large\n    large_fragment_penalty = large_fragment_penalty_base * (1 + (item / bin_capacity))  #Penalize less when item is already big\n    complete_fill_bonus = complete_fill_bonus_base * (1 + (item/bin_capacity)) #scale up when item is large\n    \n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n    \n    #Normalize remaining capacity (relative to bin capacity)\n    normalized_remain_cap = bins_remain_cap / bin_capacity\n    \n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n\n        # Complete Fill\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Utilization Balancing\n        utilization = 1 - (remaining_cap / bin_capacity)\n        if utilization >= high_utilization_threshold:\n             priorities[i] += high_utilization_penalty_factor * (utilization**utilization_penalty_exponent)\n\n        # Empty Bin Bonus (delayed first fit)\n        if remaining_cap == bin_capacity:\n            priorities[i] += empty_bin_bonus_base\n\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_capacity = bins_remain_cap[0] # Assuming all bins have same capacity\n\n\n    # Heuristic 1: \"Near Fit\" - Prefer bins where the item fills a significant portion\n    near_fit_threshold = 0.9\n    near_fit_bonus_base = 10.0\n\n    # Heuristic 2: Avoid Fragmentation - Penalize bins that would become highly fragmented\n    fragmentation_penalty_exponent = 2\n    small_fragment_threshold = 0.1\n    large_fragment_penalty_base = -5.0\n\n    # Heuristic 3: Try to completely fill\n    complete_fill_bonus_base = 20.0\n\n    # Heuristic 4: Balance utilization across bins.  Penalize bins that are already very full\n    # to promote spreading items across bins, especially when items are small.\n    utilization_penalty_exponent = 1 # Higher exponent means stronger penalty for high utilization\n    high_utilization_threshold = 0.75 #Consider a bin highly utilized above this value\n    high_utilization_penalty_factor = -2.0\n\n    # Heuristic 5: Reward bins that have been empty for a while (delayed first fit)\n    # This encourages usage of empty bins and reduces bin count.  This is very effective when items come sorted in decreasing order.\n    # This needs to be coupled with good exploration of existing bins though, to avoid wasting space when items become smaller\n    empty_bin_bonus_base = 5.0 #Give small boost for packing into completely empty bin. This has to be a small boost\n    \n    #Adaptive Weights\n    near_fit_bonus = near_fit_bonus_base * (1 + (1-item/bin_capacity)) #Scale down when item is small, scale up when item is large\n    large_fragment_penalty = large_fragment_penalty_base * (1 + (item / bin_capacity))  #Penalize less when item is already big\n    complete_fill_bonus = complete_fill_bonus_base * (1 + (item/bin_capacity)) #scale up when item is large\n    \n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n    \n    #Normalize remaining capacity (relative to bin capacity)\n    normalized_remain_cap = bins_remain_cap / bin_capacity\n    \n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n\n        # Complete Fill\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Utilization Balancing\n        utilization = 1 - (remaining_cap / bin_capacity)\n        if utilization >= high_utilization_threshold:\n             priorities[i] += high_utilization_penalty_factor * (utilization**utilization_penalty_exponent)\n\n        # Empty Bin Bonus (delayed first fit)\n        if remaining_cap == bin_capacity:\n            priorities[i] += empty_bin_bonus_base\n\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_capacity = bins_remain_cap[0] # Assuming all bins have same capacity\n\n\n    # Heuristic 1: \"Near Fit\" - Prefer bins where the item fills a significant portion\n    near_fit_threshold = 0.9\n    near_fit_bonus_base = 10.0\n\n    # Heuristic 2: Avoid Fragmentation - Penalize bins that would become highly fragmented\n    fragmentation_penalty_exponent = 2\n    small_fragment_threshold = 0.1\n    large_fragment_penalty_base = -5.0\n\n    # Heuristic 3: Try to completely fill\n    complete_fill_bonus_base = 20.0\n\n    # Heuristic 4: Balance utilization across bins.  Penalize bins that are already very full\n    # to promote spreading items across bins, especially when items are small.\n    utilization_penalty_exponent = 1 # Higher exponent means stronger penalty for high utilization\n    high_utilization_threshold = 0.75 #Consider a bin highly utilized above this value\n    high_utilization_penalty_factor = -2.0\n\n    # Heuristic 5: Reward bins that have been empty for a while (delayed first fit)\n    # This encourages usage of empty bins and reduces bin count.  This is very effective when items come sorted in decreasing order.\n    # This needs to be coupled with good exploration of existing bins though, to avoid wasting space when items become smaller\n    empty_bin_bonus_base = 5.0 #Give small boost for packing into completely empty bin. This has to be a small boost\n    \n    #Adaptive Weights\n    near_fit_bonus = near_fit_bonus_base * (1 + (1-item/bin_capacity)) #Scale down when item is small, scale up when item is large\n    large_fragment_penalty = large_fragment_penalty_base * (1 + (item / bin_capacity))  #Penalize less when item is already big\n    complete_fill_bonus = complete_fill_bonus_base * (1 + (item/bin_capacity)) #scale up when item is large\n    \n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n    \n    #Normalize remaining capacity (relative to bin capacity)\n    normalized_remain_cap = bins_remain_cap / bin_capacity\n    \n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n\n        # Complete Fill\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bin_capacity) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Utilization Balancing\n        utilization = 1 - (remaining_cap / bin_capacity)\n        if utilization >= high_utilization_threshold:\n             priorities[i] += high_utilization_penalty_factor * (utilization**utilization_penalty_exponent)\n\n        # Empty Bin Bonus (delayed first fit)\n        if remaining_cap == bin_capacity:\n            priorities[i] += empty_bin_bonus_base\n\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, near_fit_threshold: float = 0.4537616222011033, near_fit_bonus: float = 5.046530038859154,\n                 small_fragment_threshold: float = 0.4725734793806232, large_fragment_penalty: float = -10.360790125701607,\n                 complete_fill_bonus: float = 38.25419426314882, capacity_ratio_weight: float = 0.10875781327878087) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, capacity ratio, with handling for full bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                near_fit_threshold: float = 0.29761772594302804,\n                near_fit_bonus: float = 16.302760571277386,\n                fragmentation_penalty_exponent: int = 1.044573988314493,\n                small_fragment_threshold: float = 0.16584727708016184,\n                large_fragment_penalty: float = -8.254364625617328,\n                complete_fill_bonus: float = 51.776707242150245,\n                raise_potential_bins_score: float = 0.47377604441116505) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        near_fit_threshold: Threshold for near fit heuristic.\n        near_fit_bonus: Bonus for near fit heuristic.\n        fragmentation_penalty_exponent: Exponent for fragmentation penalty.\n        small_fragment_threshold: Threshold for small fragment.\n        large_fragment_penalty: Penalty for large fragment.\n        complete_fill_bonus: Bonus for complete fill.\n        raise_potential_bins_score: Score for raising potential bins.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Handle cases where remaining capacity is zero to avoid division by zero and also not allow packing to filled bins\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces dynamic weighting and considers bin fill level.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap[0]  # Assuming all bins have the same capacity.\n\n    # Heuristic 1: Near Fit (Dynamic bonus based on fill level)\n    near_fit_threshold_low = 0.75\n    near_fit_threshold_high = 0.95\n    near_fit_bonus_max = 15.0\n\n    # Heuristic 2: Fragmentation Penalty (Adaptive based on item size)\n    fragmentation_penalty_exponent = 2\n    small_fragment_threshold = 0.1\n    large_fragment_penalty_factor = -5.0\n\n    # Heuristic 3: Complete Fill Bonus\n    complete_fill_bonus = 25.0\n\n    # Heuristic 4: Fill Level Preference (Encourage filling emptier bins first, but temper)\n    fill_level_preference_weight = 2.0\n\n    # Heuristic 5: Avoid Overfill (Strong Negative Priority)\n    overfill_penalty = -np.inf\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = overfill_penalty\n            continue\n\n        # Complete Fill\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n            continue #Short circuit to avoid other calculations\n\n        # Near Fit (Dynamic Bonus)\n        fill_ratio = item / remaining_cap\n        if near_fit_threshold_low <= fill_ratio <= near_fit_threshold_high:\n            # Scale bonus based on how close it is to the ideal near fit.\n            near_fit_bonus = near_fit_bonus_max * (1 - abs(fill_ratio - (near_fit_threshold_low + near_fit_threshold_high)/2) / ((near_fit_threshold_high - near_fit_threshold_low)/2))\n            priorities[i] += near_fit_bonus\n\n        # Fragmentation Penalty (Adaptive)\n        new_remaining = remaining_cap - item\n        if new_remaining > 0:\n            fragment_ratio = new_remaining / bin_capacity\n            if fragment_ratio < small_fragment_threshold:\n                # Scale penalty based on the item size.  Larger items causing fragmentation receive more penalty.\n                penalty = large_fragment_penalty_factor * (item / bin_capacity)\n                priorities[i] += penalty\n\n        # Fill Level Preference\n        priorities[i] += fill_level_preference_weight * (1 - (remaining_cap / bin_capacity))\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > overfill_penalty):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces dynamic weighting and considers bin fill level.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap[0]  # Assuming all bins have the same capacity.\n\n    # Heuristic 1: Near Fit (Dynamic bonus based on fill level)\n    near_fit_threshold_low = 0.75\n    near_fit_threshold_high = 0.95\n    near_fit_bonus_max = 15.0\n\n    # Heuristic 2: Fragmentation Penalty (Adaptive based on item size)\n    fragmentation_penalty_exponent = 2\n    small_fragment_threshold = 0.1\n    large_fragment_penalty_factor = -5.0\n\n    # Heuristic 3: Complete Fill Bonus\n    complete_fill_bonus = 25.0\n\n    # Heuristic 4: Fill Level Preference (Encourage filling emptier bins first, but temper)\n    fill_level_preference_weight = 2.0\n\n    # Heuristic 5: Avoid Overfill (Strong Negative Priority)\n    overfill_penalty = -np.inf\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = overfill_penalty\n            continue\n\n        # Complete Fill\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n            continue #Short circuit to avoid other calculations\n\n        # Near Fit (Dynamic Bonus)\n        fill_ratio = item / remaining_cap\n        if near_fit_threshold_low <= fill_ratio <= near_fit_threshold_high:\n            # Scale bonus based on how close it is to the ideal near fit.\n            near_fit_bonus = near_fit_bonus_max * (1 - abs(fill_ratio - (near_fit_threshold_low + near_fit_threshold_high)/2) / ((near_fit_threshold_high - near_fit_threshold_low)/2))\n            priorities[i] += near_fit_bonus\n\n        # Fragmentation Penalty (Adaptive)\n        new_remaining = remaining_cap - item\n        if new_remaining > 0:\n            fragment_ratio = new_remaining / bin_capacity\n            if fragment_ratio < small_fragment_threshold:\n                # Scale penalty based on the item size.  Larger items causing fragmentation receive more penalty.\n                penalty = large_fragment_penalty_factor * (item / bin_capacity)\n                priorities[i] += penalty\n\n        # Fill Level Preference\n        priorities[i] += fill_level_preference_weight * (1 - (remaining_cap / bin_capacity))\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > overfill_penalty):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces dynamic weighting and considers bin fill level.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap[0]  # Assuming all bins have the same capacity.\n\n    # Heuristic 1: Near Fit (Dynamic bonus based on fill level)\n    near_fit_threshold_low = 0.75\n    near_fit_threshold_high = 0.95\n    near_fit_bonus_max = 15.0\n\n    # Heuristic 2: Fragmentation Penalty (Adaptive based on item size)\n    fragmentation_penalty_exponent = 2\n    small_fragment_threshold = 0.1\n    large_fragment_penalty_factor = -5.0\n\n    # Heuristic 3: Complete Fill Bonus\n    complete_fill_bonus = 25.0\n\n    # Heuristic 4: Fill Level Preference (Encourage filling emptier bins first, but temper)\n    fill_level_preference_weight = 2.0\n\n    # Heuristic 5: Avoid Overfill (Strong Negative Priority)\n    overfill_penalty = -np.inf\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = overfill_penalty\n            continue\n\n        # Complete Fill\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n            continue #Short circuit to avoid other calculations\n\n        # Near Fit (Dynamic Bonus)\n        fill_ratio = item / remaining_cap\n        if near_fit_threshold_low <= fill_ratio <= near_fit_threshold_high:\n            # Scale bonus based on how close it is to the ideal near fit.\n            near_fit_bonus = near_fit_bonus_max * (1 - abs(fill_ratio - (near_fit_threshold_low + near_fit_threshold_high)/2) / ((near_fit_threshold_high - near_fit_threshold_low)/2))\n            priorities[i] += near_fit_bonus\n\n        # Fragmentation Penalty (Adaptive)\n        new_remaining = remaining_cap - item\n        if new_remaining > 0:\n            fragment_ratio = new_remaining / bin_capacity\n            if fragment_ratio < small_fragment_threshold:\n                # Scale penalty based on the item size.  Larger items causing fragmentation receive more penalty.\n                penalty = large_fragment_penalty_factor * (item / bin_capacity)\n                priorities[i] += penalty\n\n        # Fill Level Preference\n        priorities[i] += fill_level_preference_weight * (1 - (remaining_cap / bin_capacity))\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > overfill_penalty):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}