{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: \"Near Fit\" - Prefer bins where the item fills a significant portion\n    #  but doesn't overflow. We'll add a penalty for overflow later.\n    near_fit_threshold = 0.9  # Adjust this to fine-tune \"nearness\"\n    near_fit_bonus = 10.0 # Significant boost for near fits\n\n    # Heuristic 2: Avoid Fragmentation - Penalize bins that would become highly fragmented\n    fragmentation_penalty_exponent = 2 # Higher exponent means stronger penalty for fragmentation\n    small_fragment_threshold = 0.1 # What counts as a small fragment relative to bin size?\n    large_fragment_penalty = -5.0 # Subtract points for producing a very small remaining fragment\n    \n    # Heuristic 3: Try to completely fill\n    complete_fill_bonus = 20.0\n\n    # Handle cases where remaining capacity is zero to avoid division by zero and also not allow packing to filled bins\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    \n    possible_bins = bins_remain_cap >= item\n    \n    for i, remaining_cap in enumerate(bins_remain_cap):\n        \n        if remaining_cap < item: # Disqualify bins that are too small\n            priorities[i] = -np.inf # Significantly low priority (lower than zero) to disallow item placement\n            continue\n        \n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n        \n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:  #Compare against a base capacity\n                priorities[i] += large_fragment_penalty # Severe penalty\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates dynamic adaptation based on bin utilization\n    and more nuanced fragmentation handling, along with a first-fit consideration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # --- Heuristic Parameters (Tunable) ---\n    near_fit_threshold = 0.9\n    near_fit_bonus = 15.0  # Increased bonus for near fit\n\n    fragmentation_penalty_exponent = 2.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -10.0 # Increased penalty for small fragments\n\n    complete_fill_bonus = 25.0 # Increased bonus for complete fill\n    first_fit_bonus = 5.0  # Bonus for placing in the first available bin\n\n    # Bin Utilization Awareness: Adjust near_fit_threshold based on avg bin capacity\n    avg_bin_capacity = np.mean(bins_remain_cap) if num_bins > 0 else 1.0 # avoid division by zero\n    if avg_bin_capacity < 0.3:\n      near_fit_threshold = 0.85 # be more aggressive if bins are filling up\n    elif avg_bin_capacity > 0.7:\n      near_fit_threshold = 0.95 # be stricter if bins are mostly empty\n\n    # --- Heuristic Logic ---\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n\n    first_possible_bin_index = -1\n    for i in range(num_bins):\n        if bins_remain_cap[i] >= item:\n            first_possible_bin_index = i\n            break\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n            \n\n        # Fragmentation - More nuanced penalty calculation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0:\n            fragment_ratio = new_remaining / bins_remain_cap[0]\n            if fragment_ratio < small_fragment_threshold:\n                priorities[i] += large_fragment_penalty  # Strong penalty\n\n        # First Fit Preference (slight nudge, if applicable)\n        if i == first_possible_bin_index and first_possible_bin_index != -1:\n            priorities[i] += first_fit_bonus\n\n    # If no bins can contain the item, slightly raise score of potential bins\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic incorporates near-fit, fragmentation avoidance, and capacity ratio, while the worst only uses a logarithmic capacity ratio. Comparing (2nd best) vs (second worst), heuristics 17 and 18 present a similar contrast. The better heuristic adaptively combines multiple factors and handles edge cases. The worst heuristic uses only a ratio.\n\nComparing (1st) vs (2nd), the codes are identical. Comparing (3rd) vs (4th), the codes are identical. Comparing (second worst) vs (worst), the codes are identical.\n\nComparing (1st) vs (3rd), the first uses discrete bonuses/penalties, while the third uses adaptive bonuses/penalties based on ratios. The first also includes a complete fill bonus, and a raise score option.\n\nComparing (14th) vs (16th), 14th uses a first fit preference with an adaptive near fit threshold based on average bin capacity. 16th uses dynamic near fit and fragmentation adjustments as well.\n\nOverall: The better heuristics combine multiple relevant factors (near fit, fragmentation, capacity ratio), use adaptive weights or bonuses, consider edge cases (empty bins, overfill), and sometimes incorporate a slight preference for the first available bin. Simpler heuristics relying on a single metric perform worse. Parameter tuning is important.\n- \nOkay, let's refine \"Current self-reflection\" to be more effective for designing heuristics, considering your tips.\n\nHere's a revised approach focusing on concrete, actionable advice, and avoiding the pitfalls of ineffective reflection:\n\n*   **Keywords:** Adaptive Weights, Multifaceted, Edge Cases, Simplicity Bias, Experimental Calibration, Dynamic Adjustment, Named Arguments\n\n*   **Advice:** Prioritize heuristics combining multiple factors (near-fit, fragmentation, fill level). Dynamically adjust weights based on problem state. Use named arguments with optimized defaults for scoring parameters. Handle edge cases gracefully.\n\n*   **Avoid:** Overly simplistic approaches. Static, inflexible weighting schemes. Ignoring common problem-specific issues (e.g., fragmentation in packing).\n\n*   **Explanation:** Blend relevant factors, adjusting parameter weights on the fly depending on progress and context, and provide reasonable defaults for all scoring parameters to achieve a better trade-off between solution quality and computation speed.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}