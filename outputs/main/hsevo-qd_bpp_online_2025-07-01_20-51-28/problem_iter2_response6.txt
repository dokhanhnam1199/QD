```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines near-fit and fragmentation heuristics with adaptive scaling."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    near_fit_threshold = 0.9
    near_fit_bonus = 10.0
    small_fragment_threshold = 0.1
    large_fragment_penalty = -5.0
    complete_fill_bonus = 20.0
    
    valid_bins = bins_remain_cap > 0
    if not np.any(valid_bins):
        return priorities
    
    possible_bins = bins_remain_cap >= item

    for i, remaining_cap in enumerate(bins_remain_cap):
        if remaining_cap < item:
            priorities[i] = -np.inf
            continue

        # Near Fit
        if item / remaining_cap >= near_fit_threshold:
            priorities[i] += near_fit_bonus

        if item == remaining_cap:
            priorities[i] += complete_fill_bonus

        # Fragmentation
        new_remaining = remaining_cap - item
        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:
            priorities[i] += large_fragment_penalty
            
    if not np.any(priorities[possible_bins] > -np.inf):
        priorities[possible_bins] += 0.001

    # Adaptive Scaling (Experiment): Scale priorities based on item size.
    #  Smaller items: favor fragmentation avoidance more.
    #  Larger items: favor near-fit more.
    item_size_scale = item  # Scale linearly with item size (can be tuned)
    priorities = priorities * (1 + item_size_scale/10) # scale near fit

    #Add log ratio
    ratios = item / bins_remain_cap
    ratios[ratios>1] = 1
    log_ratios = np.log(ratios)
    priorities += -log_ratios

    return priorities
```
