[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: \"Near Fit\" - Prefer bins where the item fills a significant portion\n    #  but doesn't overflow. We'll add a penalty for overflow later.\n    near_fit_threshold = 0.9  # Adjust this to fine-tune \"nearness\"\n    near_fit_bonus = 10.0 # Significant boost for near fits\n\n    # Heuristic 2: Avoid Fragmentation - Penalize bins that would become highly fragmented\n    fragmentation_penalty_exponent = 2 # Higher exponent means stronger penalty for fragmentation\n    small_fragment_threshold = 0.1 # What counts as a small fragment relative to bin size?\n    large_fragment_penalty = -5.0 # Subtract points for producing a very small remaining fragment\n    \n    # Heuristic 3: Try to completely fill\n    complete_fill_bonus = 20.0\n\n    # Handle cases where remaining capacity is zero to avoid division by zero and also not allow packing to filled bins\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    \n    possible_bins = bins_remain_cap >= item\n    \n    for i, remaining_cap in enumerate(bins_remain_cap):\n        \n        if remaining_cap < item: # Disqualify bins that are too small\n            priorities[i] = -np.inf # Significantly low priority (lower than zero) to disallow item placement\n            continue\n        \n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n        \n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:  #Compare against a base capacity\n                priorities[i] += large_fragment_penalty # Severe penalty\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n\n    return priorities",
    "response_id": 7,
    "tryHS": true,
    "obj": 4.028719585161557,
    "SLOC": 10.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 79.86649421043717,
    "token_count": 132.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, and a capacity ratio to prioritize bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0  # Weight for the capacity ratio\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio - more continuous measure of suitability\n        priorities[i] += (item / remaining_cap) * capacity_ratio_weight\n\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 27.0,
    "cyclomatic_complexity": 9.0,
    "halstead": 358.95598430941163,
    "mi": 70.25600564940436,
    "token_count": 245.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces dynamic weighting and considers bin fill level.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = bins_remain_cap[0]  # Assuming all bins have the same capacity.\n\n    # Heuristic 1: Near Fit (Dynamic bonus based on fill level)\n    near_fit_threshold_low = 0.75\n    near_fit_threshold_high = 0.95\n    near_fit_bonus_max = 15.0\n\n    # Heuristic 2: Fragmentation Penalty (Adaptive based on item size)\n    fragmentation_penalty_exponent = 2\n    small_fragment_threshold = 0.1\n    large_fragment_penalty_factor = -5.0\n\n    # Heuristic 3: Complete Fill Bonus\n    complete_fill_bonus = 25.0\n\n    # Heuristic 4: Fill Level Preference (Encourage filling emptier bins first, but temper)\n    fill_level_preference_weight = 2.0\n\n    # Heuristic 5: Avoid Overfill (Strong Negative Priority)\n    overfill_penalty = -np.inf\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = overfill_penalty\n            continue\n\n        # Complete Fill\n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n            continue #Short circuit to avoid other calculations\n\n        # Near Fit (Dynamic Bonus)\n        fill_ratio = item / remaining_cap\n        if near_fit_threshold_low <= fill_ratio <= near_fit_threshold_high:\n            # Scale bonus based on how close it is to the ideal near fit.\n            near_fit_bonus = near_fit_bonus_max * (1 - abs(fill_ratio - (near_fit_threshold_low + near_fit_threshold_high)/2) / ((near_fit_threshold_high - near_fit_threshold_low)/2))\n            priorities[i] += near_fit_bonus\n\n        # Fragmentation Penalty (Adaptive)\n        new_remaining = remaining_cap - item\n        if new_remaining > 0:\n            fragment_ratio = new_remaining / bin_capacity\n            if fragment_ratio < small_fragment_threshold:\n                # Scale penalty based on the item size.  Larger items causing fragmentation receive more penalty.\n                penalty = large_fragment_penalty_factor * (item / bin_capacity)\n                priorities[i] += penalty\n\n        # Fill Level Preference\n        priorities[i] += fill_level_preference_weight * (1 - (remaining_cap / bin_capacity))\n\n    # If no bins can contain the item (after applying fragmentation penalty), slightly raise score of potential bins for placement\n    if not np.any(priorities[possible_bins] > overfill_penalty):\n        priorities[possible_bins] += 0.001\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 5.115676106900674,
    "SLOC": 35.0,
    "cyclomatic_complexity": 10.0,
    "halstead": 451.50849518197793,
    "mi": 74.68370763706417,
    "token_count": 340.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                near_fit_threshold: float = 0.5667358291405592,\n                near_fit_bonus: float = 22.38135249108899,\n                fragmentation_penalty_exponent: int = 2.308462920455862,\n                small_fragment_threshold: float = 0.08288814949623513,\n                large_fragment_penalty: float = -11.55606595135383,\n                complete_fill_bonus: float = 48.856383562403046,\n                desperate_priority_increase: float = 0.07980886411476741) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        near_fit_threshold: Threshold for considering a near fit.\n        near_fit_bonus: Bonus for a near fit.\n        fragmentation_penalty_exponent: Exponent for the fragmentation penalty.\n        small_fragment_threshold: Threshold for considering a fragment small.\n        large_fragment_penalty: Penalty for a large fragment.\n        complete_fill_bonus: Bonus for completely filling a bin.\n        desperate_priority_increase: priority increase when no bins are available.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Handle cases where remaining capacity is zero to avoid division by zero and also not allow packing to filled bins\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 11.60964047443681,
    "mi": 98.48956911045778,
    "token_count": 112.0,
    "exec_success": true
  }
]