{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines near-fit, fragmentation avoidance, capacity ratio, with handling for full bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_fit_threshold = 0.9\n    near_fit_bonus = 10.0\n    small_fragment_threshold = 0.1\n    large_fragment_penalty = -5.0\n    complete_fill_bonus = 20.0\n    capacity_ratio_weight = 2.0\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n    \n    possible_bins = bins_remain_cap >= item\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap < item:\n            priorities[i] = -np.inf\n            continue\n\n        # Near Fit\n        if item / remaining_cap >= near_fit_threshold:\n            priorities[i] += near_fit_bonus\n        \n        if item == remaining_cap:\n            priorities[i] += complete_fill_bonus\n\n        # Fragmentation\n        new_remaining = remaining_cap - item\n        if new_remaining > 0 and (new_remaining / bins_remain_cap[0]) < small_fragment_threshold:\n            priorities[i] += large_fragment_penalty\n\n        # Capacity Ratio\n        priorities[i] += (item / remaining_cap) * capacity_ratio_weight\n\n    # If no possible bins are good, make all possible bins minimally acceptable.\n    if not np.any(priorities[possible_bins] > -np.inf):\n        priorities[possible_bins] += 0.001\n        \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                 small_fragment_threshold: float = 0.4725734793806232, large_fragment_penalty: float = -10.360790125701607,\n                 complete_fill_bonus: float = 38.25419426314882, capacity_ratio_weight: float = 0.10875781327878087) -> np.ndarray:\n    \"\"\"Combines near-fit, fragmentation avoidance, capacity ratio, with handling for full bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic incorporates near-fit, fragmentation avoidance, and capacity ratio, while the worst only uses a logarithmic capacity ratio. Comparing (2nd best) vs (second worst), heuristics 17 and 18 present a similar contrast. The better heuristic adaptively combines multiple factors and handles edge cases. The worst heuristic uses only a ratio.\n\nComparing (1st) vs (2nd), the codes are identical. Comparing (3rd) vs (4th), the codes are identical. Comparing (second worst) vs (worst), the codes are identical.\n\nComparing (1st) vs (3rd), the first uses discrete bonuses/penalties, while the third uses adaptive bonuses/penalties based on ratios. The first also includes a complete fill bonus, and a raise score option.\n\nComparing (14th) vs (16th), 14th uses a first fit preference with an adaptive near fit threshold based on average bin capacity. 16th uses dynamic near fit and fragmentation adjustments as well.\n\nOverall: The better heuristics combine multiple relevant factors (near fit, fragmentation, capacity ratio), use adaptive weights or bonuses, consider edge cases (empty bins, overfill), and sometimes incorporate a slight preference for the first available bin. Simpler heuristics relying on a single metric perform worse. Parameter tuning is important.\n- \nOkay, let's refine \"Current self-reflection\" to be more effective for designing heuristics, considering your tips.\n\nHere's a revised approach focusing on concrete, actionable advice, and avoiding the pitfalls of ineffective reflection:\n\n*   **Keywords:** Adaptive Weights, Multifaceted, Edge Cases, Simplicity Bias, Experimental Calibration, Dynamic Adjustment, Named Arguments\n\n*   **Advice:** Prioritize heuristics combining multiple factors (near-fit, fragmentation, fill level). Dynamically adjust weights based on problem state. Use named arguments with optimized defaults for scoring parameters. Handle edge cases gracefully.\n\n*   **Avoid:** Overly simplistic approaches. Static, inflexible weighting schemes. Ignoring common problem-specific issues (e.g., fragmentation in packing).\n\n*   **Explanation:** Blend relevant factors, adjusting parameter weights on the fly depending on progress and context, and provide reasonable defaults for all scoring parameters to achieve a better trade-off between solution quality and computation speed.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}