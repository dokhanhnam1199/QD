```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A more adaptive and multi-objective priority function for online Bin Packing.
    It considers:
    1. Tightest fit (minimizing remaining capacity).
    2. Perfect fit bonus.
    3. Bin utilization efficiency (how much of the bin is used by the current item).
    4. A penalty for bins that are too empty relative to the item size.
    5. Adaptive exploration: prioritizes bins that have previously been "good" for items
       of similar size, guided by a decaying memory of past performance.
    """

    priorities = np.full_like(bins_remain_cap, -np.inf)
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # --- Core Scoring Components ---

    # 1. Tightest Fit: Maximize the negative difference (remaining capacity after fit)
    remaining_after_fit = valid_bins_capacities - item
    tightest_fit_score = -remaining_after_fit

    # 2. Perfect Fit Bonus
    perfect_fit_bonus = 1000.0
    perfect_fit_mask = np.abs(remaining_after_fit) < 1e-9
    exploitation_scores = tightest_fit_score
    exploitation_scores[perfect_fit_mask] += perfect_fit_bonus

    # 3. Bin Utilization Efficiency: Reward bins that are well-utilized by the current item.
    # This prevents picking a very large bin for a small item if a tighter fit exists.
    # Score is proportional to item_size / bin_capacity.
    utilization_score = item / (bins_remain_cap[can_fit_mask] + 1e-9) # Add epsilon to avoid division by zero
    utilization_score_weight = 0.5 # Weight for utilization score
    exploitation_scores += utilization_score * utilization_score_weight

    # 4. Penalty for overly empty bins (relative to item size):
    # Avoid bins where the item would occupy a very small fraction of its capacity.
    # This is an inverse of utilization for very small items.
    overly_empty_penalty_threshold = 0.1 # If remaining capacity > 10% of bin capacity, apply penalty
    overly_empty_penalty_factor = 0.8  # Penalty strength

    # Calculate penalty based on remaining capacity relative to the *original* bin capacity.
    # We want to penalize bins that are large and leave a lot of space *after* the item is placed.
    # A bin that is already almost full and has little remaining capacity after fitting is good.
    # We are penalizing bins that are very large and the item is small relative to them.
    # Here, we look at the residual capacity *after* fitting the item, relative to the *original* bin capacity.
    # If residual_capacity / original_bin_capacity is large, it means the bin was much larger than needed.
    overly_empty_mask = (remaining_after_fit / (valid_bins_capacities + 1e-9)) > overly_empty_penalty_threshold
    overly_empty_penalty = (remaining_after_fit / (valid_bins_capacities + 1e-9)) * overly_empty_penalty_factor
    exploitation_scores[overly_empty_mask] -= overly_empty_penalty[overly_empty_mask]


    # --- Adaptive Exploration Component (Decaying Memory) ---
    # This part requires state (memory of past performance).
    # For demonstration, we'll simulate a simple memory. In a real system,
    # this memory would be updated after each packing decision.

    # Assume `memory_scores` is a numpy array of shape `bins_remain_cap.shape`
    # where `memory_scores[i]` represents how "good" bin `i` has been historically
    # for items of similar size. A higher score means it was a good fit.
    # For this function, we'll simulate it.
    # Let's assume a global state or pass it as an argument in a real scenario.
    # For this example, we'll just generate a placeholder.
    # A real implementation would involve a dictionary or a more complex data structure
    # to store scores based on item sizes.

    # Placeholder for adaptive exploration score. In a real system, this would
    # be derived from past packing outcomes.
    # For example, if we sorted bins by their current `exploitation_scores`,
    # we might have a `past_performance` array for these bins.
    # We'll assume a slight bias towards bins that were good in the past.

    # Simulate a hypothetical past performance score for the valid bins
    # Higher means historically good for similar items
    simulated_past_performance = np.random.rand(len(valid_bins_capacities)) * 0.2 # Small random contribution

    # Combine exploitation score with a scaled adaptive exploration score.
    # We add a small random noise to the exploitation scores to break ties and
    # introduce some exploration-like behavior naturally.
    noise_level = 0.01
    final_scores = exploitation_scores + (simulated_past_performance * noise_level)

    priorities[valid_bins_indices] = final_scores

    return priorities
```
