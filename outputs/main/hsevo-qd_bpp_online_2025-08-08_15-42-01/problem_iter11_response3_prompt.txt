{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines FFD-inspired tight fitting with an epsilon-greedy exploration strategy\n    to balance exploitation of good fits and discovery of potentially better packings.\n    \"\"\"\n    epsilon = 0.1\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n    \n    if np.sum(can_fit_mask) == 0:\n        return priorities\n\n    # Exploitation: Prioritize bins with least remaining capacity after fitting (tight fit)\n    # Add a small bonus for perfect fits, similar to FFD's goal of minimizing waste.\n    tight_fit_scores = -(valid_bins_capacities - item)\n    perfect_fit_bonus = 1e-6 # Small bonus for bins that will be exactly filled\n    tight_fit_scores[valid_bins_capacities - item < 1e-9] += perfect_fit_bonus\n\n    # Exploration: Random scores for a subset of valid bins to explore options\n    exploration_scores = np.random.rand(len(valid_bins_capacities))\n\n    # Combine exploitation and exploration using epsilon-greedy\n    use_exploration = np.random.rand(len(valid_bins_capacities)) < epsilon\n    combined_scores = np.where(use_exploration, exploration_scores, tight_fit_scores)\n\n    priorities[can_fit_mask] = combined_scores\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins by combining tight fitting with a penalty for large surpluses\n    and a bonus for perfect fits, with guided exploration.\n    \"\"\"\n    epsilon = 0.08  # Exploration probability\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    valid_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n\n    # Calculate remaining capacity after fitting the item\n    remaining_after_fit = valid_bins_capacities - item\n\n    # Score 1: Tight Fit - Maximize negative remaining capacity (prioritize minimal remainder)\n    tight_fit_scores = -remaining_after_fit\n\n    # Score 2: Perfect Fit Bonus - Add a bonus for exact fits\n    perfect_fit_bonus = 0.15\n    tight_fit_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus\n\n    # Score 3: Surplus Penalty - Mild penalty for bins that would have a large surplus\n    # Scaled by item size to make it relative to the item being packed.\n    large_remainder_penalty_factor = 0.002\n    surplus_penalty = (remaining_after_fit / item) * large_remainder_penalty_factor\n    tight_fit_scores -= surplus_penalty\n\n    # Guided Exploration:\n    # Introduce randomness to a subset of \"good enough\" bins.\n    # Candidates are the top-fitting bins and those with moderate remaining capacity.\n    \n    sorted_indices_tight = np.argsort(tight_fit_scores)[::-1] # Indices sorted by tight fit score (desc)\n    \n    exploration_candidate_indices_in_valid = []\n    \n    # Select top K% of bins for exploration\n    num_top_candidates = max(1, int(len(valid_bins_capacities) * 0.3))\n    exploration_candidate_indices_in_valid.extend(sorted_indices_tight[:num_top_candidates])\n    \n    # Add bins with moderate remaining capacity (e.g., less than twice the item size, but not too small)\n    moderate_capacity_threshold_upper = np.median(valid_bins_capacities) * 1.5 if len(valid_bins_capacities) > 0 else float('inf')\n    moderate_capacity_threshold_lower = item * 1.1 # Avoid bins that are only slightly larger than item\n    \n    moderate_capacity_mask_in_valid = (remaining_after_fit > (item * 0.1)) & \\\n                                      (remaining_after_fit < moderate_capacity_threshold_upper)\n    \n    moderate_capacity_indices_in_valid = np.where(moderate_capacity_mask_in_valid)[0]\n    exploration_candidate_indices_in_valid.extend(moderate_capacity_indices_in_valid)\n    \n    # Remove duplicates and ensure indices are within bounds\n    exploration_candidate_indices_in_valid = np.unique(exploration_candidate_indices_in_valid)\n    exploration_candidate_indices_in_valid = exploration_candidate_indices_in_valid[\n        exploration_candidate_indices_in_valid < len(valid_bins_capacities)\n    ]\n\n    # Generate exploration scores (small random noise)\n    exploration_scores = np.random.rand(len(valid_bins_capacities)) * 0.02\n\n    # Combine scores: use exploration score for candidates with probability epsilon, otherwise tight fit score.\n    # For non-candidates, always use the tight fit score.\n    \n    final_scores = np.copy(tight_fit_scores)\n    \n    # Create a mask for the candidate bins within the valid set\n    is_candidate_mask_in_valid = np.zeros(len(valid_bins_capacities), dtype=bool)\n    is_candidate_mask_in_valid[exploration_candidate_indices_in_valid] = True\n    \n    # Decide probabilistically whether to use exploration score for candidates\n    use_exploration_for_candidates = np.random.rand(len(valid_bins_capacities)) < epsilon\n    \n    # Apply exploration scores to candidates if chosen\n    explore_mask_combined = is_candidate_mask_in_valid & use_exploration_for_candidates\n    final_scores[explore_mask_combined] = exploration_scores[explore_mask_combined]\n\n    # Assign the final scores to the priorities array\n    priorities[valid_bins_indices] = final_scores\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Best) vs. Heuristic 2 (Worst in this comparison): Both heuristics implement a multi-objective scoring system with exploration. Heuristic 1 is marginally better as it defines exploration candidates based on a combination of top scores and percentile-based moderate capacity, making its exploration more guided. Heuristic 2's exploration candidate selection is identical.\n\nComparing Heuristic 1 vs. Heuristic 3: Heuristic 1 uses a more sophisticated multi-objective approach (tightness, waste, future capacity) compared to Heuristic 3's simple tight fit with a perfect fit bonus and basic epsilon-greedy exploration. Heuristic 1's guided exploration is also more nuanced than Heuristic 3's random assignment.\n\nComparing Heuristic 3 vs. Heuristic 5: Heuristic 3 combines tight fitting with random exploration (epsilon-greedy), while Heuristic 5 focuses purely on tight fitting with a perfect fit bonus. Heuristic 3's exploration component, though basic, offers more potential for finding diverse solutions than Heuristic 5's deterministic approach.\n\nComparing Heuristic 5 vs. Heuristic 7: These heuristics are identical, both focusing on tight fitting with a perfect fit bonus.\n\nComparing Heuristic 8 vs. Heuristic 12: Heuristic 8 employs a more refined strategy, balancing tight fitting, perfect fit bonuses, and penalties for large remainders. Heuristic 12 uses a simple inverse capacity for scoring and a binary perfect fit bonus. Heuristic 8's more nuanced scoring and penalty system likely leads to better packing.\n\nComparing Heuristic 12 vs. Heuristic 15: Both use a simple approach where capacity dictates priority. Heuristic 12 assigns a value of 1.0 for perfect fits and `1.0 / remaining_capacity` otherwise, while Heuristic 15 assigns a random value to fitting bins. Heuristic 12's deterministic scoring for good fits is generally more desirable than random assignment.\n\nComparing Heuristic 14 vs. Heuristic 17: Heuristic 14 implements a multi-objective scoring system (tightest fit, future utility, awkward empty penalty) with a guided exploration strategy. Heuristic 17 uses similar concepts but with different weighting and thresholds, and its parameters are tuned. Without knowing the exact performance impact of the specific parameter values in Heuristic 17, it's difficult to definitively rank them, but Heuristic 14's systematic approach to multi-objective scoring and guided exploration makes it a strong contender.\n\nOverall: Heuristics that combine a primary objective (like tight fitting) with secondary objectives (like waste avoidance, future utility) and employ guided exploration strategies (rather than pure random exploration) tend to perform better. The inclusion of specific bonuses for perfect fits and penalties for undesirable states (e.g., large surpluses) also improves heuristic design. Simple random or worst-fit strategies are generally the least effective.\n- \nHere's a redefined approach to self-reflection for designing better optimization heuristics:\n\n*   **Keywords:** Adaptive, multi-objective, guided exploration, performance feedback.\n*   **Advice:** Focus on heuristics that learn from past placements and dynamically adjust their strategy. Integrate feedback mechanisms to refine scoring and exploration parameters based on actual packing outcomes.\n*   **Avoid:** Static rules, brute-force random sampling, or heuristics that don't adapt to problem instance characteristics.\n*   **Explanation:** True self-reflection involves understanding *why* a heuristic performs well or poorly on specific instances, leading to more intelligent adaptation rather than just applying predefined complex rules.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}