{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A more adaptive and multi-objective priority function for online Bin Packing.\n    It considers:\n    1. Tightest fit (minimizing remaining capacity).\n    2. Perfect fit bonus.\n    3. Bin utilization efficiency (how much of the bin is used by the current item).\n    4. A penalty for bins that are too empty relative to the item size.\n    5. Adaptive exploration: prioritizes bins that have previously been \"good\" for items\n       of similar size, guided by a decaying memory of past performance.\n    \"\"\"\n\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n    valid_bins_indices = np.where(can_fit_mask)[0]\n\n    # --- Core Scoring Components ---\n\n    # 1. Tightest Fit: Maximize the negative difference (remaining capacity after fit)\n    remaining_after_fit = valid_bins_capacities - item\n    tightest_fit_score = -remaining_after_fit\n\n    # 2. Perfect Fit Bonus\n    perfect_fit_bonus = 1000.0\n    perfect_fit_mask = np.abs(remaining_after_fit) < 1e-9\n    exploitation_scores = tightest_fit_score\n    exploitation_scores[perfect_fit_mask] += perfect_fit_bonus\n\n    # 3. Bin Utilization Efficiency: Reward bins that are well-utilized by the current item.\n    # This prevents picking a very large bin for a small item if a tighter fit exists.\n    # Score is proportional to item_size / bin_capacity.\n    utilization_score = item / (bins_remain_cap[can_fit_mask] + 1e-9) # Add epsilon to avoid division by zero\n    utilization_score_weight = 0.5 # Weight for utilization score\n    exploitation_scores += utilization_score * utilization_score_weight\n\n    # 4. Penalty for overly empty bins (relative to item size):\n    # Avoid bins where the item would occupy a very small fraction of its capacity.\n    # This is an inverse of utilization for very small items.\n    overly_empty_penalty_threshold = 0.1 # If remaining capacity > 10% of bin capacity, apply penalty\n    overly_empty_penalty_factor = 0.8  # Penalty strength\n\n    # Calculate penalty based on remaining capacity relative to the *original* bin capacity.\n    # We want to penalize bins that are large and leave a lot of space *after* the item is placed.\n    # A bin that is already almost full and has little remaining capacity after fitting is good.\n    # We are penalizing bins that are very large and the item is small relative to them.\n    # Here, we look at the residual capacity *after* fitting the item, relative to the *original* bin capacity.\n    # If residual_capacity / original_bin_capacity is large, it means the bin was much larger than needed.\n    overly_empty_mask = (remaining_after_fit / (valid_bins_capacities + 1e-9)) > overly_empty_penalty_threshold\n    overly_empty_penalty = (remaining_after_fit / (valid_bins_capacities + 1e-9)) * overly_empty_penalty_factor\n    exploitation_scores[overly_empty_mask] -= overly_empty_penalty[overly_empty_mask]\n\n\n    # --- Adaptive Exploration Component (Decaying Memory) ---\n    # This part requires state (memory of past performance).\n    # For demonstration, we'll simulate a simple memory. In a real system,\n    # this memory would be updated after each packing decision.\n\n    # Assume `memory_scores` is a numpy array of shape `bins_remain_cap.shape`\n    # where `memory_scores[i]` represents how \"good\" bin `i` has been historically\n    # for items of similar size. A higher score means it was a good fit.\n    # For this function, we'll simulate it.\n    # Let's assume a global state or pass it as an argument in a real scenario.\n    # For this example, we'll just generate a placeholder.\n    # A real implementation would involve a dictionary or a more complex data structure\n    # to store scores based on item sizes.\n\n    # Placeholder for adaptive exploration score. In a real system, this would\n    # be derived from past packing outcomes.\n    # For example, if we sorted bins by their current `exploitation_scores`,\n    # we might have a `past_performance` array for these bins.\n    # We'll assume a slight bias towards bins that were good in the past.\n\n    # Simulate a hypothetical past performance score for the valid bins\n    # Higher means historically good for similar items\n    simulated_past_performance = np.random.rand(len(valid_bins_capacities)) * 0.2 # Small random contribution\n\n    # Combine exploitation score with a scaled adaptive exploration score.\n    # We add a small random noise to the exploitation scores to break ties and\n    # introduce some exploration-like behavior naturally.\n    noise_level = 0.01\n    final_scores = exploitation_scores + (simulated_past_performance * noise_level)\n\n    priorities[valid_bins_indices] = final_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A multi-objective priority function for online Bin Packing.\n    It considers bin tightness, potential for future packing (based on remaining capacity distribution),\n    and introduces an adaptive exploration mechanism favoring bins that are not excessively full or empty.\n    \"\"\"\n    \n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    \n    # Mask for bins that can fit the current item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n    valid_bins_indices = np.where(can_fit_mask)[0]\n    \n    # --- Objective 1: Tightest Fit (Exploitation) ---\n    # Minimize remaining capacity after packing the item.\n    remaining_after_fit = valid_bins_capacities - item\n    tightness_score = -remaining_after_fit  # Higher score for smaller remaining capacity\n\n    # --- Objective 2: Future Usability (Guided Exploration) ---\n    # Favor bins that, after packing, still have a \"useful\" amount of remaining capacity.\n    # This is relative to the item size itself, aiming to leave space that could accommodate\n    # future items of moderate size. Avoid bins that become too empty.\n    \n    # Define \"useful\" range: between a small fraction and a moderate fraction of the item size.\n    min_useful_surplus_ratio = 0.2 # e.g., at least 20% of item size left\n    max_useful_surplus_ratio = 1.0 # e.g., at most 100% of item size left\n\n    # Calculate surplus relative to item size for bins that are not perfect fits\n    surplus_relative_to_item = np.where(remaining_after_fit > 1e-9, remaining_after_fit / item, 0)\n\n    # Create a score that rewards fitting within the useful surplus range\n    future_usability_score = np.zeros_like(valid_bins_capacities)\n    \n    # Reward bins that leave a moderate surplus\n    moderate_surplus_mask = (surplus_relative_to_item >= min_useful_surplus_ratio) & \\\n                            (surplus_relative_to_item <= max_useful_surplus_ratio)\n    future_usability_score[moderate_surplus_mask] = 1.0 # Base reward for \"good\" surplus\n    \n    # Add a bonus for perfect fits (zero remaining capacity) as they are optimally exploited.\n    perfect_fit_mask = np.abs(remaining_after_fit) < 1e-9\n    future_usability_score[perfect_fit_mask] = 1.5 # Higher reward for perfect fits\n    \n    # Penalize bins that become excessively empty (surplus > max_useful_surplus_ratio)\n    excessively_empty_mask = surplus_relative_to_item > max_useful_surplus_ratio\n    future_usability_score[excessively_empty_mask] = -0.5 # Penalty for leaving too much space\n\n    # --- Objective 3: Adaptive Exploration ---\n    # Introduce a small exploration component. Instead of pure random,\n    # explore among bins that are good candidates based on the other objectives.\n    # We'll use a probability to switch from a combined score to an exploration score.\n    exploration_probability = 0.1 # 10% chance to use exploration score for a candidate\n    \n    # Define candidates for exploration: bins with good tightness or good future usability.\n    # A simple thresholding based on combined scores before adding exploration noise.\n    # Let's combine tightness and usability for initial candidate selection.\n    # Normalize scores to be in a similar range if needed, or use weighted sum.\n    # For simplicity, let's consider bins that are among the top percentile for either metric.\n    \n    # Rank bins by tightness and future usability\n    sorted_indices_tightness = np.argsort(tightness_score)[::-1]\n    sorted_indices_usability = np.argsort(future_usability_score)[::-1]\n    \n    num_candidates = max(1, int(len(valid_bins_capacities) * 0.25)) # Top 25% of bins for consideration\n    \n    exploration_candidate_mask = np.zeros_like(valid_bins_capacities, dtype=bool)\n    exploration_candidate_mask[sorted_indices_tightness[:num_candidates]] = True\n    exploration_candidate_mask[sorted_indices_usability[:num_candidates]] = True\n    \n    # Generate exploration scores for candidates (small random values to break ties or explore)\n    exploration_scores_for_candidates = np.random.rand(len(valid_bins_capacities)) * 0.05\n    \n    # --- Combining Objectives ---\n    # Weighted sum of exploitation (tightness) and guided exploration (future usability).\n    # We add a slight bias to tightness.\n    weight_tightness = 0.7\n    weight_usability = 0.3\n    \n    combined_exploitation_score = (weight_tightness * tightness_score) + (weight_usability * future_usability_score)\n    \n    # Apply exploration probabilistically\n    final_scores = np.copy(combined_exploitation_score)\n    \n    # Decide for each bin whether to potentially use exploration score\n    use_exploration_roll = np.random.rand(len(valid_bins_capacities)) < exploration_probability\n    \n    # Apply exploration score ONLY to candidates that are selected for exploration AND the roll succeeds\n    apply_exploration_mask = exploration_candidate_mask & use_exploration_roll\n    \n    final_scores[apply_exploration_mask] = exploration_scores_for_candidates[apply_exploration_mask]\n    \n    # Assign the calculated scores back to the original priority array\n    priorities[valid_bins_indices] = final_scores\n    \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Best) vs Heuristic 2 (Second Best): They are identical.\nComparing Heuristic 1 vs Heuristic 3: They are identical.\nComparing Heuristic 1 vs Heuristic 4: Heuristic 1 introduces a hybrid approach with exploration (epsilon probability) and guided candidate selection, whereas Heuristic 4 is purely deterministic best-fit with a penalty for large remainders. Heuristic 1's approach is more sophisticated in balancing immediate needs with future possibilities.\nComparing Heuristic 1 vs Heuristic 5: Heuristic 1 uses a probability-based exploration with candidate selection, while Heuristic 5 attempts to integrate exploration by preferring bins with more remaining capacity, but without a clear probabilistic mechanism. Heuristic 1's explicit exploration is likely more effective.\nComparing Heuristic 1 vs Heuristic 6: Heuristic 1 is a hybrid of tightest fit with exploration. Heuristic 6 is multi-objective, incorporating utilization and adaptive exploration (though the adaptive part is simulated). Heuristic 6 attempts a more holistic approach by considering bin utilization.\nComparing Heuristic 1 vs Heuristic 7: Heuristic 1 is a simpler hybrid. Heuristic 7 builds on multi-objective scoring, adaptive exploration probability, and identifies candidates based on both tightness and moderate capacity, making it more nuanced than Heuristic 1.\nComparing Heuristic 7 vs Heuristic 8: Heuristic 8 builds on Heuristic 7's multi-objective scoring but refines it with better tie-breaking and exploration based on candidate selection and perturbations. Heuristic 8 seems to have a more structured approach to balancing objectives.\nComparing Heuristic 8 vs Heuristic 9: Heuristic 8 is a complex multi-objective heuristic with exploration. Heuristic 9 is a very simple heuristic that prioritizes bins with small remaining capacity (inverse of remaining capacity) and gives a bonus to perfect fits. Heuristic 8 is significantly more advanced.\nComparing Heuristic 9 vs Heuristic 10: Heuristics 9 and 10 are almost identical, with Heuristic 9 having a slight preference for perfect fits (score of 1.0 vs inverse of remainder) and Heuristic 10 purely using inverse of remainder. Both are simple \"best-fit\" variations.\nComparing Heuristic 10 vs Heuristic 11: Heuristic 10 is a simple inverse remainder score. Heuristic 11 is also best-fit focused but adds a tie-breaker favoring larger original capacity and a specific score for perfect fits. Heuristic 11 is more refined for tie-breaking.\nComparing Heuristic 11 vs Heuristic 12: Heuristic 11 is a best-fit with tie-breaking. Heuristic 12 introduces several tunable parameters for exploration probability, bonuses, penalties, and candidate selection, indicating a more experimental and potentially optimized approach to balancing objectives.\nComparing Heuristic 12 vs Heuristic 13: Heuristic 12 is a complex multi-objective heuristic. Heuristic 13 is a \"Random Fit\" strategy, assigning random priorities to bins that can fit the item. This is a very basic approach compared to Heuristic 12.\nComparing Heuristic 13 vs Heuristic 14: Heuristics 13 and 14 are identical \"Random Fit\" strategies.\nComparing Heuristic 14 vs Heuristic 15: Heuristic 14 is random. Heuristic 15 is a complex multi-objective heuristic with adaptive exploration based on item size variance and capacity utilization gradient, significantly more sophisticated than random.\nComparing Heuristic 15 vs Heuristic 16: Heuristics 15 and 16 are identical.\nComparing Heuristic 16 vs Heuristic 17: Heuristic 16/15 is multi-objective with adaptive exploration based on variance and utilization gradient. Heuristic 17 is also multi-objective, focusing on tightness, future usability (relative to item size), and adaptive exploration for candidates. Heuristic 16/15 seems to have a more defined adaptive exploration mechanism.\nComparing Heuristic 17 vs Heuristic 18: Heuristics 17 and 18 are identical.\nComparing Heuristic 18 vs Heuristic 19: Heuristic 18 is multi-objective with adaptive exploration. Heuristic 19 combines tightness, waste avoidance, future utility, and guided exploration with perturbated scores for candidates. Heuristic 19's exploration is more about perturbing scores of selected candidates.\nComparing Heuristic 19 vs Heuristic 20: Heuristics 19 and 20 are identical.\nOverall: The top heuristics (1-8, 15-18) are complex multi-objective strategies that balance tightest fit with some form of future utility or guided exploration. Heuristics 9-11 and 13-14 are simpler best-fit or random strategies. The intermediate heuristics (12, 19-20) attempt variations on multi-objective and exploration. Heuristics 1, 7, 8, 15, 16, 17, 18 appear to represent the most developed ideas, blending multiple objectives and adaptive/guided exploration.\n- \nHere's a redefinition of \"Current self-reflection\" to guide heuristic design, avoiding ineffective approaches:\n\n*   **Keywords:** Multi-objective, adaptive exploration, sophisticated scoring, penalized residuals, rewarded fits.\n*   **Advice:** Design heuristics that dynamically balance multiple objectives (e.g., tightness, future utility, waste) using adaptive exploration strategies that sample promising candidates rather than relying on pure randomness.\n*   **Avoid:** Overly simplistic strategies like pure Best Fit or random assignments. Also avoid neglecting the trade-off between exploration and exploitation.\n*   **Explanation:** Complex, multi-objective heuristics with nuanced scoring (e.g., softmax, explicit penalties/bonuses) and guided exploration are essential for outperforming simpler methods, especially in complex packing problems.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}