```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Calculates priority for each bin using a sigmoid-based heuristic
    tailored for the online bin packing problem.

    The heuristic favors bins that can accommodate the item with minimal
    remaining space after packing, as this promotes tighter packing.
    A sigmoid function is used to smooth the priority scores, ensuring
    that bins with slightly better fits don't disproportionately dominate.
    The sigmoid's steepness is adjusted by a factor 'k' to control sensitivity
    to the difference between item size and bin remaining capacity.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array representing the remaining capacity of each bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        is the priority score for packing the item into the corresponding bin.
    """
    k = 5.0  # Steepness parameter for the sigmoid function
    available_bins_mask = bins_remain_cap >= item
    
    if not np.any(available_bins_mask):
        return np.zeros_like(bins_remain_cap)

    # Calculate a value that represents how "good" the fit is.
    # Smaller remaining capacity after packing is generally better.
    # We invert and scale to get a positive value where larger is better.
    # For bins that cannot fit the item, we assign a very low score.
    fit_values = np.zeros_like(bins_remain_cap)
    
    for i in range(len(bins_remain_cap)):
        if bins_remain_cap[i] >= item:
            fit_values[i] = bins_remain_cap[i] - item
        else:
            fit_values[i] = np.inf # Effectively exclude bins that can't fit

    # Use sigmoid to transform fit_values.
    # We want smaller `fit_values` (tighter fit) to result in higher priority.
    # Sigmoid(x) = 1 / (1 + exp(-k*x))
    # If x is small (tight fit), 1 + exp(-large_positive) -> small, so sigmoid is close to 1.
    # If x is large (loose fit), 1 + exp(-small_positive) -> large, so sigmoid is close to 0.
    # We need to normalize our fit_values to a suitable range for the sigmoid.
    # A simple approach is to consider the range of possible remaining capacities.
    # However, a more direct approach without knowing max capacity is to scale based on item size.
    # Or, simply use the difference itself, understanding that larger differences
    # will result in lower sigmoid values.
    
    # We'll use the negative of the remaining space to make larger negative values (tighter fit)
    # more significant in the sigmoid.
    
    sigmoid_inputs = -fit_values / item # Normalize by item size for scale invariance

    # Apply sigmoid. Bins that can't fit will have sigmoid_inputs = inf,
    # resulting in sigmoid_inputs = -inf.
    # np.exp(-np.inf) is 0. So, sigmoid(-inf) = 1 / (1 + 0) = 1.
    # This is counterintuitive if we want tighter fits to have higher priority directly.

    # Let's rethink: we want smaller `remaining_space` after packing to yield higher priority.
    # So, if `remaining_space` is `r`, we want a function f(r) where f(small r) is high, f(large r) is low.
    # A standard sigmoid `s(x) = 1 / (1 + exp(-kx))` has `s(large_positive)` near 1 and `s(large_negative)` near 0.
    # If we map `remaining_space` to the input of the sigmoid:
    # We want small `r` to map to large positive `x`. So `x = -k * r + c` or `x = c / r` or similar.
    # Let's try `x = -(r - average_remaining_space)` or `x = -r`.
    # If we use `x = -r`, then small `r` -> large negative `x` -> sigmoid near 0. This is not right.
    
    # The objective is to maximize the tightness of the fit.
    # For bins where item fits: remaining_capacity - item. Smaller is better.
    # Let `space_left_after_packing = bins_remain_cap[i] - item`.
    # We want a high score when `space_left_after_packing` is small.
    # Let's try a logistic function that maps `space_left_after_packing` to a score between 0 and 1,
    # where 0 remaining space gives a score close to 1.
    # `sigmoid(z) = 1 / (1 + exp(-z))`
    # If `z = -k * (space_left_after_packing)`, then:
    # `space_left_after_packing = 0` => `z = 0` => `sigmoid(0) = 0.5`
    # `space_left_after_packing` very small (negative but fitting) => `z` large positive => `sigmoid` near 1.
    # `space_left_after_packing` very large => `z` large negative => `sigmoid` near 0.
    
    # This still implies larger remaining space after packing is better, which is counter-intuitive for BPP.
    
    # Alternative idea: use the sigmoid on the *difference* between the item size and the bin's *original* capacity (if known)
    # or on how much the item "fills" the bin.
    
    # Let's consider the proportion of the bin's *remaining capacity* that the item occupies.
    # `item_fill_ratio = item / bins_remain_cap[i]` (if bins_remain_cap[i] > 0)
    # For bins that cannot fit, this ratio is effectively infinite.
    
    # We want to prioritize bins where the item fills a large *proportion* of the *remaining capacity*.
    # This means `item / bins_remain_cap[i]` should be large.
    # Let's call `x = item / bins_remain_cap[i]`.
    # We want to map `x` to a priority score. A large `x` should give a high priority.
    # `sigmoid(k*x)` would map `large x` to 1.
    # We only consider bins where `bins_remain_cap[i] >= item`.
    
    priorities = np.zeros_like(bins_remain_cap)
    for i in range(len(bins_remain_cap)):
        if bins_remain_cap[i] >= item:
            # Calculate how much of the *remaining* capacity the item takes up.
            # We want to maximize this, so we use a sigmoid with a positive k.
            fill_ratio = item / bins_remain_cap[i]
            # The sigmoid function goes from 0 to 1.
            # We want higher fill_ratio to correspond to higher priority.
            # sigmoid(k * fill_ratio) achieves this.
            # A slightly modified sigmoid `1 / (1 + exp(-k * (fill_ratio - offset)))`
            # can tune the center.
            # Let's use the simple `1 / (1 + exp(-k * fill_ratio))`.
            # A higher fill_ratio (item takes up more of what's left) will give a higher score.
            priorities[i] = 1 / (1 + np.exp(-k * fill_ratio))
        else:
            priorities[i] = 0.0 # Cannot fit, zero priority

    return priorities
```
