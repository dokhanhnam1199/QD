```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines the multi-objective scoring of v0 with the refined tie-breaking
    and perfect-fit bonus of v15. Introduces guided exploration for better balance.
    """
    epsilon = 0.05  # Probability for exploration
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]
    remaining_after_fit = valid_bins_capacities - item

    # --- Multi-objective Scoring (inspired by v0) ---
    # 1. Tightness score: Prioritize bins that leave minimum remaining capacity.
    #    Higher score for smaller remaining_after_fit.
    tightness_score = -remaining_after_fit

    # 2. Waste avoidance score: Penalize bins that would have a large surplus.
    #    This is complementary to tightness. Less impact compared to tightness.
    waste_penalty_factor = 0.005
    waste_avoidance_score = (remaining_after_fit / item) * waste_penalty_factor

    # 3. Future capacity score: Reward bins that still have substantial capacity after packing.
    #    This helps in potentially fitting larger items later. Scaled by max original capacity.
    max_original_cap = np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1.0
    future_capacity_score = remaining_after_fit / max_original_cap

    # Combine objectives with weights. These weights can be tuned.
    weight_tightness = 1.0
    weight_waste = 0.3  # Reduced weight for waste avoidance to emphasize tightness
    weight_future_capacity = 0.2

    combined_scores = (weight_tightness * tightness_score
                       - weight_waste * waste_avoidance_score
                       + weight_future_capacity * future_capacity_score)

    # --- Perfect Fit Bonus and Tie-breaking (inspired by v15) ---
    # Identify perfect fits and assign a very high score to them.
    perfect_fit_mask_in_valid = remaining_after_fit == 0
    perfect_fit_bonus = 1000.0  # High bonus for exact fits

    # For non-perfect fits, use the combined score, but add a tie-breaker
    # that favors bins with larger original capacity if their combined score is similar.
    # We can incorporate the original capacity as a secondary sorting key by adding a scaled value.
    # This is less about a fixed bonus and more about sorting preference for similar scores.
    tie_breaker_scale = 1e-6
    exploitation_scores = combined_scores + (valid_bins_capacities * tie_breaker_scale)
    exploitation_scores[perfect_fit_mask_in_valid] = perfect_fit_bonus # Override with bonus

    # --- Guided Exploration (combining v0 and introducing structure) ---
    # Identify a set of "promising" bins for exploration.
    # These include the top-scoring bins and those with moderate remaining capacity.

    # Sort bins by the exploitation scores to identify top candidates
    sorted_indices_exploitation = np.argsort(exploitation_scores)[::-1]

    # Consider top 20% of bins or at least the top 3 bins for exploration
    num_top_bins = max(3, int(len(valid_bins_capacities) * 0.2))
    top_candidate_indices_in_valid = sorted_indices_exploitation[:num_top_bins]

    # Identify bins with moderate remaining capacity (between Q1 and Q3)
    q1_rem = np.percentile(remaining_after_fit, 25)
    q3_rem = np.percentile(remaining_after_fit, 75)
    moderate_capacity_mask = (remaining_after_fit >= q1_rem) & (remaining_after_fit <= q3_rem)

    # Combine indices for exploration candidates (unique indices)
    all_candidate_indices_in_valid = set(top_candidate_indices_in_valid)
    all_candidate_indices_in_valid.update(np.where(moderate_capacity_mask)[0])
    exploration_candidate_indices_in_valid = list(all_candidate_indices_in_valid)

    # Generate exploration scores for these candidates (small random perturbations)
    # Use Gaussian noise for smoother exploration if needed, but uniform is fine for now.
    exploration_scores_perturbation = np.random.uniform(-0.05, 0.05, size=len(valid_bins_capacities))

    final_scores = np.copy(exploitation_scores)

    # Apply exploration scores with probability epsilon to the identified candidates
    # Create a mask for the identified exploration candidates within the valid bins
    exploration_candidate_mask_in_valid = np.zeros_like(valid_bins_capacities, dtype=bool)
    if exploration_candidate_indices_in_valid:
        exploration_candidate_mask_in_valid[exploration_candidate_indices_in_valid] = True

    # Randomly decide for each candidate if we use the exploration score
    use_exploration_decision = np.random.rand(len(valid_bins_capacities)) < epsilon

    # Apply the exploration scores only to the chosen candidates
    final_scores[exploration_candidate_mask_in_valid & use_exploration_decision] = \
        exploitation_scores[exploration_candidate_mask_in_valid & use_exploration_decision] + \
        exploration_scores_perturbation[exploration_candidate_mask_in_valid & use_exploration_decision]

    priorities[valid_bins_indices] = final_scores

    return priorities
```
