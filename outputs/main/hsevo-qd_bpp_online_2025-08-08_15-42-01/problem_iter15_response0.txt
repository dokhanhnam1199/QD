```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritizes bins using a multi-objective approach considering tightness,
    future item utility, and encouraging balanced bin usage. Employs adaptive
    exploration among promising candidates.
    """

    epsilon = 0.1  # Probability of exploration
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # --- Multi-Objective Scoring ---
    # 1. Tightness Score: Prioritize bins that leave minimal remaining capacity after packing.
    #    A smaller remaining capacity is better.
    remaining_after_fit = valid_bins_capacities - item
    tightness_scores = -remaining_after_fit

    # 2. Perfect Fit Bonus: High bonus for bins that are perfectly filled.
    perfect_fit_bonus = 500.0
    tightness_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus

    # 3. Future Utility Score: Reward bins with moderate remaining capacity that
    #    could be useful for subsequent items without being overly wasteful.
    #    Bins that are "just right" for potential future items are preferred.
    #    We use a Gaussian-like function centered around a "good" remaining capacity.
    #    Let's define "good" as a capacity that is a reasonable fraction of the item size,
    #    but not so large it's likely to cause significant waste.
    
    # A capacity between item_size/2 and item_size is often a good target for future items.
    # Let's normalize this to the bin's original capacity.
    
    # Normalize remaining capacity relative to the bin's original capacity to get a usage ratio.
    # A usage ratio close to 1 is good, but we want to consider the item size too.
    
    # Let's try a score that rewards remaining capacity that is "just enough" for a potential future item.
    # A common strategy is to consider remaining capacity that could fit at least half of the current item.
    # So, remaining capacity between item/2 and item is good.
    
    # Normalize remaining capacity to a [0, 1] scale based on item size.
    # If remaining_after_fit is R, and item is I:
    # Score for remaining capacity: exp(-(R - I/2)^2 / (sigma^2))
    # where sigma controls the width of the "good" range.
    
    sigma_utility = item * 0.5  # Standard deviation for utility score
    # Ensure sigma_utility is not zero to avoid division by zero.
    sigma_utility = max(sigma_utility, 1e-6) 
    
    utility_scores = np.exp(- (remaining_after_fit - item * 0.5)**2 / (2 * sigma_utility**2))
    
    # Scale utility scores to be comparable to tightness scores
    utility_scores *= 50.0 # Adjust this multiplier to balance objectives

    # 4. Waste Penalty: Penalize bins that would be left excessively empty.
    #    This encourages using bins more fully when possible.
    #    The penalty is relative to the bin's total capacity.
    max_capacity_for_penalty = 1.0 # Consider bins whose remaining capacity exceeds a fraction of total capacity
    waste_penalty_factor = 0.3
    
    # We need the original capacities of the valid bins to calculate waste penalty.
    # This requires passing original bin capacities, which is not part of the current function signature.
    # For now, we'll use remaining_after_fit relative to item size as a proxy, or assume a default max capacity.
    # Let's assume bins have a capacity of at least 1.0 for relative comparison if original capacity is not available.
    
    # Using remaining capacity relative to item size as a penalty driver:
    # If remaining capacity is > 2 * item, it's likely wasteful.
    wasteful_threshold = item * 1.5
    waste_penalties = np.maximum(0, remaining_after_fit - item * 0.5) # Penalty starts if remaining is > item/2
    waste_penalties[remaining_after_fit <= item * 0.5] = 0 # No penalty if remaining is small

    # Scale penalty to be comparable to other scores and ensure it's negative.
    # Penalty increases with waste, so we subtract it.
    # The penalty is stronger for larger surpluses.
    waste_penalties_scaled = - (waste_penalties / item) * waste_penalty_factor
    
    # Combined Exploitation Score (weighted sum of objectives)
    exploitation_scores = tightness_scores + utility_scores + waste_penalties_scaled

    # --- Adaptive Exploration ---
    # Instead of random exploration, explore among the top-performing bins.
    # The number of candidates to explore is dynamic based on the number of valid bins.
    
    sorted_indices_exploitation = np.argsort(exploitation_scores)[::-1] # Indices sorted by exploitation score (descending)
    
    # Define exploration candidates: Top N bins based on exploitation score.
    # N is a fraction of the number of valid bins, but at least 1.
    num_exploration_candidates = min(len(valid_bins_capacities), max(1, int(len(valid_bins_capacities) * 0.25))) # Top 25%
    
    exploration_candidate_mask_local = np.zeros_like(exploitation_scores, dtype=bool)
    exploration_candidate_mask_local[sorted_indices_exploitation[:num_exploration_candidates]] = True

    # Generate small random noise for exploration to slightly perturb rankings.
    # The magnitude of noise is controlled to ensure it doesn't overpower good exploitation scores.
    exploration_noise = np.random.randn(len(valid_bins_capacities)) * 0.05 # Small standard deviation

    # Create the final priority array:
    # For exploration candidates:
    #   With probability epsilon, use the exploitation score + noise.
    #   With probability (1-epsilon), use the pure exploitation score.
    # For non-candidates: Use the pure exploitation score.

    final_priorities = np.copy(exploitation_scores)
    
    # Determine which candidates will use exploration noise
    use_noise_decision = np.random.rand(len(valid_bins_capacities)) < epsilon
    
    # Apply noise only to exploration candidates where noise is chosen
    apply_noise_mask = exploration_candidate_mask_local & use_noise_decision
    final_priorities[apply_noise_mask] = exploitation_scores[apply_noise_mask] + exploration_noise[apply_noise_mask]

    # Assign the calculated priorities to the original bins_remain_cap array indices
    priorities[valid_bins_indices] = final_priorities
    
    return priorities
```
