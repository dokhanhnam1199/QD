```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tightest fit with a bonus for near-perfect fits and a penalty
    for leaving large residual capacities, guided by adaptive exploration.
    Prioritizes bins that minimize remaining space after packing,
    rewarding exact fits and penalizing excessively large gaps.
    """
    epsilon = 0.05  # Probability of exploration
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    
    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # --- Exploitation Scores ---
    
    # Score 1: Tightest Fit (higher is better)
    # Maximize the usage of bin space, so we want to minimize remaining capacity.
    # Invert the remaining capacity after fitting the item.
    remaining_after_fit = valid_bins_capacities - item
    tightness_score = -remaining_after_fit
    
    # Bonus for perfect fits to strongly incentivize exact matches.
    perfect_fit_bonus = 0.5 
    tightness_score[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus

    # Score 2: Penalty for Large Residuals (lower penalty is better, so we negate it)
    # Discourage leaving very large gaps that might be hard to fill later.
    # Scale the penalty by the original remaining capacity to consider the bin's state.
    # A large ratio (large remaining capacity / item size) is penalized.
    # Using a log scale to moderate the impact of very large ratios.
    large_residual_penalty_factor = 0.02
    # Avoid division by zero or very small numbers when item is large relative to capacity
    ratio = np.where(valid_bins_capacities > 0, valid_bins_capacities / item, 0)
    large_residual_penalty = np.log1p(ratio * 5) * large_residual_penalty_factor # log1p for numerical stability and non-linear penalty
    
    # Combined exploitation score: prioritize tight fits, reward perfect fits, penalize large gaps.
    # Weights are set to emphasize tightness and penalize large gaps.
    combined_exploitation_score = tightness_score - large_residual_penalty

    # --- Guided Exploration ---
    
    # Select candidate bins for exploration:
    # 1. Top 20% of bins based on the combined exploitation score.
    # 2. Bins that have remaining capacity close to the median.
    
    sorted_indices_exploitation = np.argsort(combined_exploitation_score)[::-1]
    num_top_candidates = max(1, int(len(valid_bins_capacities) * 0.20))
    
    exploration_candidate_mask = np.zeros_like(combined_exploitation_score, dtype=bool)
    exploration_candidate_mask[sorted_indices_exploitation[:num_top_candidates]] = True
    
    # Add bins with remaining capacity near the median to explore diverse states.
    sorted_indices_by_remaining = np.argsort(valid_bins_capacities)
    median_idx = len(valid_bins_capacities) // 2
    # Ensure median bin is considered if not already in top candidates
    if median_idx < len(valid_bins_capacities):
      exploration_candidate_mask[sorted_indices_by_remaining[median_idx]] = True
    # Also consider the bin with the smallest remaining capacity as a candidate if it's not already there
    exploration_candidate_mask[sorted_indices_by_remaining[0]] = True

    # Generate exploration noise: Gaussian noise with a small standard deviation.
    exploration_noise = np.random.randn(len(valid_bins_capacities)) * 0.02 # Smaller std dev

    # Apply exploration noise with probability epsilon only to the selected candidate bins.
    should_explore_mask = np.random.rand(len(valid_bins_capacities)) < epsilon
    apply_exploration_mask = exploration_candidate_mask & should_explore_mask
    
    final_scores = np.copy(combined_exploitation_score)
    final_scores[apply_exploration_mask] += exploration_noise[apply_exploration_mask]

    priorities[valid_bins_indices] = final_scores
    
    return priorities
```
