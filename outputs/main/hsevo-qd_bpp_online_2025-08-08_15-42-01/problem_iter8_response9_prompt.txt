{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    epsilon = 0.05  # Slightly reduced exploration probability\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n    valid_bins_indices = np.where(can_fit_mask)[0]\n\n    # Enhanced Exploitation:\n    # 1. Tight fit: Prioritize bins that leave minimum remaining capacity.\n    # 2. Perfect fit bonus: A higher bonus for exact fits to minimize waste.\n    # 3. Surplus penalty: A mild penalty for bins that would have a large surplus\n    #    after packing, as these might be better saved for larger items.\n    \n    remaining_after_fit = valid_bins_capacities - item\n    \n    tight_fit_scores = -remaining_after_fit\n    \n    perfect_fit_bonus = 0.1  # Increased bonus for perfect fits\n    tight_fit_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus\n\n    # A gentle penalty for large remainders, scaled by the item size\n    # to make it more relevant.\n    large_remainder_penalty_factor = 0.001 \n    surplus_penalty = (remaining_after_fit / item) * large_remainder_penalty_factor\n    tight_fit_scores -= surplus_penalty\n    \n    # Adaptive Exploration:\n    # Instead of purely random exploration, we can explore bins that are \"good enough\"\n    # but not necessarily the absolute best (according to tight fit).\n    # This can be done by introducing a small random perturbation to the scores\n    # of a subset of bins, or by giving a chance to bins that are not the tightest.\n    \n    # Let's use a strategy where we explore bins that are among the top K tightest fits,\n    # or bins that have a moderate remaining capacity.\n    \n    # Sort bins by tight fit score to identify top candidates\n    sorted_indices_tight = np.argsort(tight_fit_scores)[::-1]\n    \n    exploration_candidate_mask = np.zeros_like(tight_fit_scores, dtype=bool)\n    \n    # Select a portion of the best fitting bins for potential exploration\n    num_explore_candidates = min(len(valid_bins_capacities), max(1, int(len(valid_bins_capacities) * 0.2)))\n    exploration_candidate_mask[sorted_indices_tight[:num_explore_candidates]] = True\n    \n    # Additionally, include some bins that have a moderate amount of remaining capacity\n    # This might represent bins that are not tightly packed but could be useful later.\n    moderate_capacity_threshold = np.median(valid_bins_capacities)\n    moderate_capacity_mask = (valid_bins_capacities > item) & (valid_bins_capacities < moderate_capacity_threshold * 2) # bins that are not too tight, not too empty\n    exploration_candidate_mask[moderate_capacity_mask] = True\n\n    exploration_scores = np.random.rand(len(valid_bins_capacities)) * 0.01 # Smaller random noise for exploration\n    \n    # Combine: With probability epsilon, choose exploration score for candidate bins,\n    # otherwise use the tight fit score. For non-candidate bins, always use tight fit.\n    \n    use_exploration_for_candidates = np.random.rand(len(valid_bins_capacities)) < epsilon\n    \n    combined_scores = np.copy(tight_fit_scores)\n    \n    # Apply exploration scores only to the identified exploration candidates\n    combined_scores[exploration_candidate_mask & use_exploration_for_candidates] = exploration_scores[exploration_candidate_mask & use_exploration_for_candidates]\n\n    priorities[valid_bins_indices] = combined_scores\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Almost Full Fit: Prioritize bins that will be closest to full after adding the item.\n    # Calculate the remaining capacity after placing the item.\n    potential_remain_cap = bins_remain_cap - item\n\n    # We want bins where potential_remain_cap is as close to zero as possible (but non-negative)\n    # A simple way to achieve this is to maximize the negative of the absolute difference from zero.\n    # However, to encourage fitting rather than just being close, we can also consider\n    # bins that can actually fit the item.\n\n    # Create a mask for bins that can fit the item\n    can_fit_mask = potential_remain_cap >= 0\n\n    # For bins that can fit, calculate a score based on how full they will become.\n    # A higher score means the bin will be closer to full.\n    # We can use -(potential_remain_cap) as a measure of \"fullness\" after packing.\n    # To avoid prioritizing bins that become \"too full\" or negative capacity,\n    # we only consider valid fits.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[can_fit_mask] = -potential_remain_cap[can_fit_mask]\n\n    # We can add a small bonus for fitting the item at all to ensure\n    # that fitting items is generally preferred over not fitting.\n    # However, the negative of remaining capacity already does this indirectly.\n    # A more sophisticated approach might involve considering the original capacity\n    # to prioritize filling larger bins more.\n\n    # For \"Almost Full Fit\", we want to minimize the remaining capacity.\n    # So, we want to maximize the negative of the remaining capacity.\n    # Let's refine this. We want the remaining capacity to be as close to 0 as possible.\n    # The value `potential_remain_cap` represents this.\n    # We want to maximize this value if it's negative (meaning it's a good fit).\n    # Let's re-evaluate. For Almost Full Fit, we want the resulting remaining capacity\n    # to be as small as possible, but still non-negative.\n    # So, we want to maximize `-(potential_remain_cap)` for valid fits.\n\n    # Consider the difference between the bin's original capacity and the item size.\n    # We want to prioritize bins where this difference is minimized, but non-negative.\n    # The `potential_remain_cap` already captures this.\n    # We want the most \"positive\" value of `-(potential_remain_cap)` for bins that fit.\n\n    # Another perspective: prioritize bins that have the *least* remaining capacity *after* the item is placed.\n    # This directly translates to maximizing `-(potential_remain_cap)`.\n\n    # Let's consider a small perturbation or a \"niceness\" factor.\n    # Perhaps bins that are already somewhat full are preferred.\n    # But for \"Almost Full Fit\", the focus is purely on the state *after* packing.\n\n    # We want to maximize the remaining capacity in a way that favors being close to zero.\n    # The score should be higher for bins that result in less remaining capacity.\n    # So, we want to maximize `-(bins_remain_cap - item)` for valid bins.\n    # This is equivalent to maximizing `item - bins_remain_cap`. This isn't quite right.\n\n    # The goal is to make the bin as \"full\" as possible *after* adding the item.\n    # \"Full\" means having small remaining capacity.\n    # So, we want to minimize `potential_remain_cap`.\n    # To turn this into a maximization problem for priority, we can use `-potential_remain_cap`.\n    # We also need to ensure that bins that *cannot* fit the item get a very low priority.\n\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    # Let's refine the \"Almost Full Fit\" idea. We want the bin with the smallest remaining capacity after packing.\n    # This means we want to minimize `bins_remain_cap - item`.\n    # For a priority score (higher is better), we can use the negative of this difference.\n    # So, we want to maximize `-(bins_remain_cap - item)` which is `item - bins_remain_cap`.\n\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] = item - bins_remain_cap[fit_mask]\n\n    # This score will be highest for bins where `bins_remain_cap` is just slightly larger than `item`.\n    # Example: item=5\n    # bin1_rem=6  -> priority = 5 - 6 = -1\n    # bin2_rem=5  -> priority = 5 - 5 = 0\n    # bin3_rem=10 -> priority = 5 - 10 = -5\n    # bin4_rem=3  -> priority = -inf (cannot fit)\n\n    # The highest score is 0, from the bin that becomes exactly full.\n    # This seems correct for \"Almost Full Fit\".\n\n    # Consider a scenario where there are multiple bins that become exactly full.\n    # The current heuristic doesn't differentiate between them.\n    # For this strategy, simply picking any of them is fine.\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1st and 2nd:\n*   **Heuristic 1st** employs a multi-objective scoring system (tightness, waste avoidance, future capacity) and a guided exploration strategy (top 30% scores, moderate capacity bins).\n*   **Heuristic 2nd** focuses on tight fit with a perfect fit bonus and a surplus penalty, using a simpler adaptive exploration (top 20% tightest, moderate capacity). It uses a smaller random noise for exploration.\n*   **Difference:** Heuristic 1st is more complex, with more defined objectives and a more structured exploration. Heuristic 2nd is simpler and more focused on the \"tight fit\" aspect, with less nuanced exploration.\n\nComparing Heuristics 2nd and 3rd:\n*   These two heuristics are identical.\n\nComparing Heuristics 3rd and 4th:\n*   **Heuristic 3rd** uses a combination of tight fit, perfect fit bonus, and surplus penalty, with adaptive exploration based on top tightest fits and moderate capacity.\n*   **Heuristic 4th** is a simpler epsilon-greedy approach combining tight fit (with a perfect fit bonus) and purely random exploration scores. The exploration is applied to *all* valid bins with probability epsilon.\n*   **Difference:** Heuristic 3rd's exploration is \"guided\" to specific candidates, aiming for a more informed exploration. Heuristic 4th's exploration is purely random across all eligible bins. Heuristic 3rd also has a more refined scoring for exploitation.\n\nComparing Heuristics 4th and 5th:\n*   These two heuristics are identical.\n\nComparing Heuristics 5th and 6th:\n*   **Heuristic 5th** is a simple epsilon-greedy combining tight fit and random exploration.\n*   **Heuristic 6th** employs a more complex multi-objective scoring (tightness, space utilization, future suitability) and a guided exploration strategy (top 15% combined score, median remaining capacity, smallest remaining capacity). It uses Gaussian noise for exploration.\n*   **Difference:** Heuristic 6th is significantly more sophisticated in its objective definition and exploration strategy compared to the basic epsilon-greedy of Heuristic 5th. It aims to balance multiple packing goals.\n\nComparing Heuristics 6th and 7th:\n*   **Heuristic 6th** is multi-objective with guided exploration.\n*   **Heuristic 7th** is a single-objective \"tightest fit\" with a perfect fit bonus. It lacks any exploration strategy.\n*   **Difference:** Heuristic 6th is much more advanced due to its multi-objective nature and exploration. Heuristic 7th is a pure exploitation strategy.\n\nComparing Heuristics 7th and 8th:\n*   **Heuristic 7th** focuses solely on minimizing remaining capacity and a bonus for perfect fits.\n*   **Heuristic 8th** combines Best Fit with a penalty for large remaining capacity and a bonus for near-perfect fits. It uses a complex, non-linear scoring function.\n*   **Difference:** Heuristic 8th is more nuanced in its scoring by incorporating penalties and bonuses for specific conditions, whereas Heuristic 7th is simpler and focuses only on the immediate tightest fit.\n\nComparing Heuristics 8th and 9th:\n*   **Heuristic 8th** uses a custom complex score involving scaling and exponentials.\n*   **Heuristic 9th** uses an inverse score with a bonus for perfect fits, and then applies a softmax to normalize scores.\n*   **Difference:** Heuristic 9th's use of softmax can help normalize priorities into a probabilistic-like distribution, which might be useful in some contexts, but the score calculation in Heuristic 8th appears more targeted at specific packing behaviors (penalty for large waste, bonus for near-perfect). Heuristic 8th seems to have a more deliberate design for multiple packing goals.\n\nComparing Heuristics 9th and 10th:\n*   **Heuristic 9th** uses inverse scores with softmax.\n*   **Heuristic 10th** implements \"Almost Full Fit\" by maximizing `item - bins_remain_cap`, which directly prioritizes bins that become exactly full, then those with minimal positive remainder.\n*   **Difference:** Heuristic 10th has a clearer, more direct implementation of \"Almost Full Fit\" by maximizing `item - remaining_capacity`. Heuristic 9th's inverse score is related but less direct, and softmax adds normalization. Heuristic 10th is simpler and more purpose-built for its named strategy.\n\nComparing Heuristics 10th and 11th:\n*   **Heuristic 10th** implements \"Almost Full Fit\" by maximizing `item - bins_remain_cap`.\n*   **Heuristic 11th** implements \"Almost Full Fit\" by maximizing `1 / (bins_remain_cap - item + 1e-9)`.\n*   **Difference:** Both aim for tight fits. Heuristic 11th's inverse score will strongly favor bins that are very close to full, potentially more so than Heuristic 10th's linear approach. Heuristic 10th's direct maximization of `item - remaining_capacity` is simpler to understand and implement for the \"exactly full\" goal.\n\nComparing Heuristics 11th and 12th:\n*   These are functionally identical (both use `1 / (bins_remain_cap - item + 1e-9)` for fitting bins). The only difference is the presence of unused imports in 12th.\n\nComparing Heuristics 12th and 13th:\n*   These are identical.\n\nComparing Heuristics 13th and 14th:\n*   These are identical.\n\nComparing Heuristics 14th and 15th:\n*   **Heuristic 14th** uses `1 / (bins_remain_cap - item + 1e-9)`, with a special case for exact fits (score 1.0).\n*   **Heuristic 15th** uses a more complex scoring: perfect fits get 1000.0, non-perfect fits get `-(remaining_capacity) + (original_capacity / MaxCapacity) * tie_breaker_factor`. It prioritizes perfect fits, then tight fits, and breaks ties using original capacity.\n*   **Difference:** Heuristic 15th is significantly more sophisticated due to its prioritized scoring and tie-breaking mechanism, aiming for a more robust tight-fit strategy. Heuristic 14th is simpler.\n\nComparing Heuristics 15th and 16th:\n*   **Heuristic 15th** is a sophisticated tight-fit strategy with tie-breaking.\n*   **Heuristic 16th** implements a pure \"Random Fit\" strategy, assigning random priorities to any bin that can fit the item.\n*   **Difference:** Heuristic 15th is an exploitation-focused strategy, while Heuristic 16th is a pure exploration strategy. Heuristic 15th is far more intelligent in its bin selection.\n\nComparing Heuristics 16th and 17th:\n*   **Heuristic 16th** is pure random fit.\n*   **Heuristic 17th** is identical to Heuristic 15th.\n*   **Difference:** Heuristic 17th (and 15th) is a sophisticated exploitation strategy, while Heuristic 16th is a random exploration.\n\nComparing Heuristics 17th and 18th:\n*   **Heuristic 17th** (and 15th) is a strong tight-fit strategy with perfect fit bonus and tie-breaking based on original capacity.\n*   **Heuristic 18th** combines Best Fit (inverse scaled remaining capacity), penalty for large waste, and bonus for near-perfect fits using a custom, more complex scoring function.\n*   **Difference:** Heuristic 18th attempts to balance multiple aspects (tightness, waste, near-perfect fits) with a more elaborate scoring mechanism. Heuristic 17th is primarily focused on tightest fit and perfect fits, with a simpler tie-breaker. Heuristic 18th's approach might be more robust across various item/bin size distributions.\n\nComparing Heuristics 18th and 19th:\n*   These two heuristics are identical.\n\nComparing Heuristics 19th and 20th:\n*   **Heuristic 19th** (and 18th) combines Best Fit, waste penalty, and near-perfect bonus with complex scoring.\n*   **Heuristic 20th** implements a pure \"Worst Fit\" strategy, prioritizing bins with the most remaining capacity.\n*   **Difference:** Heuristic 19th is an advanced exploitation strategy focused on tight packing and efficiency, while Heuristic 20th is a simple exploration strategy with a specific (and often sub-optimal for immediate packing) goal.\n\nOverall Ranking Logic:\nThe top heuristics (1st, 6th) introduce multi-objective optimization and sophisticated guided exploration. The next tier (3rd, 15th/17th, 18th/19th) focus on advanced exploitation, balancing tight fits, perfect fits, and sometimes waste penalties. Mid-tier heuristics (2nd, 4th, 10th, 14th) use simpler exploitation strategies like basic tight fit or epsilon-greedy. Lower tiers are pure random (16th) or specific but often suboptimal strategies (20th Worst Fit, 11th/12th/13th basic inverse).\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective, guided exploration, adaptive scoring, explicit penalties/rewards, exploration-exploitation.\n*   **Advice:** Focus on heuristics that dynamically evaluate candidate solutions across multiple criteria (e.g., tightness, future usability) and use intelligent sampling strategies rather than random choices.\n*   **Avoid:** Purely greedy approaches, static scoring, and random exploration that doesn't leverage learned information or problem structure.\n*   **Explanation:** Effective heuristics learn from past performance, balancing exploration of new strategies with exploitation of known good ones. This involves refining evaluation metrics and guiding search towards promising regions of the solution space.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}