{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins using a hybrid approach: tightest fit with perfect fit bonus,\n    and guided exploration favoring promising bins, balancing exploitation and exploration.\"\"\"\n\n    epsilon = 0.05  # Probability of exploration\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n    valid_bins_indices = np.where(can_fit_mask)[0]\n\n    # --- Exploitation Strategy (Based on Heuristic 15th/17th and 18th/19th) ---\n    # Prioritize perfect fits, then tight fits. Add a small bonus for bins\n    # that are not excessively empty after packing.\n    \n    remaining_after_fit = valid_bins_capacities - item\n    \n    # Score for tightest fit: maximize negative remaining capacity\n    exploitation_scores = -remaining_after_fit\n    \n    # Bonus for perfect fits (exactly zero remaining capacity)\n    perfect_fit_bonus = 1000.0  # High bonus for exact matches\n    exploitation_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus\n    \n    # Add a small penalty for bins that would have a very large surplus,\n    # encouraging more efficient use of space for the current item.\n    # Scale penalty by item size and bin capacity to make it relative.\n    large_surplus_threshold_ratio = 0.5 # If remaining capacity is more than 50% of item size\n    large_surplus_penalty_factor = 0.1\n    surplus_penalty_mask = remaining_after_fit > (item * large_surplus_threshold_ratio)\n    exploitation_scores[surplus_penalty_mask] -= (remaining_after_fit[surplus_penalty_mask] / item) * large_surplus_penalty_factor\n\n    # --- Exploration Strategy (Guided by Heuristic 1st/6th) ---\n    # Instead of purely random, explore among the 'good enough' bins.\n    # This involves selecting a subset of bins that are either very good fits\n    # or have moderate remaining capacity (potentially useful for future larger items).\n    \n    sorted_indices_exploitation = np.argsort(exploitation_scores)[::-1] # Indices sorted by exploitation score\n    \n    # Candidate selection for exploration:\n    # 1. Top X% of bins based on exploitation score.\n    # 2. Bins with moderate remaining capacity.\n    exploration_candidate_mask = np.zeros_like(exploitation_scores, dtype=bool)\n    \n    num_candidates_from_top = min(len(valid_bins_capacities), max(1, int(len(valid_bins_capacities) * 0.2))) # Top 20%\n    exploration_candidate_mask[sorted_indices_exploitation[:num_candidates_from_top]] = True\n    \n    # Consider bins that are not too tight, but not too empty.\n    median_capacity = np.median(valid_bins_capacities)\n    moderate_capacity_mask = (remaining_after_fit > item * 0.1) & (remaining_after_fit < median_capacity) # Greater than 10% of item, less than median remaining\n    exploration_candidate_mask[moderate_capacity_mask] = True\n\n    # Generate random scores for exploration candidates\n    exploration_scores = np.random.rand(len(valid_bins_capacities)) * 0.01 # Small random noise\n\n    # --- Combine Exploitation and Exploration ---\n    # With probability epsilon, use exploration score for candidates; otherwise, use exploitation.\n    # For non-candidates, always use exploitation score.\n    \n    combined_priorities = np.copy(exploitation_scores)\n    \n    # Decide for each candidate whether to use exploration score\n    use_exploration_decision = np.random.rand(len(valid_bins_capacities)) < epsilon\n    \n    # Apply exploration scores only to candidates selected for exploration AND where exploration is chosen\n    apply_exploration_mask = exploration_candidate_mask & use_exploration_decision\n    combined_priorities[apply_exploration_mask] = exploration_scores[apply_exploration_mask]\n\n    priorities[valid_bins_indices] = combined_priorities\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a Random Fit strategy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    fitting_bins_indices = np.where(bins_remain_cap >= item)[0]\n    if len(fitting_bins_indices) > 0:\n        priorities[fitting_bins_indices] = np.random.rand(len(fitting_bins_indices))\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Best) vs Heuristic 2 (Second Best): They are identical.\nComparing Heuristic 1 vs Heuristic 3: They are identical.\nComparing Heuristic 1 vs Heuristic 4: Heuristic 1 introduces a hybrid approach with exploration (epsilon probability) and guided candidate selection, whereas Heuristic 4 is purely deterministic best-fit with a penalty for large remainders. Heuristic 1's approach is more sophisticated in balancing immediate needs with future possibilities.\nComparing Heuristic 1 vs Heuristic 5: Heuristic 1 uses a probability-based exploration with candidate selection, while Heuristic 5 attempts to integrate exploration by preferring bins with more remaining capacity, but without a clear probabilistic mechanism. Heuristic 1's explicit exploration is likely more effective.\nComparing Heuristic 1 vs Heuristic 6: Heuristic 1 is a hybrid of tightest fit with exploration. Heuristic 6 is multi-objective, incorporating utilization and adaptive exploration (though the adaptive part is simulated). Heuristic 6 attempts a more holistic approach by considering bin utilization.\nComparing Heuristic 1 vs Heuristic 7: Heuristic 1 is a simpler hybrid. Heuristic 7 builds on multi-objective scoring, adaptive exploration probability, and identifies candidates based on both tightness and moderate capacity, making it more nuanced than Heuristic 1.\nComparing Heuristic 7 vs Heuristic 8: Heuristic 8 builds on Heuristic 7's multi-objective scoring but refines it with better tie-breaking and exploration based on candidate selection and perturbations. Heuristic 8 seems to have a more structured approach to balancing objectives.\nComparing Heuristic 8 vs Heuristic 9: Heuristic 8 is a complex multi-objective heuristic with exploration. Heuristic 9 is a very simple heuristic that prioritizes bins with small remaining capacity (inverse of remaining capacity) and gives a bonus to perfect fits. Heuristic 8 is significantly more advanced.\nComparing Heuristic 9 vs Heuristic 10: Heuristics 9 and 10 are almost identical, with Heuristic 9 having a slight preference for perfect fits (score of 1.0 vs inverse of remainder) and Heuristic 10 purely using inverse of remainder. Both are simple \"best-fit\" variations.\nComparing Heuristic 10 vs Heuristic 11: Heuristic 10 is a simple inverse remainder score. Heuristic 11 is also best-fit focused but adds a tie-breaker favoring larger original capacity and a specific score for perfect fits. Heuristic 11 is more refined for tie-breaking.\nComparing Heuristic 11 vs Heuristic 12: Heuristic 11 is a best-fit with tie-breaking. Heuristic 12 introduces several tunable parameters for exploration probability, bonuses, penalties, and candidate selection, indicating a more experimental and potentially optimized approach to balancing objectives.\nComparing Heuristic 12 vs Heuristic 13: Heuristic 12 is a complex multi-objective heuristic. Heuristic 13 is a \"Random Fit\" strategy, assigning random priorities to bins that can fit the item. This is a very basic approach compared to Heuristic 12.\nComparing Heuristic 13 vs Heuristic 14: Heuristics 13 and 14 are identical \"Random Fit\" strategies.\nComparing Heuristic 14 vs Heuristic 15: Heuristic 14 is random. Heuristic 15 is a complex multi-objective heuristic with adaptive exploration based on item size variance and capacity utilization gradient, significantly more sophisticated than random.\nComparing Heuristic 15 vs Heuristic 16: Heuristics 15 and 16 are identical.\nComparing Heuristic 16 vs Heuristic 17: Heuristic 16/15 is multi-objective with adaptive exploration based on variance and utilization gradient. Heuristic 17 is also multi-objective, focusing on tightness, future usability (relative to item size), and adaptive exploration for candidates. Heuristic 16/15 seems to have a more defined adaptive exploration mechanism.\nComparing Heuristic 17 vs Heuristic 18: Heuristics 17 and 18 are identical.\nComparing Heuristic 18 vs Heuristic 19: Heuristic 18 is multi-objective with adaptive exploration. Heuristic 19 combines tightness, waste avoidance, future utility, and guided exploration with perturbated scores for candidates. Heuristic 19's exploration is more about perturbing scores of selected candidates.\nComparing Heuristic 19 vs Heuristic 20: Heuristics 19 and 20 are identical.\nOverall: The top heuristics (1-8, 15-18) are complex multi-objective strategies that balance tightest fit with some form of future utility or guided exploration. Heuristics 9-11 and 13-14 are simpler best-fit or random strategies. The intermediate heuristics (12, 19-20) attempt variations on multi-objective and exploration. Heuristics 1, 7, 8, 15, 16, 17, 18 appear to represent the most developed ideas, blending multiple objectives and adaptive/guided exploration.\n- \nHere's a redefinition of \"Current self-reflection\" to guide heuristic design, avoiding ineffective approaches:\n\n*   **Keywords:** Multi-objective, adaptive exploration, sophisticated scoring, penalized residuals, rewarded fits.\n*   **Advice:** Design heuristics that dynamically balance multiple objectives (e.g., tightness, future utility, waste) using adaptive exploration strategies that sample promising candidates rather than relying on pure randomness.\n*   **Avoid:** Overly simplistic strategies like pure Best Fit or random assignments. Also avoid neglecting the trade-off between exploration and exploitation.\n*   **Explanation:** Complex, multi-objective heuristics with nuanced scoring (e.g., softmax, explicit penalties/bonuses) and guided exploration are essential for outperforming simpler methods, especially in complex packing problems.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}