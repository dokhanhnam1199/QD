```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    
    epsilon = 0.03  # Slightly reduced exploration probability
    priorities = np.full_like(bins_remain_cap, -np.inf)
    
    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # Multi-objective approach: balance several factors
    # 1. Tightest Fit: Minimize remaining space after packing.
    # 2. Perfect Fit Bonus: High bonus for exact matches.
    # 3. Capacity Utilization: Favor bins that are neither too full nor too empty relative to the item size.
    # 4. Exploration Factor: Introduce controlled randomness to explore less obvious but potentially good options.

    remaining_after_fit = valid_bins_capacities - item
    
    # Objective 1: Tightest Fit Score (maximize negative remaining capacity)
    tightest_fit_scores = -remaining_after_fit

    # Objective 2: Perfect Fit Bonus
    perfect_fit_bonus = 0.2
    tightest_fit_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus

    # Objective 3: Capacity Utilization Score
    # Reward bins that are not too empty (e.g., capacity > item * 1.5)
    # Penalize bins that are very close to full, leaving little room for future items.
    # Normalize by bin capacity to make it less dependent on absolute bin size.
    utilization_scores = np.zeros_like(valid_bins_capacities)
    
    # Penalize large remainders (potential for future larger items)
    # Scale penalty by item size to be relative
    large_remainder_penalty_factor = 0.005
    utilization_scores -= (remaining_after_fit / item) * large_remainder_penalty_factor

    # Reward moderate remaining capacity (good balance)
    moderate_remainder_reward_factor = 0.002
    # Reward bins that have some space but not excessive
    moderate_remainder_threshold_low = item * 1.2
    moderate_remainder_threshold_high = item * 3.0
    
    moderate_mask = (remaining_after_fit > (moderate_remainder_threshold_low - item)) & \
                    (remaining_after_fit < (moderate_remainder_threshold_high - item))
    utilization_scores[moderate_mask] += moderate_remainder_reward_factor * remaining_after_fit[moderate_mask]

    # Combine objectives. Weighting can be tuned.
    # Current weights: Tightest fit dominates, with bonuses/penalties from utilization.
    combined_scores = tightest_fit_scores + utilization_scores
    
    # Adaptive Exploration: Introduce randomness to a subset of bins
    # We want to explore bins that are "good enough" but not necessarily the absolute best.
    # This can be achieved by adding a small random noise to the scores of some bins.
    
    # Identify a set of "promising" bins: those not in the absolute top percentile of tightness,
    # but still good candidates.
    sorted_indices_tight = np.argsort(tightest_fit_scores)[::-1]
    
    exploration_pool_indices = []
    
    # Include top ~20% of tightest fits in the exploration pool
    num_top_tight = max(1, int(len(valid_bins_capacities) * 0.2))
    exploration_pool_indices.extend(sorted_indices_tight[:num_top_tight])

    # Include bins that have a moderate remaining capacity, as these are less explored by tightest-fit
    moderate_capacity_threshold_lower = item * 1.5
    moderate_capacity_threshold_upper = item * 4.0
    moderate_bins_mask = (valid_bins_capacities > moderate_capacity_threshold_lower) & \
                         (valid_bins_capacities < moderate_capacity_threshold_upper)
    
    moderate_bins_indices = np.where(moderate_bins_mask)[0]
    
    # Add a subset of moderate bins to the exploration pool, avoiding duplicates
    current_pool_set = set(exploration_pool_indices)
    for idx in moderate_bins_indices:
        if idx not in current_pool_set:
            exploration_pool_indices.append(idx)
            current_pool_set.add(idx)

    # Ensure we don't explore too many bins; limit exploration pool size
    max_exploration_pool_size = max(1, int(len(valid_bins_capacities) * 0.3))
    if len(exploration_pool_indices) > max_exploration_pool_size:
        exploration_pool_indices = np.random.choice(exploration_pool_indices, max_exploration_pool_size, replace=False).tolist()

    # Generate exploration noise for the selected pool
    exploration_noise = np.random.rand(len(valid_bins_capacities)) * 0.005 # Small noise factor

    # Apply exploration noise with probability epsilon to bins in the exploration pool
    # For bins *not* in the pool, we don't add noise.
    
    exploration_mask = np.zeros_like(valid_bins_capacities, dtype=bool)
    exploration_mask[exploration_pool_indices] = True
    
    should_explore = np.random.rand(len(valid_bins_capacities)) < epsilon
    
    # Apply noise only if the bin is in the pool AND the random check passes
    final_scores = np.copy(combined_scores)
    final_scores[exploration_mask & should_explore] += exploration_noise[exploration_mask & should_explore]

    # Assign final scores to the priority array
    priorities[valid_bins_indices] = final_scores
    
    return priorities
```
