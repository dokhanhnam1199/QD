```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Employs an adaptive priority function that balances the tendency for tight fits
    with a strategic exploration of bins that might lead to better overall packing,
    considering the item's size relative to bin capacity.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf)
    can_fit_mask = bins_remain_cap >= item

    if np.sum(can_fit_mask) == 0:
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # Calculate a "tightness" score: the negative of the remaining capacity after placing the item.
    # Smaller remaining capacity means a tighter fit, thus a higher score (closer to 0).
    tightness_scores = -(valid_bins_capacities - item)

    # Introduce a "utilization potential" score. This score is higher for bins
    # that have a significant amount of remaining capacity but can still fit the item.
    # This encourages using bins that aren't already almost full, potentially saving
    # tighter bins for smaller items later. A simple way to model this is to consider
    # the ratio of remaining capacity to bin capacity (if we knew original bin capacity),
    # but since we only have remaining capacity, we can approximate this by considering
    # how much space is left *after* placing the item. A bin with moderate remaining
    # capacity after fitting might be more flexible than a nearly full bin.
    # We'll use a score that is higher when (valid_bins_capacities - item) is not too small.
    # To avoid division by zero or very small numbers, we can add a small constant.
    # A simple approach: penalize bins that become *very* empty after fitting.
    # This can be done by penalizing large (valid_bins_capacities - item).
    # The score will be a transformation of this difference, e.g., 1 / (1 + difference).
    # Higher values of this indicate more "flexibility" or less "denseness" in the resulting bin.
    # Let's try a score that is higher when the remaining capacity after packing is *not* close to zero.
    # This favors bins where the item takes up a substantial portion of the *remaining* capacity,
    # but not so much that it leaves almost no room.

    # Let's consider the *relative* remaining capacity after fitting: (remaining_cap - item) / remaining_cap
    # Higher values mean more space left relative to the bin's current state.
    # We want to favor bins where this ratio is not too high (i.e., good utilization), but also not too low (i.e., not too tight).
    # Let's try to reward bins that are not almost full, and also not almost empty relative to their current state.
    # A score based on the *inverse* of the remaining capacity *after* fitting might be good.
    # Consider the score `1.0 / (1.0 + (valid_bins_capacities - item))`
    # This gives higher scores to bins with less remaining capacity after packing, encouraging tightness.

    # Let's refine the "utilization potential" idea. Instead of purely random exploration,
    # let's explore bins that are "somewhat" full but not critically so.
    # A heuristic could be to prioritize bins that have remaining capacity between a certain range.
    # Or, give a small boost to bins that aren't the absolute tightest fits, as this might
    # leave better options for future items.

    # We can combine tightness with a penalty for leaving *too much* empty space.
    # Let's use the negative remaining capacity as a base (tighter = better).
    # Then, subtract a penalty proportional to the *excess* capacity left.
    # Excess capacity = (remaining_cap - item)
    # Penalty = alpha * (remaining_cap - item)
    # Total Score = -(remaining_cap - item) - alpha * (remaining_cap - item)
    # This is equivalent to -(1 + alpha) * (remaining_cap - item). This is just a scaled tightness.

    # Let's try a different approach:
    # 1. Tightness score: `-(valid_bins_capacities - item)`
    # 2. Exploration/Flexibility score: A measure of how "good" the remaining space is.
    #    - A bin that becomes almost full (very small `valid_bins_capacities - item`) is good for tightness.
    #    - A bin that becomes moderately full (intermediate `valid_bins_capacities - item`) might be good for flexibility.
    #    - A bin that becomes very empty (large `valid_bins_capacities - item`) is generally bad.

    # Let's create a score that rewards tightness but also gives a slight edge to bins
    # that are not *too* full after placing the item.
    # We can use a quadratic penalty for remaining capacity after packing.
    # `score = -(valid_bins_capacities - item) - weight * (valid_bins_capacities - item)**2`
    # This will heavily penalize large remaining capacities, but also slightly penalize
    # bins that become *extremely* tight, favoring those that leave a small but not negligible amount of space.
    # The weight needs to be tuned.

    # Let's try a simpler, more interpretable approach:
    # Primary objective: Minimize remaining capacity `-(bins_remain_cap - item)`.
    # Secondary objective: If multiple bins offer similar tightness, prefer those that
    # leave a "reasonable" amount of space. This means the remaining capacity after packing
    # should not be too close to zero (perfect fit) nor too large.
    # We can add a bonus to tightness score for bins that are *not* perfect fits.
    # `perfect_fit_penalty = 1e-3` if `valid_bins_capacities - item < 1e-9` else `0`
    # `priority = -(valid_bins_capacities - item) - perfect_fit_penalty`

    # Let's consider the *ratio* of the item size to the current remaining capacity.
    # `item_density = item / valid_bins_capacities`
    # Higher density means the item takes up a larger portion of the bin, which is generally good.
    # We can combine this with the tightness score.

    # Let's try a score that emphasizes minimizing waste, but also explores options that
    # might leave a small buffer for future items without being overly wasteful.
    # Base score: `-(valid_bins_capacities - item)` (favors tightest fits)
    # Adjustment: A slight penalty for *extremely* tight fits.
    # This can be done by adding a small value that increases as `valid_bins_capacities - item` approaches zero.
    # `tightness_boost = 1.0 / (1.0 + (valid_bins_capacities - item))`
    # `priority = -(valid_bins_capacities - item) + tightness_boost * 0.1`

    # Let's combine the "tightness" score with a "balance" score.
    # Tightness score: `-(valid_bins_capacities - item)`
    # Balance score: A score that is high for bins that are not too full and not too empty *after* packing.
    # Let `remaining_after_fit = valid_bins_capacities - item`
    # We want `remaining_after_fit` to be small, but not zero.
    # Consider `1.0 / (1.0 + remaining_after_fit**2)` which peaks when `remaining_after_fit` is 0.
    # Let's try to make it peak at a small positive value, say 1.
    # `balance_score = 1.0 / (1.0 + (remaining_after_fit - 1)**2)`
    # This would favor bins leaving 1 unit of capacity.

    # Let's go back to the idea of adaptive exploration, but tied to the item's size.
    # If the item is large, prioritize tight fits.
    # If the item is small, explore more.

    # New Strategy:
    # 1. Calculate tightness score: `-(valid_bins_capacities - item)`. This is the primary driver.
    # 2. Add an exploration bonus. Instead of random, let's explore bins that are "good" but not necessarily the absolute best.
    #    A bin that leaves a moderate amount of remaining capacity after fitting might be considered "exploratory"
    #    because it's not a perfect/tight fit. We can reward bins where `(valid_bins_capacities - item)` is not
    #    too close to zero, but also not too large.
    #    Let `residual_capacity = valid_bins_capacities - item`.
    #    We want to give a bonus when `residual_capacity` is in a sweet spot, e.g., around `item/2` or some fraction of the original bin capacity.
    #    Since we don't have original bin capacity, let's consider `residual_capacity` relative to the item size.
    #    A bonus for `residual_capacity` in `[item * alpha, item * beta]`.
    #    This is complex to implement with a simple score.

    # Let's try a simpler but effective approach:
    # Prioritize tightest fits.
    # Among bins with similar tightness, prefer those that result in a bin with a "balanced" residual capacity.
    # "Balanced" means not extremely full, not extremely empty relative to the bin's original capacity.
    # Since we don't know original capacity, let's consider `valid_bins_capacities - item` relative to the `item` size.
    # A bin that leaves `item / 2` remaining space might be considered balanced.

    # Let's use a score that is the negative of the remaining capacity after packing,
    # plus a bonus for bins that are not *too* tight.
    # `tightness_score = -(valid_bins_capacities - item)`
    # `exploration_bonus = np.exp(- (valid_bins_capacities - item) / (item + 1e-6) )`
    # This bonus is higher for bins that leave more space relative to the item size.
    # It will decay exponentially as the remaining space gets smaller.

    # Combine: `priority = tightness_score + exploration_bonus * exploration_weight`
    # The `exploration_weight` needs to be tuned. A smaller weight means we lean more towards tightness.

    tightness_score = -(valid_bins_capacities - item)

    # A score that rewards bins that are not perfectly filled, but still utilize the space well.
    # We want to find a balance: avoid extreme waste, but also avoid extreme packing that might
    # leave no room for future items.
    # Let's consider the proportion of *remaining* capacity that the item occupies.
    # `utilization_proportion = item / valid_bins_capacities` (if valid_bins_capacities > 0)
    # Higher proportion is good.
    # Also consider the residual capacity: `residual_capacity = valid_bins_capacities - item`
    # We want `residual_capacity` to be small but not zero.

    # Let's use a score that is `-(remaining_capacity)` and then add a penalty for
    # *extremely* small `remaining_capacity`.
    # `penalty_for_tightness = 0.1 * np.exp(-(valid_bins_capacities - item) / 1e-3)`
    # This penalizes bins that are extremely tight.

    # Consider the item's size relative to the bin's current remaining capacity.
    # A larger `item / valid_bins_capacities` ratio means the item is "making a significant dent".
    # Let `item_occupancy_ratio = item / valid_bins_capacities`

    # Final Approach Idea:
    # Primary score: Minimize remaining capacity `-(valid_bins_capacities - item)`.
    # Secondary score: Add a bonus for bins that leave a "reasonable" amount of space.
    # What is reasonable? Perhaps space that is a fraction of the item's size.
    # Let `residual = valid_bins_capacities - item`.
    # Bonus if `residual` is between `item * 0.1` and `item * 0.5`.
    # A function that peaks in this range. Gaussian-like.
    # `bonus = np.exp(-(residual - (item * 0.3))**2 / (item * 0.2)**2)`
    # This bonus will be higher for bins where the residual capacity is around 30% of the item size.
    # This encourages using bins that are not maximally tight but still efficient.

    residual_capacity = valid_bins_capacities - item
    
    # Base score: Minimize remaining capacity after packing (tightest fit)
    tightness_priority = -residual_capacity

    # Exploration bonus: Reward bins that leave a "balanced" residual capacity.
    # We want the residual capacity to be not too small (avoiding extreme tightness)
    # and not too large (avoiding excessive waste).
    # A sweet spot for residual capacity could be around `item / 2` or `item / 3`.
    # Let's use a Gaussian-like function centered around `item * 0.4` with a certain width.
    # The width should adapt to the item size.
    # A larger item might allow for a larger absolute residual capacity in its sweet spot.
    # Let's try `center = item * 0.4` and `width = item * 0.3` (standard deviation).
    # The bonus will be `exp(-(residual - center)^2 / (2 * width^2))`.

    # To prevent division by zero for very small items, add a small epsilon.
    item_plus_eps = item + 1e-9
    
    center = item_plus_eps * 0.4
    width = item_plus_eps * 0.3
    
    # Ensure width is not too small
    width = max(width, 1e-3)

    # Calculate the exploration bonus. Higher bonus for residuals closer to the 'center'.
    # We use `np.exp` to create a bell curve shape.
    # The division by `2 * width**2` normalizes the exponent.
    exploration_bonus = np.exp(- (residual_capacity - center)**2 / (2 * width**2))

    # Combine the tightness priority with the exploration bonus.
    # The exploration_bonus ranges from 0 to 1. We can scale it.
    # A scaling factor can be used to control the influence of exploration.
    # Let's scale it by a small factor, e.g., 0.5, to ensure tightness remains dominant.
    exploration_weight = 0.5
    
    priorities_for_valid_bins = tightness_priority + exploration_bonus * exploration_weight
    
    priorities[can_fit_mask] = priorities_for_valid_bins

    return priorities
```
