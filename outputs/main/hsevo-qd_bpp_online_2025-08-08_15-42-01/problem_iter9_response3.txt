```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A multi-objective priority function for online bin packing.
    It balances 'tightest fit' with 'future utility' and guided exploration.
    It explicitly rewards bins with high remaining capacity for future items
    and penalizes bins that might become "awkwardly empty" after packing.
    Exploration is focused on bins that are good candidates for either
    tight fit or future utility, with a bias towards the former.
    """
    epsilon = 0.1  # Probability of biased exploration
    priorities = np.full_like(bins_remain_cap, -np.inf)

    can_fit_mask = bins_remain_cap >= item
    valid_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    remaining_after_fit = valid_bins_capacities - item

    # --- Multi-Objective Scoring ---
    # 1. Tightest Fit Score: Maximize -remaining_after_fit. Higher score for less remaining space.
    tightest_fit_scores = -remaining_after_fit

    # 2. Future Utility Score: Maximize remaining capacity. Higher score for more remaining space.
    # This encourages leaving larger bins for potentially larger future items.
    future_utility_scores = remaining_after_fit

    # 3. Perfect Fit Bonus: Add a significant bonus for exact matches.
    perfect_fit_bonus = 1000.0
    tightest_fit_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus
    future_utility_scores[np.abs(remaining_after_fit) < 1e-9] = 0 # No future utility for perfect fit

    # 4. Awkward Empty Penalty: Penalize bins that become "too empty" after packing,
    # relative to the item size. This discourages leaving small unusable remainders.
    # A bin becoming empty by more than twice the item size is penalized.
    awkward_empty_threshold_ratio = 2.0
    awkward_empty_penalty_factor = 0.5
    awkward_mask = remaining_after_fit > (item * awkward_empty_threshold_ratio)
    if np.any(awkward_mask):
        # Penalty is proportional to how much it exceeds the threshold, normalized by item size
        awkward_penalty = (remaining_after_fit[awkward_mask] / item - awkward_empty_threshold_ratio) * awkward_empty_penalty_factor
        tightest_fit_scores[awkward_mask] -= awkward_penalty
        future_utility_scores[awkward_mask] -= awkward_penalty # Penalize future utility as well

    # --- Combined Score ---
    # A weighted sum of tightest fit and future utility.
    # Weights can be adjusted. Here, we give slightly more weight to tight fit.
    tight_fit_weight = 0.6
    future_utility_weight = 0.4
    
    # Normalize scores to prevent one objective from dominating due to scale.
    # Using robust scaling (median and IQR) might be better, but simple min-max is often sufficient.
    # We will normalize within the valid bins only.
    
    min_tf = np.min(tightest_fit_scores)
    max_tf = np.max(tightest_fit_scores)
    range_tf = max_tf - min_tf if max_tf != min_tf else 1.0
    normalized_tight_fit = (tightest_fit_scores - min_tf) / range_tf if range_tf != 0 else np.zeros_like(tightest_fit_scores)

    min_fu = np.min(future_utility_scores)
    max_fu = np.max(future_utility_scores)
    range_fu = max_fu - min_fu if max_fu != min_fu else 1.0
    normalized_future_utility = (future_utility_scores - min_fu) / range_fu if range_fu != 0 else np.zeros_like(future_utility_scores)

    combined_scores = (tight_fit_weight * normalized_tight_fit) + (future_utility_weight * normalized_future_utility)

    # --- Guided Exploration ---
    # Exploration will be applied to a subset of bins that are "promising" based on the combined score.
    # "Promising" bins are those with high combined scores.
    
    sorted_indices_combined = np.argsort(combined_scores)[::-1] # Indices sorted by combined score (descending)

    # Exploration candidates: Top K bins by combined score, plus bins that represent
    # a good compromise (e.g., not perfectly tight, but good future utility, or vice-versa).
    
    exploration_candidate_mask = np.zeros_like(combined_scores, dtype=bool)
    
    # Select top 30% of bins as initial candidates for exploration
    num_top_candidates = min(len(combined_scores), max(1, int(len(combined_scores) * 0.3)))
    exploration_candidate_mask[sorted_indices_combined[:num_top_candidates]] = True

    # Add bins with high future utility but not necessarily top-tier tight fit,
    # as these might be useful for larger items that might come later.
    # Threshold: bins with future utility in the top 50% percentile, but not in the top 20% of combined scores.
    utility_threshold = np.percentile(future_utility_scores, 50)
    high_utility_mask = future_utility_scores >= utility_threshold
    
    # Exclude already selected top candidates to avoid over-representation
    already_selected_mask = exploration_candidate_mask
    potential_explore_candidates = high_utility_mask & ~already_selected_mask
    
    # Add a portion of these high-utility candidates
    num_high_utility_to_add = min(np.sum(potential_explore_candidates), max(0, int(len(combined_scores) * 0.1)))
    
    if num_high_utility_to_add > 0:
        high_utility_indices = np.where(potential_explore_candidates)[0]
        # Randomly select from potential high utility candidates
        selected_high_utility_indices = np.random.choice(high_utility_indices, num_high_utility_to_add, replace=False)
        exploration_candidate_mask[selected_high_utility_indices] = True

    # Generate exploration scores (noisy values for exploration candidates)
    exploration_scores = np.random.rand(len(combined_scores)) * 0.05 # Small random noise

    # --- Decision: Exploit or Explore ---
    # With probability epsilon, choose exploration score for selected candidates.
    # Otherwise, use the combined exploitation score.
    # For bins not selected as candidates, always use the combined score.

    final_priorities_for_valid_bins = np.copy(combined_scores)

    # For candidates, decide whether to explore
    should_explore_mask = np.random.rand(len(combined_scores)) < epsilon
    
    # Apply exploration score ONLY to candidates where exploration is chosen
    apply_exploration_mask = exploration_candidate_mask & should_explore_mask
    
    # Use exploration score for these bins
    final_priorities_for_valid_bins[apply_exploration_mask] = exploration_scores[apply_exploration_mask]

    priorities[valid_bins_indices] = final_priorities_for_valid_bins

    return priorities
```
