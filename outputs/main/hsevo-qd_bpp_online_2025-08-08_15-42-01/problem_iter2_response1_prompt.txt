{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_after_fit = bins_remain_cap[i] - item\n            if remaining_after_fit == 0:\n                priorities[i] = 1.0\n            else:\n                priorities[i] = 1.0 / (remaining_after_fit + 1e-9)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Worst Fit strategy.\n\n    The Worst Fit strategy aims to place the current item into the bin that has the most remaining capacity.\n    This heuristic attempts to keep bins with less capacity available for smaller items later on,\n    potentially leading to a more efficient packing in the long run.\n    In this priority function, we assign a higher priority score to bins with larger remaining capacities.\n    Specifically, the priority is directly proportional to the remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.array([bin_cap if bin_cap >= item else -np.inf for bin_cap in bins_remain_cap])\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1st (Almost Full Fit) vs. Heuristic 16th (Random Fit), the former focuses on a specific fitting strategy (minimizing remaining capacity after placement), while the latter uses random assignment for valid bins. Heuristic 1st is likely better as it's deterministic and aims for efficiency.\n\nComparing Heuristic 2nd (Softmax-Based Fit) vs. Heuristic 11th (Inverse of Remaining Capacity with special case for perfect fit), both aim to prioritize bins with less remaining capacity. Heuristic 2nd uses softmax to normalize these scores into probabilities, which might offer smoother transitions and better exploration of options. Heuristic 11th is simpler but the special case for perfect fit is a good addition.\n\nComparing Heuristic 7th (FFD-inspired with penalty) vs. Heuristic 20th (Worst Fit), Heuristic 7th's approach of prioritizing bins with least remaining capacity is generally preferred in bin packing for tighter fits, whereas Worst Fit prioritizes largest remaining capacity which can lead to fragmentation.\n\nComparing Heuristic 10th and Heuristic 14th (both seem to be identical, \"Best Fit with tie-breaking for perfect fit and worst fit\"), they explicitly handle perfect fits with a bonus and provide a slight bonus for worst fits among available bins, which is more sophisticated than simple inverse remaining capacity.\n\nComparing Heuristic 17th, 18th, and 19th (all identical, Epsilon-Greedy) vs. Heuristic 11th/2nd, the epsilon-greedy approach introduces exploration, which can be beneficial for discovering better packing strategies over time, but it adds complexity and randomness.\n\nOverall: The heuristics that aim for a \"tight fit\" (minimizing remaining capacity after placement), like 1st, 5th, 6th, 7th, 8th, 9th, 10th, 11th, 12th, 13th, 14th, 15th, 17th, 18th, 19th, generally perform better than random or worst-fit strategies. Among these, those with explicit tie-breaking (like 10th/14th) or more nuanced scoring (like softmax in 2nd) show potential for better performance. Epsilon-greedy strategies offer exploration but introduce randomness.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Bin Packing, Tight Packing, Perfect Fits, Exploration, Scoring, Adaptability.\n*   **Advice:** Focus on *maximizing utilization* and *exploring beneficial deviations* from greedy approaches. Quantify the value of \"perfect fits\" and incorporate adaptive scoring.\n*   **Avoid:** Relying solely on simple \"fill first\" logic; ignoring the long-term impact of placement choices; implementing exploration without a clear performance target.\n*   **Explanation:** Current success hinges on packing densely. Effective heuristics should explicitly reward this (e.g., bonus for tight fits) and consider intelligent exploration to find even better packings than pure greedy, rather than random exploration which often degrades performance.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}