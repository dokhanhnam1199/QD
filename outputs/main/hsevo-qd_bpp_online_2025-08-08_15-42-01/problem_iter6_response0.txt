```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    epsilon = 0.03  # Slightly reduced exploration probability
    priorities = np.full_like(bins_remain_cap, -np.inf)
    
    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # Multi-objective approach:
    # 1. Tight fit: Prioritize bins that leave minimum remaining capacity.
    # 2. Perfect fit bonus: A higher bonus for exact fits to minimize waste.
    # 3. Capacity utilization penalty: A penalty for bins that are too full,
    #    making them less suitable for subsequent items. This encourages
    #    leaving some slack.
    # 4. Bin diversity bonus: Reward bins that have not been chosen recently
    #    or that represent a wider range of remaining capacities. This promotes exploration.

    remaining_after_fit = valid_bins_capacities - item
    
    # Score 1: Tight fit (higher is better)
    tight_fit_scores = -remaining_after_fit
    
    # Score 2: Perfect fit bonus (applied to tight fit scores)
    perfect_fit_bonus = 0.2
    tight_fit_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus

    # Score 3: Capacity utilization penalty (lower is better, so we subtract)
    # Penalize bins where remaining capacity is very small relative to bin capacity.
    # Assume bin capacity is implicitly 1 for scoring purposes, or could be a parameter.
    # For simplicity, let's use a relative measure to the item size.
    utilization_penalty_factor = 0.1
    # Penalty is higher if remaining capacity is small compared to item size.
    utilization_penalty = np.clip(remaining_after_fit / item, 0, 1) * utilization_penalty_factor
    tight_fit_scores -= utilization_penalty

    # Score 4: Bin diversity bonus
    # We can introduce a "novelty" score. For simplicity, let's give a small bonus
    # to bins that have a moderate amount of remaining capacity, suggesting they
    # are not overly full or overly empty.
    diversity_bonus_factor = 0.02
    # Bonus for bins that are not too tight and not too empty.
    moderate_capacity_bonus = np.zeros_like(valid_bins_capacities)
    median_capacity = np.median(valid_bins_capacities)
    # Reward bins that are between, say, 50% of median and median capacity
    if median_capacity > 0:
        moderate_capacity_bonus[
            (valid_bins_capacities >= median_capacity * 0.5) &
            (valid_bins_capacities <= median_capacity * 1.5)
        ] += diversity_bonus_factor
    
    combined_scores = tight_fit_scores + moderate_capacity_bonus

    # Guided Exploration:
    # Instead of random exploration, we can explore bins that offer a good balance
    # between exploitation (tight fit) and diversification (moderate capacity).
    # We'll introduce a small random noise and a probability to pick from the
    # "good enough" candidates.
    
    # Identify "good enough" candidates: bins in the top K% of scores or
    # bins that have a certain percentage of remaining capacity relative to bin capacity.
    sorted_indices_overall = np.argsort(combined_scores)[::-1]
    
    exploration_candidate_mask = np.zeros_like(combined_scores, dtype=bool)
    
    # Top 20% of candidates based on combined score
    num_top_candidates = min(len(valid_bins_capacities), max(1, int(len(valid_bins_capacities) * 0.2)))
    exploration_candidate_mask[sorted_indices_overall[:num_top_candidates]] = True
    
    # Also consider bins with remaining capacity that's a significant fraction of the item size
    # to ensure we don't always pick the absolute tightest and might save capacity.
    significant_capacity_threshold = 0.5 # e.g., 50% of item size
    significant_capacity_mask = (remaining_after_fit > item * significant_capacity_threshold)
    exploration_candidate_mask[significant_capacity_mask] = True

    # Exploration scores: Small random noise, slightly biased towards better candidates
    exploration_scores = np.random.rand(len(valid_bins_capacities)) * 0.05 # Base noise

    # Enhance exploration scores for candidates
    exploration_scores[exploration_candidate_mask] += np.random.rand(np.sum(exploration_candidate_mask)) * 0.05

    # Combine: With probability epsilon, choose exploration score for candidate bins,
    # otherwise use the combined score. For non-candidate bins, always use combined score.
    
    use_exploration_for_candidates = np.random.rand(len(valid_bins_capacities)) < epsilon
    
    final_scores = np.copy(combined_scores)
    
    # Apply exploration scores only to the identified exploration candidates if selected
    final_scores[exploration_candidate_mask & use_exploration_for_candidates] = exploration_scores[exploration_candidate_mask & use_exploration_for_candidates]

    priorities[valid_bins_indices] = final_scores
    
    return priorities
```
