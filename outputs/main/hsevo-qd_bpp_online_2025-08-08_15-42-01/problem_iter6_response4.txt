```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    epsilon = 0.03  # Further reduced exploration probability
    priorities = np.full_like(bins_remain_cap, -np.inf)
    
    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # Multi-objective approach: balance several criteria
    # 1. Tightness (minimize remaining capacity)
    # 2. Space Utilization (maximize used capacity)
    # 3. Future Item Suitability (prioritize bins that can fit subsequent items well)

    remaining_after_fit = valid_bins_capacities - item
    
    # Score 1: Tightness (higher is better, i.e., less remaining capacity)
    # Invert the remaining capacity, so smaller positive remaining capacity is better.
    tightness_score = -remaining_after_fit 
    
    # Bonus for perfect fits
    perfect_fit_bonus = 0.2
    tightness_score[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus

    # Score 2: Space Utilization (maximize the use of existing bin capacity)
    # This encourages filling bins more fully, even if not a perfect fit.
    # We consider the *current* remaining capacity as a proxy for how "full" the bin is.
    # Higher remaining capacity means less utilized. So, we want to penalize bins with high remaining capacity.
    # We use the original remaining capacity before fitting the item.
    # Using current remaining capacity as it directly reflects the bin's state.
    space_utilization_score = valid_bins_capacities 
    
    # Score 3: Future Item Suitability (Adaptive Penalty for large remainders)
    # Penalize bins that leave a large residual capacity relative to the bin's current capacity.
    # This encourages leaving "medium-sized" gaps rather than very large ones,
    # which might be better suited for specific intermediate-sized items later.
    # We scale the penalty by the *current* remaining capacity.
    future_suitability_penalty_factor = 0.005
    future_suitability_score = -(valid_bins_capacities / item) * future_suitability_penalty_factor

    # Combine scores with weighted sum. Weights can be tuned.
    # Weight for tightness: emphasizes finding tight fits.
    # Weight for utilization: ensures bins are utilized well.
    # Weight for future suitability: tries to leave useful residual capacities.
    combined_exploitation_score = 1.0 * tightness_score + 0.5 * space_utilization_score + 0.8 * future_suitability_score

    # Guided Exploration:
    # Instead of purely random, we explore bins that are "good enough" or represent diverse states.
    # The exploration should slightly perturb the exploitation scores.
    
    # Define a threshold for "good enough" bins.
    # We consider bins that are in the top X percentile of the combined exploitation score.
    sorted_indices_exploitation = np.argsort(combined_exploitation_score)[::-1]
    
    exploration_candidate_mask = np.zeros_like(combined_exploitation_score, dtype=bool)
    
    # Select a small percentage of the best bins for exploration.
    num_top_candidates = max(1, int(len(valid_bins_capacities) * 0.15))
    exploration_candidate_mask[sorted_indices_exploitation[:num_top_candidates]] = True
    
    # Additionally, include bins that are "average" in terms of remaining capacity.
    # This helps explore bins that are neither too tight nor too empty.
    sorted_indices_by_remaining = np.argsort(valid_bins_capacities)
    median_idx = len(valid_bins_capacities) // 2
    # Include the bin closest to the median remaining capacity.
    exploration_candidate_mask[sorted_indices_by_remaining[median_idx]] = True
    # Include the bin with the smallest remaining capacity (if not already in top candidates)
    exploration_candidate_mask[sorted_indices_by_remaining[0]] = True
    

    exploration_noise = np.random.randn(len(valid_bins_capacities)) * 0.005 # Gaussian noise

    # Apply exploration noise with probability epsilon only to the selected candidate bins
    # The noise is added to the *original* exploitation score for these candidates.
    
    final_scores = np.copy(combined_exploitation_score)
    
    # For candidate bins, with probability epsilon, apply the exploration noise
    # This means we explore the decision for these bins.
    should_explore_mask = np.random.rand(len(valid_bins_capacities)) < epsilon
    
    # We only apply exploration to the candidates that are selected for exploration
    apply_exploration_mask = exploration_candidate_mask & should_explore_mask
    
    final_scores[apply_exploration_mask] = combined_exploitation_score[apply_exploration_mask] + exploration_noise[apply_exploration_mask]

    priorities[valid_bins_indices] = final_scores
    
    return priorities
```
