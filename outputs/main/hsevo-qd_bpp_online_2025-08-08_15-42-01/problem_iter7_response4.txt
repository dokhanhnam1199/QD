import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, 
                  epsilon: float = 0.35236200788813676, 
                  perfect_fit_bonus: float = 0.44800986427627426, 
                  large_remainder_penalty_factor: float = 0.01465531750390482,
                  exploration_top_k_percentage: float = 0.24448299101689563,
                  moderate_capacity_scaling_factor: float = 2.0768430899386012,
                  moderate_capacity_lower_bound_factor: float = 1.8381505293332823,
                  exploration_noise_scale: float = 0.03383793695896974,
                  surplus_tolerance_factor: float = 0.09660354274701338) -> np.ndarray:
    """
    Prioritizes bins by combining tight fitting with a penalty for large surpluses
    and a bonus for perfect fits, with guided exploration.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Mask for bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    valid_bins_indices = np.where(can_fit_mask)[0]

    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]

    # Calculate remaining capacity after fitting the item
    remaining_after_fit = valid_bins_capacities - item

    # Score 1: Tight Fit - Maximize negative remaining capacity (prioritize minimal remainder)
    tight_fit_scores = -remaining_after_fit

    # Score 2: Perfect Fit Bonus - Add a bonus for exact fits
    tight_fit_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus

    # Score 3: Surplus Penalty - Mild penalty for bins that would have a large surplus
    # Scaled by item size to make it relative to the item being packed.
    surplus_penalty = (remaining_after_fit / item) * large_remainder_penalty_factor
    tight_fit_scores -= surplus_penalty

    # Guided Exploration:
    # Introduce randomness to a subset of "good enough" bins.
    # Candidates are the top-fitting bins and those with moderate remaining capacity.
    
    sorted_indices_tight = np.argsort(tight_fit_scores)[::-1] # Indices sorted by tight fit score (desc)
    
    exploration_candidate_indices_in_valid = []
    
    # Select top K% of bins for exploration
    num_top_candidates = max(1, int(len(valid_bins_capacities) * exploration_top_k_percentage))
    exploration_candidate_indices_in_valid.extend(sorted_indices_tight[:num_top_candidates])
    
    # Add bins with moderate remaining capacity (e.g., less than a scaled median capacity, but not too small)
    moderate_capacity_threshold_upper = np.median(valid_bins_capacities) * moderate_capacity_scaling_factor if len(valid_bins_capacities) > 0 else float('inf')
    moderate_capacity_threshold_lower = item * moderate_capacity_lower_bound_factor # Avoid bins that are only slightly larger than item
    
    moderate_capacity_mask_in_valid = (remaining_after_fit > (item * surplus_tolerance_factor)) & \
                                      (remaining_after_fit < moderate_capacity_threshold_upper)
    
    moderate_capacity_indices_in_valid = np.where(moderate_capacity_mask_in_valid)[0]
    exploration_candidate_indices_in_valid.extend(moderate_capacity_indices_in_valid)
    
    # Remove duplicates and ensure indices are within bounds
    exploration_candidate_indices_in_valid = np.unique(exploration_candidate_indices_in_valid)
    exploration_candidate_indices_in_valid = exploration_candidate_indices_in_valid[
        exploration_candidate_indices_in_valid < len(valid_bins_capacities)
    ]

    # Generate exploration scores (small random noise)
    exploration_scores = np.random.rand(len(valid_bins_capacities)) * exploration_noise_scale

    # Combine scores: use exploration score for candidates with probability epsilon, otherwise tight fit score.
    # For non-candidates, always use the tight fit score.
    
    final_scores = np.copy(tight_fit_scores)
    
    # Create a mask for the candidate bins within the valid set
    is_candidate_mask_in_valid = np.zeros(len(valid_bins_capacities), dtype=bool)
    is_candidate_mask_in_valid[exploration_candidate_indices_in_valid] = True
    
    # Decide probabilistically whether to use exploration score for candidates
    use_exploration_for_candidates = np.random.rand(len(valid_bins_capacities)) < epsilon
    
    # Apply exploration scores to candidates if chosen
    explore_mask_combined = is_candidate_mask_in_valid & use_exploration_for_candidates
    final_scores[explore_mask_combined] = exploration_scores[explore_mask_combined]

    # Assign the final scores to the priorities array
    priorities[valid_bins_indices] = final_scores

    return priorities
