{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \n    epsilon = 0.03\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n    valid_bins_indices = np.where(can_fit_mask)[0]\n\n    remaining_after_fit = valid_bins_capacities - item\n    \n    # Multi-objective scoring:\n    # 1. Tightness score: Prioritize bins that leave minimum remaining capacity.\n    # 2. Waste avoidance score: Penalize bins that would have a large surplus.\n    # 3. Future capacity score: Reward bins that still have substantial capacity after packing.\n    \n    tightness_score = -remaining_after_fit\n    \n    # Penalty for large remainders, scaled by item size\n    waste_penalty_factor = 0.005\n    waste_avoidance_score = (remaining_after_fit / item) * waste_penalty_factor\n    \n    # Reward for significant remaining capacity - can be useful for larger items later\n    future_capacity_score = remaining_after_fit / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else np.zeros_like(remaining_after_fit)\n    \n    # Combine objectives with weights. These weights can be tuned.\n    # We want to strongly favor tightness, moderately avoid waste, and lightly favor future capacity.\n    weight_tightness = 1.0\n    weight_waste = 0.5\n    weight_future_capacity = 0.2\n    \n    combined_scores = (weight_tightness * tightness_score - \n                       weight_waste * waste_avoidance_score + \n                       weight_future_capacity * future_capacity_score)\n\n    # Enhanced Exploration:\n    # Instead of random exploration, we can introduce guided exploration.\n    # This means exploring bins that are \"good enough\" but not necessarily the absolute best.\n    # We can define \"good enough\" as bins that fall within a certain percentile of the best fits.\n    \n    # Sort bins by the combined score to identify top candidates\n    sorted_indices_combined = np.argsort(combined_scores)[::-1]\n    \n    exploration_candidate_indices_in_valid = []\n    \n    # Identify a range of bins to consider for exploration\n    # This could be the top K bins, or bins within a certain score range.\n    # Let's consider bins within the top 30% of scores, or at least the top 3 bins.\n    num_top_bins = max(3, int(len(valid_bins_capacities) * 0.3))\n    top_candidate_indices_in_valid = sorted_indices_combined[:num_top_bins]\n    \n    # Also consider bins that offer a \"balanced\" fit, not too tight, not too empty.\n    # A bin that leaves a moderate amount of space might be more versatile.\n    # Let's consider bins where remaining_after_fit is between a small fraction and a larger fraction of bin capacity.\n    \n    # To define \"moderate\", we can look at the distribution of remaining capacities.\n    # Let's use quartiles for guidance.\n    q1_rem = np.percentile(remaining_after_fit, 25)\n    q3_rem = np.percentile(remaining_after_fit, 75)\n    \n    # Bins with remaining capacity between Q1 and Q3 (inclusive of Q3) are considered moderately remaining.\n    moderate_capacity_mask = (remaining_after_fit >= q1_rem) & (remaining_after_fit <= q3_rem)\n    \n    # Combine indices for exploration candidates\n    all_candidate_indices_in_valid = set(top_candidate_indices_in_valid)\n    all_candidate_indices_in_valid.update(np.where(moderate_capacity_mask)[0])\n    \n    exploration_candidate_indices_in_valid = list(all_candidate_indices_in_valid)\n\n    # Generate exploration scores for these candidates\n    # We want these exploration scores to be slightly random but not too high,\n    # to offer a chance for diversity without sacrificing too much performance.\n    exploration_scores = np.random.uniform(-0.1, 0.1, size=len(valid_bins_capacities))\n    \n    # Apply exploration scores:\n    # With probability epsilon, use exploration score for exploration candidates.\n    # Otherwise, use the combined score.\n    # For non-candidates, always use the combined score.\n    \n    final_scores = np.copy(combined_scores)\n    \n    # Create a mask for the identified exploration candidates\n    exploration_mask = np.zeros_like(valid_bins_capacities, dtype=bool)\n    if exploration_candidate_indices_in_valid:\n        exploration_mask[exploration_candidate_indices_in_valid] = True\n    \n    # Decide whether to use exploration score for exploration candidates\n    use_exploration_for_candidates = np.random.rand(len(valid_bins_capacities)) < epsilon\n    \n    # Apply the exploration scores only to the chosen candidates\n    final_scores[exploration_mask & use_exploration_for_candidates] = exploration_scores[exploration_mask & use_exploration_for_candidates]\n    \n    priorities[valid_bins_indices] = final_scores\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins that result in the tightest fit after packing,\n    with a bonus for perfect fits and a fallback for worst-fit among remaining options.\"\"\"\n\n    # Initialize priorities with a very low value for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity after placing the item in valid bins.\n    potential_remain_cap = bins_remain_cap[fit_mask] - item\n\n    # Assign scores:\n    # 1. High priority for perfect fits (remaining capacity = 0).\n    #    We give a bonus score (e.g., 1.0) to indicate preference.\n    perfect_fit_mask = potential_remain_cap == 0\n    priorities[fit_mask][perfect_fit_mask] = 1.0\n\n    # 2. For other valid fits, prioritize bins that leave less remaining capacity.\n    #    This encourages a \"tight\" packing. We use the negative of the remaining capacity.\n    #    The smallest non-negative remaining capacity will get the highest score here.\n    non_perfect_fit_mask = ~perfect_fit_mask\n    priorities[fit_mask][non_perfect_fit_mask] = -potential_remain_cap[non_perfect_fit_mask]\n\n    # 3. Tie-breaking for bins that result in the same remaining capacity (or are perfect fits):\n    #    Among bins with the same resulting remaining capacity, favor the one with the\n    #    largest original remaining capacity (closer to worst-fit among good fits).\n    #    This helps to keep smaller bins available for smaller items.\n    #    We can achieve this by adding a small bonus proportional to the original capacity.\n    #    Add a small epsilon to the priority to break ties.\n    #    For perfect fits, they already have a score of 1.0. We want to differentiate them.\n    #    Let's use the negative of the original remaining capacity as a secondary score.\n    #    This means, for equally good fits, we prefer the one that was originally larger.\n    #    The `item - bins_remain_cap[fit_mask]` was a good starting point for 'tightness'\n    #    but did not handle tie-breaking well.\n\n    # Let's combine the score: Prioritize by minimizing remaining capacity.\n    # A simple way is to maximize `-(remaining_capacity)`.\n    # To differentiate between equally good fits, we can use the original capacity.\n    # If two bins result in the same remaining capacity, the one that started larger\n    # (worst fit among the tightest) is preferred.\n    # So, for the same `-(remaining_capacity)`, we want to maximize the original capacity.\n\n    # Re-calculating for clarity and combined logic:\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate potential remaining capacity for fitting bins.\n    potential_remain_cap_vals = bins_remain_cap[fit_mask] - item\n\n    # Score: Primarily, minimize remaining capacity. Maximize -(remaining_capacity).\n    # Secondary: For ties in remaining capacity, prefer larger original capacity.\n    # This can be achieved by maximizing `original_capacity - item`.\n    # Or more simply, `item - original_capacity` (smaller is better here, so maximize `-(item - original_capacity)`)\n    # Let's focus on minimizing `potential_remain_cap_vals`.\n    # A good score would be `-(potential_remain_cap_vals)`.\n    # To break ties (same `potential_remain_cap_vals`), we prefer bins that had higher initial capacity.\n    # So, we can add `bins_remain_cap[fit_mask]` as a secondary factor.\n    # This means we want to maximize: `-(potential_remain_cap_vals) + C * bins_remain_cap[fit_mask]`\n    # where C is a small constant to ensure primary sorting is by remaining capacity.\n\n    # Let's use a simpler approach that captures the essence:\n    # Prioritize bins that leave the least remainder.\n    # For ties, pick the one that was originally larger.\n    # Score = -(remaining_capacity) + small_bonus * original_capacity\n\n    # Let's refine the score calculation.\n    # For bins that fit:\n    # Primary goal: Minimize `potential_remain_cap`.\n    # Secondary goal: If `potential_remain_cap` is the same, pick the bin that was originally largest.\n\n    # Score: `item - bins_remain_cap[fit_mask]` works well for tight fits.\n    # The highest score is for `bins_remain_cap[fit_mask] == item`.\n    # If there are multiple such bins, they have the same score.\n    # To break ties, we can add a small value related to the original capacity.\n    # Higher original capacity is preferred for ties in remaining capacity.\n\n    # Let's use the inverse of remaining capacity, but penalize bins that are too large.\n    # The \"perfect fit\" is ideal.\n    # So, let's try a combined score:\n    # - Perfect fit: Highest score (e.g., 100)\n    # - Tight fit (small remaining capacity): Score inversely proportional to remaining capacity.\n    # - Break ties by original capacity: Higher original capacity gets a small bonus.\n\n    # Final approach:\n    # 1. Perfect fits get a significant bonus (e.g., 1000).\n    # 2. Other fits get a score based on inverse of remaining capacity + a small bonus\n    #    for larger original capacity to break ties.\n    #    Score = 1 / (potential_remain_cap + epsilon) + original_capacity * epsilon_small\n    #    where epsilon is for avoiding division by zero and epsilon_small for tie-breaking.\n\n    # Revised attempt focusing on minimizing remaining capacity and then maximizing original capacity for ties.\n    # Score = -(remaining_capacity) + (original_capacity / MaxCapacity) * epsilon_tiebreak\n    # This needs careful scaling.\n\n    # Let's use a scoring that strongly favors perfect fits, then tight fits, and then larger original bins.\n    scores = np.zeros_like(bins_remain_cap, dtype=float)\n    scores.fill(-np.inf) # Initialize with a very low score\n\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_capacity = bins_remain_cap[can_fit_mask]\n    potential_remain_cap_vals = fitting_bins_capacity - item\n\n    # Perfect fits have the highest priority\n    perfect_fit_indices_in_fitting = np.where(potential_remain_cap_vals == 0)[0]\n    if len(perfect_fit_indices_in_fitting) > 0:\n        scores[can_fit_mask][perfect_fit_indices_in_fitting] = 1000.0\n\n    # Tight fits get priority based on negative remaining capacity\n    # Add a small factor to ensure they are ranked below perfect fits but above others.\n    # The secondary criterion: prefer larger original capacity among those with same remainder.\n    # We can add `fitting_bins_capacity` multiplied by a small factor.\n    # Let's combine this into a single score for non-perfect fits.\n    non_perfect_fit_indices_in_fitting = np.where(potential_remain_cap_vals > 0)[0]\n    if len(non_perfect_fit_indices_in_fitting) > 0:\n        # Score = -(remaining_capacity) + bonus for larger original capacity\n        # The bonus should be small enough not to override the primary goal of minimizing remainder.\n        # Use a small fraction of max possible capacity as tie-breaker.\n        # Max possible remainder is roughly bin_capacity. So, max of `fitting_bins_capacity` can be used.\n        max_cap_val = np.max(fitting_bins_capacity) if fitting_bins_capacity.size > 0 else 1.0\n        tie_breaker_factor = 1e-6 # A very small factor for tie-breaking\n\n        # Score for non-perfect fits: prioritize less remaining capacity, then more original capacity.\n        scores[can_fit_mask][non_perfect_fit_indices_in_fitting] = \\\n            -(potential_remain_cap_vals[non_perfect_fit_indices_in_fitting]) \\\n            + (fitting_bins_capacity[non_perfect_fit_indices_in_fitting] / max_cap_val) * tie_breaker_factor\n\n    # Ensure perfect fits still have highest priority if they exist\n    # If perfect fits were assigned 1000.0, and non-perfect fits get scores like -0.1 + 0.99 * 1e-6,\n    # this order is maintained.\n\n    # If there are no perfect fits, and multiple bins have the same minimal remainder,\n    # the tie-breaker correctly selects the one with higher original capacity.\n\n    return scores\n\n### Analyze & experience\n- Comparing Heuristics 1st and 2nd:\n*   **Heuristic 1st** employs a multi-objective scoring system (tightness, waste avoidance, future capacity) and a guided exploration strategy (top 30% scores, moderate capacity bins).\n*   **Heuristic 2nd** focuses on tight fit with a perfect fit bonus and a surplus penalty, using a simpler adaptive exploration (top 20% tightest, moderate capacity). It uses a smaller random noise for exploration.\n*   **Difference:** Heuristic 1st is more complex, with more defined objectives and a more structured exploration. Heuristic 2nd is simpler and more focused on the \"tight fit\" aspect, with less nuanced exploration.\n\nComparing Heuristics 2nd and 3rd:\n*   These two heuristics are identical.\n\nComparing Heuristics 3rd and 4th:\n*   **Heuristic 3rd** uses a combination of tight fit, perfect fit bonus, and surplus penalty, with adaptive exploration based on top tightest fits and moderate capacity.\n*   **Heuristic 4th** is a simpler epsilon-greedy approach combining tight fit (with a perfect fit bonus) and purely random exploration scores. The exploration is applied to *all* valid bins with probability epsilon.\n*   **Difference:** Heuristic 3rd's exploration is \"guided\" to specific candidates, aiming for a more informed exploration. Heuristic 4th's exploration is purely random across all eligible bins. Heuristic 3rd also has a more refined scoring for exploitation.\n\nComparing Heuristics 4th and 5th:\n*   These two heuristics are identical.\n\nComparing Heuristics 5th and 6th:\n*   **Heuristic 5th** is a simple epsilon-greedy combining tight fit and random exploration.\n*   **Heuristic 6th** employs a more complex multi-objective scoring (tightness, space utilization, future suitability) and a guided exploration strategy (top 15% combined score, median remaining capacity, smallest remaining capacity). It uses Gaussian noise for exploration.\n*   **Difference:** Heuristic 6th is significantly more sophisticated in its objective definition and exploration strategy compared to the basic epsilon-greedy of Heuristic 5th. It aims to balance multiple packing goals.\n\nComparing Heuristics 6th and 7th:\n*   **Heuristic 6th** is multi-objective with guided exploration.\n*   **Heuristic 7th** is a single-objective \"tightest fit\" with a perfect fit bonus. It lacks any exploration strategy.\n*   **Difference:** Heuristic 6th is much more advanced due to its multi-objective nature and exploration. Heuristic 7th is a pure exploitation strategy.\n\nComparing Heuristics 7th and 8th:\n*   **Heuristic 7th** focuses solely on minimizing remaining capacity and a bonus for perfect fits.\n*   **Heuristic 8th** combines Best Fit with a penalty for large remaining capacity and a bonus for near-perfect fits. It uses a complex, non-linear scoring function.\n*   **Difference:** Heuristic 8th is more nuanced in its scoring by incorporating penalties and bonuses for specific conditions, whereas Heuristic 7th is simpler and focuses only on the immediate tightest fit.\n\nComparing Heuristics 8th and 9th:\n*   **Heuristic 8th** uses a custom complex score involving scaling and exponentials.\n*   **Heuristic 9th** uses an inverse score with a bonus for perfect fits, and then applies a softmax to normalize scores.\n*   **Difference:** Heuristic 9th's use of softmax can help normalize priorities into a probabilistic-like distribution, which might be useful in some contexts, but the score calculation in Heuristic 8th appears more targeted at specific packing behaviors (penalty for large waste, bonus for near-perfect). Heuristic 8th seems to have a more deliberate design for multiple packing goals.\n\nComparing Heuristics 9th and 10th:\n*   **Heuristic 9th** uses inverse scores with softmax.\n*   **Heuristic 10th** implements \"Almost Full Fit\" by maximizing `item - bins_remain_cap`, which directly prioritizes bins that become exactly full, then those with minimal positive remainder.\n*   **Difference:** Heuristic 10th has a clearer, more direct implementation of \"Almost Full Fit\" by maximizing `item - remaining_capacity`. Heuristic 9th's inverse score is related but less direct, and softmax adds normalization. Heuristic 10th is simpler and more purpose-built for its named strategy.\n\nComparing Heuristics 10th and 11th:\n*   **Heuristic 10th** implements \"Almost Full Fit\" by maximizing `item - bins_remain_cap`.\n*   **Heuristic 11th** implements \"Almost Full Fit\" by maximizing `1 / (bins_remain_cap - item + 1e-9)`.\n*   **Difference:** Both aim for tight fits. Heuristic 11th's inverse score will strongly favor bins that are very close to full, potentially more so than Heuristic 10th's linear approach. Heuristic 10th's direct maximization of `item - remaining_capacity` is simpler to understand and implement for the \"exactly full\" goal.\n\nComparing Heuristics 11th and 12th:\n*   These are functionally identical (both use `1 / (bins_remain_cap - item + 1e-9)` for fitting bins). The only difference is the presence of unused imports in 12th.\n\nComparing Heuristics 12th and 13th:\n*   These are identical.\n\nComparing Heuristics 13th and 14th:\n*   These are identical.\n\nComparing Heuristics 14th and 15th:\n*   **Heuristic 14th** uses `1 / (bins_remain_cap - item + 1e-9)`, with a special case for exact fits (score 1.0).\n*   **Heuristic 15th** uses a more complex scoring: perfect fits get 1000.0, non-perfect fits get `-(remaining_capacity) + (original_capacity / MaxCapacity) * tie_breaker_factor`. It prioritizes perfect fits, then tight fits, and breaks ties using original capacity.\n*   **Difference:** Heuristic 15th is significantly more sophisticated due to its prioritized scoring and tie-breaking mechanism, aiming for a more robust tight-fit strategy. Heuristic 14th is simpler.\n\nComparing Heuristics 15th and 16th:\n*   **Heuristic 15th** is a sophisticated tight-fit strategy with tie-breaking.\n*   **Heuristic 16th** implements a pure \"Random Fit\" strategy, assigning random priorities to any bin that can fit the item.\n*   **Difference:** Heuristic 15th is an exploitation-focused strategy, while Heuristic 16th is a pure exploration strategy. Heuristic 15th is far more intelligent in its bin selection.\n\nComparing Heuristics 16th and 17th:\n*   **Heuristic 16th** is pure random fit.\n*   **Heuristic 17th** is identical to Heuristic 15th.\n*   **Difference:** Heuristic 17th (and 15th) is a sophisticated exploitation strategy, while Heuristic 16th is a random exploration.\n\nComparing Heuristics 17th and 18th:\n*   **Heuristic 17th** (and 15th) is a strong tight-fit strategy with perfect fit bonus and tie-breaking based on original capacity.\n*   **Heuristic 18th** combines Best Fit (inverse scaled remaining capacity), penalty for large waste, and bonus for near-perfect fits using a custom, more complex scoring function.\n*   **Difference:** Heuristic 18th attempts to balance multiple aspects (tightness, waste, near-perfect fits) with a more elaborate scoring mechanism. Heuristic 17th is primarily focused on tightest fit and perfect fits, with a simpler tie-breaker. Heuristic 18th's approach might be more robust across various item/bin size distributions.\n\nComparing Heuristics 18th and 19th:\n*   These two heuristics are identical.\n\nComparing Heuristics 19th and 20th:\n*   **Heuristic 19th** (and 18th) combines Best Fit, waste penalty, and near-perfect bonus with complex scoring.\n*   **Heuristic 20th** implements a pure \"Worst Fit\" strategy, prioritizing bins with the most remaining capacity.\n*   **Difference:** Heuristic 19th is an advanced exploitation strategy focused on tight packing and efficiency, while Heuristic 20th is a simple exploration strategy with a specific (and often sub-optimal for immediate packing) goal.\n\nOverall Ranking Logic:\nThe top heuristics (1st, 6th) introduce multi-objective optimization and sophisticated guided exploration. The next tier (3rd, 15th/17th, 18th/19th) focus on advanced exploitation, balancing tight fits, perfect fits, and sometimes waste penalties. Mid-tier heuristics (2nd, 4th, 10th, 14th) use simpler exploitation strategies like basic tight fit or epsilon-greedy. Lower tiers are pure random (16th) or specific but often suboptimal strategies (20th Worst Fit, 11th/12th/13th basic inverse).\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective, guided exploration, adaptive scoring, explicit penalties/rewards, exploration-exploitation.\n*   **Advice:** Focus on heuristics that dynamically evaluate candidate solutions across multiple criteria (e.g., tightness, future usability) and use intelligent sampling strategies rather than random choices.\n*   **Avoid:** Purely greedy approaches, static scoring, and random exploration that doesn't leverage learned information or problem structure.\n*   **Explanation:** Effective heuristics learn from past performance, balancing exploration of new strategies with exploitation of known good ones. This involves refining evaluation metrics and guiding search towards promising regions of the solution space.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}