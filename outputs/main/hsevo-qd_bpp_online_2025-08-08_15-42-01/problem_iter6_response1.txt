```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A multi-objective priority function for online Bin Packing.
    Prioritizes bins based on a combination of fitting tightness, bin utilization,
    and guided exploration.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf)
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    # Objective 1: Minimize waste (tightest fit)
    remaining_after_fit = valid_bins_capacities - item
    tight_fit_scores = -remaining_after_fit

    # Objective 2: Maximize bin utilization (prioritize fuller bins that can still fit)
    # This encourages using partially filled bins before opening new ones, if possible.
    utilization_scores = (valid_bins_capacities - item) / (valid_bins_capacities + 1e-9) # Normalize for item size

    # Objective 3: Exploration - balance between exploitation and trying less obvious fits.
    # We want to explore bins that are not the absolute tightest but still good,
    # or bins that have a significant amount of remaining capacity that might be useful later.

    # Combined exploitation score: weighted sum of tight fit and utilization.
    # Weights can be tuned. Here, tight fit is slightly more emphasized.
    w_tight = 0.7
    w_util = 0.3
    exploitation_scores = w_tight * tight_fit_scores + w_util * utilization_scores

    # Introduce exploration based on diversity and potential future utility.
    # Bins with moderate remaining capacity are candidates for exploration.
    # Also, bins that are "good enough" but not optimal in terms of tightness.

    # Identify bins that are not perfectly tight but still fit.
    # We can assign a bonus to bins that are not the absolute best fit,
    # to encourage exploration of alternatives.
    sorted_indices_by_tightness = np.argsort(tight_fit_scores)
    best_tight_idx = sorted_indices_by_tightness[0]
    exploration_bonus_for_diverse_fits = 0.02 # Small bonus for not being the absolute tightest

    # Create a mask for bins that are not the absolute tightest fit.
    not_absolute_tightest_mask = np.ones_like(exploitation_scores, dtype=bool)
    not_absolute_tightest_mask[0] = False # Mark the best one as False

    exploration_scores = np.copy(exploitation_scores)
    exploration_scores[not_absolute_tightest_mask] += exploration_bonus_for_diverse_fits

    # Add a small random component for stochastic exploration.
    # The magnitude of the random noise is kept small to not overpower
    # the deterministic scoring, but enough to introduce variability.
    random_exploration_noise = np.random.rand(len(valid_bins_capacities)) * 0.005
    exploration_scores += random_exploration_noise

    # Dynamic weighting of exploration vs. exploitation based on current state.
    # If there are many bins that fit "well" (e.g., tight fit is close for many bins),
    # we might want to explore more.
    std_dev_tight_fit = np.std(tight_fit_scores)
    exploration_weight_factor = np.clip(std_dev_tight_fit * 5, 0.0, 0.1) # Adjust exploration influence

    # Final priority is a blend of exploitation and exploration.
    # The exploration_weight_factor controls how much we lean towards exploration_scores.
    final_scores = (1 - exploration_weight_factor) * exploitation_scores + exploration_weight_factor * exploration_scores

    priorities[valid_bins_indices] = final_scores

    return priorities
```
