```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A sophisticated multi-objective priority function for online Bin Packing.
    It balances tightest fit, perfect fit bonus, and a penalty for excessive remaining capacity,
    while employing an adaptive exploration strategy focused on promising bins.
    """
    epsilon = 0.1  # Probability of exploration
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities

    valid_bins_capacities = bins_remain_cap[can_fit_mask]
    valid_bins_indices = np.where(can_fit_mask)[0]

    remaining_after_fit = valid_bins_capacities - item

    # --- Multi-Objective Scoring ---
    # 1. Tightest Fit: Maximize negative remaining capacity (minimize surplus)
    # 2. Perfect Fit Bonus: High bonus for bins that become exactly full.
    # 3. Future Utility: Reward bins with moderate remaining capacity that might fit future items.
    # 4. Waste Penalty: Penalize bins that leave a disproportionately large surplus.

    # Base score for tightest fit (higher is better, so -remaining)
    exploitation_scores = -remaining_after_fit

    # Perfect fit bonus
    perfect_fit_bonus = 1000.0
    exploitation_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus

    # Moderate remaining capacity bonus (encourages using bins that are not too tight or too empty)
    # This helps in potentially fitting medium-sized items later.
    moderate_capacity_bonus_factor = 0.1
    median_rem_cap = np.median(valid_bins_capacities)
    # Consider bins with remaining capacity between 10% of item size and median remaining capacity
    moderate_rem_mask = (remaining_after_fit > item * 0.1) & (remaining_after_fit < median_rem_cap)
    exploitation_scores[moderate_rem_mask] += moderate_capacity_bonus_factor * remaining_after_fit[moderate_rem_mask]

    # Excessive waste penalty (discourage packing into bins that will have a lot of leftover space)
    # Penalty is proportional to the surplus relative to the bin's original capacity, but capped.
    excessive_surplus_threshold_ratio = 0.6  # If remaining capacity > 60% of original bin capacity
    excessive_surplus_penalty_factor = 0.5
    excessive_surplus_mask = remaining_after_fit > (valid_bins_capacities * excessive_surplus_threshold_ratio)
    penalty = (remaining_after_fit[excessive_surplus_mask] / valid_bins_capacities[excessive_surplus_mask]) * excessive_surplus_penalty_factor
    exploitation_scores[excessive_surplus_mask] -= penalty * 100 # Scale penalty to be significant

    # Normalize exploitation scores to avoid extreme values dominating
    if np.ptp(exploitation_scores) > 1e-9: # Avoid division by zero if all scores are the same
        exploitation_scores = (exploitation_scores - np.min(exploitation_scores)) / np.ptp(exploitation_scores)
    else:
        exploitation_scores = np.ones_like(exploitation_scores) * 0.5 # All same, give neutral score

    # --- Adaptive Exploration Strategy ---
    # Instead of random exploration, focus exploration on bins that are "promising"
    # based on the current multi-objective score.

    # Identify candidates for exploration:
    # - Bins with highest exploitation scores (top 20%)
    # - Bins that are "good enough" (score above a certain threshold)
    sorted_indices_exploitation = np.argsort(exploitation_scores)[::-1]
    num_top_candidates = max(1, int(len(valid_bins_capacities) * 0.2))
    exploration_candidate_mask = np.zeros_like(exploitation_scores, dtype=bool)
    exploration_candidate_mask[sorted_indices_exploitation[:num_top_candidates]] = True

    # Add bins that have at least a "good" score (e.g., above median exploitation score)
    median_exploitation_score = np.median(exploitation_scores)
    good_enough_mask = exploitation_scores >= median_exploitation_score
    exploration_candidate_mask[good_enough_mask] = True

    # Generate exploration scores for candidates: small random perturbations
    exploration_scores_candidates = np.random.rand(len(valid_bins_capacities)) * 0.05 # Small noise for variety

    # --- Combine Exploitation and Exploration ---
    # With probability epsilon, use exploration score for selected candidates.
    # Otherwise, use exploitation score for all valid bins.

    combined_priorities = np.copy(exploitation_scores)

    # Determine for each candidate if exploration should be used
    use_exploration_for_candidate = np.random.rand(len(valid_bins_capacities)) < epsilon

    # Apply exploration scores only to candidates where exploration is chosen
    apply_exploration_mask = exploration_candidate_mask & use_exploration_for_candidate
    combined_priorities[apply_exploration_mask] = exploration_scores_candidates[apply_exploration_mask]

    # Assign the calculated combined priorities to the original bins
    priorities[valid_bins_indices] = combined_priorities

    return priorities
```
