{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    epsilon = 0.05  # Slightly reduced exploration probability\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[can_fit_mask]\n    valid_bins_indices = np.where(can_fit_mask)[0]\n\n    # Enhanced Exploitation:\n    # 1. Tight fit: Prioritize bins that leave minimum remaining capacity.\n    # 2. Perfect fit bonus: A higher bonus for exact fits to minimize waste.\n    # 3. Surplus penalty: A mild penalty for bins that would have a large surplus\n    #    after packing, as these might be better saved for larger items.\n    \n    remaining_after_fit = valid_bins_capacities - item\n    \n    tight_fit_scores = -remaining_after_fit\n    \n    perfect_fit_bonus = 0.1  # Increased bonus for perfect fits\n    tight_fit_scores[np.abs(remaining_after_fit) < 1e-9] += perfect_fit_bonus\n\n    # A gentle penalty for large remainders, scaled by the item size\n    # to make it more relevant.\n    large_remainder_penalty_factor = 0.001 \n    surplus_penalty = (remaining_after_fit / item) * large_remainder_penalty_factor\n    tight_fit_scores -= surplus_penalty\n    \n    # Adaptive Exploration:\n    # Instead of purely random exploration, we can explore bins that are \"good enough\"\n    # but not necessarily the absolute best (according to tight fit).\n    # This can be done by introducing a small random perturbation to the scores\n    # of a subset of bins, or by giving a chance to bins that are not the tightest.\n    \n    # Let's use a strategy where we explore bins that are among the top K tightest fits,\n    # or bins that have a moderate remaining capacity.\n    \n    # Sort bins by tight fit score to identify top candidates\n    sorted_indices_tight = np.argsort(tight_fit_scores)[::-1]\n    \n    exploration_candidate_mask = np.zeros_like(tight_fit_scores, dtype=bool)\n    \n    # Select a portion of the best fitting bins for potential exploration\n    num_explore_candidates = min(len(valid_bins_capacities), max(1, int(len(valid_bins_capacities) * 0.2)))\n    exploration_candidate_mask[sorted_indices_tight[:num_explore_candidates]] = True\n    \n    # Additionally, include some bins that have a moderate amount of remaining capacity\n    # This might represent bins that are not tightly packed but could be useful later.\n    moderate_capacity_threshold = np.median(valid_bins_capacities)\n    moderate_capacity_mask = (valid_bins_capacities > item) & (valid_bins_capacities < moderate_capacity_threshold * 2) # bins that are not too tight, not too empty\n    exploration_candidate_mask[moderate_capacity_mask] = True\n\n    exploration_scores = np.random.rand(len(valid_bins_capacities)) * 0.01 # Smaller random noise for exploration\n    \n    # Combine: With probability epsilon, choose exploration score for candidate bins,\n    # otherwise use the tight fit score. For non-candidate bins, always use tight fit.\n    \n    use_exploration_for_candidates = np.random.rand(len(valid_bins_capacities)) < epsilon\n    \n    combined_scores = np.copy(tight_fit_scores)\n    \n    # Apply exploration scores only to the identified exploration candidates\n    combined_scores[exploration_candidate_mask & use_exploration_for_candidates] = exploration_scores[exploration_candidate_mask & use_exploration_for_candidates]\n\n    priorities[valid_bins_indices] = combined_scores\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Worst Fit strategy.\n\n    The Worst Fit strategy aims to place the current item into the bin that has the most remaining capacity.\n    This heuristic attempts to keep bins with less capacity available for smaller items later on,\n    potentially leading to a more efficient packing in the long run.\n    In this priority function, we assign a higher priority score to bins with larger remaining capacities.\n    Specifically, the priority is directly proportional to the remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.array([bin_cap if bin_cap >= item else -np.inf for bin_cap in bins_remain_cap])\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1st and 2nd:\n*   **Heuristic 1st** employs a multi-objective scoring system (tightness, waste avoidance, future capacity) and a guided exploration strategy (top 30% scores, moderate capacity bins).\n*   **Heuristic 2nd** focuses on tight fit with a perfect fit bonus and a surplus penalty, using a simpler adaptive exploration (top 20% tightest, moderate capacity). It uses a smaller random noise for exploration.\n*   **Difference:** Heuristic 1st is more complex, with more defined objectives and a more structured exploration. Heuristic 2nd is simpler and more focused on the \"tight fit\" aspect, with less nuanced exploration.\n\nComparing Heuristics 2nd and 3rd:\n*   These two heuristics are identical.\n\nComparing Heuristics 3rd and 4th:\n*   **Heuristic 3rd** uses a combination of tight fit, perfect fit bonus, and surplus penalty, with adaptive exploration based on top tightest fits and moderate capacity.\n*   **Heuristic 4th** is a simpler epsilon-greedy approach combining tight fit (with a perfect fit bonus) and purely random exploration scores. The exploration is applied to *all* valid bins with probability epsilon.\n*   **Difference:** Heuristic 3rd's exploration is \"guided\" to specific candidates, aiming for a more informed exploration. Heuristic 4th's exploration is purely random across all eligible bins. Heuristic 3rd also has a more refined scoring for exploitation.\n\nComparing Heuristics 4th and 5th:\n*   These two heuristics are identical.\n\nComparing Heuristics 5th and 6th:\n*   **Heuristic 5th** is a simple epsilon-greedy combining tight fit and random exploration.\n*   **Heuristic 6th** employs a more complex multi-objective scoring (tightness, space utilization, future suitability) and a guided exploration strategy (top 15% combined score, median remaining capacity, smallest remaining capacity). It uses Gaussian noise for exploration.\n*   **Difference:** Heuristic 6th is significantly more sophisticated in its objective definition and exploration strategy compared to the basic epsilon-greedy of Heuristic 5th. It aims to balance multiple packing goals.\n\nComparing Heuristics 6th and 7th:\n*   **Heuristic 6th** is multi-objective with guided exploration.\n*   **Heuristic 7th** is a single-objective \"tightest fit\" with a perfect fit bonus. It lacks any exploration strategy.\n*   **Difference:** Heuristic 6th is much more advanced due to its multi-objective nature and exploration. Heuristic 7th is a pure exploitation strategy.\n\nComparing Heuristics 7th and 8th:\n*   **Heuristic 7th** focuses solely on minimizing remaining capacity and a bonus for perfect fits.\n*   **Heuristic 8th** combines Best Fit with a penalty for large remaining capacity and a bonus for near-perfect fits. It uses a complex, non-linear scoring function.\n*   **Difference:** Heuristic 8th is more nuanced in its scoring by incorporating penalties and bonuses for specific conditions, whereas Heuristic 7th is simpler and focuses only on the immediate tightest fit.\n\nComparing Heuristics 8th and 9th:\n*   **Heuristic 8th** uses a custom complex score involving scaling and exponentials.\n*   **Heuristic 9th** uses an inverse score with a bonus for perfect fits, and then applies a softmax to normalize scores.\n*   **Difference:** Heuristic 9th's use of softmax can help normalize priorities into a probabilistic-like distribution, which might be useful in some contexts, but the score calculation in Heuristic 8th appears more targeted at specific packing behaviors (penalty for large waste, bonus for near-perfect). Heuristic 8th seems to have a more deliberate design for multiple packing goals.\n\nComparing Heuristics 9th and 10th:\n*   **Heuristic 9th** uses inverse scores with softmax.\n*   **Heuristic 10th** implements \"Almost Full Fit\" by maximizing `item - bins_remain_cap`, which directly prioritizes bins that become exactly full, then those with minimal positive remainder.\n*   **Difference:** Heuristic 10th has a clearer, more direct implementation of \"Almost Full Fit\" by maximizing `item - remaining_capacity`. Heuristic 9th's inverse score is related but less direct, and softmax adds normalization. Heuristic 10th is simpler and more purpose-built for its named strategy.\n\nComparing Heuristics 10th and 11th:\n*   **Heuristic 10th** implements \"Almost Full Fit\" by maximizing `item - bins_remain_cap`.\n*   **Heuristic 11th** implements \"Almost Full Fit\" by maximizing `1 / (bins_remain_cap - item + 1e-9)`.\n*   **Difference:** Both aim for tight fits. Heuristic 11th's inverse score will strongly favor bins that are very close to full, potentially more so than Heuristic 10th's linear approach. Heuristic 10th's direct maximization of `item - remaining_capacity` is simpler to understand and implement for the \"exactly full\" goal.\n\nComparing Heuristics 11th and 12th:\n*   These are functionally identical (both use `1 / (bins_remain_cap - item + 1e-9)` for fitting bins). The only difference is the presence of unused imports in 12th.\n\nComparing Heuristics 12th and 13th:\n*   These are identical.\n\nComparing Heuristics 13th and 14th:\n*   These are identical.\n\nComparing Heuristics 14th and 15th:\n*   **Heuristic 14th** uses `1 / (bins_remain_cap - item + 1e-9)`, with a special case for exact fits (score 1.0).\n*   **Heuristic 15th** uses a more complex scoring: perfect fits get 1000.0, non-perfect fits get `-(remaining_capacity) + (original_capacity / MaxCapacity) * tie_breaker_factor`. It prioritizes perfect fits, then tight fits, and breaks ties using original capacity.\n*   **Difference:** Heuristic 15th is significantly more sophisticated due to its prioritized scoring and tie-breaking mechanism, aiming for a more robust tight-fit strategy. Heuristic 14th is simpler.\n\nComparing Heuristics 15th and 16th:\n*   **Heuristic 15th** is a sophisticated tight-fit strategy with tie-breaking.\n*   **Heuristic 16th** implements a pure \"Random Fit\" strategy, assigning random priorities to any bin that can fit the item.\n*   **Difference:** Heuristic 15th is an exploitation-focused strategy, while Heuristic 16th is a pure exploration strategy. Heuristic 15th is far more intelligent in its bin selection.\n\nComparing Heuristics 16th and 17th:\n*   **Heuristic 16th** is pure random fit.\n*   **Heuristic 17th** is identical to Heuristic 15th.\n*   **Difference:** Heuristic 17th (and 15th) is a sophisticated exploitation strategy, while Heuristic 16th is a random exploration.\n\nComparing Heuristics 17th and 18th:\n*   **Heuristic 17th** (and 15th) is a strong tight-fit strategy with perfect fit bonus and tie-breaking based on original capacity.\n*   **Heuristic 18th** combines Best Fit (inverse scaled remaining capacity), penalty for large waste, and bonus for near-perfect fits using a custom, more complex scoring function.\n*   **Difference:** Heuristic 18th attempts to balance multiple aspects (tightness, waste, near-perfect fits) with a more elaborate scoring mechanism. Heuristic 17th is primarily focused on tightest fit and perfect fits, with a simpler tie-breaker. Heuristic 18th's approach might be more robust across various item/bin size distributions.\n\nComparing Heuristics 18th and 19th:\n*   These two heuristics are identical.\n\nComparing Heuristics 19th and 20th:\n*   **Heuristic 19th** (and 18th) combines Best Fit, waste penalty, and near-perfect bonus with complex scoring.\n*   **Heuristic 20th** implements a pure \"Worst Fit\" strategy, prioritizing bins with the most remaining capacity.\n*   **Difference:** Heuristic 19th is an advanced exploitation strategy focused on tight packing and efficiency, while Heuristic 20th is a simple exploration strategy with a specific (and often sub-optimal for immediate packing) goal.\n\nOverall Ranking Logic:\nThe top heuristics (1st, 6th) introduce multi-objective optimization and sophisticated guided exploration. The next tier (3rd, 15th/17th, 18th/19th) focus on advanced exploitation, balancing tight fits, perfect fits, and sometimes waste penalties. Mid-tier heuristics (2nd, 4th, 10th, 14th) use simpler exploitation strategies like basic tight fit or epsilon-greedy. Lower tiers are pure random (16th) or specific but often suboptimal strategies (20th Worst Fit, 11th/12th/13th basic inverse).\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective, guided exploration, adaptive scoring, explicit penalties/rewards, exploration-exploitation.\n*   **Advice:** Focus on heuristics that dynamically evaluate candidate solutions across multiple criteria (e.g., tightness, future usability) and use intelligent sampling strategies rather than random choices.\n*   **Avoid:** Purely greedy approaches, static scoring, and random exploration that doesn't leverage learned information or problem structure.\n*   **Explanation:** Effective heuristics learn from past performance, balancing exploration of new strategies with exploitation of known good ones. This involves refining evaluation metrics and guiding search towards promising regions of the solution space.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}