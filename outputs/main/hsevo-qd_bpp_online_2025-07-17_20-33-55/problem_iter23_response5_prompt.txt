{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                target_relative_residual: float = 0.9647642401422942,\n                random_noise_scale: float = 3.6399893513957206e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        target_relative_residual: Ideal relative residual capacity after placing the item.\n        random_noise_scale: Scale of the random noise added to priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n    \n    # 2. Maximize bin utilization: Prefer bins where the item fills a large portion\n    # of the remaining capacity, but not too large that it creates near-empty bins\n    # with the next item.\n    \n    # Fill ratio: item size / remaining capacity. Higher is better, but should be < 1.\n    fill_ratios = item / bins_remain_cap\n    \n    # Residual capacity after placing item\n    residual_capacity = bins_remain_cap - item\n    \n    # Relative residual capacity compared to item size. We want it large enough\n    # that we will likely fill it with some other item.\n    relative_residual = residual_capacity / item\n\n    # Score based on fill ratio, penalized if near-full or too empty after insertion.\n    # Scale by 1 / (1+abs(relative_residual-target)), where target = ideal value (say, 0.5 or 1)\n    priorities[~infeasible_bins] = fill_ratios[~infeasible_bins] / (1 + np.abs(relative_residual[~infeasible_bins] - target_relative_residual))\n    \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * random_noise_scale\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines fill ratio, residual capacity target, and low waste with adaptive bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    # 1. Infeasible penalty\n    priorities[~feasible_bins] = -np.inf\n\n    # 2. Fill ratio with residual target\n    fill_ratios = item / bins_remain_cap\n    residual_capacity = bins_remain_cap - item\n    relative_residual = residual_capacity / item\n    priorities[feasible_bins] = fill_ratios[feasible_bins] / (1 + np.abs(relative_residual[feasible_bins] - target_relative_residual))\n\n    # 3. Low waste bonus, adaptively scaled\n    low_waste_amount = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    low_waste_bins = low_waste_amount < low_waste_threshold\n    bonus_scale = np.clip(1 - (low_waste_amount[low_waste_bins] / low_waste_threshold), 0, 1)  # Scale bonus inversely to how close we are to the threshold\n    priorities[feasible_bins][low_waste_bins] += 0.1 * bonus_scale\n\n    # 4. Small random number for tie-breaking\n    priorities += np.random.rand(len(bins_remain_cap)) * small_constant\n    \n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see the best heuristic incorporates feasibility checks, maximizes bin utilization by considering fill ratios and residual capacity, adds random noise for tie-breaking, whereas the worst heuristic only calculates ratios and log ratios, lacking crucial elements like feasibility and controlled exploration.\n*   Comparing (1st) vs (9th), the best heuristic includes sophisticated waste management with waste penalty and fullness bonus, while the 9th only maximizes bin utilization.\n*   Comparing (7th) vs (9th), we see 7th heuristic considered target residual, fullness bonus and noise level, while 9th only focus on maximizing bin utilization.\n*   Comparing (10th) vs (12th), there are identical. They consider fill ratio, residual capacity, low waste bonus, and tie-breaking noise.\n*   Comparing (13th) vs (14th), we observe that both involve fill ratio, residual target, adaptive waste bonus, and noise, with the 13th using more parameters.\n*   Comparing (16th) vs (17th), the key difference lies in almost full bin prioritization.\n\nOverall: Better heuristics incorporate more factors (feasibility check, fill ratio, waste penalty, fullness bonus), use adaptive weighting and bonus, and add a small noise to avoid identical priorities.\n- \nOkay, let's refine \"Current Self-Reflection\" to focus on actionable insights for designing better heuristics, avoiding the pitfalls identified in \"Ineffective Self-Reflection.\"\n\nHere's a redefined self-reflection focusing on concrete actions:\n\n*   **Keywords:** Multi-factor evaluation, Dynamic weights, Adaptive parameters, Controlled exploration, Explicit constraints, Prioritization mechanisms, Configurable parameters, Performance feedback.\n\n*   **Advice:** Design heuristics considering *multiple* interacting objectives (feasibility, fill ratio, waste).  Employ dynamic weights that adapt based on real-time performance indicators (e.g., bin utilization, constraint violations). Incorporate *configurable* parameters to allow for fine-tuning and adaptation to diverse problem instances. Introduce controlled randomness judiciously to encourage exploration.\n\n*   **Avoid:** Single-factor decision-making, hardcoded parameters, ignoring constraints, static or overly simplistic weights, lack of adaptive behaviour and relying solely on pre-existing strategies.\n\n*   **Explanation:** This approach moves beyond simply *mentioning* multiple factors. It emphasizes actively *using* them through dynamic weighting and adaptive parameters. It pushes for configurable elements so that they can be refined through observation. Controlled randomness ensures exploration while explicitly acknowledging the need for feasibility.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}