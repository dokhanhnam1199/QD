{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by quantum mechanics, we assign probabilities (priorities) based on\n    a 'potential' that favors bins that are close to the item's size. This introduces\n    a kind of 'tunneling' effect, allowing the algorithm to occasionally explore\n    less obvious placements to potentially avoid creating many almost-empty bins.\n\n    We use an exponential potential, and then normalize to get pseudo-probabilities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    potential = -np.abs(bins_remain_cap - item)  # Potential well centered around item size\n    # Apply a temperature parameter to control exploration.  Higher temperature leads to more exploration\n    temperature = np.mean(bins_remain_cap) # adaptive temperature\n    priorities = np.exp(potential / temperature)  # Boltzmann distribution\n    \n    #Favor bins with sufficient capacity\n    sufficient_capacity = (bins_remain_cap >= item)\n    priorities = priorities * sufficient_capacity\n\n    #Normalize so we have something akin to probabilities, and avoid zeros. Add a tiny eps\n    priorities = priorities + 1e-9  # Avoid zero probabilities\n    priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Encourage filling bins that can fit the item\n            priorities[i] = (cap - item) / cap  # Remaining space ratio. Smaller is better (higher priority).\n\n            #Prioritize almost full bins (maximize space utilization)\n            #priorities[i] = 1- ((cap - item) / cap) #space utilization. Larger is better.\n        else:\n            # Discourage bins that cannot fit the item\n            priorities[i] = -1e9  #Very low priority\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first one uses multiple criteria like \"almost full\", \"low waste\", and \"capacity difference\", while the last one only focuses on remaining space ratio. The first also uses larger absolute priority values (1000, 500, 100) to allow clear distinctions between bins, where the last uses ratio values.\n\nComparing (2nd) vs (19th), the second uses advanced techniques such as high priority to almost-full bins, lower priority to bins with low waste and priority to bins with capacity closest to item size while the 19th one uses log ratio\n\nComparing (3rd) vs (18th), the third one considers waste minimization, fuller bins, and penalizes infeasible bins and the 18th one uses log ratio\n\nComparing (4th) vs (17th), the fourth one inspired by \"First-Fit Decreasing\" and \"Best-Fit Decreasing\" and considers waste while the 17th one uses log ratio\n\nComparing (5th) vs (16th), the fifth one considers waste minimization, fuller bins, and penalizes infeasible bins, while the sixteenth one penalizes small bin, gives score based on \"snugness\" and also remaining capacities\n\nComparing (second worst) vs (worst), we see the second worst uses logarithmic ratios directly as priorities, while the worst only focuses on remaining space ratio. The second worst also has unused imports, which suggests potentially incomplete or abandoned features.\nComparing (1st) vs (2nd), they are identical, implying redundancy. Comparing (3rd) vs (4th), we see the third heuristic tries to avoid creating almost empty bins (minimizes waste), while the fourth uses a combination of the First-Fit Decreasing and Best-Fit Decreasing approaches.\nComparing (second worst) vs (worst), both are relatively simplistic, calculating ratios and using them as or to derive priorities. But the latter one is inferior.\nOverall:\n\nThe better heuristics use a combination of multiple factors such as waste, fill ratio, and penalties for near-full or infeasible bins. They incorporate more complex logic and scaling to differentiate between bins effectively. They are also more explicitly designed with inspiration from known bin packing strategies such as First-Fit and Best-Fit Decreasing. Simplistic approaches that focus on a single metric or lack scaling tend to perform worse.\nAlso, the heuristics with more clear and well-defined priorities that leverage constant values tend to do better. Avoid using a single ratio.\n- \nOkay, here's a redefinition of \"Current Self-Reflection\" designed to guide the creation of better heuristics, while actively avoiding pitfalls of ineffective reflection, and focusing on actionable advice:\n\n*   **Keywords:** Multi-objective, penalty-based, priority-driven, algorithm-inspired, code simplification.\n*   **Advice:** Design heuristics that balance competing objectives (waste, fill ratio, etc.) using weighted penalties reflecting their importance. Prioritize key decision factors through scaling and ordering.\n*   **Avoid:** Over-reliance on single metrics, neglecting established algorithms, and code redundancy.\n*   **Explanation:** Heuristics should be nuanced, mimicking successful algorithms, while penalizing undesirable states based on a priority order, all while striving for simplicity and efficiency in code.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}