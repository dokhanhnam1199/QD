{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                fullness_bonus_weight: float = 0.2013748833676067, noise_level: float = 2.0819988765816894e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_penalty_weight: Weight of the small waste penalty.\n        fullness_bonus_weight: Weight of the bonus for bins closer to full.\n        noise_level: Magnitude of the random noise added to priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # 2.  First-Fit Decreasing inspired: Prioritize bins that can accommodate the item\n    #     with minimal waste.  Avoid creating very small remaining spaces if possible.\n\n    # Waste: Remaining capacity after placing the item.\n    waste = bins_remain_cap - item\n    waste[infeasible_bins] = np.inf  # Ensure infeasible bins are penalized\n\n    # Normalized Waste: Waste relative to the item size and bin size.\n    normalized_waste_item = waste / item\n    normalized_waste_bin = waste / bins_remain_cap\n\n    # Penalty for too small waste (encourages filling bins reasonably)\n    small_waste_penalty = np.exp(-normalized_waste_item)  # Exponential penalty for small waste\n\n    # Reward for filling the bin well.  A higher fill ratio is generally better.\n    fill_ratio = item / bins_remain_cap\n    fill_reward = fill_ratio\n\n    # Combine the factors: Prioritize based on fill ratio, penalized by small waste\n    priorities[~infeasible_bins] = fill_reward[~infeasible_bins] - waste_penalty_weight * small_waste_penalty[~infeasible_bins]\n\n    # Bonus:  Slightly prioritize bins closer to full if other factors are equal.\n    # This helps close out bins more quickly. Only apply if not infeasible.\n    priorities[~infeasible_bins] += fullness_bonus_weight * (1 - normalized_waste_bin[~infeasible_bins])\n        \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * noise_level\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, adaptive waste bonus, and residual target.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    # 1. Infeasible penalty\n    priorities[~feasible_bins] = -np.inf\n\n    # 2. Fill ratio with residual target\n    fill_ratios = item / bins_remain_cap\n    residual_capacity = bins_remain_cap - item\n    relative_residual = residual_capacity / item\n    priorities[feasible_bins] = fill_ratios[feasible_bins] / (1 + np.abs(relative_residual[feasible_bins] - target_relative_residual))\n\n    # 3. Low waste bonus (adaptive)\n    waste = bins_remain_cap - item\n    normalized_waste_bin = waste / bins_remain_cap\n    low_waste_bins = normalized_waste_bin < low_waste_threshold\n    \n    # Adaptive bonus: Larger bonus when bins are closer to full.\n    bonus_scale = adaptive_bonus_scale * (1 - normalized_waste_bin)\n    priorities[feasible_bins & low_waste_bins] += bonus_scale[feasible_bins & low_waste_bins]\n\n    # 4. Fullness Bonus: Prioritize bins that are closer to being full.\n    priorities[feasible_bins] += fullness_bonus_weight * (1 - normalized_waste_bin[feasible_bins])\n\n    # 5. Small random number for tie-breaking\n    priorities += np.random.rand(len(bins_remain_cap)) * tie_breaking_noise\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see the best heuristic incorporates feasibility checks, maximizes bin utilization by considering fill ratios and residual capacity, adds random noise for tie-breaking, whereas the worst heuristic only calculates ratios and log ratios, lacking crucial elements like feasibility and controlled exploration.\n*   Comparing (1st) vs (9th), the best heuristic includes sophisticated waste management with waste penalty and fullness bonus, while the 9th only maximizes bin utilization.\n*   Comparing (7th) vs (9th), we see 7th heuristic considered target residual, fullness bonus and noise level, while 9th only focus on maximizing bin utilization.\n*   Comparing (10th) vs (12th), there are identical. They consider fill ratio, residual capacity, low waste bonus, and tie-breaking noise.\n*   Comparing (13th) vs (14th), we observe that both involve fill ratio, residual target, adaptive waste bonus, and noise, with the 13th using more parameters.\n*   Comparing (16th) vs (17th), the key difference lies in almost full bin prioritization.\n\nOverall: Better heuristics incorporate more factors (feasibility check, fill ratio, waste penalty, fullness bonus), use adaptive weighting and bonus, and add a small noise to avoid identical priorities.\n- \nOkay, let's refine \"Current Self-Reflection\" to focus on actionable insights for designing better heuristics, avoiding the pitfalls identified in \"Ineffective Self-Reflection.\"\n\nHere's a redefined self-reflection focusing on concrete actions:\n\n*   **Keywords:** Multi-factor evaluation, Dynamic weights, Adaptive parameters, Controlled exploration, Explicit constraints, Prioritization mechanisms, Configurable parameters, Performance feedback.\n\n*   **Advice:** Design heuristics considering *multiple* interacting objectives (feasibility, fill ratio, waste).  Employ dynamic weights that adapt based on real-time performance indicators (e.g., bin utilization, constraint violations). Incorporate *configurable* parameters to allow for fine-tuning and adaptation to diverse problem instances. Introduce controlled randomness judiciously to encourage exploration.\n\n*   **Avoid:** Single-factor decision-making, hardcoded parameters, ignoring constraints, static or overly simplistic weights, lack of adaptive behaviour and relying solely on pre-existing strategies.\n\n*   **Explanation:** This approach moves beyond simply *mentioning* multiple factors. It emphasizes actively *using* them through dynamic weighting and adaptive parameters. It pushes for configurable elements so that they can be refined through observation. Controlled randomness ensures exploration while explicitly acknowledging the need for feasibility.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}