{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                target_relative_residual: float = 0.96,\n                fullness_bonus_weight: float = 0.2,\n                noise_level: float = 1e-9) -> np.ndarray:\n    \"\"\"Combines fill ratio, target residual, fullness bonus, and noise.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    fill_ratios = item / bins_remain_cap\n    residual_capacity = bins_remain_cap - item\n    relative_residual = residual_capacity / item\n\n    priorities[~infeasible_bins] = fill_ratios[~infeasible_bins] / (1 + np.abs(relative_residual[~infeasible_bins] - target_relative_residual))\n\n    normalized_waste_bin = residual_capacity / bins_remain_cap\n    almost_full_bonus = np.exp(-20 * normalized_waste_bin)\n    priorities[~infeasible_bins] += fullness_bonus_weight * almost_full_bonus[~infeasible_bins]\n\n    priorities += np.random.rand(len(bins_remain_cap)) * noise_level\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                fullness_bonus_weight: float = 0.2013748833676067, noise_level: float = 2.0819988765816894e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_penalty_weight: Weight of the small waste penalty.\n        fullness_bonus_weight: Weight of the bonus for bins closer to full.\n        noise_level: Magnitude of the random noise added to priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # 2. Waste calculation and handling of infeasible bins\n    waste = bins_remain_cap - item\n    waste[infeasible_bins] = np.inf\n\n    # 3. Normalized waste based on item size and bin capacity\n    normalized_waste_item = waste / item\n    normalized_waste_bin = waste / bins_remain_cap\n\n    # 4. Small waste penalty: Exponential penalty, more sensitive.\n    small_waste_penalty = np.exp(-5 * normalized_waste_item) # Increase the exponent to penalize more\n\n    # 5. Fill ratio reward: Sigmoid function to reward high fill ratios more\n    fill_ratio = item / bins_remain_cap\n    fill_reward = 1 / (1 + np.exp(-10 * (fill_ratio - 0.8)))  # Sigmoid, centerd around 0.8\n\n    # 6. Combine factors: Adjusted weights for better balance\n    priorities[~infeasible_bins] = fill_reward[~infeasible_bins] - waste_penalty_weight * small_waste_penalty[~infeasible_bins]\n\n    # 7. Fullness bonus: Stronger bonus for almost-full bins\n    almost_full_bonus = np.exp(-20 * normalized_waste_bin) # Strong bonus when bin is nearly full\n    priorities[~infeasible_bins] += fullness_bonus_weight * almost_full_bonus[~infeasible_bins]\n\n    # 8. Introduce a bin-selection bias based on current bin utilization\n    bin_utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    utilization_bias = 0.01 * bin_utilization  # Small bias to prefer bins with more items already in them\n    priorities[~infeasible_bins] += utilization_bias[~infeasible_bins]\n\n    # 9. Noise\n    priorities += np.random.rand(len(bins_remain_cap)) * noise_level\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see the best heuristic incorporates feasibility checks, maximizes bin utilization by considering fill ratios and residual capacity, adds random noise for tie-breaking, whereas the worst heuristic only calculates ratios and log ratios, lacking crucial elements like feasibility and controlled exploration.\n*   Comparing (1st) vs (9th), the best heuristic includes sophisticated waste management with waste penalty and fullness bonus, while the 9th only maximizes bin utilization.\n*   Comparing (7th) vs (9th), we see 7th heuristic considered target residual, fullness bonus and noise level, while 9th only focus on maximizing bin utilization.\n*   Comparing (10th) vs (12th), there are identical. They consider fill ratio, residual capacity, low waste bonus, and tie-breaking noise.\n*   Comparing (13th) vs (14th), we observe that both involve fill ratio, residual target, adaptive waste bonus, and noise, with the 13th using more parameters.\n*   Comparing (16th) vs (17th), the key difference lies in almost full bin prioritization.\n\nOverall: Better heuristics incorporate more factors (feasibility check, fill ratio, waste penalty, fullness bonus), use adaptive weighting and bonus, and add a small noise to avoid identical priorities.\n- \nOkay, let's refine \"Current Self-Reflection\" to focus on actionable insights for designing better heuristics, avoiding the pitfalls identified in \"Ineffective Self-Reflection.\"\n\nHere's a redefined self-reflection focusing on concrete actions:\n\n*   **Keywords:** Multi-factor evaluation, Dynamic weights, Adaptive parameters, Controlled exploration, Explicit constraints, Prioritization mechanisms, Configurable parameters, Performance feedback.\n\n*   **Advice:** Design heuristics considering *multiple* interacting objectives (feasibility, fill ratio, waste).  Employ dynamic weights that adapt based on real-time performance indicators (e.g., bin utilization, constraint violations). Incorporate *configurable* parameters to allow for fine-tuning and adaptation to diverse problem instances. Introduce controlled randomness judiciously to encourage exploration.\n\n*   **Avoid:** Single-factor decision-making, hardcoded parameters, ignoring constraints, static or overly simplistic weights, lack of adaptive behaviour and relying solely on pre-existing strategies.\n\n*   **Explanation:** This approach moves beyond simply *mentioning* multiple factors. It emphasizes actively *using* them through dynamic weighting and adaptive parameters. It pushes for configurable elements so that they can be refined through observation. Controlled randomness ensures exploration while explicitly acknowledging the need for feasibility.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}