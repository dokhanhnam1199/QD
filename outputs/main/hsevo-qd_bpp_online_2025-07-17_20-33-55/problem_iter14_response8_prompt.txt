{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines fill ratio, waste, and residual target, adapts bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    # 1. Infeasible penalty\n    priorities[~feasible_bins] = -np.inf\n\n    # 2. Fill ratio with residual target\n    fill_ratios = item / bins_remain_cap\n    residual_capacity = bins_remain_cap - item\n    target_relative_residual = 0.75\n    relative_residual = residual_capacity / item\n    priorities[feasible_bins] = fill_ratios[feasible_bins] / (1 + np.abs(relative_residual[feasible_bins] - target_relative_residual))\n\n    # 3. Low waste bonus (adaptive)\n    waste = bins_remain_cap - item\n    normalized_waste_bin = waste / bins_remain_cap\n    low_waste_threshold = 0.1\n    low_waste_bins = normalized_waste_bin < low_waste_threshold\n    \n    # Adaptive bonus: Larger bonus when bins are closer to full.\n    bonus_scale = 0.2 * (1 - normalized_waste_bin)\n    priorities[feasible_bins & low_waste_bins] += bonus_scale[feasible_bins & low_waste_bins]\n\n    # 4. Small random number for tie-breaking\n    priorities += np.random.rand(len(bins_remain_cap)) * 1e-9\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                fullness_bonus_weight: float = 0.2013748833676067, noise_level: float = 2.0819988765816894e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_penalty_weight: Weight of the small waste penalty.\n        fullness_bonus_weight: Weight of the bonus for bins closer to full.\n        noise_level: Magnitude of the random noise added to priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # 2. Waste calculation and handling of infeasible bins\n    waste = bins_remain_cap - item\n    waste[infeasible_bins] = np.inf\n\n    # 3. Normalized waste based on item size and bin capacity\n    normalized_waste_item = waste / item\n    normalized_waste_bin = waste / bins_remain_cap\n\n    # 4. Small waste penalty: Exponential penalty, more sensitive.\n    small_waste_penalty = np.exp(-5 * normalized_waste_item) # Increase the exponent to penalize more\n\n    # 5. Fill ratio reward: Sigmoid function to reward high fill ratios more\n    fill_ratio = item / bins_remain_cap\n    fill_reward = 1 / (1 + np.exp(-10 * (fill_ratio - 0.8)))  # Sigmoid, centerd around 0.8\n\n    # 6. Combine factors: Adjusted weights for better balance\n    priorities[~infeasible_bins] = fill_reward[~infeasible_bins] - waste_penalty_weight * small_waste_penalty[~infeasible_bins]\n\n    # 7. Fullness bonus: Stronger bonus for almost-full bins\n    almost_full_bonus = np.exp(-20 * normalized_waste_bin) # Strong bonus when bin is nearly full\n    priorities[~infeasible_bins] += fullness_bonus_weight * almost_full_bonus[~infeasible_bins]\n\n    # 8. Introduce a bin-selection bias based on current bin utilization\n    bin_utilization = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    utilization_bias = 0.01 * bin_utilization  # Small bias to prefer bins with more items already in them\n    priorities[~infeasible_bins] += utilization_bias[~infeasible_bins]\n\n    # 9. Noise\n    priorities += np.random.rand(len(bins_remain_cap)) * noise_level\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic prioritizes feasibility, manages waste (penalizing small waste and rewarding fullness), and adds noise for differentiation, while the worst simply uses the negative log of the fill ratio. (2nd) vs (19th) is similar to (1st) vs (20th). (3rd) vs (18th) is similar to (1st) vs (20th). Comparing (1st) vs (2nd), we see the best heuristic incorporates explicit waste and fullness considerations with tunable weights, while the second focuses on a target relative residual capacity. (3rd) vs (4th) are identical. Comparing (second worst) vs (worst), we see the second worst includes the standard imports. Overall: The better heuristics incorporate more factors (feasibility, fill ratio, waste management, fullness), often with tunable parameters, and add a small amount of noise to break ties. Simpler heuristics rely primarily on fill ratio and lack specific mechanisms to handle waste or prioritize bin completion. Adaptive bonuses and capacity thresholds help improve performance.\n- \nOkay, I understand. Let's redefine \"Current Self-Reflection\" focusing on actionable insights for designing better bin packing heuristics, while avoiding the pitfalls of \"Ineffective Self-Reflection\" (which seem to be high-level, generic suggestions). We want *specific* advice that leads to *concrete* design improvements.\n\nHere's the refined approach:\n\n*   **Keywords:** Multi-criteria optimization, dynamic weighting, adaptive parameters, instance-specific tuning, component-wise analysis, performance profiling, iterative refinement, trade-off exploration.\n\n*   **Advice:** Instead of simply *considering* multiple factors, identify *specific, quantifiable metrics* for each factor (e.g., waste as a percentage, fill as a ratio, feasibility as a penalty score for constraint violations). Focus on designing mechanisms to dynamically *learn and adjust* the weights assigned to these metrics *during runtime*, possibly using techniques like reinforcement learning or online optimization. Implement and test individual heuristic components separately, then in combination.\n\n*   **Avoid:** General statements like \"consider multiple factors\" or \"fine-tune parameters.\" Avoid vague suggestions and focus on quantifiable metrics. Stay away from hardcoded parameters and the over-reliance on established algorithms without critical adaptation. Also, avoid focusing on \"fragmentation\" as a primary factor. Instead, it should naturally be tackled in conjunction with other factors.\n\n*   **Explanation:** The goal is to move from abstract considerations to concrete implementation strategies. Dynamic weighting allows adaptation to problem instance characteristics. Component-wise analysis helps isolate the impact of different heuristic elements. Iterative refinement allows for continuous improvement based on empirical results. Prioritizing quantifiable metrics enables systematic evaluation and comparison of different heuristic designs. Essentially, we should be aiming to build heuristics that *learn* and *adapt* to the specific problem instance they are solving.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}