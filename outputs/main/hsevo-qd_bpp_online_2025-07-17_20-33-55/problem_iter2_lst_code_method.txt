{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # A bin is feasible only if its remaining capacity is greater than or equal to item's size\n    feasible_bins = bins_remain_cap >= item\n\n    # Give a high priority to almost-full bins, but only if they're feasible\n    almost_full_threshold = 0.95  # Experiment with this value\n    almost_full_bins = (bins_remain_cap - item) / bins_remain_cap < (1-almost_full_threshold)\n    priorities[feasible_bins & almost_full_bins] = 1000 # Very high priority to fill them quickly\n\n    #Give a slightly lower, but still high, priority to bins that have low waste.\n    low_waste_bins = (bins_remain_cap - item) / np.max(bins_remain_cap) < 0.1\n    priorities[feasible_bins & low_waste_bins] = 500\n\n\n    # Prioritize bins with remaining capacity closest to item size, avoiding fragmentation\n    capacity_diff = np.abs(bins_remain_cap - item)\n    priorities[feasible_bins] = 100 - (capacity_diff[feasible_bins] / np.max(bins_remain_cap)) * 50 #scale to avoid extreme values and normalize by max capacity\n    \n    # Small nudge to non-empty bins so empty bins aren't always chosen first\n    non_empty_bins = bins_remain_cap < np.max(bins_remain_cap)\n    priorities[feasible_bins & non_empty_bins] += 5\n\n    # Make infeasible bins very low priority\n    priorities[~feasible_bins] = -1000\n    \n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # A bin is feasible only if its remaining capacity is greater than or equal to item's size\n    feasible_bins = bins_remain_cap >= item\n\n    # Give a high priority to almost-full bins, but only if they're feasible\n    almost_full_threshold = 0.95  # Experiment with this value\n    almost_full_bins = (bins_remain_cap - item) / bins_remain_cap < (1-almost_full_threshold)\n    priorities[feasible_bins & almost_full_bins] = 1000 # Very high priority to fill them quickly\n\n    #Give a slightly lower, but still high, priority to bins that have low waste.\n    low_waste_bins = (bins_remain_cap - item) / np.max(bins_remain_cap) < 0.1\n    priorities[feasible_bins & low_waste_bins] = 500\n\n\n    # Prioritize bins with remaining capacity closest to item size, avoiding fragmentation\n    capacity_diff = np.abs(bins_remain_cap - item)\n    priorities[feasible_bins] = 100 - (capacity_diff[feasible_bins] / np.max(bins_remain_cap)) * 50 #scale to avoid extreme values and normalize by max capacity\n    \n    # Small nudge to non-empty bins so empty bins aren't always chosen first\n    non_empty_bins = bins_remain_cap < np.max(bins_remain_cap)\n    priorities[feasible_bins & non_empty_bins] += 5\n\n    # Make infeasible bins very low priority\n    priorities[~feasible_bins] = -1000\n    \n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin is feasible only if its remaining capacity is greater than or equal to the item size.\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        # No feasible bins, assign very low priority to all bins. It practically means open a new bin\n        return priorities - 1e9  # or -np.inf, ensuring it's the lowest. Avoid np.inf for numerical stability\n\n    # 1. Prioritize bins with a capacity close to the item size (minimize wasted space)\n    waste = bins_remain_cap - item\n    priorities[feasible_bins] = -np.abs(waste[feasible_bins])  # Negate waste to make smaller waste higher priority\n\n    # 2. Slightly prefer bins that are fuller (minimize the creation of almost-empty bins). A small perturbation.\n    priorities[feasible_bins] += 0.1 * (1 - bins_remain_cap[feasible_bins] / np.max(bins_remain_cap))  # Bias towards using less full bins less.\n\n    # 3. Add large negative values to infeasible bins.\n    priorities[~feasible_bins] = -1e8 #make these impossible if there are feasible options.\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by:\n    1.  First-Fit Decreasing (FFD): Prefer bins with enough space for the item.\n    2.  Best-Fit Decreasing (BFD): Among bins with enough space, prefer the one with smallest remaining space after packing the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Assign high priority to bins where the item fits\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] = 1.0  # Base priority\n\n    # Prioritize based on the remaining space *after* fitting the item (Best-Fit Decreasing inspired)\n    remaining_space = bins_remain_cap[fit_mask] - item\n    # Invert the remaining space; small space becomes a higher number.\n    # Adding a small constant to avoid division by zero or very large negative numbers\n    inverted_remaining_space = 1.0 / (remaining_space + 0.00001)\n    priorities[fit_mask] += inverted_remaining_space\n\n    # Consider \"waste\". A bin that fits tightly should be preferred.\n    waste_ratio = item / bins_remain_cap\n    priorities[fit_mask] += (1.0 - np.abs(waste_ratio[fit_mask]- 1))  # penalizing waste if we fill more than what is required in the selected bin. We prefer the minimum waste from using a bin. This forces utilization as an approximation to solve the problem.\n\n    # Scale to balance the priorities:\n    if np.sum(priorities) > 0: #If all bins cannot accomodate, do nothing\n        priorities = priorities / np.max(priorities)  # Normalize to 0-1 range\n    #Small noise injection to create diversity\n\n    noise = np.random.normal(0, 0.0001, len(priorities))\n    priorities = priorities + noise\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin is feasible only if its remaining capacity is greater than or equal to the item size.\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        # No feasible bins, assign very low priority to all bins. It practically means open a new bin\n        return priorities - 1e9  # or -np.inf, ensuring it's the lowest. Avoid np.inf for numerical stability\n\n    # 1. Prioritize bins with a capacity close to the item size (minimize wasted space)\n    waste = bins_remain_cap - item\n    priorities[feasible_bins] = -np.abs(waste[feasible_bins])  # Negate waste to make smaller waste higher priority\n\n    # 2. Slightly prefer bins that are fuller (minimize the creation of almost-empty bins). A small perturbation.\n    priorities[feasible_bins] += 0.1 * (1 - bins_remain_cap[feasible_bins] / np.max(bins_remain_cap))  # Bias towards using less full bins less.\n\n    # 3. Add large negative values to infeasible bins.\n    priorities[~feasible_bins] = -1e8 #make these impossible if there are feasible options.\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First-Fit Decreasing heuristic with a gravitational twist\n    # Bins that can fit the item get a priority boost inversely proportional to the remaining capacity *after* packing\n    # To simulate a black hole's pull on an item.\n\n    available_bins = bins_remain_cap >= item\n\n    if np.any(available_bins):\n        remaining_capacity_after_fit = bins_remain_cap[available_bins] - item\n        #Gravitational Pull\n        priorities[available_bins] = 1.0 / (remaining_capacity_after_fit + 0.00001)  # Avoid division by zero\n        #Scale to make it more relevant\n        priorities[available_bins] = priorities[available_bins] / np.sum(priorities[available_bins])\n\n    # Give a small penalty to nearly full bins for exploration and fairness\n    nearly_full_threshold = 0.1  #Bins filled to 90% capacity\n    nearly_full_bins = (bins_remain_cap / np.max(bins_remain_cap)) < nearly_full_threshold\n    priorities[nearly_full_bins] = priorities[nearly_full_bins] - 0.001 # Small penalty\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First-Fit Decreasing heuristic with a gravitational twist\n    # Bins that can fit the item get a priority boost inversely proportional to the remaining capacity *after* packing\n    # To simulate a black hole's pull on an item.\n\n    available_bins = bins_remain_cap >= item\n\n    if np.any(available_bins):\n        remaining_capacity_after_fit = bins_remain_cap[available_bins] - item\n        #Gravitational Pull\n        priorities[available_bins] = 1.0 / (remaining_capacity_after_fit + 0.00001)  # Avoid division by zero\n        #Scale to make it more relevant\n        priorities[available_bins] = priorities[available_bins] / np.sum(priorities[available_bins])\n\n    # Give a small penalty to nearly full bins for exploration and fairness\n    nearly_full_threshold = 0.1  #Bins filled to 90% capacity\n    nearly_full_bins = (bins_remain_cap / np.max(bins_remain_cap)) < nearly_full_threshold\n    priorities[nearly_full_bins] = priorities[nearly_full_bins] - 0.001 # Small penalty\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Inspired by gravitational potential and the second law of thermodynamics.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Apply a gravitational potential analogy: Larger remaining capacity attracts the item more strongly (lower potential).\n    # Also, favor bins where the item fills a significant portion, but not perfectly.\n    \n    # Avoid division by zero and negative values in logarithms\n    bins_remain_cap_safe = np.clip(bins_remain_cap, 1e-6, None)\n    \n    potential = -np.log(bins_remain_cap_safe)  # Gravitational potential (analogy)\n\n    # Calculate how well the item fits in each bin (a measure of entropy).\n    # A perfect fit (item == remaining capacity) should have a lower priority.\n    fit_score = -np.abs(bins_remain_cap_safe - item) # closer to 0 is a better fit.\n\n    # Combine the potential (capacity) and fit (entropy) scores\n    # We want to prioritize based on high capacity and good fit, but the item MUST fit.\n    \n    priorities = np.where(bins_remain_cap_safe >= item, potential + fit_score, -np.inf) #Only assign priority if it fits\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by gravitational potential and energy minimization.\n    A bin is more attractive (higher priority) if:\n    1. It can accommodate the item.\n    2. The item is a 'significant' portion of the bin's capacity (efficiency).\n    3. We avoid leaving bins only slightly filled (stability).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Filter out bins that cannot accommodate the item.\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        #If no bins fit, prioritize bins with smallest remaining capacity to hopefully finish those bins first\n        priorities = -bins_remain_cap\n        return priorities\n\n    # Efficiency: Item size as a fraction of bin capacity.\n    efficiency = item / bins_remain_cap\n    efficiency[~eligible_bins] = 0  # Zero out ineligible bins\n\n    # Stability: Penalty for leaving too much space after adding the item.\n    remaining_space = bins_remain_cap - item\n    stability = np.exp(-remaining_space) # Exponential decay for penalty\n    stability[~eligible_bins] = 0\n\n    # Combined priority: Efficiency balanced with stability, only for eligible bins\n    priorities[eligible_bins] = efficiency[eligible_bins] * stability[eligible_bins]\n\n    #Further refine by slightly preferring nearly-full bins if any are available\n    nearly_full = (remaining_space > 0) & (remaining_space < 0.1 * bins_remain_cap)\n    priorities[nearly_full] += 0.5 # small preference to nearly-full\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by quantum mechanics, we assign probabilities (priorities) based on\n    a 'potential' that favors bins that are close to the item's size. This introduces\n    a kind of 'tunneling' effect, allowing the algorithm to occasionally explore\n    less obvious placements to potentially avoid creating many almost-empty bins.\n\n    We use an exponential potential, and then normalize to get pseudo-probabilities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    potential = -np.abs(bins_remain_cap - item)  # Potential well centered around item size\n    # Apply a temperature parameter to control exploration.  Higher temperature leads to more exploration\n    temperature = np.mean(bins_remain_cap) # adaptive temperature\n    priorities = np.exp(potential / temperature)  # Boltzmann distribution\n    \n    #Favor bins with sufficient capacity\n    sufficient_capacity = (bins_remain_cap >= item)\n    priorities = priorities * sufficient_capacity\n\n    #Normalize so we have something akin to probabilities, and avoid zeros. Add a tiny eps\n    priorities = priorities + 1e-9  # Avoid zero probabilities\n    priorities = priorities / np.sum(priorities)\n    \n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version prioritizes bins that can fit the item reasonably well,\n    but also considers the amount of wasted space if the item is placed.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give bins that can fit the item a base priority\n    can_fit = bins_remain_cap >= item\n    priorities[can_fit] = 1.0\n\n    # Adjust priority based on how well the item fits\n    remaining_space = bins_remain_cap - item\n    fit_ratio = item / bins_remain_cap  # ratio of item size to bin capacity\n\n    # Higher priority if the item utilizes a larger proportion of the bin\n    # Also penalize bins that will have too much wasted space, say 10% capacity left.\n    small_waste = remaining_space / bins_remain_cap < 0.1\n    priorities[can_fit & small_waste] += fit_ratio[can_fit & small_waste]\n\n    priorities[can_fit & ~small_waste] += 0.5 * fit_ratio[can_fit & ~small_waste]\n\n    # Significantly penalize bins where the item doesn't fit\n    priorities[~can_fit] = -1000.0 # Ensure these bins are not considered unless no other option\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a more sophisticated priority function considering:\n    1. Waste (remaining capacity after adding the item)\n    2. Fill Ratio (item size relative to remaining capacity)\n    3. Avoidance of tiny residuals that are hard to fill later.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity if the item is placed in each bin\n    remaining_capacity = bins_remain_cap - item\n\n    # Initialize priority with a low value for bins that cannot fit the item\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    # Identify bins where the item fits\n    valid_bins = remaining_capacity >= 0\n\n    if np.any(valid_bins):  # Ensure there's at least one valid bin.\n        # Calculate fill ratios for the valid bins\n        fill_ratios = item / bins_remain_cap[valid_bins]\n\n        # Calculate waste (remaining capacity) for valid bins\n        waste = remaining_capacity[valid_bins]\n\n        # Define scaling factor to penalize extremely small waste. Higher lambda yields to bins that are more fully filled (larger item/capacity ratios)\n        lambda_waste = 1.0 # Larger lambda gives emphasis on the waste function\n\n        # Define scaling factor to penalize low item/capacity fill ratios\n        lambda_fill = 1.0 # Larger lambda gives emphasis on the fill function\n\n        # A function to make small residuals undesirable - Hawking radiation of tiny residual\n        waste_score = -lambda_waste * np.exp(-waste)\n        fill_score = lambda_fill * fill_ratios # Favors higher fill ratio\n\n        priorities[valid_bins] = fill_score + waste_score\n\n        #Boost the score of bins nearly perfectly fitting the item\n        nearly_perfect = (waste < 0.05) & valid_bins #Tolerance is a small residual.\n        priorities[nearly_perfect] += 2*lambda_fill\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a more sophisticated priority function considering:\n    1. Waste (remaining capacity after adding the item)\n    2. Fill Ratio (item size relative to remaining capacity)\n    3. Avoidance of tiny residuals that are hard to fill later.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity if the item is placed in each bin\n    remaining_capacity = bins_remain_cap - item\n\n    # Initialize priority with a low value for bins that cannot fit the item\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    # Identify bins where the item fits\n    valid_bins = remaining_capacity >= 0\n\n    if np.any(valid_bins):  # Ensure there's at least one valid bin.\n        # Calculate fill ratios for the valid bins\n        fill_ratios = item / bins_remain_cap[valid_bins]\n\n        # Calculate waste (remaining capacity) for valid bins\n        waste = remaining_capacity[valid_bins]\n\n        # Define scaling factor to penalize extremely small waste. Higher lambda yields to bins that are more fully filled (larger item/capacity ratios)\n        lambda_waste = 1.0 # Larger lambda gives emphasis on the waste function\n\n        # Define scaling factor to penalize low item/capacity fill ratios\n        lambda_fill = 1.0 # Larger lambda gives emphasis on the fill function\n\n        # A function to make small residuals undesirable - Hawking radiation of tiny residual\n        waste_score = -lambda_waste * np.exp(-waste)\n        fill_score = lambda_fill * fill_ratios # Favors higher fill ratio\n\n        priorities[valid_bins] = fill_score + waste_score\n\n        #Boost the score of bins nearly perfectly fitting the item\n        nearly_perfect = (waste < 0.05) & valid_bins #Tolerance is a small residual.\n        priorities[nearly_perfect] += 2*lambda_fill\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    A high priority indicates a bin is preferred.\n\n    This version prioritizes bins that can accommodate the item with minimal wasted space,\n    but also penalizes near-full bins that would be a poor choice for future items.\n    It also adds a small random element to break ties and encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities  # No bin can hold the item\n\n    # Calculate wasted space if the item is placed in the bin\n    wasted_space = bins_remain_cap - item\n\n    # Prioritize bins based on minimal wasted space (higher is better)\n    space_priority = np.zeros_like(bins_remain_cap, dtype=float)\n    space_priority[eligible_bins] = -np.abs(wasted_space[eligible_bins])  # Negative since we want to minimize wasted space\n\n\n    # Penalize near-full bins to avoid fragmentation (lower is worse)\n    fullness_penalty = np.zeros_like(bins_remain_cap, dtype=float)\n    fullness_penalty[bins_remain_cap < 1.1 * item] = -10  # Significantly penalize near full\n\n    # Reward bins that are nearly full, but *can* still fit the current item.\n    # Encourage consolidation. Note: This can be improved.\n    consolidation_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    consolidation_bonus[eligible_bins & (bins_remain_cap < 1.2 * item)] = 5\n\n    # Add a small random factor to break ties and encourage exploration\n    random_factor = np.random.rand(len(bins_remain_cap)) * 0.1\n\n    # Combine all factors to calculate the final priority\n    priorities = space_priority + fullness_penalty + consolidation_bonus + random_factor\n\n    # Set priority of bins that *cannot* hold the item to a very low value\n    priorities[~eligible_bins] = -np.inf  # ensures these bins are never selected.\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    A high priority indicates a bin is preferred.\n\n    This version prioritizes bins that can accommodate the item with minimal wasted space,\n    but also penalizes near-full bins that would be a poor choice for future items.\n    It also adds a small random element to break ties and encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities  # No bin can hold the item\n\n    # Calculate wasted space if the item is placed in the bin\n    wasted_space = bins_remain_cap - item\n\n    # Prioritize bins based on minimal wasted space (higher is better)\n    space_priority = np.zeros_like(bins_remain_cap, dtype=float)\n    space_priority[eligible_bins] = -np.abs(wasted_space[eligible_bins])  # Negative since we want to minimize wasted space\n\n\n    # Penalize near-full bins to avoid fragmentation (lower is worse)\n    fullness_penalty = np.zeros_like(bins_remain_cap, dtype=float)\n    fullness_penalty[bins_remain_cap < 1.1 * item] = -10  # Significantly penalize near full\n\n    # Reward bins that are nearly full, but *can* still fit the current item.\n    # Encourage consolidation. Note: This can be improved.\n    consolidation_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    consolidation_bonus[eligible_bins & (bins_remain_cap < 1.2 * item)] = 5\n\n    # Add a small random factor to break ties and encourage exploration\n    random_factor = np.random.rand(len(bins_remain_cap)) * 0.1\n\n    # Combine all factors to calculate the final priority\n    priorities = space_priority + fullness_penalty + consolidation_bonus + random_factor\n\n    # Set priority of bins that *cannot* hold the item to a very low value\n    priorities[~eligible_bins] = -np.inf  # ensures these bins are never selected.\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins that can fit the item snugly, but\n    # still have some space left. Avoid bins that are either too full\n    # (high ratio) or have too much space (low ratio).\n    # We also consider the absolute remaining capacity, favoring larger bins\n    # if the 'snugness' is similar.\n\n    ratios = item / bins_remain_cap\n    \n    # Penalize bins that are too small\n    too_small_penalty = np.where(ratios > 1, -1000 * (ratios - 1), 0) # Very large negative number\n\n    # Score based on how close the ratio is to 1, with a preference for slightly below 1.\n    snugness_score = np.exp(-5 * np.abs(ratios - 0.9))  # Gaussian-like, peaks at 0.9\n    \n    # Give preference to larger remaining capacities.  This term encourages the\n    # algorithm to keep larger bins open for potentially larger future items.\n    capacity_boost = bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0  # Normalize\n\n    priorities = snugness_score + capacity_boost + too_small_penalty\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Encourage filling bins that can fit the item\n            priorities[i] = (cap - item) / cap  # Remaining space ratio. Smaller is better (higher priority).\n\n            #Prioritize almost full bins (maximize space utilization)\n            #priorities[i] = 1- ((cap - item) / cap) #space utilization. Larger is better.\n        else:\n            # Discourage bins that cannot fit the item\n            priorities[i] = -1e9  #Very low priority\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}