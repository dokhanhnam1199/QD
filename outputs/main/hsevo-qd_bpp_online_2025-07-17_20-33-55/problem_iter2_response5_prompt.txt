{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # A bin is feasible only if its remaining capacity is greater than or equal to item's size\n    feasible_bins = bins_remain_cap >= item\n\n    # Give a high priority to almost-full bins, but only if they're feasible\n    almost_full_threshold = 0.95  # Experiment with this value\n    almost_full_bins = (bins_remain_cap - item) / bins_remain_cap < (1-almost_full_threshold)\n    priorities[feasible_bins & almost_full_bins] = 1000 # Very high priority to fill them quickly\n\n    #Give a slightly lower, but still high, priority to bins that have low waste.\n    low_waste_bins = (bins_remain_cap - item) / np.max(bins_remain_cap) < 0.1\n    priorities[feasible_bins & low_waste_bins] = 500\n\n\n    # Prioritize bins with remaining capacity closest to item size, avoiding fragmentation\n    capacity_diff = np.abs(bins_remain_cap - item)\n    priorities[feasible_bins] = 100 - (capacity_diff[feasible_bins] / np.max(bins_remain_cap)) * 50 #scale to avoid extreme values and normalize by max capacity\n    \n    # Small nudge to non-empty bins so empty bins aren't always chosen first\n    non_empty_bins = bins_remain_cap < np.max(bins_remain_cap)\n    priorities[feasible_bins & non_empty_bins] += 5\n\n    # Make infeasible bins very low priority\n    priorities[~feasible_bins] = -1000\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Inspired by gravitational potential and the second law of thermodynamics.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Apply a gravitational potential analogy: Larger remaining capacity attracts the item more strongly (lower potential).\n    # Also, favor bins where the item fills a significant portion, but not perfectly.\n    \n    # Avoid division by zero and negative values in logarithms\n    bins_remain_cap_safe = np.clip(bins_remain_cap, 1e-6, None)\n    \n    potential = -np.log(bins_remain_cap_safe)  # Gravitational potential (analogy)\n\n    # Calculate how well the item fits in each bin (a measure of entropy).\n    # A perfect fit (item == remaining capacity) should have a lower priority.\n    fit_score = -np.abs(bins_remain_cap_safe - item) # closer to 0 is a better fit.\n\n    # Combine the potential (capacity) and fit (entropy) scores\n    # We want to prioritize based on high capacity and good fit, but the item MUST fit.\n    \n    priorities = np.where(bins_remain_cap_safe >= item, potential + fit_score, -np.inf) #Only assign priority if it fits\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first one uses multiple criteria like \"almost full\", \"low waste\", and \"capacity difference\", while the last one only focuses on remaining space ratio. The first also uses larger absolute priority values (1000, 500, 100) to allow clear distinctions between bins, where the last uses ratio values.\n\nComparing (2nd) vs (19th), the second uses advanced techniques such as high priority to almost-full bins, lower priority to bins with low waste and priority to bins with capacity closest to item size while the 19th one uses log ratio\n\nComparing (3rd) vs (18th), the third one considers waste minimization, fuller bins, and penalizes infeasible bins and the 18th one uses log ratio\n\nComparing (4th) vs (17th), the fourth one inspired by \"First-Fit Decreasing\" and \"Best-Fit Decreasing\" and considers waste while the 17th one uses log ratio\n\nComparing (5th) vs (16th), the fifth one considers waste minimization, fuller bins, and penalizes infeasible bins, while the sixteenth one penalizes small bin, gives score based on \"snugness\" and also remaining capacities\n\nComparing (second worst) vs (worst), we see the second worst uses logarithmic ratios directly as priorities, while the worst only focuses on remaining space ratio. The second worst also has unused imports, which suggests potentially incomplete or abandoned features.\nComparing (1st) vs (2nd), they are identical, implying redundancy. Comparing (3rd) vs (4th), we see the third heuristic tries to avoid creating almost empty bins (minimizes waste), while the fourth uses a combination of the First-Fit Decreasing and Best-Fit Decreasing approaches.\nComparing (second worst) vs (worst), both are relatively simplistic, calculating ratios and using them as or to derive priorities. But the latter one is inferior.\nOverall:\n\nThe better heuristics use a combination of multiple factors such as waste, fill ratio, and penalties for near-full or infeasible bins. They incorporate more complex logic and scaling to differentiate between bins effectively. They are also more explicitly designed with inspiration from known bin packing strategies such as First-Fit and Best-Fit Decreasing. Simplistic approaches that focus on a single metric or lack scaling tend to perform worse.\nAlso, the heuristics with more clear and well-defined priorities that leverage constant values tend to do better. Avoid using a single ratio.\n- \nOkay, here's a redefinition of \"Current Self-Reflection\" designed to guide the creation of better heuristics, while actively avoiding pitfalls of ineffective reflection, and focusing on actionable advice:\n\n*   **Keywords:** Multi-objective, penalty-based, priority-driven, algorithm-inspired, code simplification.\n*   **Advice:** Design heuristics that balance competing objectives (waste, fill ratio, etc.) using weighted penalties reflecting their importance. Prioritize key decision factors through scaling and ordering.\n*   **Avoid:** Over-reliance on single metrics, neglecting established algorithms, and code redundancy.\n*   **Explanation:** Heuristics should be nuanced, mimicking successful algorithms, while penalizing undesirable states based on a priority order, all while striving for simplicity and efficiency in code.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}