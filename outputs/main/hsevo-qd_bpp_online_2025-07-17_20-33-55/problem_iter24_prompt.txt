{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\nCurrent heuristics:\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                fullness_bonus_weight: float = 0.2013748833676067, noise_level: float = 2.0819988765816894e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_penalty_weight: Weight of the small waste penalty.\n        fullness_bonus_weight: Weight of the bonus for bins closer to full.\n        noise_level: Magnitude of the random noise added to priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # 2.  First-Fit Decreasing inspired: Prioritize bins that can accommodate the item\n    #     with minimal waste.  Avoid creating very small remaining spaces if possible.\n\n    # Waste: Remaining capacity after placing the item.\n    waste = bins_remain_cap - item\n    waste[infeasible_bins] = np.inf  # Ensure infeasible bins are penalized\n\n    # Normalized Waste: Waste relative to the item size and bin size.\n    normalized_waste_item = waste / item\n    normalized_waste_bin = waste / bins_remain_cap\n\n    # Penalty for too small waste (encourages filling bins reasonably)\n    small_waste_penalty = np.exp(-normalized_waste_item)  # Exponential penalty for small waste\n\n    # Reward for filling the bin well.  A higher fill ratio is generally better.\n    fill_ratio = item / bins_remain_cap\n    fill_reward = fill_ratio\n\n    # Combine the factors: Prioritize based on fill ratio, penalized by small waste\n    priorities[~infeasible_bins] = fill_reward[~infeasible_bins] - waste_penalty_weight * small_waste_penalty[~infeasible_bins]\n\n    # Bonus:  Slightly prioritize bins closer to full if other factors are equal.\n    # This helps close out bins more quickly. Only apply if not infeasible.\n    priorities[~infeasible_bins] += fullness_bonus_weight * (1 - normalized_waste_bin[~infeasible_bins])\n        \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * noise_level\n\n    return priorities\n\nNow, think outside the box write a mutated function `priority_v2` better than current version.\nYou can use some hints below:\n- \nOkay, let's refine \"Current Self-Reflection\" to focus on actionable insights for designing better heuristics, avoiding the pitfalls identified in \"Ineffective Self-Reflection.\"\n\nHere's a redefined self-reflection focusing on concrete actions:\n\n*   **Keywords:** Multi-factor evaluation, Dynamic weights, Adaptive parameters, Controlled exploration, Explicit constraints, Prioritization mechanisms, Configurable parameters, Performance feedback.\n\n*   **Advice:** Design heuristics considering *multiple* interacting objectives (feasibility, fill ratio, waste).  Employ dynamic weights that adapt based on real-time performance indicators (e.g., bin utilization, constraint violations). Incorporate *configurable* parameters to allow for fine-tuning and adaptation to diverse problem instances. Introduce controlled randomness judiciously to encourage exploration.\n\n*   **Avoid:** Single-factor decision-making, hardcoded parameters, ignoring constraints, static or overly simplistic weights, lack of adaptive behaviour and relying solely on pre-existing strategies.\n\n*   **Explanation:** This approach moves beyond simply *mentioning* multiple factors. It emphasizes actively *using* them through dynamic weighting and adaptive parameters. It pushes for configurable elements so that they can be refined through observation. Controlled randomness ensures exploration while explicitly acknowledging the need for feasibility.\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}