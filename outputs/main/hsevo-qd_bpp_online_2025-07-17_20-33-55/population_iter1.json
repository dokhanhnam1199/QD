[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate wasted space if item is added to each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits and wasted space is minimized\n    feasible_bins = wasted_space >= 0\n    \n    if np.any(feasible_bins):\n        priorities[feasible_bins] = 1 / (wasted_space[feasible_bins] + 0.00001) #Avoid division by zero\n        \n        # Further prioritize bins that are close to being full after adding the item\n        remaining_capacity_after_add = bins_remain_cap[feasible_bins] - item\n        \n        priorities[feasible_bins] += 1 / (np.abs(remaining_capacity_after_add) + 0.00001) #Prioritize almost full\n        \n        \n        #prioritize bins that will have capacity < item after adding.\n        #Prioritize based on how close to being empty.\n\n        \n    # If no feasible bins, prioritize bins with largest remaining capacity but penalize\n    else:\n        priorities = bins_remain_cap / (item * 100)  # low priority values\n        \n        \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin is feasible only if its remaining capacity is greater than or equal to the item size.\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        # No feasible bins, assign very low priority to all bins. It practically means open a new bin\n        return priorities - 1e9  # or -np.inf, ensuring it's the lowest. Avoid np.inf for numerical stability\n\n    # 1. Prioritize bins with a capacity close to the item size (minimize wasted space)\n    waste = bins_remain_cap - item\n    priorities[feasible_bins] = -np.abs(waste[feasible_bins])  # Negate waste to make smaller waste higher priority\n\n    # 2. Slightly prefer bins that are fuller (minimize the creation of almost-empty bins). A small perturbation.\n    priorities[feasible_bins] += 0.1 * (1 - bins_remain_cap[feasible_bins] / np.max(bins_remain_cap))  # Bias towards using less full bins less.\n\n    # 3. Add large negative values to infeasible bins.\n    priorities[~feasible_bins] = -1e8 #make these impossible if there are feasible options.\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # The closer the item size is to the remaining capacity, the higher the priority\n            priorities[i] = (cap - item + 1e-9) / (cap + 1e-9)  # Adding small constant to avoid division by zero\n            # Scale by remaining capacity to favor bins that are fuller relative to their size\n            priorities[i] = (1 - priorities[i]) * cap # Scale so that when cap-item is small, it is a good fit, but we still prefer larger cap\n        else:\n            priorities[i] = -np.inf  # Assign negative infinity if item doesn't fit\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999969849999616 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # A bin is feasible only if its remaining capacity is greater than or equal to item's size\n    feasible_bins = bins_remain_cap >= item\n\n    # Give a high priority to almost-full bins, but only if they're feasible\n    almost_full_threshold = 0.95  # Experiment with this value\n    almost_full_bins = (bins_remain_cap - item) / bins_remain_cap < (1-almost_full_threshold)\n    priorities[feasible_bins & almost_full_bins] = 1000 # Very high priority to fill them quickly\n\n    #Give a slightly lower, but still high, priority to bins that have low waste.\n    low_waste_bins = (bins_remain_cap - item) / np.max(bins_remain_cap) < 0.1\n    priorities[feasible_bins & low_waste_bins] = 500\n\n\n    # Prioritize bins with remaining capacity closest to item size, avoiding fragmentation\n    capacity_diff = np.abs(bins_remain_cap - item)\n    priorities[feasible_bins] = 100 - (capacity_diff[feasible_bins] / np.max(bins_remain_cap)) * 50 #scale to avoid extreme values and normalize by max capacity\n    \n    # Small nudge to non-empty bins so empty bins aren't always chosen first\n    non_empty_bins = bins_remain_cap < np.max(bins_remain_cap)\n    priorities[feasible_bins & non_empty_bins] += 5\n\n    # Make infeasible bins very low priority\n    priorities[~feasible_bins] = -1000\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Encourage filling bins that can fit the item well\n            # Higher priority for bins closer to the item's size, but not exceeding\n            priority = 1.0 / (cap - item + 0.0001) #Adding a small value to prevent division by zero\n            priorities[i] = priority\n        else:\n            # Assign a very low priority to bins that cannot fit the item\n            priorities[i] = -1e9 # very low priority for bins that are too small\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Calculate the waste if the item is placed in the bin.  Negative waste is impossible.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf # Mark infeasible bins. It's infinity b/c small waste is good.\n    # Heuristic 1: Favor bins with small waste but big enough to fit\n    priority = -waste\n\n    # Heuristic 2: If item is small and many bins are very empty (e.g., first few items), use First Fit Decreasing (FFD)\n    # Give high priority to almost full bins to fill them before new bins open\n\n    near_full_threshold = 0.9 # Bin almost full (e.g. last 10% free)\n    if item < 0.2 and np.sum(bins_remain_cap > near_full_threshold) == 0:\n        priority += 0.1 * bins_remain_cap  # Smaller remaining capacities will get slightly higher scores. Small number, because we are early and do not want this dominating the 'waste' calculation.\n\n    # Heuristic 3: Encourage efficient packing in the long run\n    # Penalize extremely empty bins (e.g., > 80% empty) from being used unless truly needed. This only applied to bins capable of holding the item.\n\n    extremely_empty_threshold = 0.8\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] > item: # Applicable ONLY to bins capable of containing the item, hence IF\n\n           if bins_remain_cap[i] > extremely_empty_threshold :\n\n                priority[i] -= 0.05   #Reduce priority for those bins. The reduction will depend on how full they are relatively. The more full the less reduction. Important to be a small number.\n\n\n    # Heuristic 4 : Moderate size items, prevent \"hole creation\". If near to bin capacity, strongly prefer.\n    moderate_threshold_low = 0.3 # item is relatively large\n    moderate_threshold_high = 0.7\n\n    if moderate_threshold_low <= item <= moderate_threshold_high:\n        near_capacity_bins = (bins_remain_cap -item < 0.1) & (bins_remain_cap -item >= 0) # small room left\n\n        priority[near_capacity_bins] += 0.2 # very strong preferece if near capacity and fits.\n    return priority",
    "response_id": 5,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999685599978 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a more sophisticated priority function considering:\n    1. Waste (remaining capacity after adding the item)\n    2. Fill Ratio (item size relative to remaining capacity)\n    3. Avoidance of tiny residuals that are hard to fill later.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity if the item is placed in each bin\n    remaining_capacity = bins_remain_cap - item\n\n    # Initialize priority with a low value for bins that cannot fit the item\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    # Identify bins where the item fits\n    valid_bins = remaining_capacity >= 0\n\n    if np.any(valid_bins):  # Ensure there's at least one valid bin.\n        # Calculate fill ratios for the valid bins\n        fill_ratios = item / bins_remain_cap[valid_bins]\n\n        # Calculate waste (remaining capacity) for valid bins\n        waste = remaining_capacity[valid_bins]\n\n        # Define scaling factor to penalize extremely small waste. Higher lambda yields to bins that are more fully filled (larger item/capacity ratios)\n        lambda_waste = 1.0 # Larger lambda gives emphasis on the waste function\n\n        # Define scaling factor to penalize low item/capacity fill ratios\n        lambda_fill = 1.0 # Larger lambda gives emphasis on the fill function\n\n        # A function to make small residuals undesirable - Hawking radiation of tiny residual\n        waste_score = -lambda_waste * np.exp(-waste)\n        fill_score = lambda_fill * fill_ratios # Favors higher fill ratio\n\n        priorities[valid_bins] = fill_score + waste_score\n\n        #Boost the score of bins nearly perfectly fitting the item\n        nearly_perfect = (waste < 0.05) & valid_bins #Tolerance is a small residual.\n        priorities[nearly_perfect] += 2*lambda_fill\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.397686477862,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by quantum mechanics, we assign probabilities (priorities) based on\n    a 'potential' that favors bins that are close to the item's size. This introduces\n    a kind of 'tunneling' effect, allowing the algorithm to occasionally explore\n    less obvious placements to potentially avoid creating many almost-empty bins.\n\n    We use an exponential potential, and then normalize to get pseudo-probabilities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    potential = -np.abs(bins_remain_cap - item)  # Potential well centered around item size\n    # Apply a temperature parameter to control exploration.  Higher temperature leads to more exploration\n    temperature = np.mean(bins_remain_cap) # adaptive temperature\n    priorities = np.exp(potential / temperature)  # Boltzmann distribution\n    \n    #Favor bins with sufficient capacity\n    sufficient_capacity = (bins_remain_cap >= item)\n    priorities = priorities * sufficient_capacity\n\n    #Normalize so we have something akin to probabilities, and avoid zeros. Add a tiny eps\n    priorities = priorities + 1e-9  # Avoid zero probabilities\n    priorities = priorities / np.sum(priorities)\n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version prioritizes bins that can fit the item reasonably well,\n    but also considers the amount of wasted space if the item is placed.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give bins that can fit the item a base priority\n    can_fit = bins_remain_cap >= item\n    priorities[can_fit] = 1.0\n\n    # Adjust priority based on how well the item fits\n    remaining_space = bins_remain_cap - item\n    fit_ratio = item / bins_remain_cap  # ratio of item size to bin capacity\n\n    # Higher priority if the item utilizes a larger proportion of the bin\n    # Also penalize bins that will have too much wasted space, say 10% capacity left.\n    small_waste = remaining_space / bins_remain_cap < 0.1\n    priorities[can_fit & small_waste] += fit_ratio[can_fit & small_waste]\n\n    priorities[can_fit & ~small_waste] += 0.5 * fit_ratio[can_fit & ~small_waste]\n\n    # Significantly penalize bins where the item doesn't fit\n    priorities[~can_fit] = -1000.0 # Ensure these bins are not considered unless no other option\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # First, consider bins where the item actually fits.\n            # Higher priority to bins that have just enough space (minimize wasted space).\n            # Subtracting from a large number emphasizes small differences in remaining space.\n            priorities[i] = 1000 - abs(cap - item)\n\n            # Additionally, slightly prefer bins that are already somewhat full.\n            # This encourages filling bins before starting new ones. The smaller 'item' impact is to avoid overfilling.\n            priorities[i] += (bins_remain_cap.max() - cap)*0.1\n        else:\n            # Very low priority for bins that can't fit the item.\n            priorities[i] = -1000  # or -np.inf\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997158900078 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n    \n    # 2. Maximize bin utilization: Prefer bins where the item fills a large portion\n    # of the remaining capacity, but not too large that it creates near-empty bins\n    # with the next item.\n    \n    # Fill ratio: item size / remaining capacity. Higher is better, but should be < 1.\n    fill_ratios = item / bins_remain_cap\n    \n    # Residual capacity after placing item\n    residual_capacity = bins_remain_cap - item\n    \n    # Relative residual capacity compared to item size. We want it large enough\n    # that we will likely fill it with some other item.\n    relative_residual = residual_capacity / item\n\n    # Score based on fill ratio, penalized if near-full or too empty after insertion.\n    # Scale by 1 / (1+abs(relative_residual-target)), where target = ideal value (say, 0.5 or 1)\n    target_relative_residual = 0.75\n    priorities[~infeasible_bins] = fill_ratios[~infeasible_bins] / (1 + np.abs(relative_residual[~infeasible_bins] - target_relative_residual))\n    \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * 1e-9\n\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 3.819305943358592,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Employs a combination of factors inspired by concepts of energy minimization\n    and space-time curvature to prioritize bin selection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # 1. Energy Minimization (Smaller gaps favored):\n    # Penalize bins where the remaining capacity after placing the item\n    # would be too small (energy well), or too large (wasted space).\n    remaining_space = bins_remain_cap - item\n    small_gap_penalty = np.exp(-10 * np.abs(remaining_space) / np.max(bins_remain_cap)) # Exponential penalty\n    priorities += small_gap_penalty\n\n    # 2. Gravitational Attraction (Fill levels close to capacity favored):\n    # \"Attract\" the item to bins that are already reasonably full\n    # but have enough space. Analogy: gravity pulls objects together.\n    fill_levels = bins_remain_cap / np.max(bins_remain_cap) # Normalize remaining cap to [0,1]\n    gravitational_attraction = (1 - fill_levels) * (remaining_space >= 0) # Larger when bin is close to full\n    priorities += gravitational_attraction\n\n    # 3. Space-Time Curvature (Prevent extreme fragmentation):\n    # Favor bins with capacities close to the item size. Prevents having too many very tiny\n    # gaps at the expense of the bin count.  Analogy: minimize curvature (extreme fragmentation)\n    curvature = np.abs(bins_remain_cap - item) / np.max(bins_remain_cap) # relative to capacity.\n    curvature_penalty = np.exp(-5 * curvature)\n    priorities += curvature_penalty\n\n    # 4.  Avoid Overfilling: Severe negative penalty for insufficient capacity\n    insufficient_capacity = remaining_space < 0\n    priorities[insufficient_capacity] = -np.inf  # Very strong penalty\n\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\n    # Calculate how well the item fits in each bin (a measure of entropy).\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n9\n3\n72.33974351909447\n73.23053449813924\n123\n"
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Inspired by gravitational potential and the second law of thermodynamics.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Apply a gravitational potential analogy: Larger remaining capacity attracts the item more strongly (lower potential).\n    # Also, favor bins where the item fills a significant portion, but not perfectly.\n    \n    # Avoid division by zero and negative values in logarithms\n    bins_remain_cap_safe = np.clip(bins_remain_cap, 1e-6, None)\n    \n    potential = -np.log(bins_remain_cap_safe)  # Gravitational potential (analogy)\n\n    # Calculate how well the item fits in each bin (a measure of entropy).\n    # A perfect fit (item == remaining capacity) should have a lower priority.\n    fit_score = -np.abs(bins_remain_cap_safe - item) # closer to 0 is a better fit.\n\n    # Combine the potential (capacity) and fit (entropy) scores\n    # We want to prioritize based on high capacity and good fit, but the item MUST fit.\n    \n    priorities = np.where(bins_remain_cap_safe >= item, potential + fit_score, -np.inf) #Only assign priority if it fits\n\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Initialize priority array with a small default value to avoid issues with empty bins.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - 1e9\n\n    # Only consider bins that can actually fit the item.\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        # If no bin can fit, return the initialized priority array\n        return priorities\n\n    # Calculate waste if item is placed in each valid bin\n    waste = bins_remain_cap[valid_bins] - item\n\n    # Assign priority based on minimizing waste, prefering bins that result in less waste.\n    priorities[valid_bins] = -waste\n\n    # Add a bonus for filling the bin closer to full, but only if it doesn't create too much waste.\n    fill_ratio = item / bins_remain_cap[valid_bins]\n\n    # Experiment: Apply a more complex bonus.\n    # Prefer bins where the fill ratio is high, but not too high (avoid very small wastes)\n\n    bonus = np.where((fill_ratio > 0.7) & (waste < 0.2), fill_ratio*5 , 0) #Moderate fill ratio and waste is not too high\n    priorities[valid_bins] += bonus\n\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    A high priority indicates a bin is preferred.\n\n    This version prioritizes bins that can accommodate the item with minimal wasted space,\n    but also penalizes near-full bins that would be a poor choice for future items.\n    It also adds a small random element to break ties and encourage exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities  # No bin can hold the item\n\n    # Calculate wasted space if the item is placed in the bin\n    wasted_space = bins_remain_cap - item\n\n    # Prioritize bins based on minimal wasted space (higher is better)\n    space_priority = np.zeros_like(bins_remain_cap, dtype=float)\n    space_priority[eligible_bins] = -np.abs(wasted_space[eligible_bins])  # Negative since we want to minimize wasted space\n\n\n    # Penalize near-full bins to avoid fragmentation (lower is worse)\n    fullness_penalty = np.zeros_like(bins_remain_cap, dtype=float)\n    fullness_penalty[bins_remain_cap < 1.1 * item] = -10  # Significantly penalize near full\n\n    # Reward bins that are nearly full, but *can* still fit the current item.\n    # Encourage consolidation. Note: This can be improved.\n    consolidation_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    consolidation_bonus[eligible_bins & (bins_remain_cap < 1.2 * item)] = 5\n\n    # Add a small random factor to break ties and encourage exploration\n    random_factor = np.random.rand(len(bins_remain_cap)) * 0.1\n\n    # Combine all factors to calculate the final priority\n    priorities = space_priority + fullness_penalty + consolidation_bonus + random_factor\n\n    # Set priority of bins that *cannot* hold the item to a very low value\n    priorities[~eligible_bins] = -np.inf  # ensures these bins are never selected.\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 5.075787794176315,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, consider only bins that can actually hold the item.\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # If no bin can hold the item, prioritize bins with the most remaining capacity (least recently used).  Important to not return 0's if no bin can hold it, and to rather try to maximize remaining space to avoid the very frequent problem of using an extra bin right before running out in all bins\n        priorities = bins_remain_cap\n        return priorities\n\n    # Calculate remaining capacity after placing the item in eligible bins.\n    remaining_capacity_after_placement = bins_remain_cap[eligible_bins] - item\n\n    # Prioritize bins that leave the least amount of wasted space, but don't fill the bin entirely. Small value added so we dont only priortize completely filled bins\n    space_efficiency = 1 - (remaining_capacity_after_placement / bins_remain_cap[eligible_bins] + 0.000001 )\n    priorities[eligible_bins] = space_efficiency\n        #Give priority to fully filled bin in the case we do fill them, otherwise prioritize the bin such that we leave the least empty space (we use the most amount of space)\n    is_fully_filled = remaining_capacity_after_placement == 0\n    priorities[eligible_bins][is_fully_filled] = 100 #arbitarily large number\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item snugly, but also\n    includes a penalty for bins that are already very full (to avoid\n    overfilling bins prematurely).  It also adds a small bonus to bins\n    that are completely empty, encouraging initial bin usage.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Huge negative priority if item doesn't fit\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Bonus for empty bins to encourage initial usage\n    priorities[bins_remain_cap == 1.0] += 1.0 #Assuming bin capacity is 1.0, change this if other bin sizes are tested\n\n    # Main priority calculation for bins that *can* fit the item:\n    # - Use the *inverse* of the remaining capacity *after* adding the item.\n    #   This gives higher priority to bins where the item results in a smaller\n    #   remaining space (i.e., a snug fit). We want the *negative* of this to maximize usage but minimize wasted space\n    # - Add a small penalty for bins that are already nearly full, given by some function of the original remaining capacity.\n    #   This function should be small but sensitive to remaining capacities less than the item\n    fit_mask = bins_remain_cap >= item\n\n    remaining_after_fit = bins_remain_cap[fit_mask] - item\n    # Avoid division by zero by adding a small constant.\n    # and avoid taking the log of zero\n    priorities[fit_mask] += -np.log(remaining_after_fit + 1e-9)\n\n    #A penalty for bins that are close to full before placement\n    priorities[fit_mask] -= 0.1*np.exp(-bins_remain_cap[fit_mask]/item) #Adjust the 0.1 to be a larger value for tighter restrictions\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by:\n    1.  First-Fit Decreasing (FFD): Prefer bins with enough space for the item.\n    2.  Best-Fit Decreasing (BFD): Among bins with enough space, prefer the one with smallest remaining space after packing the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Assign high priority to bins where the item fits\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] = 1.0  # Base priority\n\n    # Prioritize based on the remaining space *after* fitting the item (Best-Fit Decreasing inspired)\n    remaining_space = bins_remain_cap[fit_mask] - item\n    # Invert the remaining space; small space becomes a higher number.\n    # Adding a small constant to avoid division by zero or very large negative numbers\n    inverted_remaining_space = 1.0 / (remaining_space + 0.00001)\n    priorities[fit_mask] += inverted_remaining_space\n\n    # Consider \"waste\". A bin that fits tightly should be preferred.\n    waste_ratio = item / bins_remain_cap\n    priorities[fit_mask] += (1.0 - np.abs(waste_ratio[fit_mask]- 1))  # penalizing waste if we fill more than what is required in the selected bin. We prefer the minimum waste from using a bin. This forces utilization as an approximation to solve the problem.\n\n    # Scale to balance the priorities:\n    if np.sum(priorities) > 0: #If all bins cannot accomodate, do nothing\n        priorities = priorities / np.max(priorities)  # Normalize to 0-1 range\n    #Small noise injection to create diversity\n\n    noise = np.random.normal(0, 0.0001, len(priorities))\n    priorities = priorities + noise\n\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Prioritize bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n    \n    # Heuristic 1: Prefer bins where item fills a large proportion of the bin's remaining capacity (but fits!)\n    fill_ratio = item / bins_remain_cap\n    priorities[fit_mask] = fill_ratio[fit_mask]\n\n    # Heuristic 2: Among the bins that fit, slightly prefer bins with less remaining capacity after placing the item\n    #This avoids leaving very small useless fragments. We add small values to avoid division by zero or log of zero\n    remaining_capacity_after_placement = bins_remain_cap - item + 1e-9\n\n    priorities[fit_mask] += 1.0 / (remaining_capacity_after_placement[fit_mask] + 1e-9) # Avoid div by zero if item == remaining_cap\n\n    #Very important - make bins that CANNOT fit, have the lowest priority possible\n    priorities[~fit_mask] = -np.inf  # Ensure bins that can't fit have the lowest priority\n    \n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 26, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n9\n3\n72.33974351909447\n73.23053449813924\n123\n"
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Prioritize bins that can fit the item. Higher capacity remaining gets higher priority to fill them more effectively and leave the smaller leftover for smaller items\n            priorities[i] = cap - item #or cap - item\n        else:\n            # Very low priority if it doesn't fit to avoid this bin unless necessary.\n            priorities[i] = -np.inf #Prefer to exclude to avoid fragments. Could assign -item if absolutely required\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Feasibility check: assign -inf priority to bins that cannot fit the item\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # For feasible bins, calculate a score based on remaining capacity after adding the item.\n    feasible_bins = ~infeasible_bins\n    remaining_capacity_after_fit = bins_remain_cap[feasible_bins] - item\n\n    # Give higher priority to bins where the remaining capacity is small but non-negative\n    # to encourage filling bins as much as possible. We add a small value to avoid division by zero\n    priorities[feasible_bins] = 1.0 / (remaining_capacity_after_fit + 0.0001)\n    \n    # Bonus for bins that fit the item almost perfectly (within some tolerance). This can avoid creating extremely small remaining capacity.\n    almost_full_mask = (remaining_capacity_after_fit >= 0) & (remaining_capacity_after_fit <= 0.1) #tolerance = 0.1\n    priorities[feasible_bins][almost_full_mask] += 10 # Add a large bonus\n    \n    # Negative priority if item would cause bin to be too empty. Encourage use of partially-full bins,\n    too_empty_mask = (remaining_capacity_after_fit > 0.5) & (remaining_capacity_after_fit < 1) # arbitrary constant\n    priorities[feasible_bins][too_empty_mask] -= 5\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the principles of relativity, this priority function seeks\n    a balance between filling bins and avoiding excessive fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin is suitable if it has enough space\n    suitable_bins = bins_remain_cap >= item\n\n    if not np.any(suitable_bins):\n        # No bin can fit the item. Return a very low priority for all bins.\n        # This essentially forces the creation of a new bin (handled externally).\n        return priorities - 1e9  # Very negative priority\n\n    for i, cap in enumerate(bins_remain_cap):\n        if suitable_bins[i]:\n            # Priority is higher for bins with remaining capacity closer to the item size\n            # to minimize wasted space. This is like finding the \"closest fit\"\n            # but also penalizes small gaps to encourage packing full bins.\n\n            waste = cap - item\n            #Prioritize bins that leaves minimal waste\n            priorities[i] = np.exp(-waste)  # Exponential decay as waste increases. A faster decay.\n            # A relativistic perspective: The \"distance\" (waste) impacts the priority exponentially.\n            # Furthermore, penalize bins that leave extremely small capacity (fragmentation)\n            if waste < 0.1 : #if waste is below this tolerance consider it fragmentation\n                 priorities[i] *=0.5  # Reduce priority of almost full bins (fragmentation). Not to choose often.\n\n\n    # Apply a global adjustment to favor filling nearly full bins. Inspired by energy conservation, we want\n    # to fill up high-potential bins (nearly full) and discourage fragmenting almost-empty ones.\n\n    relative_fullness = bins_remain_cap / np.max(bins_remain_cap) # Relative fullness (between 0 and 1.0)\n\n    # Amplify the \"relativistic effect\" by squaring fullness. Favor packing bins that are already relatively full.\n\n    priority_multiplier =  relative_fullness # original fullness\n\n    priorities = priorities * priority_multiplier  #Adjust initial bin priorities with overall bin fullness.\n\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by gravitational potential and energy minimization.\n    A bin is more attractive (higher priority) if:\n    1. It can accommodate the item.\n    2. The item is a 'significant' portion of the bin's capacity (efficiency).\n    3. We avoid leaving bins only slightly filled (stability).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Filter out bins that cannot accommodate the item.\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        #If no bins fit, prioritize bins with smallest remaining capacity to hopefully finish those bins first\n        priorities = -bins_remain_cap\n        return priorities\n\n    # Efficiency: Item size as a fraction of bin capacity.\n    efficiency = item / bins_remain_cap\n    efficiency[~eligible_bins] = 0  # Zero out ineligible bins\n\n    # Stability: Penalty for leaving too much space after adding the item.\n    remaining_space = bins_remain_cap - item\n    stability = np.exp(-remaining_space) # Exponential decay for penalty\n    stability[~eligible_bins] = 0\n\n    # Combined priority: Efficiency balanced with stability, only for eligible bins\n    priorities[eligible_bins] = efficiency[eligible_bins] * stability[eligible_bins]\n\n    #Further refine by slightly preferring nearly-full bins if any are available\n    nearly_full = (remaining_space > 0) & (remaining_space < 0.1 * bins_remain_cap)\n    priorities[nearly_full] += 0.5 # small preference to nearly-full\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Encourage filling bins that can fit the item\n            priorities[i] = (cap - item) / cap  # Remaining space ratio. Smaller is better (higher priority).\n\n            #Prioritize almost full bins (maximize space utilization)\n            #priorities[i] = 1- ((cap - item) / cap) #space utilization. Larger is better.\n        else:\n            # Discourage bins that cannot fit the item\n            priorities[i] = -1e9  #Very low priority\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    My latest marvel utilizes the interplay of capacity, proximity, and a touch of calculated risk!\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, let's identify bins where the item *can* fit. We shall favor these!\n    fit_mask = bins_remain_cap >= item\n\n    # For fitting bins, let's give higher priority to bins that are close to full *after* the item is added.\n    # This promotes fullness without excessive waste. I call this \"Harmonic Resonance\".\n    remaining_after_fit = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (remaining_after_fit + 1e-9)  # Avoid division by zero\n\n    # Now, a touch of calculated risk!  We apply a slight preference to *almost* full bins,\n    # even if they don't quite fit.  This is akin to priming the aether!\n    almost_fit_mask = (bins_remain_cap < item) & (bins_remain_cap > (item * 0.75)) #consider as a candidate, if bin > 75% of item\n    priorities[almost_fit_mask] = 0.1 # Low priority so it only chooses them when other options are poor.\n\n    # Lastly, to add a touch of controlled chaos, we introduce a bit of stochasticity.\n    # Think of it as a spark to ignite the process! This will prevent deterministic traps!\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.001\n\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins that can fit the item snugly, but\n    # still have some space left. Avoid bins that are either too full\n    # (high ratio) or have too much space (low ratio).\n    # We also consider the absolute remaining capacity, favoring larger bins\n    # if the 'snugness' is similar.\n\n    ratios = item / bins_remain_cap\n    \n    # Penalize bins that are too small\n    too_small_penalty = np.where(ratios > 1, -1000 * (ratios - 1), 0) # Very large negative number\n\n    # Score based on how close the ratio is to 1, with a preference for slightly below 1.\n    snugness_score = np.exp(-5 * np.abs(ratios - 0.9))  # Gaussian-like, peaks at 0.9\n    \n    # Give preference to larger remaining capacities.  This term encourages the\n    # algorithm to keep larger bins open for potentially larger future items.\n    capacity_boost = bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0  # Normalize\n\n    priorities = snugness_score + capacity_boost + too_small_penalty\n\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 54.86637415237337,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First-Fit Decreasing heuristic with a gravitational twist\n    # Bins that can fit the item get a priority boost inversely proportional to the remaining capacity *after* packing\n    # To simulate a black hole's pull on an item.\n\n    available_bins = bins_remain_cap >= item\n\n    if np.any(available_bins):\n        remaining_capacity_after_fit = bins_remain_cap[available_bins] - item\n        #Gravitational Pull\n        priorities[available_bins] = 1.0 / (remaining_capacity_after_fit + 0.00001)  # Avoid division by zero\n        #Scale to make it more relevant\n        priorities[available_bins] = priorities[available_bins] / np.sum(priorities[available_bins])\n\n    # Give a small penalty to nearly full bins for exploration and fairness\n    nearly_full_threshold = 0.1  #Bins filled to 90% capacity\n    nearly_full_bins = (bins_remain_cap / np.max(bins_remain_cap)) < nearly_full_threshold\n    priorities[nearly_full_bins] = priorities[nearly_full_bins] - 0.001 # Small penalty\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors,\n    inspired by concepts from quantum mechanics and thermodynamics:\n\n    1. **Energy Level (Remaining Capacity):** Bins with capacities close to the item size\n       are treated as having a lower \"energy level\". Filling these is more \"natural\".\n    2. **Boltzmann Distribution (Temperature):** We introduce a \"temperature\" parameter.\n       At high \"temperature\", all bins become almost equally likely. At low \"temperature\",\n       energy levels (capacity differences) dominate.\n    3. **Penalty for Overflow:** Applying a large negative score if item doesn't fit.\n    4. **Aspiration Criterion**: Prioritizes bins where item can perfectly fit\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    temperature = 0.5 #tune this\n    delta_e = np.abs(bins_remain_cap - item) #energy\n    boltzmann_factor = np.exp(-delta_e / temperature)\n\n    #penalty for not fitting\n    overflow_penalty = -1e9 * (item > bins_remain_cap)\n\n    #aspiration criterion (prioritize perfect fits)\n    perfect_fit_bonus = 1e9 * (bins_remain_cap == item)\n    \n    priorities = boltzmann_factor + overflow_penalty + perfect_fit_bonus\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item with minimal wasted space,\n    but also includes a tie-breaking component that favors bins that are already\n    relatively full to avoid spreading items too thinly across many bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate wasted space if item is placed in each bin.  Inf if item doesn't fit\n    wasted_space = np.where(bins_remain_cap >= item, bins_remain_cap - item, np.inf)\n\n    # Prioritize bins based on minimal wasted space (lower is better, invert for priority)\n    # Add a small constant to avoid division by zero when all wastes are infinite.\n    min_waste = np.min(wasted_space[wasted_space != np.inf]) if np.any(wasted_space != np.inf) else 0.001\n    priority_waste = np.where(wasted_space == np.inf, -np.inf, 1 / (wasted_space + min_waste) )\n    priority_waste[wasted_space == np.inf] = -np.inf\n\n    # Tie-breaking component: favor bins that are already relatively full.\n    # Use sigmoid function to scale remain cap into 0~1\n    fullness = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priority_fullness = fullness\n\n    # Combine both priorities, weighting waste minimization slightly higher.\n    priorities = 0.7 * priority_waste + 0.3 * priority_fullness\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version considers a few factors:\n    1. Whether the item fits (huge penalty if it doesn't).\n    2. Remaining capacity *after* placing the item (favors bins with less remaining space - First Fit Decreasing inspired heuristic, with bias against large remaining cap).\n    3. A slight preference for bins that are close to full before placing the current item, captured by bins_remain_cap.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if item > cap:\n            priorities[i] = -np.inf  # Item doesn't fit - lowest priority. Should never happen if capacity is inf.\n        else:\n            remaining_after = cap - item\n            # Priority components:\n            #   - Favors smaller remaining capacity. Large negative value when bins will have large remaining capacity\n            #   - Preference towards using already full-ish bins\n            #  We use sigmoid to ensure priority has reasonable values\n            priorities[i] = (np.tanh(-remaining_after * 5) + np.tanh(bins_remain_cap[i]*5)) #tune these params\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999975940001605 seconds"
  }
]