[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n    \n    # 2. Maximize bin utilization: Prefer bins where the item fills a large portion\n    # of the remaining capacity, but not too large that it creates near-empty bins\n    # with the next item.\n    \n    # Fill ratio: item size / remaining capacity. Higher is better, but should be < 1.\n    fill_ratios = item / bins_remain_cap\n    \n    # Residual capacity after placing item\n    residual_capacity = bins_remain_cap - item\n    \n    # Relative residual capacity compared to item size. We want it large enough\n    # that we will likely fill it with some other item.\n    relative_residual = residual_capacity / item\n\n    # Score based on fill ratio, penalized if near-full or too empty after insertion.\n    # Scale by 1 / (1+abs(relative_residual-target)), where target = ideal value (say, 0.5 or 1)\n    target_relative_residual = 0.75\n    priorities[~infeasible_bins] = fill_ratios[~infeasible_bins] / (1 + np.abs(relative_residual[~infeasible_bins] - target_relative_residual))\n    \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * 1e-9\n\n    return priorities",
    "response_id": 10,
    "tryHS": true,
    "obj": 3.819305943358592,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 72.33974351909447,
    "mi": 73.23053449813924,
    "token_count": 123.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of v0 and v1. Balances fill, waste, feasibility.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    feasible_bins = bins_remain_cap >= item\n    \n    #Almost Full Bins\n    almost_full_threshold = 0.95\n    almost_full_bins = (bins_remain_cap - item) / bins_remain_cap < (1-almost_full_threshold)\n    priorities[feasible_bins & almost_full_bins] = 1000\n    \n    #Low Waste Bins\n    low_waste_bins = (bins_remain_cap - item) / np.max(bins_remain_cap) < 0.1\n    priorities[feasible_bins & low_waste_bins] = 500\n\n    # Capacity Difference\n    capacity_diff = np.abs(bins_remain_cap - item)\n    priorities[feasible_bins] = 100 - (capacity_diff[feasible_bins] / np.max(bins_remain_cap)) * 50\n\n    # Non-empty nudge\n    non_empty_bins = bins_remain_cap < np.max(bins_remain_cap)\n    priorities[feasible_bins & non_empty_bins] += 5\n\n    # Infeasible penalty\n    priorities[~feasible_bins] = -1000\n    \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 158.64271242790093,
    "mi": 88.4718950136701,
    "token_count": 150.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # 2.  First-Fit Decreasing inspired: Prioritize bins that can accommodate the item\n    #     with minimal waste.  Avoid creating very small remaining spaces if possible.\n\n    # Waste: Remaining capacity after placing the item.\n    waste = bins_remain_cap - item\n    waste[infeasible_bins] = np.inf  # Ensure infeasible bins are penalized\n\n    # Normalized Waste: Waste relative to the item size and bin size.\n    normalized_waste_item = waste / item\n    normalized_waste_bin = waste / bins_remain_cap\n\n    # Penalty for too small waste (encourages filling bins reasonably)\n    small_waste_penalty = np.exp(-normalized_waste_item)  # Exponential penalty for small waste\n\n    # Reward for filling the bin well.  A higher fill ratio is generally better.\n    fill_ratio = item / bins_remain_cap\n    fill_reward = fill_ratio\n\n    # Combine the factors: Prioritize based on fill ratio, penalized by small waste\n    priorities[~infeasible_bins] = fill_reward[~infeasible_bins] - 0.5 * small_waste_penalty[~infeasible_bins]\n\n    # Bonus:  Slightly prioritize bins closer to full if other factors are equal.\n    # This helps close out bins more quickly. Only apply if not infeasible.\n    priorities[~infeasible_bins] += 0.1 * (1 - normalized_waste_bin[~infeasible_bins])\n        \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * 1e-9\n\n    return priorities",
    "response_id": 1,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 23.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 271.8519998980832,
    "mi": 77.63257112773547,
    "token_count": 228.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_hs4.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, target_relative_residual: float = 0.8490339139952625, random_priority_scale: float = 7.594919713500124e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        target_relative_residual: Ideal relative residual capacity after placing item.\n        random_priority_scale: Scale of random constant added to priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n    \n    # 2. Maximize bin utilization: Prefer bins where the item fills a large portion\n    # of the remaining capacity, but not too large that it creates near-empty bins\n    # with the next item.\n    \n    # Fill ratio: item size / remaining capacity. Higher is better, but should be < 1.\n    fill_ratios = item / bins_remain_cap\n    \n    # Residual capacity after placing item\n    residual_capacity = bins_remain_cap - item\n    \n    # Relative residual capacity compared to item size. We want it large enough\n    # that we will likely fill it with some other item.\n    relative_residual = residual_capacity / item\n\n    # Score based on fill ratio, penalized if near-full or too empty after insertion.\n    # Scale by 1 / (1+abs(relative_residual-target)), where target = ideal value (say, 0.5 or 1)\n    priorities[~infeasible_bins] = fill_ratios[~infeasible_bins] / (1 + np.abs(relative_residual[~infeasible_bins] - target_relative_residual))\n    \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * random_priority_scale\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 3.560031910650184,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 156.0801066523054,
    "mi": 67.92126112677907,
    "token_count": 161.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, residual capacity target, and low waste.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    # 1. Infeasible penalty\n    priorities[~feasible_bins] = -np.inf\n\n    # 2. Fill ratio with residual target\n    fill_ratios = item / bins_remain_cap\n    residual_capacity = bins_remain_cap - item\n    target_relative_residual = 0.75\n    relative_residual = residual_capacity / item\n    priorities[feasible_bins] = fill_ratios[feasible_bins] / (1 + np.abs(relative_residual[feasible_bins] - target_relative_residual))\n\n    # 3. Low waste bonus\n    low_waste_threshold = 0.1\n    low_waste_bins = (bins_remain_cap - item) / np.max(bins_remain_cap) < low_waste_threshold\n    priorities[feasible_bins & low_waste_bins] += 0.1  # Add a bonus for low waste\n\n    # 4. Small random number for tie-breaking\n    priorities += np.random.rand(len(bins_remain_cap)) * 1e-9\n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 3.8691663342640563,
    "SLOC": 14.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 223.46712577586834,
    "mi": 86.33196572343152,
    "token_count": 164.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, target_relative_residual: float = 0.75, random_priority_scale: float = 0.01, aggressive_fill: bool = False, capacity_threshold: float = 0.2) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces adaptive elements:\n    - `aggressive_fill`: If True, prioritizes filling bins closer to full when sufficient capacity remains.\n    - `capacity_threshold`: If bins have low remaining capacity, focus on filling them completely.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        target_relative_residual: Ideal relative residual capacity after placing item.\n        random_priority_scale: Scale of random constant added to priorities.\n        aggressive_fill: Whether to prioritize bins that are close to full.\n        capacity_threshold: Threshold below which filling a bin takes highest priority.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # 2. Prioritize bins with very low capacity to encourage completion.\n    low_capacity_bins = bins_remain_cap < capacity_threshold\n    if np.any(low_capacity_bins):\n        priorities[low_capacity_bins] = 10  # High priority to fill these.\n\n    # 3. Maximize bin utilization: Prefer bins where the item fills a large portion\n    # of the remaining capacity, but not too large that it creates near-empty bins\n    # with the next item.\n    \n    # Fill ratio: item size / remaining capacity. Higher is better, but should be < 1.\n    fill_ratios = item / bins_remain_cap\n    \n    # Residual capacity after placing item\n    residual_capacity = bins_remain_cap - item\n    \n    # Relative residual capacity compared to item size. We want it large enough\n    # that we will likely fill it with some other item.\n    relative_residual = residual_capacity / item\n\n    # Score based on fill ratio, penalized if near-full or too empty after insertion.\n    # Scale by 1 / (1+abs(relative_residual-target)), where target = ideal value (say, 0.5 or 1)\n    priorities[~infeasible_bins & ~low_capacity_bins] = fill_ratios[~infeasible_bins & ~low_capacity_bins] / (1 + np.abs(relative_residual[~infeasible_bins & ~low_capacity_bins] - target_relative_residual))\n\n    # 4. Aggressive Fill: Give a boost to bins that are already relatively full\n    #    This encourages using partially filled bins over empty ones (when applicable)\n    if aggressive_fill:\n        fullness = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Normalize to bin size.\n        priorities[~infeasible_bins & ~low_capacity_bins] += fullness[~infeasible_bins & ~low_capacity_bins] * 0.5\n\n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * random_priority_scale\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 3.9090546469884373,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 320.0,
    "mi": 69.07555851426481,
    "token_count": 237.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_hs4.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, waste_penalty_weight: float = 0.898487989707919,\n                fullness_bonus_weight: float = 0.2013748833676067, noise_level: float = 2.0819988765816894e-09) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_penalty_weight: Weight of the small waste penalty.\n        fullness_bonus_weight: Weight of the bonus for bins closer to full.\n        noise_level: Magnitude of the random noise added to priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility check: Assign -inf priority if the item doesn't fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # 2.  First-Fit Decreasing inspired: Prioritize bins that can accommodate the item\n    #     with minimal waste.  Avoid creating very small remaining spaces if possible.\n\n    # Waste: Remaining capacity after placing the item.\n    waste = bins_remain_cap - item\n    waste[infeasible_bins] = np.inf  # Ensure infeasible bins are penalized\n\n    # Normalized Waste: Waste relative to the item size and bin size.\n    normalized_waste_item = waste / item\n    normalized_waste_bin = waste / bins_remain_cap\n\n    # Penalty for too small waste (encourages filling bins reasonably)\n    small_waste_penalty = np.exp(-normalized_waste_item)  # Exponential penalty for small waste\n\n    # Reward for filling the bin well.  A higher fill ratio is generally better.\n    fill_ratio = item / bins_remain_cap\n    fill_reward = fill_ratio\n\n    # Combine the factors: Prioritize based on fill ratio, penalized by small waste\n    priorities[~infeasible_bins] = fill_reward[~infeasible_bins] - waste_penalty_weight * small_waste_penalty[~infeasible_bins]\n\n    # Bonus:  Slightly prioritize bins closer to full if other factors are equal.\n    # This helps close out bins more quickly. Only apply if not infeasible.\n    priorities[~infeasible_bins] += fullness_bonus_weight * (1 - normalized_waste_bin[~infeasible_bins])\n        \n    # Add small constant to avoid identical priorities and encourage some differentiation.\n    priorities += np.random.rand(len(bins_remain_cap)) * noise_level\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 2.0841643398484337,
    "SLOC": 16.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 237.74437510817344,
    "mi": 74.82529106897069,
    "token_count": 210.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, waste, and residual target, adapts bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    # 1. Infeasible penalty\n    priorities[~feasible_bins] = -np.inf\n\n    # 2. Fill ratio with residual target\n    fill_ratios = item / bins_remain_cap\n    residual_capacity = bins_remain_cap - item\n    target_relative_residual = 0.75\n    relative_residual = residual_capacity / item\n    priorities[feasible_bins] = fill_ratios[feasible_bins] / (1 + np.abs(relative_residual[feasible_bins] - target_relative_residual))\n\n    # 3. Low waste bonus (adaptive)\n    waste = bins_remain_cap - item\n    normalized_waste_bin = waste / bins_remain_cap\n    low_waste_threshold = 0.1\n    low_waste_bins = normalized_waste_bin < low_waste_threshold\n    \n    # Adaptive bonus: Larger bonus when bins are closer to full.\n    bonus_scale = 0.2 * (1 - normalized_waste_bin)\n    priorities[feasible_bins & low_waste_bins] += bonus_scale[feasible_bins & low_waste_bins]\n\n    # 4. Small random number for tie-breaking\n    priorities += np.random.rand(len(bins_remain_cap)) * 1e-9\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 3.8791384124451627,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 333.4033961014228,
    "mi": 78.0781337288105,
    "token_count": 179.0,
    "exec_success": true
  }
]