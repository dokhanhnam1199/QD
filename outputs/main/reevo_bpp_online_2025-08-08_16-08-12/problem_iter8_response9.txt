```python
import numpy as np

def softmax(x):
    """Compute softmax values for each set of scores in x."""
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum(axis=0)

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin.

    This heuristic prioritizes bins that can fit the item. Among those that fit,
    it assigns a higher priority to bins that will have less remaining capacity
    after the item is placed (exploitation). It uses a softmax function to
    introduce a degree of exploration, where bins with good fits are more likely
    to be chosen but not guaranteed. The temperature parameter can be tuned to
    balance exploitation and exploration.

    This version refines the scoring for "near fits" to better differentiate
    between them, and also explicitly handles exact fits with a very high score
    before applying softmax to other near fits.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    fitting_bins_cap = bins_remain_cap[can_fit_mask]
    remaining_after_placement = fitting_bins_cap - item

    # Scores for bins that can fit the item
    scores = np.zeros_like(fitting_bins_cap, dtype=float)

    # Prioritize exact fits with a very high score
    exact_fit_indices = np.where(remaining_after_placement == 0)[0]
    scores[exact_fit_indices] = 1e9  # A very large score for exact fits

    # For near fits, we want to prioritize smaller remaining capacities.
    # We use a transformation that rewards smaller remainders more strongly.
    # A simple inverse can be sensitive to very small remainders.
    # A small negative score for remaining capacity can work,
    # or a score that penalizes larger remaining space.
    # Let's try to give a score that is proportional to how 'tight' the fit is,
    # but also differentiate near fits from exact fits.
    # We can use 1 / (remainder + epsilon) and add a bonus for exact fits.
    near_fit_indices = np.where(remaining_after_placement > 0)[0]
    if len(near_fit_indices) > 0:
        # Use inverse of remaining capacity. Add a small constant to avoid
        # huge values for tiny remainders and to slightly differentiate them.
        # A small positive score for near fits.
        scores[near_fit_indices] = 1.0 / (remaining_after_placement[near_fit_indices] + 0.1)

    # Ensure exact fits still dominate if they exist.
    # If there are exact fits, they have very high scores already.
    # If only near fits, softmax will operate on those scores.

    # Apply softmax to introduce exploration.
    # A moderate temperature to balance exploration/exploitation.
    temperature = 0.5
    if scores.size > 0:
        probabilities = softmax(scores / temperature)
        priorities[can_fit_mask] = probabilities
    # If there were no fitting bins, priorities remain 0, which is handled by the initial check.

    return priorities
```
