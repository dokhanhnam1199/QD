```python
import numpy as np
from scipy.special import softmax

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    This heuristic prioritizes exact fits first. For bins that do not offer
    an exact fit, it uses a scaled softmax on the inverse remaining capacity.
    This encourages tighter packing by giving higher priority to bins that
    will have less remaining space after the item is placed. The scaling factor
    adapts the exploration based on the number of available bins.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item

    # Calculate the remaining capacity if the item is placed in a fitting bin
    remaining_after_placement = bins_remain_cap[can_fit_mask] - item

    # Prioritize exact fits
    exact_fit_mask = np.isclose(remaining_after_placement, 0.0)
    priorities[can_fit_mask][exact_fit_mask] = 1.0

    # For near fits, use scaled softmax on inverse remaining capacity
    near_fit_mask = ~exact_fit_mask
    if np.any(can_fit_mask[can_fit_mask][near_fit_mask]):
        near_fit_remaining = remaining_after_placement[near_fit_mask]
        
        # Inverse remaining capacity, higher value for smaller remaining capacity
        # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0
        inverse_remaining = 1.0 / (near_fit_remaining + 1e-9)

        # Scale the scores to make the highest score more prominent, especially with fewer bins
        # A simple scaling could be to multiply by the number of bins that can fit the item
        # or a function of it to encourage exploration on more options when many are available.
        # Here, we use a simple scaling based on the number of fitting bins to adjust exploration.
        # A larger number of fitting bins might warrant a slightly wider spread in priorities.
        # Alternatively, a fixed scaling factor can be used, but dynamic scaling can be more adaptive.
        # Let's use a scaling factor that is inversely proportional to the number of fitting bins to keep priorities
        # from becoming too extreme when many options exist.
        num_fitting_bins = np.sum(can_fit_mask)
        if num_fitting_bins > 0:
            scaling_factor = 1.0  # Keep a baseline, can be tuned
            # For more aggressive exploration, a factor like np.log(num_fitting_bins + 1)
            # For more conservative, like 1/num_fitting_bins
            
            scaled_scores = inverse_remaining * scaling_factor
            
            # Apply softmax to get probabilities, which are used as priorities
            # Softmax naturally handles the relative differences.
            # We add a small constant to the logits to ensure that even if all inverse_remaining are very close,
            # there's still some differentiation.
            priorities[can_fit_mask][near_fit_mask] = softmax(scaled_scores)
        else:
             priorities[can_fit_mask][near_fit_mask] = 0.0 # Should not happen if can_fit_mask is true

    return priorities
```
