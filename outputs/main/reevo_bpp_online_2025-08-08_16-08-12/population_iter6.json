[
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a best-fit approach with explicit prioritization of exact fits and exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it first gives the highest priority to exact fits. For bins that are not\n    exact fits but can accommodate the item, it assigns priority based on\n    how much remaining capacity is left, favoring smaller remaining capacities.\n    To encourage exploration, a soft constraint using a temperature parameter\n    is applied to the non-exact fits, allowing bins with slightly more remaining\n    capacity a chance to be selected.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign highest priority to exact fits.\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    priorities[can_fit_mask][exact_fit_mask_subset] = 100.0\n\n    # For bins that fit but are not exact fits, assign priorities.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    if np.any(near_fit_mask_subset):\n        near_fit_priorities_raw = remaining_after_placement[near_fit_mask_subset]\n        \n        # Apply a transformation to favor smaller remaining capacities (closer to zero).\n        # Using negative of remaining capacity means smaller remaining capacity gets higher raw priority.\n        # Add a small epsilon to avoid issues with zero remaining capacity if it wasn't caught as exact fit\n        # (though the exact_fit_mask_subset should handle this).\n        transformed_priorities = -near_fit_priorities_raw - 1e-9 \n\n        # Apply softmax for exploration.\n        # Higher temperature means more exploration.\n        temperature = 1.0\n        \n        # Normalize for softmax to avoid overflow/underflow and ensure numerical stability\n        # Subtracting max makes the largest value 0, exp(0) = 1.\n        if np.any(transformed_priorities):\n            normalized_transformed_priorities = transformed_priorities - np.max(transformed_priorities)\n            soft_priorities = np.exp(normalized_transformed_priorities / temperature)\n            \n            # Scale soft_priorities to be less than the exact fit priority (100.0)\n            # and positive. The maximum possible value for soft_priorities is 1 (before scaling).\n            # We want these to be lower than 100, and positive.\n            # A simple scaling factor can work, or we can ensure they are just below 100.\n            # Let's scale them such that the best near-fit is slightly less than exact fit.\n            # The current max value of soft_priorities is 1.0.\n            # We can scale it by a factor less than 100, e.g., 99.\n            scale_factor = 99.0\n            soft_priorities_scaled = soft_priorities * scale_factor\n\n            priorities[can_fit_mask][near_fit_mask_subset] = soft_priorities_scaled\n        else:\n            # If somehow no near fits had valid transformed priorities (highly unlikely with -inf initialization)\n            pass # Keep them at -inf or handle as an error case if necessary.\n\n    return priorities",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 23.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using a refined \"Best Fit\" heuristic, with a mild exploration component.\n\n    This heuristic aims to find the bin that, after placing the item, will have the\n    least remaining capacity (i.e., the tightest fit) among all bins that can\n    accommodate the item. It prioritizes bins that are closer to being full.\n    An exact fit (remaining capacity == item size) is implicitly handled as\n    it results in zero remaining capacity, which is the minimum possible.\n\n    The priority is calculated as:\n    - For bins that can fit the item: A score that rewards tighter fits.\n      Specifically, `-(bins_remain_cap - item)` is used, which means bins with\n      less remaining capacity after placing the item get higher scores.\n      A small penalty is added for bins that leave a *very* small positive remainder\n      to slightly encourage exploration if the best fit is only marginally better\n      than another option.\n    - For bins that cannot fit the item: A priority of negative infinity to ensure\n      they are never selected.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    epsilon = 1e-6  # Small constant to slightly penalize near-zero remainders\n\n    # Identify bins that have enough capacity to fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after packing\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities. Higher priority for smaller remaining capacity (tighter fit).\n    # We use the negative of the remaining capacity.\n    # A small epsilon is added to the remaining capacity before negation to slightly\n    # discourage extremely tight fits when there are other good options, promoting\n    # a mild form of exploration by making slightly looser fits appear more attractive\n    # if the difference is negligible.\n    # The primary goal is still best fit, but this adds a slight nudge.\n    priorities[can_fit_mask] = -(remaining_capacities_after_fit + epsilon)\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority for each bin to pack an item.\n    Prioritizes exact fits, then near fits.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot fit the item\n        will have a very low priority.\n    \"\"\"\n    # Initialize priorities to a very low value.\n    priorities = np.full_like(bins_remain_cap, -float('inf'))\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate potential remaining capacities for bins that can fit the item.\n    potential_remainders = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priority:\n    # 1. Exact fits (remainder is 0) get the highest priority.\n    # 2. Near fits (smaller positive remainder) get higher priority than larger remainders.\n    # We can achieve this by assigning a high value for exact fits and then\n    # using the negative of the remainder for near fits, so smaller remainders\n    # (less negative values) get higher priority.\n\n    # For exact fits\n    exact_fit_indices = np.where(potential_remainders == 0)[0]\n    if len(exact_fit_indices) > 0:\n        priorities[can_fit_mask][exact_fit_indices] = 100.0  # High priority for exact fits\n\n    # For near fits\n    near_fit_indices = np.where(potential_remainders > 0)[0]\n    if len(near_fit_indices) > 0:\n        # Assign priorities based on the negative of the remainder.\n        # This means smaller remainders get higher (less negative) scores.\n        priorities[can_fit_mask][near_fit_indices] = -potential_remainders[near_fit_indices]\n\n    return priorities",
    "response_id": 2,
    "obj": 4.487435181491823,
    "SLOC": 13.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a strategy that prioritizes exact fits, then near fits, and incorporates exploration.\n\n    This strategy prioritizes exact fits (leaving zero remaining capacity).\n    Among bins that can accommodate the item but are not exact fits, it prioritizes\n    those that leave the least remaining capacity (best-fit approach).\n    To encourage exploration, a softmax function is applied to the priorities of\n    near-fitting bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Handle exact fits\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    exact_fit_indices = np.where(can_fit_mask)[0][exact_fit_mask_subset]\n    priorities[exact_fit_indices] = 100.0  # High priority for exact fits\n\n    # Handle near fits\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    if np.any(near_fit_mask_subset):\n        near_fit_indices_subset = np.where(can_fit_mask)[0][near_fit_mask_subset]\n        near_fit_remaining = remaining_after_placement[near_fit_mask_subset]\n\n        # Base priority for near fits: prioritize smaller remaining capacity.\n        # Using negative remaining capacity to make smaller remaining capacity have higher score.\n        # Add a small epsilon to avoid issues with identical remaining capacities and for stability.\n        near_fit_base_priorities = -near_fit_remaining\n\n        # Apply softmax to the base priorities of near fits for exploration.\n        # Softmax converts scores into probabilities, giving a chance to bins with slightly more remaining space.\n        temperature = 1.0  # Tunable parameter for exploration\n        \n        # Shift priorities to avoid large negative exponents in exp\n        shifted_near_fit_priorities = near_fit_base_priorities - np.max(near_fit_base_priorities)\n        \n        # Calculate softmax probabilities\n        exp_priorities = np.exp(shifted_near_fit_priorities / temperature)\n        \n        # Normalize probabilities to sum to 1 across the near-fitting bins\n        sum_exp_priorities = np.sum(exp_priorities)\n        if sum_exp_priorities > 0:\n            softmax_probabilities = exp_priorities / sum_exp_priorities\n        else:\n            # If all exponents are effectively zero or negative infinity, assign uniform probability\n            softmax_probabilities = np.ones_like(exp_priorities) / len(exp_priorities)\n\n        # Assign these probabilities (scaled to still be lower than exact fits) to the priority array\n        # We can scale them down or add a constant to ensure they are less than the exact fit priority.\n        # For simplicity, let's scale them by a factor less than 1, but larger than the penalty for non-exact fits.\n        # The goal is that exact fits are still distinctly preferred, but exploration happens among near fits.\n        # We can map the probabilities to a range like [50, 99] for example.\n        scaled_near_fit_priorities = 50.0 + softmax_probabilities * 49.0 # Scale probabilities to a range below exact fits\n        \n        priorities[near_fit_indices_subset] = scaled_near_fit_priorities\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 26.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a\n    strategy that prioritizes exact fits and then uses softmax for exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (closer to an exact fit). It then applies a\n    softmax function to these priorities to balance exploration and exploitation,\n    allowing for a chance to pack items into bins that are not the absolute best fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Small value to avoid division by zero\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin.\n    # We want to prioritize bins that leave *less* remaining capacity.\n    # Therefore, the \"quality\" of a fit is inversely related to the remaining capacity.\n    # A small positive remainder is good. A negative remainder means it doesn't fit.\n    # To use softmax, we need positive values. A simple way is to use the\n    # inverse of the remaining capacity plus a small constant for stability.\n    # Alternatively, we can use the negative of the remaining capacity and\n    # adjust the softmax interpretation.\n    # Let's stick to the idea of inverse remaining capacity for now.\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # We want to maximize the \"goodness\" of the fit. A smaller remainder is better.\n    # The score should reflect this: higher score for smaller remainders.\n    # A common approach is 1 / (remainder + epsilon).\n    # We'll scale these scores before applying softmax to control the spread.\n    fit_scores = 1.0 / (remaining_after_placement + epsilon)\n\n    # Scale scores to prevent very large or small exponents in softmax.\n    # A simple normalization can be dividing by the maximum score among fitting bins.\n    max_fit_score = np.max(fit_scores) if fit_scores.size > 0 else 1.0\n    if max_fit_score > epsilon: # Avoid division by zero if all fit_scores are ~0\n        scaled_fit_scores = fit_scores / max_fit_score\n    else:\n        scaled_fit_scores = np.ones_like(fit_scores) # If all scores are negligible, treat them equally\n\n    # Apply softmax. This converts scores into probabilities, balancing exploration\n    # (more uniform probabilities) and exploitation (probabilities concentrated on high scores).\n    # A temperature parameter could be introduced for more fine-grained control,\n    # but here we use a standard softmax.\n    exp_scores = np.exp(scaled_fit_scores)\n    sum_exp_scores = np.sum(exp_scores)\n\n    if sum_exp_scores > epsilon:\n        probabilities = exp_scores / sum_exp_scores\n    else:\n        # This case should be rare with the scaling, but for safety,\n        # assign uniform probabilities if the sum is too small.\n        probabilities = np.ones_like(fit_scores) / len(fit_scores)\n\n    # Assign these probabilities as priorities to the bins that can fit the item.\n    priorities[can_fit_mask] = probabilities\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response5.txt_stdout.txt",
    "code_path": "problem_iter6_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin, prioritizing Exact Fit, then Best Fit,\n    with a small exploration component favoring bins with larger remaining capacity.\n\n    This heuristic prioritizes bins that offer an exact fit for the item.\n    If no exact fit is available, it then prioritizes bins that can accommodate the item\n    with the smallest remaining capacity (Best Fit approach among the remaining options).\n    As a secondary exploration, it slightly boosts bins that have a larger remaining capacity,\n    aiming to keep more space available for potentially larger future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Exact fits get the highest priority (e.g., 100). Bins that fit but not exactly\n        get a priority based on the \"tightness\" of the fit, inversely proportional to\n        the slack (remaining capacity - item size), with a slight bonus for larger remaining capacity.\n        Bins that cannot fit get 0 priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 0.05  # Probability of exploration based on remaining capacity\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    fitting_indices = np.where(can_fit_mask)[0]\n\n    if fitting_bins_capacities.size == 0:\n        return priorities  # No bin can fit the item\n\n    # Calculate slack for bins that can fit the item\n    slacks = fitting_bins_capacities - item\n\n    # Exact fit has the highest priority\n    exact_fit_mask = slacks == 0\n    exact_fit_indices = fitting_indices[exact_fit_mask]\n    priorities[exact_fit_indices] = 100.0\n\n    # For bins that are not an exact fit, assign priority based on the slack (Best Fit)\n    # and introduce a small exploration bonus for larger remaining capacity.\n    non_exact_fit_mask = slacks > 0\n    non_exact_fit_indices = fitting_indices[non_exact_fit_mask]\n    non_exact_slacks = slacks[non_exact_fit_mask]\n    non_exact_capacities = fitting_bins_capacities[non_exact_fit_mask]\n\n    if non_exact_fit_indices.size > 0:\n        # Sort these bins by slack in ascending order.\n        sorted_slack_indices = np.argsort(non_exact_slacks)\n\n        # Assign base priorities from highest (99) to lowest based on sorted slack\n        base_priorities = 99.0 - np.arange(non_exact_slacks.size)\n\n        # Introduce a small exploration bonus for bins with larger remaining capacity.\n        # This bonus is scaled by epsilon and the relative difference in capacity.\n        # We normalize capacities to avoid issues with very large numbers and to\n        # ensure the bonus is relative.\n        min_cap = np.min(non_exact_capacities)\n        max_cap = np.max(non_exact_capacities)\n        \n        exploration_bonus = np.zeros(non_exact_slacks.size)\n        if max_cap > min_cap: # Avoid division by zero if all non-exact fits have the same capacity\n            normalized_capacities = (non_exact_capacities - min_cap) / (max_cap - min_cap)\n            # Small bonus for higher capacity, scaled by epsilon\n            exploration_bonus = epsilon * normalized_capacities\n\n        # Combine base priority and exploration bonus\n        combined_priorities = base_priorities + exploration_bonus\n\n        # Assign combined priorities\n        priorities[non_exact_fit_indices[sorted_slack_indices]] = combined_priorities\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 28.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response6.txt_stdout.txt",
    "code_path": "problem_iter6_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using a combination of \"Best Fit\" (exploitation) and a\n    penalty for bins that are too empty (exploration component).\n\n    This heuristic aims to:\n    1. Exploit: Prioritize bins that provide a \"tight fit\" for the current item.\n       This is achieved by favoring bins where the remaining capacity after\n       placing the item is minimized (closest to zero).\n    2. Explore: Slightly penalize bins that have a large amount of remaining\n       capacity even before placing the item. This encourages using bins that\n       are already somewhat full, potentially leaving the emptier bins for\n       future larger items.\n\n    The priority is calculated as:\n    - For bins that can fit the item:\n      The score is derived from the remaining capacity after fitting.\n      A tight fit (small `bins_remain_cap - item`) yields a higher score.\n      The score is designed such that a tight fit gets a high positive value,\n      and a loose fit gets a lower value.\n    - For bins that cannot fit the item: A priority of negative infinity.\n\n    A penalty is applied to bins that are \"too empty\" to encourage using\n    bins that are already partially filled.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity after placing the item for bins that can fit.\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate a base \"best fit\" score. Higher score for smaller remaining capacity.\n    # We use the negative of the remaining capacity. Smaller remaining capacity means\n    # a larger negative number, which we want to be higher priority.\n    # Example:\n    # Bin A: remaining_cap = 10, item = 7 -> remaining_after_fit = 3. Score = -3.\n    # Bin B: remaining_cap = 8, item = 7 -> remaining_after_fit = 1. Score = -1.\n    # Bin B is a tighter fit and has a higher score.\n    best_fit_scores = -remaining_capacities_after_fit\n\n    # Introduce an exploration penalty for bins that are too empty.\n    # This encourages using bins that are already somewhat occupied.\n    # We can define \"too empty\" as having a remaining capacity significantly larger\n    # than the item itself, or simply a very large absolute capacity.\n    # A simple penalty: subtract a value proportional to the original remaining capacity.\n    # This makes bins with large remaining capacity less attractive.\n    # We only apply this penalty to bins that can fit the item.\n    # The penalty should be smaller for bins that are already a tight fit.\n    # Let's define a 'emptiness_penalty' that is higher for bins with higher initial capacity.\n    # We can use a logarithmic scale or a simple linear scale, scaled to not overwhelm best_fit_scores.\n    # A common approach is to penalize bins with lots of unused space.\n    # Let's consider the \"slack\" or unused capacity if we were to fill the bin as much as possible.\n    # However, for online BPP, we only care about the remaining capacity.\n    # Let's penalize bins that have remaining_capacities_after_fit that are still large.\n    # Or even simpler, penalize based on the original bin capacity if it's much larger than the item.\n    # A simple approach: penalize the original `bins_remain_cap` itself.\n    # The penalty should be subtracted from the `best_fit_scores`.\n\n    # For bins that can fit:\n    # Score = (tight_fit_score) - (emptiness_penalty)\n    # tight_fit_score = -remaining_capacities_after_fit\n    # emptiness_penalty could be related to bins_remain_cap[can_fit_mask]\n\n    # Let's refine the scoring:\n    # We want to prioritize bins that have `bins_remain_cap - item` small and positive.\n    # The `priority_v1` did this well with `-remaining_capacities_after_fit`.\n    # Now, let's add the exploration: penalize bins that are \"too empty\".\n    # What if we define \"too empty\" as a bin whose remaining capacity is much larger than the item?\n    # Or a bin that has a lot of unused capacity relative to the bin's total capacity (if we knew it)?\n    # Since we only have `bins_remain_cap`, let's focus on that.\n    # A bin is \"too empty\" if `bins_remain_cap` is large.\n    # Let's subtract a portion of `bins_remain_cap` from the best-fit score.\n    # The larger `bins_remain_cap`, the larger the subtraction (more penalty).\n    # We need to be careful not to make the penalty too aggressive.\n    # A scaling factor might be needed.\n\n    # Let's consider a weighted sum:\n    # priority = w1 * (best_fit_score) + w2 * (exploration_score)\n    # where best_fit_score is high for tight fits, and exploration_score is low for empty bins.\n    # Or simply:\n    # priority = best_fit_score - penalty_for_emptiness\n\n    # A potential formula:\n    # priority = - (bins_remain_cap[i] - item) - alpha * bins_remain_cap[i]\n    # where alpha is a small positive constant to control the penalty.\n    # Let's try to combine these directly.\n    # We want to maximize `- (bins_remain_cap[i] - item)` (tight fit)\n    # and minimize `bins_remain_cap[i]` (avoid empty bins).\n    # So we want to maximize `-(bins_remain_cap[i] - item) - alpha * bins_remain_cap[i]`\n\n    alpha = 0.1  # Controls the penalty for empty bins. Adjust as needed.\n\n    # Calculate the combined score for bins that can fit.\n    # The first term promotes tight fits.\n    # The second term penalizes bins that are initially large (empty).\n    combined_scores = -remaining_capacities_after_fit - alpha * bins_remain_cap[can_fit_mask]\n\n    priorities[can_fit_mask] = combined_scores\n\n    # Ensure we don't have NaN or Inf from potential division by zero if alpha were in denominator etc.\n    # Our current formula is safe.\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response7.txt_stdout.txt",
    "code_path": "problem_iter6_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem using a hybrid approach\n    that balances \"Best Fit\" (exploitation) with a small chance of \"First Fit\"\n    or random choice among fitting bins (exploration).\n\n    The \"Best Fit\" component prioritizes bins that leave the least remaining\n    capacity after the item is placed. This is achieved by assigning a priority\n    that is the negative of the remaining capacity after fitting the item.\n    A tighter fit (smaller remaining capacity) results in a higher (less negative)\n    priority.\n\n    The exploration component is introduced to prevent getting stuck in local\n    optima. With a small probability (epsilon), it favors bins that are not\n    necessarily the best fit, by assigning a random priority among those that\n    can fit the item. This allows for exploring different packing configurations.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    epsilon = 0.05  # Probability of exploration\n    num_bins = len(bins_remain_cap)\n\n    # Initialize priorities to negative infinity for all bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity for bins that can fit the item\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # --- Exploitation Component (Best Fit) ---\n    # Assign priorities based on the tightness of the fit.\n    # The negative of the remaining capacity is used: smaller remaining capacity\n    # leads to a less negative (higher) priority.\n    exploitation_scores = np.full_like(bins_remain_cap, -np.inf)\n    exploitation_scores[can_fit_mask] = -remaining_capacities_after_fit\n\n    # --- Exploration Component ---\n    # Generate random scores for exploration among fitting bins.\n    # We want to give a chance to bins that might not be the \"best\" according to Best Fit.\n    # A simple approach is to assign a random value if exploration is chosen.\n    exploration_scores_random = np.random.rand(num_bins)\n\n    # Combine exploitation and exploration using an epsilon-greedy strategy.\n    # Generate a random choice for each bin: True for exploration, False for exploitation.\n    explore_choice_mask = np.random.rand(num_bins) < epsilon\n\n    # For bins where exploration is chosen AND they can fit the item, use the random score.\n    # For bins where exploitation is chosen AND they can fit the item, use the exploitation score.\n    # For bins that cannot fit, their priority remains -np.inf.\n    \n    # Create a mask for bins that are candidates for selection (can fit the item)\n    candidate_mask = can_fit_mask\n    \n    # Apply exploration choice: if exploration is chosen for a candidate bin, use its random score.\n    priorities[explore_choice_mask & candidate_mask] = exploration_scores_random[explore_choice_mask & candidate_mask]\n    \n    # Apply exploitation choice: if exploitation is chosen for a candidate bin, use its exploitation score.\n    # We only update if the bin was NOT chosen for exploration (or if exploration wasn't chosen for it).\n    # The condition `~explore_choice_mask` ensures we only apply exploitation if exploration wasn't picked.\n    priorities[~explore_choice_mask & candidate_mask] = exploitation_scores[~explore_choice_mask & candidate_mask]\n\n    # Ensure that bins that cannot fit remain at -np.inf\n    priorities[~can_fit_mask] = -np.inf\n\n    return priorities",
    "response_id": 7,
    "obj": 73.81332269644994,
    "SLOC": 15.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response8.txt_stdout.txt",
    "code_path": "problem_iter6_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin, prioritizing\n    minimal slack after placement while also slightly penalizing bins that\n    would become exactly full. This version aims to balance the greedy approach\n    of minimizing slack with a touch of exploration by slightly boosting bins\n    that are not the absolute best fit but still good candidates.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (minimal slack). This encourages denser packing.\n    A slight penalty is applied to bins that would become completely full,\n    encouraging leaving some space for potentially larger items. To introduce\n    a mild exploratory element, bins that result in a slightly larger, but still\n    good, remainder are given a small boost to avoid over-optimization on just\n    the smallest slack.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Base priority: prioritize bins with minimal slack.\n    # Higher score for smaller remainders. Add epsilon for numerical stability.\n    base_priorities = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Introduce a penalty for bins that would become exactly full.\n    # Subtract a small value to slightly reduce their priority.\n    penalty_for_full = 0.1\n    fully_filled_mask = (remaining_after_placement == 0)\n    priorities[can_fit_mask] = base_priorities\n    priorities[can_fit_mask][fully_filled_mask] -= penalty_for_full\n\n    # Add a small exploratory boost: slightly favor bins that have a small positive remainder,\n    # but not necessarily the absolute minimum. This can be achieved by adding a small\n    # positive value to the priority score for a range of remainders.\n    # For example, we can add a small constant to priorities where the remainder is small but not zero.\n    # We can define a threshold for \"small positive remainder\". Let's say up to 10% of bin capacity,\n    # but this is problem-dependent. For a general heuristic, let's add a small constant to\n    # all positive remainders (that are not exactly zero) as a slight encouragement.\n    # We can make this boost decay as the remainder increases.\n    # For simplicity here, let's add a constant boost to all non-exact fits.\n    # This is a very simple form of exploration.\n    exploratory_boost_value = 0.05\n    not_fully_filled_mask = ~fully_filled_mask\n    priorities[can_fit_mask][not_fully_filled_mask] += exploratory_boost_value\n\n    # Ensure all priorities are non-negative.\n    priorities = np.clip(priorities, 0, None)\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response9.txt_stdout.txt",
    "code_path": "problem_iter6_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin, prioritizing\n    minimal slack after placement while also slightly penalizing bins that\n    would become exactly full to maintain flexibility.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (minimal slack). This encourages denser packing.\n    Additionally, it slightly penalizes bins that would become completely full\n    to encourage leaving some space for potentially larger items that might\n    arrive later, promoting a balance between filling bins and maintaining flexibility.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity (minimal slack)\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Add a small epsilon to avoid division by zero and to ensure that bins with zero remaining\n    # capacity after placement are still prioritized highest among the minimal slack options.\n    # A higher value indicates higher priority.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Introduce a slight penalty for bins that would become exactly full after placement.\n    # This encourages keeping some space for potentially larger future items.\n    # The penalty is a small constant subtracted from the priority.\n    # We apply this penalty only to the bins that are *exactly* filled.\n    fully_filled_mask = (remaining_after_placement == 0)\n    # Reduce priority for bins that become exactly full. The magnitude of reduction\n    # should be small enough not to override the primary goal of minimizing slack,\n    # but significant enough to encourage non-full bins.\n    penalty = 0.05  # A smaller penalty than in v1 to prioritize minimal slack more strongly\n    priorities[can_fit_mask][fully_filled_mask] -= penalty\n\n    # Ensure all priorities are non-negative. If the penalty makes a priority negative,\n    # it should be capped at 0, as a negative priority doesn't make logical sense in this context.\n    priorities = np.clip(priorities, 0, None)\n\n    return priorities",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]