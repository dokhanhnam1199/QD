{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a best-fit approach with explicit prioritization of exact fits and exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it first gives the highest priority to exact fits. For bins that are not\n    exact fits but can accommodate the item, it assigns priority based on\n    how much remaining capacity is left, favoring smaller remaining capacities.\n    To encourage exploration, a soft constraint using a temperature parameter\n    is applied to the non-exact fits, allowing bins with slightly more remaining\n    capacity a chance to be selected.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign highest priority to exact fits.\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    priorities[can_fit_mask][exact_fit_mask_subset] = 100.0\n\n    # For bins that fit but are not exact fits, assign priorities.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    if np.any(near_fit_mask_subset):\n        near_fit_priorities_raw = remaining_after_placement[near_fit_mask_subset]\n        \n        # Apply a transformation to favor smaller remaining capacities (closer to zero).\n        # Using negative of remaining capacity means smaller remaining capacity gets higher raw priority.\n        # Add a small epsilon to avoid issues with zero remaining capacity if it wasn't caught as exact fit\n        # (though the exact_fit_mask_subset should handle this).\n        transformed_priorities = -near_fit_priorities_raw - 1e-9 \n\n        # Apply softmax for exploration.\n        # Higher temperature means more exploration.\n        temperature = 1.0\n        \n        # Normalize for softmax to avoid overflow/underflow and ensure numerical stability\n        # Subtracting max makes the largest value 0, exp(0) = 1.\n        if np.any(transformed_priorities):\n            normalized_transformed_priorities = transformed_priorities - np.max(transformed_priorities)\n            soft_priorities = np.exp(normalized_transformed_priorities / temperature)\n            \n            # Scale soft_priorities to be less than the exact fit priority (100.0)\n            # and positive. The maximum possible value for soft_priorities is 1 (before scaling).\n            # We want these to be lower than 100, and positive.\n            # A simple scaling factor can work, or we can ensure they are just below 100.\n            # Let's scale them such that the best near-fit is slightly less than exact fit.\n            # The current max value of soft_priorities is 1.0.\n            # We can scale it by a factor less than 100, e.g., 99.\n            scale_factor = 99.0\n            soft_priorities_scaled = soft_priorities * scale_factor\n\n            priorities[can_fit_mask][near_fit_mask_subset] = soft_priorities_scaled\n        else:\n            # If somehow no near fits had valid transformed priorities (highly unlikely with -inf initialization)\n            pass # Keep them at -inf or handle as an error case if necessary.\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy with a temperature-controlled exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (Best Fit). A softmax function is used to introduce\n    controlled exploration, allowing slightly less optimal bins to be chosen with\n    a certain probability, which can help escape local optima. The temperature\n    parameter can be adjusted to control the degree of exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # A higher temperature means more exploration (closer to uniform probabilities)\n    # A lower temperature means more exploitation (closer to greedy best fit)\n    temperature = 0.1  # Tunable parameter\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # For bins that can fit, calculate a \"fit score\". A smaller remaining capacity\n    # after placement is better, so we use the negative of the remaining capacity.\n    # This is what the softmax will operate on.\n    fit_scores = -remaining_after_placement\n\n    # Apply softmax to get probabilities/priorities.\n    # Ensure exp(fit_scores) doesn't overflow for very small negative fit_scores.\n    # Adding a constant offset to shift the scores to be less negative, which can\n    # help with numerical stability in exp. The relative order is preserved.\n    # We can shift by the maximum value in fit_scores to make the largest element 0.\n    if fit_scores.size > 0:\n        shifted_fit_scores = fit_scores - np.max(fit_scores)\n        # Handle potential NaNs if fit_scores were all Inf or -Inf (unlikely here)\n        if np.any(np.isnan(shifted_fit_scores)):\n             shifted_fit_scores = np.nan_to_num(shifted_fit_scores, nan=-1e9) # Assign a very low score\n\n        # Softmax calculation: exp(score / temperature) / sum(exp(score / temperature))\n        # We are interested in the relative priority, not necessarily normalized probabilities.\n        # So, we can simply use exp(score / temperature). Higher values indicate higher priority.\n        # The smaller the remaining_after_placement, the more negative fit_scores,\n        # so exp(negative_value/temperature) will be smaller.\n        # We want higher priority for smaller remaining_after_placement, so we should use positive fit_scores.\n        # Let's re-evaluate: we want smaller remaining_after_placement to have higher priority.\n        # The current fit_scores are -remaining_after_placement.\n        # Softmax on -remaining_after_placement will assign higher probability to LARGER (less negative) values,\n        # which means LARGER remaining_after_placement. This is the opposite of what we want.\n        # We want smaller remaining_after_placement to have higher priority.\n        # So, we should use the reciprocal of remaining capacity for the softmax, or a score that\n        # increases as remaining_after_placement decreases.\n\n        # Let's use the inverse of remaining capacity for the score.\n        # Larger inverse means smaller remaining capacity, which is what we want.\n        # Add a small epsilon to avoid division by zero.\n        inverse_remaining = 1.0 / (remaining_after_placement + 1e-9)\n\n        # Softmax on these positive scores will give higher probabilities to bins\n        # with smaller remaining capacity.\n        # We want to prioritize tighter fits, so smaller remaining_after_placement.\n        # If remaining_after_placement is 0, inverse is large (high priority).\n        # If remaining_after_placement is large, inverse is small (low priority).\n        # So, inverse_remaining is a good score for \"goodness of fit\".\n        priorities[can_fit_mask] = np.exp(inverse_remaining / temperature)\n    else:\n        # If no bins can fit, all priorities remain 0.\n        pass\n\n    return priorities\n\n[Reflection]\nPrioritize exact fits, use negative remaining capacity for softmax, and adjust temperature.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}