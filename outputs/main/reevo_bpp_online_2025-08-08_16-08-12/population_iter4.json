[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, favoring 'Tight Fit'.\n\n    This heuristic prioritizes bins that can accommodate the item and have a remaining\n    capacity that is closest to the item's size. This is a refinement of the \"Tight Fit\"\n    strategy by penalizing bins where the remaining capacity is significantly larger\n    than the item size. The goal is to leave larger contiguous free spaces in other bins\n    for potentially larger future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher priority is given to bins where remaining_capacity - item is smallest\n        and non-negative.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate a score.\n    # We want to minimize the difference (bins_remain_cap - item).\n    # The smaller this difference, the higher the priority.\n    # We use the inverse of this difference to achieve higher scores for smaller differences.\n    # Add epsilon to avoid division by zero if the difference is exactly 0.\n    # Also, we add a penalty proportional to how much larger the remaining capacity is than the item,\n    # to further emphasize tighter fits over looser fits.\n    epsilon = 1e-9\n    difference = bins_remain_cap[can_fit_mask] - item\n\n    # The score is primarily driven by the inverse of the difference (tightest fit).\n    # We add a term that slightly penalizes larger differences. For example,\n    # a bin with remaining capacity 5 for item 3 (diff=2) should be less preferred\n    # than a bin with remaining capacity 3 for item 3 (diff=0).\n    # The term `difference` itself penalizes larger differences when used in the denominator.\n    # To make it more direct, we can use `1 / (difference + epsilon)` for \"Tight Fit\"\n    # and potentially add a secondary term or use a different function for \"Almost Full Fit\".\n    # For a refined \"Tight Fit\", we want to minimize `difference`.\n    # Let's use a score that is high when `difference` is small and positive.\n    # `1 / (difference + epsilon)` works for this.\n\n    # To further refine towards 'tightest' fit and penalize larger gaps:\n    # Consider a function that penalizes larger `difference` more.\n    # For example, we can square the difference, or use `exp(-difference)`.\n    # Let's stick with the inverse for now as it's a direct interpretation of prioritizing small positive differences.\n    # If we want to penalize larger differences, making them *less* preferred than very tight fits:\n    # `priorities[can_fit_mask] = 1.0 / (difference + epsilon)` naturally does this.\n    # A bin with difference 1 gets priority 1/(1+eps), difference 2 gets 1/(2+eps).\n\n    # A more aggressive approach to penalize larger gaps:\n    # `priorities[can_fit_mask] = 1.0 / (difference**2 + epsilon)` - this penalizes larger differences more heavily.\n    # Let's use the simple inverse for a direct \"Tight Fit\" as described in the reflection.\n    priorities[can_fit_mask] = 1.0 / (difference + epsilon)\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, prioritizing Exact Fit, then Best Fit.\n\n    This heuristic prioritizes bins that offer an exact fit for the item.\n    If no exact fit is available, it then prioritizes bins that can accommodate the item\n    with the smallest remaining capacity (Best Fit approach among the remaining options).\n    This aims to minimize wasted space and leave larger capacities available for subsequent items.\n    It avoids penalizing good fits, ensuring that tighter fits receive higher priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Exact fits get the highest priority (e.g., 100). Bins that fit but not exactly\n        get a priority based on the \"tightness\" of the fit, inversely proportional to\n        the slack (remaining capacity - item size). Bins that cannot fit get 0 priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    fitting_indices = np.where(can_fit_mask)[0]\n\n    if fitting_bins_capacities.size == 0:\n        return priorities  # No bin can fit the item\n\n    # Calculate slack for bins that can fit the item\n    slacks = fitting_bins_capacities - item\n\n    # Exact fit has the highest priority\n    exact_fit_mask = slacks == 0\n    exact_fit_indices = fitting_indices[exact_fit_mask]\n    priorities[exact_fit_indices] = 100.0\n\n    # For bins that are not an exact fit, assign priority based on the slack (Best Fit)\n    # Smaller slack (tighter fit) gets a higher priority.\n    non_exact_fit_mask = slacks > 0\n    non_exact_fit_indices = fitting_indices[non_exact_fit_mask]\n    non_exact_slacks = slacks[non_exact_fit_mask]\n\n    if non_exact_fit_indices.size > 0:\n        # Sort these bins by slack in ascending order.\n        # The bin with the smallest slack (closest to fitting perfectly) gets the highest priority\n        # among the non-exact fits.\n        sorted_slack_indices = np.argsort(non_exact_slacks)\n\n        # Assign priorities decreasingly.\n        # Max priority for non-exact fits will be 99 (if exact fits exist),\n        # down to a lower value.\n        # The number of non-exact fits determines the range of these priorities.\n        max_non_exact_priority = 99.0\n        # Assign priorities from highest (99) to lowest based on sorted slack\n        priorities[non_exact_fit_indices[sorted_slack_indices]] = max_non_exact_priority - np.arange(non_exact_slacks.size)\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin, prioritizing\n    minimal slack after placement while also slightly penalizing bins that\n    would become exactly full to maintain flexibility.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (minimal slack). This encourages denser packing.\n    Additionally, it slightly penalizes bins that would become completely full\n    to encourage leaving some space for potentially larger items that might\n    arrive later, promoting a balance between filling bins and maintaining flexibility.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity (minimal slack)\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Add a small epsilon to avoid division by zero and to ensure that bins with zero remaining\n    # capacity after placement are still prioritized highest among the minimal slack options.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Introduce a slight penalty for bins that would become exactly full after placement.\n    # This encourages keeping some space for potentially larger future items.\n    # The penalty is a small constant subtracted from the priority.\n    # We apply this penalty only to the bins that are *exactly* filled.\n    fully_filled_mask = (remaining_after_placement == 0)\n    priorities[can_fit_mask][fully_filled_mask] -= 0.1\n\n    # Ensure all priorities are non-negative. If the penalty makes a priority negative,\n    # it should be capped at 0, as a negative priority doesn't make logical sense in this context.\n    priorities = np.clip(priorities, 0, None)\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an improved strategy that prioritizes exact fits then near fits.\n\n    This strategy prioritizes bins that can fit the item, aiming to minimize the\n    remaining capacity (gap) after packing. Exact fits are given the highest priority.\n    Among bins that don't offer an exact fit but can accommodate the item,\n    it prioritizes those that leave the least remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value. Bins that cannot fit the item\n    # will retain this low priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate the remaining capacity after placing the item in fitting bins.\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign high priority to exact fits.\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    priorities[can_fit_mask][exact_fit_mask_subset] = 100.0\n\n    # For bins that fit but are not exact fits, prioritize those with the least remaining capacity.\n    # This means we want to prioritize bins with smaller remaining_after_placement.\n    # We use the negative of remaining_after_placement as the score.\n    # Smaller remaining_after_placement values will result in less negative scores, hence higher priority.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    if np.any(near_fit_mask_subset):\n        priorities[can_fit_mask][near_fit_mask_subset] = -remaining_after_placement[near_fit_mask_subset]\n\n    return priorities",
    "response_id": 3,
    "obj": 4.487435181491823,
    "SLOC": 12.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a strategy that\n    balances fitting the item well (exploitation) with leaving space for future items\n    and potentially using less full bins (exploration).\n\n    This version aims to prioritize bins that leave a small, positive remainder,\n    which is often a good heuristic for BPP. It also incorporates an exploration\n    component by occasionally favoring bins that are not necessarily the \"best\" fit,\n    to avoid getting stuck in local optima.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploration\n    num_bins = len(bins_remain_cap)\n\n    # Calculate potential remainders for bins where the item fits.\n    potential_remainders = bins_remain_cap - item\n\n    # Identify bins where the item can fit.\n    fitting_bins_mask = potential_remainders >= 0\n\n    # Calculate exploitation scores: prioritize bins with small positive remainders.\n    # A score of 1/(remainder + small_constant) means smaller remainders get higher scores.\n    # For bins that don't fit, assign a very low score (-infinity) to ensure they are not chosen.\n    exploitation_scores = np.full_like(bins_remain_cap, -np.inf)\n\n    # For bins that fit, calculate a score based on the remainder.\n    # We want to reward bins that leave a small, positive remainder.\n    # A simple heuristic is 1 / (remainder + epsilon) for small remainders.\n    # For exact fits (remainder = 0), this gives a high score.\n    # For very small remainders, it also gives high scores.\n    # As remainder increases, the score decreases.\n    # Adding a small constant `1e-9` to the denominator for numerical stability and to avoid division by zero.\n    exploitation_scores[fitting_bins_mask] = 1.0 / (potential_remainders[fitting_bins_mask] + 1e-9)\n\n    # Normalize exploitation scores to be between 0 and 1.\n    # This makes it easier to combine with exploration scores.\n    # If no bins fit, all scores remain -inf, and normalization will result in zeros.\n    max_exploitation_score = np.max(exploitation_scores[fitting_bins_mask]) if np.any(fitting_bins_mask) else 0\n    if max_exploitation_score > 0:\n        normalized_exploitation_scores = exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(exploitation_scores) # If no bins fit, all normalized scores are 0\n\n    # Introduce exploration: with probability epsilon, pick a random bin among those that fit.\n    # With probability (1 - epsilon), pick the bin with the highest exploitation score.\n\n    # Generate random scores for exploration. We want to give a chance to bins that\n    # might not be the \"best\" according to the greedy criterion.\n    # We can generate random values and then pick among fitting bins.\n    exploration_scores = np.random.rand(num_bins)\n\n    # Combine exploitation and exploration using an epsilon-greedy approach.\n    # With probability epsilon, we use random exploration scores.\n    # With probability (1 - epsilon), we use normalized exploitation scores.\n\n    # First, create a mask for exploration choice.\n    explore_mask = np.random.rand(num_bins) < epsilon\n\n    # For bins chosen for exploration, use their random exploration score, but only if they fit.\n    # If a bin is chosen for exploration but doesn't fit, its priority should be very low.\n    # For bins chosen for exploitation, use their normalized exploitation score, but only if they fit.\n    # If a bin is chosen for exploitation but doesn't fit, its priority should be very low.\n    priorities = np.where(explore_mask & fitting_bins_mask, exploration_scores,\n                          np.where(~explore_mask & fitting_bins_mask, normalized_exploitation_scores, -np.inf))\n\n\n    return priorities",
    "response_id": 4,
    "obj": 36.06900678101317,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-Based Best Fit strategy with adaptive temperature.\n\n    This heuristic prioritizes bins that have a remaining capacity closest to the item size,\n    aiming for the \"best fit\". It calculates a fitness score based on the gap between\n    the remaining capacity and the item size, preferring smaller non-negative gaps.\n    The softmax function is then used to convert these fitness scores into priorities.\n    The temperature parameter is adapted based on the spread of suitable gaps to control\n    the exploration/exploitation balance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the \"gap\" for bins that can fit the item.\n    # We want to minimize this gap (i.e., find the best fit).\n    gaps = bins_remain_cap - item\n\n    # Initialize fitness scores. Bins that cannot fit the item will have a very low score.\n    # Using a large negative number to ensure they are not picked by softmax unless absolutely necessary.\n    fitness_scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = (gaps >= 0)\n    valid_gaps = gaps[can_fit_mask]\n\n    if np.any(can_fit_mask):\n        # Adaptive temperature:\n        # A smaller temperature makes the probability distribution sharper, favoring the best fit more.\n        # A larger temperature makes the distribution flatter, allowing more exploration.\n        # We can adapt the temperature based on the variance or range of suitable gaps.\n        # If there's a wide range of gaps, a larger temperature might be suitable.\n        # If gaps are very close, a smaller temperature is appropriate.\n        if valid_gaps.size > 1:\n            # Use standard deviation of valid gaps as a measure of spread.\n            # Add a small constant to avoid division by zero if all gaps are identical.\n            gap_spread = np.std(valid_gaps) + 1e-6\n            # The temperature should be proportional to the spread.\n            # A scaling factor can be tuned. Here, we use a simple linear relationship.\n            temperature = gap_spread\n        elif valid_gaps.size == 1:\n            # If only one bin fits, temperature doesn't really matter for distinctiveness,\n            # but setting it to a small value ensures exp(-gap/temp) is well-behaved.\n            temperature = 1.0\n        else:\n            # This case should not be reached due to np.any(can_fit_mask) check,\n            # but for robustness, set a default.\n            temperature = 1.0\n\n        # Ensure temperature is positive and not excessively small to avoid numerical instability.\n        temperature = max(temperature, 1e-3)\n\n        # Calculate fitness scores: exp(-gap / temperature). Smaller gap = higher score.\n        scaled_gaps = valid_gaps / temperature\n        positive_scores = np.exp(-scaled_gaps)\n\n        fitness_scores[can_fit_mask] = positive_scores\n\n    # Handle the case where no bins can fit the item.\n    # In this scenario, all fitness scores are -np.inf. Softmax would result in NaNs.\n    # A reasonable fallback is to assign uniform probabilities, as any bin choice is equally \"bad\"\n    # and creating a new bin would be the ultimate action in a BPP solver.\n    if not np.any(np.isfinite(fitness_scores)):\n        # If no bins can fit, and there are bins available, assign uniform probability.\n        if bins_remain_cap.size > 0:\n            return np.ones_like(bins_remain_cap) / bins_remain_cap.size\n        else:\n            return np.array([], dtype=float) # Return empty array if no bins at all\n\n    # Apply Softmax to convert fitness scores into probabilities (priorities).\n    # Shift scores to avoid numerical issues with very small/large exponents in exp().\n    # Subtracting the maximum finite score from all scores does not change the softmax output\n    # but can help prevent overflow/underflow issues.\n    finite_mask = np.isfinite(fitness_scores)\n    if np.any(finite_mask):\n        max_finite_score = np.max(fitness_scores[finite_mask])\n        shifted_scores = fitness_scores - max_finite_score\n    else:\n        # This case is covered by the `if not np.any(np.isfinite(fitness_scores))` block,\n        # but for absolute safety, handle it.\n        return np.ones_like(bins_remain_cap) / bins_remain_cap.size if bins_remain_cap.size > 0 else np.array([], dtype=float)\n\n    # Compute the exponentiated scores. Replace -inf with 0 to avoid exp(-inf) = 0 issues\n    # which might incorrectly lead to a sum of zero if all were -inf.\n    exp_scores = np.where(np.isfinite(shifted_scores), np.exp(shifted_scores), 0)\n\n    sum_exp_scores = np.sum(exp_scores)\n\n    # If the sum is zero (e.g., all original scores were -inf, or numerical issues),\n    # fall back to uniform distribution among available bins.\n    if sum_exp_scores == 0:\n        return np.ones_like(bins_remain_cap) / bins_remain_cap.size if bins_remain_cap.size > 0 else np.array([], dtype=float)\n    else:\n        priorities = exp_scores / sum_exp_scores\n        return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 35.0,
    "cyclomatic_complexity": 10.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, prioritizing Exact Fit, then Best Fit.\n\n    This heuristic prioritizes bins that offer an exact fit for the item.\n    If multiple exact fits exist, they all receive the highest priority.\n    If no exact fit is available, it then prioritizes bins that can accommodate the item\n    with the smallest remaining capacity (Best Fit approach among the remaining options).\n    This aims to minimize wasted space and leave larger capacities available for subsequent items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Exact fits get the highest priority (e.g., 100). Bins that fit but not exactly\n        get a priority based on the \"tightness\" of the fit, inversely proportional to\n        the slack (remaining capacity - item size). Bins that cannot fit get 0 priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    fitting_indices = np.where(can_fit_mask)[0]\n\n    if fitting_bins_capacities.size == 0:\n        return priorities  # No bin can fit the item\n\n    # Calculate slack for bins that can fit the item\n    slacks = fitting_bins_capacities - item\n\n    # Assign highest priority to exact fits\n    exact_fit_mask = slacks == 0\n    exact_fit_indices = fitting_indices[exact_fit_mask]\n    priorities[exact_fit_indices] = 100  # Highest priority\n\n    # For bins that are not an exact fit, assign priority based on the slack (Best Fit)\n    # Smaller slack (tighter fit) gets a higher priority.\n    non_exact_fit_mask = slacks > 0\n    non_exact_fit_indices = fitting_indices[non_exact_fit_mask]\n    non_exact_slacks = slacks[non_exact_fit_mask]\n\n    if non_exact_fit_indices.size > 0:\n        # Sort these bins by slack in ascending order.\n        # The bin with the smallest slack (closest to fitting perfectly) gets the highest priority\n        # among the non-exact fits.\n        sorted_slack_indices = np.argsort(non_exact_slacks)\n\n        # Assign priorities decreasingly.\n        # The priority for non-exact fits will be slightly lower than exact fits.\n        # We ensure a clear differentiation from exact fits.\n        max_non_exact_priority = 99\n        for i, original_index_in_fitting in enumerate(non_exact_fit_indices[sorted_slack_indices]):\n            priorities[original_index_in_fitting] = max_non_exact_priority - i\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an improved Best Fit strategy.\n\n    This heuristic prioritizes bins that can fit the item. Among those, it\n    favors bins that result in the smallest *non-negative* remaining capacity\n    after placing the item (i.e., the \"tightest\" fit). If multiple bins offer\n    the exact same minimal remaining capacity, it does not introduce a specific\n    tie-breaking rule and relies on the order of evaluation or underlying\n    numpy behavior.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher priority score indicates a better fit. Bins that cannot fit\n        the item are given a very low priority.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    # Using -infinity ensures that any valid fit will have a higher priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the residual capacity.\n    # Residual capacity = remaining_capacity - item_size.\n    # We want to minimize this residual capacity.\n    # To convert this minimization problem into a maximization problem for priority scores,\n    # we can use the negative of the residual capacity.\n    # A smaller (or less negative) value for `-residual` means a better fit.\n    # For example:\n    # If residual is 0 (perfect fit), priority is 0.\n    # If residual is 1, priority is -1.\n    # If residual is 5, priority is -5.\n    # This naturally prioritizes exact fits (priority 0) over larger residuals.\n    residual_capacities = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities to the suitable bins. The priority is the negative of the residual capacity.\n    priorities[can_fit_mask] = -residual_capacities\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a refined\n    Best Fit strategy that also considers the item's size relative to the bin's capacity.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have the smallest remaining\n    capacity after the item is placed (Best Fit). Additionally, it slightly favors\n    bins that are not \"too large\" for the item, to prevent using large bins for small items,\n    which can lead to fragmentation. The score is based on the inverse of the remaining capacity,\n    giving a higher score to tighter fits. Bins that cannot fit the item receive a score of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate a score that prioritizes smaller remaining capacity (Best Fit).\n    # The inverse of remaining capacity is used, with a small epsilon for numerical stability.\n    # Smaller remaining capacity leads to a higher score.\n    best_fit_scores = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Optionally, can add a factor that penalizes very large remaining capacities relative to the item.\n    # For simplicity and focusing on the \"tight fit\" aspect, we primarily rely on the inverse remaining capacity.\n    # A potential refinement could be `best_fit_scores * (1 - (bins_remain_cap[can_fit_mask] - item) / bins_remain_cap[can_fit_mask])`\n    # but this might overcomplicate and could lead to issues if bin capacity is 0.\n    # Sticking to the core Best Fit principle here.\n\n    priorities[can_fit_mask] = best_fit_scores\n\n    # Ensure that bins that cannot fit the item have a priority of 0, which is handled by initialization.\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using the \"Best Fit\" heuristic for the online Bin Packing Problem.\n\n    This heuristic aims to find the bin that, after placing the item, will have the\n    least remaining capacity (i.e., the tightest fit) among all bins that can\n    accommodate the item. It prioritizes bins that are closer to being full.\n    An exact fit (remaining capacity == item size) is implicitly handled as\n    it results in zero remaining capacity, which is the minimum possible.\n\n    The priority is calculated as:\n    - For bins that can fit the item: a value inversely proportional to the\n      remaining capacity after placing the item (i.e., -(bins_remain_cap - item)).\n      This means bins with less remaining capacity (tighter fit) get higher priorities.\n      The highest priority is given to the bin with the smallest non-negative\n      remaining capacity after placing the item.\n    - For bins that cannot fit the item: a priority of negative infinity to ensure\n      they are never selected.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after packing\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities. Higher priority for smaller remaining capacity (tighter fit).\n    # We use the negative of the remaining capacity so that the minimum remaining\n    # capacity (tightest fit) gets the highest positive priority.\n    # If a bin has remaining_capacity - item = 0 (exact fit), its priority contribution is 0.\n    # If remaining_capacity - item = 5, its priority contribution is -5.\n    # The largest negative value will correspond to the smallest remaining capacity.\n    # By using negative remaining capacity, we ensure that smaller (more negative)\n    # values are preferred, which corresponds to smaller remaining capacities.\n    priorities[can_fit_mask] = -remaining_capacities_after_fit\n\n    return priorities",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]