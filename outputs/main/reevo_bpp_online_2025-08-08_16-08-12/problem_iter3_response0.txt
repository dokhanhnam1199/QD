```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin, favoring 'Best Fit'
    while also considering exploration by slightly penalizing bins that are too full.

    This heuristic prioritizes bins that can fit the item. Among those that fit,
    it assigns a higher priority to bins that will have less remaining capacity
    after the item is placed (Best Fit principle). To encourage exploration and
    prevent overly filling bins prematurely, it slightly penalizes bins where
    the item would leave very little remaining space.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities # No bin can fit the item

    # Calculate remaining capacity if the item is placed in a fitting bin
    remaining_after_placement = bins_remain_cap[can_fit_mask] - item

    # Prioritize bins that result in less remaining capacity (Best Fit)
    # We invert the remaining capacity: smaller remaining capacity gets higher priority.
    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0.
    best_fit_score = 1.0 / (remaining_after_placement + 1e-9)

    # Introduce a slight penalty for bins that become "too full" to encourage exploration
    # A bin is considered "too full" if the remaining capacity is very small relative to the item size.
    # We want to avoid cases where placing the item leaves almost no space,
    # as this might prevent fitting larger subsequent items.
    # The penalty is inversely related to the remaining capacity.
    # If remaining_after_placement is small, the penalty is higher.
    # We use a small divisor (e.g., 100) to scale this penalty, making it a slight adjustment.
    exploration_penalty = 1.0 / (remaining_after_placement * 100.0 + 1e-9)

    # Combine the scores: prioritize best fit, but slightly penalize extreme fits
    # Subtracting the penalty means higher penalty leads to lower priority.
    priorities[can_fit_mask] = best_fit_score - exploration_penalty

    # Ensure priorities are non-negative, as negative priorities can be problematic
    # depending on how the selection mechanism handles them. A simple clip is effective.
    priorities = np.clip(priorities, 0, None)

    return priorities
```
