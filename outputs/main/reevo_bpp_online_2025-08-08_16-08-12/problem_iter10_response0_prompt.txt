{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy with explicit prioritization of exact fits and temperature-controlled exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it first gives the highest priority to exact fits. For bins that are not\n    exact fits but can accommodate the item, it assigns priority based on\n    how much remaining capacity is left, favoring smaller remaining capacities.\n    To encourage exploration, a softmax function is applied to the non-exact fits\n    with a temperature parameter. A smaller temperature leads to more exploitation (closer to greedy),\n    while a larger temperature leads to more exploration (closer to uniform).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    temperature = 0.1  # Tunable parameter for exploration. Lower = more greedy.\n\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate remaining capacity if item is placed\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign highest priority to exact fits\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    priorities[can_fit_mask][exact_fit_mask_subset] = 100.0\n\n    # For bins that fit but are not exact fits, calculate scores for softmax\n    non_exact_fit_indices_subset = np.where(~exact_fit_mask_subset)[0]\n\n    if non_exact_fit_indices_subset.size > 0:\n        non_exact_fitting_bins_remain_cap = fitting_bins_remain_cap[~exact_fit_mask_subset]\n        non_exact_remaining_after_placement = non_exact_fitting_bins_remain_cap - item\n\n        # We want to prioritize smaller remaining capacities.\n        # Using the negative of remaining capacity means smaller remaining capacity\n        # yields a larger (less negative) score, which is good for softmax.\n        # Add epsilon to avoid division by zero in case of floating point inaccuracies\n        # if remaining_after_placement is very close to zero but not exactly zero.\n        # However, a simpler approach is to just use the negative remaining capacity.\n        # Let's use negative remaining capacity as the score for softmax.\n        # A smaller remaining_after_placement will result in a less negative score.\n        fit_scores_for_softmax = -non_exact_remaining_after_placement\n\n        # Apply softmax for exploration. Higher score (less remaining capacity) means higher priority.\n        # To ensure numerical stability with exp, shift scores so the maximum is 0.\n        if fit_scores_for_softmax.size > 0:\n            shifted_fit_scores = fit_scores_for_softmax - np.max(fit_scores_for_softmax)\n            # Handle potential NaNs if fit_scores were all Inf or -Inf (unlikely here)\n            if np.any(np.isnan(shifted_fit_scores)):\n                 shifted_fit_scores = np.nan_to_num(shifted_fit_scores, nan=-1e9)\n\n            # Calculate the softmax values. The relative magnitude is what matters.\n            # Higher value for smaller remaining_after_placement.\n            soft_priorities = np.exp(shifted_fit_scores / temperature)\n\n            # Scale these priorities to be less than the exact fit priority (100.0)\n            # and ensure they are positive.\n            # The maximum possible value of soft_priorities (before scaling) is 1.0.\n            # We can scale them by a factor like 99.0 to ensure they are lower than exact fits.\n            scale_factor = 99.0\n            priorities[can_fit_mask][~exact_fit_mask_subset] = soft_priorities * scale_factor\n        else:\n            # If no non-exact fits (all were exact fits)\n            pass\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem.\n    This strategy prioritizes exact fits, then near fits using a soft-max approach\n    for exploration among near-fitting bins, and penalizes bins with very large remaining capacities.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    fitting_bins_remain_cap = bins_remain_cap[fitting_bins_indices]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign very high priority for exact fits\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    exact_fit_indices = fitting_bins_indices[exact_fit_mask_subset]\n    priorities[exact_fit_indices] = 100.0\n\n    # Handle near fits with a softmax for exploration.\n    # Lower remaining capacity should lead to a higher score.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    near_fit_indices_subset = fitting_bins_indices[near_fit_mask_subset]\n\n    if np.any(near_fit_mask_subset):\n        near_fit_remaining = remaining_after_placement[near_fit_mask_subset]\n\n        # Calculate scores for near fits. We want to prioritize smaller remaining capacities.\n        # Using negative remaining capacity: smaller capacity -> less negative score -> higher priority.\n        # Add a small constant to ensure scores are not zero for softmax, and to keep them lower than exact fits.\n        # We also want to penalize bins with very large remaining capacity if they are not exact fits.\n        # A simple way is to make the priority decrease as remaining capacity increases beyond a certain point.\n        # Let's use a transformation that is high for small remaining, and tapers off.\n        # A negative exponential function could work: exp(-k * remaining_capacity)\n        # Or, simply use the negative remaining capacity and apply softmax.\n        # Let's ensure the scores are positive for softmax, and scale them.\n        \n        # Calculate \"desirability\" for near fits: higher for smaller remaining capacity.\n        # We can use a scale where 0 remaining capacity is best, and it degrades.\n        # Let's map the remaining capacities to a desirability score.\n        # Smallest remaining capacity should get highest score among near fits.\n        # Max value for near fits to avoid extreme values in exp\n        max_near_fit_remaining = np.max(near_fit_remaining) if near_fit_remaining.size > 0 else 0\n        \n        # Calculate scores that are higher for smaller remaining capacity.\n        # We scale by a factor to ensure they are less than exact fits.\n        # A simple approach: -(remaining_capacity).\n        # To make it suitable for softmax and exploration, we want values that differentiate.\n        # Let's consider the inverse of remaining capacity (plus a small epsilon to avoid division by zero).\n        # Or more simply, negative of remaining capacity, shifted and scaled.\n\n        # We want values that increase as remaining capacity decreases.\n        # `near_fit_remaining` values are >= 0.\n        # Let's transform `near_fit_remaining` into \"fitness scores\" where higher is better.\n        # Score = max_remaining_if_near_fit - current_remaining_if_near_fit\n        # This makes exact fits (0 remaining) have the highest score among near fits.\n        # But we already handled exact fits separately with a fixed high score.\n        # For near fits, we want to prioritize smaller `near_fit_remaining`.\n        \n        # Let's use -near_fit_remaining as base scores. Add a base value to shift it.\n        # A base value like 10.0 could be used.\n        # Score = 10.0 - near_fit_remaining\n        \n        # The problem is that `near_fit_remaining` can vary widely.\n        # If we want to use softmax for exploration, we need scores that can be exponentiated.\n        # Let's use the negative of remaining capacity as the base score.\n        # We need to scale and shift these to be positive for softmax and to be distinct from exact fits.\n        \n        # Calculate base priorities: prioritize smaller remaining capacity.\n        # We want to assign higher scores to bins with smaller `near_fit_remaining`.\n        # Let's use `-near_fit_remaining` as the raw score.\n        # To make it suitable for softmax, we can shift and scale it.\n        # Example: shift to make all values positive, then scale.\n        \n        # Calculate values that are higher for smaller remaining capacity.\n        # If remaining capacity is 0.1, score is higher than if it's 0.5.\n        # Let's try `1 / (near_fit_remaining + epsilon)`.\n        epsilon_small = 1e-6\n        near_fit_scores_for_softmax = 1.0 / (near_fit_remaining + epsilon_small)\n        \n        # Normalize these scores using softmax for exploration.\n        # Softmax will give higher probabilities to bins with smaller remaining capacity (larger scores).\n        temperature = 1.0  # Tunable parameter for exploration control\n\n        # Shift scores to prevent numerical underflow/overflow in exp\n        max_score = np.max(near_fit_scores_for_softmax)\n        shifted_scores = near_fit_scores_for_softmax - max_score\n        \n        exp_scores = np.exp(shifted_scores / temperature)\n        sum_exp_scores = np.sum(exp_scores)\n\n        if sum_exp_scores > 0:\n            softmax_probabilities = exp_scores / sum_exp_scores\n        else:\n            # Fallback to uniform probability if all scores are ~0 or -inf\n            softmax_probabilities = np.ones_like(exp_scores) / len(exp_scores)\n\n        # Scale these probabilities to a range that is lower than exact fits but reflects preference.\n        # For example, map probabilities to a range like [50, 90].\n        # Higher probability for smaller remaining capacity -> higher scaled score.\n        # The softmax probabilities range from ~0 to 1.\n        scaled_near_fit_priorities = 50.0 + softmax_probabilities * 40.0 # Range [50, 90)\n\n        priorities[near_fit_indices_subset] = scaled_near_fit_priorities\n\n    # Bins that can fit but were not assigned exact fit or near fit priority (shouldn't happen with current logic)\n    # or bins that could fit but had issues in scoring, will remain -np.inf.\n    # However, to be safe, we can assign a baseline priority to any bin that can fit but wasn't covered.\n    # This could happen if `near_fit_mask_subset` is empty, and `exact_fit_mask_subset` is also empty,\n    # but `can_fit_mask` is True. In this case, the item is smaller than remaining capacity but not an exact fit,\n    # and no other near fits were processed.\n    # This implies `near_fit_remaining` was empty. This scenario should be covered by the `if np.any(near_fit_mask_subset):` block.\n\n    # Any bin that *can* fit but has no priority assigned yet should get a default low priority.\n    # For example, any remaining `can_fit_mask` that are not `exact_fit_indices` and not `near_fit_indices_subset`.\n    # This should logically not occur given how near_fit_mask_subset is derived.\n    # If a bin can fit, it's either an exact fit or a near fit.\n    \n    # Let's ensure that any bin that *can* fit has at least a minimal positive priority if not an exact fit.\n    # This default priority should be lower than any near-fit priority.\n    default_low_priority = 1.0\n    unassigned_fitting_bins = np.where(can_fit_mask & (priorities == -np.inf))[0]\n    priorities[unassigned_fitting_bins] = default_low_priority\n\n    return priorities\n\n[Reflection]\nPrioritize exact fits. For near fits, use scaled softmax on inverse remaining capacity.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}