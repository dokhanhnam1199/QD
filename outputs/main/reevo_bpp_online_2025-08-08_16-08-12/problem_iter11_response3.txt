```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a greedy strategy
    that prioritizes exact fits and uses scaled softmax for near fits.

    This heuristic prioritizes bins that can fit the item. Among those that fit,
    it assigns a higher priority to bins that will have less remaining capacity
    after the item is placed (encouraging tighter packing). For bins that are
    close to an exact fit, it uses a scaled softmax function on the inverse
    remaining capacity to amplify the preference for tighter fits. This aims to
    adapt exploration for fewer, direct improvements by favoring solutions
    that are closer to optimal.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities  # No bins can fit the item

    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]

    # Calculate the remaining capacity if the item is placed in a fitting bin
    remaining_after_placement = fitting_bins_remain_cap - item

    # Prioritize exact fits: if remaining capacity is 0, give a very high priority.
    # For near fits, use scaled softmax on the inverse remaining capacity.
    # The scaling factor (e.g., 10) is a hyperparameter to tune the "aggressiveness"
    # of prioritizing tighter fits. A higher scale makes smaller remaining capacities
    # contribute much more to the priority.
    scale_factor = 10.0
    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0.
    # The softmax will naturally handle 0 remaining capacity with a high value.
    inverse_remaining_capacity = 1.0 / (remaining_after_placement + 1e-9)

    # Apply scaled softmax to the inverse remaining capacities
    # Softmax: exp(scaled_values) / sum(exp(scaled_values))
    # This will turn the inverse remaining capacities into a probability-like distribution
    # where smaller remaining capacities (larger inverse capacities) get higher scores.
    scaled_inverse_capacity = scale_factor * inverse_remaining_capacity
    exp_scaled_inverse_capacity = np.exp(scaled_inverse_capacity)
    softmax_scores = exp_scaled_inverse_capacity / np.sum(exp_scaled_inverse_capacity)

    priorities[can_fit_mask] = softmax_scores

    return priorities
```
