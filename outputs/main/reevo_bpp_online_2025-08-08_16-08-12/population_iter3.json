[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an improved Almost Full Fit strategy.\n\n    This strategy prioritizes bins that can fit the item, aiming to minimize the\n    remaining capacity (gap) after packing. Exact fits are given the highest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value to signify that bins that cannot\n    # fit the item have the lowest priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Find bins where the item fits exactly. These should have the highest priority.\n    exact_fit_mask = (bins_remain_cap - item) == 0\n    priorities[exact_fit_mask] = 100.0  # High priority for exact fits\n\n    # Find bins where the item fits but not exactly.\n    # For these bins, we want to prioritize those with the smallest remaining capacity\n    # after placing the item (i.e., minimize bins_remain_cap - item).\n    # This means we want to prioritize bins with the smallest bins_remain_cap.\n    # We assign priorities as negative remaining capacity.\n    valid_fit_mask = bins_remain_cap >= item\n    eligible_bins_mask = valid_fit_mask & ~exact_fit_mask\n\n    if np.any(eligible_bins_mask):\n        # Calculate the negative remaining capacity for eligible bins.\n        # Smaller remaining capacity (closer to 'item') will result in a less negative\n        # number, hence a higher priority among these eligible bins.\n        priorities[eligible_bins_mask] = -bins_remain_cap[eligible_bins_mask]\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Tight Fit strategy.\n\n    The \"Tight Fit\" strategy prioritizes bins that have a remaining capacity\n    that is just enough to fit the current item. This aims to leave larger capacities\n    in other bins for potentially larger future items. This is an refinement of\n    \"Almost Full Fit\" by directly penalizing bins with much larger remaining capacity\n    than needed.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher priority is given to bins with remaining capacity closer to the item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate the difference between remaining capacity and item size for bins that can fit\n    # We want to prioritize bins where this difference is small and non-negative.\n    # A small difference means a \"tight\" fit.\n    diff = bins_remain_cap - item\n\n    # Mask for bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate priority.\n    # We want to give higher priority to smaller positive differences.\n    # A common way to achieve this is to use the inverse of the difference.\n    # To avoid division by zero when diff is 0 (perfect fit), we add a small epsilon.\n    # Bins with larger differences will have lower priority (1 / (large_diff + epsilon)).\n    epsilon = 1e-9\n    priorities[can_fit_mask] = 1.0 / (diff[can_fit_mask] + epsilon)\n\n    # Bins that cannot fit the item will have a priority of 0, as initialized.\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy.\n\n    The Best Fit strategy aims to place the item into the bin where it fits most snugly,\n    leaving the least remaining capacity. This heuristic prioritizes bins that have the\n    smallest non-negative residual capacity after placing the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher priority score indicates a better fit.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the residual capacity after placement.\n    # The residual capacity is `bins_remain_cap[i] - item`.\n    # We want to prioritize bins with the smallest *positive* residual.\n    # A smaller residual means a \"tighter\" fit.\n    # To ensure higher priority for tighter fits, we can use the negative of the residual.\n    # For example:\n    # If residual is 0 (perfect fit), priority is 0.\n    # If residual is 1, priority is -1.\n    # If residual is 5, priority is -5.\n    # This way, 0 is the highest priority, followed by -1, then -5, etc.\n    residual_capacities = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities to the bins that can fit the item.\n    # The priority is the negative of the residual capacity.\n    priorities[can_fit_mask] = -residual_capacities\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that have the smallest remaining capacity\n    that is still sufficient to accommodate the item. This aims to minimize wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value (e.g., negative infinity)\n    # for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Find bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, calculate the difference between remaining capacity and item size.\n    # We want to select the bin where this difference is minimized (the \"tightest fit\").\n    # Therefore, a smaller difference means a higher priority.\n    # We can use the negative of this difference as the priority score.\n    # Smaller (bins_remain_cap - item) will result in a larger (less negative) priority.\n\n    # Calculate the difference for eligible bins\n    differences = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priority as the negative of the difference.\n    # The smaller the difference, the higher the priority.\n    priorities[can_fit_mask] = -differences\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First, then Best Fit.\n\n    This heuristic prioritizes bins that offer an exact fit for the item.\n    If no exact fit is available, it then prioritizes bins that can accommodate the item\n    with the smallest remaining capacity (Best Fit approach among the remaining options).\n    This aims to minimize wasted space and leave larger capacities available for subsequent items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Exact fits get the highest priority (e.g., 100). Bins that fit but not exactly\n        get a priority based on the \"tightness\" of the fit, inversely proportional to\n        the slack (remaining capacity - item size). Bins that cannot fit get 0 priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    fitting_indices = np.where(can_fit_mask)[0]\n\n    if fitting_bins_capacities.size == 0:\n        return priorities  # No bin can fit the item\n\n    # Calculate slack for bins that can fit the item\n    slacks = fitting_bins_capacities - item\n\n    # Exact fit has the highest priority\n    exact_fit_mask = slacks == 0\n    exact_fit_indices = fitting_indices[exact_fit_mask]\n    priorities[exact_fit_indices] = 100\n\n    # For bins that are not an exact fit, assign priority based on the slack (Best Fit)\n    # Smaller slack (tighter fit) gets a higher priority.\n    non_exact_fit_mask = slacks > 0\n    non_exact_fit_indices = fitting_indices[non_exact_fit_mask]\n    non_exact_slacks = slacks[non_exact_fit_mask]\n\n    if non_exact_fit_indices.size > 0:\n        # Sort these bins by slack in ascending order.\n        # The bin with the smallest slack (closest to fitting perfectly) gets the highest priority\n        # among the non-exact fits.\n        sorted_slack_indices = np.argsort(non_exact_slacks)\n\n        # Assign priorities decreasingly.\n        # Max priority for non-exact fits will be 99 (if exact fits exist),\n        # down to a lower value.\n        # The number of non-exact fits determines the range of these priorities.\n        max_non_exact_priority = 99\n        for i, original_index_in_fitting in enumerate(non_exact_fit_indices[sorted_slack_indices]):\n            priorities[original_index_in_fitting] = max_non_exact_priority - i\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-Based Best Fit strategy.\n\n    This heuristic prioritizes bins that have a remaining capacity closest to the item size,\n    aiming for the \"best fit\". It calculates a fitness score based on the gap between\n    the remaining capacity and the item size, preferring smaller non-negative gaps.\n    The softmax function is then used to convert these fitness scores into priorities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the \"gap\" for bins that can fit the item.\n    # We want to minimize this gap (i.e., find the best fit).\n    gaps = bins_remain_cap - item\n\n    # Initialize fitness scores. Bins that cannot fit the item will have a very low score.\n    # Using a large negative number to ensure they are not picked by softmax unless absolutely necessary.\n    fitness_scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = (gaps >= 0)\n    valid_gaps = gaps[can_fit_mask]\n\n    if np.any(can_fit_mask):\n        # For bins that can fit, we want to assign higher scores to smaller gaps.\n        # A common approach is to use an exponential decay function based on the gap.\n        # The 'temperature' parameter controls the sharpness of the distribution.\n        # A smaller temperature leads to a stronger preference for the best fit.\n        # We can set a temperature based on the average remaining capacity, or a fixed value.\n        # A small positive temperature ensures that the scores are not excessively large or small.\n        # Let's use a temperature that is related to the typical capacity values.\n        # If bins_remain_cap is empty or all zeros, use a default temperature.\n        non_zero_caps = bins_remain_cap[bins_remain_cap > 0]\n        if non_zero_caps.size > 0:\n            temperature = np.mean(non_zero_caps) / 2.0 # Heuristic for temperature\n            temperature = max(temperature, 1e-3) # Ensure temperature is positive\n        else:\n            temperature = 1.0 # Default temperature if no positive capacities\n\n        # Calculate fitness scores: exp(-gap / temperature). Smaller gap = higher score.\n        # We use a scaled version of the gap to control the spread of the exponential.\n        scaled_gaps = valid_gaps / temperature\n        positive_scores = np.exp(-scaled_gaps)\n\n        fitness_scores[can_fit_mask] = positive_scores\n\n    # Handle the case where no bins can fit the item.\n    # In this scenario, all fitness scores are -np.inf. Softmax would result in NaNs.\n    # A reasonable fallback is to assign uniform probabilities, as any bin choice is equally \"bad\".\n    if not np.any(np.isfinite(fitness_scores)):\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n\n    # Apply Softmax to convert fitness scores into probabilities (priorities).\n    # Shift scores to avoid numerical issues with very small/large exponents in exp().\n    # Subtracting the maximum finite score from all scores does not change the softmax output\n    # but can help prevent overflow/underflow issues.\n    finite_mask = np.isfinite(fitness_scores)\n    if np.any(finite_mask):\n        max_finite_score = np.max(fitness_scores[finite_mask])\n        shifted_scores = fitness_scores - max_finite_score\n    else:\n        shifted_scores = fitness_scores # Should not happen due to the check above, but for safety\n\n    # Compute the exponentiated scores. Replace -inf with 0 to avoid exp(-inf) = 0 issues\n    # which might incorrectly lead to a sum of zero if all were -inf.\n    exp_scores = np.where(np.isfinite(shifted_scores), np.exp(shifted_scores), 0)\n\n    sum_exp_scores = np.sum(exp_scores)\n\n    # If the sum is zero (e.g., all original scores were -inf, or numerical issues),\n    # fall back to uniform distribution.\n    if sum_exp_scores == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n    else:\n        priorities = exp_scores / sum_exp_scores\n        return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 30.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a balanced Epsilon-Greedy strategy.\n\n    This version aims to balance the exploitation of the \"best fit\" strategy with\n    exploration by giving a decaying exploration bonus to all valid bins.\n    This encourages trying different bins, especially when multiple bins offer\n    a similar \"best fit\".\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n    epsilon_exploration_factor = 0.2  # Controls the magnitude of the exploration bonus\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the \"best fit\" score for bins that can accommodate the item.\n    # The score is inversely proportional to the remaining space after packing,\n    # favoring bins that leave less residual capacity. Add epsilon for numerical stability.\n    best_fit_scores = np.zeros(num_bins)\n    epsilon = 1e-9\n    potential_remaining_cap = bins_remain_cap - item\n    best_fit_scores[can_fit_mask] = 1.0 / (potential_remaining_cap[can_fit_mask] + epsilon)\n\n    # Exploration bonus: Add a small, decaying bonus to all bins that can fit.\n    # This bonus is designed to be smaller than the best-fit score for clearly\n    # \"good\" fits, but significant enough to encourage exploration of less obvious\n    # fits. A simple approach is to use a fraction of the best-fit score of the\n    # *best* bin, or a fixed small value. Here, we'll use a fraction of the\n    # maximum possible \"best fit\" score (which occurs when remaining capacity is epsilon).\n    # The epsilon_exploration_factor scales this bonus.\n    exploration_bonus = np.zeros(num_bins)\n    if np.any(can_fit_mask):\n        # A baseline exploration bonus, perhaps related to the average or max fit\n        # For simplicity, let's make it a fraction of a very good fit.\n        # Consider the case where the item perfectly fills a bin, leading to a high score.\n        # A simpler approach: a small constant exploration bonus.\n        # Let's try a decaying bonus based on how \"full\" the bin would become.\n        # The fuller the bin becomes (smaller remaining capacity), the lower the exploration bonus.\n        # So, the bonus is proportional to the item size / bin capacity.\n        # We normalize the item size by a typical bin capacity (assuming unit capacity if not specified)\n        # or more generally, by the remaining capacity of the *best* fitting bin.\n\n        # A more direct approach: give a bonus proportional to the inverse of the item size.\n        # This favors trying smaller items in different bins.\n        # Let's try a simple additive exploration bonus that is uniform for all valid bins.\n        # The magnitude is controlled by epsilon_exploration_factor.\n        exploration_bonus[can_fit_mask] = epsilon_exploration_factor * (item / (bins_remain_cap[can_fit_mask] + epsilon))\n\n\n    # Combine best fit scores with exploration bonus\n    priorities[can_fit_mask] = best_fit_scores[can_fit_mask] + exploration_bonus[can_fit_mask]\n\n    # Ensure bins that cannot fit have zero priority\n    priorities[~can_fit_mask] = 0\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best-Fit strategy with exploration.\n\n    This heuristic prioritizes bins that have the smallest remaining capacity\n    greater than or equal to the item's size. A small epsilon is added to the\n    remaining capacity before calculating priority to encourage picking bins\n    that are not *exactly* full, leaving a tiny bit of slack to avoid fragmentation.\n    A small probability `epsilon` is used to explore other options.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of choosing a random bin among suitable ones\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if np.any(suitable_bins_mask):\n        # Calculate a \"fit\" score. We want to minimize `bins_remain_cap - item`.\n        # To use this in a maximization context (higher priority is better),\n        # we can use the negative of this difference, or 1/(difference + small_constant).\n        # Using 1 / (difference + small_constant) penalizes larger differences more.\n        # Adding a small epsilon `1e-6` to `bins_remain_cap` before calculating the difference\n        # can slightly favor bins that are not completely full, reducing fragmentation.\n        # The smaller `bins_remain_cap + epsilon - item` is, the higher the priority.\n        \n        # Calculate the \"slack\" for suitable bins.\n        slack = bins_remain_cap[suitable_bins_mask] - item\n        \n        # We want to prioritize bins with minimum slack.\n        # A good heuristic is `1 / (slack + a_small_value)`.\n        # The smaller the slack, the higher the priority.\n        # Adding `1e-6` to slack prevents division by zero if slack is exactly zero.\n        priorities[suitable_bins_mask] = 1.0 / (slack + 1e-6)\n\n        # Epsilon-greedy exploration: With probability epsilon, choose randomly among suitable bins.\n        if np.random.rand() < epsilon:\n            # Assign equal probability to all suitable bins\n            priorities[suitable_bins_mask] = 1.0 / np.sum(suitable_bins_mask)\n        else:\n            # Exploit: The current priorities already favor the best fit.\n            # We can optionally normalize priorities so they sum to 1 for suitable bins,\n            # but it's not strictly necessary if we just pick the max.\n            # For this function returning scores, leaving them as is is fine,\n            # as higher score implies higher preference.\n            pass\n    else:\n        # If no bin can fit the item, all priorities remain 0.\n        # In a real online BPP solver, this would typically trigger the creation of a new bin.\n        pass\n\n    return priorities",
    "response_id": 7,
    "obj": 4.0885520542481055,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using the \"Best Fit\" heuristic for the online Bin Packing Problem.\n\n    This heuristic aims to find the bin that, after placing the item, will have the\n    least remaining capacity (i.e., the tightest fit) among all bins that can\n    accommodate the item. It prioritizes bins that are closer to being full.\n    An exact fit (remaining capacity == item size) is implicitly handled as\n    it results in zero remaining capacity, which is the minimum possible.\n\n    The priority is calculated as:\n    - For bins that can fit the item: a value inversely proportional to the\n      remaining capacity after placing the item (i.e., -(bins_remain_cap - item)).\n      This means bins with less remaining capacity (tighter fit) get higher priorities.\n      The highest priority is given to the bin with the smallest non-negative\n      remaining capacity after placing the item.\n    - For bins that cannot fit the item: a priority of 0.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after packing\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities. Higher priority for smaller remaining capacity (tighter fit).\n    # We use the negative of the remaining capacity so that the minimum remaining\n    # capacity (tightest fit) gets the highest positive priority.\n    # If a bin has remaining_capacity - item = 0 (exact fit), its priority contribution is 0.\n    # If remaining_capacity - item = 5, its priority contribution is -5.\n    # The largest negative value will correspond to the smallest remaining capacity.\n    priorities[can_fit_mask] = -remaining_capacities_after_fit\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a strategy that\n    balances fitting the item well (exploitation) with leaving space for future items\n    and potentially using less full bins (exploration).\n\n    This version aims to prioritize bins that leave a small, positive remainder,\n    which is often a good heuristic for BPP. It also incorporates an exploration\n    component by occasionally favoring bins that are not necessarily the \"best\" fit,\n    to avoid getting stuck in local optima.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploration\n    num_bins = len(bins_remain_cap)\n\n    # Calculate potential remainders for bins where the item fits.\n    potential_remainders = bins_remain_cap - item\n\n    # Identify bins where the item can fit.\n    fitting_bins_mask = potential_remainders >= 0\n\n    # Calculate exploitation scores: prioritize bins with small positive remainders.\n    # A score of 1/(remainder + small_constant) means smaller remainders get higher scores.\n    # For bins that don't fit, assign a very low score (-infinity) to ensure they are not chosen.\n    exploitation_scores = np.full_like(bins_remain_cap, -np.inf)\n    \n    # For bins that fit, calculate a score based on the remainder.\n    # We want to reward bins that leave a small, positive remainder.\n    # A simple heuristic is 1 / (remainder + epsilon) for small remainders.\n    # For exact fits (remainder = 0), this gives a high score.\n    # For very small remainders, it also gives high scores.\n    # As remainder increases, the score decreases.\n    # Adding a small constant `1e-9` to the denominator for numerical stability and to avoid division by zero.\n    exploitation_scores[fitting_bins_mask] = 1.0 / (potential_remainders[fitting_bins_mask] + 1e-9)\n\n    # Normalize exploitation scores to be between 0 and 1.\n    # This makes it easier to combine with exploration scores.\n    # If no bins fit, all scores remain -inf, and normalization will result in zeros.\n    max_exploitation_score = np.max(exploitation_scores[fitting_bins_mask]) if np.any(fitting_bins_mask) else 0\n    if max_exploitation_score > 0:\n        normalized_exploitation_scores = exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(exploitation_scores) # If no bins fit, all normalized scores are 0\n\n    # Introduce exploration: with probability epsilon, pick a random bin among those that fit.\n    # With probability (1 - epsilon), pick the bin with the highest exploitation score.\n\n    # Generate random scores for exploration. We want to give a chance to bins that\n    # might not be the \"best\" according to the greedy criterion.\n    # We can generate random values and then pick among fitting bins.\n    exploration_scores = np.random.rand(num_bins)\n\n    # Combine exploitation and exploration using an epsilon-greedy approach.\n    # With probability epsilon, we use random exploration scores.\n    # With probability (1 - epsilon), we use normalized exploitation scores.\n    \n    # First, create a mask for exploration choice.\n    explore_mask = np.random.rand(num_bins) < epsilon\n\n    # For bins chosen for exploration, use their random exploration score, but only if they fit.\n    # If a bin is chosen for exploration but doesn't fit, its priority should be very low.\n    priorities = np.where(explore_mask,\n                          np.where(fitting_bins_mask, exploration_scores, -np.inf),\n                          np.where(fitting_bins_mask, normalized_exploitation_scores, -np.inf))\n\n    # Ensure that bins where the item doesn't fit have a priority of -infinity,\n    # so they are never selected. This is already handled by the `np.where` above.\n    \n    return priorities",
    "response_id": 9,
    "obj": 36.537694455524544,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin, favoring 'Best Fit'\n    while also considering exploration by slightly penalizing bins that are too full.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (Best Fit principle). To encourage exploration and\n    prevent overly filling bins prematurely, it slightly penalizes bins where\n    the item would leave very little remaining space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities # No bin can fit the item\n\n    # Calculate remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Prioritize bins that result in less remaining capacity (Best Fit)\n    # We invert the remaining capacity: smaller remaining capacity gets higher priority.\n    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0.\n    best_fit_score = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Introduce a slight penalty for bins that become \"too full\" to encourage exploration\n    # A bin is considered \"too full\" if the remaining capacity is very small relative to the item size.\n    # We want to avoid cases where placing the item leaves almost no space,\n    # as this might prevent fitting larger subsequent items.\n    # The penalty is inversely related to the remaining capacity.\n    # If remaining_after_placement is small, the penalty is higher.\n    # We use a small divisor (e.g., 100) to scale this penalty, making it a slight adjustment.\n    exploration_penalty = 1.0 / (remaining_after_placement * 100.0 + 1e-9)\n\n    # Combine the scores: prioritize best fit, but slightly penalize extreme fits\n    # Subtracting the penalty means higher penalty leads to lower priority.\n    priorities[can_fit_mask] = best_fit_score - exploration_penalty\n\n    # Ensure priorities are non-negative, as negative priorities can be problematic\n    # depending on how the selection mechanism handles them. A simple clip is effective.\n    priorities = np.clip(priorities, 0, None)\n\n    return priorities",
    "response_id": 0,
    "obj": 5.195452732349436,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a First Fit strategy with a twist.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This is a greedy approach aiming to fill bins\n    as much as possible, encouraging denser packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity\n    # This is equivalent to prioritizing bins where the item fills a larger\n    # proportion of the remaining space.\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Adding a small epsilon to avoid division by zero if remaining capacity is exactly 0,\n    # although with this logic, that case would already have a high priority.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-9)\n\n    return priorities",
    "response_id": 1,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\n"
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit Decreasing approach with a twist.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This is a greedy approach aiming to fill bins\n    as much as possible, encouraging denser packing. Additionally, it introduces\n    a slight penalty for bins with very little remaining capacity, to encourage\n    exploration and avoid prematurely closing bins that might fit larger items later.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity\n    # This is equivalent to prioritizing bins where the item fills a larger\n    # proportion of the remaining space.\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Introduce a slight penalty for bins that would have very little remaining capacity\n    # after placement. This encourages using bins with slightly more slack,\n    # potentially leaving them open for larger items later.\n    # We define \"very little remaining capacity\" as being less than the item size itself.\n    # This is a heuristic to avoid extreme fits where the bin is almost full.\n    # The penalty is applied as a subtraction, reducing the priority score.\n    penalty_mask = remaining_after_placement < item\n    priorities[can_fit_mask][penalty_mask] -= 0.1  # Adjust penalty value as needed\n\n    # Ensure priorities are not negative\n    priorities = np.maximum(priorities, 0)\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit Decreasing strategy with a twist.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (minimal slack). This encourages denser packing.\n    Additionally, it slightly penalizes bins that would become completely full\n    to encourage leaving some space for potentially larger items that might\n    arrive later, promoting a balance between filling bins and maintaining flexibility.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity (minimal slack)\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Add a small epsilon to avoid division by zero.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Introduce a slight penalty for bins that become completely full after placement.\n    # This encourages keeping some space for potentially larger future items.\n    # A small value (e.g., 0.1) is subtracted from the priority of bins that would become exactly full.\n    fully_filled_mask = (remaining_after_placement == 0)\n    priorities[can_fit_mask][fully_filled_mask] -= 0.1\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have the smallest remaining\n    capacity after the item is placed. This is a greedy approach aiming to minimize\n    slack, encouraging denser packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity.\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Adding a small epsilon to avoid division by zero if remaining capacity is exactly 0.\n    # This aims to find the \"best fit\".\n    priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-9)\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]