```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritizes bins for the online Bin Packing Problem, with enhanced strategies
    based on prior reflection.

    This heuristic categorizes bins into:
    1. Exact Fits: Bins where the item perfectly fills the remaining capacity.
       Highest priority.
    2. Near Fits (Aggressively Scaled): Bins where the item fits, and the remaining
       capacity after placement is small (below a threshold). These are prioritized
       using a scaled inverse of remaining capacity to aggressively favor tighter fits.
       The scaling is designed to be stable.
    3. General Fits: Bins where the item fits, but the remaining capacity after
       placement is not considered "near". These receive a moderate positive priority.
    4. Unfittable: Bins where the item cannot fit. These receive a priority of
       negative infinity.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array containing the remaining capacity of each bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        represents the priority score for placing the item in the corresponding bin.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # --- Configuration Parameters ---
    EXACT_FIT_PRIORITY = 100.0
    # Base score for "near fits" to distinguish them from general fits.
    NEAR_FIT_BASE_SCORE = 10.0
    # Scaling factor for aggressive prioritization of near fits. Higher means
    # more distinction between near fits.
    NEAR_FIT_AGGRESSIVE_SCALE = 50.0
    # Priority for bins that fit but are not considered "near".
    GENERAL_FIT_PRIORITY = 1.0
    # Threshold to define what constitutes a "near fit". A smaller value is stricter.
    # Relative threshold: remaining capacity < 15% of item size
    NEAR_FIT_THRESHOLD_RELATIVE = 0.15
    # Absolute threshold: remaining capacity < 5.0 units, to handle very small items or capacities
    NEAR_FIT_THRESHOLD_ABSOLUTE = 5.0

    # Small epsilon to prevent division by zero and handle floating point comparisons.
    epsilon_small = 1e-9

    # --- Identify Bin Categories ---
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities  # No bin can fit the item

    # 1. Exact Fits
    # Bins where remaining capacity is exactly the item size (within a tolerance).
    exact_fit_mask = can_fit_mask & (np.abs(bins_remain_cap - item) < epsilon_small)
    priorities[exact_fit_mask] = EXACT_FIT_PRIORITY

    # Identify potential candidates for near and general fits.
    # These are bins that can fit the item but are not exact fits.
    potential_fit_mask = can_fit_mask & ~exact_fit_mask

    if np.any(potential_fit_mask):
        potential_fit_indices = np.where(potential_fit_mask)[0]
        remaining_capacities_after_placement = bins_remain_cap[potential_fit_indices] - item

        # 2. Near Fits (Aggressively Scaled)
        # Define near fit criteria: remaining capacity is small.
        # Combine relative and absolute thresholds for robustness.
        is_near_fit_criteria = (remaining_capacities_after_placement < NEAR_FIT_THRESHOLD_ABSOLUTE) | \
                               (remaining_capacities_after_placement < item * NEAR_FIT_THRESHOLD_RELATIVE)

        near_fit_indices_subset = potential_fit_indices[is_near_fit_criteria]
        general_fit_indices_subset = potential_fit_indices[~is_near_fit_criteria]

        # Process Near Fits: Aggressively scale inverse remaining capacity.
        if len(near_fit_indices_subset) > 0:
            near_fit_remaining_caps = remaining_capacities_after_placement[is_near_fit_criteria]

            # Score based on inverse remaining capacity. Adding epsilon_small for stability.
            # This term will be large for small remaining capacities.
            # The aggressive scaling amplifies differences between smaller remaining capacities.
            near_fit_scores_raw = 1.0 / (near_fit_remaining_caps + epsilon_small)

            # Stable scaling: Shift scores to avoid large exponents, then scale.
            # Using a bounded transformation (e.g., clipping or sigmoid-like) can
            # prevent extreme values. Here we use a linear scaling after shifting.
            # This provides aggressive scaling without the risk of vanishing gradients
            # from a standard softmax if temperatures were too low or scores too extreme.
            min_raw_score = np.min(near_fit_scores_raw)
            max_raw_score = np.max(near_fit_scores_raw)
            
            # Normalize raw scores to a [0, 1] range first, then scale.
            # If all raw scores are the same, this will result in 0.5s.
            if max_raw_score - min_raw_score > epsilon_small:
                normalized_near_fit_scores = (near_fit_scores_raw - min_raw_score) / (max_raw_score - min_raw_score)
            else:
                normalized_near_fit_scores = np.full_like(near_fit_scores_raw, 0.5) # Default to middle if all same

            # Apply aggressive scaling to the normalized scores.
            scaled_near_fit_priorities = NEAR_FIT_BASE_SCORE + normalized_near_fit_scores * NEAR_FIT_AGGRESSIVE_SCALE
            priorities[near_fit_indices_subset] = scaled_near_fit_priorities

        # 3. General Fits
        # Bins that fit the item but are not exact or near fits.
        if len(general_fit_indices_subset) > 0:
            priorities[general_fit_indices_subset] = GENERAL_FIT_PRIORITY

    return priorities
```
