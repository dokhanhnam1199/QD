{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes exact fits first. For bins that do not offer\n    an exact fit, it uses a scaled softmax on the inverse remaining capacity.\n    This encourages tighter packing by giving higher priority to bins that\n    will have less remaining space after the item is placed. The scaling factor\n    adapts the exploration based on the number of available bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Prioritize exact fits\n    exact_fit_mask = np.isclose(remaining_after_placement, 0.0)\n    priorities[can_fit_mask][exact_fit_mask] = 1.0\n\n    # For near fits, use scaled softmax on inverse remaining capacity\n    near_fit_mask = ~exact_fit_mask\n    if np.any(can_fit_mask[can_fit_mask][near_fit_mask]):\n        near_fit_remaining = remaining_after_placement[near_fit_mask]\n        \n        # Inverse remaining capacity, higher value for smaller remaining capacity\n        # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0\n        inverse_remaining = 1.0 / (near_fit_remaining + 1e-9)\n\n        # Scale the scores to make the highest score more prominent, especially with fewer bins\n        # A simple scaling could be to multiply by the number of bins that can fit the item\n        # or a function of it to encourage exploration on more options when many are available.\n        # Here, we use a simple scaling based on the number of fitting bins to adjust exploration.\n        # A larger number of fitting bins might warrant a slightly wider spread in priorities.\n        # Alternatively, a fixed scaling factor can be used, but dynamic scaling can be more adaptive.\n        # Let's use a scaling factor that is inversely proportional to the number of fitting bins to keep priorities\n        # from becoming too extreme when many options exist.\n        num_fitting_bins = np.sum(can_fit_mask)\n        if num_fitting_bins > 0:\n            scaling_factor = 1.0  # Keep a baseline, can be tuned\n            # For more aggressive exploration, a factor like np.log(num_fitting_bins + 1)\n            # For more conservative, like 1/num_fitting_bins\n            \n            scaled_scores = inverse_remaining * scaling_factor\n            \n            # Apply softmax to get probabilities, which are used as priorities\n            # Softmax naturally handles the relative differences.\n            # We add a small constant to the logits to ensure that even if all inverse_remaining are very close,\n            # there's still some differentiation.\n            priorities[can_fit_mask][near_fit_mask] = softmax(scaled_scores)\n        else:\n             priorities[can_fit_mask][near_fit_mask] = 0.0 # Should not happen if can_fit_mask is true\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a greedy strategy\n    that prioritizes exact fits and uses scaled softmax for near fits.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (encouraging tighter packing). For bins that are\n    close to an exact fit, it uses a scaled softmax function on the inverse\n    remaining capacity to amplify the preference for tighter fits. This aims to\n    adapt exploration for fewer, direct improvements by favoring solutions\n    that are closer to optimal.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bins can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Prioritize exact fits: if remaining capacity is 0, give a very high priority.\n    # For near fits, use scaled softmax on the inverse remaining capacity.\n    # The scaling factor (e.g., 10) is a hyperparameter to tune the \"aggressiveness\"\n    # of prioritizing tighter fits. A higher scale makes smaller remaining capacities\n    # contribute much more to the priority.\n    scale_factor = 10.0\n    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0.\n    # The softmax will naturally handle 0 remaining capacity with a high value.\n    inverse_remaining_capacity = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Apply scaled softmax to the inverse remaining capacities\n    # Softmax: exp(scaled_values) / sum(exp(scaled_values))\n    # This will turn the inverse remaining capacities into a probability-like distribution\n    # where smaller remaining capacities (larger inverse capacities) get higher scores.\n    scaled_inverse_capacity = scale_factor * inverse_remaining_capacity\n    exp_scaled_inverse_capacity = np.exp(scaled_inverse_capacity)\n    softmax_scores = exp_scaled_inverse_capacity / np.sum(exp_scaled_inverse_capacity)\n\n    priorities[can_fit_mask] = softmax_scores\n\n    return priorities\n\n[Reflection]\nPrioritize exact fits. Tune softmax scaling for near fits, favoring tighter packing.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}