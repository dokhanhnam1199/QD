[
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem using a refined strategy.\n    This heuristic prioritizes exact fits, then uses a temperature-controlled\n    softmax on the inverse of remaining capacity for near fits to encourage exploration\n    while favoring bins with less remaining space.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    temperature = 0.5  # Tunable parameter for exploration. Lower = more greedy.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    fitting_bins_remain_cap = bins_remain_cap[fitting_bins_indices]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign a very high priority for exact fits.\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    exact_fit_indices = fitting_bins_indices[exact_fit_mask_subset]\n    priorities[exact_fit_indices] = 100.0\n\n    # Handle near fits using a softmax on the inverse of remaining capacity.\n    # This favors bins with less remaining capacity among the near fits.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    near_fit_indices_subset = fitting_bins_indices[near_fit_mask_subset]\n\n    if np.any(near_fit_mask_subset):\n        near_fit_remaining = remaining_after_placement[near_fit_mask_subset]\n\n        # Calculate scores for near fits: higher score for smaller remaining capacity.\n        # Use inverse of remaining capacity to achieve this. Add epsilon for stability.\n        epsilon_small = 1e-6\n        near_fit_scores_for_softmax = 1.0 / (near_fit_remaining + epsilon_small)\n\n        # Apply softmax for exploration. Higher scores (smaller remaining capacity) get higher probabilities.\n        # Ensure numerical stability for exp by shifting scores.\n        if near_fit_scores_for_softmax.size > 0:\n            max_score = np.max(near_fit_scores_for_softmax)\n            shifted_scores = near_fit_scores_for_softmax - max_score\n            \n            # Avoid potential division by zero if all shifted_scores are -inf\n            if np.all(np.isneginf(shifted_scores)):\n                exp_scores = np.ones_like(shifted_scores)\n            else:\n                exp_scores = np.exp(shifted_scores / temperature)\n            \n            sum_exp_scores = np.sum(exp_scores)\n\n            if sum_exp_scores > 0:\n                softmax_probabilities = exp_scores / sum_exp_scores\n            else:\n                # Fallback to uniform if sum is zero (e.g., all exp_scores were 0)\n                softmax_probabilities = np.ones_like(exp_scores) / len(exp_scores)\n\n            # Scale these probabilities to a range that is lower than exact fits,\n            # but reflects the relative preference. A range like [50, 99.9] would be suitable.\n            # Higher softmax probability (from smaller remaining capacity) results in a higher score.\n            scaled_near_fit_priorities = 50.0 + softmax_probabilities * 49.9\n\n            priorities[near_fit_indices_subset] = scaled_near_fit_priorities\n\n    # Ensure any bin that can fit but wasn't assigned a priority (e.g., if near_fit_mask_subset was empty)\n    # gets a minimal positive priority. This scenario is less likely with the current logic\n    # but good for robustness.\n    default_low_priority = 1.0\n    unassigned_fitting_bins = np.where(can_fit_mask & (priorities == -np.inf))[0]\n    priorities[unassigned_fitting_bins] = default_low_priority\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 36.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response1.txt_stdout.txt",
    "code_path": "problem_iter10_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy with explicit prioritization of exact fits.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it first gives the highest priority to exact fits. For bins that are not\n    exact fits but can accommodate the item, it assigns priority based on\n    how much remaining capacity is left, favoring smaller remaining capacities.\n    This strategy is a greedy approach aiming to fill bins as much as possible\n    while also rewarding perfect fits.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate remaining capacity if item is placed\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign highest priority to exact fits\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    priorities[can_fit_mask][exact_fit_mask_subset] = 100.0  # High priority for exact fits\n\n    # For bins that fit but are not exact fits, prioritize those with less remaining capacity.\n    # A higher score means less remaining capacity after placement.\n    non_exact_fit_indices_subset = np.where(~exact_fit_mask_subset)[0]\n\n    if non_exact_fit_indices_subset.size > 0:\n        non_exact_fitting_bins_remain_cap = fitting_bins_remain_cap[~exact_fit_mask_subset]\n        non_exact_remaining_after_placement = non_exact_fitting_bins_remain_cap - item\n\n        # Prioritize smaller remaining capacities. Use inverse for higher score.\n        # Add a small epsilon to avoid division by zero if remaining capacity is very close to zero.\n        fit_scores_for_non_exact = 1.0 / (non_exact_remaining_after_placement + 1e-9)\n\n        # Scale these priorities to be lower than exact fits but still positive.\n        # The maximum possible value of fit_scores_for_non_exact depends on the\n        # minimum non-zero remaining capacity. We can normalize or use a fixed\n        # scaling to ensure they are below the exact fit priority.\n        # A simple approach is to scale by a factor that ensures they are less than 100.\n        # For example, if the minimum remaining capacity for non-exact fits is `min_rem_non_exact`,\n        # the max score is `1 / (min_rem_non_exact + epsilon)`.\n        # We can scale this by `99.0 / max(fit_scores_for_non_exact)` to bound them\n        # between 0 and 99.\n        max_score_non_exact = np.max(fit_scores_for_non_exact)\n        if max_score_non_exact > 0:\n            scaled_priorities = (fit_scores_for_non_exact / max_score_non_exact) * 99.0\n            priorities[can_fit_mask][~exact_fit_mask_subset] = scaled_priorities\n        else: # This case implies all non-exact fits have remaining capacity close to 0, which shouldn't happen if they are not exact fits.\n            priorities[can_fit_mask][~exact_fit_mask_subset] = 99.0 # Assign a high non-exact priority\n\n    return priorities",
    "response_id": 1,
    "obj": 4.487435181491823,
    "SLOC": 21.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response2.txt_stdout.txt",
    "code_path": "problem_iter10_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This is a greedy approach aiming to fill bins\n    as much as possible, encouraging denser packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to negative infinity for bins that cannot fit the item.\n    # A higher score indicates higher priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate their priority.\n    # The priority is defined as the negative of the remaining capacity after placing the item.\n    # This ensures that bins with smaller remaining capacities (tighter fits)\n    # will have higher priority scores (closer to zero or positive if the remaining is negative).\n    # Using a negative value for remaining capacity directly translates to \"less empty space\",\n    # which is the core idea of Best Fit.\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = -remaining_capacities_after_fit\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response3.txt_stdout.txt",
    "code_path": "problem_iter10_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem, favoring exact fits\n    and using a softmax approach based on the inverse of remaining capacity\n    for other fitting bins to balance exploitation and exploration.\n\n    This heuristic assigns the highest priority to bins where the item fits exactly.\n    For bins that can fit the item but not exactly, it calculates a priority score\n    based on the inverse of the remaining capacity after placement. This score\n    is then passed through a softmax function with a temperature parameter,\n    allowing for exploration. Higher inverse remaining capacity (i.e., smaller\n    remaining capacity) leads to a higher score before softmax.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score of placing the item in the corresponding bin.\n        Bins that cannot fit the item will have a priority of -np.inf.\n    \"\"\"\n    temperature = 0.5  # Tunable parameter for exploration. Lower = more greedy.\n\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign a very high priority to exact fits\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    priorities[can_fit_mask][exact_fit_mask_subset] = 100.0\n\n    # For bins that fit but are not exact fits, calculate scores for softmax\n    non_exact_fit_indices_subset = np.where(~exact_fit_mask_subset)[0]\n\n    if non_exact_fit_indices_subset.size > 0:\n        non_exact_fitting_bins_remain_cap_subset = fitting_bins_remain_cap[~exact_fit_mask_subset]\n        non_exact_remaining_after_placement = non_exact_fitting_bins_remain_cap_subset - item\n\n        # Calculate scores for softmax: higher score for smaller remaining capacity (better fit)\n        # Use inverse of remaining capacity. Add epsilon to avoid division by zero.\n        fit_scores_for_softmax = 1.0 / (non_exact_remaining_after_placement + 1e-9)\n\n        # Apply softmax for exploration.\n        # Shift scores so the maximum is 0 for numerical stability with exp.\n        if fit_scores_for_softmax.size > 0:\n            shifted_fit_scores = fit_scores_for_softmax - np.max(fit_scores_for_softmax)\n            soft_priorities = np.exp(shifted_fit_scores / temperature)\n\n            # Scale these priorities to be less than the exact fit priority (100.0)\n            # and ensure they are positive. Max value of soft_priorities is 1.0.\n            scale_factor = 99.0\n            priorities[can_fit_mask][~exact_fit_mask_subset] = soft_priorities * scale_factor\n\n    return priorities",
    "response_id": 3,
    "obj": 4.487435181491823,
    "SLOC": 21.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response4.txt_stdout.txt",
    "code_path": "problem_iter10_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Best-Fit strategy.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns higher priority to bins that result in less remaining capacity,\n    thus encouraging tighter packing. It also introduces a small bonus for\n    exact fits to ensure they are always preferred.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate their priority.\n    # The priority is the negative of the remaining capacity after placing the item.\n    # This means bins with smaller remaining capacity (tighter fits) will have higher priorities.\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign a base priority based on how tight the fit is.\n    # A smaller remaining capacity (closer to 0) results in a higher priority (less negative).\n    base_priorities = -remaining_capacities_after_fit\n\n    # Introduce a bonus for exact fits. Exact fits have remaining_capacities_after_fit == 0.\n    # Adding a positive constant (e.g., 1.0) to the priority of exact fits ensures\n    # they are always preferred over near fits, even if the near fit is very close.\n    exact_fit_bonus = np.zeros_like(base_priorities)\n    exact_fit_bonus[remaining_capacities_after_fit == 0] = 1.0\n\n    priorities[can_fit_mask] = base_priorities + exact_fit_bonus\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response5.txt_stdout.txt",
    "code_path": "problem_iter10_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (exact fits are preferred). This is a greedy approach\n    aiming to fill bins as much as possible, encouraging denser packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    # Bins that can fit will have their priorities calculated.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate their priority.\n    # The priority is the negative of the remaining capacity after placing the item.\n    # This means bins with smaller remaining capacity (tighter fits) will have higher priorities.\n    # We directly assign the negative remaining capacity as the priority score.\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = -remaining_capacities_after_fit\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response6.txt_stdout.txt",
    "code_path": "problem_iter10_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem, favoring exact fits and minimal slack,\n    with temperature-controlled exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among fitting bins,\n    it assigns the highest priority to exact fits (zero remaining capacity after packing).\n    For bins that don't offer an exact fit, it assigns priority based on the\n    inverse of the slack (remaining capacity after packing), scaled by a temperature\n    parameter. A higher temperature leads to smoother priority distributions,\n    increasing the chance of selecting bins that are not the absolute best fit.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n        Bins that cannot fit the item will have a priority of 0.\n    \"\"\"\n    temperature = 1.0  # Tunable parameter for exploration\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return all zeros.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the slack for bins that can fit the item.\n    # Slack is the remaining capacity after placing the item.\n    slack = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities:\n    # - Highest priority for exact fits (slack == 0)\n    # - For non-exact fits, priority is inversely proportional to slack, scaled by temperature.\n    #   Use exp(-slack / temperature) to give higher priority to smaller slack.\n\n    # Separate exact fits to give them maximum priority\n    exact_fit_indices_in_subset = np.where(slack == 0)[0]\n    priorities[can_fit_mask][exact_fit_indices_in_subset] = 1e6  # High priority for exact fits\n\n    # Calculate priorities for bins with positive slack\n    positive_slack_indices_in_subset = np.where(slack > 0)[0]\n    positive_slack_values = slack[positive_slack_indices_in_subset]\n\n    # Use exp(-slack / temperature) for exploration. Smaller slack gets higher priority.\n    # Adding a small epsilon to slack in the denominator of exp argument could be done,\n    # but using the slack value directly in the exponent is more standard for this type of scaling.\n    # `np.exp(-value / temperature)`: as `value` (slack) decreases, `np.exp` increases.\n    scaled_priorities = np.exp(-positive_slack_values / temperature)\n    \n    # Apply these scaled priorities to the corresponding bins\n    priorities[can_fit_mask][positive_slack_indices_in_subset] = scaled_priorities\n\n    # Normalize priorities to be between 0 and 1 (optional, but good practice)\n    # If only exact fits exist, max_priority would be 1e6. If only positive slack,\n    # max_priority would be from the exp calculation. If no bins fit, it's 0.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities /= max_priority\n\n    return priorities",
    "response_id": 6,
    "obj": 4.487435181491823,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response7.txt_stdout.txt",
    "code_path": "problem_iter10_code7.py",
    "code": "import numpy as np\nimport scipy.special\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem.\n    This strategy prioritizes exact fits, then uses a temperature-controlled softmax\n    on the inverse remaining capacity for near fits, and assigns a low base priority\n    to bins that fit but are not near fits. Bins that cannot fit receive a very low priority.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    \n    # Identifiable priorities for different categories\n    EXACT_FIT_PRIORITY = 100.0\n    NEAR_FIT_BASE_SCORE = 50.0 # Base score for near fits before softmax scaling\n    NEAR_FIT_SCALE = 40.0     # Scaling factor for softmax probabilities\n    LOW_PRIORITY_FOR_FITTING_BIN = 1.0 # For bins that fit but are not 'near'\n\n    # Temperature for softmax to control exploration among near fits\n    # Higher temperature means more exploration (priorities are more uniform)\n    # Lower temperature means less exploration (priorities are more skewed towards best fits)\n    TEMPERATURE = 0.5 # Tunable parameter\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # --- Handle Exact Fits ---\n    exact_fit_mask = can_fit_mask & (bins_remain_cap == item)\n    priorities[exact_fit_mask] = EXACT_FIT_PRIORITY\n\n    # --- Handle Near Fits ---\n    # Bins that can fit, but are not exact fits.\n    near_fit_potential_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(near_fit_potential_mask):\n        near_fit_indices = np.where(near_fit_potential_mask)[0]\n        remaining_capacities_for_near_fits = bins_remain_cap[near_fit_indices] - item\n\n        # To prioritize smaller remaining capacities, we can use their inverse.\n        # Add a small epsilon to avoid division by zero.\n        epsilon_small = 1e-6\n        # The score should be higher for smaller remaining_capacities_for_near_fits.\n        # Using 1 / (remaining + epsilon) achieves this.\n        # We also want to ensure these scores are distinctly lower than EXACT_FIT_PRIORITY.\n        # The scaling and softmax will handle this.\n        near_fit_scores = 1.0 / (remaining_capacities_for_near_fits + epsilon_small)\n\n        # Apply softmax to convert scores into probabilities for exploration.\n        # Higher scores (smaller remaining capacity) will get higher probabilities.\n        if len(near_fit_scores) > 0:\n            # Shift scores before exponentiation to prevent potential underflow/overflow\n            max_score = np.max(near_fit_scores)\n            shifted_scores = near_fit_scores - max_score\n            \n            exp_scores = np.exp(shifted_scores / TEMPERATURE)\n            sum_exp_scores = np.sum(exp_scores)\n\n            if sum_exp_scores > 0:\n                softmax_probabilities = exp_scores / sum_exp_scores\n            else:\n                # Fallback to uniform if all exponentiated scores are zero or NaN\n                softmax_probabilities = np.ones_like(near_fit_scores) / len(near_fit_scores)\n            \n            # Scale these probabilities to a range that is lower than exact fits\n            # but reflects the preference for smaller remaining capacity.\n            scaled_near_fit_priorities = NEAR_FIT_BASE_SCORE + softmax_probabilities * NEAR_FIT_SCALE\n            priorities[near_fit_indices] = scaled_near_fit_priorities\n\n    # --- Handle remaining fitting bins ---\n    # Any bin that can fit the item but was not assigned an exact or near-fit priority\n    # (e.g., if the 'near fit' criteria were too strict, or if there were no near fits processed)\n    # should get a low, positive priority to indicate they are usable.\n    # This mask identifies bins that can fit but currently have the default -np.inf priority.\n    unassigned_fitting_mask = can_fit_mask & (priorities == -np.inf)\n    priorities[unassigned_fitting_mask] = LOW_PRIORITY_FOR_FITTING_BIN\n    \n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 32.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response8.txt_stdout.txt",
    "code_path": "problem_iter10_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin, prioritizing\n    minimal slack, penalizing exact fits, and exploring small positive remainders.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (minimal slack). This encourages denser packing.\n    A penalty is applied to bins that would become completely full, discouraging\n    exact fits. To introduce an exploratory element, bins that result in a\n    small, positive remainder (e.g., up to 5% of the item's size) are given a\n    moderate boost to their priority. This encourages leaving a useful, but not\n    excessive, amount of space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Base priority: prioritize bins with minimal slack.\n    # Higher score for smaller remainders. Use negative to sort ascending.\n    # Add a small epsilon to avoid ties with exact fits if we don't want to penalize them heavily\n    base_priorities = -remaining_after_placement\n\n    # Penalty for bins that would become exactly full.\n    # Subtract a value to make exact fits less attractive than small positive remainders.\n    # The magnitude of the penalty can be tuned.\n    penalty_for_full = 0.1\n    fully_filled_mask = (remaining_after_placement == 0)\n    priorities[can_fit_mask] = base_priorities\n    priorities[can_fit_mask][fully_filled_mask] -= penalty_for_full\n\n    # Exploratory boost: favor bins that have a small positive remainder.\n    # A small positive remainder is considered to be up to 5% of the item's size.\n    exploratory_boost_threshold = 0.05 * item\n    small_positive_remainder_mask = (remaining_after_placement > 0) & (remaining_after_placement <= exploratory_boost_threshold)\n    exploratory_boost_value = 0.2  # Moderate boost value\n    priorities[can_fit_mask][small_positive_remainder_mask] += exploratory_boost_value\n\n    # Ensure all priorities are non-negative by shifting if necessary.\n    # Find the minimum priority among valid choices and shift all priorities up.\n    valid_priorities = priorities[can_fit_mask]\n    if valid_priorities.size > 0:\n        min_valid_priority = np.min(valid_priorities)\n        if min_valid_priority < 0:\n            priorities[can_fit_mask] -= min_valid_priority\n\n    # Ensure non-fitting bins have the lowest possible priority (0 after shift)\n    priorities[~can_fit_mask] = 0.0\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response9.txt_stdout.txt",
    "code_path": "problem_iter10_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This aims for denser packing by favoring bins\n    that are nearly full. It uses a transformation that emphasizes exact fits\n    and penalizes larger remaining capacities more severely than a simple inverse.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Transform remaining capacity to priority.\n        # We want smaller remaining_after_placement to have higher priority.\n        # Using `1.0 / (1.0 + slack)` gives a score between 0 and 1, where 1 is for exact fit.\n        # To more strongly emphasize exact fits and penalize larger slacks,\n        # we can use a transformation like `exp(-alpha * slack)` or `1 / (1 + slack^beta)`.\n        # Let's use a transformation that grows faster as slack decreases.\n        # A hyperbolic tangent or a power function could also work.\n        # For now, let's use a simple inverse with a power to make the preference for small slack stronger.\n        # For example, `1.0 / (1.0 + slack**2)` would give higher scores for smaller slacks.\n        # An alternative is `1.0 - (remaining_after_placement / max(bins_remain_cap))`.\n        # Let's use `1.0 / (1.0 + remaining_after_placement)` as it's intuitive and bounded.\n        # To make it more aggressive towards exact fits, we can scale the remaining capacity\n        # before applying the inverse.\n\n        # Example: Scale slack by a factor `k` before taking the inverse.\n        # `k = 2.0` or higher would make exact fits much more preferred.\n        k = 2.0  # Tunable parameter to control preference for exact fits\n        priorities[can_fit_mask] = 1.0 / (1.0 + k * remaining_after_placement)\n\n        # Alternative: Use an exponential decay, similar to softmax but without normalization.\n        # `priorities[can_fit_mask] = np.exp(-k * remaining_after_placement)`\n        # This can also work well and is often used. The `1/(1+x)` form is less prone to overflow\n        # if `k` is very large. Let's stick with the inverse form for now.\n\n    return priorities",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a scaled softmax on inverse remaining capacity.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This is a greedy approach aiming to fill bins\n    as much as possible, encouraging denser packing. A scaled softmax is used\n    to provide a smoother distribution of priorities and encourage exploration\n    among near-fitting bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate inverse remaining capacity. Add a small epsilon to avoid division by zero.\n    inverse_remaining_capacity = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Apply softmax with a scaling factor.\n    # The scaling factor can be tuned. A higher scale emphasizes differences.\n    # Here, we use a simple scaling related to the number of bins,\n    # but a more adaptive or fixed scale could also be used.\n    scale_factor = 1.0  # This can be adjusted.\n    scaled_scores = scale_factor * inverse_remaining_capacity\n\n    # Calculate softmax probabilities.\n    # Add a small value to the scores before exp to avoid very small numbers\n    # and potential underflow with exp.\n    exp_scores = np.exp(scaled_scores - np.max(scaled_scores)) # For numerical stability\n    softmax_priorities = exp_scores / np.sum(exp_scores)\n\n    # Assign the calculated priorities to the bins that can fit the item.\n    priorities[can_fit_mask] = softmax_priorities\n\n    # To handle cases where no bins can fit, or to ensure a minimum priority,\n    # you might add a small baseline priority or handle the 'no fit' scenario\n    # by creating a new bin (which is outside the scope of this function).\n    # For this function, if no bins fit, all priorities remain 0.\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a First Fit strategy with a twist.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This is a greedy approach aiming to fill bins\n    as much as possible, encouraging denser packing. It uses a scaled softmax\n    on the inverse remaining capacity to encourage tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Adding a small epsilon to avoid division by zero if remaining capacity is exactly 0.\n    inverse_remaining_capacity = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Scale the inverse remaining capacity to potentially encourage exploration\n    # A simple scaling factor can be used, or it could be adapted based on\n    # the distribution of remaining capacities. Here, we use a fixed scaling\n    # for demonstration.\n    scaling_factor = 1.0  # This could be tuned or made dynamic\n    scaled_priorities = scaling_factor * inverse_remaining_capacity\n\n    # Apply softmax to the scaled priorities. This can help in creating a\n    # smoother distribution of priorities among fitting bins, potentially\n    # leading to more exploration of near-perfect fits.\n    # Add a small epsilon before exp to prevent numerical instability if all scaled_priorities are very large negative.\n    # (Though in this case, they are positive).\n    exp_priorities = np.exp(scaled_priorities)\n    softmax_priorities = exp_priorities / np.sum(exp_priorities + 1e-9) # Add epsilon to sum to avoid division by zero if sum is zero\n\n    priorities[can_fit_mask] = softmax_priorities\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a First Fit strategy with a twist.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This is a greedy approach aiming to fill bins\n    as much as possible, encouraging denser packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign higher priority to bins that will have less remaining capacity\n    # This is equivalent to prioritizing bins where the item fills a larger\n    # proportion of the remaining space.\n    # We invert the remaining capacity so that smaller remaining capacity gets higher priority.\n    # Adding a small epsilon to avoid division by zero if remaining capacity is exactly 0,\n    # although with this logic, that case would already have a high priority.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-9)\n\n    return priorities",
    "response_id": 2,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\n"
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a greedy strategy\n    that prioritizes exact fits and uses scaled softmax for near fits.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (encouraging tighter packing). For bins that are\n    close to an exact fit, it uses a scaled softmax function on the inverse\n    remaining capacity to amplify the preference for tighter fits. This aims to\n    adapt exploration for fewer, direct improvements by favoring solutions\n    that are closer to optimal.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bins can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Prioritize exact fits: if remaining capacity is 0, give a very high priority.\n    # For near fits, use scaled softmax on the inverse remaining capacity.\n    # The scaling factor (e.g., 10) is a hyperparameter to tune the \"aggressiveness\"\n    # of prioritizing tighter fits. A higher scale makes smaller remaining capacities\n    # contribute much more to the priority.\n    scale_factor = 10.0\n    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0.\n    # The softmax will naturally handle 0 remaining capacity with a high value.\n    inverse_remaining_capacity = 1.0 / (remaining_after_placement + 1e-9)\n\n    # Apply scaled softmax to the inverse remaining capacities\n    # Softmax: exp(scaled_values) / sum(exp(scaled_values))\n    # This will turn the inverse remaining capacities into a probability-like distribution\n    # where smaller remaining capacities (larger inverse capacities) get higher scores.\n    scaled_inverse_capacity = scale_factor * inverse_remaining_capacity\n    exp_scaled_inverse_capacity = np.exp(scaled_inverse_capacity)\n    softmax_scores = exp_scaled_inverse_capacity / np.sum(exp_scaled_inverse_capacity)\n\n    priorities[can_fit_mask] = softmax_scores\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\nfrom scipy.special import softmax\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes exact fits first. For bins that do not offer\n    an exact fit, it uses a scaled softmax on the inverse remaining capacity.\n    This encourages tighter packing by giving higher priority to bins that\n    will have less remaining space after the item is placed. The scaling factor\n    adapts the exploration based on the number of available bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Prioritize exact fits\n    exact_fit_mask = np.isclose(remaining_after_placement, 0.0)\n    priorities[can_fit_mask][exact_fit_mask] = 1.0\n\n    # For near fits, use scaled softmax on inverse remaining capacity\n    near_fit_mask = ~exact_fit_mask\n    if np.any(can_fit_mask[can_fit_mask][near_fit_mask]):\n        near_fit_remaining = remaining_after_placement[near_fit_mask]\n        \n        # Inverse remaining capacity, higher value for smaller remaining capacity\n        # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0\n        inverse_remaining = 1.0 / (near_fit_remaining + 1e-9)\n\n        # Scale the scores to make the highest score more prominent, especially with fewer bins\n        # A simple scaling could be to multiply by the number of bins that can fit the item\n        # or a function of it to encourage exploration on more options when many are available.\n        # Here, we use a simple scaling based on the number of fitting bins to adjust exploration.\n        # A larger number of fitting bins might warrant a slightly wider spread in priorities.\n        # Alternatively, a fixed scaling factor can be used, but dynamic scaling can be more adaptive.\n        # Let's use a scaling factor that is inversely proportional to the number of fitting bins to keep priorities\n        # from becoming too extreme when many options exist.\n        num_fitting_bins = np.sum(can_fit_mask)\n        if num_fitting_bins > 0:\n            scaling_factor = 1.0  # Keep a baseline, can be tuned\n            # For more aggressive exploration, a factor like np.log(num_fitting_bins + 1)\n            # For more conservative, like 1/num_fitting_bins\n            \n            scaled_scores = inverse_remaining * scaling_factor\n            \n            # Apply softmax to get probabilities, which are used as priorities\n            # Softmax naturally handles the relative differences.\n            # We add a small constant to the logits to ensure that even if all inverse_remaining are very close,\n            # there's still some differentiation.\n            priorities[can_fit_mask][near_fit_mask] = softmax(scaled_scores)\n        else:\n             priorities[can_fit_mask][near_fit_mask] = 0.0 # Should not happen if can_fit_mask is true\n\n    return priorities",
    "response_id": 4,
    "obj": 4.487435181491823,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]