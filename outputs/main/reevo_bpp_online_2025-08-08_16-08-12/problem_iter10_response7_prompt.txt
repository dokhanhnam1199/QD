{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (exact fits are preferred). It then considers\n    bins with slightly more slack. Softmax is used to convert these scores into\n    probabilities, with a temperature parameter to control exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    temperature = 1.0  # Tunable parameter for exploration\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Prioritize exact fits (remaining capacity is 0)\n        # Then prioritize bins with minimal slack.\n        # We want smaller remaining_after_placement to have higher priority.\n        # Adding a small constant to avoid log(0) and to ensure positive values.\n        # Scaling by a factor to make differences more pronounced before softmax.\n        # An arbitrary scaling factor, could be tuned.\n        scaled_slack_scores = -1.0 / (remaining_after_placement + 1e-9)\n\n        # Apply softmax to convert scores to probabilities (priorities)\n        # Higher scores (smaller slack) will get higher probabilities\n        priorities[can_fit_mask] = scipy.special.softmax(scaled_slack_scores / temperature)\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem.\n    This strategy prioritizes exact fits, then near fits using a soft-max approach\n    for exploration among near-fitting bins, and penalizes bins with very large remaining capacities.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    fitting_bins_remain_cap = bins_remain_cap[fitting_bins_indices]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign very high priority for exact fits\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    exact_fit_indices = fitting_bins_indices[exact_fit_mask_subset]\n    priorities[exact_fit_indices] = 100.0\n\n    # Handle near fits with a softmax for exploration.\n    # Lower remaining capacity should lead to a higher score.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    near_fit_indices_subset = fitting_bins_indices[near_fit_mask_subset]\n\n    if np.any(near_fit_mask_subset):\n        near_fit_remaining = remaining_after_placement[near_fit_mask_subset]\n\n        # Calculate scores for near fits. We want to prioritize smaller remaining capacities.\n        # Using negative remaining capacity: smaller capacity -> less negative score -> higher priority.\n        # Add a small constant to ensure scores are not zero for softmax, and to keep them lower than exact fits.\n        # We also want to penalize bins with very large remaining capacity if they are not exact fits.\n        # A simple way is to make the priority decrease as remaining capacity increases beyond a certain point.\n        # Let's use a transformation that is high for small remaining, and tapers off.\n        # A negative exponential function could work: exp(-k * remaining_capacity)\n        # Or, simply use the negative remaining capacity and apply softmax.\n        # Let's ensure the scores are positive for softmax, and scale them.\n        \n        # Calculate \"desirability\" for near fits: higher for smaller remaining capacity.\n        # We can use a scale where 0 remaining capacity is best, and it degrades.\n        # Let's map the remaining capacities to a desirability score.\n        # Smallest remaining capacity should get highest score among near fits.\n        # Max value for near fits to avoid extreme values in exp\n        max_near_fit_remaining = np.max(near_fit_remaining) if near_fit_remaining.size > 0 else 0\n        \n        # Calculate scores that are higher for smaller remaining capacity.\n        # We scale by a factor to ensure they are less than exact fits.\n        # A simple approach: -(remaining_capacity).\n        # To make it suitable for softmax and exploration, we want values that differentiate.\n        # Let's consider the inverse of remaining capacity (plus a small epsilon to avoid division by zero).\n        # Or more simply, negative of remaining capacity, shifted and scaled.\n\n        # We want values that increase as remaining capacity decreases.\n        # `near_fit_remaining` values are >= 0.\n        # Let's transform `near_fit_remaining` into \"fitness scores\" where higher is better.\n        # Score = max_remaining_if_near_fit - current_remaining_if_near_fit\n        # This makes exact fits (0 remaining) have the highest score among near fits.\n        # But we already handled exact fits separately with a fixed high score.\n        # For near fits, we want to prioritize smaller `near_fit_remaining`.\n        \n        # Let's use -near_fit_remaining as base scores. Add a base value to shift it.\n        # A base value like 10.0 could be used.\n        # Score = 10.0 - near_fit_remaining\n        \n        # The problem is that `near_fit_remaining` can vary widely.\n        # If we want to use softmax for exploration, we need scores that can be exponentiated.\n        # Let's use the negative of remaining capacity as the base score.\n        # We need to scale and shift these to be positive for softmax and to be distinct from exact fits.\n        \n        # Calculate base priorities: prioritize smaller remaining capacity.\n        # We want to assign higher scores to bins with smaller `near_fit_remaining`.\n        # Let's use `-near_fit_remaining` as the raw score.\n        # To make it suitable for softmax, we can shift and scale it.\n        # Example: shift to make all values positive, then scale.\n        \n        # Calculate values that are higher for smaller remaining capacity.\n        # If remaining capacity is 0.1, score is higher than if it's 0.5.\n        # Let's try `1 / (near_fit_remaining + epsilon)`.\n        epsilon_small = 1e-6\n        near_fit_scores_for_softmax = 1.0 / (near_fit_remaining + epsilon_small)\n        \n        # Normalize these scores using softmax for exploration.\n        # Softmax will give higher probabilities to bins with smaller remaining capacity (larger scores).\n        temperature = 1.0  # Tunable parameter for exploration control\n\n        # Shift scores to prevent numerical underflow/overflow in exp\n        max_score = np.max(near_fit_scores_for_softmax)\n        shifted_scores = near_fit_scores_for_softmax - max_score\n        \n        exp_scores = np.exp(shifted_scores / temperature)\n        sum_exp_scores = np.sum(exp_scores)\n\n        if sum_exp_scores > 0:\n            softmax_probabilities = exp_scores / sum_exp_scores\n        else:\n            # Fallback to uniform probability if all scores are ~0 or -inf\n            softmax_probabilities = np.ones_like(exp_scores) / len(exp_scores)\n\n        # Scale these probabilities to a range that is lower than exact fits but reflects preference.\n        # For example, map probabilities to a range like [50, 90].\n        # Higher probability for smaller remaining capacity -> higher scaled score.\n        # The softmax probabilities range from ~0 to 1.\n        scaled_near_fit_priorities = 50.0 + softmax_probabilities * 40.0 # Range [50, 90)\n\n        priorities[near_fit_indices_subset] = scaled_near_fit_priorities\n\n    # Bins that can fit but were not assigned exact fit or near fit priority (shouldn't happen with current logic)\n    # or bins that could fit but had issues in scoring, will remain -np.inf.\n    # However, to be safe, we can assign a baseline priority to any bin that can fit but wasn't covered.\n    # This could happen if `near_fit_mask_subset` is empty, and `exact_fit_mask_subset` is also empty,\n    # but `can_fit_mask` is True. In this case, the item is smaller than remaining capacity but not an exact fit,\n    # and no other near fits were processed.\n    # This implies `near_fit_remaining` was empty. This scenario should be covered by the `if np.any(near_fit_mask_subset):` block.\n\n    # Any bin that *can* fit but has no priority assigned yet should get a default low priority.\n    # For example, any remaining `can_fit_mask` that are not `exact_fit_indices` and not `near_fit_indices_subset`.\n    # This should logically not occur given how near_fit_mask_subset is derived.\n    # If a bin can fit, it's either an exact fit or a near fit.\n    \n    # Let's ensure that any bin that *can* fit has at least a minimal positive priority if not an exact fit.\n    # This default priority should be lower than any near-fit priority.\n    default_low_priority = 1.0\n    unassigned_fitting_bins = np.where(can_fit_mask & (priorities == -np.inf))[0]\n    priorities[unassigned_fitting_bins] = default_low_priority\n\n    return priorities\n\n[Reflection]\nPrioritize exact fits, use softmax for near fits, and explore tunable scaling.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}