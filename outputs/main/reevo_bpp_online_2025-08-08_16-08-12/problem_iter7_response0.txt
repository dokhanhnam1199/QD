```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a Best Fit strategy with a temperature-controlled exploration.

    This heuristic prioritizes bins that can fit the item. Among those that fit,
    it assigns a higher priority to bins that will have less remaining capacity
    after the item is placed (Best Fit). A softmax function is used to introduce
    controlled exploration, allowing slightly less optimal bins to be chosen with
    a certain probability, which can help escape local optima. The temperature
    parameter can be adjusted to control the degree of exploration.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # A higher temperature means more exploration (closer to uniform probabilities)
    # A lower temperature means more exploitation (closer to greedy best fit)
    temperature = 0.1  # Tunable parameter

    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item

    # Calculate the remaining capacity if the item is placed in a fitting bin
    remaining_after_placement = bins_remain_cap[can_fit_mask] - item

    # For bins that can fit, calculate a "fit score". A smaller remaining capacity
    # after placement is better, so we use the negative of the remaining capacity.
    # This is what the softmax will operate on.
    fit_scores = -remaining_after_placement

    # Apply softmax to get probabilities/priorities.
    # Ensure exp(fit_scores) doesn't overflow for very small negative fit_scores.
    # Adding a constant offset to shift the scores to be less negative, which can
    # help with numerical stability in exp. The relative order is preserved.
    # We can shift by the maximum value in fit_scores to make the largest element 0.
    if fit_scores.size > 0:
        shifted_fit_scores = fit_scores - np.max(fit_scores)
        # Handle potential NaNs if fit_scores were all Inf or -Inf (unlikely here)
        if np.any(np.isnan(shifted_fit_scores)):
             shifted_fit_scores = np.nan_to_num(shifted_fit_scores, nan=-1e9) # Assign a very low score

        # Softmax calculation: exp(score / temperature) / sum(exp(score / temperature))
        # We are interested in the relative priority, not necessarily normalized probabilities.
        # So, we can simply use exp(score / temperature). Higher values indicate higher priority.
        # The smaller the remaining_after_placement, the more negative fit_scores,
        # so exp(negative_value/temperature) will be smaller.
        # We want higher priority for smaller remaining_after_placement, so we should use positive fit_scores.
        # Let's re-evaluate: we want smaller remaining_after_placement to have higher priority.
        # The current fit_scores are -remaining_after_placement.
        # Softmax on -remaining_after_placement will assign higher probability to LARGER (less negative) values,
        # which means LARGER remaining_after_placement. This is the opposite of what we want.
        # We want smaller remaining_after_placement to have higher priority.
        # So, we should use the reciprocal of remaining capacity for the softmax, or a score that
        # increases as remaining_after_placement decreases.

        # Let's use the inverse of remaining capacity for the score.
        # Larger inverse means smaller remaining capacity, which is what we want.
        # Add a small epsilon to avoid division by zero.
        inverse_remaining = 1.0 / (remaining_after_placement + 1e-9)

        # Softmax on these positive scores will give higher probabilities to bins
        # with smaller remaining capacity.
        # We want to prioritize tighter fits, so smaller remaining_after_placement.
        # If remaining_after_placement is 0, inverse is large (high priority).
        # If remaining_after_placement is large, inverse is small (low priority).
        # So, inverse_remaining is a good score for "goodness of fit".
        priorities[can_fit_mask] = np.exp(inverse_remaining / temperature)
    else:
        # If no bins can fit, all priorities remain 0.
        pass

    return priorities
```
