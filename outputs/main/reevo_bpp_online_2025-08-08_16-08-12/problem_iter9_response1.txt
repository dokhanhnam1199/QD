```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin.
    This heuristic prioritizes bins that can fit the item. Among those that fit,
    it assigns a higher priority to bins that will have less remaining capacity
    after the item is placed. This is a greedy approach aiming to fill bins
    as much as possible, encouraging denser packing. It also introduces a
    soft-max like behavior to allow for some exploration and preference.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    
    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item
    
    # Calculate remaining capacity if item is placed in a fitting bin
    remaining_after_placement = bins_remain_cap[can_fit_mask] - item
    
    # Assign higher priority to bins with less remaining capacity after placement.
    # We use a transformation that favors exact fits or near-exact fits more strongly.
    # A simple inverse might not differentiate enough between good fits.
    # A common approach is to use something like 1 / (1 + slack) or a scaled version.
    # Here, we'll use a slightly more aggressive inverse, but add a small constant
    # to ensure that perfect fits (slack=0) get a very high, but not infinite, score.
    # We can also consider a form that penalizes very large remaining capacities more.
    
    # Transform remaining capacity to priority: lower remaining capacity = higher priority.
    # We invert the remaining capacity. Adding 1 avoids division by zero for exact fits
    # and makes the priority for exact fits finite but highest.
    # A small scaling factor can be used for temperature/exploration tuning.
    # Let's use a scaling factor `alpha`. Higher alpha means more greedy.
    alpha = 1.0 # Tunable parameter for exploration/greediness
    
    # Higher values of `remaining_after_placement` should result in lower priorities.
    # We can use `exp(-alpha * remaining_after_placement)` or similar, but for a
    # direct priority score that favors minimal slack, an inverse is more direct.
    
    # Let's try a transformation that makes smaller remaining capacities map to larger priorities.
    # We want to prioritize exact fits, then minimal slack.
    # For slack = 0, priority should be high.
    # For slack = small, priority should be high.
    # For slack = large, priority should be low.
    
    # A common approach in soft-max like prioritization is:
    # priority = exp(score)
    # Where score is something like -slack or 1/slack.
    # To avoid extremely large values for exact fits, we can normalize or use a different function.
    
    # Option 1: Simple inverse with a base to avoid division by zero and provide a floor.
    # `priorities[can_fit_mask] = 1.0 / (remaining_after_placement + 1e-6)`
    
    # Option 2: Using a scaled exponential for a softer distribution, closer to softmax.
    # `priorities[can_fit_mask] = np.exp(-alpha * remaining_after_placement)`
    
    # Option 3: Prioritize exact fits strongly, then minimal slack.
    # Let's create a score that is high for small remaining_after_placement.
    # `score = 1.0 / (1.0 + remaining_after_placement)` - this gives 1 for exact fit.
    # Or, `score = 1.0 - (remaining_after_placement / max_possible_slack)` to normalize.
    
    # Let's go with a transformation that heavily favors smaller remaining capacities.
    # We can use a function like: `1 / (1 + slack)` or `1 - (slack / max_item_size)`
    # Using `1.0 / (1.0 + remaining_after_placement)` provides a score between 0 and 1,
    # where 1 is for an exact fit. This seems to capture the "minimal slack" idea well.
    
    priorities[can_fit_mask] = 1.0 / (1.0 + remaining_after_placement)
    
    # Optional: Introduce a small random noise or a soft-max like scaling to encourage exploration
    # For a purely greedy approach, this is not needed.
    # If exploration is desired, we could do:
    # scaled_priorities = np.exp(priorities[can_fit_mask] * temp)
    # For now, sticking to the core reflection of prioritizing minimal slack.

    return priorities
```
