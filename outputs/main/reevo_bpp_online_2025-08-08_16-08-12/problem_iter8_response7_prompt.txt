{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority for each bin to pack an item.\n    Prioritizes exact fits, then near fits.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot fit the item\n        will have a very low priority.\n    \"\"\"\n    # Initialize priorities to a very low value.\n    priorities = np.full_like(bins_remain_cap, -float('inf'))\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate potential remaining capacities for bins that can fit the item.\n    potential_remainders = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priority:\n    # 1. Exact fits (remainder is 0) get the highest priority.\n    # 2. Near fits (smaller positive remainder) get higher priority than larger remainders.\n    # We can achieve this by assigning a high value for exact fits and then\n    # using the negative of the remainder for near fits, so smaller remainders\n    # (less negative values) get higher priority.\n\n    # For exact fits\n    exact_fit_indices = np.where(potential_remainders == 0)[0]\n    if len(exact_fit_indices) > 0:\n        priorities[can_fit_mask][exact_fit_indices] = 100.0  # High priority for exact fits\n\n    # For near fits\n    near_fit_indices = np.where(potential_remainders > 0)[0]\n    if len(near_fit_indices) > 0:\n        # Assign priorities based on the negative of the remainder.\n        # This means smaller remainders get higher (less negative) scores.\n        priorities[can_fit_mask][near_fit_indices] = -potential_remainders[near_fit_indices]\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a\n    strategy that prioritizes exact fits and then uses softmax for exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (closer to an exact fit). It then applies a\n    softmax function to these priorities to balance exploration and exploitation,\n    allowing for a chance to pack items into bins that are not the absolute best fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Small value to avoid division by zero\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin.\n    # We want to prioritize bins that leave *less* remaining capacity.\n    # Therefore, the \"quality\" of a fit is inversely related to the remaining capacity.\n    # A small positive remainder is good. A negative remainder means it doesn't fit.\n    # To use softmax, we need positive values. A simple way is to use the\n    # inverse of the remaining capacity plus a small constant for stability.\n    # Alternatively, we can use the negative of the remaining capacity and\n    # adjust the softmax interpretation.\n    # Let's stick to the idea of inverse remaining capacity for now.\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # We want to maximize the \"goodness\" of the fit. A smaller remainder is better.\n    # The score should reflect this: higher score for smaller remainders.\n    # A common approach is 1 / (remainder + epsilon).\n    # We'll scale these scores before applying softmax to control the spread.\n    fit_scores = 1.0 / (remaining_after_placement + epsilon)\n\n    # Scale scores to prevent very large or small exponents in softmax.\n    # A simple normalization can be dividing by the maximum score among fitting bins.\n    max_fit_score = np.max(fit_scores) if fit_scores.size > 0 else 1.0\n    if max_fit_score > epsilon: # Avoid division by zero if all fit_scores are ~0\n        scaled_fit_scores = fit_scores / max_fit_score\n    else:\n        scaled_fit_scores = np.ones_like(fit_scores) # If all scores are negligible, treat them equally\n\n    # Apply softmax. This converts scores into probabilities, balancing exploration\n    # (more uniform probabilities) and exploitation (probabilities concentrated on high scores).\n    # A temperature parameter could be introduced for more fine-grained control,\n    # but here we use a standard softmax.\n    exp_scores = np.exp(scaled_fit_scores)\n    sum_exp_scores = np.sum(exp_scores)\n\n    if sum_exp_scores > epsilon:\n        probabilities = exp_scores / sum_exp_scores\n    else:\n        # This case should be rare with the scaling, but for safety,\n        # assign uniform probabilities if the sum is too small.\n        probabilities = np.ones_like(fit_scores) / len(fit_scores)\n\n    # Assign these probabilities as priorities to the bins that can fit the item.\n    priorities[can_fit_mask] = probabilities\n\n    return priorities\n\n[Reflection]\nPrioritize exact fits. Use softmax for exploration. Tune scaling and temperature.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}