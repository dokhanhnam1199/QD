{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy with explicit prioritization of exact fits and temperature-controlled exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it first gives the highest priority to exact fits. For bins that are not\n    exact fits but can accommodate the item, it assigns priority based on\n    how much remaining capacity is left, favoring smaller remaining capacities.\n    To encourage exploration, a softmax function is applied to the non-exact fits\n    with a temperature parameter. A smaller temperature leads to more exploitation (closer to greedy),\n    while a larger temperature leads to more exploration (closer to uniform).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    temperature = 0.1  # Tunable parameter for exploration. Lower = more greedy.\n\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate remaining capacity if item is placed\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign highest priority to exact fits\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    priorities[can_fit_mask][exact_fit_mask_subset] = 100.0\n\n    # For bins that fit but are not exact fits, calculate scores for softmax\n    non_exact_fit_indices_subset = np.where(~exact_fit_mask_subset)[0]\n\n    if non_exact_fit_indices_subset.size > 0:\n        non_exact_fitting_bins_remain_cap = fitting_bins_remain_cap[~exact_fit_mask_subset]\n        non_exact_remaining_after_placement = non_exact_fitting_bins_remain_cap - item\n\n        # We want to prioritize smaller remaining capacities.\n        # Using the negative of remaining capacity means smaller remaining capacity\n        # yields a larger (less negative) score, which is good for softmax.\n        # Add epsilon to avoid division by zero in case of floating point inaccuracies\n        # if remaining_after_placement is very close to zero but not exactly zero.\n        # However, a simpler approach is to just use the negative remaining capacity.\n        # Let's use negative remaining capacity as the score for softmax.\n        # A smaller remaining_after_placement will result in a less negative score.\n        fit_scores_for_softmax = -non_exact_remaining_after_placement\n\n        # Apply softmax for exploration. Higher score (less remaining capacity) means higher priority.\n        # To ensure numerical stability with exp, shift scores so the maximum is 0.\n        if fit_scores_for_softmax.size > 0:\n            shifted_fit_scores = fit_scores_for_softmax - np.max(fit_scores_for_softmax)\n            # Handle potential NaNs if fit_scores were all Inf or -Inf (unlikely here)\n            if np.any(np.isnan(shifted_fit_scores)):\n                 shifted_fit_scores = np.nan_to_num(shifted_fit_scores, nan=-1e9)\n\n            # Calculate the softmax values. The relative magnitude is what matters.\n            # Higher value for smaller remaining_after_placement.\n            soft_priorities = np.exp(shifted_fit_scores / temperature)\n\n            # Scale these priorities to be less than the exact fit priority (100.0)\n            # and ensure they are positive.\n            # The maximum possible value of soft_priorities (before scaling) is 1.0.\n            # We can scale them by a factor like 99.0 to ensure they are lower than exact fits.\n            scale_factor = 99.0\n            priorities[can_fit_mask][~exact_fit_mask_subset] = soft_priorities * scale_factor\n        else:\n            # If no non-exact fits (all were exact fits)\n            pass\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n    e_x = np.exp(x / temp)\n    return e_x / e_x.sum(axis=0)\n\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem using a softmax-based\n    approach to balance \"Best Fit\" (exploitation) with exploration.\n\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed (exploitation). The softmax function is used to\n    convert these \"fit scores\" into probabilities, introducing a degree of\n    exploration. Bins with better fits are more likely to be chosen, but not\n    guaranteed, depending on the temperature parameter.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the probability (priority score) of placing the item in the\n        corresponding bin.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the \"goodness\" of fit for bins that can accommodate the item.\n        # A smaller remaining capacity after placement indicates a better fit.\n        # We want to maximize this \"goodness\", so we use the inverse of\n        # remaining capacity. Adding a small epsilon to avoid division by zero.\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n        fit_scores = 1.0 / (remaining_after_placement + 1e-9)\n\n        # Apply softmax to convert fit scores into probabilities.\n        # The 'temperature' parameter controls the balance between exploitation and exploration.\n        # A lower temperature (e.g., 0.1) makes the probabilities sharper, favoring the best fit more.\n        # A higher temperature (e.g., 1.0 or more) makes the probabilities smoother,\n        # increasing the chance of picking less optimal fits.\n        temperature = 0.5  # Tunable parameter\n        probabilities = softmax(fit_scores, temp=temperature)\n\n        # Assign these probabilities as priorities to the bins that can fit the item.\n        priorities[can_fit_mask] = probabilities\n    \n    # Bins that cannot fit the item will have a priority of 0.\n    # In a real application, if all priorities are 0, a new bin would be opened.\n\n    return priorities\n\n[Reflection]\nPrioritize exact fits, use softmax with inverse remaining capacity.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}