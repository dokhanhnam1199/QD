[
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This aims for denser packing by favoring bins\n    that are nearly full. It uses a transformation that strongly emphasizes exact fits\n    and penalizes larger remaining capacities more severely than a simple inverse.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Transform remaining capacity to priority.\n        # We want smaller remaining_after_placement to have higher priority.\n        # Using `1.0 / (1.0 + slack)` gives a score between 0 and 1, where 1 is for exact fit.\n        # To more strongly emphasize exact fits and penalize larger slacks,\n        # we use `1.0 / (1.0 + k * slack)` where k is a parameter controlling the steepness\n        # of the preference for smaller slacks. A higher k means a stronger preference for\n        # exact or near-exact fits.\n        k = 3.0  # Tunable parameter to control preference for exact fits. Increased from v1.\n        priorities[can_fit_mask] = 1.0 / (1.0 + k * remaining_after_placement)\n\n        # To further boost exact fits, we can add a small bonus for perfect matches.\n        # This ensures that exact fits are always strictly preferred over any non-exact fit\n        # if the transformation alone doesn't guarantee it due to floating point inaccuracies.\n        exact_fit_bonus = 0.05 # A small bonus for exact fits\n        exact_fit_mask_for_fitting_bins = np.isclose(remaining_after_placement, 0.0)\n        priorities[can_fit_mask][exact_fit_mask_for_fitting_bins] += exact_fit_bonus\n\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem, favoring exact fits and minimal slack.\n\n    This heuristic prioritizes bins that can fit the item. Among fitting bins,\n    it assigns the highest priority to exact fits (zero remaining capacity after packing).\n    For bins that don't offer an exact fit, it assigns priority based on the\n    remaining capacity after packing, favoring bins with less remaining capacity.\n    This strategy aims for a Best Fit approach without complex temperature scaling,\n    focusing on minimizing waste.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n        Bins that cannot fit the item will have a priority of -infinity.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    priorities = np.full(num_bins, -np.inf, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the initialized priorities.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities:\n    # - Exact fits (remaining_capacity_after_fit == 0) get the highest possible priority\n    #   within the group of fitting bins.\n    # - For non-exact fits, priority is the negative of the remaining capacity.\n    #   This naturally favors bins with smaller remaining capacity (tighter fits).\n    #   Using negative remaining capacity makes smaller values (tighter fits) larger\n    #   and thus higher priority.\n    priorities[can_fit_mask] = -remaining_capacity_after_fit\n\n    # To ensure exact fits are prioritized above all others, we can assign them\n    # a value slightly higher than any possible negative remaining capacity.\n    # Since remaining_capacity_after_fit is non-negative, -remaining_capacity_after_fit is non-positive.\n    # An exact fit results in a remaining capacity of 0, so its priority is 0.\n    # Any other fit will result in a negative priority.\n    # Thus, the current calculation naturally prioritizes exact fits (0) over others (<0).\n    # No further adjustment is strictly needed for prioritizing exact fits,\n    # as 0 is greater than any negative number.\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem using a refined strategy.\n    This heuristic prioritizes exact fits, then uses a temperature-controlled\n    softmax on the inverse of remaining capacity for near fits to encourage exploration\n    while favoring bins with less remaining space.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    temperature = 0.2  # Tunable parameter for exploration. Lower = more greedy.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    fitting_bins_remain_cap = bins_remain_cap[fitting_bins_indices]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign a very high priority for exact fits.\n    exact_fit_mask_subset = np.isclose(remaining_after_placement, 0.0)\n    exact_fit_indices = fitting_bins_indices[exact_fit_mask_subset]\n    priorities[exact_fit_indices] = 100.0\n\n    # Handle near fits using a softmax on the inverse of remaining capacity.\n    # This favors bins with less remaining capacity among the near fits.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    near_fit_indices_subset = fitting_bins_indices[near_fit_mask_subset]\n\n    if np.any(near_fit_mask_subset):\n        near_fit_remaining = remaining_after_placement[near_fit_mask_subset]\n\n        # Calculate scores for near fits: higher score for smaller remaining capacity.\n        # Use inverse of remaining capacity to achieve this. Add epsilon for stability.\n        epsilon_small = 1e-6\n        near_fit_scores_for_softmax = 1.0 / (near_fit_remaining + epsilon_small)\n\n        # Apply softmax for exploration. Higher scores (smaller remaining capacity) get higher probabilities.\n        # Ensure numerical stability for exp by shifting scores.\n        if near_fit_scores_for_softmax.size > 0:\n            max_score = np.max(near_fit_scores_for_softmax)\n            shifted_scores = near_fit_scores_for_softmax - max_score\n            \n            # Avoid potential division by zero if all shifted_scores are -inf\n            if np.all(np.isneginf(shifted_scores)):\n                exp_scores = np.ones_like(shifted_scores)\n            else:\n                exp_scores = np.exp(shifted_scores / temperature)\n            \n            sum_exp_scores = np.sum(exp_scores)\n\n            if sum_exp_scores > 0:\n                softmax_probabilities = exp_scores / sum_exp_scores\n            else:\n                # Fallback to uniform if sum is zero (e.g., all exp_scores were 0)\n                softmax_probabilities = np.ones_like(exp_scores) / len(exp_scores)\n\n            # Scale these probabilities to a range that is lower than exact fits,\n            # but reflects the relative preference. A range like [50, 99.9] would be suitable.\n            # Higher softmax probability (from smaller remaining capacity) results in a higher score.\n            scaled_near_fit_priorities = 50.0 + softmax_probabilities * 49.9\n\n            priorities[near_fit_indices_subset] = scaled_near_fit_priorities\n\n    # Ensure any bin that can fit but wasn't assigned a priority (e.g., if near_fit_mask_subset was empty)\n    # gets a minimal positive priority. This scenario is less likely with the current logic\n    # but good for robustness. Bins that can fit should have a priority greater than -inf.\n    unassigned_fitting_bins = np.where(can_fit_mask & (priorities == -np.inf))[0]\n    # If there are any unassigned fitting bins, it means they could fit but were not exact fits,\n    # and also there were no near fits to apply softmax to. We assign a default low priority.\n    if unassigned_fitting_bins.size > 0:\n        priorities[unassigned_fitting_bins] = 1.0 # A low priority for bins that can fit but are not preferred\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 36.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response3.txt_stdout.txt",
    "code_path": "problem_iter12_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. It uses a transformation that more aggressively\n    penalizes larger remaining capacities, effectively emphasizing exact fits and\n    bins that become nearly full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Transform remaining capacity to priority.\n        # To emphasize exact fits and penalize larger remaining capacities more aggressively,\n        # we can use a function that grows faster as remaining capacity approaches zero.\n        # A function like `1 / (1 + slack^p)` where `p > 1` will achieve this.\n        # For `p=2`, it means a slack of 0.1 is much more preferred than a slack of 0.2.\n        # An exponential decay `exp(-k * slack)` also works, but the power function\n        # offers a direct way to control the steepness of the penalty.\n        # Let's use `1.0 / (1.0 + slack**2)` which provides a quadratic penalty for slack.\n\n        # Set a small offset to avoid division by zero if remaining_after_placement is exactly 0.\n        # However, `1.0 / (1.0 + 0**2)` is 1.0, which is fine.\n        # If we wanted to ensure exact fits get a strictly higher score than any non-exact fit,\n        # we could add a large constant to exact fits. But `1/(1+0)` already gives the max score.\n\n        slack_squared = remaining_after_placement**2\n        priorities[can_fit_mask] = 1.0 / (1.0 + slack_squared)\n\n        # To make the preference for exact fits even stronger, or to ensure exact fits\n        # are always strictly preferred over any other fit, we can add a small boost.\n        # However, the current formulation where `slack=0` gives a priority of 1.0,\n        # and any `slack > 0` gives a priority < 1.0, inherently prioritizes exact fits.\n        # The quadratic penalty `slack**2` already makes smaller slacks much more favorable.\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem using a refined strategy.\n    This heuristic prioritizes exact fits, then uses a temperature-controlled\n    softmax on the inverse of remaining capacity for near fits to encourage exploration\n    while favoring bins with less remaining space.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n        Higher scores indicate higher priority. Bins that cannot fit the item\n        will have a priority of -np.inf.\n    \"\"\"\n    temperature = 0.5  # Tunable parameter for exploration. Lower = more greedy.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[fitting_bins_indices]\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Assign a very high priority for exact fits.\n    exact_fit_mask_subset = (remaining_after_placement == 0)\n    exact_fit_indices_in_fitting = np.where(exact_fit_mask_subset)[0]\n    exact_fit_original_indices = fitting_bins_indices[exact_fit_indices_in_fitting]\n    priorities[exact_fit_original_indices] = 100.0\n\n    # Handle near fits using a softmax on the inverse of remaining capacity.\n    # This favors bins with less remaining capacity among the near fits.\n    near_fit_mask_subset = ~exact_fit_mask_subset\n    near_fit_indices_in_fitting = np.where(near_fit_mask_subset)[0]\n\n    if np.any(near_fit_mask_subset):\n        near_fit_remaining = remaining_after_placement[near_fit_indices_in_fitting]\n\n        # Calculate scores for near fits: higher score for smaller remaining capacity.\n        # Use inverse of remaining capacity to achieve this. Add epsilon for stability.\n        epsilon_small = 1e-9\n        near_fit_scores_for_softmax = 1.0 / (near_fit_remaining + epsilon_small)\n\n        # Apply softmax for exploration. Higher scores (smaller remaining capacity) get higher probabilities.\n        # Ensure numerical stability for exp by shifting scores.\n        if near_fit_scores_for_softmax.size > 0:\n            # Shift scores so the maximum is 0 for numerical stability with exp.\n            max_score = np.max(near_fit_scores_for_softmax)\n            shifted_scores = near_fit_scores_for_softmax - max_score\n            \n            # Handle the case where all shifted_scores might be -inf (e.g., if all near_fit_scores_for_softmax were identical and very small)\n            if np.all(np.isneginf(shifted_scores)):\n                exp_scores = np.ones_like(shifted_scores)\n            else:\n                exp_scores = np.exp(shifted_scores / temperature)\n            \n            sum_exp_scores = np.sum(exp_scores)\n\n            if sum_exp_scores > 0:\n                softmax_probabilities = exp_scores / sum_exp_scores\n            else:\n                # Fallback to uniform if sum is zero (e.g., all exp_scores were 0)\n                softmax_probabilities = np.ones_like(exp_scores) / len(exp_scores)\n\n            # Scale these probabilities to a range that is lower than exact fits,\n            # but reflects the relative preference. A range like [50, 99.9] would be suitable.\n            # Higher softmax probability (from smaller remaining capacity) results in a higher score.\n            # Scale to [50, 99.9] to ensure they are less than exact fits (100) and greater than default.\n            scaled_near_fit_priorities = 50.0 + softmax_probabilities * 49.9\n            \n            near_fit_original_indices = fitting_bins_indices[near_fit_indices_in_fitting]\n            priorities[near_fit_original_indices] = scaled_near_fit_priorities\n\n    # Assign a minimal positive priority to any fitting bin that might not have received a score\n    # (e.g., if there were fitting bins but no exact or near fits, which shouldn't happen with current logic,\n    # but as a safeguard). This ensures they are considered over not-fitting bins.\n    # The value 1.0 is arbitrary and very low compared to the others.\n    default_low_priority = 1.0\n    unassigned_fitting_bins_mask = can_fit_mask & (priorities == -np.inf)\n    priorities[unassigned_fitting_bins_mask] = default_low_priority\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 38.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response5.txt_stdout.txt",
    "code_path": "problem_iter12_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. It uses a transformation that more aggressively\n    prioritizes exact fits and penalizes larger remaining capacities compared to\n    a simple inverse.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Prioritize exact fits strongly and penalize larger remaining capacities more.\n        # Using `1.0 / (1.0 + remaining_after_placement**2)` amplifies the preference for\n        # smaller remaining capacities. An exact fit (remaining_after_placement = 0)\n        # will have a priority of 1.0. A slack of 0.1 will have a priority of\n        # 1.0 / (1.0 + 0.01) = 0.99. A slack of 1.0 will have a priority of\n        # 1.0 / (1.0 + 1.0) = 0.5. This is more aggressive than `1/(1+slack)`.\n        # We can also use a tunable exponent `p` such that `1.0 / (1.0 + remaining_after_placement**p)`.\n        # A larger `p` makes the preference for small slack even stronger.\n        \n        exponent = 2.0  # Tunable parameter to control the aggression towards exact fits\n        priorities[can_fit_mask] = 1.0 / (1.0 + remaining_after_placement**exponent)\n        \n        # Ensure exact fits have the highest possible score if they exist,\n        # to strictly enforce the \"prioritize exact fits\" rule if numerical\n        # precision issues arise with the power function.\n        exact_fit_mask_local = np.isclose(remaining_after_placement, 0.0)\n        if np.any(exact_fit_mask_local):\n            priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response6.txt_stdout.txt",
    "code_path": "problem_iter12_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins for the online Bin Packing Problem, with enhanced strategies.\n\n    This heuristic categorizes bins into:\n    1. Exact Fits: Bins where the item perfectly fills the remaining capacity.\n    2. Near Fits: Bins where the item fits, and the remaining capacity after placement\n       is small (defined by a threshold). These are further prioritized using a\n       temperature-controlled softmax on the inverse of the remaining capacity\n       to balance exploitation (best near fit) and exploration (trying other near fits).\n    3. General Fits: Bins where the item fits, but the remaining capacity after\n       placement is not considered \"near\". These receive a low positive priority.\n    4. Unfittable: Bins where the item cannot fit. These receive negative infinity priority.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        represents the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # --- Configuration Parameters ---\n    # Priority for exact fits, set high to ensure they are always chosen if available.\n    EXACT_FIT_PRIORITY = 100.0\n    # Base score for near fits before applying softmax, ensuring they are preferred over general fits.\n    NEAR_FIT_BASE_SCORE = 50.0\n    # Scaling factor for softmax probabilities to map them into a desirable range.\n    NEAR_FIT_SCALE = 40.0\n    # Priority for bins that fit but are not considered \"near\". This ensures they are usable.\n    GENERAL_FIT_PRIORITY = 1.0\n    # Threshold to define what constitutes a \"near fit\". A smaller value is stricter.\n    # For example, if remaining capacity is less than 10% of the item size or a small absolute value.\n    # Let's use a relative threshold combined with an absolute minimum for robustness.\n    NEAR_FIT_THRESHOLD_RELATIVE = 0.15 # e.g., remaining capacity < 15% of item size\n    NEAR_FIT_THRESHOLD_ABSOLUTE = 5.0  # e.g., remaining capacity < 5.0 units\n\n    # Temperature for softmax to control exploration among near fits.\n    # Higher temperature -> more exploration (priorities more uniform).\n    # Lower temperature -> less exploration (priorities more skewed to best fits).\n    TEMPERATURE = 0.7  # Tunable parameter\n\n    epsilon_small = 1e-9 # Small value to prevent division by zero.\n\n    # --- Identify Bin Categories ---\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Exact Fits\n    exact_fit_mask = can_fit_mask & (np.abs(bins_remain_cap - item) < epsilon_small)\n    priorities[exact_fit_mask] = EXACT_FIT_PRIORITY\n\n    # 2. Near Fits\n    # Bins that can fit, but are not exact fits.\n    general_fitting_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(general_fitting_mask):\n        fitting_bin_indices = np.where(general_fitting_mask)[0]\n        remaining_capacities_after_placement = bins_remain_cap[fitting_bin_indices] - item\n\n        # Define near fit criteria: remaining capacity is small.\n        near_fit_criteria = (remaining_capacities_after_placement < NEAR_FIT_THRESHOLD_ABSOLUTE) | \\\n                            (remaining_capacities_after_placement < item * NEAR_FIT_THRESHOLD_RELATIVE)\n        \n        near_fit_indices_subset = fitting_bin_indices[near_fit_criteria]\n        non_near_fit_indices_subset = fitting_bin_indices[~near_fit_criteria]\n\n        # Process Near Fits\n        if len(near_fit_indices_subset) > 0:\n            near_fit_remaining_caps = remaining_capacities_after_placement[near_fit_criteria]\n\n            # Score for softmax: higher score for smaller remaining capacity.\n            # Using inverse capacity ensures smaller remaining space gets higher score.\n            near_fit_scores = 1.0 / (near_fit_remaining_caps + epsilon_small)\n\n            # Apply softmax for exploration among near fits.\n            if len(near_fit_scores) > 0:\n                # Shift scores for numerical stability before exponentiation.\n                max_score = np.max(near_fit_scores)\n                shifted_scores = near_fit_scores - max_score\n                \n                exp_scores = np.exp(shifted_scores / TEMPERATURE)\n                sum_exp_scores = np.sum(exp_scores)\n\n                if sum_exp_scores > 0:\n                    softmax_probabilities = exp_scores / sum_exp_scores\n                else:\n                    # Fallback to uniform distribution if all exp_scores are ~0 or NaN.\n                    softmax_probabilities = np.ones_like(near_fit_scores) / len(near_fit_scores)\n                \n                # Scale probabilities to a priority range below exact fits.\n                scaled_near_fit_priorities = NEAR_FIT_BASE_SCORE + softmax_probabilities * NEAR_FIT_SCALE\n                priorities[near_fit_indices_subset] = scaled_near_fit_priorities\n\n        # 3. General Fits\n        # Bins that fit but are not exact or near fits.\n        if len(non_near_fit_indices_subset) > 0:\n            priorities[non_near_fit_indices_subset] = GENERAL_FIT_PRIORITY\n            \n    return priorities",
    "response_id": 6,
    "obj": 3.948942959712818,
    "SLOC": 40.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response7.txt_stdout.txt",
    "code_path": "problem_iter12_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes bins that can accommodate the item. Among those\n    that fit, it assigns a higher priority to bins that will have less remaining\n    capacity after the item is placed, aiming for tighter packing. Exact fits\n    (zero remaining capacity) are given a significantly higher priority than\n    near fits. For near fits, a scaled softmax is applied to the inverse\n    remaining capacity, where the scaling factor is a tunable hyperparameter\n    (e.g., 10.0) to control the emphasis on tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bins can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = fitting_bins_remain_cap - item\n\n    # Define a high priority for exact fits\n    exact_fit_priority = 1.0\n    # Define a scaling factor for near fits to emphasize tighter packing\n    near_fit_scale_factor = 10.0\n\n    # Calculate scores for bins that can fit the item\n    scores = np.zeros_like(fitting_bins_remain_cap, dtype=float)\n\n    # Identify exact fits\n    exact_fit_mask = np.isclose(remaining_after_placement, 0.0)\n    scores[exact_fit_mask] = exact_fit_priority\n\n    # For near fits, use scaled softmax on the inverse remaining capacity\n    near_fit_mask = ~exact_fit_mask\n    if np.any(near_fit_mask):\n        near_fit_remaining = remaining_after_placement[near_fit_mask]\n        # Inverse remaining capacity, higher value for smaller remaining capacity.\n        # Add a small epsilon to avoid division by zero.\n        inverse_remaining = 1.0 / (near_fit_remaining + 1e-9)\n\n        # Apply scaling and then softmax to amplify preference for tighter fits\n        scaled_inverse = near_fit_scale_factor * inverse_remaining\n        exp_scaled_inverse = np.exp(scaled_inverse)\n\n        # Normalize the scores using softmax. This converts them into a probability-like\n        # distribution, ensuring that bins with higher scaled inverse remaining capacity\n        # (i.e., tighter fits) get proportionally higher scores.\n        softmax_scores = exp_scaled_inverse / np.sum(exp_scaled_inverse)\n\n        # Assign these softmax scores to the near-fitting bins\n        scores[near_fit_mask] = softmax_scores\n\n    # Distribute the calculated scores to the original priority array\n    priorities[can_fit_mask] = scores\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response8.txt_stdout.txt",
    "code_path": "problem_iter12_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that can fit the item. Among those that fit,\n    it assigns a higher priority to bins that will have less remaining capacity\n    after the item is placed. This aims for denser packing by favoring bins\n    that are nearly full. It uses an exponential decay function to assign\n    priorities, emphasizing exact fits more strongly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins that cannot fit the item will have a priority of 0.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Transform remaining capacity to priority using an exponential decay function.\n        # `np.exp(-k * slack)`: as slack decreases, the priority increases.\n        # An exact fit (slack=0) will yield exp(0) = 1.\n        # Larger slack values will result in smaller priorities.\n        # The parameter `k` controls how quickly the priority drops with increasing slack.\n        k = 1.5  # Tunable parameter to control the decay rate, higher k means stronger preference for exact fits.\n        priorities[can_fit_mask] = np.exp(-k * remaining_after_placement)\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response9.txt_stdout.txt",
    "code_path": "problem_iter12_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes exact fits first, assigning them the highest priority.\n    For bins that do not offer an exact fit but can accommodate the item,\n    it prioritizes those that leave the least remaining capacity, encouraging tighter packing.\n    Bins that cannot fit the item are assigned a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a fitting bin\n    remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities: higher values mean higher priority\n    # Exact fits (remaining capacity is 0) get the highest priority (e.g., 0.0)\n    # Other fitting bins get priorities based on negative remaining capacity.\n    # This ensures that smaller remaining capacities have higher (less negative) priorities.\n    priorities[can_fit_mask] = -remaining_after_placement\n    priorities[can_fit_mask][remaining_after_placement == 0] = 0.0\n\n    return priorities",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]