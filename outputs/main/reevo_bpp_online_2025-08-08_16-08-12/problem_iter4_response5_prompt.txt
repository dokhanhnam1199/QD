{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a Best-Fit strategy with exploration.\n\n    This heuristic prioritizes bins that have the smallest remaining capacity\n    greater than or equal to the item's size. A small epsilon is added to the\n    remaining capacity before calculating priority to encourage picking bins\n    that are not *exactly* full, leaving a tiny bit of slack to avoid fragmentation.\n    A small probability `epsilon` is used to explore other options.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of choosing a random bin among suitable ones\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if np.any(suitable_bins_mask):\n        # Calculate a \"fit\" score. We want to minimize `bins_remain_cap - item`.\n        # To use this in a maximization context (higher priority is better),\n        # we can use the negative of this difference, or 1/(difference + small_constant).\n        # Using 1 / (difference + small_constant) penalizes larger differences more.\n        # Adding a small epsilon `1e-6` to `bins_remain_cap` before calculating the difference\n        # can slightly favor bins that are not completely full, reducing fragmentation.\n        # The smaller `bins_remain_cap + epsilon - item` is, the higher the priority.\n        \n        # Calculate the \"slack\" for suitable bins.\n        slack = bins_remain_cap[suitable_bins_mask] - item\n        \n        # We want to prioritize bins with minimum slack.\n        # A good heuristic is `1 / (slack + a_small_value)`.\n        # The smaller the slack, the higher the priority.\n        # Adding `1e-6` to slack prevents division by zero if slack is exactly zero.\n        priorities[suitable_bins_mask] = 1.0 / (slack + 1e-6)\n\n        # Epsilon-greedy exploration: With probability epsilon, choose randomly among suitable bins.\n        if np.random.rand() < epsilon:\n            # Assign equal probability to all suitable bins\n            priorities[suitable_bins_mask] = 1.0 / np.sum(suitable_bins_mask)\n        else:\n            # Exploit: The current priorities already favor the best fit.\n            # We can optionally normalize priorities so they sum to 1 for suitable bins,\n            # but it's not strictly necessary if we just pick the max.\n            # For this function returning scores, leaving them as is is fine,\n            # as higher score implies higher preference.\n            pass\n    else:\n        # If no bin can fit the item, all priorities remain 0.\n        # In a real online BPP solver, this would typically trigger the creation of a new bin.\n        pass\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-Based Best Fit strategy.\n\n    This heuristic prioritizes bins that have a remaining capacity closest to the item size,\n    aiming for the \"best fit\". It calculates a fitness score based on the gap between\n    the remaining capacity and the item size, preferring smaller non-negative gaps.\n    The softmax function is then used to convert these fitness scores into priorities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the \"gap\" for bins that can fit the item.\n    # We want to minimize this gap (i.e., find the best fit).\n    gaps = bins_remain_cap - item\n\n    # Initialize fitness scores. Bins that cannot fit the item will have a very low score.\n    # Using a large negative number to ensure they are not picked by softmax unless absolutely necessary.\n    fitness_scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    can_fit_mask = (gaps >= 0)\n    valid_gaps = gaps[can_fit_mask]\n\n    if np.any(can_fit_mask):\n        # For bins that can fit, we want to assign higher scores to smaller gaps.\n        # A common approach is to use an exponential decay function based on the gap.\n        # The 'temperature' parameter controls the sharpness of the distribution.\n        # A smaller temperature leads to a stronger preference for the best fit.\n        # We can set a temperature based on the average remaining capacity, or a fixed value.\n        # A small positive temperature ensures that the scores are not excessively large or small.\n        # Let's use a temperature that is related to the typical capacity values.\n        # If bins_remain_cap is empty or all zeros, use a default temperature.\n        non_zero_caps = bins_remain_cap[bins_remain_cap > 0]\n        if non_zero_caps.size > 0:\n            temperature = np.mean(non_zero_caps) / 2.0 # Heuristic for temperature\n            temperature = max(temperature, 1e-3) # Ensure temperature is positive\n        else:\n            temperature = 1.0 # Default temperature if no positive capacities\n\n        # Calculate fitness scores: exp(-gap / temperature). Smaller gap = higher score.\n        # We use a scaled version of the gap to control the spread of the exponential.\n        scaled_gaps = valid_gaps / temperature\n        positive_scores = np.exp(-scaled_gaps)\n\n        fitness_scores[can_fit_mask] = positive_scores\n\n    # Handle the case where no bins can fit the item.\n    # In this scenario, all fitness scores are -np.inf. Softmax would result in NaNs.\n    # A reasonable fallback is to assign uniform probabilities, as any bin choice is equally \"bad\".\n    if not np.any(np.isfinite(fitness_scores)):\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n\n    # Apply Softmax to convert fitness scores into probabilities (priorities).\n    # Shift scores to avoid numerical issues with very small/large exponents in exp().\n    # Subtracting the maximum finite score from all scores does not change the softmax output\n    # but can help prevent overflow/underflow issues.\n    finite_mask = np.isfinite(fitness_scores)\n    if np.any(finite_mask):\n        max_finite_score = np.max(fitness_scores[finite_mask])\n        shifted_scores = fitness_scores - max_finite_score\n    else:\n        shifted_scores = fitness_scores # Should not happen due to the check above, but for safety\n\n    # Compute the exponentiated scores. Replace -inf with 0 to avoid exp(-inf) = 0 issues\n    # which might incorrectly lead to a sum of zero if all were -inf.\n    exp_scores = np.where(np.isfinite(shifted_scores), np.exp(shifted_scores), 0)\n\n    sum_exp_scores = np.sum(exp_scores)\n\n    # If the sum is zero (e.g., all original scores were -inf, or numerical issues),\n    # fall back to uniform distribution.\n    if sum_exp_scores == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n    else:\n        priorities = exp_scores / sum_exp_scores\n        return priorities\n\n[Reflection]\nFocus on the \"gap\" for best fit. Softmax for exploration. Fine-tune temperature.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}