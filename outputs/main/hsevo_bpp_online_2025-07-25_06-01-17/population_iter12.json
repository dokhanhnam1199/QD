[
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the ratio of the item size to the remaining capacity of each bin\n    ratio = item / np.maximum(bins_remain_cap, 1e-8)  # avoid division by zero\n    \n    # Assign higher priority to bins with lower ratio (i.e., less likely to leave a small gap)\n    # and with more remaining capacity (i.e., more space to accommodate future items)\n    priority_ratio = np.where(bins_remain_cap >= item, \n                              # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                              bins_remain_cap * (1 - ratio) / (bins_remain_cap + 1), \n                              # for bins that cannot hold the item, the priority is zero\n                              0.0)\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the shortfall or excess capacity for each bin\n    adaptive_shortfall = np.maximum(0, item - bins_remain_cap)\n    adaptive_excess = np.maximum(0, bins_remain_cap - item)\n    adaptive_weight = 1 / (1 + np.exp(-item / np.mean(bins_remain_cap)))\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    adaptive_fit_priority = adaptive_weight / (1 + capacity_diff)\n    \n    # Calculate a utilization-aware penalty factor for each bin\n    utilization_penalty = 1 / (1 + np.exp(-adaptive_shortfall / np.mean(bins_remain_cap))) * 1 / (1 + np.exp(adaptive_excess / np.mean(bins_remain_cap)))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate a dynamic weight for balancing fit and utilization priorities\n    dynamic_weight = np.exp(-(capacity_diff / np.mean(capacity_diff)))\n    \n    # Combine priorities using adaptive weighting\n    alpha = 0.7  # weight for priority based on waste\n    beta = 0.2  # weight for priority based on ratio\n    gamma = 0.1  # weight for priority based on capacity difference\n    delta_weight = 0.5  # weight for adaptive fit priority\n    epsilon_weight = 0.5  # weight for utilization priority\n    combined_priority = alpha * priority_tight_fit + beta * priority_ratio + gamma * priority_capacity * penalty_factor\n    combined_priority += delta_weight * adaptive_fit_priority + epsilon_weight * utilization_priority * utilization_penalty * bins_remain_cap\n    \n    # Avoid bins that are too full or too empty\n    combined_priority = np.where(bins_remain_cap < item, -np.inf, combined_priority)\n    combined_priority = np.where(bins_remain_cap == 0, combined_priority * 0.9, combined_priority)  # reduce priority for empty bins\n    \n    return combined_priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 61.46788990825689,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive, multi-objective priority function with dynamic weighting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    alpha = 0.4 + 0.2 * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.3 + 0.1 * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    gamma = 0.3  # Weighting for penalty factor\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    utilization_priority = (bins_remain_cap + avg_bin_cap) / (bins_remain_cap + item + avg_bin_cap)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    balance_priority = balance_factor * fit_priority\n    \n    # Calculate the wasted space for each bin if the item is added\n    wasted_space = np.maximum(bins_remain_cap - item, 0)\n    \n    # Invert the wasted space so that bins with least wasted space get higher priority\n    inverted_wasted_space = 1 / (wasted_space + 1e-6)  # Add small value for numerical stability\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Ensure utilization_priority does not exceed a certain threshold (e.g., 0.9)\n    utilization_threshold = 0.9\n    utilization_priority = np.where(utilization_priority > utilization_threshold, utilization_threshold, utilization_priority)\n    \n    # Combine the priorities using adaptive weighting\n    alpha = 0.4  # Weight for fit priority\n    beta = 0.3  # Weight for balance priority\n    gamma = 0.2  # Weight for utilization priority\n    delta = 0.1  # Weight for penalty factor\n    priority = alpha * fit_priority + beta * balance_priority + gamma * utilization_priority + delta * penalty_factor * inverted_wasted_space\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    return priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and dynamic prioritization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    balance_priority = balance_factor * fit_priority\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Ensure utilization_priority does not exceed a certain threshold (e.g., 0.9)\n    utilization_threshold = 0.9\n    utilization_priority = np.where\tutilization_priority > utilization_threshold, utilization_threshold, utilization_priority)\n    \n    # Calculate the overall priority, balancing the current item's fit, balance factor, and bin utilization\n    alpha = 0.4  # Weight for fit priority\n    beta = 0.3  # Weight for balance priority\n    gamma = 0.3  # Weight for utilization priority\n    priority = alpha * fit_priority + beta * balance_priority + gamma * utilization_priority + (1 - alpha - beta - gamma) * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    threshold_item_size = 1.0\n    priority = np.where(bins_remain_cap >= threshold_item_size, priority, -1)\n    \n    return priority",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 33\n    utilization_priority = np.where\tutilization_priority > utilization_threshold, utilization_threshold, utilization_priority)\n                                                                                                                             ^\nSyntaxError: unmatched ')'\n25\n2\n823.5700269106578\n78.75938249541407\n348\n"
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization with balancing.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the available space in each bin relative to the item size\n    relative_available_space = np.where(bins_remain_cap >= item, bins_remain_cap - item, -np.inf)\n    \n    # Adaptive weighting based on the problem landscape\n    alpha = 0.4  # initial weighting for fit priority\n    beta = 0.3  # initial weighting for utilization priority\n    gamma = 0.3  # initial weighting for penalty factor\n    \n    avg_bin_cap = np.mean(bins_remain_cap)\n    if avg_bin_cap > item:\n        alpha += 0.1\n        beta -= 0.1\n    else:\n        alpha -= 0.1\n        beta += 0.1\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Combine the priorities using adaptive weighting and balancing\n    priorities = alpha * priority_capacity + beta * (bins_remain_cap / (bins_remain_cap + item)) + gamma * penalty_factor * bins_remain_cap + 0.1 * balance_factor\n    \n    # Ensure priorities are not negative\n    priorities = np.where(priorities < 0, 0, priorities)\n    \n    # Consider the remaining capacity of each bin to avoid overfilling\n    priorities = np.where(bins_remain_cap >= item, priorities + 0.01 * bins_remain_cap, priorities)\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 82.58875149581174,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective priorities.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    balance_priority = balance_factor * fit_priority\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Ensure utilization_priority does not exceed a certain threshold (e.g., 0.9)\n    utilization_threshold = 0.8618692586727021\n    utilization_priority = np.where(utilization_priority > utilization_threshold, utilization_threshold, utilization_priority)\n    \n    # Calculate the overall priority, balancing the current item's fit, balance factor, and bin utilization\n    alpha = 0.30802702122924797\n    beta = 0.5604929558148649\n    gamma = 0.12235746371576073\n    priority = alpha * fit_priority + beta * balance_priority + gamma * utilization_priority + (1 - alpha - beta - gamma) * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    threshold_item_size = 6.210180126136486\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic combining adaptive weighting and balancing.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)  # Using a simple invert function\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Adaptive weighting based on the problem's current state\n    total_remain_cap = np.sum(bins_remain_cap)\n    if total_remain_cap == 0:\n        adapt_weight = 0\n    else:\n        adapt_weight = (item / total_remain_cap) * 0.4 + (1 - item / total_remain_cap) * 0.3  # Dynamic weighting\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap / (bins_remain_cap + item)) - 0.5)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and adaptive weighting\n    priority = adapt_weight * fit_priority + (1 - adapt_weight) * (0.3 * utilization_priority + 0.3 * balance_factor)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the remaining capacity of each bin\n    priority *= (bins_remain_cap / np.sum(bins_remain_cap))\n    \n    return priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 99.42161946549662,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response7.txt_stdout.txt",
    "code_path": "problem_iter11_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic combining adaptive weighting and multi-objective optimization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Calculate an adaptive weight based on the item size and bin capacities\n    adaptive_weight = 1 / (1 + np.exp(-item / np.mean(bins_remain_cap)))\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = adaptive_weight / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the ratio of the item size to the remaining capacity of each bin\n    ratio = item / np.maximum(bins_remain_cap, 1e-8)  # avoid division by zero\n    \n    # Assign higher priority to bins with lower ratio (i.e., less likely to leave a small gap)\n    # and with more remaining capacity (i.e., more space to accommodate future items)\n    priority_ratio = np.where(bins_remain_cap >= item, \n                              # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                              bins_remain_cap * (1 - ratio) / (bins_remain_cap + 1), \n                              # for bins that cannot hold the item, the priority is zero\n                              0.0)\n    \n    # Calculate a balance factor to prioritize bins with remaining capacity close to 50% of the bin size\n    avg_bin_size = np.mean(bins_remain_cap)\n    balance_factor = 1 - np.abs((bins_remain_cap - avg_bin_size / 2) / avg_bin_size)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and balance factor\n    alpha = 0.5  # weight for priority based on fit\n    beta = 0.3  # weight for priority based on tight fit\n    gamma = 0.2  # weight for priority based on ratio and balance factor\n    combined_priority = alpha * fit_priority + beta * priority_tight_fit + gamma * (priority_ratio * balance_factor)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    combined_priority = np.nan_to_num(combined_priority)\n    \n    return combined_priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive, multi-objective priority function combining dynamic weighting and balancing.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority = np.where(bins_remain_cap >= item, fit_priority, 0)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    fit_priority *= balance_factor\n    \n    # Calculate the tightness of fit for the current item in each bin\n    tight_fit_priority = np.exp(-np.abs(bins_remain_cap - item))\n    \n    # Calculate a utilization-aware penalty factor for each bin\n    utilization_penalty = 1 / (1 + np.exp(-np.maximum(0, item - bins_remain_cap) / np.mean(bins_remain_cap))) * 1 / (1 + np.exp(np.maximum(0, bins_remain_cap - item) / np.mean(bins_remain_cap)))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate a dynamic weight for balancing fit and utilization priorities\n    dynamic_weight = np.exp(-(capacity_diff / np.mean(capacity_diff)))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalties\n    alpha = 0.4  # Dynamic weighting for fit priority\n    beta = 0.3   # Dynamic weighting for utilization priority\n    gamma = 0.3  # Dynamic weighting for tight fit priority\n    \n    combined_priority = alpha * fit_priority + beta * utilization_priority * utilization_penalty + gamma * tight_fit_priority\n    \n    # Normalize the priorities to ensure they add up to 1\n    normalized_priority = combined_priority / (np.sum(combined_priority) + 1e-6)\n    \n    return normalized_priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization with balancing.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority_capacity[bins_remain_cap < item] = 0\n    \n    # Calculate priority based on how full the bin is and how well the item fits\n    priority_fullness = np.where(bins_remain_cap >= item, \n                                 # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                                 1.0 / (bins_remain_cap + 1), \n                                 # for bins that cannot hold the item, the priority is zero\n                                 0.0)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Adaptive weighting based on the problem's current state\n    total_remain_cap = np.sum(bins_remain_cap)\n    if total_remain_cap == 0:\n        adapt_weight = 0\n    else:\n        adapt_weight = (item / total_remain_cap) * 0.4 + (1 - item / total_remain_cap) * 0.3\n    \n    # Dynamic prioritization based on the current item's size and the remaining capacities\n    dynamic_prioritization = np.exp(-capacity_diff / (1 + item))\n    \n    # Combine the priorities using adaptive weighting\n    priorities = adapt_weight * priority_capacity + (1 - adapt_weight) * (0.3 * utilization_priority + 0.2 * balance_factor + 0.1 * penalty_factor + 0.1 * dynamic_prioritization)\n    \n    # Ensure priorities are not negative\n    priorities = np.where(priorities < 0, 0, priorities)\n    \n    # Consider the remaining capacity of each bin to avoid overfilling\n    priorities = np.where(bins_remain_cap >= item, priorities + 0.01 * bins_remain_cap, priorities)\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 134.57319505384925,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 823.5700269106578,
    "mi": 78.75938249541407,
    "token_count": 348.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority function for the online Bin Packing Problem (BPP).\n    \n    This function combines dynamic weighting, forecasting, and bin utilization \n    metrics to create an effective heuristic. It adapts to problem state changes \n    and balances multiple objectives to minimize the number of bins used.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the overall priority, balancing the current item's fit and bin utilization\n    # with dynamic weighting based on the problem state\n    alpha = 0.4  # Weight for the current item's fit\n    beta = 0.3  # Weight for bin utilization\n    gamma = 0.3  # Weight for the penalty factor and remaining capacity\n    \n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap\n    \n    # Adapt the priority based on the problem state (i.e., the number of bins and their utilization)\n    num_bins = len(bins_remain_cap)\n    avg_utilization = np.mean(bins_remain_cap) / (num_bins * np.mean(bins_remain_cap))\n    \n    if avg_utilization < 0.5:  # Low utilization, prioritize efficient packing\n        priority *= 1.1\n    elif avg_utilization > 0.8:  # High utilization, prioritize bin utilization\n        priority *= 0.9\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.856402074192266,
    "SLOC": 19.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 729.4477381208684,
    "mi": 79.09382223114932,
    "token_count": 355.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    A prioritization function for the online Bin Packing Problem, incorporating adaptive weighting and forecasting.\n\n    Parameters:\n    item (float): The size of the item to be packed.\n    bins_remain_cap (np.ndarray): An array of remaining capacities of the bins.\n    alpha (float): The weight for the current item's fit (default: 0.4).\n    beta (float): The weight for the bin utilization (default: 0.3).\n    gamma (float): The weight for the capacity utilization (default: 0.3).\n\n    Returns:\n    np.ndarray: An array of priority scores for each bin.\n    \"\"\"\n\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the capacity utilization priority, emphasizing bins with sufficient capacity\n    capacity_utilization_priority = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and capacity utilization\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * capacity_utilization_priority\n    \n    # Adapt the weights based on the problem state (e.g., the number of bins and their remaining capacities)\n    num_bins = len(bins_remain_cap)\n    avg_capacity = np.mean(bins_remain_cap)\n    if num_bins > 10 and avg_capacity < item / 2:\n        alpha += 0.1\n        beta -= 0.05\n        gamma -= 0.05\n    elif num_bins < 5 and avg_capacity > item * 2:\n        alpha -= 0.1\n        beta += 0.05\n        gamma += 0.05\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 79.18827283605904,
    "SLOC": 19.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 729.4477381208684,
    "mi": 79.09382223114932,
    "token_count": 355.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective priorities with dynamic weighting and forecasting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Forecast the future item sizes based on the remaining capacities\n    forecast_factor = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and forecasted future item sizes\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * forecast_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority\n\n# Example usage:\nitem_size = 10.0\nbins_remain_cap = np.array([5.0, 15.0, 20.0])\npriority_scores = priority_v2(item_size, bins_remain_cap)\nprint(\"Priority scores:\", priority_scores)",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.856402074192266,
    "SLOC": 19.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 729.4477381208684,
    "mi": 79.09382223114932,
    "token_count": 355.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response3.txt_stdout.txt",
    "code_path": "problem_iter12_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    An evolved priority function that incorporates dynamic weighting, forecasting, and problem state adaptation.\n    \n    Parameters:\n    item (float): The size of the current item to be packed.\n    bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n    alpha (float): Weight for the current item's fit priority (default: 0.4).\n    beta (float): Weight for the bin utilization priority (default: 0.3).\n    gamma (float): Weight for the future potential and forecasting priority (default: 0.3).\n    \n    Returns:\n    np.ndarray: A priority score for each bin, with the highest score indicating the best bin for the current item.\n    \"\"\"\n\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Forecast future item sizes based on the average remaining capacity\n    forecasted_item_size = np.mean(bins_remain_cap) + np.std(bins_remain_cap)\n    future_potential_priority = bins_remain_cap / (bins_remain_cap + forecasted_item_size)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and future potential\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * future_potential_priority * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 729.4477381208684,
    "mi": 79.09382223114932,
    "token_count": 355.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    A new priority function that incorporates dynamic weighting, forecasting, and adaptation to the problem state.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate a forecasted utilization priority based on the average remaining capacity and item size\n    forecasted_utilization_priority = (np.mean(bins_remain_cap) + item) / (np.mean(bins_remain_cap) + item + avg_historic_size)\n    \n    # Adjust the weighting factors based on the problem state (average remaining capacity and item size)\n    adjusted_alpha = alpha * (1 - np.mean(bins_remain_cap) / (item + np.mean(bins_remain_cap)))\n    adjusted_beta = beta * (1 - np.mean(bins_remain_cap) / (item + np.mean(bins_remain_cap)))\n    adjusted_gamma = gamma * (1 - np.mean(bins_remain_cap) / (item + np.mean(bins_remain_cap)))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and forecasted utilization\n    priority = adjusted_alpha * fit_priority + adjusted_beta * utilization_priority + adjusted_gamma * forecasted_utilization_priority\n    \n    # Incorporate a penalty for bins with low remaining capacity\n    penalty_for_low_capacity = 1 / (1 + np.exp(-bins_remain_cap))\n    priority *= penalty_for_low_capacity\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.856402074192266,
    "SLOC": 19.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 729.4477381208684,
    "mi": 79.09382223114932,
    "token_count": 355.0,
    "exec_success": true
  }
]