[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\n# Define the weights for the priorities\nalpha = 0.4\nbeta = 0.3\ngamma = 0.3\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and dynamic weighting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Forecast the future item sizes based on the remaining capacities\n    forecast_factor = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and forecasted future item sizes\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * forecast_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority\n\n# Example usage:\nitem_size = 10.0\nbins_remain_cap = np.array([5.0, 15.0, 20.0])\npriority_scores = priority_v2(item_size, bins_remain_cap)\nprint(\"Priority scores:\", priority_scores)",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.856402074192266,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority function combining multiple objectives.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_bin_cap = np.mean(bins_remain_cap)\n    utilization_priority = (bins_remain_cap + avg_bin_cap) / (bins_remain_cap + item + avg_bin_cap)\n    \n    # Adaptive weighting based on the problem landscape\n    alpha = 0.4 + 0.2 * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.3 + 0.1 * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    gamma = 0.3  # Weighting for penalty factor\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap\n    \n    # Incorporate a penalty for bins with low remaining capacity\n    penalty_for_low_capacity = 1 / (1 + np.exp(-bins_remain_cap))\n    priority *= penalty_for_low_capacity\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and dynamic prioritization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    alpha = 0.4 + 0.2 * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.3 + 0.1 * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    gamma = 0.3  # Weighting for penalty factor\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    utilization_priority = (bins_remain_cap + avg_bin_cap) / (bins_remain_cap + item + avg_bin_cap)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap + 0.1 * balance_factor\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic combining adaptive weighting and forecasting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Using a log-based invert function\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Adaptive weighting based on the problem's current state\n    alpha = 0.4  # Weight for the current item's fit priority\n    beta = 0.3  # Weight for the bin utilization priority\n    gamma = 0.3  # Weight for the future potential and forecasting priority\n    \n    # Forecast future item sizes based on the average remaining capacity\n    forecasted_item_size = np.mean(bins_remain_cap) + np.std(bins_remain_cap)\n    future_potential_priority = bins_remain_cap / (bins_remain_cap + forecasted_item_size)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and future potential\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * future_potential_priority * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and dynamic prioritization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # Calculate the ratio of the item size to the remaining capacity of each bin\n    ratio = item / np.maximum(bins_remain_cap, 1e-8)  # avoid division by zero\n    \n    # Assign higher priority to bins with lower ratio (i.e., less likely to leave a small gap)\n    # and with more remaining capacity (i.e., more space to accommodate future items)\n    priority_ratio = np.where(bins_remain_cap >= item, \n                              # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                              bins_remain_cap * (1 - ratio) / (bins_remain_cap + 1), \n                              # for bins that cannot hold the item, the priority is zero\n                              0.0)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Adaptive weighting based on the problem's current state\n    total_remain_cap = np.sum(bins_remain_cap)\n    if total_remain_cap == 0:\n        adapt_weight = 0\n    else:\n        adapt_weight = (item / total_remain_cap) * 0.4 + (1 - item / total_remain_cap) * 0.3\n    \n    # Dynamic prioritization based on the current item's size and the remaining capacities\n    dynamic_prioritization = np.exp(-capacity_diff / (1 + item))\n    \n    # Combine the priorities using adaptive weighting\n    alpha = 0.6  # weight for priority based on capacity\n    beta = 0.2  # weight for priority based on ratio\n    gamma = 0.1  # weight for utilization priority\n    delta_weight = 0.1  # weight for dynamic prioritization\n    combined_priority = alpha * priority_capacity + beta * priority_ratio + gamma * utilization_priority * penalty_factor\n    combined_priority += delta_weight * dynamic_prioritization\n    \n    # Ensure priorities are not negative\n    combined_priority = np.where(combined_priority < 0, 0, combined_priority)\n    \n    # Consider the remaining capacity of each bin to avoid overfilling\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority + 0.01 * bins_remain_cap, combined_priority)\n    \n    return combined_priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 86.94654966094936,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and dynamic forecasting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff) / np.log(3.260733352983878 + 1))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall) / 8.750124496524109) * 1 / (1 + np.exp(excess) / 8.750124496524109)\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    alpha = 0.5312997516499514 + (0.5100436931845322 - 0.5312997516499514) * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.39664870844933536 + (0.3737788894904021 - 0.39664870844933536) * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + (1 - alpha - beta) * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multiple objectives.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)  # Using a simple invert function\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    balance_priority = balance_factor * fit_priority\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Ensure utilization_priority does not exceed a certain threshold (e.g., 0.9)\n    utilization_threshold = 0.8618692586727021\n    utilization_priority = np.where(utilization_priority > utilization_threshold, utilization_threshold, utilization_priority)\n    \n    # Adaptive weighting based on the problem's current state\n    total_remain_cap = np.sum(bins_remain_cap)\n    if total_remain_cap == 0:\n        adapt_weight = 0\n    else:\n        adapt_weight = (item / total_remain_cap) * 0.4 + (1 - item / total_remain_cap) * 0.3  # Dynamic weighting\n    \n    # Calculate the overall priority, balancing the current item's fit, balance factor, and bin utilization\n    alpha = 0.30802702122924797\n    beta = 0.5604929558148649\n    gamma = 0.12235746371576073\n    priority = alpha * fit_priority + beta * balance_priority + gamma * utilization_priority + (1 - alpha - beta - gamma) * penalty_factor * bins_remain_cap\n    \n    # Add dynamic weighting to the priority calculation\n    priority = adapt_weight * priority + (1 - adapt_weight) * (0.3 * utilization_priority + 0.3 * balance_factor)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    threshold_item_size = 6.210180126136486\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and dynamic prioritization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate priority based on how full the bin is and how well the item fits\n    priority_fullness = np.where(bins_remain_cap >= item, \n                                 # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                                 1.0 / (bins_remain_cap + 1), \n                                 # for bins that cannot hold the item, the priority is zero\n                                 0.0)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Adaptive weighting based on the problem's current state\n    total_remain_cap = np.sum(bins_remain_cap)\n    if total_remain_cap == 0:\n        adapt_weight = 0\n    else:\n        adapt_weight = (item / total_remain_cap) * 0.4 + (1 - item / total_remain_cap) * 0.3\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Forecast the future item sizes based on the remaining capacities\n    forecast_factor = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Dynamic prioritization based on the current item's size and the remaining capacities\n    dynamic_prioritization = np.exp(-capacity_diff / (1 + item))\n    \n    # Combine the priorities using adaptive weighting\n    alpha = 0.4\n    beta = 0.3\n    gamma = 0.3\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * forecast_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority\n\n# Example usage:\nitem_size = 10.0\nbins_remain_cap = np.array([5.0, 15.0, 20.0])\npriority_scores = priority_v2(item_size, bins_remain_cap)\nprint(\"Priority scores:\", priority_scores)",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.856402074192266,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic combining adaptive weighting, multiple objectives, and dynamic weighting.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and tight fit\n    alpha = 0.4  # weight for priority based on fit\n    beta = 0.3  # weight for priority based on utilization\n    gamma = 0.3  # weight for priority based on tight fit and penalty factor\n    combined_priority = alpha * fit_priority + beta * utilization_priority + gamma * (priority_tight_fit * penalty_factor * bins_remain_cap)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    combined_priority = np.nan_to_num(combined_priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority, -1)\n    \n    return combined_priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 6.342241723175124,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    Combining adaptive weighting and forecasting.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  \n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the forecasted utilization priority based on the average remaining capacity and item size\n    forecasted_utilization_priority = (np.mean(bins_remain_cap) + item) / (np.mean(bins_remain_cap) + item + avg_historic_size)\n    \n    # Adjust the weighting factors based on the problem state (average remaining capacity and item size)\n    adjusted_alpha = alpha * (1 - np.mean(bins_remain_cap) / (item + np.mean(bins_remain_cap)))\n    adjusted_beta = beta * (1 - np.mean(bins_remain_cap) / (item + np.mean(bins_remain_cap)))\n    adjusted_gamma = gamma * (1 - np.mean(bins_remain_cap) / (item + np.mean(bins_remain_cap)))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and forecasted utilization\n    priority = adjusted_alpha * fit_priority + adjusted_beta * utilization_priority + adjusted_gamma * forecasted_utilization_priority\n    \n    # Incorporate a penalty for bins with low remaining capacity\n    penalty_for_low_capacity = 1 / (1 + np.exp(-bins_remain_cap))\n    priority *= penalty_for_low_capacity\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Adapt the weights based on the problem state (e.g., the number of bins and their remaining capacities)\n    num_bins = len(bins_remain_cap)\n    avg_capacity = np.mean(bins_remain_cap)\n    if num_bins > 10 and avg_capacity < item / 2:\n        adjusted_alpha += 0.1\n        adjusted_beta -= 0.05\n        adjusted_gamma -= 0.05\n    elif num_bins < 5 and avg_capacity > item * 2:\n        adjusted_alpha -= 0.1\n        adjusted_beta += 0.05\n        adjusted_gamma += 0.05\n    \n    # Recalculate the overall priority with the adapted weights\n    priority = adjusted_alpha * fit_priority + adjusted_beta * utilization_priority + adjusted_gamma * forecasted_utilization_priority\n    \n    return priority",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.856402074192266,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1137.657801614067,
    "mi": 74.63474087972187,
    "token_count": 442.0,
    "exec_success": true
  }
]