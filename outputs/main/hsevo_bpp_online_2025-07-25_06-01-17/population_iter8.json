[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, all_items: np.ndarray = None) -> np.ndarray:\n    \"\"\"\n    Combines dynamic weighting, capacity difference, balance factor, and forecasting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity_diff = 1 / (1 + capacity_diff)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Calculate waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and tight fit\n    # Use dynamic weighting based on the item size and remaining capacity\n    weight_tight_fit = np.where(item > np.mean(bins_remain_cap), 0.6, 0.4)\n    weight_capacity_diff = np.where(item < np.mean(bins_remain_cap), 0.3, 0.2)\n    weight_balance = 1 - weight_tight_fit - weight_capacity_diff\n    \n    priority = weight_tight_fit * priority_tight_fit + weight_capacity_diff * priority_capacity_diff + weight_balance * balance_factor\n    \n    # Consider forecasting future items to anticipate constraints\n    if all_items is not None:\n        future_items = all_items[all_items > item]\n        forecast_factor = 1 / (1 + np.sum(future_items))\n        priority *= forecast_factor\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero) and avoid bins that are too full or too empty\n    priority = np.where(bins_remain_cap < item, -np.inf, priority)\n    priority = np.where(bins_remain_cap == 0, priority * 0.9, priority)  # reduce priority for empty bins\n    \n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the capacity difference factor\n    priority_capacity = 1 / (1 + capacity_diff)  # Prioritize bins with smallest capacity difference\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n\n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the available space in each bin relative to the item size\n    relative_available_space = np.where(bins_remain_cap >= item, bins_remain_cap - item, -np.inf)\n\n    # Combine the priorities using dynamic weighting\n    # Weight1: gives more importance to bins with enough capacity and a good fit\n    weight1 = np.where(bins_remain_cap >= item, bins_remain_cap * penalty_factor, 0)\n    # Weight2: favors bins that have enough capacity to fit the item and have the most available space\n    weight2 = priority_capacity * relative_available_space / (item + 1e-6)\n    \n    # Calculate the current utilization of each bin\n    current_utilization = 1 - (bins_remain_cap / np.sum(bins_remain_cap))\n    \n    # Calculate the priority score for the current utilization factor\n    priority_utilization = 1 / (1 + current_utilization)  # Prioritize bins with lowest utilization\n    \n    # Combine the weighted priorities with dynamic weighting\n    alpha = 0.4  # weight for capacity difference\n    beta = 0.3   # weight for current utilization\n    gamma = 0.3  # weight for available space and penalty factor\n    combined_priority = alpha * priority_capacity + beta * priority_utilization + gamma * (weight1 + weight2)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    combined_priority[bins_remain_cap < item] = 0  # Ensure item can fit in bin\n    \n    return combined_priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\n# Define weighting factors with default values\nalpha = 0.4\nbeta = 0.3\ngamma = 0.3\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective priorities with dynamic weighting and fragmentation.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the bin fragmentation, prioritizing bins with less wasted space\n    fragmentation_priority = 1 / (1 + np.abs(bins_remain_cap - item) / bins_remain_cap)\n    fragmentation_priority[bins_remain_cap == 0] = 0\n    \n    # Dynamically adjust the weighting factors\n    avg_remain_cap = np.mean(bins_remain_cap)\n    if avg_remain_cap < item:\n        alpha = 0.5\n        beta = 0.3\n        gamma = 0.2\n    else:\n        alpha = 0.3\n        beta = 0.4\n        gamma = 0.3\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and fragmentation\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * fragmentation_priority\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, all_items: np.ndarray = None) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective optimization, adaptive weighting, and dynamic prioritization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    priority *= balance_factor\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    priority *= penalty_factor\n    \n    # Calculate the wasted space for each bin if the item is added\n    wasted_space = np.maximum(bins_remain_cap - item, 0)\n    \n    # Invert the wasted space so that bins with least wasted space get higher priority\n    inverted_wasted_space = 1 / (wasted_space + 1e-6)  # Add small value for numerical stability\n    \n    # Combine the two priorities\n    combined_priority = priority * inverted_wasted_space\n    \n    # Consider forecasting future items to anticipate constraints\n    if all_items is not None:\n        future_items = all_items[all_items > item]\n        forecast_factor = 1 / (1 + np.sum(future_items))\n        combined_priority *= forecast_factor\n    \n    # Normalize the priorities to ensure they add up to 1\n    normalized_priority = combined_priority / (np.sum(combined_priority) + 1e-6)\n    \n    # Ensure bins with higher remaining capacity get higher priority when the item fits\n    normalized_priority = np.where(bins_remain_cap >= item, normalized_priority + 0.1 * bins_remain_cap, normalized_priority)\n    \n    return normalized_priority",
    "response_id": 3,
    "tryHS": false,
    "obj": 149.2919824491424,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n\n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n\n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_score = 1 / (1 + capacity_diff)\n\n    # Calculate the available space in each bin relative to the item size\n    relative_available_space = np.where(bins_remain_cap >= item, bins_remain_cap - item, -np.inf)\n\n    # Adaptive weighting based on the problem landscape\n    alpha = 0.4  # initial weighting for fit priority\n    beta = 0.3  # initial weighting for utilization priority\n    gamma = 0.3  # initial weighting for penalty factor\n\n    avg_bin_cap = np.mean(bins_remain_cap)\n    if avg_bin_cap > item:\n        alpha += 0.1\n        beta -= 0.1\n    else:\n        alpha -= 0.1\n        beta += 0.1\n\n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    weight1 = np.where(bins_remain_cap >= item, bins_remain_cap * penalty_factor, 0)\n    weight2 = priority_score * relative_available_space / (item + 1e-6)\n    combined_priority = weight1 + weight2\n\n    # Ensure bins with higher remaining capacity get higher priority when the item fits\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority + bins_remain_cap, combined_priority)\n\n    # Assign high priority to bins with enough capacity and a good fit\n    priority = alpha * priority_score + beta * (bins_remain_cap / (bins_remain_cap + item)) + gamma * penalty_factor * bins_remain_cap\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n\n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 51.58556043079378,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the ratio of the item size to the remaining capacity of each bin\n    ratio = item / np.maximum(bins_remain_cap, 1e-8)  # avoid division by zero\n    \n    # Assign higher priority to bins with lower ratio (i.e., less likely to leave a small gap)\n    # and with more remaining capacity (i.e., more space to accommodate future items)\n    priority_ratio = np.where(bins_remain_cap >= item, \n                              # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                              bins_remain_cap * (1 - ratio) / (bins_remain_cap + 1), \n                              # for bins that cannot hold the item, the priority is zero\n                              0.0)\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Combine priorities using adaptive weighting\n    alpha = 0.7  # weight for priority based on waste\n    beta = 0.3  # weight for priority based on ratio\n    gamma = 0.5  # weight for priority based on capacity difference\n    combined_priority = alpha * priority_tight_fit + beta * priority_ratio + gamma * priority_capacity * penalty_factor\n    \n    # Avoid bins that are too full or too empty\n    combined_priority = np.where(bins_remain_cap < item, -np.inf, combined_priority)\n    combined_priority = np.where(bins_remain_cap == 0, combined_priority * 0.9, combined_priority)  # reduce priority for empty bins\n    \n    return combined_priority",
    "response_id": 5,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multi-objective optimization, and dynamic prioritization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    balance_priority = balance_factor * fit_priority\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Ensure utilization_priority does not exceed a certain threshold (e.g., 0.9)\n    utilization_threshold = 0.9\n    utilization_priority = np.where(utilization_priority > utilization_threshold, utilization_threshold, utilization_priority)\n    \n    # Calculate the overall priority, balancing the current item's fit, balance factor, and bin utilization\n    alpha = 0.4  # Weight for fit priority\n    beta = 0.3  # Weight for balance priority\n    gamma = 0.3  # Weight for utilization priority\n    priority = alpha * fit_priority + beta * balance_priority + gamma * utilization_priority + (1 - alpha - beta - gamma) * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    threshold_item_size = 1.0\n    priority = np.where(bins_remain_cap >= threshold_item_size, priority, -1)\n    \n    return priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.028719585161557,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 5.6183698719462525 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate bin utilization, considering both the current item and future potential\n    avg_historic_size = 5.24157358822766 * np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Ensure utilization_priority does not exceed the utilization_threshold\n    utilization_threshold = 0.8882678823010766\n    utilization_priority = np.where(utilization_priority > utilization_threshold, utilization_threshold, utilization_priority)\n    \n    # Calculate waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Use dynamic weighting based on the item size and remaining capacity\n    weight_tight_fit = np.where(item > np.mean(bins_remain_cap), 0.6, 0.4)\n    weight_fit_priority = np.where(item < np.mean(bins_remain_cap), 0.3, 0.2)\n    weight_utilization = 1 - weight_tight_fit - weight_fit_priority\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and tight fit\n    priority = weight_tight_fit * priority_tight_fit + weight_fit_priority * fit_priority + weight_utilization * utilization_priority + (1 - weight_tight_fit - weight_fit_priority - weight_utilization) * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    threshold_item_size = 1.7749043239515936\n    priority = np.where(bins_remain_cap >= threshold_item_size, priority, -1)\n    \n    return priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority = np.where(bins_remain_cap >= item, priority, 0)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    priority *= balance_factor\n    \n    # Calculate the tightness of fit for the current item in each bin\n    fit_priority = np.exp(-np.abs(bins_remain_cap - item))\n    \n    # Calculate the utilization ratio for each bin, considering the current item\n    utilization_priority = (bins_remain_cap + item) / (bins_remain_cap + np.mean(bins_remain_cap))\n    \n    # Calculate a penalty factor for each bin based on the excess capacity\n    excess_penalty = np.exp(-np.maximum(0, bins_remain_cap - item))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and excess penalty\n    alpha = 0.4  # Dynamic weighting for fit priority\n    beta = 0.3   # Dynamic weighting for utilization priority\n    gamma = 0.3  # Dynamic weighting for excess penalty\n    \n    # Combine the priorities\n    combined_priority = alpha * fit_priority + beta * utilization_priority + gamma * priority * balance_factor\n    \n    # Normalize the priorities to ensure they add up to 1\n    normalized_priority = combined_priority / (np.sum(combined_priority) + 1e-6)\n    \n    return normalized_priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 66.6832867969685,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multi-objective optimization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority_capacity[bins_remain_cap < item] = 0\n    \n    # Calculate priority based on how full the bin is and how well the item fits\n    priority_fullness = np.where(bins_remain_cap >= item, \n                                 # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                                 1.0 / (bins_remain_cap + 1), \n                                 # for bins that cannot hold the item, the priority is zero\n                                 0.0)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Combine the priorities using adaptive weighting\n    priorities = 0.4 * priority_capacity + 0.3 * priority_fullness + 0.2 * balance_factor + 0.1 * penalty_factor\n    \n    # Ensure priorities are not negative\n    priorities = np.where(priorities < 0, 0, priorities)\n    \n    # Consider the remaining capacity of each bin to avoid overfilling\n    priorities = np.where(bins_remain_cap >= item, priorities + 0.01 * bins_remain_cap, priorities)\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 94.83446350219387,
    "SLOC": 17.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 459.82999304101565,
    "mi": 84.07007542080652,
    "token_count": 238.0,
    "exec_success": true
  }
]