[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective approach with dynamic weighting.\n    \"\"\"\n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the ratio of the item size to the remaining capacity of each bin\n    ratio = item / np.maximum(bins_remain_cap, 1e-8)  # avoid division by zero\n    \n    # Assign higher priority to bins with lower ratio (i.e., less likely to leave a small gap)\n    # and with more remaining capacity (i.e., more space to accommodate future items)\n    priority_ratio = np.where(bins_remain_cap >= item, \n                              # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                              bins_remain_cap * (1 - ratio) / (bins_remain_cap + 1), \n                              # for bins that cannot hold the item, the priority is zero\n                              0.0)\n    \n    # Combine priorities using dynamic weighting\n    alpha = 0.7  # weight for priority based on waste\n    beta = 0.3  # weight for priority based on ratio\n    combined_priority = alpha * priority + beta * priority_ratio\n    \n    # Avoid bins that are too full or too empty\n    combined_priority = np.where(bins_remain_cap < item, -np.inf, combined_priority)\n    combined_priority = np.where(bins_remain_cap == 0, combined_priority * 0.9, combined_priority)  # reduce priority for empty bins\n    \n    return combined_priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective and weighted factors for better bin packing.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority_capacity[bins_remain_cap < item] = 0\n    \n    # Calculate priority based on how full the bin is and how well the item fits\n    priority_fullness = np.where(bins_remain_cap >= item, \n                                 # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                                 1.0 / (bins_remain_cap + 1), \n                                 # for bins that cannot hold the item, the priority is zero\n                                 0.0)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Combine the priorities using adaptive weighting\n    priorities = 0.5 * priority_capacity + 0.3 * priority_fullness + 0.2 * balance_factor\n    \n    # Ensure priorities are not negative\n    priorities = np.where(priorities < 0, 0, priorities)\n    \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, all_items: np.ndarray = None) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective and dynamic weighting for better outcomes.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    priority *= balance_factor\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    priority *= penalty_factor\n    \n    # Consider forecasting future items to anticipate constraints\n    if all_items is not None:\n        future_items = all_items[all_items > item]\n        forecast_factor = 1 / (1 + np.sum(future_items))\n        priority *= forecast_factor\n    \n    # Ensure bins with higher remaining capacity get higher priority when the item fits\n    priority = np.where(bins_remain_cap >= item, priority + 0.1 * bins_remain_cap, priority)\n    \n    return priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective approach with dynamic weighting.\n    \"\"\"\n    # Calculate waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    priority_capacity_diff = 1 / (1 + capacity_diff)\n    \n    # Calculate bin utilization, considering both the current item and future potential\n    utilization_priority = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and tight fit\n    # Use dynamic weighting based on the item size and remaining capacity\n    weight_tight_fit = np.where(item > np.mean(bins_remain_cap), 0.6, 0.4)\n    weight_capacity_diff = np.where(item < np.mean(bins_remain_cap), 0.3, 0.2)\n    weight_utilization = 1 - weight_tight_fit - weight_capacity_diff\n    \n    priority = weight_tight_fit * priority_tight_fit + weight_capacity_diff * priority_capacity_diff + weight_utilization * utilization_priority\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero) and avoid bins that are too full or too empty\n    priority = np.where(bins_remain_cap < item, -np.inf, priority)\n    priority = np.where(bins_remain_cap == 0, priority * 0.9, priority)  # reduce priority for empty bins\n    \n    return priority",
    "response_id": 3,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, \n                all_items: np.ndarray = None, alpha: float = 0.5, beta: float = 0.3, gamma: float = 0.2) -> np.ndarray:\n    \"\"\"\n    Combines capacity difference, balance factor, and forecasting for bin prioritization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the capacity difference factor\n    priority_capacity = 1 / (1 + capacity_diff)  # Prioritize bins with smallest capacity difference\n    \n    # Calculate the current utilization of each bin\n    current_utilization = 1 - (bins_remain_cap / np.sum(bins_remain_cap))\n    \n    # Calculate the priority score for the current utilization factor\n    priority_utilization = 1 / (1 + current_utilization)  # Prioritize bins with lowest utilization\n    \n    # If all item sizes are provided, calculate the expected future utilization\n    if all_items is not None:\n        # Calculate the average item size\n        avg_item_size = np.mean(all_items)\n        \n        # Calculate the expected future utilization of each bin\n        future_utilization = bins_remain_cap / (np.sum(bins_remain_cap) + avg_item_size)\n        \n        # Calculate the priority score for the future utilization factor\n        priority_future = 1 / (1 + future_utilization)  # Prioritize bins with lowest expected future utilization\n    else:\n        priority_future = np.ones_like(bins_remain_cap)\n    \n    # Calculate the overall priority score by combining the three factors\n    priority = alpha * priority_capacity + beta * priority_utilization + gamma * priority_future\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority[bins_remain_cap < item] = 0  # Ensure item can fit in bin\n    \n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, historic_item_sizes: np.ndarray = None, alpha: float = 0.5, beta: float = 0.3) -> np.ndarray:\n    \"\"\"\n    Multi-objective heuristic with dynamic weighting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # Calculate the available space in each bin relative to the item size\n    # to favor bins that have enough capacity to fit the item and have the most available space\n    relative_available_space = np.where(bins_remain_cap >= item, bins_remain_cap - item, -np.inf)\n    \n    # Combine the two priorities to balance competing factors\n    priority_balance = priority_capacity * relative_available_space / (item + 1e-6)\n    \n    # If historic item sizes are available, forecast future item sizes\n    if historic_item_sizes is not None:\n        # Calculate the average size of historic items\n        avg_historic_size = np.mean(historic_item_sizes)\n        \n        # Calculate the difference between the remaining capacity of each bin and the forecasted item size\n        forecast_diff = np.abs(bins_remain_cap - avg_historic_size)\n        \n        # Invert the differences to obtain a priority score (lower difference -> higher priority)\n        priority_forecast = 1 / (1 + forecast_diff)\n        \n        # Combine the priority scores using weighting factors\n        priority = alpha * priority_balance + beta * priority_forecast\n    else:\n        # If no historic item sizes are available, use only the balance priority\n        priority = priority_balance\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority[bins_remain_cap < item] = 0\n    \n    return priority",
    "response_id": 5,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective approach with dynamic weighting.\n    \"\"\"\n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n\n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n\n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_score = 1 / (1 + capacity_diff)\n\n    # Calculate the available space in each bin relative to the item size\n    relative_available_space = np.where(bins_remain_cap >= item, bins_remain_cap - item, -np.inf)\n\n    # Combine the priorities using dynamic weighting\n    # Weight1: gives more importance to bins with enough capacity and a good fit\n    weight1 = np.where(bins_remain_cap >= item, bins_remain_cap * penalty_factor, 0)\n    # Weight2: favors bins that have enough capacity to fit the item and have the most available space\n    weight2 = priority_score * relative_available_space / (item + 1e-6)\n\n    # Combine the weighted priorities\n    combined_priority = weight1 + weight2\n\n    # If the item size exceeds the remaining capacity, set the priority to 0\n    combined_priority[bins_remain_cap < item] = 0\n\n    # Ensure bins with higher remaining capacity get higher priority when the item fits\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority + bins_remain_cap, combined_priority)\n\n    return combined_priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 148.53410450737937,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, historic_item_sizes: np.ndarray = None, alpha: float = 0.5, beta: float = 0.3) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective approach with adaptive weighting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority_capacity = 1 / (1 + capacity_diff)\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # If historic item sizes are available, forecast future item sizes\n    if historic_item_sizes is not None:\n        # Calculate the average size of historic items\n        avg_historic_size = np.mean(historic_item_sizes)\n        \n        # Calculate the difference between the remaining capacity of each bin and the forecasted item size\n        forecast_diff = np.abs(bins_remain_cap - avg_historic_size)\n        \n        # Invert the differences to obtain a priority score (lower difference -> higher priority)\n        priority_forecast = 1 / (1 + forecast_diff)\n        \n        # Combine the priority scores using weighting factors\n        priority = alpha * priority_capacity * penalty_factor + beta * priority_forecast * penalty_factor\n    else:\n        # If no historic item sizes are available, use only the capacity difference objective\n        priority = priority_capacity * penalty_factor\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority[bins_remain_cap < item] = 0\n    \n    # Ensure bins with higher remaining capacity get higher priority when the item fits\n    priority = np.where(bins_remain_cap >= item, priority + bins_remain_cap, priority)\n    \n    return priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.5, beta: float = 0.3) -> np.ndarray:\n    \"\"\"\n    Combines multi-objective priorities with dynamic weighting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the overall priority, balancing the current item's fit and bin utilization\n    priority = alpha * fit_priority + beta * utilization_priority + (1 - alpha - beta) * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 3.8492221779018885,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, all_items: np.ndarray = None) -> np.ndarray:\n    \"\"\"\n    Combines capacity difference, balance factor, and forecasting for a robust heuristic.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score (lower difference -> higher priority)\n    priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    priority[bins_remain_cap < item] = 0\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    priority *= balance_factor\n    \n    # Calculate the wasted space for each bin if the item is added\n    wasted_space = np.maximum(bins_remain_cap - item, 0)\n    \n    # Invert the wasted space so that bins with least wasted space get higher priority\n    inverted_wasted_space = 1 / (wasted_space + 1e-6)  # Add small value for numerical stability\n    \n    # Combine the two priorities\n    combined_priority = priority * inverted_wasted_space\n    \n    # Consider forecasting future items to anticipate constraints\n    if all_items is not None:\n        future_items = all_items[all_items > item]\n        forecast_factor = 1 / (1 + np.sum(future_items))\n        combined_priority *= forecast_factor\n    \n    # Normalize the priorities to ensure they add up to 1\n    normalized_priority = combined_priority / (np.sum(combined_priority) + 1e-6)\n    \n    return normalized_priority",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 291.47885970765435,
    "mi": 83.59101348814166,
    "token_count": 199.0,
    "exec_success": true
  }
]