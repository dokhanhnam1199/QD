```python
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

class AdaptivePriority:
    def __init__(self, learning_rate=0.1, regularization=0.01):
        self.learning_rate = learning_rate
        self.regularization = regularization
        self.scaler = StandardScaler()
        self.model = LinearRegression()

    def fit(self, X, y):
        X_scaled = self.scaler.fit_transform(X)
        self.model.fit(X_scaled, y)

    def predict(self, X):
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)

def priority_v2(item: float, bins_remain_cap: np.ndarray, adaptive_priority: AdaptivePriority) -> np.ndarray:
    """
    Integrates machine learning with adaptive weighting and multi-objective priorities.
    """
    # Calculate the difference between the remaining capacity of each bin and the item size
    capacity_diff = np.abs(bins_remain_cap - item)
    
    # Invert the differences to obtain a priority score for the current item's fit
    fit_priority = 1 / (1 + capacity_diff)
    
    # If the item size exceeds the remaining capacity, set the priority to 0
    fit_priority[bins_remain_cap < item] = 0
    
    # Calculate the shortfall or excess capacity for each bin
    shortfall = np.maximum(0, item - bins_remain_cap)
    excess = np.maximum(0, bins_remain_cap - item)
    
    # Calculate a penalty factor for each bin based on the shortfall or excess capacity
    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))
    
    # Calculate the bin utilization, considering both the current item and future potential
    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes
    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)
    
    # Train a linear regression model to predict the optimal bin utilization based on item size and remaining capacity
    X = np.array([bins_remain_cap, item * np.ones_like(bins_remain_cap)]).T
    y = utilization_priority
    adaptive_priority.fit(X, y)
    
    # Predict the adaptive weighting factor for each bin
    X_adaptive = np.array([bins_remain_cap, item * np.ones_like(bins_remain_cap)]).T
    weights = adaptive_priority.predict(X_adaptive)
    
    # Calculate the overall priority, balancing the current item's fit and bin utilization
    priority = fit_priority * weights + utilization_priority * (1 - weights) + penalty_factor * bins_remain_cap
    
    # Ensure the priority scores are not NaN (e.g., due to division by zero)
    priority = np.nan_to_num(priority)
    
    # Assign high priority to bins with enough capacity and a good fit
    priority = np.where(bins_remain_cap >= item, priority, -1)
    
    return priority

# Example usage:
adaptive_priority = AdaptivePriority()
item_size = 10.0
bins_remain_cap = np.array([20.0, 15.0, 30.0, 25.0])
priority_scores = priority_v2(item_size, bins_remain_cap, adaptive_priority)
print(priority_scores)
```
