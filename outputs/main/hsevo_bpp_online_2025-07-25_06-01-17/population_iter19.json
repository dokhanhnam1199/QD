[
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and nuance.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the ratio of the item size to the remaining capacity of each bin\n    ratio = item / np.maximum(bins_remain_cap, 1e-8)  # avoid division by zero\n    \n    # Assign higher priority to bins with lower ratio (i.e., less likely to leave a small gap)\n    # and with more remaining capacity (i.e., more space to accommodate future items)\n    priority_ratio = np.where(bins_remain_cap >= item, \n                              # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                              bins_remain_cap * (1 - ratio) / (bins_remain_cap + 1), \n                              # for bins that cannot hold the item, the priority is zero\n                              0.0)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Adaptive weighting based on the problem's current state\n    total_remain_cap = np.sum(bins_remain_cap)\n    if total_remain_cap == 0:\n        adapt_weight = 0\n    else:\n        adapt_weight = (item / total_remain_cap) * 0.4 + (1 - item / total_remain_cap) * 0.3\n    \n    # Dynamic prioritization based on the current item's size and the remaining capacities\n    dynamic_prioritization = np.exp(-capacity_diff / (1 + item))\n    \n    # Combine the priorities using adaptive weighting\n    alpha = 0.6  # weight for priority based on capacity\n    beta = 0.2  # weight for priority based on ratio\n    gamma = 0.1  # weight for utilization priority\n    delta_weight = 0.1  # weight for dynamic prioritization\n    combined_priority = alpha * fit_priority + beta * priority_ratio + gamma * utilization_priority * penalty_factor\n    combined_priority += delta_weight * dynamic_prioritization\n    \n    # Ensure priorities are not negative\n    combined_priority = np.where(combined_priority < 0, 0, combined_priority)\n    \n    # Consider the remaining capacity of each bin to avoid overfilling\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority + 0.01 * bins_remain_cap, combined_priority)\n    \n    return combined_priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 86.94654966094936,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multiple objectives for robust optimization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    # Using a combination of both heuristics for calculating fit priority\n    fit_priority = 0.5 * (1 / (1 + capacity_diff)) + 0.5 * (1 / (1 + np.log(1 + capacity_diff) / np.log(3.260733352983878 + 1)))\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    # Using a combination of both heuristics for calculating penalty factor\n    penalty_factor = 0.5 * (1 / (1 + np.exp(shortfall))) * 0.5 * (1 / (1 + np.exp(excess))) + 0.5 * (1 / (1 + np.exp(shortfall) / 8.750124496524109)) * 0.5 * (1 / (1 + np.exp(excess) / 8.750124496524109))\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    alpha = 0.5312997516499514 + (0.5100436931845322 - 0.5312997516499514) * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.39664870844933536 + (0.3737788894904021 - 0.39664870844933536) * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + (1 - alpha - beta) * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 1,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and dynamic prioritization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the ratio of the item size to the remaining capacity of each bin\n    ratio = item / np.maximum(bins_remain_cap, 1e-8)  # avoid division by zero\n    \n    # Assign higher priority to bins with lower ratio (i.e., less likely to leave a small gap)\n    # and with more remaining capacity (i.e., more space to accommodate future items)\n    priority_ratio = np.where(bins_remain_cap >= item, \n                              # for bins that can hold the item, the priority is inversely proportional to the remaining capacity\n                              bins_remain_cap * (1 - ratio) / (bins_remain_cap + 1), \n                              # for bins that cannot hold the item, the priority is zero\n                              0.0)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Adaptive weighting based on the problem's current state\n    total_remain_cap = np.sum(bins_remain_cap)\n    if total_remain_cap == 0:\n        adapt_weight = 0\n    else:\n        adapt_weight = (item / total_remain_cap) * 0.4 + (1 - item / total_remain_cap) * 0.3\n    \n    # Dynamic prioritization based on the current item's size and the remaining capacities\n    dynamic_prioritization = np.exp(-capacity_diff / (1 + item))\n    \n    # Combine the priorities using adaptive weighting\n    alpha = 0.6  # weight for priority based on capacity\n    beta = 0.2  # weight for priority based on ratio\n    gamma = 0.1  # weight for utilization priority\n    delta_weight = 0.1  # weight for dynamic prioritization\n    combined_priority = alpha * fit_priority + beta * priority_ratio + gamma * utilization_priority * penalty_factor\n    combined_priority += delta_weight * dynamic_prioritization\n    \n    # Ensure priorities are not negative\n    combined_priority = np.where(combined_priority < 0, 0, combined_priority)\n    \n    # Consider the remaining capacity of each bin to avoid overfilling\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority + 0.01 * bins_remain_cap, combined_priority)\n    \n    # Combine multiple objectives with dynamic weighting\n    final_priority = 0.7 * combined_priority + 0.3 * (1 / (1 + capacity_diff))\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    final_priority = np.nan_to_num(final_priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    final_priority = np.where(bins_remain_cap >= item, final_priority, -1)\n    \n    return final_priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 86.40805743917032,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multiple objectives for robust optimization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Forecast the future item sizes based on the remaining capacities\n    forecast_factor = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and tight fit\n    alpha = 0.4  # weight for priority based on fit\n    beta = 0.3  # weight for priority based on utilization\n    gamma = 0.3  # weight for priority based on tight fit and penalty factor\n    combined_priority = alpha * fit_priority + beta * utilization_priority + gamma * (priority_tight_fit * penalty_factor * forecast_factor * bins_remain_cap)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    combined_priority = np.nan_to_num(combined_priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority, -1)\n    \n    return combined_priority\n\n# Example usage:\nitem_size = 10.0\nbins_remain_cap = np.array([5.0, 15.0, 20.0])\npriority_scores = priority_v2(item_size, bins_remain_cap)\nprint(\"Priority scores:\", priority_scores)",
    "response_id": 3,
    "tryHS": true,
    "obj": 6.342241723175124,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multiple objectives for robust optimization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    alpha = 0.4 + 0.2 * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.3 + 0.1 * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    gamma = 0.3  # Weighting for penalty factor\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    utilization_priority = (bins_remain_cap + avg_bin_cap) / (bins_remain_cap + item + avg_bin_cap)\n    \n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap + 0.1 * balance_factor + 0.1 * priority_tight_fit\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response5.txt_stdout.txt",
    "code_path": "problem_iter17_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and dynamic weighting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_bin_cap = np.mean(bins_remain_cap)\n    utilization_priority = (bins_remain_cap + avg_bin_cap) / (bins_remain_cap + item + avg_bin_cap)\n    \n    # Adaptive weighting based on the problem landscape\n    alpha_min = 0.5143700815933027\n    alpha_max = 0.6317414200996265\n    alpha = alpha_min + (alpha_max - alpha_min) * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta_min = 0.5305372003112541\n    beta_max = 0.22893487109456445\n    beta = beta_min + (beta_max - beta_min) * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + 0.378029924253778 * penalty_factor * bins_remain_cap\n    \n    # Incorporate a penalty for bins with low remaining capacity\n    penalty_for_low_capacity = 1 / (1 + np.exp(-bins_remain_cap))\n    priority *= penalty_for_low_capacity\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority\n\n# Example usage:\nitem_size = 10.0\nbins_remain_cap = np.array([5.0, 15.0, 20.0])\npriority_scores = priority_v2(item_size, bins_remain_cap)\nprint(\"Priority scores:\", priority_scores)",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response6.txt_stdout.txt",
    "code_path": "problem_iter17_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and dynamic prioritization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    alpha = 0.4 + 0.2 * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.3 + 0.1 * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    gamma = 0.3  # Weighting for penalty factor\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    utilization_priority = (bins_remain_cap + avg_bin_cap) / (bins_remain_cap + item + avg_bin_cap)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap + 0.1 * balance_factor\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    # Incorporate a penalty for bins with low remaining capacity\n    penalty_for_low_capacity = 1 / (1 + np.exp(-bins_remain_cap))\n    priority *= penalty_for_low_capacity\n    \n    return priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response7.txt_stdout.txt",
    "code_path": "problem_iter17_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and dynamic forecasting.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    # Improved fit priority using a logarithmic function\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff) / np.log(3.260733352983878 + 1))  \n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    # Improved penalty factor using exponential functions\n    penalty_factor = 1 / (1 + np.exp(shortfall) / 8.750124496524109) * 1 / (1 + np.exp(excess) / 8.750124496524109)\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    # Dynamic weighting for fit priority\n    alpha = 0.5312997516499514 + (0.5100436931845322 - 0.5312997516499514) * (item / (item + avg_bin_cap))  \n    # Dynamic weighting for utilization priority\n    beta = 0.39664870844933536 + (0.3737788894904021 - 0.39664870844933536) * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  \n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Forecast the future item sizes based on the remaining capacities\n    # Simple forecast factor\n    forecast_factor = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and forecasted future item sizes\n    # Combining priorities with adaptive weighting and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + (1 - alpha - beta) * penalty_factor * forecast_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority\n\n# Example usage:\nitem_size = 10.0\nbins_remain_cap = np.array([5.0, 15.0, 20.0])\npriority_scores = priority_v2(item_size, bins_remain_cap)\nprint(\"Priority scores:\", priority_scores)",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response8.txt_stdout.txt",
    "code_path": "problem_iter17_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and dynamic prioritization.\n    \"\"\"\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  # Improved fit priority\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Adaptive weighting based on the problem landscape\n    avg_bin_cap = np.mean(bins_remain_cap)\n    alpha = 0.4 + 0.2 * (item / (item + avg_bin_cap))  # Dynamic weighting for fit priority\n    beta = 0.3 + 0.1 * (bins_remain_cap.mean() / (bins_remain_cap.mean() + item))  # Dynamic weighting for utilization priority\n    gamma = 0.3  # Weighting for penalty factor\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    utilization_priority = (bins_remain_cap + avg_bin_cap) / (bins_remain_cap + item + avg_bin_cap)\n    \n    # Introduce a 'balance' factor to prioritize bins with remaining capacity close to 50% of the bin size\n    balance_factor = 1 - np.abs((bins_remain_cap - item) / (bins_remain_cap + item))\n    \n    # Forecast the future item sizes based on the remaining capacities\n    forecast_factor = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and forecasted future item sizes\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * forecast_factor * bins_remain_cap + 0.1 * balance_factor\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Dynamic prioritization based on the current state of the bins\n    max_bin_priority = np.max(priority)\n    priority[priority < max_bin_priority] *= (1 - (max_bin_priority - priority[priority < max_bin_priority]) / max_bin_priority)\n    \n    return priority\n\n# Example usage:\nitem_size = 10.0\nbins_remain_cap = np.array([5.0, 15.0, 20.0])\npriority_scores = priority_v2(item_size, bins_remain_cap)\nprint(\"Priority scores:\", priority_scores)",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and nuanced prioritization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    # Using a log-based invert function for a more nuanced approach\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))  \n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    # Using a more complex formula for a more adaptive approach\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  \n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + 1e-10), -np.inf)\n    \n    # Forecast future item sizes based on the average remaining capacity\n    forecasted_item_size = np.mean(bins_remain_cap) + np.std(bins_remain_cap)\n    future_potential_priority = bins_remain_cap / (bins_remain_cap + forecasted_item_size)\n    \n    # Adaptive weighting based on the problem's current state\n    alpha = 0.4  # weight for priority based on fit\n    beta = 0.3  # weight for priority based on utilization\n    gamma = 0.3  # weight for priority based on tight fit and future potential\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and tight fit\n    combined_priority = alpha * fit_priority + beta * utilization_priority + gamma * (priority_tight_fit * penalty_factor * future_potential_priority * bins_remain_cap)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    combined_priority = np.nan_to_num(combined_priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority, -1)\n    \n    return combined_priority",
    "response_id": 9,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 21.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 589.5445336320969,
    "mi": 76.10969148840158,
    "token_count": 326.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    An evolved priority function for the online Bin Packing Problem, incorporating adaptive weighting, \n    multiple objectives, and nuanced problem understanding.\n\n    Parameters:\n    item (float): The size of the current item to be packed.\n    bins_remain_cap (np.ndarray): The remaining capacities of the available bins.\n    alpha (float): Weight for the current item's fit priority (default: 0.4).\n    beta (float): Weight for the bin utilization priority (default: 0.3).\n    gamma (float): Weight for the bin capacity utilization priority (default: 0.3).\n\n    Returns:\n    np.ndarray: Priority scores for each bin, where higher scores indicate a better choice for the current item.\n    \"\"\"\n\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the bin capacity utilization priority, emphasizing the efficient use of bin space\n    bin_capacity_utilization = bins_remain_cap / (bins_remain_cap + item)\n    capacity_utilization_priority = np.where(bin_capacity_utilization > 0.5, 1 - bin_capacity_utilization, bin_capacity_utilization)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and capacity utilization\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * capacity_utilization_priority\n    \n    # Introduce an adaptive weighting mechanism, adjusting the priority based on problem complexities\n    complexity_factor = 1 - (np.sum(bins_remain_cap) / (len(bins_remain_cap) * np.max(bins_remain_cap)))\n    priority *= (1 + complexity_factor)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 512.2701551639823,
    "mi": 67.39044948283035,
    "token_count": 266.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response1.txt_stdout.txt",
    "code_path": "problem_iter18_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and nuanced problem understanding.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Calculate the diversity factor, promoting the use of bins with diverse capacities\n    diversity_factor = np.exp(-np.abs(bins_remain_cap - np.mean(bins_remain_cap)))\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and diversity\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * diversity_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    # Introduce adaptive weighting based on the problem state\n    if np.mean(bins_remain_cap) > item:\n        priority *= 1.1  # Favor bins with sufficient capacity\n    else:\n        priority *= 0.9  # Favor bins with tighter fits when capacity is scarce\n    \n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.856402074192266,
    "SLOC": 14.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 512.2701551639823,
    "mi": 67.39044948283035,
    "token_count": 266.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting, multiple objectives, and nuanced considerations for improved bin packing priority.\n\n    Parameters:\n    item (float): The size of the current item to be packed.\n    bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n    alpha (float): The weight assigned to the item's fit priority (default: 0.4).\n    beta (float): The weight assigned to the bin utilization priority (default: 0.3).\n    gamma (float): The weight assigned to the penalty factor (default: 0.3).\n\n    Returns:\n    np.ndarray: An array of priority scores for each bin, considering the item's fit, bin utilization, and penalty factors.\n    \"\"\"\n\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff))\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Introduce a new objective: encouraging the use of bins with more remaining capacity\n    capacity_objective = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Combine multiple objectives using adaptive weighting\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * capacity_objective\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 512.2701551639823,
    "mi": 67.39044948283035,
    "token_count": 266.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response3.txt_stdout.txt",
    "code_path": "problem_iter18_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    An advanced priority function for online Bin Packing Problem, incorporating adaptive weighting, \n    multiple objectives, and nuanced problem understanding.\n    \n    Parameters:\n    item (float): The size of the current item to be packed.\n    bins_remain_cap (np.ndarray): The remaining capacities of the bins.\n    alpha (float, optional): Weight for the fit priority. Defaults to 0.4.\n    beta (float, optional): Weight for the utilization priority. Defaults to 0.3.\n    gamma (float, optional): Weight for the penalty factor. Defaults to 0.3.\n    \n    Returns:\n    np.ndarray: Priority scores for each bin.\n    \"\"\"\n\n    # Calculate the absolute difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.log(1 + capacity_diff) if capacity_diff != 0 else 1)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Adaptive weighting based on problem state\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    if np.mean(bins_remain_cap) < item:\n        alpha += 0.1\n        beta -= 0.1\n    else:\n        alpha -= 0.1\n        beta += 0.1\n    \n    alpha = max(0, min(0.6, alpha))  # Clamp alpha between 0 and 0.6\n    beta = max(0, min(0.6, beta))  # Clamp beta between 0 and 0.6\n    gamma = 1 - alpha - beta  # Adjust gamma accordingly\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and penalty factor\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 23, in priority_v2\n    fit_priority = 1 / (1 + np.exp(capacity_diff))  # Using exponential decay for smoother prioritization\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n14\n1\n512.2701551639823\n67.39044948283035\n266\n"
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.4, beta: float = 0.3, gamma: float = 0.3) -> np.ndarray:\n    \"\"\"\n    An advanced priority function for online Bin Packing Problem, incorporating adaptive weighting, \n    multiple objectives, and nuanced problem state assessment.\n\n    Parameters:\n    item (float): The size of the current item to be packed.\n    bins_remain_cap (np.ndarray): The remaining capacities of the bins.\n    alpha (float): Weight for the fit priority (default: 0.4).\n    beta (float): Weight for the utilization priority (default: 0.3).\n    gamma (float): Weight for the penalty factor (default: 0.3).\n\n    Returns:\n    np.ndarray: Priority scores for each bin.\n    \"\"\"\n\n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + np.exp(capacity_diff))  # Using exponential decay for smoother prioritization\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Introduce a new objective: minimizing the number of bins used\n    bin_usage_priority = 1 / (1 + np.exp(bins_remain_cap / (bins_remain_cap + item)))\n    \n    # Calculate the overall priority, balancing multiple competing objectives\n    priority = alpha * fit_priority + beta * utilization_priority + gamma * penalty_factor * bins_remain_cap + (1 - alpha - beta - gamma) * bin_usage_priority\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    priority = np.nan_to_num(priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    priority = np.where(bins_remain_cap >= item, priority, -1)\n    \n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 76.14678899082571,
    "SLOC": 14.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 512.2701551639823,
    "mi": 67.39044948283035,
    "token_count": 266.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_hs2.txt_stdout.txt",
    "code_path": "problem_iter19_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float, \n    bins_remain_cap: np.ndarray, \n    alpha: float = 0.6678013264161259, \n    beta: float = 0.4183174440334584, \n    gamma: float = 0.647224654051985, \n    epsilon: float = 1.240423918062452e-07) -> np.ndarray:\n    \"\"\"\n    Combines adaptive weighting and multiple objectives for robust optimization.\n    \"\"\"\n    \n    # Calculate the difference between the remaining capacity of each bin and the item size\n    capacity_diff = np.abs(bins_remain_cap - item)\n    \n    # Invert the differences to obtain a priority score for the current item's fit\n    fit_priority = 1 / (1 + capacity_diff)\n    \n    # If the item size exceeds the remaining capacity, set the priority to 0\n    fit_priority[bins_remain_cap < item] = 0\n    \n    # Calculate the shortfall or excess capacity for each bin\n    shortfall = np.maximum(0, item - bins_remain_cap)\n    excess = np.maximum(0, bins_remain_cap - item)\n    \n    # Calculate a penalty factor for each bin based on the shortfall or excess capacity\n    penalty_factor = 1 / (1 + np.exp(shortfall)) * 1 / (1 + np.exp(excess))\n    \n    # Calculate the bin utilization, considering both the current item and future potential\n    avg_historic_size = np.mean(bins_remain_cap)  # Using mean remaining capacity as a proxy for historic item sizes\n    utilization_priority = (bins_remain_cap + avg_historic_size) / (bins_remain_cap + item + avg_historic_size)\n    \n    # Forecast the future item sizes based on the remaining capacities\n    forecast_factor = bins_remain_cap / (bins_remain_cap + item)\n    \n    # Calculate the waste (remaining capacity) if the item is added to each bin\n    waste = bins_remain_cap - item\n    \n    # Give higher priority to bins where item fits more tightly\n    delta = np.where(waste < 0, -np.inf, waste)\n    \n    # Prioritize bins with just enough capacity and higher available space\n    priority_tight_fit = np.where(delta > 0, bins_remain_cap / (delta + epsilon), -np.inf)\n    \n    # Calculate the overall priority, balancing the current item's fit, bin utilization, and tight fit\n    combined_priority = alpha * fit_priority + beta * utilization_priority + gamma * (priority_tight_fit * penalty_factor * forecast_factor * bins_remain_cap)\n    \n    # Ensure the priority scores are not NaN (e.g., due to division by zero)\n    combined_priority = np.nan_to_num(combined_priority)\n    \n    # Assign high priority to bins with enough capacity and a good fit\n    combined_priority = np.where(bins_remain_cap >= item, combined_priority, -1)\n    \n    return combined_priority",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.9760670123653865,
    "SLOC": 23.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 543.6934565366378,
    "mi": 81.92361905336358,
    "token_count": 312.0,
    "exec_success": true
  }
]