{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit inverse waste with a relative fragmentation penalty for improved packing.\"\"\"\n    small_value = 0.000664\n    fragmentation_penalty = 0.1\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins = bins_remain_cap >= item\n    if not np.any(suitable_bins):\n        return priorities\n    waste = bins_remain_cap[suitable_bins] - item\n    fit_score = 1.0 / (waste + small_value)\n    priorities[suitable_bins] = fit_score - fragmentation_penalty * (1 - (waste / bins_remain_cap[suitable_bins]))\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit inverse waste with relative fragmentation penalty for stable bin prioritization.\"\"\"\n    small_value = 0.000664\n    fragmentation_penalty = 0.05\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n    if np.any(feasible_bins):\n        priorities[feasible_bins] = 1.0 / (bins_remain_cap[feasible_bins] - item + small_value)\n        priorities[feasible_bins] -= fragmentation_penalty * (1 - (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins])\n    return priorities\n\n### Analyze & experience\n- Comparing heuristics 1st vs 2nd, both are very similar, employing best-fit inverse waste with a fragmentation penalty. The 1st uses `waste = bins_remain_cap[suitable_bins] - item` directly in the fit score, while the 2nd uses `1.0 / (bins_remain_cap - item + small_value)` which, though similar, subtly changes the weighting of the waste.  The 1st appears more efficient as it avoids redundant calculations.\n\nComparing 1st vs 3rd, the 3rd repeats the calculations of the 1st, adding an extra `if np.any(feasible_bins):` check which doesn\u2019t add value as the initial `suitable_bins` check handles that.\n\nComparing 2nd vs 3rd, the 3rd is less concise, repeating calculations. \n\nThe pattern across many pairs (e.g., 4th vs 1st, 5th vs 1st, 6th vs 3rd, 7th vs 1st, 8th vs 1st, 9th vs 1st, 10th vs 1st, 11th vs 2nd, 12th vs 2nd, 13th vs 12th, 14th vs 1st, 15th vs 2nd, 16th vs 12th, 17th vs 1st, 18th vs 17th, 19th vs 17th, 20th vs 19th) reveals a few key trends:\n\n*   **Conciseness & Redundancy:** The higher-ranked heuristics consistently avoid redundant calculations and have more compact code. The repeated `if np.any()` checks and duplicated variable assignments in the lower-ranked versions negatively impact performance and readability.\n*   **Direct Calculation vs. `np.where`:** Direct calculation (like in the 1st heuristic) is generally preferable to using `np.where` when the conditions are straightforward. `np.where` introduces overhead without providing substantial benefit in these cases.\n*   **Small Value Impact:** The `small_value` parameter is crucial for numerical stability, preventing division by zero. The choice of value (e.g., 0.000664 vs 1e-6) does not seem to dramatically affect ranking, but consistency is important.\n*   **Fragmentation Penalty:** The fragmentation penalty is applied consistently across all heuristics, and variations in its value (0.1 vs 0.05 vs 0.2) do not appear to be a primary differentiator in the ranking.\n*   **Code Duplication:** The later heuristics (17th - 20th) demonstrate significant code duplication, and the introduction of default arguments (20th) without substantial algorithmic improvement leads to lower ranking.\n\nOverall: The best heuristics (1st \u2013 3rd) prioritize concise, direct calculation of priorities based on best-fit inverse waste and fragmentation penalty. Lower-ranked heuristics introduce redundancy, unnecessary complexity, and code duplication.\n- \nOkay, here\u2019s a refined self-reflection guide for heuristic design, aiming for that $999K reward!\n\n*   **Keywords:** Feasibility, Waste Minimization, Stability, Simplicity.\n*   **Advice:** Prioritize direct calculation of waste/fit. Employ a small, *relative* fragmentation penalty (bin capacity based). Vectorize with NumPy. Rigorously test parameter sensitivity.\n*   **Avoid:** Complex prioritization logic, premature optimization, redundant code, unnecessary normalization, and absolute waste calculations.\n*   **Explanation:** Robust heuristics consistently favor simple, numerically stable solutions. While penalties can help, they\u2019re secondary to ensuring feasible, low-waste placements. Clarity trumps cleverness.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}