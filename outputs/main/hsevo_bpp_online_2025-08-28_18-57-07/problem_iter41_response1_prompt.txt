{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    small_value = 0.0001\n    fragmentation_penalty = 0.05\n    best_fit_weight = 0.6\n    first_fit_weight = 0.4\n    \n    feasible_bins = bins_remain_cap >= item\n    \n    if not np.any(feasible_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    best_fit_priorities = np.where(feasible_bins, 1.0 / (bins_remain_cap - item + small_value), 0.0)\n    first_fit_priorities = np.where(feasible_bins, 1.0, 0.0)\n    \n    priorities = best_fit_weight * best_fit_priorities + first_fit_weight * first_fit_priorities\n    \n    priorities = priorities - fragmentation_penalty * (1 - (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins])\n    \n    priorities[~feasible_bins] = 0.0\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                fragmentation_penalty: float = 0.06876889105796839, best_fit_weight: float = 0.1269509077176042,\n                first_fit_weight: float = 0.10417962921319557) -> np.ndarray:\n    \"\"\"\n    Calculates priorities for bin selection based on best-fit and first-fit strategies.\n\n    Args:\n        item: The size of the item to be placed.\n        bins_remain_cap: An array representing the remaining capacity of each bin.\n        small_value: A small value to avoid division by zero. Defaults to 0.0001.\n        fragmentation_penalty: A penalty for fragmentation. Defaults to 0.05.\n        best_fit_weight: The weight given to the best-fit priority. Defaults to 0.6.\n        first_fit_weight: The weight given to the first-fit priority. Defaults to 0.4.\n\n    Returns:\n        An array of priorities for each bin.\n    \"\"\"\n    feasible_bins = bins_remain_cap >= item\n    if not np.any(feasible_bins):\n        return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing heuristics 1st & 2nd, we observe they are identical. This suggests the ranking isn't based on code differences, but potentially performance in testing. Comparing 1st/2nd vs 3rd/4th/5th/6th/7th/8th/9th/10th, the core logic \u2013 best-fit inverse waste with fragmentation penalty \u2013 remains largely the same, differing only in minor variable names and comments.  Heuristics 11th-16th are very similar as well but a bit more concise. Heuristics 17th & 18th & 19th & 20th all look identical and include unnecessary imports (random, math, scipy, torch) which are never used, signifying a potential copy-paste artifact and reduced efficiency. Notably, the 'small_value' used to prevent division by zero varies across the heuristics (0.0001 vs 0.000664). The weightings of best-fit and first-fit strategies are only in the first and last two heuristics. Fragmentation penalty values also vary (0.05 vs 0.1). Overall, the heuristics cluster into groups with very minor differences, with later ones tending to include unnecessary imports. The highest ranked versions are more explicit in their weighting of best-fit and first-fit strategies.\n- \nOkay, let's distill actionable advice for designing superior heuristics from this extensive self-reflection. Here's a breakdown:\n\n* **Keywords:** Feasibility, Waste Minimization, Numerical Stability, Parameter Tuning.\n* **Advice:** Prioritize a clean, core \"best-fit feasible\" logic. Rigorously *experiment* with tunable parameters (weights, penalties) \u2013 don\u2019t guess. Focus on relative penalties (to bin capacity) and maintain a clear baseline.\n* **Avoid:** Complexity, Redundancy, Premature Optimization, and over-reliance on explicit waste calculations *without* demonstrated improvement.\n* **Explanation:** The consistent theme is simplicity & stability. Minor code changes often yield minimal gains; impactful improvement arises from disciplined parameter tuning *guided* by empirical testing within a solid, fundamentally sound algorithm.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}