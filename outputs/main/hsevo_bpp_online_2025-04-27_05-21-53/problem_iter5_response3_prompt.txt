{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including remaining capacity,\n    item size relative to bin size, and a penalty for creating small fragments.\n    It also incorporates a mechanism to encourage exploration of less-utilized bins\n    initially and then shift toward filling bins more completely as the packing\n    progresses (Adaptive behavior).\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n\n    Returns:\n        np.ndarray: An array containing the priority score for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio)\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins]\n\n        # 2. Encourage Exploration (Early Stage): Prioritize less-utilized bins initially.\n        #    This helps to distribute items across bins, reducing the chance of early convergence\n        #    on suboptimal solutions.  The effect diminishes as bins get filled (adaptive).\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += 0.5 * exploration_factor\n\n        # 3. Fill-Optimization (Later Stage): As packing progresses, prioritize bins that are\n        #    closer to being full. This promotes efficient space utilization.\n        almost_full_threshold = 0.1  #dynamic: can be made dependent on item size\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 1.5 #Boost almost full slightly higher\n\n        # 4. Fragmentation Penalty: Discourage creating small remaining fragments to avoid wasting space.\n        small_remainder_threshold = 0.2\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 1\n\n        # 5. Near-Perfect Fit Penalty: While fitting snugly is good, extremely close fits can sometimes\n        #    lead to more bins being used overall, so a mild penalty is applied.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 0.75\n\n        # 6. Moderate-Fit Bonus: If the item fits reasonably well without creating a tiny fragment or an almost-perfect fit,\n        # it gets a small bonus. This encourages balanced filling.\n        moderate_fit = feasible_bins & ~almost_full & ~small_remainder & ~near_perfect_fit\n        moderate_fit_threshold_low = 0.25\n        moderate_fit_threshold_high = 0.75\n        moderate_fit = moderate_fit & (remaining_capacity >= moderate_fit_threshold_low * bins_remain_cap) & (remaining_capacity <= moderate_fit_threshold_high * bins_remain_cap)\n        priorities[moderate_fit] += 0.25\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines fullness and near-overflow penalization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n    if not np.any(fits):\n        return priorities\n\n    # Fullness score: prioritize bins with smaller remaining capacity\n    remaining_capacities = bins_remain_cap - item\n    remaining_capacities[remaining_capacities < 0] = 0\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fullness_scores = np.where(bins_remain_cap > 0, (bins_remain_cap - item) / bins_remain_cap, 0)\n    fullness_scores = np.nan_to_num(fullness_scores, nan=1.0) #set nan to 1\n    priorities = np.where(fits, 1.0 - fullness_scores, -np.inf)\n\n\n    # Near-overflow penalty\n    overflow_margin = 0.05 * item\n    near_overflow = (bins_remain_cap[fits] - item) < overflow_margin\n    if np.any(near_overflow):\n        overflow_penalty = np.exp(5 * (bins_remain_cap[fits][near_overflow] - item - overflow_margin) / overflow_margin)\n        priorities[fits][near_overflow] -= overflow_penalty\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st heuristic has a lot of tunable hyper parameters that could be optimized with enough experimentation to get better packing results. Comparing (2nd) vs (19th) we see the inverse, the 2nd heuristic is too rigid and has too little parameters. Comparing (1st) vs (2nd), we see that the first heuristic has more parameters, which gives it more flexibility and adaptability, where the second one has hard coded parameters. Comparing (3rd) vs (4th), we see that 3rd is much more interpretable than the 4th heuristic. Comparing (2nd worst) vs (worst), we see the importance of including perfect fit bonus. Overall: more parameters with adaptive thresholds, bonus and penalties leads to better heuristics, also making the heuristic more interpretable is important.\n- \nHere's a refined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Adaptability, Exploration, Transparency, Multi-objective.\n*   **Advice:** Prioritize flexible designs with adaptive parameters and stochastic elements for robust exploration. Ensure interpretability.\n*   **Avoid:** Rigid, hardcoded parameters; redundant code; focusing solely on single objectives.\n*   **Explanation:** Design heuristics that dynamically adjust to problem characteristics, actively explore the solution space, and are easily understood and maintained.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}