{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                 exploration_weight: float = 0.3482592920692952,\n                 almost_full_boost: float = 2.3120758085100395,\n                 small_remainder_penalty: float = 1.048883701071912,\n                 near_perfect_fit_penalty: float = 1.5814163090985471,\n                 moderate_fit_bonus: float = 0.97011540494973,\n                 almost_full_threshold: float = 0.073331980441882,\n                 small_remainder_threshold: float = 0.02524284985386266,\n                 near_perfect_fit_threshold: float = 0.04468113355144796,\n                 moderate_fit_threshold_low: float = 0.33776523602030956,\n                 moderate_fit_threshold_high: float = 0.7785575931513438,\n                 bin_diversity_penalty: float = 0.5,\n                 utilization_exponent: float = 1.5,\n                 random_factor: float = 0.01) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, incorporating bin diversity,\n    a stochastic element, and adaptive exploration.\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n        exploration_weight (float): Weight for exploration factor.\n        almost_full_boost (float): Boost for almost full bins.\n        small_remainder_penalty (float): Penalty for small remainders.\n        near_perfect_fit_penalty (float): Penalty for near perfect fits.\n        moderate_fit_bonus (float): Bonus for moderate fits.\n        almost_full_threshold (float): Threshold for considering a bin almost full (fraction of bin size).\n        small_remainder_threshold (float): Threshold for considering a remainder small (fraction of bin size).\n        near_perfect_fit_threshold (float): Threshold for considering a fit near perfect (fraction of bin size).\n        moderate_fit_threshold_low: Lower threshold for moderate fit.\n        moderate_fit_threshold_high: Higher threshold for moderate fit.\n        bin_diversity_penalty (float): Penalty to encourage the algorithm to use bins with different fill levels.\n        utilization_exponent (float): Exponent to adjust the impact of bin utilization.\n        random_factor (float): A small random number to break ties and encourage exploration.\n\n    Returns:\n        np.ndarray: An array containing the priority score for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio) - Increased importance with exponent\n        utilization = (item / bins_remain_cap) ** utilization_exponent\n        priorities[feasible_bins] += utilization[feasible_bins]\n\n        # 2. Encourage Exploration (Adaptive): Prioritize less-utilized bins initially.\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += exploration_weight * exploration_factor\n\n        # 3. Fill-Optimization (Later Stage): Prioritize bins that are closer to being full.\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += almost_full_boost\n\n        # 4. Fragmentation Penalty: Discourage creating small remaining fragments.\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= small_remainder_penalty\n\n        # 5. Near-Perfect Fit Penalty\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= near_perfect_fit_penalty\n\n        # 6. Moderate-Fit Bonus\n        moderate_fit = feasible_bins & ~almost_full & ~small_remainder & ~near_perfect_fit\n        moderate_fit = moderate_fit & (remaining_capacity >= moderate_fit_threshold_low * bins_remain_cap) & (remaining_capacity <= moderate_fit_threshold_high * bins_remain_cap)\n        priorities[moderate_fit] += moderate_fit_bonus\n\n        # 7. Bin Diversity Penalty: Discourage packing into bins with similar fill levels.\n        #    This is calculated based on the standard deviation of the utilization of bins\n        #    that are not empty. High standard deviation means more diversity. We *subtract*\n        #    a value that is inversely proportional to the standard deviation.\n\n        filled_bins = bins_remain_cap < 1  # Assuming bin capacity is 1.0.  Adapt as needed.\n        if np.sum(filled_bins) > 1:  # Only apply if there are at least two bins filled\n            filled_bin_utilizations = 1 - bins_remain_cap[filled_bins]  # utilization is 1 - remaining cap\n            utilization_std = np.std(filled_bin_utilizations)\n            priorities[feasible_bins] -= bin_diversity_penalty / (utilization_std + 1e-6)  # Avoid division by zero\n\n        # 8. Stochastic Element: Add a small random number to break ties and explore alternatives.\n        priorities[feasible_bins] += random_factor * np.random.rand(np.sum(feasible_bins))\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                 exploration_weight: float = 0.35,\n                 almost_full_boost: float = 2.3,\n                 small_remainder_penalty: float = 1.05,\n                 near_perfect_fit_penalty: float = 1.6,\n                 moderate_fit_bonus: float = 0.95,\n                 almost_full_threshold: float = 0.07,\n                 small_remainder_threshold: float = 0.025,\n                 near_perfect_fit_threshold: float = 0.045,\n                 moderate_fit_threshold_low: float = 0.34,\n                 moderate_fit_threshold_high: float = 0.78,\n                 capacity_usage_exponent: float = 1.5,\n                 large_item_penalty: float = 0.5,\n                 large_item_threshold: float = 0.8) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including remaining capacity,\n    item size relative to bin size, and a penalty for creating small fragments.\n    It also incorporates a mechanism to encourage exploration of less-utilized bins\n    initially and then shift toward filling bins more completely as the packing\n    progresses (Adaptive behavior). This version adds a capacity usage exponent to emphasize\n    the filling of bins and a large item penalty to discourage placing very large items.\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n        exploration_weight (float): Weight for exploration factor.\n        almost_full_boost (float): Boost for almost full bins.\n        small_remainder_penalty (float): Penalty for small remainders.\n        near_perfect_fit_penalty (float): Penalty for near perfect fits.\n        moderate_fit_bonus (float): Bonus for moderate fits.\n        almost_full_threshold (float): Threshold for considering a bin almost full (fraction of bin size).\n        small_remainder_threshold (float): Threshold for considering a remainder small (fraction of bin size).\n        near_perfect_fit_threshold (float): Threshold for considering a fit near perfect (fraction of bin size).\n        moderate_fit_threshold_low: Lower threshold for moderate fit (fraction of bin size).\n        moderate_fit_threshold_high: Higher threshold for moderate fit (fraction of bin size).\n        capacity_usage_exponent (float): Exponent to emphasize filling of bins.\n        large_item_penalty (float): Penalty for placing large items.\n        large_item_threshold (float): Threshold for considering an item large (fraction of bin size).\n\n\n    Returns:\n        np.ndarray: An array containing the priority score for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio) - Emphasize filling with exponent\n        utilization = (item / bins_remain_cap) ** capacity_usage_exponent\n        priorities[feasible_bins] += utilization[feasible_bins]\n\n        # 2. Encourage Exploration (Early Stage): Prioritize less-utilized bins initially.\n        #    This helps to distribute items across bins, reducing the chance of early convergence\n        #    on suboptimal solutions.  The effect diminishes as bins get filled (adaptive).\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += exploration_weight * exploration_factor\n\n        # 3. Fill-Optimization (Later Stage): As packing progresses, prioritize bins that are\n        #    closer to being full. This promotes efficient space utilization.\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += almost_full_boost\n\n        # 4. Fragmentation Penalty: Discourage creating small remaining fragments to avoid wasting space.\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= small_remainder_penalty\n\n        # 5. Near-Perfect Fit Penalty: While fitting snugly is good, extremely close fits can sometimes\n        #    lead to more bins being used overall, so a mild penalty is applied.\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= near_perfect_fit_penalty\n\n        # 6. Moderate-Fit Bonus: If the item fits reasonably well without creating a tiny fragment or an almost-perfect fit,\n        # it gets a small bonus. This encourages balanced filling.\n        moderate_fit = feasible_bins & ~almost_full & ~small_remainder & ~near_perfect_fit\n        moderate_fit = moderate_fit & (remaining_capacity >= moderate_fit_threshold_low * bins_remain_cap) & (remaining_capacity <= moderate_fit_threshold_high * bins_remain_cap)\n        priorities[moderate_fit] += moderate_fit_bonus\n\n        # 7. Large Item Penalty: Discourage placing very large items unless necessary\n        if item > large_item_threshold:\n            priorities[feasible_bins] -= large_item_penalty\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (2nd), we see that the 1st one uses a `bin_level_threshold` and `bin_level_boost` and adapts exploration based on the average bin level, while the 2nd one introduces `bin_diversity_penalty`, `utilization_exponent`, and `random_factor`.\n*   Comparing (1st) vs (3rd), we see that the 1st one uses a `bin_level_threshold` and `bin_level_boost` and adapts exploration based on the average bin level, while the 3rd one introduces `capacity_usage_exponent`, `large_item_penalty`, and `large_item_threshold`.\n*   Comparing (2nd) vs (3rd), we see that the 2nd one introduces `bin_diversity_penalty` and `random_factor` while the 3rd one introduces `large_item_penalty` and `large_item_threshold`. Both have `capacity_usage_exponent`.\n*   Comparing (3rd) vs (4th), the code is the same.\n*   Comparing (2nd) vs (6th), both use similar parameters like `exploration_weight`, `almost_full_boost`, etc. However, the 6th function uses some imported libraries and fixed values for parameters. The 2nd one introduces `bin_diversity_penalty`, `utilization_exponent`, and `random_factor`.\n*   Comparing (1st) vs (7th), the 1st version incorporates many configurable parameters and adaptive exploration while the 7th version is highly simplified with hardcoded constants and less sophisticated exploration.\n*   Comparing (7th) vs (8th), the code is the same.\n*   Comparing (2nd worst) vs (worst), we see that the 2nd worst has adaptive parameters based on item sizes and a Gaussian boost, whereas the worst one lacks this adaptivity and boost. Both versions priorize bins considering fullness, fragmentation, and item size.\n*   Comparing (second best) vs (second worst) the second best is using constant parameters, while the second worst is using dynamic parameters.\n\nOverall: The better heuristics tend to incorporate more sophisticated mechanisms for exploration, adaptive parameter adjustments, and penalties/bonuses based on a broader range of factors (e.g., bin diversity, item size). Simpler heuristics with hardcoded constants generally perform worse. It is evident that adaptive parameter adjustments based on item sizes leads to improved packing efficiency.\n- \nOkay, let's redefine \"Current Self-Reflection\" to boost heuristic design:\n\n*   **Keywords:** Adaptive, dynamic, balanced exploration/exploitation, diversity, tunable weights, interpretable, random components.\n\n*   **Advice:** Design heuristics that adapt to problem characteristics (item sizes, bin fill levels). Use tunable weights to balance competing objectives (feasibility, utilization, fragmentation). Incorporate randomness for exploration.\n\n*   **Avoid:** Hardcoded parameters, premature convergence, redundancy.\n\n*   **Explanation:** Focus on adaptability and balanced strategies. Employ tunable parameters for flexibility and interpretability. Prioritize exploration to avoid local optima while ensuring efficient resource utilization.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}