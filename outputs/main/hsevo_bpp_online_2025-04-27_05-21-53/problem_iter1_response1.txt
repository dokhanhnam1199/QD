```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    This version incorporates a few Einstein-inspired heuristics:

    1. **Space-Time Curvature Analogy:** Smaller remaining capacity bins "attract" smaller items more strongly.  This is modeled by a higher priority for bins where the item fits relatively snugly (but still fits).

    2. **Principle of Least Action (Energy Minimization):** We prefer filling bins as completely as possible to minimize wasted space (potential energy). This is implemented by rewarding bins with remaining capacity close to the item size.

    3. **Relativistic Effect (Size Dilation):** As the item size approaches the bin capacity, the relative "difficulty" of packing increases dramatically. We model this by a term that penalizes near-overflows, especially if many near-full bins exist. This also emulates length contraction when an item is placed into bins and a contraction term will be calculated to avoid packing it into those bins.

    4. **Avoid Extreme Packing Densities:** If the bins are nearly full, apply a scaling factor to priorities based on the average fullness ratio. We prioritize dispersing the load across bins.
    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    # First, handle cases where item doesn't fit.
    fits = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    priorities[~fits] = -np.inf  # Very low priority for bins too small.
    if not np.any(fits):
        return priorities

    # Calculate a "snug fit" score: Reward bins where the item fits relatively well.
    snug_fit_score = (bins_remain_cap[fits] - item) / bins_remain_cap[fits]
    snug_fit_score = 1.0 - snug_fit_score  # Higher score for better fit (closer to item size)
    snug_fit_score = np.clip(snug_fit_score, 0.0, 1.0)  # Ensure values are within bounds
    priorities[fits] += snug_fit_score

    # Energy minimization: Prefer bins that get filled up nicely
    remaining_space = bins_remain_cap[fits] - item
    energy_score = np.exp(-np.abs(remaining_space) / (item + 1e-6))
    priorities[fits] += energy_score

    # Relativistic penalty for near-overflows.
    overflow_margin = 0.05 * item  # Define a small margin near overflow

    near_overflow = (bins_remain_cap[fits] - item) < overflow_margin
    if np.any(near_overflow):
        overflow_penalty = np.exp(5 * (bins_remain_cap[fits][near_overflow] - item - overflow_margin) / overflow_margin)
        priorities[fits][near_overflow] -= overflow_penalty

    #Contraction term to avoid packing item to a nearly full bin
    contraction_term = np.exp(5 * (item-bins_remain_cap[fits]))
    priorities[fits] -= contraction_term

    # Avoid Extreme Densities scaling factor
    avg_fullness = np.mean((np.sum(bins_remain_cap) - bins_remain_cap) / np.sum(bins_remain_cap))
    density_scale = 1.0 - np.clip(avg_fullness, 0.0, 0.9)  # Apply the scaling based on the range, can be between 0.1 to 1

    priorities[fits] *= density_scale # Scale priorities

    return priorities
```
