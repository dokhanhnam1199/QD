{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates a few heuristics:\n\n    1.  **Feasibility:**  It strongly penalizes bins that are too small to hold the item.\n        This avoids wasting time calculating priorities for impossible placements.\n\n    2.  **Capacity Utilization:**  Bins closer to being full (after placing the item)\n        are preferred.  This encourages filling bins completely.  We use a scaled\n        exponential function to capture this effect - small changes near full\n        capacity yield large priority changes.\n\n    3.  **Fragmentation Avoidance:** Bins that have too much remaining capacity\n        after adding the item are also penalized to avoid highly fragmented bins.\n        The penalty scales with the amount of wasted space.\n        We only apply this if a \"reasonable\" number of feasible bins exist.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Feasibility Check and Initial Penalty\n    feasible = bins_remain_cap >= item\n    priorities[~feasible] = -np.inf  # Very low priority if not feasible\n\n    feasible_bins_count = np.sum(feasible)\n\n    if feasible_bins_count > 0:  # Only compute if there are feasible bins\n\n        remaining_after_placement = bins_remain_cap[feasible] - item\n\n        # Capacity Utilization - Exponentially Prefer Near-Full Bins\n        capacity_utilization = np.exp(-5 * remaining_after_placement / np.max(bins_remain_cap)) # Scale the penalty\n\n        priorities[feasible] = capacity_utilization\n\n\n        # Fragmentation Avoidance (applied only if enough choices exist to avoid being stuck)\n        if feasible_bins_count > 2 :  # Threshold adjusted for different size datasets\n            waste_penalty = np.zeros_like(remaining_after_placement)\n            large_waste = remaining_after_placement > 0.5 * np.max(bins_remain_cap)\n            waste_penalty[large_waste] = -0.1 * remaining_after_placement[large_waste] # Penalize large waste\n\n            priorities[feasible] += waste_penalty\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            priorities[i] = (cap - item) / cap  # Remaining capacity after packing, relative to original capacity. Higher is better.\n        else:\n            priorities[i] = -1  # Impossible to pack\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see 1st uses a heliocentric model analogy, prioritizing bins closer in capacity to the item, while 20th prioritizes minimizing wasted space directly and uses a random factor. 1st normalizes differences and scales priority based on percentage filled, while 20th squares the remaining capacity.\n\nComparing (2nd) vs (19th), 2nd prioritizes bins with the smallest remaining capacity after packing and uses Newton's law of cooling analogy, while 19th prioritizes bins that can fit the item snugly by squaring the remaining space and adds a random factor. 2nd adds a bias to partially filled bins, and sets infeasible bins to negative infinity while 19th returns the bin capacities directly\n\nComparing (3rd) vs (18th), 3rd calculates fullness scores and prioritizes viable bins, discouraging almost-full bins, while 18th prioritizes bins that fit snugly, squaring the wasted space and adding a random factor. 3rd uses np.where to assign priorities and handles potential division by zero, while 18th returns bin capacities if no bins fit.\n\nComparing (4th) vs (17th), 4th incorporates feasibility checks, capacity utilization with exponential preference, and fragmentation avoidance, while 17th considers waste, fill level, and avoidance of near-full bins, normalizing waste and using exponentials for fill level priority. 4th penalizes fragmentation only if enough feasible bins exist. 17th uses a combination of normalized waste, fill level priority and fullness penalty, with weighting.\n\nComparing (5th) vs (16th), 5th duplicates the code from the 4th heuristic, which may be problematic since duplicate functions are redundant. 16th prioritizes bins that are \"almost full\" after adding item but penalize near-perfect fits and penalize bins that would have too little remaining space.\n\nComparing (6th) vs (15th), 6th calculates wasted space and adds a bonus for relatively full bins using a logarithm while 15th prioritizes bins large enough to accomodate item, prioritize \"almost full\" bins and penalize near-perfect fits and bins that would have too little remaining space.\n\nComparing (7th) vs (14th), 7th and 14th both include relativistic near-overflow penalization, however 7th has a perfect fit huge boost, while 14th has Space-Time Curvature Analogy, Principle of Least Action and Avoid Extreme Packing Densities\n\nComparing (8th) vs (13th), 8th prioritizes bins with smaller wasted space and gives higher priority to almost full bins after adding item while 13th also includes relativistic near-overflow penalization and Avoid Extreme Packing Densities\n\nComparing (9th) vs (12th), 9th duplicates the code from the 5th heuristic, which may be problematic since duplicate functions are redundant. 12th has Remaining capacity after packing relative to original capacity\n\nComparing (10th) vs (11th), 10th includes a perfect fit huge boost, while 11th has Remaining capacity after packing relative to original capacity\n\nComparing (second worst) vs (worst), we see 11th has Remaining capacity after packing relative to original capacity whereas 12th duplicates the code from the 11th heuristic, which may be problematic since duplicate functions are redundant.\n\nOverall: The better heuristics incorporate feasibility checks, capacity utilization, and fragmentation avoidance, often using mathematical functions like exponentials and logarithms to prioritize near-full bins while penalizing excessive waste or near-overflows. The best approaches also incorporate scaling factors or biases to encourage complete filling and avoid creating bins that can only hold very small items. Poorer performing heuristics have less sophisticated logic that do not account for edge cases and duplicate code.\n- \nOkay, let's redefine \"Current Self-Reflection\" to make it more effective for heuristic design, focusing on avoiding pitfalls and leading to better heuristics.\n\n*   **Keywords:** Adaptive Learning, Outcome Analysis, Solution Diversity, Algorithmic Bias.\n*   **Advice:** Analyze heuristic *performance* across diverse problem instances and parameter settings. Quantify solution *quality*, not just feasibility. Explicitly track *algorithmic bias* and design heuristics to mitigate it. Explore diverse solution pathways and avoid premature convergence.\n*   **Avoid:** Focusing solely on mathematical models without empirical validation. Ignoring the impact of parameter tuning on heuristic performance. Neglecting the exploration of alternative solution generation strategies.\n*   **Explanation:** Shift from static rules to adaptive learning from results. Validate and prevent bias. Aim for more diverse and better solutions.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}