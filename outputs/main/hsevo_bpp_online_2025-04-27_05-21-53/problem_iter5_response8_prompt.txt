{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including fullness,\n    fragmentation avoidance, and a dynamic adjustment based on item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Prioritize bins that will be nearly full after packing.\n        almost_full_threshold = 0.15  # Slightly wider range\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        # 2. Discourage very small remainders (fragmentation).  Slightly more aggressive.\n        small_remainder_threshold = 0.25  # Increased threshold\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 5\n\n        # 3. Penalize near-perfect fits, but less severely if the item is large.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 3  # Slightly reduced penalty\n\n        # 4. Base priority on utilization, scaled by item size.  Larger items get more influence.\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (0.5 + item)  # Scale by item size\n\n        # 5. Adaptive adjustment:  Favor bins whose remaining capacity is close to the item size.\n        capacity_difference = np.abs(bins_remain_cap - item)\n        priority_boost = np.exp(-capacity_difference / np.mean(bins_remain_cap[feasible_bins]))  # Gaussian-like boost\n        priorities[feasible_bins] += priority_boost[feasible_bins] * 2\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on a combination of factors including fill percentage,\n    avoidance of small remainders, and a slight preference for bins that are\n    already reasonably full.  Uses a more adaptive approach than v1.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # Prioritize bins close to full, but with a more adaptive threshold\n        # The threshold depends on the item size, so big items prefer more empty bins\n        almost_full_threshold = 0.1 + 0.1 * (item) # adaptive\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        #Penalize Near-Perfect Fit, but less aggressively than before\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 2  # Reduced penalty\n\n        #Penalize small remainders to avoid fragmentation, but adaptive to item size\n        small_remainder_threshold = 0.2 - 0.05 * (item) # adaptive\n        small_remainder_threshold = max(0.05, small_remainder_threshold) # ensure its positive\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 3 # increased penalty\n\n        # Add a base priority based on how much space is used and current bin usage\n        # This encourages filling partially filled bins\n        utilization = item / bins_remain_cap\n        current_fill = (bins_remain_cap - remaining_capacity) / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (1 + current_fill[feasible_bins]) # favor more filled bins\n        \n        # Add a small random component to break ties and explore diverse solutions\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st heuristic has a lot of tunable hyper parameters that could be optimized with enough experimentation to get better packing results. Comparing (2nd) vs (19th) we see the inverse, the 2nd heuristic is too rigid and has too little parameters. Comparing (1st) vs (2nd), we see that the first heuristic has more parameters, which gives it more flexibility and adaptability, where the second one has hard coded parameters. Comparing (3rd) vs (4th), we see that 3rd is much more interpretable than the 4th heuristic. Comparing (2nd worst) vs (worst), we see the importance of including perfect fit bonus. Overall: more parameters with adaptive thresholds, bonus and penalties leads to better heuristics, also making the heuristic more interpretable is important.\n- \nHere's a refined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Adaptability, Exploration, Transparency, Multi-objective.\n*   **Advice:** Prioritize flexible designs with adaptive parameters and stochastic elements for robust exploration. Ensure interpretability.\n*   **Avoid:** Rigid, hardcoded parameters; redundant code; focusing solely on single objectives.\n*   **Explanation:** Design heuristics that dynamically adjust to problem characteristics, actively explore the solution space, and are easily understood and maintained.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}