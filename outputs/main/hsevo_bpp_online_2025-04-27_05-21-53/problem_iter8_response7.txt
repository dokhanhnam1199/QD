```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive heuristic combining fullness, overflow penalty, & exploration."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible = bins_remain_cap >= item
    priorities[~feasible] = -np.inf

    if np.any(feasible):
        remaining_after = bins_remain_cap[feasible] - item
        max_cap = np.max(bins_remain_cap)

        # Capacity utilization score
        capacity_utilization = np.exp(-5 * remaining_after / max_cap)
        priorities[feasible] = capacity_utilization

        # Adaptive near-overflow penalization
        almost_full_threshold = 0.1 + 0.05 * item
        almost_full = remaining_after < almost_full_threshold * max_cap
        priorities[feasible][almost_full] -= 2 * (almost_full_threshold * max_cap - remaining_after[almost_full]) / max_cap

        # Adaptive small remainder penalization
        small_remainder_threshold = 0.2 - 0.025 * item
        small_remainder_threshold = max(0.05, small_remainder_threshold)
        small_remainder = (remaining_after > 0) & (remaining_after <= small_remainder_threshold * max_cap)
        priorities[feasible][small_remainder] -= 1.5

        # Perfect fit bonus
        perfect_fit_threshold = 0.01 * max_cap
        perfect_fit = remaining_after <= perfect_fit_threshold
        priorities[feasible][perfect_fit] += 1

        # Exploration using a scaled random component
        exploration_weight = 0.05
        priorities[feasible] += np.random.rand(np.sum(feasible)) * exploration_weight

    return priorities
```
