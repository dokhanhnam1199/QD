{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                 exploration_weight: float = 0.3482592920692952,\n                 almost_full_boost: float = 2.3120758085100395,\n                 small_remainder_penalty: float = 1.048883701071912,\n                 near_perfect_fit_penalty: float = 1.5814163090985471,\n                 moderate_fit_bonus: float = 0.97011540494973,\n                 almost_full_threshold: float = 0.073331980441882,\n                 small_remainder_threshold: float = 0.02524284985386266,\n                 near_perfect_fit_threshold: float = 0.04468113355144796,\n                 moderate_fit_threshold_low: float = 0.33776523602030956,\n                 moderate_fit_threshold_high: float = 0.7785575931513438) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including remaining capacity,\n    item size relative to bin size, and a penalty for creating small fragments.\n    It also incorporates a mechanism to encourage exploration of less-utilized bins\n    initially and then shift toward filling bins more completely as the packing\n    progresses (Adaptive behavior).\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n        exploration_weight (float): Weight for exploration factor.\n        almost_full_boost (float): Boost for almost full bins.\n        small_remainder_penalty (float): Penalty for small remainders.\n        near_perfect_fit_penalty (float): Penalty for near perfect fits.\n        moderate_fit_bonus (float): Bonus for moderate fits.\n        almost_full_threshold (float): Threshold for considering a bin almost full (fraction of bin size).\n        small_remainder_threshold (float): Threshold for considering a remainder small (fraction of bin size).\n        near_perfect_fit_threshold (float): Threshold for considering a fit near perfect (fraction of bin size).\n        moderate_fit_threshold_low (float): Lower threshold for moderate fit (fraction of bin size).\n        moderate_fit_threshold_high (float): Higher threshold for moderate fit (fraction of bin size).\n\n    Returns:\n        np.ndarray: An array containing the priority score for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio)\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins]\n\n        # 2. Encourage Exploration (Early Stage): Prioritize less-utilized bins initially.\n        #    This helps to distribute items across bins, reducing the chance of early convergence\n        #    on suboptimal solutions.  The effect diminishes as bins get filled (adaptive).\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += exploration_weight * exploration_factor\n\n        # 3. Fill-Optimization (Later Stage): As packing progresses, prioritize bins that are\n        #    closer to being full. This promotes efficient space utilization.\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += almost_full_boost #Boost almost full slightly higher\n\n        # 4. Fragmentation Penalty: Discourage creating small remaining fragments to avoid wasting space.\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= small_remainder_penalty\n\n        # 5. Near-Perfect Fit Penalty: While fitting snugly is good, extremely close fits can sometimes\n        #    lead to more bins being used overall, so a mild penalty is applied.\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= near_perfect_fit_penalty\n\n        # 6. Moderate-Fit Bonus: If the item fits reasonably well without creating a tiny fragment or an almost-perfect fit,\n        # it gets a small bonus. This encourages balanced filling.\n        moderate_fit = feasible_bins & ~almost_full & ~small_remainder & ~near_perfect_fit\n        moderate_fit = moderate_fit & (remaining_capacity >= moderate_fit_threshold_low * bins_remain_cap) & (remaining_capacity <= moderate_fit_threshold_high * bins_remain_cap)\n        priorities[moderate_fit] += moderate_fit_bonus\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including remaining capacity,\n    item size relative to bin size, and a penalty for creating small fragments.\n    It also incorporates a mechanism to encourage exploration of less-utilized bins\n    initially and then shift toward filling bins more completely as the packing\n    progresses (Adaptive behavior).\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n\n    Returns:\n        np.ndarray: An array containing the priority score for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio)\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins]\n\n        # 2. Encourage Exploration (Early Stage): Prioritize less-utilized bins initially.\n        #    This helps to distribute items across bins, reducing the chance of early convergence\n        #    on suboptimal solutions.  The effect diminishes as bins get filled (adaptive).\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += 0.5 * exploration_factor\n\n        # 3. Fill-Optimization (Later Stage): As packing progresses, prioritize bins that are\n        #    closer to being full. This promotes efficient space utilization.\n        almost_full_threshold = 0.1  #dynamic: can be made dependent on item size\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 1.5 #Boost almost full slightly higher\n\n        # 4. Fragmentation Penalty: Discourage creating small remaining fragments to avoid wasting space.\n        small_remainder_threshold = 0.2\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 1\n\n        # 5. Near-Perfect Fit Penalty: While fitting snugly is good, extremely close fits can sometimes\n        #    lead to more bins being used overall, so a mild penalty is applied.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 0.75\n\n        # 6. Moderate-Fit Bonus: If the item fits reasonably well without creating a tiny fragment or an almost-perfect fit,\n        # it gets a small bonus. This encourages balanced filling.\n        moderate_fit = feasible_bins & ~almost_full & ~small_remainder & ~near_perfect_fit\n        moderate_fit_threshold_low = 0.25\n        moderate_fit_threshold_high = 0.75\n        moderate_fit = moderate_fit & (remaining_capacity >= moderate_fit_threshold_low * bins_remain_cap) & (remaining_capacity <= moderate_fit_threshold_high * bins_remain_cap)\n        priorities[moderate_fit] += 0.25\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including remaining capacity,\n    item size relative to bin size, and a penalty for creating small fragments.\n    It also incorporates a mechanism to encourage exploration of less-utilized bins\n    initially and then shift toward filling bins more completely as the packing\n    progresses (Adaptive behavior).\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n\n    Returns:\n        np.ndarray: An array containing the priority score for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio)\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins]\n\n        # 2. Encourage Exploration (Early Stage): Prioritize less-utilized bins initially.\n        #    This helps to distribute items across bins, reducing the chance of early convergence\n        #    on suboptimal solutions.  The effect diminishes as bins get filled (adaptive).\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += 0.5 * exploration_factor\n\n        # 3. Fill-Optimization (Later Stage): As packing progresses, prioritize bins that are\n        #    closer to being full. This promotes efficient space utilization.\n        almost_full_threshold = 0.1  #dynamic: can be made dependent on item size\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 1.5 #Boost almost full slightly higher\n\n        # 4. Fragmentation Penalty: Discourage creating small remaining fragments to avoid wasting space.\n        small_remainder_threshold = 0.2\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 1\n\n        # 5. Near-Perfect Fit Penalty: While fitting snugly is good, extremely close fits can sometimes\n        #    lead to more bins being used overall, so a mild penalty is applied.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 0.75\n\n        # 6. Moderate-Fit Bonus: If the item fits reasonably well without creating a tiny fragment or an almost-perfect fit,\n        # it gets a small bonus. This encourages balanced filling.\n        moderate_fit = feasible_bins & ~almost_full & ~small_remainder & ~near_perfect_fit\n        moderate_fit_threshold_low = 0.25\n        moderate_fit_threshold_high = 0.75\n        moderate_fit = moderate_fit & (remaining_capacity >= moderate_fit_threshold_low * bins_remain_cap) & (remaining_capacity <= moderate_fit_threshold_high * bins_remain_cap)\n        priorities[moderate_fit] += 0.25\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity utilization and relativistic near-overflow penalization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible = bins_remain_cap >= item\n    priorities[~feasible] = -np.inf\n\n    if np.any(feasible):\n        remaining_after = bins_remain_cap[feasible] - item\n        max_cap = np.max(bins_remain_cap)\n\n        # Capacity utilization: prefer near-full\n        capacity_utilization = np.exp(-5 * remaining_after / max_cap)\n        priorities[feasible] = capacity_utilization\n\n        # Relativistic near-overflow penalization\n        almost_full = remaining_after < 0.1 * max_cap\n        priorities[feasible][almost_full] -= 2*(0.1 * max_cap - remaining_after[almost_full]) / max_cap\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fullness and near-overflow penalization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n    if not np.any(fits):\n        return priorities\n\n    # Fullness score: prioritize bins with smaller remaining capacity\n    remaining_capacities = bins_remain_cap - item\n    remaining_capacities[remaining_capacities < 0] = 0\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fullness_scores = np.where(bins_remain_cap > 0, (bins_remain_cap - item) / bins_remain_cap, 0)\n    fullness_scores = np.nan_to_num(fullness_scores, nan=1.0) #set nan to 1\n    priorities = np.where(fits, 1.0 - fullness_scores, -np.inf)\n\n\n    # Near-overflow penalty\n    overflow_margin = 0.05 * item\n    near_overflow = (bins_remain_cap[fits] - item) < overflow_margin\n    if np.any(near_overflow):\n        overflow_penalty = np.exp(5 * (bins_remain_cap[fits][near_overflow] - item - overflow_margin) / overflow_margin)\n        priorities[fits][near_overflow] -= overflow_penalty\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fullness and near-overflow penalization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n    if not np.any(fits):\n        return priorities\n\n    # Fullness score: prioritize bins with smaller remaining capacity\n    remaining_capacities = bins_remain_cap - item\n    remaining_capacities[remaining_capacities < 0] = 0\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fullness_scores = np.where(bins_remain_cap > 0, (bins_remain_cap - item) / bins_remain_cap, 0)\n    fullness_scores = np.nan_to_num(fullness_scores, nan=1.0) #set nan to 1\n    priorities = np.where(fits, 1.0 - fullness_scores, -np.inf)\n\n\n    # Near-overflow penalty\n    overflow_margin = 0.05 * item\n    near_overflow = (bins_remain_cap[fits] - item) < overflow_margin\n    if np.any(near_overflow):\n        overflow_penalty = np.exp(5 * (bins_remain_cap[fits][near_overflow] - item - overflow_margin) / overflow_margin)\n        priorities[fits][near_overflow] -= overflow_penalty\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on remaining capacity, perfect fit, and fragmentation.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(valid_bins):\n        remaining_capacity = bins_remain_cap[valid_bins] - item\n        \n        # Prioritize smaller remaining capacity and avoid fragmentation.\n        priorities[valid_bins] = (1 / (remaining_capacity + 1e-6)) - (10 * (remaining_capacity < 0.1))\n        \n        # Boost perfect fits.\n        perfect_fit = np.abs(remaining_capacity) < 1e-6\n        if np.any(perfect_fit):\n            priorities[valid_bins][perfect_fit] += 100\n            \n        # Relativistic near-overflow penalization\n        almost_full = (remaining_capacity > 0) & (remaining_capacity < 0.2)\n        if np.any(almost_full):\n             priorities[valid_bins][almost_full] -= 50 #Moderate Penalty\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on remaining capacity, perfect fit, and fragmentation.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(valid_bins):\n        remaining_capacity = bins_remain_cap[valid_bins] - item\n        \n        # Prioritize smaller remaining capacity and avoid fragmentation.\n        priorities[valid_bins] = (1 / (remaining_capacity + 1e-6)) - (10 * (remaining_capacity < 0.1))\n        \n        # Boost perfect fits.\n        perfect_fit = np.abs(remaining_capacity) < 1e-6\n        if np.any(perfect_fit):\n            priorities[valid_bins][perfect_fit] += 100\n            \n        # Relativistic near-overflow penalization\n        almost_full = (remaining_capacity > 0) & (remaining_capacity < 0.2)\n        if np.any(almost_full):\n             priorities[valid_bins][almost_full] -= 50 #Moderate Penalty\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on remaining capacity, perfect fit, and fragmentation.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(valid_bins):\n        remaining_capacity = bins_remain_cap[valid_bins] - item\n        \n        # Prioritize smaller remaining capacity and avoid fragmentation.\n        priorities[valid_bins] = (1 / (remaining_capacity + 1e-6)) - (10 * (remaining_capacity < 0.1))\n        \n        # Boost perfect fits.\n        perfect_fit = np.abs(remaining_capacity) < 1e-6\n        if np.any(perfect_fit):\n            priorities[valid_bins][perfect_fit] += 100\n            \n        # Relativistic near-overflow penalization\n        almost_full = (remaining_capacity > 0) & (remaining_capacity < 0.2)\n        if np.any(almost_full):\n             priorities[valid_bins][almost_full] -= 50 #Moderate Penalty\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of v0 and v1.\n    Prioritizes snug fits, avoids near overflows, and encourages full bins.\n    \"\"\"\n    fits = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(fits):\n        return priorities\n\n    # Snug fit score (v1)\n    snug_fit_score = (bins_remain_cap[fits] - item) / bins_remain_cap[fits]\n    snug_fit_score = 1.0 - snug_fit_score\n    snug_fit_score = np.clip(snug_fit_score, 0.0, 1.0)\n    priorities[fits] += snug_fit_score\n\n    # Remaining capacity priority (v0-inspired, more direct)\n    remaining_capacity = bins_remain_cap[fits] - item\n    priorities[fits] += (1 / (remaining_capacity + 1e-6))\n\n    # Near overflow penalty (v1)\n    overflow_margin = 0.05 * item\n    near_overflow = (bins_remain_cap[fits] - item) < overflow_margin\n    if np.any(near_overflow):\n        overflow_penalty = np.exp(5 * (bins_remain_cap[fits][near_overflow] - item - overflow_margin) / overflow_margin)\n        priorities[fits][near_overflow] -= overflow_penalty\n\n    # Perfect fit bonus (v0)\n    perfect_fit = np.abs(remaining_capacity) < 1e-6\n    if np.any(perfect_fit):\n        priorities[fits][perfect_fit] += 100\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including fullness,\n    fragmentation avoidance, and a dynamic adjustment based on item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Prioritize bins that will be nearly full after packing.\n        almost_full_threshold = 0.15  # Slightly wider range\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        # 2. Discourage very small remainders (fragmentation).  Slightly more aggressive.\n        small_remainder_threshold = 0.25  # Increased threshold\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 5\n\n        # 3. Penalize near-perfect fits, but less severely if the item is large.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 3  # Slightly reduced penalty\n\n        # 4. Base priority on utilization, scaled by item size.  Larger items get more influence.\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (0.5 + item)  # Scale by item size\n\n        # 5. Adaptive adjustment:  Favor bins whose remaining capacity is close to the item size.\n        capacity_difference = np.abs(bins_remain_cap - item)\n        priority_boost = np.exp(-capacity_difference / np.mean(bins_remain_cap[feasible_bins]))  # Gaussian-like boost\n        priorities[feasible_bins] += priority_boost[feasible_bins] * 2\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including fullness,\n    fragmentation avoidance, and a dynamic adjustment based on item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Prioritize bins that will be nearly full after packing.\n        almost_full_threshold = 0.15  # Slightly wider range\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        # 2. Discourage very small remainders (fragmentation).  Slightly more aggressive.\n        small_remainder_threshold = 0.25  # Increased threshold\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 5\n\n        # 3. Penalize near-perfect fits, but less severely if the item is large.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 3  # Slightly reduced penalty\n\n        # 4. Base priority on utilization, scaled by item size.  Larger items get more influence.\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (0.5 + item)  # Scale by item size\n\n        # 5. Adaptive adjustment:  Favor bins whose remaining capacity is close to the item size.\n        capacity_difference = np.abs(bins_remain_cap - item)\n        priority_boost = np.exp(-capacity_difference / np.mean(bins_remain_cap[feasible_bins]))  # Gaussian-like boost\n        priorities[feasible_bins] += priority_boost[feasible_bins] * 2\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including fullness,\n    fragmentation avoidance, and a dynamic adjustment based on item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Prioritize bins that will be nearly full after packing.\n        almost_full_threshold = 0.15  # Slightly wider range\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        # 2. Discourage very small remainders (fragmentation).  Slightly more aggressive.\n        small_remainder_threshold = 0.25  # Increased threshold\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 5\n\n        # 3. Penalize near-perfect fits, but less severely if the item is large.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 3  # Slightly reduced penalty\n\n        # 4. Base priority on utilization, scaled by item size.  Larger items get more influence.\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (0.5 + item)  # Scale by item size\n\n        # 5. Adaptive adjustment:  Favor bins whose remaining capacity is close to the item size.\n        capacity_difference = np.abs(bins_remain_cap - item)\n        priority_boost = np.exp(-capacity_difference / np.mean(bins_remain_cap[feasible_bins]))  # Gaussian-like boost\n        priorities[feasible_bins] += priority_boost[feasible_bins] * 2\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, including fullness,\n    fragmentation avoidance, and a dynamic adjustment based on item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Prioritize bins that will be nearly full after packing.\n        almost_full_threshold = 0.15  # Slightly wider range\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        # 2. Discourage very small remainders (fragmentation).  Slightly more aggressive.\n        small_remainder_threshold = 0.25  # Increased threshold\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 5\n\n        # 3. Penalize near-perfect fits, but less severely if the item is large.\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 3  # Slightly reduced penalty\n\n        # 4. Base priority on utilization, scaled by item size.  Larger items get more influence.\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (0.5 + item)  # Scale by item size\n\n        # 5. Adaptive adjustment:  Favor bins whose remaining capacity is close to the item size.\n        capacity_difference = np.abs(bins_remain_cap - item)\n        priority_boost = np.exp(-capacity_difference / np.mean(bins_remain_cap[feasible_bins]))  # Gaussian-like boost\n        priorities[feasible_bins] += priority_boost[feasible_bins] * 2\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a combination of factors including fill percentage,\n    avoidance of small remainders, and a slight preference for bins that are\n    already reasonably full.  Uses a more adaptive approach than v1.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # Prioritize bins close to full, but with a more adaptive threshold\n        # The threshold depends on the item size, so big items prefer more empty bins\n        almost_full_threshold = 0.1 + 0.1 * (item) # adaptive\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        #Penalize Near-Perfect Fit, but less aggressively than before\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 2  # Reduced penalty\n\n        #Penalize small remainders to avoid fragmentation, but adaptive to item size\n        small_remainder_threshold = 0.2 - 0.05 * (item) # adaptive\n        small_remainder_threshold = max(0.05, small_remainder_threshold) # ensure its positive\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 3 # increased penalty\n\n        # Add a base priority based on how much space is used and current bin usage\n        # This encourages filling partially filled bins\n        utilization = item / bins_remain_cap\n        current_fill = (bins_remain_cap - remaining_capacity) / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (1 + current_fill[feasible_bins]) # favor more filled bins\n        \n        # Add a small random component to break ties and explore diverse solutions\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a combination of factors including fill percentage,\n    avoidance of small remainders, and a slight preference for bins that are\n    already reasonably full.  Uses a more adaptive approach than v1.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # Prioritize bins close to full, but with a more adaptive threshold\n        # The threshold depends on the item size, so big items prefer more empty bins\n        almost_full_threshold = 0.1 + 0.1 * (item) # adaptive\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        #Penalize Near-Perfect Fit, but less aggressively than before\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 2  # Reduced penalty\n\n        #Penalize small remainders to avoid fragmentation, but adaptive to item size\n        small_remainder_threshold = 0.2 - 0.05 * (item) # adaptive\n        small_remainder_threshold = max(0.05, small_remainder_threshold) # ensure its positive\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 3 # increased penalty\n\n        # Add a base priority based on how much space is used and current bin usage\n        # This encourages filling partially filled bins\n        utilization = item / bins_remain_cap\n        current_fill = (bins_remain_cap - remaining_capacity) / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (1 + current_fill[feasible_bins]) # favor more filled bins\n        \n        # Add a small random component to break ties and explore diverse solutions\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a combination of factors including fill percentage,\n    avoidance of small remainders, and a slight preference for bins that are\n    already reasonably full.  Uses a more adaptive approach than v1.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # Prioritize bins close to full, but with a more adaptive threshold\n        # The threshold depends on the item size, so big items prefer more empty bins\n        almost_full_threshold = 0.1 + 0.1 * (item) # adaptive\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        #Penalize Near-Perfect Fit, but less aggressively than before\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 2  # Reduced penalty\n\n        #Penalize small remainders to avoid fragmentation, but adaptive to item size\n        small_remainder_threshold = 0.2 - 0.05 * (item) # adaptive\n        small_remainder_threshold = max(0.05, small_remainder_threshold) # ensure its positive\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 3 # increased penalty\n\n        # Add a base priority based on how much space is used and current bin usage\n        # This encourages filling partially filled bins\n        utilization = item / bins_remain_cap\n        current_fill = (bins_remain_cap - remaining_capacity) / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (1 + current_fill[feasible_bins]) # favor more filled bins\n        \n        # Add a small random component to break ties and explore diverse solutions\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a combination of factors including fill percentage,\n    avoidance of small remainders, and a slight preference for bins that are\n    already reasonably full.  Uses a more adaptive approach than v1.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # Prioritize bins close to full, but with a more adaptive threshold\n        # The threshold depends on the item size, so big items prefer more empty bins\n        almost_full_threshold = 0.1 + 0.1 * (item) # adaptive\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15  # Increased priority\n\n        #Penalize Near-Perfect Fit, but less aggressively than before\n        near_perfect_fit_threshold = 0.01\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 2  # Reduced penalty\n\n        #Penalize small remainders to avoid fragmentation, but adaptive to item size\n        small_remainder_threshold = 0.2 - 0.05 * (item) # adaptive\n        small_remainder_threshold = max(0.05, small_remainder_threshold) # ensure its positive\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 3 # increased penalty\n\n        # Add a base priority based on how much space is used and current bin usage\n        # This encourages filling partially filled bins\n        utilization = item / bins_remain_cap\n        current_fill = (bins_remain_cap - remaining_capacity) / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (1 + current_fill[feasible_bins]) # favor more filled bins\n        \n        # Add a small random component to break ties and explore diverse solutions\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins considering multiple factors:\n    - Remaining capacity relative to item size.\n    - Potential for creating balanced bin utilization.\n    - Penalties for creating very small remainders or near-perfect fits.\n    - Encourages packing into bins that are already somewhat filled.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Prioritize bins where the item fills a significant portion of the bin.\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += 2 * utilization[feasible_bins]  # Increased weight\n\n        # 2. Encourage balanced bin utilization (avoiding very empty or very full bins after packing).\n        #   - Aim for a target utilization around 70-80%.\n        target_utilization = 0.75\n        expected_new_capacity = bins_remain_cap[feasible_bins] - item\n        expected_utilization = (bins_remain_cap[feasible_bins] - expected_new_capacity) / bins_remain_cap[feasible_bins]\n        \n        # give a higher priority to bins which are closer to target utilization after packing\n        balanced_utilization_score = np.exp(-((expected_utilization - target_utilization)**2) / 0.02) # Gaussian-like weighting\n        priorities[feasible_bins] += 3 * balanced_utilization_score # Increased weight\n\n        # 3. Penalize Near-Perfect Fit (leaving very little unused space).\n        near_perfect_fit_threshold = 0.05  # Increased threshold slightly\n        near_perfect_fit = feasible_bins & (remaining_capacity <= near_perfect_fit_threshold * bins_remain_cap)\n        priorities[near_perfect_fit] -= 5\n\n        # 4. Penalize small remainders to avoid fragmentation. Adjusted Threshold\n        small_remainder_threshold = 0.15 # Decreased threshold\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 3\n\n        # 5. Give a slight bonus to bins that are already partially filled (but not too full). This encourages\n        #    using existing bins instead of always starting new ones.\n        already_filled_threshold_low = 0.2\n        already_filled_threshold_high = 0.9\n        already_filled = feasible_bins & (bins_remain_cap > already_filled_threshold_low * np.max(bins_remain_cap)) & (bins_remain_cap < already_filled_threshold_high * np.max(bins_remain_cap))\n        priorities[already_filled] += 1\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins considering multiple factors:\n    - Remaining capacity relative to item size.\n    - Potential for creating balanced bin utilization.\n    - Penalties for creating very small remainders or near-perfect fits.\n    - Encourages packing into bins that are already somewhat filled.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Prioritize bins where the item fills a significant portion of the bin.\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += 2 * utilization[feasible_bins]  # Increased weight\n\n        # 2. Encourage balanced bin utilization (avoiding very empty or very full bins after packing).\n        #   - Aim for a target utilization around 70-80%.\n        target_utilization = 0.75\n        expected_new_capacity = bins_remain_cap[feasible_bins] - item\n        expected_utilization = (bins_remain_cap[feasible_bins] - expected_new_capacity) / bins_remain_cap[feasible_bins]\n        \n        # give a higher priority to bins which are closer to target utilization after packing\n        balanced_utilization_score = np.exp(-((expected_utilization - target_utilization)**2) / 0.02) # Gaussian-like weighting\n        priorities[feasible_bins] += 3 * balanced_utilization_score # Increased weight\n\n        # 3. Penalize Near-Perfect Fit (leaving very little unused space).\n        near_perfect_fit_threshold = 0.05  # Increased threshold slightly\n        near_perfect_fit = feasible_bins & (remaining_capacity <= near_perfect_fit_threshold * bins_remain_cap)\n        priorities[near_perfect_fit] -= 5\n\n        # 4. Penalize small remainders to avoid fragmentation. Adjusted Threshold\n        small_remainder_threshold = 0.15 # Decreased threshold\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 3\n\n        # 5. Give a slight bonus to bins that are already partially filled (but not too full). This encourages\n        #    using existing bins instead of always starting new ones.\n        already_filled_threshold_low = 0.2\n        already_filled_threshold_high = 0.9\n        already_filled = feasible_bins & (bins_remain_cap > already_filled_threshold_low * np.max(bins_remain_cap)) & (bins_remain_cap < already_filled_threshold_high * np.max(bins_remain_cap))\n        priorities[already_filled] += 1\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}