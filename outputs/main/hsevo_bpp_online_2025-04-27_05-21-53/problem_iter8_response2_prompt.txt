{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines exploration, fill optimization, and fragmentation avoidance.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio)\n        utilization = item / bins_remain_cap[feasible_bins]\n        priorities[feasible_bins] += utilization\n\n        # 2. Exploration Bonus: Prioritize less-utilized bins.\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += 0.3 * exploration_factor\n\n        # 3. Fill Optimization: Prioritize bins close to full.\n        almost_full_threshold = 0.1\n        almost_full = feasible_bins & (remaining_capacity >= 0) & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 1.2\n\n        # 4. Fragmentation Penalty: Discourage small remainders.\n        small_remainder_threshold = 0.2\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 0.8\n\n        # 5. Perfect Fit Bonus: High bonus\n        perfect_fit = np.abs(remaining_capacity) < 1e-6\n        if np.any(perfect_fit & feasible_bins):\n            priorities[feasible_bins][perfect_fit[feasible_bins]] += 10 #Big bonus\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins considering fullness, fragmentation, and item size.\n    Adaptive thresholds and bonuses are used to improve performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # Adaptive almost full threshold\n        almost_full_threshold = 0.1 + 0.05 * item\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += 15\n\n        # Adaptive small remainder penalty\n        small_remainder_threshold = 0.2 - 0.03 * item\n        small_remainder_threshold = max(0.05, small_remainder_threshold)\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= 5\n\n        # Adaptive near perfect fit penalty\n        near_perfect_fit_threshold = 0.01 + 0.005 * item\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= 3\n\n        # Utilization priority with current fill consideration\n        utilization = item / bins_remain_cap\n        current_fill = (bins_remain_cap - remaining_capacity) / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins] * (0.75 + current_fill[feasible_bins])\n\n        # Gaussian boost based on capacity difference\n        capacity_difference = np.abs(bins_remain_cap - item)\n        priority_boost = np.exp(-capacity_difference / np.mean(bins_remain_cap[feasible_bins]))\n        priorities[feasible_bins] += priority_boost[feasible_bins] * 1.5\n\n        # Random component for tie-breaking\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (2nd), we see that the 1st one uses a `bin_level_threshold` and `bin_level_boost` and adapts exploration based on the average bin level, while the 2nd one introduces `bin_diversity_penalty`, `utilization_exponent`, and `random_factor`.\n*   Comparing (1st) vs (3rd), we see that the 1st one uses a `bin_level_threshold` and `bin_level_boost` and adapts exploration based on the average bin level, while the 3rd one introduces `capacity_usage_exponent`, `large_item_penalty`, and `large_item_threshold`.\n*   Comparing (2nd) vs (3rd), we see that the 2nd one introduces `bin_diversity_penalty` and `random_factor` while the 3rd one introduces `large_item_penalty` and `large_item_threshold`. Both have `capacity_usage_exponent`.\n*   Comparing (3rd) vs (4th), the code is the same.\n*   Comparing (2nd) vs (6th), both use similar parameters like `exploration_weight`, `almost_full_boost`, etc. However, the 6th function uses some imported libraries and fixed values for parameters. The 2nd one introduces `bin_diversity_penalty`, `utilization_exponent`, and `random_factor`.\n*   Comparing (1st) vs (7th), the 1st version incorporates many configurable parameters and adaptive exploration while the 7th version is highly simplified with hardcoded constants and less sophisticated exploration.\n*   Comparing (7th) vs (8th), the code is the same.\n*   Comparing (2nd worst) vs (worst), we see that the 2nd worst has adaptive parameters based on item sizes and a Gaussian boost, whereas the worst one lacks this adaptivity and boost. Both versions priorize bins considering fullness, fragmentation, and item size.\n*   Comparing (second best) vs (second worst) the second best is using constant parameters, while the second worst is using dynamic parameters.\n\nOverall: The better heuristics tend to incorporate more sophisticated mechanisms for exploration, adaptive parameter adjustments, and penalties/bonuses based on a broader range of factors (e.g., bin diversity, item size). Simpler heuristics with hardcoded constants generally perform worse. It is evident that adaptive parameter adjustments based on item sizes leads to improved packing efficiency.\n- \nOkay, let's redefine \"Current Self-Reflection\" to boost heuristic design:\n\n*   **Keywords:** Adaptive, dynamic, balanced exploration/exploitation, diversity, tunable weights, interpretable, random components.\n\n*   **Advice:** Design heuristics that adapt to problem characteristics (item sizes, bin fill levels). Use tunable weights to balance competing objectives (feasibility, utilization, fragmentation). Incorporate randomness for exploration.\n\n*   **Avoid:** Hardcoded parameters, premature convergence, redundancy.\n\n*   **Explanation:** Focus on adaptability and balanced strategies. Employ tunable parameters for flexibility and interpretability. Prioritize exploration to avoid local optima while ensuring efficient resource utilization.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}