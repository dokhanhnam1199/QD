{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                 exploration_weight: float = 0.4,\n                 almost_full_boost: float = 2.5,\n                 small_remainder_penalty: float = 1.2,\n                 near_perfect_fit_penalty: float = 1.4,\n                 moderate_fit_bonus: float = 1.1,\n                 almost_full_threshold: float = 0.08,\n                 small_remainder_threshold: float = 0.03,\n                 near_perfect_fit_threshold: float = 0.05,\n                 moderate_fit_threshold_low: float = 0.35,\n                 moderate_fit_threshold_high: float = 0.75,\n                 bin_level_threshold: float = 0.5,\n                 bin_level_boost: float = 0.5) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of factors, adaptively adjusting\n    exploration and exploitation based on bin utilization levels. Adds a bin-level\n    consideration to further refine bin selection.\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): An array containing the remaining capacity of each bin.\n        exploration_weight (float): Weight for exploration factor.\n        almost_full_boost (float): Boost for almost full bins.\n        small_remainder_penalty (float): Penalty for small remainders.\n        near_perfect_fit_penalty (float): Penalty for near perfect fits.\n        moderate_fit_bonus (float): Bonus for moderate fits.\n        almost_full_threshold (float): Threshold for considering a bin almost full (fraction of bin size).\n        small_remainder_threshold (float): Threshold for considering a remainder small (fraction of bin size).\n        near_perfect_fit_threshold (float): Threshold for considering a fit near perfect (fraction of bin size).\n        moderate_fit_threshold_low: Lower threshold for moderate fit (fraction of bin size).\n        moderate_fit_threshold_high: Higher threshold for moderate fit (fraction of bin size).\n        bin_level_threshold (float): Threshold to consider a bin at a certain level.\n        bin_level_boost (float): Boost for bins that have passed the bin level.\n\n\n    Returns:\n        np.ndarray: An array containing the priority score for each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_capacity = bins_remain_cap - item\n\n    # Infeasible bins get the lowest priority\n    priorities[remaining_capacity < 0] = -np.inf\n\n    feasible_bins = remaining_capacity >= 0\n\n    if np.any(feasible_bins):\n        # 1. Base Priority: Bin Utilization (Fill Ratio)\n        utilization = item / bins_remain_cap\n        priorities[feasible_bins] += utilization[feasible_bins]\n\n        # 2. Adaptive Exploration: Adjust exploration based on bin fill levels.\n        #    Prioritize less-utilized bins when most bins are relatively empty.\n        bin_levels = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Normalized fill levels\n        average_bin_level = np.mean(bin_levels)\n        exploration_factor = (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins]))\n\n        # Adjust exploration weight dynamically\n        adaptive_exploration_weight = exploration_weight * (1 - average_bin_level)\n        priorities[feasible_bins] += adaptive_exploration_weight * exploration_factor\n\n        # 3. Fill-Optimization (Later Stage): Prioritize bins that are closer to being full.\n        almost_full = feasible_bins & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n        priorities[almost_full] += almost_full_boost\n\n        # 4. Fragmentation Penalty: Discourage creating small remaining fragments.\n        small_remainder = feasible_bins & (remaining_capacity > 0) & (remaining_capacity <= small_remainder_threshold * bins_remain_cap)\n        priorities[small_remainder] -= small_remainder_penalty\n\n        # 5. Near-Perfect Fit Penalty: Mild penalty for extremely close fits.\n        near_perfect_fit = feasible_bins & (remaining_capacity > (1 - near_perfect_fit_threshold) * bins_remain_cap)\n        priorities[near_perfect_fit] -= near_perfect_fit_penalty\n\n        # 6. Moderate-Fit Bonus: Bonus for reasonably well-fitting items.\n        moderate_fit = feasible_bins & ~almost_full & ~small_remainder & ~near_perfect_fit\n        moderate_fit = moderate_fit & (remaining_capacity >= moderate_fit_threshold_low * bins_remain_cap) & (remaining_capacity <= moderate_fit_threshold_high * bins_remain_cap)\n        priorities[moderate_fit] += moderate_fit_bonus\n\n        # 7. Bin Level consideration\n        bin_level_reached = feasible_bins & (bin_levels >= bin_level_threshold)\n        priorities[bin_level_reached] += bin_level_boost\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive, combines fullness, near-overflow penalty, and small remainder penalty.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n\n    if not np.any(fits):\n        return priorities\n\n    # Fullness score\n    remaining_capacities = bins_remain_cap - item\n    remaining_capacities[remaining_capacities < 0] = 0\n    fullness_scores = np.where(fits, (bins_remain_cap - item) / bins_remain_cap, 1.0) # Avoid inf\n    priorities[fits] = 1.0 - fullness_scores[fits]\n\n    # Adaptive near-overflow penalty\n    overflow_margin = 0.05 * item\n    near_overflow = fits & ((bins_remain_cap - item) < overflow_margin)\n    if np.any(near_overflow):\n        overflow_penalty = np.exp(5 * ((bins_remain_cap[near_overflow] - item - overflow_margin) / overflow_margin))\n        priorities[near_overflow] -= overflow_penalty\n\n    # Adaptive small remainder penalty\n    small_remainder_threshold = 0.2 - 0.05 * item\n    small_remainder_threshold = max(0.05, small_remainder_threshold)\n    small_remainder = fits & (remaining_capacities > 0) & (remaining_capacities <= small_remainder_threshold * bins_remain_cap)\n    priorities[small_remainder] -= 3\n\n    # Encourage filling partially filled bins, adaptive to item size\n    utilization = item / bins_remain_cap\n    current_fill = (bins_remain_cap - remaining_capacities) / bins_remain_cap\n    priorities[fits] += utilization[fits] * (1 + current_fill[fits])\n    \n    # Small random component for exploration\n    priorities[fits] += np.random.rand(np.sum(fits)) * 0.1\n    \n    priorities[bins_remain_cap < item] = -np.inf # Ensure infeasible bins have lowest priority\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (2nd), we see that the 1st one uses a `bin_level_threshold` and `bin_level_boost` and adapts exploration based on the average bin level, while the 2nd one introduces `bin_diversity_penalty`, `utilization_exponent`, and `random_factor`.\n*   Comparing (1st) vs (3rd), we see that the 1st one uses a `bin_level_threshold` and `bin_level_boost` and adapts exploration based on the average bin level, while the 3rd one introduces `capacity_usage_exponent`, `large_item_penalty`, and `large_item_threshold`.\n*   Comparing (2nd) vs (3rd), we see that the 2nd one introduces `bin_diversity_penalty` and `random_factor` while the 3rd one introduces `large_item_penalty` and `large_item_threshold`. Both have `capacity_usage_exponent`.\n*   Comparing (3rd) vs (4th), the code is the same.\n*   Comparing (2nd) vs (6th), both use similar parameters like `exploration_weight`, `almost_full_boost`, etc. However, the 6th function uses some imported libraries and fixed values for parameters. The 2nd one introduces `bin_diversity_penalty`, `utilization_exponent`, and `random_factor`.\n*   Comparing (1st) vs (7th), the 1st version incorporates many configurable parameters and adaptive exploration while the 7th version is highly simplified with hardcoded constants and less sophisticated exploration.\n*   Comparing (7th) vs (8th), the code is the same.\n*   Comparing (2nd worst) vs (worst), we see that the 2nd worst has adaptive parameters based on item sizes and a Gaussian boost, whereas the worst one lacks this adaptivity and boost. Both versions priorize bins considering fullness, fragmentation, and item size.\n*   Comparing (second best) vs (second worst) the second best is using constant parameters, while the second worst is using dynamic parameters.\n\nOverall: The better heuristics tend to incorporate more sophisticated mechanisms for exploration, adaptive parameter adjustments, and penalties/bonuses based on a broader range of factors (e.g., bin diversity, item size). Simpler heuristics with hardcoded constants generally perform worse. It is evident that adaptive parameter adjustments based on item sizes leads to improved packing efficiency.\n- \nOkay, let's redefine \"Current Self-Reflection\" to boost heuristic design:\n\n*   **Keywords:** Adaptive, dynamic, balanced exploration/exploitation, diversity, tunable weights, interpretable, random components.\n\n*   **Advice:** Design heuristics that adapt to problem characteristics (item sizes, bin fill levels). Use tunable weights to balance competing objectives (feasibility, utilization, fragmentation). Incorporate randomness for exploration.\n\n*   **Avoid:** Hardcoded parameters, premature convergence, redundancy.\n\n*   **Explanation:** Focus on adaptability and balanced strategies. Employ tunable parameters for flexibility and interpretability. Prioritize exploration to avoid local optima while ensuring efficient resource utilization.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}