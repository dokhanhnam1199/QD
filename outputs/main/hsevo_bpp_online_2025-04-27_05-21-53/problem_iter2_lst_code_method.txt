{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This function uses a heuristic inspired by the heliocentric model:\n    bins closer in capacity to the item's size are favored, as a more harmonious \"fit\" is sought,\n    akin to the celestial spheres finding their proper place.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Calculate the difference between the bin capacity and the item size.\n    diffs = np.abs(bins_remain_cap - item)\n\n    # Normalize the differences. A smaller difference yields a higher priority.\n    # Add a small epsilon to avoid division by zero and to handle cases where item > bin cap\n    epsilon = 1e-9\n    priorities = 1 / (diffs + epsilon)\n\n    # Further refine the priority: bins with sufficient capacity should have a significantly increased priority.\n    # Bins that cannot contain the item receive zero priority (a 'planetary orbit' that cannot contain the object).\n    sufficient_capacity = bins_remain_cap >= item\n    priorities = np.where(sufficient_capacity, priorities * (1 + (bins_remain_cap - item) / bins_remain_cap) , 0) # Scale priority by percentage filled if valid\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Bins that can't fit get a negative infinite priority\n    priorities = np.where(bins_remain_cap < item, -np.inf, 0)\n\n    # For bins that can fit, prioritize those with smallest remaining capacity *after* packing the item. This approximates minimizing wasted space *locally*.\n\n    possible_bins = bins_remain_cap[bins_remain_cap >= item]\n    post_fill_waste = possible_bins - item\n\n    #Use Newton's law of cooling analogy. Larger temperature differences(bins with little space after adding the item) should be cooled down quickly(higher priority).\n    # We invert it, so the colder temp gets larger values\n    priorities[bins_remain_cap >= item] = -post_fill_waste\n\n    #Add a small bias to partially filled bins to encourage them being completely full\n    priorities[bins_remain_cap >= item] += 0.01*(bins_remain_cap[bins_remain_cap >= item]/ np.max(bins_remain_cap)) # add a fraction of the remaining capacity compared to maximum capacity to all bins\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin is viable only if it has enough capacity for the item.\n    viable_bins = bins_remain_cap >= item\n    if not np.any(viable_bins):\n      return priorities # If no bin can fit, return all zeros\n\n    # Calculate the remaining capacity after adding the item to each viable bin.\n    remaining_capacities = bins_remain_cap - item\n    remaining_capacities[remaining_capacities < 0 ] = 0 # setting non-viable bins cap to zero, needed for division\n    \n    # Calculate a \"fullness\" score for each viable bin.  Bins that are fuller (closer to full) are penalized.\n    # Avoid division by zero\n    with np.errstate(divide='ignore', invalid='ignore'):  # Handle potential divide by zero. Set invalid to ignore will give us nan, which are handled below\n      fullness_scores = np.where(bins_remain_cap > 0, (bins_remain_cap - item) / bins_remain_cap, 0) # remaining capacity / initial capacity\n    fullness_scores = np.nan_to_num(fullness_scores, nan=1.0, posinf = 1.0, neginf = 1.0)\n    # Bins that are close to full (smaller relative wasted space) should be prioritized.\n\n    priorities = np.where(viable_bins, 1.0 - fullness_scores, -np.inf) # prioritize viable bins, and discourage (but allow) packing on almost full bins\n    \n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates a few heuristics:\n\n    1.  **Feasibility:**  It strongly penalizes bins that are too small to hold the item.\n        This avoids wasting time calculating priorities for impossible placements.\n\n    2.  **Capacity Utilization:**  Bins closer to being full (after placing the item)\n        are preferred.  This encourages filling bins completely.  We use a scaled\n        exponential function to capture this effect - small changes near full\n        capacity yield large priority changes.\n\n    3.  **Fragmentation Avoidance:** Bins that have too much remaining capacity\n        after adding the item are also penalized to avoid highly fragmented bins.\n        The penalty scales with the amount of wasted space.\n        We only apply this if a \"reasonable\" number of feasible bins exist.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Feasibility Check and Initial Penalty\n    feasible = bins_remain_cap >= item\n    priorities[~feasible] = -np.inf  # Very low priority if not feasible\n\n    feasible_bins_count = np.sum(feasible)\n\n    if feasible_bins_count > 0:  # Only compute if there are feasible bins\n\n        remaining_after_placement = bins_remain_cap[feasible] - item\n\n        # Capacity Utilization - Exponentially Prefer Near-Full Bins\n        capacity_utilization = np.exp(-5 * remaining_after_placement / np.max(bins_remain_cap)) # Scale the penalty\n\n        priorities[feasible] = capacity_utilization\n\n\n        # Fragmentation Avoidance (applied only if enough choices exist to avoid being stuck)\n        if feasible_bins_count > 2 :  # Threshold adjusted for different size datasets\n            waste_penalty = np.zeros_like(remaining_after_placement)\n            large_waste = remaining_after_placement > 0.5 * np.max(bins_remain_cap)\n            waste_penalty[large_waste] = -0.1 * remaining_after_placement[large_waste] # Penalize large waste\n\n            priorities[feasible] += waste_penalty\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates a few heuristics:\n\n    1.  **Feasibility:**  It strongly penalizes bins that are too small to hold the item.\n        This avoids wasting time calculating priorities for impossible placements.\n\n    2.  **Capacity Utilization:**  Bins closer to being full (after placing the item)\n        are preferred.  This encourages filling bins completely.  We use a scaled\n        exponential function to capture this effect - small changes near full\n        capacity yield large priority changes.\n\n    3.  **Fragmentation Avoidance:** Bins that have too much remaining capacity\n        after adding the item are also penalized to avoid highly fragmented bins.\n        The penalty scales with the amount of wasted space.\n        We only apply this if a \"reasonable\" number of feasible bins exist.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Feasibility Check and Initial Penalty\n    feasible = bins_remain_cap >= item\n    priorities[~feasible] = -np.inf  # Very low priority if not feasible\n\n    feasible_bins_count = np.sum(feasible)\n\n    if feasible_bins_count > 0:  # Only compute if there are feasible bins\n\n        remaining_after_placement = bins_remain_cap[feasible] - item\n\n        # Capacity Utilization - Exponentially Prefer Near-Full Bins\n        capacity_utilization = np.exp(-5 * remaining_after_placement / np.max(bins_remain_cap)) # Scale the penalty\n\n        priorities[feasible] = capacity_utilization\n\n\n        # Fragmentation Avoidance (applied only if enough choices exist to avoid being stuck)\n        if feasible_bins_count > 2 :  # Threshold adjusted for different size datasets\n            waste_penalty = np.zeros_like(remaining_after_placement)\n            large_waste = remaining_after_placement > 0.5 * np.max(bins_remain_cap)\n            waste_penalty[large_waste] = -0.1 * remaining_after_placement[large_waste] # Penalize large waste\n\n            priorities[feasible] += waste_penalty\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers:\n    1. The wasted space if the item is added to the bin (smaller wasted space is better).\n    2. A preference for bins that are already somewhat full. This encourages filling bins more completely.\n    3. A large penalty for bins that are too small to hold the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            # Large negative priority if item doesn't fit.  Think of this as an infinite cost to overflowing a bin.\n            priorities[i] = -np.inf\n        else:\n            wasted_space = cap - item\n            # Favor bins with less wasted space (negative because lower wasted space means HIGHER priority)\n            priorities[i] -= wasted_space\n\n            # Add a bonus for bins that are already relatively full\n            #  The fuller, the better, but with diminishing returns, hence the log.\n            # Avoid log(0) if item is exactly the bin capacity.\n            if wasted_space > 0:\n                 priorities[i] += np.log(item / cap) # Use item/cap for more resolution.\n            else:\n                priorities[i] += 1.0 # Max bonus if perfect fit (cap=item, wasted space is exactly 0).\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Only consider bins that can fit the item.\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(valid_bins):\n        # Calculate remaining capacity after placing the item.\n        remaining_capacity = bins_remain_cap[valid_bins] - item\n\n        # Give higher priority to bins with smaller remaining capacity (First Fit Decreasing principle).\n        # Also, penalize bins that result in very small remaining capacity to avoid fragmentation.\n        priorities[valid_bins] = (1 / (remaining_capacity + 1e-6)) - (10 * (remaining_capacity < 0.1))  # Adding small epsilon to avoid division by zero\n\n        # Give a boost to bins that can perfectly fit the item if there are any\n        perfect_fit = np.abs(remaining_capacity) < 1e-6 # Numerical Stability\n        if np.any(perfect_fit):\n            priorities[valid_bins][perfect_fit] += 100 # Huge Boost!\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item\n    remaining_capacity = bins_remain_cap - item\n    \n    # Give very low priority to bins that cannot fit the item\n    priorities[remaining_capacity < 0] = -np.inf\n    \n    # Prioritize bins with smaller wasted space after packing\n    priorities[remaining_capacity >= 0] = 1 / (remaining_capacity[remaining_capacity >= 0] + 1e-9)\n\n    # Give higher priority to bins that are almost full after adding the item.\n    almost_full_threshold = 0.1  # e.g., bin must be at least 90% full.\n    almost_full = (remaining_capacity >= 0) & (remaining_capacity <= almost_full_threshold * bins_remain_cap)\n    priorities[almost_full] += 10  # Increase priority significantly\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function incorporates a few heuristics:\n\n    1.  **Feasibility:**  It strongly penalizes bins that are too small to hold the item.\n        This avoids wasting time calculating priorities for impossible placements.\n\n    2.  **Capacity Utilization:**  Bins closer to being full (after placing the item)\n        are preferred.  This encourages filling bins completely.  We use a scaled\n        exponential function to capture this effect - small changes near full\n        capacity yield large priority changes.\n\n    3.  **Fragmentation Avoidance:** Bins that have too much remaining capacity\n        after adding the item are also penalized to avoid highly fragmented bins.\n        The penalty scales with the amount of wasted space.\n        We only apply this if a \"reasonable\" number of feasible bins exist.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Feasibility Check and Initial Penalty\n    feasible = bins_remain_cap >= item\n    priorities[~feasible] = -np.inf  # Very low priority if not feasible\n\n    feasible_bins_count = np.sum(feasible)\n\n    if feasible_bins_count > 0:  # Only compute if there are feasible bins\n\n        remaining_after_placement = bins_remain_cap[feasible] - item\n\n        # Capacity Utilization - Exponentially Prefer Near-Full Bins\n        capacity_utilization = np.exp(-5 * remaining_after_placement / np.max(bins_remain_cap)) # Scale the penalty\n\n        priorities[feasible] = capacity_utilization\n\n\n        # Fragmentation Avoidance (applied only if enough choices exist to avoid being stuck)\n        if feasible_bins_count > 2 :  # Threshold adjusted for different size datasets\n            waste_penalty = np.zeros_like(remaining_after_placement)\n            large_waste = remaining_after_placement > 0.5 * np.max(bins_remain_cap)\n            waste_penalty[large_waste] = -0.1 * remaining_after_placement[large_waste] # Penalize large waste\n\n            priorities[feasible] += waste_penalty\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Only consider bins that can fit the item.\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(valid_bins):\n        # Calculate remaining capacity after placing the item.\n        remaining_capacity = bins_remain_cap[valid_bins] - item\n\n        # Give higher priority to bins with smaller remaining capacity (First Fit Decreasing principle).\n        # Also, penalize bins that result in very small remaining capacity to avoid fragmentation.\n        priorities[valid_bins] = (1 / (remaining_capacity + 1e-6)) - (10 * (remaining_capacity < 0.1))  # Adding small epsilon to avoid division by zero\n\n        # Give a boost to bins that can perfectly fit the item if there are any\n        perfect_fit = np.abs(remaining_capacity) < 1e-6 # Numerical Stability\n        if np.any(perfect_fit):\n            priorities[valid_bins][perfect_fit] += 100 # Huge Boost!\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            priorities[i] = (cap - item) / cap  # Remaining capacity after packing, relative to original capacity. Higher is better.\n        else:\n            priorities[i] = -1  # Impossible to pack\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            priorities[i] = (cap - item) / cap  # Remaining capacity after packing, relative to original capacity. Higher is better.\n        else:\n            priorities[i] = -1  # Impossible to pack\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates a few Einstein-inspired heuristics:\n\n    1. **Space-Time Curvature Analogy:** Smaller remaining capacity bins \"attract\" smaller items more strongly.  This is modeled by a higher priority for bins where the item fits relatively snugly (but still fits).\n\n    2. **Principle of Least Action (Energy Minimization):** We prefer filling bins as completely as possible to minimize wasted space (potential energy). This is implemented by rewarding bins with remaining capacity close to the item size.\n\n    3. **Relativistic Effect (Size Dilation):** As the item size approaches the bin capacity, the relative \"difficulty\" of packing increases dramatically. We model this by a term that penalizes near-overflows, especially if many near-full bins exist. This also emulates length contraction when an item is placed into bins and a contraction term will be calculated to avoid packing it into those bins.\n\n    4. **Avoid Extreme Packing Densities:** If the bins are nearly full, apply a scaling factor to priorities based on the average fullness ratio. We prioritize dispersing the load across bins.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # First, handle cases where item doesn't fit.\n    fits = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[~fits] = -np.inf  # Very low priority for bins too small.\n    if not np.any(fits):\n        return priorities\n\n    # Calculate a \"snug fit\" score: Reward bins where the item fits relatively well.\n    snug_fit_score = (bins_remain_cap[fits] - item) / bins_remain_cap[fits]\n    snug_fit_score = 1.0 - snug_fit_score  # Higher score for better fit (closer to item size)\n    snug_fit_score = np.clip(snug_fit_score, 0.0, 1.0)  # Ensure values are within bounds\n    priorities[fits] += snug_fit_score\n\n    # Energy minimization: Prefer bins that get filled up nicely\n    remaining_space = bins_remain_cap[fits] - item\n    energy_score = np.exp(-np.abs(remaining_space) / (item + 1e-6))\n    priorities[fits] += energy_score\n\n    # Relativistic penalty for near-overflows.\n    overflow_margin = 0.05 * item  # Define a small margin near overflow\n\n    near_overflow = (bins_remain_cap[fits] - item) < overflow_margin\n    if np.any(near_overflow):\n        overflow_penalty = np.exp(5 * (bins_remain_cap[fits][near_overflow] - item - overflow_margin) / overflow_margin)\n        priorities[fits][near_overflow] -= overflow_penalty\n\n    #Contraction term to avoid packing item to a nearly full bin\n    contraction_term = np.exp(5 * (item-bins_remain_cap[fits]))\n    priorities[fits] -= contraction_term\n\n    # Avoid Extreme Densities scaling factor\n    avg_fullness = np.mean((np.sum(bins_remain_cap) - bins_remain_cap) / np.sum(bins_remain_cap))\n    density_scale = 1.0 - np.clip(avg_fullness, 0.0, 0.9)  # Apply the scaling based on the range, can be between 0.1 to 1\n\n    priorities[fits] *= density_scale # Scale priorities\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates a few Einstein-inspired heuristics:\n\n    1. **Space-Time Curvature Analogy:** Smaller remaining capacity bins \"attract\" smaller items more strongly.  This is modeled by a higher priority for bins where the item fits relatively snugly (but still fits).\n\n    2. **Principle of Least Action (Energy Minimization):** We prefer filling bins as completely as possible to minimize wasted space (potential energy). This is implemented by rewarding bins with remaining capacity close to the item size.\n\n    3. **Relativistic Effect (Size Dilation):** As the item size approaches the bin capacity, the relative \"difficulty\" of packing increases dramatically. We model this by a term that penalizes near-overflows, especially if many near-full bins exist. This also emulates length contraction when an item is placed into bins and a contraction term will be calculated to avoid packing it into those bins.\n\n    4. **Avoid Extreme Packing Densities:** If the bins are nearly full, apply a scaling factor to priorities based on the average fullness ratio. We prioritize dispersing the load across bins.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # First, handle cases where item doesn't fit.\n    fits = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[~fits] = -np.inf  # Very low priority for bins too small.\n    if not np.any(fits):\n        return priorities\n\n    # Calculate a \"snug fit\" score: Reward bins where the item fits relatively well.\n    snug_fit_score = (bins_remain_cap[fits] - item) / bins_remain_cap[fits]\n    snug_fit_score = 1.0 - snug_fit_score  # Higher score for better fit (closer to item size)\n    snug_fit_score = np.clip(snug_fit_score, 0.0, 1.0)  # Ensure values are within bounds\n    priorities[fits] += snug_fit_score\n\n    # Energy minimization: Prefer bins that get filled up nicely\n    remaining_space = bins_remain_cap[fits] - item\n    energy_score = np.exp(-np.abs(remaining_space) / (item + 1e-6))\n    priorities[fits] += energy_score\n\n    # Relativistic penalty for near-overflows.\n    overflow_margin = 0.05 * item  # Define a small margin near overflow\n\n    near_overflow = (bins_remain_cap[fits] - item) < overflow_margin\n    if np.any(near_overflow):\n        overflow_penalty = np.exp(5 * (bins_remain_cap[fits][near_overflow] - item - overflow_margin) / overflow_margin)\n        priorities[fits][near_overflow] -= overflow_penalty\n\n    #Contraction term to avoid packing item to a nearly full bin\n    contraction_term = np.exp(5 * (item-bins_remain_cap[fits]))\n    priorities[fits] -= contraction_term\n\n    # Avoid Extreme Densities scaling factor\n    avg_fullness = np.mean((np.sum(bins_remain_cap) - bins_remain_cap) / np.sum(bins_remain_cap))\n    density_scale = 1.0 - np.clip(avg_fullness, 0.0, 0.9)  # Apply the scaling based on the range, can be between 0.1 to 1\n\n    priorities[fits] *= density_scale # Scale priorities\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Version 2 incorporates more nuanced considerations.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Bin is large enough to accommodate the item.\n            # Prioritize bins that are \"almost full\" after adding the item,\n            # but penalize near-perfect fits to avoid creating too many bins\n            # that can only hold very small items.\n            new_cap = cap - item\n            fill_ratio = 1 - (new_cap / cap)\n\n            if new_cap > 0.01:  # Prevents division by zero and near-perfect fit penalty.\n                priorities[i] = fill_ratio ** 2 # Square it to emphasize close fits\n\n            else:\n                 priorities[i] = -1 # Penalize bins that would have too little remaining space.\n\n\n        else:\n            # Bin is too small to accommodate the item. Set priority to a large negative number.\n            priorities[i] = -1e9  # A very low priority to ensure it's not selected.\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Version 2 incorporates more nuanced considerations.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Bin is large enough to accommodate the item.\n            # Prioritize bins that are \"almost full\" after adding the item,\n            # but penalize near-perfect fits to avoid creating too many bins\n            # that can only hold very small items.\n            new_cap = cap - item\n            fill_ratio = 1 - (new_cap / cap)\n\n            if new_cap > 0.01:  # Prevents division by zero and near-perfect fit penalty.\n                priorities[i] = fill_ratio ** 2 # Square it to emphasize close fits\n\n            else:\n                 priorities[i] = -1 # Penalize bins that would have too little remaining space.\n\n\n        else:\n            # Bin is too small to accommodate the item. Set priority to a large negative number.\n            priorities[i] = -1e9  # A very low priority to ensure it's not selected.\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers:\n    1. Waste: The smaller the waste, the higher the priority.\n    2. Fill Level: Prefer bins that are already somewhat full.\n    3. Avoidance of Near-Full Bins: Avoid bins that will be nearly full after packing (risk of fragmentation).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Calculate waste if the item is placed in each bin.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Mark infeasible bins as infinitely bad.\n\n    # Normalize waste (lower waste is better).  Small values of waste should contribute heavily\n    normalized_waste = np.exp(-waste)\n\n    # Encourage filling partially filled bins.  The closer to halfway, the better.\n    fill_level_priority = np.exp(-np.abs(bins_remain_cap - item - np.mean(bins_remain_cap))/np.std(bins_remain_cap)) if np.std(bins_remain_cap) > 0 else np.ones_like(bins_remain_cap)\n\n    # Penalize bins that become very full after packing (e.g., > 90% full).\n    fullness_after = (bins_remain_cap - item) / np.max(bins_remain_cap) # max capacity\n    fullness_penalty = np.where(fullness_after < 0.1, -100 * (0.1-fullness_after), 0)\n\n    # Combine the factors. Weighting is important.\n    priorities = (normalized_waste * 0.6 +\n                 fill_level_priority * 0.3 +\n                 fullness_penalty * 0.1)\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that can fit the item snugly but avoids nearly full bins unless absolutely necessary.\n    It also includes a small random factor to break ties and encourage exploration of different packing configurations,\n    mimicking the probabilistic nature of quantum phenomena near event horizons.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate wasted space if the item is placed in each bin.  If wasted space negative, it means item doesn't fit\n    wasted_space = bins_remain_cap - item\n\n    # Give high priority to bins where the item fits and leaves little wasted space.  Squarer the remaining space more is preferred\n    fit_indices = wasted_space >= 0\n    if np.any(fit_indices):\n      priorities[fit_indices] = (bins_remain_cap[fit_indices] - item)**2 #Squarer the smaller space to avoid too small items or almost full bin. This is better near horizon\n    else:\n      # if no bins fit. Use First Fit Decreasing\n      return bins_remain_cap\n\n    # Add a small random factor to break ties and encourage exploration.\n    # The magnitude of the random factor should be small compared to the typical differences in wasted space.\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.0001\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that can fit the item snugly but avoids nearly full bins unless absolutely necessary.\n    It also includes a small random factor to break ties and encourage exploration of different packing configurations,\n    mimicking the probabilistic nature of quantum phenomena near event horizons.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate wasted space if the item is placed in each bin.  If wasted space negative, it means item doesn't fit\n    wasted_space = bins_remain_cap - item\n\n    # Give high priority to bins where the item fits and leaves little wasted space.  Squarer the remaining space more is preferred\n    fit_indices = wasted_space >= 0\n    if np.any(fit_indices):\n      priorities[fit_indices] = (bins_remain_cap[fit_indices] - item)**2 #Squarer the smaller space to avoid too small items or almost full bin. This is better near horizon\n    else:\n      # if no bins fit. Use First Fit Decreasing\n      return bins_remain_cap\n\n    # Add a small random factor to break ties and encourage exploration.\n    # The magnitude of the random factor should be small compared to the typical differences in wasted space.\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.0001\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that can fit the item snugly but avoids nearly full bins unless absolutely necessary.\n    It also includes a small random factor to break ties and encourage exploration of different packing configurations,\n    mimicking the probabilistic nature of quantum phenomena near event horizons.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate wasted space if the item is placed in each bin.  If wasted space negative, it means item doesn't fit\n    wasted_space = bins_remain_cap - item\n\n    # Give high priority to bins where the item fits and leaves little wasted space.  Squarer the remaining space more is preferred\n    fit_indices = wasted_space >= 0\n    if np.any(fit_indices):\n      priorities[fit_indices] = (bins_remain_cap[fit_indices] - item)**2 #Squarer the smaller space to avoid too small items or almost full bin. This is better near horizon\n    else:\n      # if no bins fit. Use First Fit Decreasing\n      return bins_remain_cap\n\n    # Add a small random factor to break ties and encourage exploration.\n    # The magnitude of the random factor should be small compared to the typical differences in wasted space.\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.0001\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}