[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and prioritizes bins that\n    can fit the item with less remaining space using a capacity ratio. It avoids\n    penalties for nearly empty bins and encourages filling larger gaps to reduce\n    fragmentation by comparing to the average remaining capacity of feasible bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - bins_remain_cap / np.max(bins_remain_cap), -np.inf)\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.5, 0)\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 0,
    "obj": 65.30714000797767,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers multiple criteria: the remaining capacity,\n    the number of bins used, and fragmentation minimization. It aims to balance\n    penalties and boosts to optimize bin utilization and reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    base_priority = np.where(bins_remain_cap >= item, 1 / (bins_remain_cap - item + 1), -1)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -1, 0)\n    penalty_priority = base_priority + nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    boosted_priority = penalty_priority + perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.5, 0)\n        final_priority = boosted_priority + large_gap_boost\n    else:\n        final_priority = boosted_priority\n\n    return final_priority",
    "response_id": 1,
    "obj": 68.07937774232151,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses capacity ratios to assign priorities, penalizes bins\n    that cannot fit the current item severely, and applies a regularization factor\n    to distribute priority evenly across bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item\n    remaining_capacity_after_item = bins_remain_cap - item\n    \n    # Priority is based on the remaining capacity after placing the item\n    # Bins with less remaining capacity after placing the item get higher priority\n    # We use a negative sign to invert the order (less remaining capacity -> higher priority)\n    prio_scores = -remaining_capacity_after_item\n    \n    # Penalize bins that cannot fit the item\n    prio_scores[bins_remain_cap < item] -= 1000  # High penalty for non-fitting bins\n\n    # Regularization to avoid fragmentation and distribute priority evenly\n    # Use a sigmoid function to add a small value to even out priorities across bins that can fit the item\n    regularization_factor = 1 / (1 + np.exp(-remaining_capacity_after_item / np.mean(remaining_capacity_after_item)))\n    prio_scores += regularization_factor\n\n    return prio_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. It also encourages\n    filling larger gaps to reduce fragmentation and boosts bins that can fit the\n    item precisely.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -1)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.5, 0)\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 3,
    "obj": 4.028719585161557,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation heavily penalizes bins that cannot fit the current item,\n    uses negative remaining capacity to assign higher priority to bins that will have\n    less remaining capacity after placing the item, and adds a regularization term\n    to distribute priority evenly among bins that can fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item\n    remaining_capacity_after_item = bins_remain_cap - item\n    \n    # Priority is based on the remaining capacity after placing the item\n    # Bins with less remaining capacity after placing the item get higher priority\n    # We use a negative sign to invert the order (less remaining capacity -> higher priority)\n    prio_scores = -remaining_capacity_after_item\n    \n    # Penalize bins that cannot fit the item\n    prio_scores[bins_remain_cap < item] -= 1000  # High penalty for non-fitting bins\n\n    # Regularization to avoid fragmentation and distribute priority evenly\n    # Add a small value to even out priorities across bins that can fit the item\n    regularization_factor = 0.05 * (bins_remain_cap / np.max(bins_remain_cap))\n    prio_scores += regularization_factor\n\n    return prio_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that\n    cannot fit the item. It scales priorities better, penalizes bins that are nearly\n    empty, and prioritizes near perfect fits more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, (item - (bins_remain_cap - item)) / item, -np.inf)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -2, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 1, 0)\n    priority += perfect_fit_boost\n\n    # Penalize bins that are empty\n    empty_bin_penalty = np.where(bins_remain_cap == 0, -3, 0)\n    priority += empty_bin_penalty\n\n    return priority",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins with larger gaps, penalizes bins that cannot fit the item,\n    and gently boosts the second smallest gaps to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    remaining_after_item = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority = np.where(bins_remain_cap >= item, remaining_after_item, -100)  # Penalize non-fit bins strictly\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        # Sort the remaining capacities for fit bins\n        sorted_remaining = np.sort(remaining_after_item[can_fit_mask])\n        \n        # Boost the second smallest gap if it exists\n        if len(sorted_remaining) > 1:\n            second_smallest_gap = sorted_remaining[1]\n            second_smallest_indices = np.where(np.isclose(bins_remain_cap, second_smallest_gap + item))[0]\n            priority[second_smallest_indices] += 1\n    \n    return priority",
    "response_id": 6,
    "obj": 149.30195452732352,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. It also encourages\n    filling larger gaps to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -np.inf)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.25, 0)\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. It also encourages\n    filling larger gaps to reduce fragmentation and penalizes nearly empty bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -np.inf)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.25, 0)\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on balancing remaining capacity and bin usage.\n    It penalizes bins that cannot fit the current item strictly and prioritizes bins that are nearly full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    remaining_after_item = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority = np.where(bins_remain_cap >= item, (1 - remaining_after_item / bins_remain_cap), -np.inf)\n    \n    # Penalize bins that cannot fit the current item\n    priority[bins_remain_cap < item] = -np.inf\n    \n    # Prioritize bins that are nearly full but can still fit the item\n    nearly_full_priority_factor = 0.5\n    nearly_full_bins = np.where((bins_remain_cap - item) < np.max(remaining_after_item) * 0.1)[0]\n    priority[nearly_full_bins] += nearly_full_priority_factor\n    \n    return priority",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]