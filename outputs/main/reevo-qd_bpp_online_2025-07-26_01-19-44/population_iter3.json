[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero, mask out bins that cannot fit the item\n    remainder = bins_remain_cap - item\n    can_fit_mask = remainder >= 0\n    \n    # Initialize priority scores with -Inf\n    priority_scores = np.full_like(bins_remain_cap, -np.inf)\n    \n    # Calculate the percentage of remaining capacity after adding the item\n    if np.any(can_fit_mask):\n        filled_percentage = 1 - (remainder[can_fit_mask] / bins_remain_cap[can_fit_mask])\n        # Prioritize bins that will have a lower filled percentage after adding the item\n        priority_scores[can_fit_mask] = -filled_percentage\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 5.534503390506582,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. Also, it encourages\n    filling larger gaps to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -1)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap == 0, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.5, 0)\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 1,
    "obj": 4.028719585161557,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses capacity ratios to assign priorities, penalizes bins\n    that cannot fit the current item, and distributes priority evenly across bins\n    to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate capacity ratios for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    capacity_ratio = (bins_remain_cap[can_fit_mask] - item) / bins_remain_cap[can_fit_mask]\n    \n    # Assign priority scores based on capacity ratios (closer to full = higher priority)\n    prio_scores = np.zeros_like(bins_remain_cap)\n    prio_scores[can_fit_mask] = (1 - capacity_ratio) ** 2\n    \n    # Penalize bins that cannot fit the current item heavily\n    prio_scores[~can_fit_mask] -= 100\n    \n    # Distribute priority evenly across bins to avoid fragmentation (optional tweak)\n    even_distribution_factor = 0.1\n    prio_scores += even_distribution_factor\n    \n    return prio_scores",
    "response_id": 2,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 34, in priority_v2\n    second_smallest_indices = np.where(np.isclose(bins_remain_cap, second_smallest_gap + item))[0]\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n2\n"
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins with larger gaps, penalizes bins that cannot fit the item,\n    and slightly boosts the second smallest gaps to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    remaining_after_item = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority = np.where(bins_remain_cap >= item, remaining_after_item, -100)  # Penalize non-fit bins strictly\n    \n    # Sort the capacities that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    if np.any(can_fit_mask):\n        sorted_remaining = np.sort(bins_remain_cap[can_fit_mask])\n        \n        # Boost the second smallest gap if it exists\n        if len(sorted_remaining) > 1:\n            second_smallest_gap = sorted_remaining[1]\n            second_smallest_indices = np.where(np.isclose(bins_remain_cap, second_smallest_gap + item))[0]\n            priority[second_smallest_indices] += 10\n    \n    return priority",
    "response_id": 3,
    "obj": 147.36737136019147,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Prioritizes bins with higher remaining capacity,\n    penalizes bins that cannot fit the item, and boosts bins with the second-largest gaps.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority scores\n    priority = np.zeros_like(bins_remain_cap)\n    \n    # Penalize bins that cannot fit the item\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[~can_fit_item_mask] = -np.inf\n    \n    # Prioritize bins based on remaining capacity\n    priority[can_fit_item_mask] = bins_remain_cap[can_fit_item_mask] - item\n    \n    # Boost the second-largest gaps\n    if np.any(can_fit_item_mask):\n        remaining_capacity_after_item = bins_remain_cap[can_fit_item_mask] - item\n        sorted capacities = np.sort(remaining_capacity_after_item)[::-1]\n        \n        # Check if there is at least a second largest gap\n        if len(sorted_capacities) > 1:\n            second_largest_gap = sorted_capacities[1]\n            # Boost bins that have the second-largest gap\n            priority[np.where(np.isclose(remaining_capacity_after_item, second_largest_gap))] += 1\n            \n    return priority",
    "response_id": 4,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 34\n    sorted capacities = np.sort(remaining_capacity_after_item)[::-1]\n           ^^^^^^^^^^\nSyntaxError: invalid syntax\n11\n2\n"
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins with higher remaining capacity, penalizes\n    bins that cannot fit the item, and slightly boosts bins with smaller yet\n    significant remaining gaps to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority scores\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Penalize bins that cannot fit the item\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[~can_fit_item_mask] = -2  # High penalty for bins that cannot fit the item\n    \n    # Calculate initial priority for bins that can fit the item\n    priority[can_fit_item_mask] = bins_remain_cap[can_fit_item_mask] - item\n    \n    # Boost bins with smaller yet significant remaining gaps\n    # Identify the second smallest gaps after inserting the item\n    if np.any(can_fit_item_mask):\n        remaining_caps = bins_remain_cap[can_fit_item_mask] - item\n        if len(remaining_caps) > 1:\n            second_smallest_gap = np.partition(remaining_caps, 1)[1]\n            # Boost bins with the second smallest gap\n            priority[bins_remain_cap - item == second_smallest_gap] += 1\n    \n    return priority",
    "response_id": 5,
    "obj": 149.30195452732352,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero, mask out bins that cannot fit the item\n    remainder = bins_remain_cap - item\n    can_fit_mask = remainder >= 0\n    # Calculate the percentage of remaining capacity after adding the item\n    filled_percentage = 1 - (remainder / bins_remain_cap[can_fit_mask])\n    # Prioritize bins that will have a lower filled percentage after adding the item\n    priority_scores = np.full_like(bins_remain_cap, -np.inf)  # Initialize with -Inf\n    priority_scores[can_fit_mask] = -filled_percentage  # Priority is higher for lower filled percentage\n    return priority_scores",
    "response_id": 6,
    "obj": 5.534503390506582,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses capacity ratios to assign priorities, penalizes bins\n    that cannot fit the current item, and distributes priority evenly across bins\n    to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item\n    remaining_capacity_after_item = bins_remain_cap - item\n    \n    # Priority is based on the remaining capacity after placing the item\n    # Bins with less remaining capacity after placing the item get higher priority\n    # We use a negative sign to invert the order (less remaining capacity -> higher priority)\n    prio_scores = -remaining_capacity_after_item\n    \n    # Penalize bins that cannot fit the item\n    prio_scores[bins_remain_cap < item] -= 1000  # High penalty for non-fitting bins\n\n    # Regularization to avoid fragmentation and distribute priority evenly\n    # Add a small value to even out priorities across bins that can fit the item\n    regularization_factor = 1 / (1 + np.exp(-remaining_capacity_after_item))\n    prio_scores += regularization_factor\n\n    return prio_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but bins that are used less often are also given some preference.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Number of bins used (here we assume bins with 0 remaining capacity are used)\n    bins_count = bins_remain_cap.shape[0]\n    used_bins_count = np.sum(bins_remain_cap == 0)\n    \n    # Priority based on remaining capacity\n    capacity_ratio = (bins_remain_cap - item) / bins_remain_cap\n    bin_not_full = capacity_ratio >= 0\n    prio_scores = (1 - capacity_ratio) ** 2 * bin_not_full\n    \n    # Regularization factor that will boost completeness of some bins\n    regularization_factor = 0.5 / max(1, bins_count - used_bins_count)\n    prio_scores += regularization_factor\n\n    # Penalize bins that cannot fit the current item\n    prio_scores[bins_remain_cap - item < 0] = -np.inf\n    \n    return prio_scores",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that have enough remaining capacity to fit\n    the item. It uses a high penalty for bins that cannot fit the item to discourage\n    their selection. Additionally, it normalizes the priority scores to better\n    distribute the priorities among the bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate available space for the item in each bin\n    available_space = bins_remain_cap - item\n    \n    # Penalty for using a new bin (arbitrary large negative number to discourage)\n    penalty_new_bin = -10000\n    \n    # Prioritize bins where the item fits\n    priority_scores = np.where(available_space >= 0, -available_space, penalty_new_bin)\n    \n    # Normalize scores to make the selection more democratic\n    max_score = priority_scores.max()\n    min_score = priority_scores.min()\n    if max_score != min_score:\n        priority_scores = (priority_scores - min_score) / (max_score - min_score)\n    else:\n        priority_scores = np.ones_like(priority_scores)  # If all scores are the same, make them equal\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that\n    cannot fit the item. It gives higher priority to bins that are closer to being\n    full but can still fit the item, encouraging a balanced fill. It also penalizes\n    nearly empty bins and incentivizes perfect fits.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, (bins_remain_cap - item) / bins_remain_cap, -np.inf)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 1, 0)\n    priority += perfect_fit_boost\n\n    return priority",
    "response_id": 0,
    "obj": 86.58755484643,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that\n    cannot fit the item. It uses a capacity ratio to prioritize bins that can fit\n    the item with less remaining space while avoiding penalties for nearly empty bins.\n    It also encourages filling larger gaps to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - bins_remain_cap / np.max(bins_remain_cap), -1)\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.5, 0)\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 1,
    "obj": 65.30714000797767,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that\n    cannot fit the item. It gives higher priority to bins that are closer to being\n    full but can still fit the item. New bins are penalized by giving them a low\n    priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -1)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap == 0, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    return priority",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that\n    cannot fit the item. It gives higher priority to bins that are closer to being\n    full but can still fit the item. New bins are penalized by giving them a low\n    priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -1)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap == 0, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    return priority",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that\n    cannot fit the item. It gives higher priority to bins that are closer to being\n    full but can still fit the item. New bins are penalized by giving them a low\n    priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -1)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap == 0, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    return priority",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]