[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 2.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent addition where the item cannot fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that cannot accept the current item\n    can_fit = bins_remain_cap >= item\n    penalty = np.where(can_fit, 0, -np.inf)\n\n    # Higher score for closer to full bins\n    priority_scores = np.log(bins_remain_cap - item + 1)\n\n    # Final score with the penality\n    final_scores = penalty + priority_scores\n\n    return final_scores",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent addition where the item cannot fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that cannot accept the current item\n    can_fit = bins_remain_cap >= item\n    penalty = np.where(can_fit, 0, -np.inf)\n\n    # Higher score for closer to full bins\n    priority_scores = np.log(bins_remain_cap - item + 1)\n\n    # Final score with the penality\n    final_scores = penalty + priority_scores\n\n    return final_scores",
    "response_id": 1,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that would exceed their\n    capacity after adding the item. Thus, bins that are nearly full and can fit the item\n    are prioritized, with a small penalty to avoid filling bins completely unless necessary.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate simple fill ratio score\n    fill_ratio_score = 1 - (bins_remain_cap / bins_remain_cap.max())\n    \n    # Penalize bins that cannot hold the item\n    cannot_fit_penalty = np.where(bins_remain_cap < item, -0.5, 0)\n    \n    # Calculate priorities by combining scores\n    priority_scores = fill_ratio_score + cannot_fit_penalty\n    \n    # Reduce very negative scores from bins that already are full\n    priority_scores[bins_remain_cap < 0] = -1\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but bins that are used less often are also given some preference.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Number of bins used (here we assume bins with 0 remaining capacity are used)\n    bins_count = bins_remain_cap.shape[0]\n    used_bins_count = np.sum(bins_remain_cap == 0)\n    \n    # Priority based on remaining capacity\n    capacity_ratio = (bins_remain_cap - item) / bins_remain_cap\n    bin_not_full = capacity_ratio >= 0\n    prio_scores = (1 - capacity_ratio) ** 2 * bin_not_full\n    \n    # Regularization factor that will boost completeness of some bins\n    regularization_factor = 0.4 / max(1, bins_count - used_bins_count)\n    prio_scores += regularization_factor\n\n    # Penalize bins that cannot fit the current item\n    prio_scores[bins_remain_cap - item < 0] -= 100\n    \n    return prio_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used from a balance perspective. Items will get priority to go into bins\n    with higher remaining capacity and fewer bins will get prioritized if they are\n    not yet used or lightly used to distribute sizes across bins more evenly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Priority score calculation components\n    back_fill_ratio = (bins_remain_cap - item) / bins_remain_cap\n    unused_bins_discount = np.exp(-np.mean(bins_remain_cap == bins_remain_cap.max()))  # Discounts less for bins with max size, more for more unused\n    overfill_penalty = np.where(bins_remain_cap - item < 0, -np.inf, 0)  # Heavy overfill penalization\n    \n    # Calculating final score\n    priority_scores = (back_fill_ratio player outage ~(environment change poor_performance & >opponent_win_ratio unsure_about_authority)\"\n\n    validate_letters(query)\n    print(\"Query is valid, proceeding with optimization.\")\nexcept Exception as e:\n    print(str(e))",
    "response_id": 4,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 24\n    priority_scores = (back_fill_ratio player outage ~(environment change poor_performance & >opponent_win_ratio unsure_about_authority)\"\n                                                                                                                                        ^\nSyntaxError: unterminated string literal (detected at line 24)\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of times a bin has approached full capacity.\n    We prioritize bins that have more remaining capacity but penalize bins that have been frequently close to full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the ideal capacity left after adding the item\n    ideal_cap_left = bins_remain_cap - item\n    \n    # Priority score is 0 if the item cannot fit in the bin\n    priority_scores = np.where(ideal_cap_left >= 0, ideal_cap_left, -np.inf)\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # If a bin has less capacity than the current item, it should not be considered\n    bin_availability = (bins_remain_cap >= item).astype(int)\n    \n    # Normalize remaining capacity to have higher score for capacities closer to the item size\n    normalized_remain_cap = (bins_remain_cap + 1e-6) / (item + 1e-6)\n    \n    # Combined priority score: higher for available and almost fitting bins\n    priority_score = bin_availability * normalized_remain_cap\n    \n    return priority_score",
    "response_id": 6,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Bins that can fit the item get penalties.\n    penalties = np.where(bins_remain_cap < item, 1.0, 0.0)\n    # Calculate a priority that is lower for fuller bins:\n    priority_scores = bins_remain_cap - np.min(bins_remain_cap[bins_remain_cap >= item])\n    # Balance between instant unpacking efficiency and avoiding unused bins\n    weights = 0.7 * bins_remain_cap + 0.3 * np.where(bins_remain_cap >= item, bins_remain_cap - item, 0)\n    priority_scores = weights * priority_scores * (1 - penalties)\n    return priority_scores",
    "response_id": 7,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used on a priority basis. Items will get packed into bins that not only have \n    enough space but also minimize the waste (over capacity or deviation from the \n    optimal state), thus prompting it fill remaining spaces more efficiently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins with very low\u5269\u4f59 space and reward closer remaining capacity to the item\n    priorities = (bins_remain_cap - item) / np.where(bins_remain_cap > item, bins_remain_cap, float('inf'))\n    # Add a small negated value of the bin_index artificially created by np.where to slightly \n    #favor consecutive bins among same priority ones, simulating decreasing expected remaining items.\n    return priorities - (np.where(priorities >= 0, np.arange(len(bins_remain_cap)), auto_std_constructor()))",
    "response_id": 8,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used: prioritizing bins that are about to be filled and have space,\n    trying to avoid creating new bins unless necessary.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that are almost full (using a sigmoid-like function) and\n    # prioritize ones that have enough space.\n    # Blo\u62e5\u6324-ness coefficient to emphasize bins with less space left.\n    overcrowding_coefficient = 2.0\n    priorities = (bins_remain_cap - item) / \\\n                 (bins_remain_cap + overcrowding_coefficient * item)\n    return priorities",
    "response_id": 9,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used on a heuristic basis. Prioritize bins that have enough space for\n    the item and try to avoid spreading small items across too many bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Check which bins have enough capacity\n    capacity_mask = bins_remain_cap >= item\n    \n    # Heuristic:those which are full minus the item size should be deprioritized\n    # Penalty for bins where placing the item would leave little space remaining\n    small_space_penalty = np.log2(bins_remain_cap - item + 1) * capacity_mask\n\n    # Calculate priority based on remaining capacity (more left usually better) minus the penalty\n    priorities = (bins_remain_cap - item + 1) - small_space_penalty * 2\n\n    # Set the priorities of bins that fit as useful candidates\n    priorities[~capacity_mask] = float('-inf')  # Use only bins that can fit the item\n\n    # Heuristic boost for bins with smaller item sizes maximized heuristic ug-max-c weighted fit on the fly decisions\n    existing_item_sizes = np.array([1] * bins_remain_cap.shape[0]) / (bins_remain_cap + 1)\n    diversity_boost = 5 * existing_item_sizes\n    priorities += diversity_boost\n\n    return priorities",
    "response_id": 10,
    "obj": 149.2919824491424,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalty for under-utilized bin after adding the item\n    penalty = bins_remain_cap - item\n    # Higher penalty if the item does not fit in the bin\n    penalty[penalty < 0] -= 100 * item\n    # Favor bins that will be filled exactly after adding the item\n    exact_match_score = 1000 * (penalty == 0)\n    # Favor bins that will still have some room after adding the item\n    room_left_score = penalty\n    # Disfavor bins that already have very little room left and filling them would lead to under-utilization\n    non_coherent_packing_penalty = np.maximum(0, -penalty) * -1\n    \n    priority_score = exact_match_score + room_left_score + non_coherent_packing_penalty\n    return priority_score",
    "response_id": 11,
    "obj": 86.58755484643,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used less as a heuristic to preferentially use smaller bins first, aiming to fill larger bins later.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize larger remaining capacities to favor bins closer to being full\n    capacity_penalty = 1 / (bins_remain_cap + 1e-9)  # Small epsilon to avoid division by zero\n\n    # Reward bins that can fit the item\n    fit_reward = (bins_remain_cap >= item).astype(float)\n\n    # Also consider the number of bins used by penalizing the number of bins with 100% usage\n    bins_almost_full = np.sum(bins_remain_cap < 0.01)\n    almost_full_penalty = np.ones_like(bins_remain_cap) * bins_almost_full\n\n    # Combine penalties and rewards into a single priority score\n    priority_score = fit_reward - capacity_penalty - almost_full_penalty\n    return priority_score",
    "response_id": 12,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    cap_based_priority = bins_remain_cap\n    \n    # Penalize bins that cannot fit the item at all\n    cap_based_priority[bins_remain_cap < item] = -float('inf')\n    \n    # Consider the proximity to being full (more potential fittings left)\n    remaining_bins = bins_remain_cap != 0\n    fullness_priority = remaining_bins / (bins_remain_cap + item)\n    fullness_priority[np.isnan(fullness_priority)] = 0  # Handle division by unintentional float('inf') conversion\n    \n    # Combine both priorities: capacity emphasis and bin usage moderation\n    priority_score = cap_based_priority + 0.1 * fullness_priority  # Give a lesserweight to the fill rate\n\n    return priority_score",
    "response_id": 13,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\nOverflowError: cannot convert float infinity to integer\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero, mask out bins that cannot fit the item\n    remainder = bins_remain_cap - item\n    can_fit_mask = remainder >= 0\n    # Calculate the percentage of remaining capacity after adding the item\n    filled_percentage = (1 - (remainder / bins_remain_cap[can_fit_mask]))\n    # Prioritize bins that will have a lower filled percentage after adding the item\n    priority_scores = np.full_like(bins_remain_cap, -np.inf)  # Initialize with -Inf\n    priority_scores[can_fit_mask] = -filled_percentage  # Priority is higher for lower filled percentage\n    return priority_scores",
    "response_id": 14,
    "obj": 5.534503390506582,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used penalties to encourage efficient packing while distributing load.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that are already slightly used to encourage new bin usage\n    usage_penalty = np.minimum(bins_remain_cap, item) / max(item, 1e-9)\n    # Use remaining capacity by less items as higher priority\n    remaining_capacity = bins_remain_cap - item\n    # Less usage penalty gets higher priority (more positive score -> higher priority)\n    priority = remaining_capacity - usage_penalty\n    return priority",
    "response_id": 15,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used penalties to encourage efficient packing while utilizing\n    existing bins more effectively.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate available space for the item in each bin\n    available_space = bins_remain_cap - item\n    \n    # Penalty for using a new bin (arbitrary large negative number to discourage)\n    penalty_new_bin = -10000\n    \n    # Prioritize bins where the item fits\n    priority_scores = np.where(available_space >= 0, -available_space, penalty_new_bin)\n    \n    # Normalize scores to be more democratic and consider smaller packs\n    min_remaining_cap = bins_remain_cap.min()\n    priority_scores = (priority_scores - min_remaining_cap)\n    \n    return priority_scores",
    "response_id": 16,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used: prioritizing bins that are about to be filled and penalizing nearly empty bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    empty_bin_penalty = np.where(bins_remain_cap == 0, -10, 0)\n\n    # Prioritize bins that can just fit the item to maximize usage\n    perfect_fit_boost = np.where(bins_remain_cap == item, 5, 0)\n    \n    # Avoid overfilling bins to maintain balance\n    overfit_prevention = np.where(bins_remain_cap < item, -bins_remain_cap, 0)\n    \n    # Consider the remaining capacity among the suitable bins\n    potential_remaining_space = bins_remain_cap - item\n\n    # Combine all test andBalance strategies\n    priority_scores = (potential_remaining_space \n                       + perfect_fit_boost \n                       + empty_bin_penalty \n                       + overfit_prevention)\n\n    return priority_scores",
    "response_id": 17,
    "obj": 149.2919824491424,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= np.max(priority) + 1\n\n    return priority",
    "response_id": 18,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent generation of additional bins unnecessarily.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that cannot fit the current item\n    feasibility = (bins_remain_cap >= item).astype(float)\n    # Consider the remaining capacity, but less so if the remaining capacity is less than the item size\n    priority_scores = feasibility * ((bins_remain_cap - item) * (bins_remain_cap >= 2*item).astype(float) + (bins_remain_cap / np.max(bins_remain_cap, axis=0)) * (bins_remain_cap < 2*item).astype(float))\n    return np.array(priority_scores)",
    "response_id": 19,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        binary_fit_flag = (priority_after_check == 0).astype(np.float32)\n        sorted_gaps = np.sort(priority_after_check[can_fit_item_mask])\n        gap_difference = sorted_gaps[(sorted_gaps > 0)].reshape(-1, 1).min(axis=0) - priority_after_check.reshape(-1, 1)\n        priority += binary_fit_flag * gap_difference.astype(np.float32)\n        \n    return priority",
    "response_id": 20,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 33, in priority_v2\nValueError: non-broadcastable output operand with shape (5000,) doesn't match the broadcast shape (5000,5000)\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    cap_based_priority = bins_remain_cap\n    \n    # Penalize bins that cannot fit the item at all\n    cap_based_priority[bins_remain_cap < item] -= 2 * item\n    \n    # Encourage using more bins efficiently by slightly reducing the importance of nearly full bins\n    penalty = np.tanh((item - bins_remain_cap) / (item + 1e-10))\n    cap_based_priority -= 0.1 * penalty\n    \n    return cap_based_priority",
    "response_id": 21,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\n    # Bonus for bins with higher initial remaining capacity\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used actively to penalize bins that would approach their capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the potential remaining capacity after adding the item\n    potential_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins where the item would exceed the remaining capacity\n    penalties = np.where(bins_remain_cap < item, -np.inf, 0)\n    \n    # Bonus for bins with higher initial remaining capacity\n    initial_cap_bonuses = bins_remain_cap\n    \n    # Encourage using bins that won't be completely filled, some moisture is good\n    moisture_bonus = (bins_remain_cap - item) / bins_remain_cap.size if item > 0 else 0\n    \n    # Priority is high if capacity remains with penalties and bonuses\n    priorities = potential_remain_cap + initial_cap_bonuses + penalties + moisture_bonus\n    \n    return priorities",
    "response_id": 22,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of times a bin has approached full capacity.\n    We also incentivize filling bins to reduce the total number of bins used.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Number of bins\n    num_bins = len(bins_remain_cap)\n    \n    # Bias towards bins that have more space remaining\n    capacity_preference = bins_remain_cap / np.max(bins_remain_cap)\n    \n    # Penalize bins that are close to being full, encouraging filling bins\n    fullness_penalty = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    \n    # Heuristic is a combination of the capacity preference and fullness penalty, with item size as a factor\n    # Adjust the weight of item size towards filling bigger bins faster, not packing on single bin\n    priority_scores = capacity_preference - fullness_penalty**2 - item / np.sum(bins_remain_cap) * capacity_preference\n    \n    return priority_scores",
    "response_id": 23,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used on a priority basis. Items with greater size are prioritized to fill \n    bins with larger remaining capacities, and avoidance of empty spaces after the \n    item is placed. Uses a weighing strategy reflecting aspects of First-Fit Decreasing \n    but slight modifications are made to integrate remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score for each bin.\n    \"\"\"\n    # Compute the differences between item size and remaining capacities\n    size_differences = bins_remain_cap - item\n    \n    # Define penalty for bins cannot fit the item\n    size_differences[size_differences < 0] -= bins_remain_cap[size_differences < 0]\n\n    # Items will be prioritized for space-consuming efficient packing, with smaller positive deficit given bonuses\n    score bonuses = bins_remain_cap - size_differences\n    \n    # Binsishes Bonus-rate defines the usefulness of fitting such sized items in given positioned bins consecutively \n    can_fit = size_differences >= 0\n\n    # give bonus if fit \n    score_w_bon = size_differences + can_fit * (bins_remain_cap - size_differences) / bins_remain_cap.shape[0]\n\n    return score_w_bon",
    "response_id": 24,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 26\n    score bonuses = bins_remain_cap - size_differences\n          ^^^^^^^\nSyntaxError: invalid syntax\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of times a bin has approached full capacity.\n    We encourage the use of bins that are relatively more underutilized but penalize bins that often do not have enough space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Priority based on remaining capacity divided by capacity (maximized for less remaining space)\n    normalized_capacity_priority = -(bins_remain_cap - item) / bins_remain_cap\n\n    # Decay factor for frequent near-overfull bins, assuming a counter array exists\n    # This is a placeholder simulating a penalty for bins that are often at the edge of capacity\n    previous_near_full_count = np.random.rand(*bins_remain_cap.shape)  # Replace with actual counters in a real scenario\n    decay_rate = 0.01  # Lower the decay rate to make this more impactful\n   \u2019est_work\u59daavPenalty = np.exp(-decay_rate * previous_near_full_count)\n\n    # Assuming bins_remain_cap > item for valid bins (else penalty = 0)\n    penalties = (bins_remain_cap - item <= 0).astype(float)  # 1 if cannot fit, 0 otherwise\n    penalties = 1 - (1 - penalties) * est_workAvPenalty  # Adjust purely based on a decay\n\n    # Combine capacity usage and penalty\n    priority_scores = normalized_capacity_priority * penalties\n\n    return priority_scores",
    "response_id": 25,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 23\n    \u2019est_work\u59daavPenalty = np.exp(-decay_rate * previous_near_full_count)\n                                                                            ^\nIndentationError: unindent does not match any outer indentation level\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 26,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 27,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 28,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 29,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  }
]