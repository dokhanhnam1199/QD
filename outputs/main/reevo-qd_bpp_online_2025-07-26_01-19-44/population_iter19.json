[
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. It also encourages\n    filling larger gaps to reduce fragmentation and boosts bins that can fit the\n    item precisely.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -1)\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -1, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 0.5, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 0.5, 0)\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 3,
    "obj": 4.028719585161557,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response0.txt_stdout.txt",
    "code_path": "problem_iter16_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies the penalty and boost mechanisms, using fixed weights.\n    It emphasizes filling larger gaps and precise fits, penalizes emptiness, and significantly\n    boosts perfect fits. The function aims to balance complexity and practical efficiency.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -10)  # Heavy penalty for bins that can't fit\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -5, 0)  # Heavier penalty for nearly empty bins\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 5, 0)  # Significant boost for perfect fits\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    feasible_caps = bins_remain_cap[bins_remain_cap >= item]\n    if feasible_caps.size > 0:\n        avg_remaining = np.mean(feasible_caps)\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 1, 0)  # Stronger boost for larger gaps\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 0,
    "obj": 3.8093338651775075,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response5.txt_stdout.txt",
    "code_path": "problem_iter6_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. It encourages\n    filling larger gaps to reduce fragmentation. The function also penalizes bins\n    that are nearly empty more heavily and boosts perfect fits more significantly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -20)  # Heavily penalize bins that can't fit\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -5 * bins_remain_cap / item, 0)  # Heavier penalty for nearly empty bins\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 2, 0)  # More significant boost for perfect fits\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 1, 0)  # Stronger boost for larger gaps\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 5,
    "obj": 3.8093338651775075,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response2.txt_stdout.txt",
    "code_path": "problem_iter13_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. It encourages\n    filling larger gaps to reduce fragmentation. The function also penalizes bins\n    that are nearly empty more heavily and boosts perfect fits more significantly.\n    The penalty and boost weights are dynamically adjusted based on the remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -10)  # Heavily penalize bins that can't fit\n\n    # Dynamically adjust penalty for nearly empty bins\n    nearly_empty_penalty_weight = 5 * np.exp(-np.mean(bins_remain_cap[bins_remain_cap < item]) / item) if np.any(bins_remain_cap < item) else 0\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -nearly_empty_penalty_weight * bins_remain_cap / item, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost_weight = 2 + np.exp(-np.mean(bins_remain_cap[bins_remain_cap == item]) / item) if np.any(bins_remain_cap == item) else 0\n    perfect_fit_boost = np.where(bins_remain_cap == item, perfect_fit_boost_weight, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 1 + (bins_remain_cap - avg_remaining) / avg_remaining, 0)  # Stronger boost for larger gaps\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 2,
    "obj": 3.839250099720782,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. It encourages\n    filling larger gaps to reduce fragmentation. The function also penalizes bins\n    that are nearly empty more heavily and boosts perfect fits more significantly.\n    The penalty and boost weights are dynamically adjusted based on the remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -10)  # Heavily penalize bins that can't fit\n\n    # Dynamically adjust penalty for nearly empty bins\n    nearly_empty_penalty_weight = 5 * np.exp(-np.mean(bins_remain_cap[bins_remain_cap < item]) / item) if np.any(bins_remain_cap < item) else 0\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -nearly_empty_penalty_weight * bins_remain_cap / item, 0)\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost_weight = 2 + np.exp(-np.mean(bins_remain_cap[bins_remain_cap == item]) / item) if np.any(bins_remain_cap == item) else 0\n    perfect_fit_boost = np.where(bins_remain_cap == item, perfect_fit_boost_weight, 0)\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    if np.any(bins_remain_cap >= item):\n        avg_remaining = np.mean(bins_remain_cap[bins_remain_cap >= item])\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 1 + (bins_remain_cap - avg_remaining) / avg_remaining, 0)  # Stronger boost for larger gaps\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 0,
    "obj": 3.839250099720782,
    "SLOC": 13.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response4.txt_stdout.txt",
    "code_path": "problem_iter15_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. It emphasizes filling larger gaps and precise fits,\n    penalizes emptiness, and significantly boosts perfect fits. The function aims to\n    balance complexity and practical efficiency.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: higher for bins that can fit the item with less remaining space\n    priority = np.where(bins_remain_cap >= item, 1 - (bins_remain_cap - item) / item, -10)  # Heavy penalty for bins that can't fit\n\n    # Penalize bins that are nearly empty to avoid creating unused bins\n    nearly_empty_penalty = np.where(bins_remain_cap < item, -10 * bins_remain_cap / item, 0)  # Heavier penalty for nearly empty bins\n    priority += nearly_empty_penalty\n\n    # Boost bins that can just fit the item precisely\n    perfect_fit_boost = np.where(bins_remain_cap == item, 3, 0)  # Even more significant boost for perfect fits\n    priority += perfect_fit_boost\n\n    # Encourage filling larger gaps to reduce fragmentation\n    # Identify bins that can fit the item and have more than the average remaining capacity\n    feasible_caps = bins_remain_cap[bins_remain_cap >= item]\n    if feasible_caps.size > 0:\n        avg_remaining = np.mean(feasible_caps)\n        large_gap_boost = np.where((bins_remain_cap >= item) & (bins_remain_cap > avg_remaining), 1, 0)  # Stronger boost for larger gaps\n        priority += large_gap_boost\n\n    return priority",
    "response_id": 4,
    "obj": 3.8093338651775075,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]