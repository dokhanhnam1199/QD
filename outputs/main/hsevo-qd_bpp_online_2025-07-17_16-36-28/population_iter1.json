[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item\n    remaining_cap_after_add = bins_remain_cap - item\n    \n    # Give a high priority to bins where the item fits\n    valid_bins = remaining_cap_after_add >= 0\n    priorities[valid_bins] = 1\n\n    #Prioritize bins that will have the least wasted space\n    wasted_space = remaining_cap_after_add[valid_bins]\n    priorities[valid_bins] += 1.0 / (1e-6 + wasted_space)\n\n    # Try to spread items across bins if possible, less important when nearing full bins\n    priorities[valid_bins] += bins_remain_cap[valid_bins] / np.sum(bins_remain_cap[valid_bins] + 1e-6)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by gravitational attraction and space-time distortion.\n    Bigger items warp space-time more (desire closer fit).\n    Closer fit = higher priority.\n    Bins with higher remaining capacity have more \"inertia\"\n    and are harder to warp (lower priority unless very close fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Avoid division by zero: Add a small epsilon to remaining capacities\n    epsilon = 1e-9\n    bins_remain_cap = np.array(bins_remain_cap) + epsilon\n\n    # Calculate how much space will be wasted\n    waste = bins_remain_cap - item\n\n    # A bin cannot be used if the waste is negative\n    waste[waste < 0] = np.inf  # Mark invalid bins\n\n    # Calculate the \"gravitational potential\" or warping of spacetime\n    # Higher potential = higher priority\n    potential = item / (waste + epsilon)\n\n    # Normalize the potential based on remaining capacity.\n    # Larger remaining capacities \"resist\" being used.\n\n    priorities = potential / (bins_remain_cap**0.5) # square root provides diminishing resistance\n\n    # Mark invalid bins as minimum priority.\n    priorities[waste == np.inf] = -np.inf # bins where item won't fit\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic considers:\n        1. Space utilization (closeness of item size to remaining capacity).\n        2. Avoidance of near-full bins unless necessary (discourages filling almost full bins further).\n        3. Preference for bins that can accommodate the item comfortably,\n           but not too much waste, i.e., balance.\n        4. Introduce a stochastic element for exploration and escape local optima, especially when bins are very similar.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate space utilization.  Prefer higher utilization, but penalize overfilling.\n    utilization = item / bins_remain_cap\n    utilization = np.clip(utilization, 0, 1) # cap it\n\n    # Calculate remaining space after adding the item.\n    remaining_space = bins_remain_cap - item\n    remaining_space[remaining_space < 0] = -1  # Make invalid (cannot accommodate) zero (it will then have small priority.\n\n    # Give preference to bins that can accommodate the item (positive remaining space).\n    valid_mask = remaining_space >= 0\n    priorities[valid_mask] += 1.0  # Base priority for valid bins\n\n    # Heuristic for space utilization for available slots:\n    #  - We prefer higher utilization (item_size / remaining_capacity) up to some point\n    #  - After that we give preference to slots that create a bin neither too full, nor too empty.\n    utilization_available = utilization[valid_mask]\n    remaining_available = remaining_space[valid_mask]\n\n    # Score based on space-left after fitting:\n    priorities[valid_mask] += np.exp(-np.abs(remaining_available - item / 2))  # Bell curve shaped prefrence around item/2\n\n    # Boost with utilization score (how well this item fills a bin), without going over 1.\n    priorities[valid_mask] += utilization_available\n    # Avoid near-full bins unless very small space available (discourage too full)\n\n    almost_full_bins_id = (remaining_available < (0.05 * item))\n    if almost_full_bins_id.any():\n      priorities[valid_mask][almost_full_bins_id] -= 0.5 # Penality\n\n    # Introduce a bit of randomness to avoid getting stuck in local minima:\n\n    priorities += np.random.normal(0, 0.001, size=priorities.shape)\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 5.6142800159553214,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin is only feasible if the item fits.\n    feasible_bins = bins_remain_cap >= item\n\n    # If no bin can fit item, assign minimum priority (this should ideally never happen).\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # Assign very low priority to all bins\n\n    # Prioritize bins that can fit the item and have the least remaining capacity after packing, but not too little.\n    remaining_capacity_after_packing = bins_remain_cap - item\n    # Bins which cannot fit have rem cap as negative. Convert to infinity so that feasible is always preferred\n    remaining_capacity_after_packing[remaining_capacity_after_packing < 0] = np.inf\n\n    # Give higher priority to bins with low remaining capacity *after* packing\n    priorities = -remaining_capacity_after_packing\n\n    # Add a bonus to bins whose remaining capacity after packing is still significant\n    # This prevents bins from being overly packed. Set the target to ~ 1/3 or 1/4 bin usage\n    capacity_target = np.mean(bins_remain_cap)/3\n    bonus = np.exp(-np.abs(remaining_capacity_after_packing - capacity_target))\n\n    priorities = priorities + bonus\n\n\n    # Zero out priority for infeasible bins\n    priorities[~feasible_bins] = -np.inf\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    A Tesla-inspired heuristic leveraging remaining capacity and wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate the wasted space if the item is placed in each bin.\n    wasted_space = bins_remain_cap - item\n\n    # Prioritize bins that can accommodate the item. Bins that can't will receive -inf priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    #if item is smaller than the remain cap of all bins:\n    if np.all(bins_remain_cap >= item):\n        #if there is one exact match bin (remain_cap == item) return 1 for this bin\n        if np.any(bins_remain_cap == item):\n          idx = np.where(bins_remain_cap == item)[0]\n          priorities[idx] = 1\n          return priorities\n        #If no exact match, favor bins with slightly larger remain_cap.\n\n        diff = bins_remain_cap - item\n        min_diff = np.min(diff)\n        idx = np.where(diff == min_diff)[0]\n        priorities[idx] = 0.9\n        return priorities\n\n    #prioritze using remaining capacity in an intelligent fashion\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n      # Utilize the Golden Ratio to reward nearly-full bins after insertion.\n      golden_ratio = (1 + np.sqrt(5)) / 2\n      fill_ratios = item / bins_remain_cap[valid_bins]\n      \n      # Apply a non-linear transformation to emphasize near-perfect fits. This emulates resonance.\n      priorities[valid_bins] = np.exp(fill_ratios*golden_ratio)\n      # Penalize wasted space, as an imperfection. A little imperfection can be tolerated.\n      priorities[valid_bins] -= (wasted_space[valid_bins] / np.max(bins_remain_cap)) * 0.5  #A bit imperfection will be penalized less than a very big imperfection\n      priorities[valid_bins] = np.nan_to_num(priorities[valid_bins], nan=-np.inf) #remove NaN values\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers several factors:\n    1. Waste minimization: Prioritizes bins where the remaining space after adding the item is small.\n    2. Bin utilization: Rewards bins that are already relatively full.\n    3. Avoiding near-empty bins: Penalizes placing an item in a nearly empty bin.\n    4. Feasibility: Only considers bins with sufficient capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities  # No feasible bins, all priorities remain zero.\n\n    remaining_space = bins_remain_cap - item\n    remaining_space[~feasible_bins] = np.inf  # Mark infeasible bins as having infinite remaining space\n\n    # Waste minimization: Prefer bins that leave less remaining space (higher priority)\n    waste_priority = -remaining_space\n\n    # Bin utilization: Prefer bins that are already relatively full\n    utilization_priority = 1 / (bins_remain_cap + 1e-9)  # Add a small constant to avoid division by zero\n    utilization_priority[~feasible_bins] = 0 # set priority of infeasible bins to 0\n\n    # Avoiding near-empty bins. Penalize placing the item if the bin will still have >90% capacity remaining *after* adding item.  If the bin is close to full already, then no penalty.\n    near_empty_penalty = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_size = 1 # assumed fixed size of bin.\n    near_empty_bins = remaining_space > 0.9 * bin_size # check which remaining space leads to near empty\n    near_empty_penalty[near_empty_bins] = -1  # Large penalty for near-empty bins\n\n    # Combine the priorities\n    priorities = waste_priority + utilization_priority + near_empty_penalty\n\n    # Infeasible bins get a very low priority to ensure they are not selected.\n    priorities[~feasible_bins] = -np.inf\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item snugly (small wasted space),\n    but also avoids bins that are almost full to reduce fragmentation.\n    It incorporates a sigmoid function to balance these two aspects.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Calculate wasted space for each bin\n    wasted_space = bins_remain_cap - item\n\n    # Bins that can't fit the item get a very low priority\n    priorities = np.where(wasted_space < 0, -np.inf, 0.0)\n\n    # For bins that *can* fit the item:\n\n    # 1. Calculate \"snugness\":  Inversely proportional to wasted space.  Smaller waste is better.\n    # Avoid division by zero by adding a small epsilon.\n    snugness = 1 / (wasted_space + 1e-9)\n    snugness = np.nan_to_num(snugness, nan=0.0, posinf=0.0, neginf=0.0)  # Handle potential infinities.\n\n    # 2. Calculate \"fragmentation risk\": high when the remaining capacity is close to the item size.\n    #  This is where the sigmoid comes in.\n    #  Sigmoid will be close to 1 when item size approaches bin capacity, and close to 0 if its almost empty.\n    # Higher sigmoid means bins which has smaller space compared to item\n    sigmoid_input = 5 * (bins_remain_cap - item) / bins_remain_cap  # Scale the difference\n    fragmentation_risk = 1 / (1 + np.exp(-sigmoid_input))  # Sigmoid function\n\n\n    # 3. Combine snugness and fragmentation risk\n    priorities = np.where(wasted_space >= 0, snugness * (1-fragmentation_risk), priorities)\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a more nuanced approach based on 'quantum tunneling'\n    probability metaphor - the closer to fitting perfectly, the better\n    but with a penalty for bins that are too small (negative tunneling).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    delta = bins_remain_cap - item\n\n    # Define the \"potential\" landscape.\n    potential = np.where(delta >= 0, np.exp(-np.abs(delta) / item), -np.inf)  # \"Tunneling\" where delta>0, infinite barrier when delta<0\n    #Consider also the level of occupancy.\n    occupancy_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n\n    #Combine terms for the priority\n    priorities = potential + 0.1 * occupancy_level # Add an extra term.\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item with minimal waste.\n    It also incorporates a term that encourages filling bins that are already somewhat full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Filter bins that can fit the item\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        # If no bin can fit the item, prioritize the bin with largest remaining capacity.\n        priorities = bins_remain_cap\n        return priorities\n\n    # Calculate waste for bins that can fit the item\n    waste = bins_remain_cap[valid_bins] - item\n    \n    # Prioritize bins with smallest waste\n    priorities[valid_bins] = -waste\n\n    #Add bonus for bins that are already somewhat full (avoid creating many almost-empty bins)\n    # The more full the bin is (without overflowing), the higher the bonus.\n    priorities[valid_bins] += (bins_remain_cap[valid_bins] / np.sum(bins_remain_cap))\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 34, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n6\n1\n49.82892142331044\n62.53484120287788\n86\n"
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    # Calculate the waste if the item were placed in each bin\n    waste = bins_remain_cap - item\n\n    # Assign high priority to bins where the item fits\n    # and low waste remains\n    valid_bins = waste >= 0\n\n    if np.any(valid_bins):\n        priorities[valid_bins] = 1 / (waste[valid_bins] + 0.0001) # Add small constant to avoid division by zero\n        # Also consider bins that are nearly full already. Encourages filling bins and reduces external fragmentation.\n        nearly_full = (bins_remain_cap > 0) & (bins_remain_cap <= item*1.1) #tolerate a bit bigger than item size because its close\n        priorities[nearly_full] += 10 # Adding constant bonus to already full bins\n    else:\n        # Item does not fit any bin. return inverse of remaining capacity\n        priorities = 1/ (bins_remain_cap + 0.0001)\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # First, consider bins that can fit the item.\n    fit_indices = bins_remain_cap >= item\n    \n    if np.any(fit_indices):\n      \n        # Among bins that fit, prioritize bins with tighter fit (smaller wasted space).\n        waste = bins_remain_cap[fit_indices] - item\n        priorities[fit_indices] = 1 / (waste + 1e-9) # Add a small constant to avoid division by zero\n        \n        # Boost bins which nearly filled, giving greater fill rate:\n        fill_rate = item / (bins_remain_cap[fit_indices])\n        priorities[fit_indices] = priorities[fit_indices] * (1 + fill_rate)\n\n    else:\n        # If no bin fits, prioritize bins with the largest remaining capacity to minimize wasted space.  Penalize greatly compared to the \"fit\" case\n        priorities = bins_remain_cap * 0.01 # Much smaller prioirities than when it fits\n    \n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that have enough space for the item\n    but avoids bins that are *too* empty after the item is placed,\n    to maximize bin utilization and reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        #If no bin can accomodate, assign uniform priority based on space left\n        priorities = bins_remain_cap\n        return priorities\n\n    # Calculate remaining capacity after placing the item in valid bins\n    remaining_cap = bins_remain_cap[valid_bins] - item\n\n    # High priority to bins that would be well-utilized\n    # After filling the bin.\n    # Penalize bins that would have too little capacity remaining\n    utilization = 1 - (remaining_cap / bins_remain_cap[valid_bins])\n    priorities[valid_bins] = utilization # Basic utilisation score\n\n    # Further adjustments to the priority:\n    # 1. Bins with capacity almost equal to the item size get higher priority (First Fit heuristic tweak)\n    almost_full = np.isclose(bins_remain_cap[valid_bins], item, rtol=0.05) #within 5%\n    priorities[valid_bins][almost_full] += 0.5\n\n    #2. Penalize bins that after putting the item would be too empty, creating fragmenation\n    # Here, if the resulting remaining capacity is more than, say, 50% of the total bin size, we penalize.\n    too_empty = remaining_cap > 0.5 * np.max(bins_remain_cap) #Compare remaining space to max remaining space\n    priorities[valid_bins][too_empty] -= 0.25\n\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a heuristic inspired by gravitational potential energy\n    and a dash of spring-like force to achieve more refined bin packing.\n    A lower potential energy (more filled bin) indicates higher priority,\n    but we add a 'spring force' term penalizing near-overflowing bins.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Gravitational Potential Energy analogy: Lower energy is preferred (more filled)\n    potential_energy = bins_remain_cap\n\n    # Spring-like force: Penalize bins that are too close to overflowing (small remaining capacity).\n    #This will simulate resistance when a bin is almost full, and it prevents to fill up such bin.\n    spring_constant = 1.0  # Adjust to control the strength of the spring force\n    spring_force = np.where(bins_remain_cap < item, -np.inf, spring_constant * (item - bins_remain_cap))\n    #Use spring_force = -np.exp(-bins_remain_cap+item) instead of spring_force = spring_constant * (item - bins_remain_cap) when overflow situation could happen.\n    # Total priority combines \"gravitational\" and \"spring\" terms, inverting the sum for maximization.\n\n    priorities = - (potential_energy + spring_force) #high score for high density after packing, penalty for overflow.\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins with capacity slightly larger than the item size,\n    but penalizes bins that are either too small or much larger. This encourages\n    more efficient packing and avoids fragmentation. It uses a combination of\n    relative fullness and a penalty for large empty space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity < item:\n            priorities[i] = -np.inf  # Cannot fit, lowest priority\n        else:\n            # Calculate the relative fullness if the item is placed in the bin\n            fullness = item / capacity\n\n            # Give higher priority to bins that are relatively full after placing the item.\n            # Avoids large wasted space if capacity is significantly larger than item.\n            # Small amount of unused capacity is preferred.  Experimented values are chosen.\n            # Also scale with item size so large items avoid \"overfilling\" bins\n\n            unused_penalty = np.exp(- (capacity - item) / (0.1*item+0.1)) # Higher capacity lead to lower value.\n\n            priorities[i] = fullness * unused_penalty # Encourage fitting items but penalized waste\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997381000003 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function combines several heuristics:\n    1.  Remaining capacity (favor bins with more remaining space to avoid fragmentation).\n    2.  Ratio of item size to remaining capacity (favor bins where the item fits reasonably well).\n    3.  A \"perfect fit\" bonus: if an item fits almost perfectly, greatly increase the priority.\n    4.  Penalize bins where the item doesn't fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            # Item doesn't fit, very low priority\n            priorities[i] = -np.inf\n        else:\n            # Primary Priority: Favor larger remaining capacity\n            priorities[i] += cap\n\n            # Secondary Priority: Consider ratio\n            ratio = item / cap\n            priorities[i] += (1 - ratio)  # Smaller ratio (item is small relative to capacity) gets higher priority\n\n            # Bonus for \"perfect fit\" (item fits with minimal waste)\n            if 0 < (cap - item) < 0.1:  # Adjust the 0.1 for desired perfect fit window\n                priorities[i] += 10  # Huge bonus for near-perfect fit\n\n            # Adjustments to priorities (feel free to tweak)\n            priorities[i] += 1 # slight additive offset to ensure the item always gets placed, no matter the bin.\n            priorities[i] += (item * 0.5) # slight bias towards using some of the space\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997151999969 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the celestial dance, favor the 'closest fit' whilst avoiding outright collisions.\n    Bins with capacity slightly exceeding the item size are to be given preference,\n    mimicking the delicate balance of planetary orbits.\n    Furthermore, severely penalize placing the item in nearly full bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Award points for bins that can fit the item.  If not, keep at 0.\n    fit_mask = bins_remain_cap >= item\n    \n    #Heuristics to adjust prioritiy based on remaining capacity\n    remaining_diff = bins_remain_cap - item\n    priorities[fit_mask] = 1.0 / (remaining_diff[fit_mask] + 0.0001)  # Inverse of remaining difference\n\n    # Penalize near-full bins severely\n    nearly_full_mask = bins_remain_cap < 0.1 #Bins with less than 0.1 remaining capacity\n    priorities[nearly_full_mask] = -1e9\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Hawking Radiation Inspired Priority:\n    # Smaller bins radiating more intensely (higher priority) if the item can fit.\n    # Avoid excessive fragmentation: prioritize bins that fit the item snugly.\n    # Introduce a stochastic element mimicking quantum uncertainty (exploration).\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Step 1: Identify feasible bins (those with enough remaining capacity)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        # No feasible bins, all priorities remain 0. Might want to open a new bin then\n        return priorities\n\n    # Step 2: Calculate Hawking-inspired \"radiation intensity\" for feasible bins.\n    # In Hawking radiation, smaller black holes radiate more. Apply a similar concept here.\n    radiation_intensity = 1.0 / (bins_remain_cap[feasible_bins] + 1e-9)  # Avoid division by zero\n\n    # Step 3: Apply a \"snug fit\" bonus: the closer the fit, the higher the priority.\n    snug_fit_bonus = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item))\n\n    # Step 4: Combine radiation intensity and snug fit bonus.\n    priorities[feasible_bins] = radiation_intensity * snug_fit_bonus\n\n    # Step 5: Introduce a small stochastic element (exploration).\n    noise = np.random.normal(0, 0.01, size=np.sum(feasible_bins)) #Adjust scale as needed\n    priorities[feasible_bins] += noise\n\n    #Normalize to make it a probability distribution-like, although not strictly necessary\n    priorities = priorities / (np.sum(priorities) + 1e-9)\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 39, in priority_v2\n    \nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n6\n1\n49.82892142331044\n62.53484120287788\n86\n"
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins where the item fills a significant portion of the bin's remaining capacity,\n    but also includes a stochastic element inspired by quantum tunneling.  Bins that are \"almost\" full\n    get a small probability boost. This is intended to allow for escaping local optima.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    \n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Heuristic 1: Fill Rate - Prioritize bins where the item fills a large fraction of the remaining capacity.\n    fill_rate = np.clip(item / bins_remain_cap, 0, 1)  # Ensure the ratio is within [0, 1]\n    priorities = fill_rate\n\n    # Heuristic 2: Capacity Slack - Slightly discourage placing the item in bins that would then have very little remaining capacity.\n    # This helps avoid fragmentation.  Note: We add a tiny constant to the denominator to avoid division by zero.\n    slack_penalty = np.exp(-50 * np.clip((bins_remain_cap - item) / (item + 1e-9), 0, 1))  # Exponential decay with smaller slack\n    priorities = priorities * slack_penalty\n\n    # Heuristic 3: Quantum Tunneling - A small stochastic bonus for \"almost full\" bins.  This introduces exploration.\n    almost_full_bonus = np.exp(-100 * np.abs((bins_remain_cap - item))) * np.random.rand(len(bins_remain_cap))*0.01\n    priorities = priorities + almost_full_bonus\n\n    # Heuristic 4: Avoid large empty bins\n    large_empty_bins = (bins_remain_cap > 2*item) # If bin is much larger than the item, prioritize it less.\n    priorities[large_empty_bins] *= 0.5 # Reduces the priority if the bin is too large for this item.\n    \n    # Heuristic 5:  Scale so they're all positive and non-zero\n    priorities += 0.0001 # Ensure no zero priorities.\n\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a default low value\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n\n    # Find bins where the item can fit\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Calculate remaining capacity after placing the item\n        remaining_capacities = bins_remain_cap[valid_bins] - item\n\n        # Give higher priority to bins with smaller remaining capacity\n        # (First-Fit Decreasing heuristic influence)\n        priorities[valid_bins] = 1.0 / (remaining_capacities + 1e-9)  # Avoid division by zero\n\n        # Add a bonus for bins where the remaining capacity is close to zero, but still positive\n        near_full = (remaining_capacities > 0) & (remaining_capacities < 0.1 * np.max(bins_remain_cap))  # Adjust 0.1 based on problem context\n        priorities[valid_bins][near_full] += 10  # Large bonus to encourage filling nearly-full bins\n    else:\n        # No bin can accommodate the item; assign minimal negative priorities\n        priorities = -1e9 * np.ones_like(bins_remain_cap)\n\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins with remaining capacity slightly larger than the item size\n    to reduce fragmentation. If the item doesn't fit, the priority is set to a very low value.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity < item:\n            priorities[i] = -np.inf  # Very low priority if it doesn't fit\n        else:\n            # Priority is higher when the remaining capacity is slightly larger than the item.\n            # The smaller the waste (capacity - item), the higher the priority, but not too small\n            waste = capacity - item\n            if waste == 0:\n                priorities[i] = 100 # perfect fit should be high priority\n            elif waste < 0.1 :\n              priorities[i] = 50 # very small waste a good choice\n            elif waste < 0.3:\n              priorities[i] = 25 # relatively small waste\n            else:\n                priorities[i] = 1 / waste #inverse proportion to the waste amount\n\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Give higher priority to bins that can fit the item perfectly or near perfectly\n            space_left = cap - item\n            if space_left == 0:\n                priorities[i] = 1000  # Perfect fit gets highest priority\n            else:\n                priorities[i] = 1.0 / (space_left + 0.0001) # Smaller space left, higher priority\n                #priorities[i] = (cap-item)/cap # how full will it be\n        else:\n            priorities[i] = -1000  # Cannot fit, lowest priority\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    A heuristic based on:\n    1. Utilization of space, prioritizing bins that would be well-utilized after adding the item.\n    2. Avoiding fragmentation, penalizing bins where adding the item leaves a small, unusable remainder.\n    3. Bin proximity, prioritizing bins that are relatively close to being full without being overfilled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if item <= remaining_cap:\n            # Utilization: higher priority for bins that, after packing, will be better utilized.\n            utilization = (item / remaining_cap)**0.5 #Square root damps the effect.\n\n            # Fragmentation penalty: reduce priority if too much space is wasted. Avoid bins with capacity slightly greater than item\n            waste = remaining_cap - item\n            fragmentation_penalty = 0.0\n            if waste > 0:\n                fragmentation_penalty = (waste / remaining_cap)**2 #Quadratic penalty. Increase fast with waste. Prevent fragmentation\n\n            #Bin Proximity (avoid almost empty and almost full).\n            proximity = np.exp(-((remaining_cap - item) / item) **2 ) #Gaussian centered on remaining_cap == item.\n\n            priorities[i] = utilization * proximity - fragmentation_penalty\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997746899999 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Reward bins where the item fits. Prioritize bins that are closer to a perfect fit.\n            # The closer the item size is to the remaining capacity, the higher the priority.\n            # Adding a small penalty to almost full bins\n            fit_ratio = item / cap\n            priorities[i] = (1 - abs(fit_ratio - 1)) - 0.01*(cap-item)\n\n            #Alternatively we can try this as well which is more deterministic:\n            #priorities[i] = 1/(cap - item + 0.000001)  # Avoid division by zero. Prefer smaller remaining space after insertion\n\n        else:\n            # Item doesn't fit, so very low priority.  Set to a large negative value\n            priorities[i] = -np.inf\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can accommodate the item with minimal wasted space.\n    It heavily penalizes bins that cannot fit the item, and rewards bins where the remaining space\n    after packing the item is close to zero (but not zero).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Penalize bins that cannot fit the item\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf  # Strongly discourage infeasible solutions\n\n    # Reward bins that can fit the item, prioritizing those with minimal wasted space\n    feasible_bins = bins_remain_cap >= item\n    remaining_space = bins_remain_cap[feasible_bins] - item\n    \n    # Calculate a score based on the inverse of the remaining space\n    # We add a small constant to avoid division by zero when the item fits perfectly.\n    # Square the inverse to further emphasize the effect of smaller remaining space.\n    \n    priorities[feasible_bins] = (1 / (remaining_space + 0.0001))**2\n    \n    # Optionally add a bonus for filling the bin more completely\n    # This helps discriminate between bins that both have small remaining space, \n    # favouring bins that have been used before rather than an empty one\n    bin_used = bins_remain_cap < 1  #Assuming that bin has capacity 1\n    priorities[bin_used] = priorities[bin_used] + 0.1 \n\n\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 21, in priority_v2\n    if np.any(fit_mask):\nOverflowError: cannot convert float infinity to integer\n6\n1\n49.82892142331044\n62.53484120287788\n86\n"
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a base value.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate remaining capacity after placing the item in each bin.\n    remaining_capacities = bins_remain_cap - item\n\n    # High priority for bins where the item fits and leaves minimal waste.\n    fit_mask = remaining_capacities >= 0\n    if np.any(fit_mask):\n        waste = remaining_capacities[fit_mask]\n        priorities[fit_mask] = 1.0 / (1e-6 + waste)  # Smaller waste = higher priority\n    else:\n        # If no bin fits, prioritize the bin with least insufficient space,\n        # but penalize severely.  This is a desperate measure.\n        insufficient_space = item - bins_remain_cap\n        priorities = -insufficient_space # Prioritize least insufficient bin. More negative = worse\n        priorities = priorities - np.max(priorities) -1 # making all negative, but retaining ordering of which bin is the least bad.\n    \n    #Further prioritize almost full bins to minimize the # of bins opened.\n    priorities = priorities + bins_remain_cap / np.sum(bins_remain_cap)\n    \n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # I, Galileo, believe that the heavens are ordered, and so too must be our bins!\n    # We seek balance and efficiency. First, let us consider only those bins that can accommodate the item.\n    eligible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)  # Initialize priorities to zero.\n\n    # For eligible bins, calculate a priority based on a combination of factors:\n    # 1. Remaining capacity:  Smaller remaining capacity is generally preferred to avoid excessive fragmentation.\n    # 2. Item-bin ratio: How well the item fits into the bin. A tighter fit is favored.\n    # 3. A slight preference for filling empty or near-empty bins to a moderate level first.\n    \n    for i in range(len(bins_remain_cap)):\n        if eligible_bins[i]:\n            remaining_cap = bins_remain_cap[i]\n            ratio = item / remaining_cap\n            \n            # Give higher priority to bins that will be filled more completely. Avoid perfect fit to reduce computation.\n            # Try to fill to 75% of the bins\n            fill_percentage = item / (1 - 0.25)\n            priorities[i] = (1/(abs(fill_percentage-remaining_cap)+ 0.0001)) + (1/ (remaining_cap + 0.0001))\n            #if(remaining_cap>=item and item/(remaining_cap) >0.95):\n            # priorities[i] =0\n\n\n    # Return the priorities.\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99998039000002 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Prioritizes bins that can accommodate the item with minimal waste,\n    and penalizes bins that are nearly full or would result in significant wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify feasible bins (bins with enough capacity)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        # If no bin can fit the item, assign a small negative priority to all bins\n        # to indicate that none are suitable.  A separate placement strategy\n        # would need to be invoked to deal with this (e.g., create a new bin).\n        priorities[:] = -1e9  # Large negative value\n        return priorities\n\n\n    # Calculate waste (remaining capacity after placing the item) for feasible bins\n    waste = bins_remain_cap - item\n    waste[~feasible_bins] = np.inf  # Set waste to infinity for infeasible bins so they don't affect calculations\n\n    # Reward bins with small waste\n    # Use a non-linear function to strongly reward small waste and less strongly reward larger waste.\n    priorities[feasible_bins] = np.exp(-waste[feasible_bins])\n\n\n    # Penalize near-full bins *before* the item is placed (risk of creating very small unusable space)\n    near_full_threshold = 0.9  # A bin is considered near-full if it's filled beyond this ratio\n\n    # A bin should be penalized if item + occupied > total capacity *near_full_threshold\n    # which is equivalent to current_capacity > item_size + total_capacity*(1 - near_full_threshold)\n    very_small_space_threshold = item / 1000  #Avoid numerical instability when dividing by zero.\n    # Penalize bins if they have very little space after placing items.\n    penalized_bins = feasible_bins & ((bins_remain_cap - item) < very_small_space_threshold)\n    priorities[penalized_bins] -= 100\n\n    # Greatly penalized if the item doesnt fit.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] -= 1e12\n\n    # Reward more full bins, but only when waste will not be near empty.\n    space_utilization_threshold = 0.25\n    bins_without_excessive_waste = (waste > bins_remain_cap*space_utilization_threshold)\n    priorities[bins_without_excessive_waste & feasible_bins] += bins_remain_cap[bins_without_excessive_waste & feasible_bins]\n\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 49, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n6\n1\n49.82892142331044\n62.53484120287788\n86\n"
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function introduces a few heuristics inspired by physical principles,\n    particularly energy minimization and potential barriers.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # 1. Energy Landscape:  A bin close to full represents a lower \"energy state\".\n    #   We want to minimize \"energy\" (waste).  So, higher remaining capacity means higher \"energy\".\n    energy = bins_remain_cap\n\n    # 2. Quantum Tunneling (modified): Bins slightly too small might still be good if we consider \"tunneling\".\n    #    In reality, we're approximating how items might fit together, even if individually they seem too big.\n    tunneling_potential = np.where(bins_remain_cap >= item, 1.0, np.exp(-100 * (item - bins_remain_cap)**2)) #High penalty if much smaller than the item size.\n\n    # 3. Heaviside Step Function with some Smoothing (inspired by Fermi-Dirac statistics):\n    #    Bins that *can* fit the item get a significant boost, encouraging use of those bins first.\n    fit_probability = 0.5 * (1 + np.tanh(100 * (bins_remain_cap - item)))\n\n    # 4.  Inverted \"energy\" with tunneling and fitting factors modulating the priority\n    priorities = (1/ (energy + 1e-9)) * tunneling_potential * fit_probability # Added small constant for numerical stability\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 5.045871559633042,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item relatively snugly,\n    but also avoids bins that are too close in capacity (risk of future issues).\n    It combines factors like remaining capacity, space utilization, and\n    a penalty for bins almost fully filled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, only consider bins where the item fits\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities  # No suitable bin. All priorities are 0.\n\n    # Calculate utilization ratio (item size / bin capacity)\n    utilization_ratios = np.where(valid_bins, item / bins_remain_cap, 0)\n\n    # Give higher priority to bins with higher utilization (but less than 1)\n    priorities[valid_bins] = utilization_ratios[valid_bins]\n\n    # Penalize bins that would be almost full after placing the item\n    almost_full_threshold = 0.95  # Adjust as needed. If closer to 1 it aggressively penalizes nearly full.\n    remaining_after_placement = bins_remain_cap - item\n    almost_full_penalty = np.where(remaining_after_placement > 0, np.where((bins_remain_cap - item) / bins_remain_cap < (1 - almost_full_threshold), -10, 0), 0)  #Large penalty for almost full. Added a >0 to make the code runnable\n\n    priorities += almost_full_penalty\n\n    # Boost bins that are relatively large and can fit item more than minimal, for balance\n    large_bin_boost = np.where(valid_bins, np.log(bins_remain_cap / item), 0) #favor bins with higher capacity left compared to size of the item\n    priorities += large_bin_boost\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 149.2919824491424,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version prioritizes bins with remaining capacity closest to the item size,\n    but also considers bins that can accommodate multiple items of similar size.\n    Uses a combination of absolute difference in remaining capacity and a normalized capacity factor.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the absolute difference between remaining capacity and item size\n    diff = np.abs(bins_remain_cap - item)\n\n    # Calculate a capacity factor.  Bins with very small capacity compared to item size get a very low factor. Bins that can take item more than once also get penalized\n    capacity_factor = np.clip(bins_remain_cap / item, 0.1, 1.5) # Lower clipping to avoid infinite priority.\n\n    # Combine the difference and capacity factor to calculate the priority\n    priorities = capacity_factor / (1 + diff) # Dividing by (1 + diff) ensures that smaller differences yield higher priority\n\n    #Set priority to 0 for bins that can't fit the item\n    priorities[bins_remain_cap < item] = 0\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  }
]