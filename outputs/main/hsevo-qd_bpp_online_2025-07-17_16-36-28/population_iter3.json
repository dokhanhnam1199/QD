[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate remaining capacity after adding the item\n    remaining_cap_after_add = bins_remain_cap - item\n    \n    # Give a high priority to bins where the item fits\n    valid_bins = remaining_cap_after_add >= 0\n    priorities[valid_bins] = 1\n\n    #Prioritize bins that will have the least wasted space\n    wasted_space = remaining_cap_after_add[valid_bins]\n    priorities[valid_bins] += 1.0 / (1e-6 + wasted_space)\n\n    # Try to spread items across bins if possible, less important when nearing full bins\n    priorities[valid_bins] += bins_remain_cap[valid_bins] / np.sum(bins_remain_cap[valid_bins] + 1e-6)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 49.82892142331044,
    "mi": 62.53484120287788,
    "token_count": 86.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit ratio and energy landscape concepts for priority.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    \n    # Fit ratio component: prioritize closer fits, avoid near-full bins\n    fit_ratio = item / bins_remain_cap[fit_mask]\n    priorities[fit_mask] = (1 - np.abs(fit_ratio - 1)) - 0.01 * (bins_remain_cap[fit_mask] - item)\n    \n    # Energy landscape component: disincentivize largely empty bins\n    priorities[fit_mask] /= (bins_remain_cap[fit_mask] + 1e-9) # Avoid division by zero\n    \n    # Set low priority for bins where item doesn't fit\n    priorities[~fit_mask] = -np.inf\n    \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 218.7248250995196,
    "mi": 78.58204003001397,
    "token_count": 150.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate remaining capacity after adding the item\n    remaining_cap_after_add = bins_remain_cap - item\n\n    # Give a high priority to bins where the item fits\n    valid_bins = remaining_cap_after_add >= 0\n    if not np.any(valid_bins):\n        return priorities # No valid bins, all priorities remain 0\n\n    priorities[valid_bins] = 1\n\n    # Prioritize bins that will have the least wasted space\n    wasted_space = remaining_cap_after_add[valid_bins]\n    priorities[valid_bins] += 1.0 / (1e-6 + wasted_space)\n\n    # Prioritize bins closer to half-full after adding the item\n    half_full_diff = np.abs(remaining_cap_after_add[valid_bins] - np.mean(bins_remain_cap) / 2) # Try to make bins uniformly occupied\n    priorities[valid_bins] += 1.0 / (1e-6 + half_full_diff)\n\n    #Scale the bin_remain_cap to emphasize almost full bins\n    scaled_bins_remain_cap = bins_remain_cap[valid_bins]**2\n\n    # Try to spread items across bins if possible, less important when nearing full bins\n    priorities[valid_bins] += scaled_bins_remain_cap / np.sum(scaled_bins_remain_cap + 1e-6)\n\n    # Add a small random component to break ties and explore different solutions\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 2.7323494216194746,
    "SLOC": 17.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 316.09556827246695,
    "mi": 81.03776293129587,
    "token_count": 238.0,
    "exec_success": true
  }
]