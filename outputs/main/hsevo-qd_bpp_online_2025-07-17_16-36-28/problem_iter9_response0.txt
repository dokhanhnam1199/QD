```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    A refined priority function for online bin packing, incorporating adaptive
    weighting and controlled exploration.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap - item >= 0

    if not np.any(valid_bins):
        return priorities

    # --- Feasibility Check ---
    priorities[valid_bins] = 1.0

    # --- Minimize Wasted Space ---
    wasted_space = bins_remain_cap[valid_bins] - item
    priorities[valid_bins] += 1.0 / (1e-6 + wasted_space)

    # --- Target Half-Full Bins (Adaptive Weight) ---
    mean_cap = np.mean(bins_remain_cap)
    half_full_diff = np.abs(bins_remain_cap[valid_bins] - item - mean_cap / 2)
    
    # Adaptive weight based on how full the bins are.  If bins are nearly empty,
    # penalize targeting the half-full state as that will just create a lot
    # of nearly-empty bins.
    fill_ratio = np.mean(bins_remain_cap / mean_cap) #average bin fill ratio
    half_full_weight = max(0.1, 1.0 - fill_ratio) # Adaptive weight
    priorities[valid_bins] += half_full_weight / (1e-6 + half_full_diff)

    # --- Spread Items (Bin Capacity Scaling) ---
    scaled_bins = bins_remain_cap[valid_bins] ** 2
    priorities[valid_bins] += scaled_bins / (np.sum(scaled_bins) + 1e-6)

    # --- Fragmentation Penalty (New Feature) ---
    # Penalize bins that are already fragmented (i.e., have a small remaining capacity).
    # This encourages filling bins with more space first.  Weight this such that
    # it does not override other metrics
    fragmentation_penalty = (1.0 - (bins_remain_cap[valid_bins] / np.max(bins_remain_cap))) * 0.2 # Scale to 0-0.2
    priorities[valid_bins] -= fragmentation_penalty

    # --- Controlled Exploration (Simulated Annealing) ---
    # Introduce randomness with a decreasing temperature.
    temperature = 0.01  # Initial temperature (can be adjusted)
    #Decrease the temperature as we add more items to force convergence
    temperature = temperature * (1.0 - (len(bins_remain_cap) / (len(bins_remain_cap) + 1000)) ) #Simulated Annealing

    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * temperature

    return priorities
```
