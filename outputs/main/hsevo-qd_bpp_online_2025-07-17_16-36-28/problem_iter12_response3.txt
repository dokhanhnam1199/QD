```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines best aspects of v1 and introduces dynamic scaling and capacity awareness."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins = bins_remain_cap - item >= 0

    if not np.any(valid_bins):
        return priorities

    priorities[valid_bins] = 1.0  # Fits check

    # Minimize wasted space, scale based on item size
    wasted_space = bins_remain_cap[valid_bins] - item
    priorities[valid_bins] += (item / (np.mean(bins_remain_cap) + 1e-6)) / (1e-6 + wasted_space)

    # Target Half-full, but adjust the target based on item size
    mean_cap = np.mean(bins_remain_cap)
    target_level = max(mean_cap / 2, item)  # Adjust the target
    half_full_diff = np.abs(bins_remain_cap[valid_bins] - item - target_level)
    priorities[valid_bins] += 1.0 / (1e-6 + half_full_diff)

    # Spread items, but normalize by mean remaining capacity
    scaled_bins = bins_remain_cap[valid_bins]**2
    priorities[valid_bins] += (scaled_bins / (np.sum(scaled_bins) + 1e-6)) * (mean_cap / (np.max(bins_remain_cap)+1e-6))

    # Introduce more nuanced tie-breaking: favor bins closer to item size.
    tiebreak_values = np.random.rand(np.sum(valid_bins))
    size_diffs = np.abs(bins_remain_cap[valid_bins] - item)
    normalized_size_diffs = size_diffs / (np.max(bins_remain_cap) + 1e-6)
    priorities[valid_bins] += tiebreak_values * (1 - normalized_size_diffs) * 0.01

    return priorities
```
