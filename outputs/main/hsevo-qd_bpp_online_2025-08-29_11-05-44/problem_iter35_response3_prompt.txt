{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste decay (like v0) with a direct fit component (like v6).\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return priorities\n\n    waste = bins_remain_cap[possible_bins] - item\n    fit_score = 1.0 / (waste + 1e-6) \n    priorities[possible_bins] = np.exp(-waste / item) * fit_score\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines worst-fit with waste decay and age bonus for improved bin selection.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    worst_fit_capacities = bins_remain_cap[valid_bins] - item\n    max_waste = np.max(worst_fit_capacities)\n    waste_decay = -np.log(np.sum(bins_remain_cap) + 1)\n    age_bonus = np.arange(len(bins_remain_cap))[valid_bins] * 0.005\n    preferences = (max_waste * 0.8) + (waste_decay * 0.1) + age_bonus\n    priorities[valid_bins] = preferences\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see both use capacity-weighted preference with waste decay and age bonus. The 1st incorporates `k` and `total_waste` as parameters offering more control. The 2nd has a hardcoded waste decay (0.01) and adds 1.0 to the best bin\u2019s priority, potentially skewing selection.\n\nComparing (3rd) vs (4th), the 3rd uses `1/(waste+1e-6)` which is prone to instability with very small waste, while the 4th utilizes `exp(-0.005 * waste)` offering a smoother decay.  The 3rd is simpler but potentially less robust.\n\nComparing (5th) vs (6th), both attempt similar weighting schemes. The 5th is simpler, using `1/(1+waste)`, while the 6th has age bonus and parameter `k` on total waste and is more complex. \n\nComparing (7th) vs (8th), 7th has simpler decay and lacks tunable weights. 8th's weighted approach (fit, waste, age) with decay_rate offers far more control.\n\nComparing (9th) vs (10th) & (11th), 9th is simply returning zero priorities. 10th and 11th are identical and are a very basic inverse capacity approach avoiding division by zero.\n\nComparing (12th) vs (13th), 13th imports `scipy` and `torch` which are unnecessary for this task increasing overhead, and is initialized with `total_waste`. 12th has explicit weighting of fit, waste, and age.\n\nComparing (14th) vs (15th), 14th uses `1/(fit_scores + 1e-6)` to penalize bad fits. 15th introduces `age_factor` and is more complex.\n\nComparing (16th) vs (17th), 16th is a simplified version, while 17th does nothing meaningful, just returning zero priorities if no bins are suitable.\n\nComparing (18th) vs (19th), 18th attempts inverse remaining capacity but lacks nuance. 19th is overcomplicated with `max_waste`, `waste_decay` and age_bonus, which seems arbitrary.\n\nComparing (20th) vs (19th), both are poor. 20th is simply a heuristic 1 with more complex equation, which is not better.\n\nOverall: Effective heuristics balance fit, waste reduction, and potentially bin age. Tunable parameters are crucial for adapting to different data distributions. Simplicity and robustness are highly desirable, avoiding unnecessary complexities and potential instability. The best heuristics (1st, 8th) utilize weighting schemes with parameters for control.\n- \nOkay, let's distill a refined approach to heuristic design, focusing on bin packing as the core example, and aiming for that $999K tip!\n\n**Keywords:** Weighted combination, Exponential decay, Robustness, Tunability.\n\n**Advice:** Prioritize a weighted combination of *fit* (remaining capacity), *waste* (with exponential decay to control influence), and *bin age*. Design for easy parameter tuning of these weights. Focus on clear, direct measures; avoid abstract normalization.\n\n**Avoid:** Complex formulas, global waste calculations, reciprocals, and sigmoid functions unless rigorously proven superior. Overly simplistic solutions or aggressive penalties for any single factor. Division by zero *at all costs*.\n\n**Explanation:** The \u201cIneffective\u201d reflections highlight a pattern: overcomplication hurts. The most successful advice emphasizes *balance* achieved through tunable weights and robust functions (exponential decay).  Simplicity allows for faster iteration and easier debugging, while weighting allows adaptation to diverse problem instances.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}