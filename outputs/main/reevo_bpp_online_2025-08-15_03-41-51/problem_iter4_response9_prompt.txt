{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This version prioritizes tighter fits using a sigmoid function and\n    adds a small bonus for bins with more remaining capacity to encourage\n    future flexibility.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate a priority score\n    if np.any(can_fit_mask):\n        valid_bins_cap = bins_remain_cap[can_fit_mask]\n        valid_bins_indices = np.where(can_fit_mask)[0]\n\n        # --- Core Priority Calculation ---\n        # 1. Tightest Fit (Exploitation):\n        #    We want bins with remaining capacity just slightly larger than the item.\n        #    A good measure is `remaining_capacity - item`. Smaller values are better.\n        #    We can use a sigmoid-like function where small positive values (tight fit)\n        #    result in high scores, and large positive values (loose fit) result in lower scores.\n        #    Let's use `1 / (1 + exp(k * (capacity - item)))` or similar.\n        #    A simpler approach is to rank based on (capacity - item) and invert.\n        #    Let's transform `capacity - item` to prioritize smaller values.\n        #    We can use `- (capacity - item)` and then apply sigmoid, or scale and invert.\n        #    A good transformation might be `1 / (1 + (capacity - item))` or\n        #    `sigmoid(negative_difference)`.\n        #    Let's try: `sigmoid(alpha * (item - remaining_capacity))`\n        #    where alpha is a steepness parameter. A larger alpha makes the \"best fit\"\n        #    more pronounced.\n        #    Alternatively, `remaining_capacity` itself can be used, but we want smaller\n        #    remaining capacities for tight fits. So, we'll invert it or use a negative\n        #    dependency.\n\n        # Let's use a function that maps (remaining_capacity - item) to a priority.\n        # We want small (remaining_capacity - item) to have high priority.\n        # A simple transformation is `1 / (1 + (remaining_capacity - item))`\n        # For numerical stability and better control, let's scale and then apply sigmoid.\n        # Consider `sigmoid(k * (item - remaining_capacity))`.\n        # `k` controls sensitivity. A positive `k` will mean smaller `remaining_capacity` (for a given `item`) has higher priority.\n        # Let `diff = remaining_capacity - item`. We want to prioritize small `diff`.\n        # Sigmoid of `-k * diff` is good. `1 / (1 + exp(k * diff))`\n        # To avoid numerical issues, let's normalize `diff` first.\n        # `normalized_diff = (diff - min_diff) / (max_diff - min_diff)`\n        # Then `sigmoid(k * (1 - normalized_diff))`\n\n        # A more direct approach for \"tightest fit\":\n        # Prioritize bins where `bins_remain_cap` is just above `item`.\n        # `tightness_score = 1.0 / (1.0 + bins_remain_cap[valid_bins_indices] - item)` # higher is better fit\n        # This can be unstable if `bins_remain_cap - item` is very large.\n        # A sigmoid is better: `sigmoid(k * (item - bins_remain_cap[valid_bins_indices]))`\n        # Let's use `k=1.0` for now.\n        k_tightness = 1.0  # Sensitivity for tight fit\n        tightness_scores = 1.0 / (1.0 + np.exp(k_tightness * (item - valid_bins_cap)))\n\n        # 2. Future Flexibility Bonus (Exploration/Balancing):\n        #    Consider bins with larger remaining capacity as having a small bonus.\n        #    This is like a small incentive to keep some space.\n        #    We can use `sigmoid(k_flex * (bins_remain_cap[valid_bins_indices] - threshold))`\n        #    or simply a linear scaling.\n        #    Let's make it a smaller bonus, so we scale `valid_bins_cap` and add it.\n        #    To prevent very large bins from dominating, we can normalize `valid_bins_cap`.\n        #    Max remaining capacity among valid bins:\n        max_cap_valid = np.max(valid_bins_cap)\n        min_cap_valid = np.min(valid_bins_cap)\n\n        if max_cap_valid > min_cap_valid:\n            normalized_caps = (valid_bins_cap - min_cap_valid) / (max_cap_valid - min_cap_valid)\n        else: # All valid bins have same remaining capacity\n            normalized_caps = np.ones_like(valid_bins_cap) * 0.5 # Neutral value\n\n        # The flexibility bonus should be smaller than the tightness score.\n        # So, we can scale `normalized_caps` by a small factor, say `0.2`.\n        flexibility_bonus_scale = 0.2\n        flexibility_bonus = flexibility_bonus_scale * normalized_caps\n\n        # Combine scores\n        combined_scores = tightness_scores + flexibility_bonus\n\n        # Assign scores to the original bins_remain_cap array\n        priorities[valid_bins_indices] = combined_scores\n\n        # --- Normalization ---\n        # Normalize priorities to a 0-1 range. This makes the scale consistent\n        # and avoids extremely large or small numbers if the sigmoid or bonus\n        # values get too extreme.\n        max_priority = np.max(priorities)\n        if max_priority > 0:\n            priorities = priorities / max_priority\n        else:\n            # If all valid bins resulted in 0 priority (unlikely with sigmoid),\n            # or if there were no valid bins, handle it.\n            pass # Priorities remain 0\n\n    # Bins that cannot fit the item will have a priority of 0, which is already set.\n\n    # Add a small random perturbation to break ties and encourage slight exploration\n    # among equally good options. This is a subtle form of exploration.\n    # Apply to bins that can fit the item.\n    if np.any(can_fit_mask):\n        perturbation_scale = 0.05 # Small random boost\n        eligible_indices = np.where(can_fit_mask)[0]\n        # Ensure we don't add perturbation to bins with 0 priority initially\n        # (though in this logic, all can_fit bins have positive priority)\n        priorities[eligible_indices] += np.random.rand(len(eligible_indices)) * perturbation_scale\n\n        # Re-normalize after adding perturbation to keep priorities in a reasonable range\n        max_priority = np.max(priorities)\n        if max_priority > 0:\n            priorities = priorities / max_priority\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    return expit(x)\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin,\n    prioritizing tightest fits with a bonus for flexibility.\n\n    The priority is a composite score based on:\n    1. Tightness: Prioritizes bins with minimal remaining capacity that can fit the item.\n       This is modeled using a sigmoid function where smaller positive gaps\n       (remaining_capacity - item) yield higher scores.\n    2. Flexibility: Prioritizes bins with larger remaining capacity.\n       This is modeled using a sigmoid function of the remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Parameters for the scoring functions\n    # k_tight: Controls the steepness of the tightness score. Higher k_tight means\n    #          smaller gaps are much more favored.\n    # k_flex: Controls the steepness of the flexibility score. Higher k_flex means\n    #         larger capacities reach saturation faster.\n    # w_tight: Weight for the tightness component.\n    # w_flex: Weight for the flexibility component.\n    k_tight = 3.0\n    k_flex = 0.5\n    w_tight = 0.7\n    w_flex = 0.3\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Process only bins that can fit the item\n    eligible_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(eligible_bins_indices) > 0:\n        eligible_rem_cap = bins_remain_cap[eligible_bins_indices]\n        gaps = eligible_rem_cap - item\n\n        # Calculate tightness score:\n        # We want small positive gaps to have high scores.\n        # Use 1 - sigmoid(k * gap)\n        # If gap = 0, score = 1 - sigmoid(0) = 0.5\n        # If gap = small positive, score < 0.5\n        # If gap = large positive, score -> 0\n        # This is slightly counter-intuitive. Let's use sigmoid(k * (1 - gap))\n        # Or sigmoid(k * (-gap)) ... this is low for small gaps.\n\n        # Let's use sigmoid(k * (score_input)) where score_input is high for tight fits.\n        # Input to sigmoid should be high for small `gap`.\n        # e.g., `k * exp(-gap)` or `k * (1 / (1 + gap))`\n        # Let's try a simple linear mapping that we then feed to sigmoid.\n        # Map gap from [0, max_gap] to [-sensitivity, sensitivity] or similar.\n\n        # Alternative: Use the reciprocal of gap + epsilon, then normalize/sigmoid.\n        # `tightness_factor = 1.0 / (gaps + 1e-6)`\n        # `tightness_score = sigmoid(k_tight * (normalized_tightness_factor))`\n\n        # Let's stick to the reflection's idea of sigmoid on a measure.\n        # Measure of \"how tight is it\": higher value for smaller positive gap.\n        # Let `tightness_measure = -gaps`.\n        # `tightness_score = sigmoid(k_tight * tightness_measure)`\n        # If gap = 0, measure = 0, score = 0.5\n        # If gap = small positive, measure = small neg, score < 0.5\n        # If gap = large positive, measure = large neg, score -> 0.\n\n        # This is inverted again. The mapping needs to be correct.\n        # Let's re-evaluate sigmoid(X) for desired mapping:\n        # We want `f(gap)` such that `f(0)` is high, `f(large)` is low.\n\n        # Option 1: `sigmoid(k * (-gap))` -> Low for small gaps.\n        # Option 2: `1 - sigmoid(k * gap)` -> High for small gaps.\n        #   If gap=0, 1-0.5 = 0.5\n        #   If gap=small pos, 1-sigmoid(pos) = 1 - ( >0.5 ) = <0.5. This is inverted!\n\n        # Let's consider the quantity `1 / (1 + exp(-k * x))` for `x`.\n        # If we want high score for small `x`, we can use `1 / (1 + exp(k * x))`.\n        # Let `x = gaps`.\n        # `tightness_score = 1 / (1 + np.exp(k_tight * gaps))`\n        #   If gap = 0, score = 1 / (1 + 1) = 0.5\n        #   If gap = small positive, score < 0.5\n        #   If gap = large positive, score -> 0. This is still inverted.\n\n        # How about `sigmoid(k * (C - gap))`? Let C be the max possible gap or just a constant.\n        # Let C = 10 (assume max gap won't exceed 10 significantly).\n        # `tightness_score = sigmoid(k_tight * (10 - gaps))`\n        #   If gap = 0, input = 10*k_tight. Score ~ 1.\n        #   If gap = 1, input = k_tight*(10-1). Score is lower.\n        #   If gap = 10, input = 0. Score = 0.5.\n        #   If gap = 11, input = k_tight*(10-11) = -k_tight. Score < 0.5.\n\n        # This seems to work! Higher score for smaller gaps.\n        # However, we must ensure that unfit bins (negative gap if we didn't mask) are handled.\n        # The `can_fit_mask` already handles this by only processing eligible bins.\n        # So, `gaps` are always non-negative here.\n\n        # Let's normalize gaps to be more robust, or choose C carefully.\n        # Max possible gap could be `bin_capacity_limit - min_item_size`.\n        # For simplicity, let's just use `k_tight` to control sensitivity.\n        # `tightness_score = sigmoid(k_tight * (item - gaps))` --> this is `sigmoid(k_tight * (2*item - eligible_rem_cap))`\n        # Let's use `sigmoid(k_tight * (target_gap - gaps))` where `target_gap` is near 0.\n        # Let `target_gap = 0`.\n        # `tightness_score = sigmoid(k_tight * (0 - gaps))` is wrong.\n\n        # Let's define tightness as `(remaining_capacity - item)`. Smaller is better.\n        # We want a function `f(x)` where `f(0)` is high, `f(large)` is low.\n        # `f(x) = 1 / (1 + x)` is decreasing. `f(0)=1, f(large)->0`.\n        # `f(x) = exp(-k * x)` is decreasing. `f(0)=1, f(large)->0`.\n        # We can use these directly or pass them through a sigmoid.\n        # Using `exp(-k * x)` for tightness:\n        tightness_score = np.exp(-k_tight * gaps)\n\n        # Using sigmoid for flexibility, to keep scores bounded and smooth.\n        flexibility_score = sigmoid(k_flex * eligible_rem_cap)\n\n        # Combine scores\n        composite_priorities = w_tight * tightness_score + w_flex * flexibility_score\n        priorities[eligible_bins_indices] = composite_priorities\n\n    # Normalize priorities so the max is 1, for easier comparison if needed.\n    # This is optional, as relative values matter for selection.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n    # If all priorities are 0, then priorities remains all zeros.\n\n    return priorities\n\n[Reflection]\nTune parameters, balance exploration/exploitation, use normalized values, and sigmoid for smooth prioritization.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}