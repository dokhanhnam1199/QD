{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin,\n    prioritizing tight fits and adding small bonuses for larger capacities.\n\n    The strategy aims to:\n    1. Prioritize bins that offer a \"tight fit\" (minimal remaining capacity after packing).\n    2. Give a small bonus to bins with larger remaining capacities, encouraging their\n       use for potentially larger future items.\n    3. Stabilize scoring and handle un-fittable bins explicitly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Determine which bins can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Filter to only consider bins that can fit the item\n    fitting_bins_cap = bins_remain_cap[can_fit_mask]\n    fitting_indices = np.where(can_fit_mask)[0]\n\n    # --- Scoring components ---\n\n    # 1. Tight Fit Score: Prioritize bins with minimal remaining capacity after packing.\n    #    We want to minimize (remaining_capacity - item).\n    #    To turn this into a priority (higher is better), we can invert and scale.\n    #    A small value for (remaining_capacity - item) should result in a high score.\n    #    Using (max_possible_difference - diff) or similar.\n    #    Let's define a \"waste\" score: waste = remaining_capacity - item. Lower waste is better.\n    waste = fitting_bins_cap - item\n\n    # Normalize waste to [0, 1] range for consistent scoring.\n    # If all waste is 0, max_waste will be 0, avoid division by zero.\n    max_waste = np.max(waste) if len(waste) > 0 else 0\n    if max_waste > 0:\n        normalized_waste = waste / max_waste\n    else:\n        normalized_waste = np.zeros_like(waste) # All bins perfectly fit or no bins fit\n\n    # Tight fit priority: Higher when normalized_waste is lower (closer to 0).\n    # We can use a function like 1 - normalized_waste or apply a sigmoid-like shape.\n    # Let's try a simple inverted linear score: 1 - normalized_waste.\n    tight_fit_scores = 1.0 - normalized_waste\n\n    # 2. Capacity Bonus Score: Give a small bonus to bins with larger remaining capacities.\n    #    This encourages using bins that might be able to fit larger items later.\n    #    Normalize remaining capacity to [0, 1].\n    max_cap = np.max(bins_remain_cap) if num_bins > 0 else 1 # Avoid division by zero if no bins\n    if max_cap > 0:\n        normalized_caps = bins_remain_cap / max_cap\n    else:\n        normalized_caps = np.zeros_like(bins_remain_cap)\n\n    # Capacity bonus: Add a fraction of the normalized capacity.\n    capacity_bonus_weight = 0.1 # Tunable parameter\n    capacity_bonus_scores = capacity_bonus_weight * normalized_caps[can_fit_mask]\n\n    # --- Combine scores ---\n    # Total score for fitting bins is a weighted sum of tight fit and capacity bonus.\n    # We can use a sigmoid-like transformation to map scores to a [0, 1] range,\n    # ensuring that tight fits dominate but capacity bonus provides a nudge.\n    # Let's combine them linearly first and then apply a scaling/transformation.\n\n    combined_raw_scores = tight_fit_scores + capacity_bonus_scores\n\n    # Apply a sigmoid-like function to map scores to [0, 1] and create a smoother distribution.\n    # A simple approach is to scale and shift, or use np.tanh.\n    # Let's map the combined_raw_scores to a range and then use a function that\n    # emphasizes higher values. For simplicity, let's use a soft ranking.\n    # A softmax-like approach can also work to create relative priorities.\n\n    # Let's use a simple scaling and add noise for exploration.\n    # We want tight fits to be generally higher.\n    # A simple approach: score = tight_fit_score + bonus_for_large_capacity\n    # Let's rescale the tight_fit_scores to be in a higher range, e.g., [0.5, 1]\n    # and bonuses in [0, 0.1].\n\n    # Re-scaling tight fit scores to [0.5, 1.0]\n    scaled_tight_fit = 0.5 + 0.5 * tight_fit_scores\n    # Adding capacity bonus (scaled down)\n    final_fitting_scores = scaled_tight_fit + capacity_bonus_scores * 0.5 # Lower weight for bonus\n\n    # Add a small random component for exploration/stochasticity\n    exploration_noise = np.random.uniform(0, 0.05, size=len(final_fitting_scores))\n    final_fitting_scores += exploration_noise\n\n    # Assign these scores to the appropriate bins\n    priorities[fitting_indices] = final_fitting_scores\n\n    # Ensure non-fitting bins have 0 priority\n    priorities[~can_fit_mask] = 0.0\n\n    # Normalize priorities to [0, 1] for consistency if needed for specific algorithms,\n    # but for selection, relative values are what matter.\n    # If all fitting scores are 0 (which shouldn't happen if can_fit_mask is true and item fits),\n    # avoid division by zero.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n    else:\n        # This case should ideally not be reached if can_fit_mask has true values.\n        pass\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a balanced Softmax-Fit with flexibility.\n\n    This version aims to balance the \"tightest fit\" heuristic with a consideration\n    for \"future flexibility\". It uses a softmax-like approach to prioritize\n    bins that leave less remaining capacity after packing the item (tightest fit).\n    Additionally, it incorporates a small bonus for bins that, even after fitting\n    the item, still retain a substantial amount of remaining capacity, suggesting\n    they might be more useful for larger future items. This bonus is added to the\n    \"tightness\" score before the softmax transformation to influence the probabilities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # No bin can fit the item, return all zeros\n        return priorities\n\n    # --- Heuristic 1: Prioritize tightest fits (minimize remaining capacity) ---\n    # Calculate the remaining capacity after packing the item for fitting bins.\n    # Smaller values of `remaining_capacity_after_packing` are better.\n    remaining_capacity_after_packing = bins_remain_cap[can_fit_mask] - item\n\n    # To use with softmax (where higher input leads to higher probability),\n    # we want to transform this such that smaller remaining capacity yields a higher score.\n    # A simple way is to use the negative of the remaining capacity.\n    # We add a small epsilon to avoid zero if item perfectly fills a bin,\n    # and to slightly penalize perfect fits to allow other options if they exist.\n    # Let's use -(remaining_capacity_after_packing - epsilon) for a slightly\n    # better differentiation among tight fits.\n    # A very small epsilon like 1e-6 can help differentiate between bins with\n    # identical remaining capacities after packing if it's zero.\n    epsilon_tightness = 1e-6\n    tightness_scores = -(remaining_capacity_after_packing - epsilon_tightness)\n\n    # --- Heuristic 2: Bonus for future flexibility (larger remaining capacity) ---\n    # We want to add a bonus to bins that have more remaining capacity *after*\n    # the item is packed. This bonus should be less impactful than the tightness.\n    # A simple linear scaling of the remaining capacity after packing can work.\n    # We want to add a *positive* bonus to bins with *larger* remaining capacity.\n    # Let's scale `bins_remain_cap[can_fit_mask]` directly.\n    # The bonus should be smaller than the tightness score's contribution.\n    bonus_scale_factor = 0.1 # Controls the influence of flexibility\n    flexibility_bonus = bonus_scale_factor * bins_remain_cap[can_fit_mask]\n\n    # Combine the tightness score and flexibility bonus.\n    # The bonus is added to the tightness score.\n    combined_scores = tightness_scores + flexibility_bonus\n\n    # Apply softmax-like transformation to get probabilities.\n    # For numerical stability, subtract the maximum score before exponentiation.\n    max_combined_score = np.max(combined_scores)\n    exp_scores = np.exp(combined_scores - max_combined_score)\n\n    sum_exp_scores = np.sum(exp_scores)\n\n    if sum_exp_scores > 1e-9:  # Check for numerical stability\n        priorities[can_fit_mask] = exp_scores / sum_exp_scores\n    else:\n        # If all scores are extremely negative (or zero), resulting in near-zero\n        # exponentials, distribute probability equally among bins that can fit.\n        num_fitting_bins = np.sum(can_fit_mask)\n        if num_fitting_bins > 0:\n            priorities[can_fit_mask] = 1.0 / num_fitting_bins\n\n    return priorities\n\n[Reflection]\nBalance tightness with flexibility, use softmax for probabilities, and consider scaling factors.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}