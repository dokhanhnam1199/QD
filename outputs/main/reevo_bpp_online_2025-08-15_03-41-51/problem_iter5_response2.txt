```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin.

    This version aims to balance tight fits with future flexibility using a
    sigmoid-like function. It also incorporates a small bonus for larger
    remaining capacities to encourage more even distribution.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher scores indicate higher priority.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # If no bins can fit the item, return all zeros
    if not np.any(can_fit_mask):
        return priorities

    # --- Heuristic Calculation ---
    # For bins that can fit the item, calculate a priority score.
    # The score is a combination of how tightly it fits and a bonus for larger capacities.

    # Calculate the "tightness" score: smaller remaining capacity after packing is better.
    # We want to penalize bins with very large remaining capacity if they are too large.
    # A sigmoid-like function can map the "waste" (remaining_cap - item) to a priority.
    # Smaller waste -> higher priority. We want to avoid large positive waste values.
    # Let's consider the inverse: remaining_cap. Higher remaining_cap might be worse for tightness.
    # A function that is high for small remaining_cap and low for large remaining_cap.
    # We can use a transformation like 1 / (1 + x) or exp(-x).
    # Let's use a function that is high when remaining_cap is just above 'item'.

    # Option 1: Focus on minimal remaining capacity (tightest fit)
    # We want bins where `bins_remain_cap - item` is minimized.
    # Let's map `bins_remain_cap` directly. High priority for small `bins_remain_cap` if they fit.
    # Softmax or sigmoid can be good here. Let's use a scaled inverse of remaining capacity
    # and add a small bonus for larger capacities to encourage distribution.

    # Calculate the actual remaining capacity after packing
    remaining_after_packing = bins_remain_cap[can_fit_mask] - item

    # We want smaller `remaining_after_packing` to have higher priority (tight fit).
    # Let's use a scaled inverse relationship.
    # To avoid division by zero or very small numbers, add a small epsilon.
    epsilon_small = 1e-6
    tightness_scores = 1.0 / (remaining_after_packing + epsilon_small)

    # Add a small bonus for larger *original* remaining capacities to encourage spreading.
    # This bonus should be smaller than the tightness score.
    # Let's scale the original `bins_remain_cap` for the bonus.
    # The bonus should be higher for larger capacities.
    larger_capacity_bonus = bins_remain_cap[can_fit_mask] / np.max(bins_remain_cap[can_fit_mask] + epsilon_small)
    bonus_weight = 0.2  # Controls how much the bonus affects the score

    # Combine tightness and bonus. The tightness should dominate.
    # We can use a weighted sum.
    combined_scores = tightness_scores + bonus_weight * larger_capacity_bonus

    # Normalize combined_scores to be between 0 and 1 for better interpretability/stability
    if np.max(combined_scores) > 0:
        normalized_combined_scores = combined_scores / np.max(combined_scores)
    else:
        normalized_combined_scores = np.zeros_like(combined_scores)


    # Assign these normalized scores to the priorities array for the fitting bins
    priorities[can_fit_mask] = normalized_combined_scores

    # Ensure bins that cannot fit have zero priority
    priorities[~can_fit_mask] = 0.0

    # Optional: Add a small random noise to break ties and encourage exploration
    # This is similar to the epsilon-greedy idea but applied to the output scores.
    # Add small random noise to all bins that can fit.
    if np.any(can_fit_mask):
        noise_magnitude = 0.05  # Small magnitude for noise
        noise = np.random.uniform(-noise_magnitude, noise_magnitude, size=priorities[can_fit_mask].shape)
        priorities[can_fit_mask] += noise
        # Ensure priorities remain non-negative after adding noise
        priorities[can_fit_mask] = np.maximum(0.0, priorities[can_fit_mask])

    # Final normalization to ensure scores are in a reasonable range and the max is 1
    if np.max(priorities) > 0:
        priorities = priorities / np.max(priorities)
    else:
        # If all bins are still 0 (e.g., item too large for all), they remain 0.
        pass

    return priorities
```
