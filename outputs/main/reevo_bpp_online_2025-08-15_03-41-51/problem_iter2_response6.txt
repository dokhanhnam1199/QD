```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Tunable Sigmoid Fit Score.

    This version introduces a tunable parameter `steepness` to control how quickly the
    priority score drops as the gap (remaining capacity - item size) increases.
    It also adds a small offset to the sigmoid argument to slightly favor bins that
    are not perfectly filled, potentially leaving more room for future items.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Initialize priorities to a very low value for bins that cannot fit the item.
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Identify bins that can accommodate the item
    possible_bins_mask = bins_remain_cap >= item

    if not np.any(possible_bins_mask):
        # No bin can fit the item, return all negative infinities.
        return priorities

    # Calculate the "gap" for possible bins (how much space is left after placing the item)
    gaps = bins_remain_cap[possible_bins_mask] - item

    # Tunable parameter to control the steepness of the sigmoid.
    # A higher value means the priority drops more sharply as the gap increases.
    # A value of 0 would make all fitting bins have a score of 0.5 (if offset is 0).
    steepness = 10.0  # Increased steepness for more distinct prioritization

    # Introduce a small negative offset to the argument.
    # This means that a gap of 0 (perfect fit) will result in sigmoid(-offset),
    # which is slightly less than 0.5. Larger gaps will result in scores even further below 0.5.
    # This can encourage using bins that have a small positive gap, potentially
    # leaving perfectly filled bins for smaller items if available.
    # Experimentation is needed to find the optimal offset.
    # Let's try to make the "ideal" gap slightly positive, e.g., `optimal_gap = 0.1 * item`.
    # We want `steepness * (optimal_gap - gap)` to be around 0.
    # `steepness * (0.1 * item - gap)`
    # This means we want `gap` to be slightly less than `0.1 * item` for highest priority.
    # Or, let's consider the argument `steepness * (item - bins_remain_cap[i])`.
    # We want this to be high when `bins_remain_cap[i]` is slightly larger than `item`.
    # Let's scale the negative gap by `steepness`.
    # `sigmoid_arg = steepness * (item - bins_remain_cap[possible_bins_mask])`
    # `sigmoid_arg = -steepness * (bins_remain_cap[possible_bins_mask] - item)`
    # This assigns 0.5 to a perfect fit, lower to larger gaps, and higher to negative gaps (not possible here).
    #
    # To slightly prefer bins that are NOT perfectly filled, we can shift the sigmoid.
    # Let's aim for the peak priority to be at a small positive gap.
    # Consider `sigmoid(k * (ideal_gap - current_gap))`.
    # If we want `ideal_gap = 0`, this is `sigmoid(k * -gap)`.
    #
    # Let's consider a function that rewards tightness: `f(gap)`.
    # `f(gap) = exp(-steepness * gap)` could be an alternative, but it's not bounded between 0 and 1.
    #
    # Let's stick to the sigmoid but adjust the argument.
    # We want to prioritize smaller gaps. `sigmoid(-steepness * gap)` does this, with peak at 0.5.
    # To shift the peak to a small positive gap `g_ideal`, we can use `sigmoid(steepness * (g_ideal - gap))`.
    # Let's choose `g_ideal` to be a small fraction of the item size, e.g., 10% of item size.
    # This introduces a dependency on the item size, which might be complex.
    #
    # A simpler approach: use `sigmoid(-steepness * gap)` and then scale or offset the output.
    # Or, slightly modify the input:
    # Let's aim for the highest priority when `bins_remain_cap[i] - item` is small and positive.
    # We can use `sigmoid(A - B * gap)` where `A` shifts the curve and `B` controls steepness.
    # If we want the peak at `gap = 0`, then `A = 0` works (for `sigmoid(B * (-gap))`).
    #
    # To reward slightly less full bins, let's try to make the score decrease faster.
    # Let's modify the sigmoid argument:
    # Instead of just `-steepness * gap`, consider `-steepness * gap - offset`.
    # This shifts the entire curve to the left.
    # For `gap = 0`, the argument becomes `-offset`. `sigmoid(-offset)` is < 0.5.
    # This means perfect fits get lower scores than before.
    #
    # The goal is to rank bins. The absolute values don't matter as much as the relative order.
    # `sigmoid(-steepness * gap)` already provides a good ranking for "tightest fit".
    #
    # Let's introduce a small constant to the sigmoid argument to shift the peak.
    # A small positive constant in `sigmoid(-steepness * gap + const)` will increase scores for all gaps.
    # A small negative constant `const` will decrease scores.
    #
    # Let's reconsider the goal: prioritize bins that are "almost full" but can still fit.
    # This means `bins_remain_cap[i]` should be minimized, subject to `bins_remain_cap[i] >= item`.
    #
    # Consider the inverse of the gap, but normalized.
    # Let `normalized_gap = gap / max_possible_gap`. This is still problematic if max_possible_gap is 0.
    #
    # Let's try a simple scaling of the gap and an offset.
    # `sigmoid_input = steepness * (item - bins_remain_cap[possible_bins_mask])`
    # `sigmoid_input = -steepness * gaps`
    #
    # Let's add a small bias to favor bins that are not completely full.
    # This is to avoid situations where a bin is filled to absolute capacity, potentially
    # making it unusable for even the smallest future items.
    # A small positive value `epsilon` added to the `item` size might simulate this.
    # `effective_item_size = item + epsilon`
    # `gaps_adjusted = bins_remain_cap[possible_bins_mask] - effective_item_size`
    # `sigmoid_arg = -steepness * gaps_adjusted`
    #
    # Let's try a simple adjustment to the input of the sigmoid:
    # Instead of `sigmoid(-steepness * gap)`, let's use `sigmoid(-steepness * gap + adjustment)`.
    # If `adjustment` is positive, it pushes scores higher for all gaps.
    # If `adjustment` is negative, it pushes scores lower.
    #
    # Let's try to favor bins with a small positive gap, say up to `item * 0.1`.
    # We want the score to be high in this range.
    #
    # Let's use `sigmoid(k * (target_capacity - current_remaining_capacity))`
    # Target capacity should be `item`. So, `sigmoid(k * (item - bins_remain_cap[i]))`.
    # This is `sigmoid(-k * gap)`.
    #
    # To slightly favor bins with a small positive gap (e.g., `gap = 0.1 * item`),
    # we want the input to sigmoid to be slightly positive.
    # `sigmoid(k * (ideal_gap - gap))`. If `ideal_gap = 0.1 * item`, and `gap` is a bit smaller.
    #
    # Let's use a simpler approach that's common: scale the gap.
    # `scaled_gap = gap / item` (if item > 0). This makes it relative.
    # Then `sigmoid(-steepness * scaled_gap)`.
    # This way, the "tightness" is relative to the item size.
    #
    # Let's try to slightly penalize perfect fits (gap=0) to encourage slight overflow.
    # This means the peak of our priority function should be at a small positive gap.
    # We can achieve this by shifting the sigmoid input.
    # `sigmoid(steepness * (ideal_gap - gap))`
    # Let `ideal_gap = 0.05 * item` (a small fraction of the item size).
    #
    # If item is 0, this formula would be problematic.
    # Let's assume item > 0.
    #
    # `ideal_gap = 0.05 * item`
    # `sigmoid_arg = steepness * (ideal_gap - gaps)`
    #
    # Example: item = 10. steepness = 10. ideal_gap = 0.5.
    # If gap = 0.1 (bin cap = 10.1): sigmoid_arg = 10 * (0.5 - 0.1) = 4.0. Score = sigmoid(4.0) ~ 0.98
    # If gap = 0.5 (bin cap = 10.5): sigmoid_arg = 10 * (0.5 - 0.5) = 0.0. Score = sigmoid(0.0) = 0.5
    # If gap = 1.0 (bin cap = 11.0): sigmoid_arg = 10 * (0.5 - 1.0) = -5.0. Score = sigmoid(-5.0) ~ 0.007
    # If gap = 0.0 (bin cap = 10.0): sigmoid_arg = 10 * (0.5 - 0.0) = 5.0. Score = sigmoid(5.0) ~ 0.993 (Oops, perfect fit is highest!)

    # The goal is usually to fill bins as much as possible. So tightest fit is preferred.
    # Let's go back to prioritizing the minimum non-negative gap.
    # `sigmoid(-steepness * gap)` where peak is at gap=0.
    #
    # To make `priority_v2` distinct and tunable, let's introduce a parameter
    # that influences the "ideal" tightness.
    #
    # `fit_preference`:
    # - `fit_preference = 0`: Prioritize bins that are exactly full (gap = 0).
    # - `fit_preference = 1`: Prioritize bins that are somewhat full, but leave a small buffer (e.g., gap = 5% of item size).
    # - `fit_preference = -1`: Prioritize bins that are less full (larger gaps). This is generally not good.

    # Let's aim for `fit_preference` to control the "ideal gap".
    # `ideal_gap = fit_preference * item * 0.1` (0.1 is a scaling factor for preference strength)
    # If `fit_preference = 0`, `ideal_gap = 0`.
    # If `fit_preference = 1`, `ideal_gap = 0.1 * item`.
    # If `fit_preference = -1`, `ideal_gap = -0.1 * item` (problematic, means item must be smaller than capacity).

    # Let's simplify: use `steepness` and a fixed adjustment that shifts the peak slightly.
    # `sigmoid(-steepness * gap)` has peak at `gap = 0`.
    # To shift the peak to `gap = ideal_gap`, use `sigmoid(steepness * (ideal_gap - gap))`.
    #
    # Let's define `ideal_gap` as a fraction of the item size.
    # `ideal_gap_fraction = 0.05`  # Aim for a gap that's 5% of the item's size
    # `ideal_gap = ideal_gap_fraction * item`
    #
    # Ensure `ideal_gap` is not negative and not larger than typical gaps.
    # `ideal_gap = max(0.0, ideal_gap)` # Ensure non-negative

    # The core idea of Sigmoid Fit Score is to rank by tightness.
    # `sigmoid(-steepness * gap)` achieves this with peak at `gap=0`.
    # The "improvement" can be in the tuning of `steepness` and potentially
    # how we normalize or bound the `gap` for the sigmoid input.

    # Let's consider a robust scaling of the gap:
    # `scaled_gap = gap / max(1, item)` # Avoid division by zero and scale by item size.
    # This makes the priority sensitive to the relative tightness.
    # Then `sigmoid(-steepness * scaled_gap)`.
    #
    # Let's try a combination: `steepness` for sensitivity and a small `gap_offset`
    # to slightly shift the priority away from perfect fits.

    # Parameter to control how sensitive the priority is to the gap.
    # Higher value means smaller gaps are much more preferred than larger gaps.
    steepness = 15.0

    # Parameter to slightly offset the ideal fit.
    # A positive `gap_preference_offset` means we slightly prefer bins that are NOT perfectly filled.
    # A negative offset would strongly prefer perfectly filled bins.
    # Let's try to prefer bins where the remaining capacity is just slightly larger than the item.
    # This corresponds to a small positive gap.
    # If `gap = 0`, we want the input to sigmoid to be low.
    # If `gap = ideal_gap > 0`, we want the input to sigmoid to be close to 0.
    # So, `k * (ideal_gap - gap)`.
    #
    # Let's use `gap` directly, but adjust the sigmoid mapping.
    # `sigmoid_arg = -steepness * gaps` -> peak at gap = 0.
    #
    # Alternative: `1 - sigmoid(steepness * gaps)` -> peak at gap = 0.
    #
    # Consider `max(0, 1 - steepness * gaps)` -- not smooth.

    # Let's stick to sigmoid and tune its input:
    # `sigmoid(steepness * (B - A * gap))` where B is offset and A is steepness multiplier.
    # `sigmoid(steepness * (0.1 - gap))` -- this is very dependent on scale.
    #
    # A common approach is to normalize the gap:
    # `normalized_gap = gap / max_capacity_of_bin` (but capacity is fixed, remaining varies)
    #
    # Let's use a simple sigmoid where `steepness` controls the curve.
    # And we can add a small constant to the sigmoid argument to nudge it.
    # `sigmoid_arg = -steepness * gaps + bias`
    # `bias = 0.0` means peak at `gap = 0`.
    # `bias = 1.0` means `sigmoid(-steepness * gap + 1.0)`.
    # If `gap=0`, arg = 1.0, score = sigmoid(1.0) > 0.5.
    # If `gap=0.1`, arg = -steepness*0.1 + 1.0. If steepness=10, arg=0.0, score=0.5.
    # So, `bias` shifts the point where score is 0.5.
    #
    # Let's make `steepness` and `bias` tunable.
    steepness = 20.0  # Higher steepness for better discrimination
    bias = 0.2        # Shift the sigmoid to favor slightly larger gaps (less than perfect fits)

    # Calculate the argument for the sigmoid function
    # We want to penalize larger gaps, so `gaps` should be subtracted from something.
    # `bias - steepness * gaps`
    # If gap is small positive, `bias - steepness * gap` is positive and large (if gap is much smaller than bias/steepness).
    # If gap is 0, arg = bias.
    # If gap is larger than `bias/steepness`, arg becomes negative.
    sigmoid_arg = bias - steepness * gaps

    # Apply the sigmoid function to get priorities
    # `1 / (1 + exp(-x))` maps values to [0, 1].
    # For `gap = 0`, score = `sigmoid(bias)`.
    # For `gap = bias / steepness`, score = `sigmoid(0) = 0.5`.
    # For `gap > bias / steepness`, score < 0.5.
    # This means bins with gaps larger than `bias / steepness` get lower scores.
    # Higher `bias` means higher scores for all gaps, and a higher gap is needed for score 0.5.
    priorities[possible_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg))

    return priorities
```
