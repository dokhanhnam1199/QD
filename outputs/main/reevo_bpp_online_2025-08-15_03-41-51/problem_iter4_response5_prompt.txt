{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority scores for each bin to pack an item, prioritizing tighter fits\n    with a slight bonus for larger remaining capacities for future flexibility.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element is the remaining capacity\n                         of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, containing priority\n        scores for each bin. Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, all priorities remain 0.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Filter to consider only bins that can fit the item\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    fitting_bin_indices = np.where(can_fit_mask)[0]\n\n    # --- Heuristic Calculation ---\n    # Prioritize bins with minimal remaining capacity (tightest fits)\n    # Use a sigmoid-like function to give higher priority to tighter fits,\n    # but with a gradual decrease rather than a sharp cutoff.\n    # We use 1 / (1 + exp(-(x - center) / scale)))\n    # Here, 'x' is related to how much capacity is left *after* placing the item.\n    # Smaller remaining capacity after placement (i.e., tighter fit) should have higher priority.\n    # So, we want to map small (fitting_bins_caps - item) values to high priority.\n\n    # Calculate remaining capacity after placing the item\n    remaining_after_placement = fitting_bins_caps - item\n\n    # Define parameters for the sigmoid-like function for tightness\n    # 'center' can be set around the median of the 'remaining_after_placement' values\n    # or a small value to emphasize very tight fits.\n    # 'scale' controls the steepness of the transition.\n    tightness_scores = np.zeros_like(fitting_bins_caps)\n    if len(remaining_after_placement) > 0:\n        # A simple approach: map 0 remaining capacity to highest priority.\n        # A slightly more sophisticated approach could use a sigmoid.\n        # Let's use a simple inverse relationship with a small offset to avoid division by zero.\n        # And add a small bonus for larger capacities to balance.\n\n        # Calculate a 'tightness' score: higher is tighter fit (closer to 0)\n        # Normalize remaining_after_placement to be between 0 and 1 (relative to max possible remaining)\n        # or use a fixed scale. A simpler approach:\n        # Higher priority for smaller remaining_after_placement.\n        # Adding a small constant to avoid division by zero or extremely high values for 0 remaining.\n        tightness_factor = 1.0 / (remaining_after_placement + 0.1)\n\n        # Bonus for larger remaining capacities (exploration/flexibility):\n        # This gives a slight boost to bins that still have significant space left,\n        # even if they aren't the tightest fit. This can help avoid packing\n        # items in a way that leaves very little space in many bins.\n        # Normalize fitting_bins_caps to get a relative sense of large capacity.\n        # We can add a scaled version of the remaining capacity itself.\n        # Ensure we don't add too much to the tightest fits.\n        flexibility_bonus_scale = 0.1 # Controls how much this bonus influences the priority\n        flexibility_factor = fitting_bins_caps / np.max(fitting_bins_caps) * flexibility_bonus_scale if np.max(fitting_bins_caps) > 0 else 0\n\n        # Combine tightness and flexibility.\n        # Tightness is the primary driver.\n        combined_priority_values = tightness_factor + flexibility_factor\n        priorities[fitting_bin_indices] = combined_priority_values\n\n        # Normalize priorities so the max is 1.0 for easier interpretation and selection.\n        if np.max(priorities) > 0:\n            priorities = priorities / np.max(priorities)\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Tunable Sigmoid Fit Score.\n\n    This version introduces a tunable parameter `steepness` to control how quickly the\n    priority score drops as the gap (remaining capacity - item size) increases.\n    It also adds a small offset to the sigmoid argument to slightly favor bins that\n    are not perfectly filled, potentially leaving more room for future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item\n    possible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(possible_bins_mask):\n        # No bin can fit the item, return all negative infinities.\n        return priorities\n\n    # Calculate the \"gap\" for possible bins (how much space is left after placing the item)\n    gaps = bins_remain_cap[possible_bins_mask] - item\n\n    # Tunable parameter to control the steepness of the sigmoid.\n    # A higher value means the priority drops more sharply as the gap increases.\n    # A value of 0 would make all fitting bins have a score of 0.5 (if offset is 0).\n    steepness = 10.0  # Increased steepness for more distinct prioritization\n\n    # Introduce a small negative offset to the argument.\n    # This means that a gap of 0 (perfect fit) will result in sigmoid(-offset),\n    # which is slightly less than 0.5. Larger gaps will result in scores even further below 0.5.\n    # This can encourage using bins that have a small positive gap, potentially\n    # leaving perfectly filled bins for smaller items if available.\n    # Experimentation is needed to find the optimal offset.\n    # Let's try to make the \"ideal\" gap slightly positive, e.g., `optimal_gap = 0.1 * item`.\n    # We want `steepness * (optimal_gap - gap)` to be around 0.\n    # `steepness * (0.1 * item - gap)`\n    # This means we want `gap` to be slightly less than `0.1 * item` for highest priority.\n    # Or, let's consider the argument `steepness * (item - bins_remain_cap[i])`.\n    # We want this to be high when `bins_remain_cap[i]` is slightly larger than `item`.\n    # Let's scale the negative gap by `steepness`.\n    # `sigmoid_arg = steepness * (item - bins_remain_cap[possible_bins_mask])`\n    # `sigmoid_arg = -steepness * (bins_remain_cap[possible_bins_mask] - item)`\n    # This assigns 0.5 to a perfect fit, lower to larger gaps, and higher to negative gaps (not possible here).\n    #\n    # To slightly prefer bins that are NOT perfectly filled, we can shift the sigmoid.\n    # Let's aim for the peak priority to be at a small positive gap.\n    # Consider `sigmoid(k * (ideal_gap - current_gap))`.\n    # If we want `ideal_gap = 0`, this is `sigmoid(k * -gap)`.\n    #\n    # Let's consider a function that rewards tightness: `f(gap)`.\n    # `f(gap) = exp(-steepness * gap)` could be an alternative, but it's not bounded between 0 and 1.\n    #\n    # Let's stick to the sigmoid but adjust the argument.\n    # We want to prioritize smaller gaps. `sigmoid(-steepness * gap)` does this, with peak at 0.5.\n    # To shift the peak to a small positive gap `g_ideal`, we can use `sigmoid(steepness * (g_ideal - gap))`.\n    # Let's choose `g_ideal` to be a small fraction of the item size, e.g., 10% of item size.\n    # This introduces a dependency on the item size, which might be complex.\n    #\n    # A simpler approach: use `sigmoid(-steepness * gap)` and then scale or offset the output.\n    # Or, slightly modify the input:\n    # Let's aim for the highest priority when `bins_remain_cap[i] - item` is small and positive.\n    # We can use `sigmoid(A - B * gap)` where `A` shifts the curve and `B` controls steepness.\n    # If we want the peak at `gap = 0`, then `A = 0` works (for `sigmoid(B * (-gap))`).\n    #\n    # To reward slightly less full bins, let's try to make the score decrease faster.\n    # Let's modify the sigmoid argument:\n    # Instead of just `-steepness * gap`, consider `-steepness * gap - offset`.\n    # This shifts the entire curve to the left.\n    # For `gap = 0`, the argument becomes `-offset`. `sigmoid(-offset)` is < 0.5.\n    # This means perfect fits get lower scores than before.\n    #\n    # The goal is to rank bins. The absolute values don't matter as much as the relative order.\n    # `sigmoid(-steepness * gap)` already provides a good ranking for \"tightest fit\".\n    #\n    # Let's introduce a small constant to the sigmoid argument to shift the peak.\n    # A small positive constant in `sigmoid(-steepness * gap + const)` will increase scores for all gaps.\n    # A small negative constant `const` will decrease scores.\n    #\n    # Let's reconsider the goal: prioritize bins that are \"almost full\" but can still fit.\n    # This means `bins_remain_cap[i]` should be minimized, subject to `bins_remain_cap[i] >= item`.\n    #\n    # Consider the inverse of the gap, but normalized.\n    # Let `normalized_gap = gap / max_possible_gap`. This is still problematic if max_possible_gap is 0.\n    #\n    # Let's try a simple scaling of the gap and an offset.\n    # `sigmoid_input = steepness * (item - bins_remain_cap[possible_bins_mask])`\n    # `sigmoid_input = -steepness * gaps`\n    #\n    # Let's add a small bias to favor bins that are not completely full.\n    # This is to avoid situations where a bin is filled to absolute capacity, potentially\n    # making it unusable for even the smallest future items.\n    # A small positive value `epsilon` added to the `item` size might simulate this.\n    # `effective_item_size = item + epsilon`\n    # `gaps_adjusted = bins_remain_cap[possible_bins_mask] - effective_item_size`\n    # `sigmoid_arg = -steepness * gaps_adjusted`\n    #\n    # Let's try a simple adjustment to the input of the sigmoid:\n    # Instead of `sigmoid(-steepness * gap)`, let's use `sigmoid(-steepness * gap + adjustment)`.\n    # If `adjustment` is positive, it pushes scores higher for all gaps.\n    # If `adjustment` is negative, it pushes scores lower.\n    #\n    # Let's try to favor bins with a small positive gap, say up to `item * 0.1`.\n    # We want the score to be high in this range.\n    #\n    # Let's use `sigmoid(k * (target_capacity - current_remaining_capacity))`\n    # Target capacity should be `item`. So, `sigmoid(k * (item - bins_remain_cap[i]))`.\n    # This is `sigmoid(-k * gap)`.\n    #\n    # To slightly favor bins with a small positive gap (e.g., `gap = 0.1 * item`),\n    # we want the input to sigmoid to be slightly positive.\n    # `sigmoid(k * (ideal_gap - gap))`. If `ideal_gap = 0.1 * item`, and `gap` is a bit smaller.\n    #\n    # Let's use a simpler approach that's common: scale the gap.\n    # `scaled_gap = gap / item` (if item > 0). This makes it relative.\n    # Then `sigmoid(-steepness * scaled_gap)`.\n    # This way, the \"tightness\" is relative to the item size.\n    #\n    # Let's try to slightly penalize perfect fits (gap=0) to encourage slight overflow.\n    # This means the peak of our priority function should be at a small positive gap.\n    # We can achieve this by shifting the sigmoid input.\n    # `sigmoid(steepness * (ideal_gap - gap))`\n    # Let `ideal_gap = 0.05 * item` (a small fraction of the item size).\n    #\n    # If item is 0, this formula would be problematic.\n    # Let's assume item > 0.\n    #\n    # `ideal_gap = 0.05 * item`\n    # `sigmoid_arg = steepness * (ideal_gap - gaps)`\n    #\n    # Example: item = 10. steepness = 10. ideal_gap = 0.5.\n    # If gap = 0.1 (bin cap = 10.1): sigmoid_arg = 10 * (0.5 - 0.1) = 4.0. Score = sigmoid(4.0) ~ 0.98\n    # If gap = 0.5 (bin cap = 10.5): sigmoid_arg = 10 * (0.5 - 0.5) = 0.0. Score = sigmoid(0.0) = 0.5\n    # If gap = 1.0 (bin cap = 11.0): sigmoid_arg = 10 * (0.5 - 1.0) = -5.0. Score = sigmoid(-5.0) ~ 0.007\n    # If gap = 0.0 (bin cap = 10.0): sigmoid_arg = 10 * (0.5 - 0.0) = 5.0. Score = sigmoid(5.0) ~ 0.993 (Oops, perfect fit is highest!)\n\n    # The goal is usually to fill bins as much as possible. So tightest fit is preferred.\n    # Let's go back to prioritizing the minimum non-negative gap.\n    # `sigmoid(-steepness * gap)` where peak is at gap=0.\n    #\n    # To make `priority_v2` distinct and tunable, let's introduce a parameter\n    # that influences the \"ideal\" tightness.\n    #\n    # `fit_preference`:\n    # - `fit_preference = 0`: Prioritize bins that are exactly full (gap = 0).\n    # - `fit_preference = 1`: Prioritize bins that are somewhat full, but leave a small buffer (e.g., gap = 5% of item size).\n    # - `fit_preference = -1`: Prioritize bins that are less full (larger gaps). This is generally not good.\n\n    # Let's aim for `fit_preference` to control the \"ideal gap\".\n    # `ideal_gap = fit_preference * item * 0.1` (0.1 is a scaling factor for preference strength)\n    # If `fit_preference = 0`, `ideal_gap = 0`.\n    # If `fit_preference = 1`, `ideal_gap = 0.1 * item`.\n    # If `fit_preference = -1`, `ideal_gap = -0.1 * item` (problematic, means item must be smaller than capacity).\n\n    # Let's simplify: use `steepness` and a fixed adjustment that shifts the peak slightly.\n    # `sigmoid(-steepness * gap)` has peak at `gap = 0`.\n    # To shift the peak to `gap = ideal_gap`, use `sigmoid(steepness * (ideal_gap - gap))`.\n    #\n    # Let's define `ideal_gap` as a fraction of the item size.\n    # `ideal_gap_fraction = 0.05`  # Aim for a gap that's 5% of the item's size\n    # `ideal_gap = ideal_gap_fraction * item`\n    #\n    # Ensure `ideal_gap` is not negative and not larger than typical gaps.\n    # `ideal_gap = max(0.0, ideal_gap)` # Ensure non-negative\n\n    # The core idea of Sigmoid Fit Score is to rank by tightness.\n    # `sigmoid(-steepness * gap)` achieves this with peak at `gap=0`.\n    # The \"improvement\" can be in the tuning of `steepness` and potentially\n    # how we normalize or bound the `gap` for the sigmoid input.\n\n    # Let's consider a robust scaling of the gap:\n    # `scaled_gap = gap / max(1, item)` # Avoid division by zero and scale by item size.\n    # This makes the priority sensitive to the relative tightness.\n    # Then `sigmoid(-steepness * scaled_gap)`.\n    #\n    # Let's try a combination: `steepness` for sensitivity and a small `gap_offset`\n    # to slightly shift the priority away from perfect fits.\n\n    # Parameter to control how sensitive the priority is to the gap.\n    # Higher value means smaller gaps are much more preferred than larger gaps.\n    steepness = 15.0\n\n    # Parameter to slightly offset the ideal fit.\n    # A positive `gap_preference_offset` means we slightly prefer bins that are NOT perfectly filled.\n    # A negative offset would strongly prefer perfectly filled bins.\n    # Let's try to prefer bins where the remaining capacity is just slightly larger than the item.\n    # This corresponds to a small positive gap.\n    # If `gap = 0`, we want the input to sigmoid to be low.\n    # If `gap = ideal_gap > 0`, we want the input to sigmoid to be close to 0.\n    # So, `k * (ideal_gap - gap)`.\n    #\n    # Let's use `gap` directly, but adjust the sigmoid mapping.\n    # `sigmoid_arg = -steepness * gaps` -> peak at gap = 0.\n    #\n    # Alternative: `1 - sigmoid(steepness * gaps)` -> peak at gap = 0.\n    #\n    # Consider `max(0, 1 - steepness * gaps)` -- not smooth.\n\n    # Let's stick to sigmoid and tune its input:\n    # `sigmoid(steepness * (B - A * gap))` where B is offset and A is steepness multiplier.\n    # `sigmoid(steepness * (0.1 - gap))` -- this is very dependent on scale.\n    #\n    # A common approach is to normalize the gap:\n    # `normalized_gap = gap / max_capacity_of_bin` (but capacity is fixed, remaining varies)\n    #\n    # Let's use a simple sigmoid where `steepness` controls the curve.\n    # And we can add a small constant to the sigmoid argument to nudge it.\n    # `sigmoid_arg = -steepness * gaps + bias`\n    # `bias = 0.0` means peak at `gap = 0`.\n    # `bias = 1.0` means `sigmoid(-steepness * gap + 1.0)`.\n    # If `gap=0`, arg = 1.0, score = sigmoid(1.0) > 0.5.\n    # If `gap=0.1`, arg = -steepness*0.1 + 1.0. If steepness=10, arg=0.0, score=0.5.\n    # So, `bias` shifts the point where score is 0.5.\n    #\n    # Let's make `steepness` and `bias` tunable.\n    steepness = 20.0  # Higher steepness for better discrimination\n    bias = 0.2        # Shift the sigmoid to favor slightly larger gaps (less than perfect fits)\n\n    # Calculate the argument for the sigmoid function\n    # We want to penalize larger gaps, so `gaps` should be subtracted from something.\n    # `bias - steepness * gaps`\n    # If gap is small positive, `bias - steepness * gap` is positive and large (if gap is much smaller than bias/steepness).\n    # If gap is 0, arg = bias.\n    # If gap is larger than `bias/steepness`, arg becomes negative.\n    sigmoid_arg = bias - steepness * gaps\n\n    # Apply the sigmoid function to get priorities\n    # `1 / (1 + exp(-x))` maps values to [0, 1].\n    # For `gap = 0`, score = `sigmoid(bias)`.\n    # For `gap = bias / steepness`, score = `sigmoid(0) = 0.5`.\n    # For `gap > bias / steepness`, score < 0.5.\n    # This means bins with gaps larger than `bias / steepness` get lower scores.\n    # Higher `bias` means higher scores for all gaps, and a higher gap is needed for score 0.5.\n    priorities[possible_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg))\n\n    return priorities\n\n[Reflection]\nTune sigmoid parameters for desired tightness and flexibility trade-off.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}