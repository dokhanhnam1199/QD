```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a balanced Softmax-Fit with flexibility.

    This version aims to balance the "tightest fit" heuristic with a consideration
    for "future flexibility". It uses a softmax-like approach to prioritize
    bins that leave less remaining capacity after packing the item (tightest fit).
    Additionally, it incorporates a small bonus for bins that, even after fitting
    the item, still retain a substantial amount of remaining capacity, suggesting
    they might be more useful for larger future items. This bonus is added to the
    "tightness" score before the softmax transformation to influence the probabilities.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher scores indicate higher priority.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        # No bin can fit the item, return all zeros
        return priorities

    # --- Heuristic 1: Prioritize tightest fits (minimize remaining capacity) ---
    # Calculate the remaining capacity after packing the item for fitting bins.
    # Smaller values of `remaining_capacity_after_packing` are better.
    remaining_capacity_after_packing = bins_remain_cap[can_fit_mask] - item

    # To use with softmax (where higher input leads to higher probability),
    # we want to transform this such that smaller remaining capacity yields a higher score.
    # A simple way is to use the negative of the remaining capacity.
    # We add a small epsilon to avoid zero if item perfectly fills a bin,
    # and to slightly penalize perfect fits to allow other options if they exist.
    # Let's use -(remaining_capacity_after_packing - epsilon) for a slightly
    # better differentiation among tight fits.
    # A very small epsilon like 1e-6 can help differentiate between bins with
    # identical remaining capacities after packing if it's zero.
    epsilon_tightness = 1e-6
    tightness_scores = -(remaining_capacity_after_packing - epsilon_tightness)

    # --- Heuristic 2: Bonus for future flexibility (larger remaining capacity) ---
    # We want to add a bonus to bins that have more remaining capacity *after*
    # the item is packed. This bonus should be less impactful than the tightness.
    # A simple linear scaling of the remaining capacity after packing can work.
    # We want to add a *positive* bonus to bins with *larger* remaining capacity.
    # Let's scale `bins_remain_cap[can_fit_mask]` directly.
    # The bonus should be smaller than the tightness score's contribution.
    bonus_scale_factor = 0.1 # Controls the influence of flexibility
    flexibility_bonus = bonus_scale_factor * bins_remain_cap[can_fit_mask]

    # Combine the tightness score and flexibility bonus.
    # The bonus is added to the tightness score.
    combined_scores = tightness_scores + flexibility_bonus

    # Apply softmax-like transformation to get probabilities.
    # For numerical stability, subtract the maximum score before exponentiation.
    max_combined_score = np.max(combined_scores)
    exp_scores = np.exp(combined_scores - max_combined_score)

    sum_exp_scores = np.sum(exp_scores)

    if sum_exp_scores > 1e-9:  # Check for numerical stability
        priorities[can_fit_mask] = exp_scores / sum_exp_scores
    else:
        # If all scores are extremely negative (or zero), resulting in near-zero
        # exponentials, distribute probability equally among bins that can fit.
        num_fitting_bins = np.sum(can_fit_mask)
        if num_fitting_bins > 0:
            priorities[can_fit_mask] = 1.0 / num_fitting_bins

    return priorities
```
