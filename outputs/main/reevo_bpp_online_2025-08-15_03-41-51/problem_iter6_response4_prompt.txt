{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes bins based on a combination of:\n    1. Tightness of fit: Bins that leave minimal remaining space after packing.\n    2. Flexibility: A small bonus for bins with larger remaining capacities.\n    3. Stability: Using a sigmoid function to smoothly differentiate priorities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Determine which bins can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate scores for bins that can fit the item\n    fittable_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    fittable_indices = np.where(can_fit_mask)[0]\n\n    # Score 1: Tightness (prioritize smaller remaining capacity after fit)\n    # We want to minimize (remaining_capacity - item).\n    # A smaller difference is better. We can map this to a higher score.\n    # Using 1 / (difference + small_epsilon) for a steep increase as difference approaches 0.\n    # Or using a negative of the difference for direct correlation with closeness.\n    tightness_scores = fittable_bins_remain_cap - item\n    # Small epsilon to avoid division by zero if remaining capacity is exactly item size\n    epsilon_small = 1e-6\n    tightness_priority = 1.0 / (tightness_scores + epsilon_small)\n\n\n    # Score 2: Flexibility bonus (prioritize larger remaining capacity)\n    # This encourages keeping some large bins open for potentially larger future items.\n    # We can use a small boost proportional to the remaining capacity.\n    flexibility_bonus = 0.1 * fittable_bins_remain_cap / np.max(fittable_bins_remain_cap + epsilon_small)\n\n    # Combined score before sigmoid\n    # Higher tightness_priority is good, higher flexibility_bonus is good\n    combined_raw_score = tightness_priority + flexibility_bonus\n\n    # Use sigmoid to smooth and bound the scores between 0 and 1.\n    # Sigmoid(x) = 1 / (1 + exp(-x))\n    # We need to scale the input to sigmoid to control its steepness.\n    # Let's map a typical range of combined_raw_score to the sigmoid's sensitive region.\n    # A simple scaling can be done by dividing by an estimate of the typical score.\n    # Or, more directly, tune a parameter 'k' for sigmoid(k * x).\n    # For simplicity, we'll use a direct sigmoid, assuming raw scores are somewhat reasonable.\n    # A higher raw score maps to a higher sigmoid output.\n    k_sigmoid = 0.5 # Steepness parameter for sigmoid\n    sigmoid_scores = 1 / (1 + np.exp(-k_sigmoid * (combined_raw_score - np.median(combined_raw_score))))\n    \n    # Assign these sigmoid scores to the priorities array\n    priorities[fittable_indices] = sigmoid_scores\n\n    # Ensure that bins that cannot fit the item have a priority of 0\n    priorities[~can_fit_mask] = 0.0\n\n    # Normalize priorities to be between 0 and 1 (optional, but good for consistency)\n    if np.max(priorities) > 0:\n        priorities = priorities / np.max(priorities)\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin,\n    prioritizing tightest fits with a bonus for flexibility, using normalized values\n    and sigmoid for smooth prioritization.\n\n    The priority is a composite score based on:\n    1. Tightness: Prioritizes bins with minimal non-negative remaining capacity\n       that can fit the item. Modeled by a sigmoid function of the negative gap.\n    2. Flexibility: Prioritizes bins with larger remaining capacity.\n       Modeled by a sigmoid function of the normalized remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Parameters for tuning:\n    # k_tight: Controls the steepness of the tightness score. Higher k_tight\n    #          means smaller gaps are much more favored.\n    # k_flex: Controls the steepness of the flexibility score. Higher k_flex means\n    #         larger capacities reach saturation faster.\n    # w_tight: Weight for the tightness component.\n    # w_flex: Weight for the flexibility component.\n    # norm_clip_max: Value to clip normalized capacities at to prevent extreme flexibility scores.\n    k_tight = 5.0\n    k_flex = 2.0\n    w_tight = 0.7\n    w_flex = 0.3\n    norm_clip_max = 1.0 # Clip normalized capacity at 1.0 to prevent infinite sigmoid input if max_cap == min_cap\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Process only bins that can fit the item\n    eligible_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(eligible_bins_indices) > 0:\n        eligible_rem_cap = bins_remain_cap[eligible_bins_indices]\n        gaps = eligible_rem_cap - item # These are guaranteed non-negative\n\n        # --- Calculate Tightness Score ---\n        # We want small positive gaps to have high scores.\n        # A measure of tightness could be `1 / (1 + gap)` or `exp(-k * gap)`.\n        # Using `exp(-k * gap)`:\n        # If gap = 0, score = exp(0) = 1.\n        # If gap = small positive, score < 1.\n        # If gap = large positive, score -> 0.\n        # This directly gives higher scores for tighter fits.\n        # We can pass this through a sigmoid to smooth and bound.\n        # Let's use sigmoid(k_tight * (1 - gap)) - this doesn't quite work as intended.\n        # Revisit: sigmoid(x) is high for positive x, low for negative x.\n        # We want high score for small gap. Let input to sigmoid be `k * (-gap)`.\n        # `tightness_score = expit(k_tight * (-gaps))`\n        # If gap = 0, input = 0, score = 0.5\n        # If gap = small positive, input = small negative, score < 0.5\n        # If gap = large positive, input = large negative, score -> 0.\n        # This is still inverted.\n\n        # Correct approach for `sigmoid(input)` to be high for small `gaps`:\n        # Input should be high for small gaps.\n        # Try `k * (1.0 / (1.0 + gaps))`\n        #   If gap = 0, input = k * 1.0. Score ~ 1.0\n        #   If gap = small, input = k * (1 / (1 + small)) < k. Score < 1.0\n        #   If gap = large, input = k * (1 / (1 + large)) -> 0. Score -> 0.5.\n        # This seems correct.\n        # Or use `k * exp(-gaps)`\n        #   If gap = 0, input = k * 1.0. Score ~ 1.0\n        #   If gap = small, input = k * exp(-small) < k. Score < 1.0\n        #   If gap = large, input = k * exp(-large) -> 0. Score -> 0.5.\n        # Let's use the `exp(-k*gap)` directly as it's simpler and then sigmoid.\n        # `tightness_measure = np.exp(-k_tight * gaps)`\n        # `tightness_score = expit(k_tight * (tightness_measure - 0.5) * 2)` # Rescale [0,1] to [-1,1] for sigmoid center at 0.5\n\n        # A more direct way for sigmoid:\n        # We want high score when `gaps` is small.\n        # Let `input = C - gaps`. Choose C large enough.\n        # `tightness_score = expit(k_tight * (1.0 - gaps))` # Assuming gaps are normalized 0-1\n        # Since gaps can be larger, let's normalize them first.\n        max_gap = np.max(gaps) if len(gaps) > 0 else 0\n        min_gap = np.min(gaps) if len(gaps) > 0 else 0\n\n        if max_gap > min_gap:\n            normalized_gaps = (gaps - min_gap) / (max_gap - min_gap)\n        else:\n            normalized_gaps = np.zeros_like(gaps) # All gaps are the same\n\n        # Now, small normalized_gaps should yield high priority.\n        # Use `expit(k_tight * (1.0 - normalized_gaps))`\n        tightness_score = expit(k_tight * (1.0 - normalized_gaps))\n\n        # --- Calculate Flexibility Score ---\n        # We want larger remaining capacities to have higher scores.\n        # Normalize `eligible_rem_cap` to [0, 1].\n        max_cap = np.max(bins_remain_cap) if num_bins > 0 else 0\n        min_cap = np.min(bins_remain_cap) if num_bins > 0 else 0\n\n        if max_cap > min_cap:\n            normalized_caps = (eligible_rem_cap - min_cap) / (max_cap - min_cap)\n            # Clip to avoid extreme values if max_cap == min_cap for eligible bins\n            normalized_caps = np.clip(normalized_caps, 0.0, norm_clip_max)\n        else:\n            # If all bins have the same capacity (or only one bin exists),\n            # assign a neutral or slightly positive normalized capacity.\n            normalized_caps = np.full_like(eligible_rem_cap, 0.5)\n\n        # Use sigmoid on normalized capacities. Higher capacity -> higher score.\n        flexibility_score = expit(k_flex * normalized_caps)\n\n        # --- Combine Scores ---\n        # Weighted sum of tightness and flexibility scores\n        composite_priorities = w_tight * tightness_score + w_flex * flexibility_score\n\n        # Assign the calculated composite priorities back to the main priorities array\n        priorities[eligible_bins_indices] = composite_priorities\n\n        # --- Final Normalization (Optional but good practice) ---\n        # Normalize all priorities to be in the range [0, 1] based on the maximum priority found.\n        # This ensures that the highest priority bin always gets a score of 1.0,\n        # making relative scores clearer.\n        max_priority_value = np.max(priorities)\n        if max_priority_value > 0:\n            priorities = priorities / max_priority_value\n        # If all priorities are zero (e.g., no eligible bins or calculation resulted in zeros),\n        # the array remains all zeros.\n\n    return priorities\n\n[Reflection]\n**Normalize features before combining; tune weights and sigmoid steepness.**\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}