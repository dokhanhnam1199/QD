{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    The Almost Full Fit strategy prioritizes bins that are \"almost full\" but can still\n    accommodate the current item. This aims to leave more space in other bins for\n    potentially larger future items, or to consolidate items into fewer bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value (negative infinity) for bins that cannot fit the item.\n    # This ensures they are never chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate priority.\n    # The strategy prioritizes bins with remaining capacity *closest* to the item size\n    # (but still greater than or equal to it). This is achieved by maximizing\n    # the remaining capacity minus the item size.\n    # A smaller remaining capacity after placing the item means the bin was \"more full\"\n    # before placing the item.\n    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask] - item\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    The Sigmoid Fit Score prioritizes bins that are closer to fitting the item perfectly,\n    using a sigmoid function to map the \"tightness\" of the fit to a priority score.\n    Bins that can fit the item (remaining capacity >= item size) are considered.\n    The score is higher for bins where (remaining_capacity - item_size) is closer to zero.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    possible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(possible_bins_mask):\n        # No bin can fit the item, return all zeros (or handle as an error/special case)\n        return priorities\n\n    # Calculate the \"gap\" for possible bins (how much space is left after placing the item)\n    # We want to minimize this gap, so a smaller gap is better.\n    gaps = bins_remain_cap[possible_bins_mask] - item\n\n    # We want to use a sigmoid function that maps smaller gaps to higher priorities.\n    # The standard sigmoid function outputs values between 0 and 1.\n    # sigmoid(x) = 1 / (1 + exp(-x))\n    # If x is large positive, sigmoid(x) is close to 1.\n    # If x is large negative, sigmoid(x) is close to 0.\n    # We want a higher score when the gap is small (close to 0).\n    # Let's transform the gap: a smaller gap should result in a larger positive value\n    # fed into the sigmoid.\n    # Consider `scaled_gap = -gaps / scale_factor`. As gap approaches 0, scaled_gap approaches 0.\n    # sigmoid(0) = 0.5. This doesn't quite give us the highest priority for a perfect fit.\n    #\n    # Let's reconsider the goal: prioritize bins that fit the item *tightly*.\n    # This means the remaining capacity is just slightly larger than the item size.\n    # So, (bins_remain_cap[i] - item) should be small and positive.\n    #\n    # A common way to use sigmoid for prioritization is to map the \"goodness\" of a\n    # characteristic to a score.\n    # Let's define \"tightness\" as how close `bins_remain_cap[i]` is to `item`.\n    # Specifically, for bins that can fit the item, we are interested in\n    # `bins_remain_cap[i] - item`.\n    #\n    # We want a function f(diff) where `diff = bins_remain_cap[i] - item` such that:\n    # - f(diff) is high when `diff` is small and positive.\n    # - f(diff) is lower when `diff` is large and positive.\n    # - f(diff) is 0 or very low when `diff` is negative (or item doesn't fit).\n    #\n    # Let's try `sigmoid(k * (max_capacity - bins_remain_cap[i]))`.\n    # If `bins_remain_cap[i]` is close to `item`, then `bins_remain_cap[i] - item` is small.\n    #\n    # Alternative approach: Model the \"cost\" of fitting.\n    # A perfect fit has zero cost. A loose fit has a cost.\n    # Consider the metric `bins_remain_cap[i] - item`.\n    # We want a high priority when this value is close to 0 (and positive).\n    #\n    # Let's use a sigmoid on the *inverse* of the gap.\n    # A small gap is a large inverse gap.\n    #\n    # Consider the difference `diff = bins_remain_cap[i] - item`.\n    # We want a high score when `diff` is small and positive.\n    #\n    # Let's map `diff` to a score using sigmoid:\n    # `sigmoid(A - B * diff)`:\n    # - If `diff` is small positive, `B * diff` is small positive. `A - B * diff` is large positive. Sigmoid is close to 1.\n    # - If `diff` is large positive, `B * diff` is large positive. `A - B * diff` is large negative. Sigmoid is close to 0.\n    #\n    # We need to choose parameters A and B appropriately.\n    # Let's set A to control the center of the sigmoid and B to control the steepness.\n    # A common approach is to center the sigmoid around 0.\n    #\n    # Let's define a score that peaks at 0 difference.\n    # We can use `sigmoid(slope * (optimal_diff - current_diff))`.\n    # `optimal_diff = 0`. So, `sigmoid(slope * (0 - (bins_remain_cap[i] - item)))`\n    # = `sigmoid(slope * (item - bins_remain_cap[i]))`\n    # = `sigmoid(slope * -(bins_remain_cap[i] - item))`\n    #\n    # For bins where `bins_remain_cap[i] < item`, this calculation is not directly applicable.\n    # We've already filtered these out.\n    # For bins where `bins_remain_cap[i] >= item`:\n    # Let `gap = bins_remain_cap[i] - item`. `gap >= 0`.\n    # The score is `sigmoid(-slope * gap)`.\n    # - If `gap = 0` (perfect fit), score = `sigmoid(0)` = 0.5.\n    # - If `gap` is small positive, `sigmoid` is slightly less than 0.5.\n    # - If `gap` is large positive, `sigmoid` is close to 0.\n    # This gives higher priority to bins with larger gaps, which is the opposite of what we want.\n    #\n    # We need a function that *decreases* as `gap` increases.\n    # So, let's use `1 - sigmoid(slope * gap)` or `sigmoid(-slope * gap)`.\n    #\n    # Let's rethink: we want to prioritize bins where `bins_remain_cap[i]` is CLOSEST to `item`.\n    # The difference `d = bins_remain_cap[i] - item`. We want `d` to be small and positive.\n    #\n    # Consider `1 / (1 + exp(-k * (value)))`\n    # If we want the score to be high when `bins_remain_cap[i]` is just above `item`.\n    #\n    # Let `ratio = item / bins_remain_cap[i]`. This is relevant if bin capacity is variable.\n    # Here, bin capacity is fixed, but remaining capacity changes.\n    #\n    # The \"Sigmoid Fit Score\" usually implies fitting the item as snugly as possible.\n    # This means minimizing `bins_remain_cap[i] - item` for `bins_remain_cap[i] >= item`.\n    #\n    # Let's use the negative of the gap as the input to the sigmoid, which will give\n    # values closer to 1 for smaller gaps.\n    # `score = sigmoid(k * (item - bins_remain_cap[i]))`\n    # This is equivalent to `sigmoid(k * -(bins_remain_cap[i] - item))`.\n    #\n    # Let's use `k = 1.0` for simplicity for now, and `sigmoid(x) = 1 / (1 + exp(-x))`.\n    #\n    # We want the score to be high for `bins_remain_cap[i]` just above `item`.\n    #\n    # Let's scale the gap to avoid numerical issues and control sensitivity.\n    # `scaled_gap = (bins_remain_cap[possible_bins_mask] - item) / max(1, bins_remain_cap[possible_bins_mask].max())`\n    # This makes the gap a value between 0 and 1 (if max_cap is 1).\n    #\n    # Consider `score = sigmoid(A - B * (bins_remain_cap[i] - item))`\n    # Let's center the sigmoid such that a difference of `delta` results in a score of 0.5.\n    # If we want a difference of 0 to be ideal, then `sigmoid(0) = 0.5`.\n    #\n    # A common sigmoid fit score in BPP aims to place the item in the bin\n    # where the remaining capacity is the smallest that can still fit the item.\n    # This is equivalent to minimizing `bins_remain_cap[i] - item` for `bins_remain_cap[i] >= item`.\n    #\n    # So, we want a function `f(gap)` where `f(gap)` is high for small `gap >= 0`.\n    #\n    # Let's use `f(gap) = 1 - sigmoid(k * gap)` or `f(gap) = sigmoid(-k * gap)`.\n    # With `sigmoid(x) = 1 / (1 + exp(-x))`:\n    # - `gap = 0`: `f(0) = sigmoid(0) = 0.5`. This is the peak value.\n    # - `gap = small_positive`: `f(small_positive) = sigmoid(-k * small_positive)` is slightly less than 0.5.\n    # - `gap = large_positive`: `f(large_positive) = sigmoid(-k * large_positive)` is close to 0.\n    #\n    # This means `sigmoid(-k * gap)` assigns a score that decreases as the gap increases.\n    # The highest score is 0.5 for a perfect fit.\n\n    # Let's define a \"steepness\" parameter for the sigmoid.\n    # A larger `steepness` will make the score drop faster as the gap increases.\n    steepness = 5.0  # Tune this parameter\n\n    # Calculate the argument for the sigmoid function\n    # We want to prioritize smaller gaps. So, `item - bins_remain_cap[i]` should be maximized (least negative).\n    # Or equivalently, `bins_remain_cap[i] - item` should be minimized.\n    # Using `sigmoid(-steepness * gap)` makes scores higher for smaller gaps.\n    sigmoid_arg = -steepness * gaps\n\n    # Apply the sigmoid function to get priorities\n    # We are only calculating for possible bins, so we need to put these values back.\n    priorities[possible_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg))\n\n    # If `item` is very small, `bins_remain_cap[i] - item` is close to `bins_remain_cap[i]`.\n    # The sigmoid still works, prioritizing bins with less remaining capacity.\n\n    return priorities\n\n[Reflection]\nExperiment with sigmoid parameters and explore alternative smooth ranking functions for better prioritization.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}