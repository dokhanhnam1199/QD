```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using an adaptive Epsilon-Greedy with Best Fit.

    This heuristic aims to improve upon a basic Epsilon-Greedy by:
    1. Prioritizing strict fits: Bins where placing the item results in very little
       remaining capacity are given higher priority. This is a refined "Best Fit" aspect.
    2. Adaptive Epsilon: The exploration rate (epsilon) can be adjusted based on the
       state of the bins. For simplicity here, we'll use a fixed epsilon but conceptually
       it could be dynamic.
    3. Balancing Exploration and Exploitation: With probability (1-epsilon), it exploits
       the best fit. With probability epsilon, it explores by selecting a bin randomly,
       but we can modulate this exploration to favor slightly less optimal but still valid fits.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher scores indicate higher priority.
    """
    epsilon = 0.1  # Exploration rate (can be made adaptive)
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item

    # If no bins can fit, return all zeros
    if not np.any(can_fit_mask):
        return priorities

    # --- Exploitation Phase: Prioritize "Best Fit" and "Near Best Fit" ---
    fitting_bins_indices = np.where(can_fit_mask)[0]
    fitting_bins_caps = bins_remain_cap[fitting_bins_indices]
    resulting_remain_cap = fitting_bins_caps - item

    # Define a desirability score for fitting bins.
    # Lower resulting_remain_cap is better. We want scores to be high for good fits.
    # Using `1.0 / (resulting_remain_cap + epsilon_stable)` where epsilon_stable is a small positive number
    # to avoid division by zero and ensure positive scores.
    epsilon_stable = 1e-6
    desirability_scores = 1.0 / (resulting_remain_cap + epsilon_stable)

    # Apply a "soft" selection based on desirability.
    # This can be seen as a smoothed Best Fit. Instead of picking only the absolute best,
    # give higher probabilities to better fits.
    # We use softmax to get probabilities, then scale them.
    try:
        # Stable softmax: subtract max before exp to prevent overflow
        max_score = np.max(desirability_scores)
        exp_scores = np.exp((desirability_scores - max_score) / 1.0) # Temperature = 1.0
        probabilities = exp_scores / np.sum(exp_scores)
    except OverflowError:
        # Fallback for extreme cases, though the above subtraction usually helps
        probabilities = np.ones_like(desirability_scores) / len(desirability_scores) # Uniform

    # Assign these probabilities as the base priority for fitting bins
    priorities[fitting_bins_indices] = probabilities

    # --- Exploration Phase ---
    # With probability epsilon, we will select a bin randomly among those that can fit.
    # Instead of completely random, we can also give a small boost to bins that
    # are "good enough" but not strictly the best fit, allowing exploration of
    # alternatives. For simplicity, we'll introduce random noise to some bins.

    # Identify a subset of bins to slightly boost for exploration/diversity
    # We can explore a random subset of the fitting bins.
    num_bins_to_explore = int(np.floor(epsilon * len(fitting_bins_indices)))

    if num_bins_to_explore > 0:
        # Select random indices from the fitting bins to apply exploration boost
        explore_indices_in_fitting = np.random.choice(
            len(fitting_bins_indices), size=num_bins_to_explore, replace=False
        )
        original_explore_indices = fitting_bins_indices[explore_indices_in_fitting]

        # Assign a moderate exploration priority, lower than the peak exploitation priority
        # but higher than zero. This encourages trying slightly suboptimal bins.
        exploration_priority_value = np.mean(priorities[fitting_bins_indices]) # Average of current priorities
        if exploration_priority_value == 0: # Ensure it's positive if all are zero
            exploration_priority_value = 0.1
        else:
            exploration_priority_value *= 0.5 # Make it slightly less than average

        priorities[original_explore_indices] = max(priorities[original_explore_indices], exploration_priority_value)

    # Ensure that bins that cannot fit have zero priority.
    priorities[~can_fit_mask] = 0.0

    # Normalize priorities to a [0, 1] range for consistency.
    # This step is important if the absolute magnitude matters or for comparisons.
    max_priority = np.max(priorities)
    if max_priority > 0:
        priorities = priorities / max_priority
    else:
        # If all priorities are zero (e.g., no bins could fit), return zeros.
        pass

    return priorities
```
