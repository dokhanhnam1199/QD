[Prior reflection]
Prioritize bins with minimal remaining capacity (tightest fits). Use smooth ranking functions like sigmoid, adjusting parameters for sensitivity. Consider a small bonus for larger remaining capacities to balance immediate tightness with future flexibility.

[Code]
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin.
    This version prioritizes tighter fits using a sigmoid function and
    adds a small bonus for bins with more remaining capacity to encourage
    future flexibility.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher scores indicate higher priority.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # For bins that can fit the item, calculate a priority score
    if np.any(can_fit_mask):
        valid_bins_cap = bins_remain_cap[can_fit_mask]
        valid_bins_indices = np.where(can_fit_mask)[0]

        # --- Core Priority Calculation ---
        # 1. Tightest Fit (Exploitation):
        #    We want bins with remaining capacity just slightly larger than the item.
        #    A good measure is `remaining_capacity - item`. Smaller values are better.
        #    We can use a sigmoid-like function where small positive values (tight fit)
        #    result in high scores, and large positive values (loose fit) result in lower scores.
        #    Let's use `1 / (1 + exp(k * (capacity - item)))` or similar.
        #    A simpler approach is to rank based on (capacity - item) and invert.
        #    Let's transform `capacity - item` to prioritize smaller values.
        #    We can use `- (capacity - item)` and then apply sigmoid, or scale and invert.
        #    A good transformation might be `1 / (1 + (capacity - item))` or
        #    `sigmoid(negative_difference)`.
        #    Let's try: `sigmoid(alpha * (item - remaining_capacity))`
        #    where alpha is a steepness parameter. A larger alpha makes the "best fit"
        #    more pronounced.
        #    Alternatively, `remaining_capacity` itself can be used, but we want smaller
        #    remaining capacities for tight fits. So, we'll invert it or use a negative
        #    dependency.

        # Let's use a function that maps (remaining_capacity - item) to a priority.
        # We want small (remaining_capacity - item) to have high priority.
        # A simple transformation is `1 / (1 + (remaining_capacity - item))`
        # For numerical stability and better control, let's scale and then apply sigmoid.
        # Consider `sigmoid(k * (item - remaining_capacity))`.
        # `k` controls sensitivity. A positive `k` will mean smaller `remaining_capacity` (for a given `item`) has higher priority.
        # Let `diff = remaining_capacity - item`. We want to prioritize small `diff`.
        # Sigmoid of `-k * diff` is good. `1 / (1 + exp(k * diff))`
        # To avoid numerical issues, let's normalize `diff` first.
        # `normalized_diff = (diff - min_diff) / (max_diff - min_diff)`
        # Then `sigmoid(k * (1 - normalized_diff))`

        # A more direct approach for "tightest fit":
        # Prioritize bins where `bins_remain_cap` is just above `item`.
        # `tightness_score = 1.0 / (1.0 + bins_remain_cap[valid_bins_indices] - item)` # higher is better fit
        # This can be unstable if `bins_remain_cap - item` is very large.
        # A sigmoid is better: `sigmoid(k * (item - bins_remain_cap[valid_bins_indices]))`
        # Let's use `k=1.0` for now.
        k_tightness = 1.0  # Sensitivity for tight fit
        tightness_scores = 1.0 / (1.0 + np.exp(k_tightness * (item - valid_bins_cap)))

        # 2. Future Flexibility Bonus (Exploration/Balancing):
        #    Consider bins with larger remaining capacity as having a small bonus.
        #    This is like a small incentive to keep some space.
        #    We can use `sigmoid(k_flex * (bins_remain_cap[valid_bins_indices] - threshold))`
        #    or simply a linear scaling.
        #    Let's make it a smaller bonus, so we scale `valid_bins_cap` and add it.
        #    To prevent very large bins from dominating, we can normalize `valid_bins_cap`.
        #    Max remaining capacity among valid bins:
        max_cap_valid = np.max(valid_bins_cap)
        min_cap_valid = np.min(valid_bins_cap)

        if max_cap_valid > min_cap_valid:
            normalized_caps = (valid_bins_cap - min_cap_valid) / (max_cap_valid - min_cap_valid)
        else: # All valid bins have same remaining capacity
            normalized_caps = np.ones_like(valid_bins_cap) * 0.5 # Neutral value

        # The flexibility bonus should be smaller than the tightness score.
        # So, we can scale `normalized_caps` by a small factor, say `0.2`.
        flexibility_bonus_scale = 0.2
        flexibility_bonus = flexibility_bonus_scale * normalized_caps

        # Combine scores
        combined_scores = tightness_scores + flexibility_bonus

        # Assign scores to the original bins_remain_cap array
        priorities[valid_bins_indices] = combined_scores

        # --- Normalization ---
        # Normalize priorities to a 0-1 range. This makes the scale consistent
        # and avoids extremely large or small numbers if the sigmoid or bonus
        # values get too extreme.
        max_priority = np.max(priorities)
        if max_priority > 0:
            priorities = priorities / max_priority
        else:
            # If all valid bins resulted in 0 priority (unlikely with sigmoid),
            # or if there were no valid bins, handle it.
            pass # Priorities remain 0

    # Bins that cannot fit the item will have a priority of 0, which is already set.

    # Add a small random perturbation to break ties and encourage slight exploration
    # among equally good options. This is a subtle form of exploration.
    # Apply to bins that can fit the item.
    if np.any(can_fit_mask):
        perturbation_scale = 0.05 # Small random boost
        eligible_indices = np.where(can_fit_mask)[0]
        # Ensure we don't add perturbation to bins with 0 priority initially
        # (though in this logic, all can_fit bins have positive priority)
        priorities[eligible_indices] += np.random.rand(len(eligible_indices)) * perturbation_scale

        # Re-normalize after adding perturbation to keep priorities in a reasonable range
        max_priority = np.max(priorities)
        if max_priority > 0:
            priorities = priorities / max_priority

    return priorities
```
