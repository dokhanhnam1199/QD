{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Random Fit.\n\n    In Random Fit, we consider all bins that can accommodate the item and assign\n    them equal priority. Then, a random bin from this subset is chosen.\n    This function assigns a priority of 1 to all bins that can fit the item,\n    and 0 to those that cannot.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # Assign priority 1 to bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = 1.0\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    The priority is calculated based on how well an item fits into a bin,\n    favoring bins that leave minimal remaining capacity after packing the item,\n    while also considering bins that have more remaining capacity. The softmax\n    function is used to convert these 'fitness' scores into probabilities,\n    where bins with higher 'fitness' (i.e., better fits) get higher priorities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the 'fitness' of each bin for the current item.\n    # A good fit is one where the remaining capacity is small after adding the item.\n    # We only consider bins that can actually fit the item.\n    # For bins that cannot fit the item, we assign a very low 'fitness' (-infinity)\n    # so they get a priority of 0 after softmax.\n    fitness_scores = np.full_like(bins_remain_cap, -np.inf)\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit, a higher priority is given to bins where\n    # the remaining capacity after adding the item is smaller.\n    # We add a small epsilon to avoid division by zero if remaining capacity is 0.\n    # The score is inversely proportional to the remaining capacity after packing.\n    # Adding the item size to the capacity and then taking the reciprocal might\n    # be a simple way to represent \"how much space is left\". A smaller value\n    # is better. We can also consider the proportion of space used.\n    \n    # Let's try a simple approach: higher priority for bins that leave *less*\n    # remaining capacity. This is the \"best fit\" idea.\n    # remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n    # To convert to a score where larger is better, we can take the negative of\n    # remaining capacity, or a function like exp(alpha * (-remaining_capacity)).\n    \n    # A common strategy for softmax-based selection is to have scores that\n    # represent desirability. For bin packing, fitting an item into a bin\n    # without leaving too much wasted space is desirable.\n    \n    # Let's define a score that is high for bins that have just enough space\n    # and lower for bins with much more space.\n    # A simple score could be 1 / (bins_remain_cap - item + epsilon)\n    # or simply the negative of the remaining capacity: -(bins_remain_cap - item)\n    # Let's try a score that represents how much capacity is *used* relative to available space.\n    # For bins that can fit: score = item / bins_remain_cap (if we want to fill bins)\n    # Or, we want to minimize wasted space, so minimize (bins_remain_cap - item).\n    # For softmax, we want higher values for better bins.\n    # So, we can use - (bins_remain_cap - item) or (item - bins_remain_cap)\n    # Let's use a score that is the negative of the leftover space.\n    # Lower (more negative) values mean more leftover space, so less desirable.\n    # Thus, a bin with *less* leftover space is more desirable.\n    # For example, if item=3, bins_remain_cap=[10, 5, 4].\n    # Bin 1: remaining=7, score=-7\n    # Bin 2: remaining=2, score=-2\n    # Bin 3: remaining=1, score=-1\n    # Softmax of [-7, -2, -1] will give higher probability to -1.\n    \n    # To avoid issues with exactly zero remaining capacity if we were to use reciprocal,\n    # and to ensure that bins that are nearly full get higher scores, we can use\n    # the negative of the remaining capacity after packing.\n    \n    # If remaining capacity is R, and item is I, new remaining capacity is R-I.\n    # We want to prioritize bins where R-I is small.\n    # So, we can assign a score of -(R-I) or equivalently I-R.\n    \n    # For bins that can fit:\n    effective_remaining_caps = bins_remain_cap[can_fit_mask] - item\n    # We want smaller effective_remaining_caps to be better.\n    # For softmax, higher values are better. So, we invert the desirability.\n    # A simple inversion is 1 / (effective_remaining_caps + epsilon) or\n    # -(effective_remaining_caps)\n    \n    # Let's use -(effective_remaining_caps). This means bins with less remaining\n    # space (after packing) get higher scores.\n    # Example: bins_remain_cap = [10, 5, 4], item = 3\n    # Bin 1: can fit, 10-3=7, score = -7\n    # Bin 2: can fit, 5-3=2, score = -2\n    # Bin 3: can fit, 4-3=1, score = -1\n    # Softmax of [-7, -2, -1] would give higher weights to the bins with smaller remaining capacity.\n    \n    scores = -(bins_remain_cap[can_fit_mask] - item)\n    fitness_scores[can_fit_mask] = scores\n\n    # Apply softmax function to get probabilities (priorities)\n    # Ensure numerical stability for softmax by subtracting the maximum score\n    if np.all(fitness_scores == -np.inf): # No bins can fit the item\n        return np.zeros_like(bins_remain_cap)\n        \n    # Subtracting the max score before exponentiation for numerical stability.\n    # The relative differences in scores are preserved.\n    max_score = np.max(fitness_scores)\n    exp_scores = np.exp(fitness_scores - max_score)\n    \n    # Avoid division by zero if all exp_scores are effectively zero\n    sum_exp_scores = np.sum(exp_scores)\n    if sum_exp_scores == 0:\n        # If all scores are very negative, resulting in near-zero exponentials,\n        # distribute probability equally among bins that *can* fit.\n        # This case is unlikely with typical capacities and item sizes.\n        # However, for robustness, if sum is zero, we can return uniform probabilities\n        # for fitting bins, and zero for non-fitting bins.\n        priorities = np.zeros_like(bins_remain_cap)\n        num_fitting_bins = np.sum(can_fit_mask)\n        if num_fitting_bins > 0:\n            priorities[can_fit_mask] = 1.0 / num_fitting_bins\n        return priorities\n        \n    priorities = exp_scores / sum_exp_scores\n\n    return priorities\n\n[Reflection]\nPrioritize bins that minimize leftover space, favoring tighter fits.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}