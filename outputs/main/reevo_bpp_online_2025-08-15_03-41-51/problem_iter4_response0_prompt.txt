{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-based Best Fit strategy.\n\n    This strategy aims to mimic the \"Best Fit\" heuristic within a softmax framework.\n    It prioritizes bins where placing the item results in the least remaining capacity\n    (i.e., the \"tightest\" fit). Bins that cannot accommodate the item receive zero priority.\n    The priorities are generated using a softmax function on desirability scores,\n    where a higher score indicates a better fit (less remaining capacity after packing).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins that cannot fit the item will have a priority of 0.\n        For fitting bins, scores are derived from the resulting remaining capacity,\n        and transformed by softmax to represent probabilities or preferences.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity *after* placing the item for eligible bins\n        valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        resulting_remain_cap = valid_bins_remain_cap - item\n\n        # Define a desirability score for each fitting bin.\n        # For \"Best Fit\", we want to minimize `resulting_remain_cap`.\n        # A higher desirability score should correspond to a lower `resulting_remain_cap`.\n        # We can use a score that is inversely proportional to `resulting_remain_cap`.\n        # To avoid division by zero and ensure positive scores, we can add a small constant\n        # or use a transformation like `1 / (slack + 1)`.\n        # A simple approach is to use `max_possible_slack - slack`, where `max_possible_slack`\n        # is the maximum possible remaining capacity among fitting bins.\n        # Or, more directly, we can use a desirability score that is higher when `resulting_remain_cap` is smaller.\n        # Let's use `-resulting_remain_cap` as a raw desirability, so smaller slack (closer to 0) is better.\n        # For softmax, we want scores that are generally positive for exponentiation.\n        # A good score is `1.0 / (resulting_remain_cap + 1.0)` which is high when `resulting_remain_cap` is small.\n\n        # Let's use a score that emphasizes bins with very little slack.\n        # A slightly larger slack should yield a significantly lower score.\n        # We can use an exponential decay, or a simple inverse relationship.\n        # `score = 1.0 / (resulting_remain_cap + epsilon)` where epsilon is a small positive number.\n        # Let's use `1.0 / (resulting_remain_cap + 1e-6)` to ensure stability and positive values.\n\n        desirability_scores = 1.0 / (resulting_remain_cap + 1e-6)\n\n        # Apply softmax to convert desirability scores into a probability-like distribution.\n        # A temperature parameter can control the \"softness\" of the distribution.\n        # A lower temperature makes the distribution sharper, favoring the best bins more.\n        # A higher temperature makes it flatter, giving more similar probabilities.\n        temperature = 1.0  # Tunable parameter\n\n        # Avoid numerical instability with very large desirability scores by clipping or normalizing first,\n        # or by using a stable softmax implementation if available.\n        # Here, we use `exp(score / temperature)`.\n\n        try:\n            exp_scores = np.exp(desirability_scores / temperature)\n            sum_exp_scores = np.sum(exp_scores)\n            if sum_exp_scores > 0:\n                softmax_probabilities = exp_scores / sum_exp_scores\n            else:\n                # If all desirability scores are extremely small (or negative if we didn't ensure positivity),\n                # softmax might result in zeros. Assign uniform probability in such edge cases.\n                softmax_probabilities = np.ones_like(desirability_scores) / len(desirability_scores)\n        except OverflowError:\n            # Handle potential overflow if desirability_scores are too large\n            # A common approach is to subtract the max score before exponentiation.\n            max_score = np.max(desirability_scores)\n            stable_scores = desirability_scores - max_score\n            exp_scores = np.exp(stable_scores / temperature)\n            sum_exp_scores = np.sum(exp_scores)\n            if sum_exp_scores > 0:\n                softmax_probabilities = exp_scores / sum_exp_scores\n            else:\n                softmax_probabilities = np.ones_like(desirability_scores) / len(desirability_scores)\n\n\n        # Place the calculated probabilities back into the original priorities array\n        priorities[can_fit_mask] = softmax_probabilities\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function implements a modified First Fit strategy,\n    often referred to as \"Almost Full Fit\" or \"Best Fit\". It prioritizes\n    bins that can accommodate the item with the least amount of remaining\n    capacity (i.e., the tightest fit). This is because packing an item\n    into a bin that is nearly full leaves less \"wasted\" space in that bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority. Bins that cannot fit the item\n        will have a very low priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # We only consider bins that have enough remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, we want to prioritize those that leave\n    # the least amount of remaining space after the item is placed.\n    # This means minimizing (bins_remain_cap - item).\n    # A common way to turn minimization into maximization for priority is to\n    # use the negative of the difference or an inverse.\n    # Using the negative of the difference directly works well:\n    # A smaller (bins_remain_cap - item) results in a less negative (higher) score.\n    # E.g., if item=0.3, bin_caps=[0.35, 0.4, 0.5]\n    # diffs: [0.05, 0.1, 0.2]\n    # scores: [-0.05, -0.1, -0.2] -> bin_cap=0.35 is prioritized.\n    \n    # To ensure higher priority for tighter fits, we can assign a score that is\n    # inversely proportional to the remaining capacity *after* placing the item.\n    # Specifically, we want to maximize `1 / (bins_remain_cap - item + epsilon)`\n    # or, equivalently, minimize `bins_remain_cap - item`.\n    \n    # A simple and effective way is to use the negative of the slack space:\n    # `slack = bins_remain_cap - item`\n    # Priority = -slack\n    # This means smaller positive slacks (tighter fits) get higher priority.\n\n    # To avoid issues with floating point precision or bins that are exactly full,\n    # we can also consider a score that peaks when bins_remain_cap is exactly item.\n    # A common approach is to use a function that is maximized at 0 for `bins_remain_cap - item`.\n    # For example, `-abs(bins_remain_cap - item)` or `1 / (1 + abs(bins_remain_cap - item))`.\n    # The former `-(bins_remain_cap - item)` is simpler and achieves the goal for\n    # bins that can fit the item.\n\n    # Let's use the negative of the slack space.\n    # We add a small epsilon to the `bins_remain_cap` before calculating slack\n    # to ensure that even if `bins_remain_cap` is exactly `item`, the slack\n    # is a small positive number, leading to a priority close to 0, and\n    # preventing any zero or negative slack values from causing issues if\n    # they were to be inverted directly without care.\n    # However, simply taking `- (bins_remain_cap - item)` is generally sufficient\n    # and more direct for \"Best Fit\" / \"Almost Full Fit\".\n\n    # Prioritize bins where `bins_remain_cap - item` is minimized.\n    # This translates to a score that is maximized for these bins.\n    # We can use `-(bins_remain_cap - item)` which means smaller positive values of `bins_remain_cap - item`\n    # result in higher (less negative) scores.\n    \n    # A small adjustment for \"almost full fit\" could be to slightly penalize bins\n    # that are *too* full (i.e., `bins_remain_cap` is very large), even if they can fit.\n    # However, standard \"Almost Full Fit\" or \"Best Fit\" primarily focuses on minimizing slack.\n\n    # Let's refine the score to be `- (bins_remain_cap - item)` for bins that fit.\n    # This score directly reflects the remaining space after packing.\n    # Higher priority for smaller remaining space.\n\n    priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    # For bins that cannot fit the item, their priority should be very low so they are never chosen.\n    # Setting them to negative infinity ensures this.\n    priorities[~can_fit_mask] = -np.inf\n\n    # Note: This heuristic is essentially \"Best Fit\". It prioritizes the bin\n    # that will have the least remaining capacity after the item is placed.\n    # This is often a good strategy for \"Almost Full Fit\" as it aims to\n    # utilize space efficiently in bins that are already somewhat full.\n\n    return priorities\n\n[Reflection]\nFocus on the goal: minimize wasted space for tighter fits.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}