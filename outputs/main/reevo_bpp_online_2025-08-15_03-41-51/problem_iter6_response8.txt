```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a balanced approach.

    This version aims to prioritize bins that offer a "good fit" (not too much wasted space)
    while also considering bins that might be more flexible for future items. It uses
    a two-component scoring:
    1. Tightness Score: Penalizes bins that leave excessive remaining capacity after
       packing the item. It's inverse to the remaining capacity after packing.
    2. Flexibility Score: Rewards bins that have a larger initial remaining capacity,
       implying they could accommodate larger future items.

    The scores are then combined and transformed using a stable softmax-like
    approach to produce probabilities.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher scores indicate higher priority.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        # No bin can fit the item, return all zeros
        return priorities

    fitting_bins_cap = bins_remain_cap[can_fit_mask]

    # --- Component 1: Tightness Score ---
    # We want to prioritize bins where the remaining capacity *after* packing
    # is minimized. A simple approach is to use the inverse of the remaining capacity
    # after packing, or a transformation that maps smaller remaining capacity to larger scores.
    # Using `-(remaining_capacity_after_packing)` achieves this.
    # Adding a small constant to the denominator can prevent division by zero and
    # slightly favor bins that are not perfectly filled if multiple bins are perfectly filled.
    remaining_after_packing = fitting_bins_cap - item
    # Use a small epsilon to avoid zero in denominator and to slightly penalize perfect fits
    # for tightest bins, ensuring that a bin with a tiny remaining capacity (e.g., 0.001)
    # gets a slightly higher tightness score than a perfectly fitting bin.
    epsilon_tightness = 1e-5
    tightness_scores = 1.0 / (remaining_after_packing + epsilon_tightness)

    # --- Component 2: Flexibility Score ---
    # We want to reward bins that have a large *original* remaining capacity.
    # This suggests they are more likely to accommodate future items.
    # A simple linear scaling works here. The scaling factor controls its influence.
    flexibility_scale = 0.05  # Tunable parameter to balance tightness vs flexibility
    flexibility_scores = flexibility_scale * fitting_bins_cap

    # --- Combine Scores ---
    # Add the flexibility score to the tightness score.
    combined_scores = tightness_scores + flexibility_scores

    # --- Softmax-like Transformation ---
    # Convert combined scores into probabilities. Using a stable softmax implementation.
    # Subtract max for numerical stability before exponentiation.
    max_combined_score = np.max(combined_scores)
    exp_scores = np.exp(combined_scores - max_combined_score)
    sum_exp_scores = np.sum(exp_scores)

    if sum_exp_scores > 1e-9:  # Handle cases where all scores might be extremely small
        priorities[can_fit_mask] = exp_scores / sum_exp_scores
    else:
        # If all scores are very small, distribute probability equally among fitting bins.
        num_fitting_bins = np.sum(can_fit_mask)
        if num_fitting_bins > 0:
            priorities[can_fit_mask] = 1.0 / num_fitting_bins

    return priorities
```
