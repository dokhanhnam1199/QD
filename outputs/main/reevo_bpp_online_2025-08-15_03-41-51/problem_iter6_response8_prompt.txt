{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a tunable Sigmoid Fit Score.\n\n    This version refines the Sigmoid Fit Score by introducing `steepness` to control the\n    sigmoid's slope and `ideal_gap_fraction` to specify the desired positive gap as a\n    fraction of the item size. This allows for fine-tuning the preference for bins\n    that are not perfectly filled, potentially leaving more room for future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins that cannot fit the item will have a priority of -inf.\n    \"\"\"\n    # Initialize priorities to negative infinity for bins that cannot fit the item.\n    # This ensures they are never selected.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item\n    possible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(possible_bins_mask):\n        # If no bin can fit the item, return the initialized -inf priorities.\n        return priorities\n\n    # Calculate the \"gap\" for bins that can fit the item.\n    # Gap is the remaining capacity after placing the item.\n    gaps = bins_remain_cap[possible_bins_mask] - item\n\n    # --- Tunable Parameters ---\n    # `steepness`: Controls how quickly the priority score decreases as the gap increases.\n    # A higher value leads to a sharper drop-off, making the choice more sensitive to small gaps.\n    steepness = 25.0\n\n    # `ideal_gap_fraction`: Defines the target gap as a fraction of the item's size.\n    # A value of 0.0 means we ideally want a perfect fit (gap=0).\n    # A value of 0.1 means we ideally want a gap of 10% of the item size.\n    # This encourages leaving some buffer space.\n    ideal_gap_fraction = 0.08 # Aim for a gap of ~8% of the item size\n\n    # Calculate the ideal gap based on the item size.\n    # Ensure the ideal gap is non-negative. If item size is 0, ideal_gap is 0.\n    ideal_gap = max(0.0, ideal_gap_fraction * item)\n\n    # --- Sigmoid Argument Calculation ---\n    # We use the sigmoid function `1 / (1 + exp(-x))` which maps x to [0, 1].\n    # To prioritize bins with gaps close to `ideal_gap`, we can map `ideal_gap` to the center\n    # of the sigmoid's steep slope (input close to 0).\n    # The argument `x` for the sigmoid will be `steepness * (ideal_gap - gap)`.\n    #\n    # If `gap < ideal_gap`: The argument is positive, sigmoid output > 0.5. Higher scores for smaller gaps.\n    # If `gap = ideal_gap`: The argument is 0, sigmoid output = 0.5. This is the pivot point.\n    # If `gap > ideal_gap`: The argument is negative, sigmoid output < 0.5. Lower scores for larger gaps.\n    #\n    # By choosing `ideal_gap_fraction`, we are effectively tuning the bias of the sigmoid.\n    # The argument can be seen as: `steepness * ideal_gap - steepness * gap`.\n    # The `steepness * ideal_gap` term acts as an additive bias.\n    sigmoid_arg = steepness * (ideal_gap - gaps)\n\n    # Apply the sigmoid function to compute the priority scores for fitting bins.\n    # Higher values indicate a more desirable bin.\n    priorities[possible_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg))\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a balanced Softmax-Fit with flexibility.\n\n    This version aims to balance the \"tightest fit\" heuristic with a consideration\n    for \"future flexibility\". It uses a softmax-like approach to prioritize\n    bins that leave less remaining capacity after packing the item (tightest fit).\n    Additionally, it incorporates a small bonus for bins that, even after fitting\n    the item, still retain a substantial amount of remaining capacity, suggesting\n    they might be more useful for larger future items. This bonus is added to the\n    \"tightness\" score before the softmax transformation to influence the probabilities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # No bin can fit the item, return all zeros\n        return priorities\n\n    # --- Heuristic 1: Prioritize tightest fits (minimize remaining capacity) ---\n    # Calculate the remaining capacity after packing the item for fitting bins.\n    # Smaller values of `remaining_capacity_after_packing` are better.\n    remaining_capacity_after_packing = bins_remain_cap[can_fit_mask] - item\n\n    # To use with softmax (where higher input leads to higher probability),\n    # we want to transform this such that smaller remaining capacity yields a higher score.\n    # A simple way is to use the negative of the remaining capacity.\n    # We add a small epsilon to avoid zero if item perfectly fills a bin,\n    # and to slightly penalize perfect fits to allow other options if they exist.\n    # Let's use -(remaining_capacity_after_packing - epsilon) for a slightly\n    # better differentiation among tight fits.\n    # A very small epsilon like 1e-6 can help differentiate between bins with\n    # identical remaining capacities after packing if it's zero.\n    epsilon_tightness = 1e-6\n    tightness_scores = -(remaining_capacity_after_packing - epsilon_tightness)\n\n    # --- Heuristic 2: Bonus for future flexibility (larger remaining capacity) ---\n    # We want to add a bonus to bins that have more remaining capacity *after*\n    # the item is packed. This bonus should be less impactful than the tightness.\n    # A simple linear scaling of the remaining capacity after packing can work.\n    # We want to add a *positive* bonus to bins with *larger* remaining capacity.\n    # Let's scale `bins_remain_cap[can_fit_mask]` directly.\n    # The bonus should be smaller than the tightness score's contribution.\n    bonus_scale_factor = 0.1 # Controls the influence of flexibility\n    flexibility_bonus = bonus_scale_factor * bins_remain_cap[can_fit_mask]\n\n    # Combine the tightness score and flexibility bonus.\n    # The bonus is added to the tightness score.\n    combined_scores = tightness_scores + flexibility_bonus\n\n    # Apply softmax-like transformation to get probabilities.\n    # For numerical stability, subtract the maximum score before exponentiation.\n    max_combined_score = np.max(combined_scores)\n    exp_scores = np.exp(combined_scores - max_combined_score)\n\n    sum_exp_scores = np.sum(exp_scores)\n\n    if sum_exp_scores > 1e-9:  # Check for numerical stability\n        priorities[can_fit_mask] = exp_scores / sum_exp_scores\n    else:\n        # If all scores are extremely negative (or zero), resulting in near-zero\n        # exponentials, distribute probability equally among bins that can fit.\n        num_fitting_bins = np.sum(can_fit_mask)\n        if num_fitting_bins > 0:\n            priorities[can_fit_mask] = 1.0 / num_fitting_bins\n\n    return priorities\n\n[Reflection]\nPrioritize tight fits, balance with future flexibility, and use scaled, stable transformations.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}