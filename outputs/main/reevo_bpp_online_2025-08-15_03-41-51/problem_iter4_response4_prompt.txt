{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    return expit(x)\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin,\n    prioritizing tightest fits with a bonus for flexibility.\n\n    The priority is a composite score based on:\n    1. Tightness: Prioritizes bins with minimal remaining capacity that can fit the item.\n       This is modeled using a sigmoid function where smaller positive gaps\n       (remaining_capacity - item) yield higher scores.\n    2. Flexibility: Prioritizes bins with larger remaining capacity.\n       This is modeled using a sigmoid function of the remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins, dtype=float)\n\n    # Parameters for the scoring functions\n    # k_tight: Controls the steepness of the tightness score. Higher k_tight means\n    #          smaller gaps are much more favored.\n    # k_flex: Controls the steepness of the flexibility score. Higher k_flex means\n    #         larger capacities reach saturation faster.\n    # w_tight: Weight for the tightness component.\n    # w_flex: Weight for the flexibility component.\n    k_tight = 3.0\n    k_flex = 0.5\n    w_tight = 0.7\n    w_flex = 0.3\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Process only bins that can fit the item\n    eligible_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(eligible_bins_indices) > 0:\n        eligible_rem_cap = bins_remain_cap[eligible_bins_indices]\n        gaps = eligible_rem_cap - item\n\n        # Calculate tightness score:\n        # We want small positive gaps to have high scores.\n        # Use 1 - sigmoid(k * gap)\n        # If gap = 0, score = 1 - sigmoid(0) = 0.5\n        # If gap = small positive, score < 0.5\n        # If gap = large positive, score -> 0\n        # This is slightly counter-intuitive. Let's use sigmoid(k * (1 - gap))\n        # Or sigmoid(k * (-gap)) ... this is low for small gaps.\n\n        # Let's use sigmoid(k * (score_input)) where score_input is high for tight fits.\n        # Input to sigmoid should be high for small `gap`.\n        # e.g., `k * exp(-gap)` or `k * (1 / (1 + gap))`\n        # Let's try a simple linear mapping that we then feed to sigmoid.\n        # Map gap from [0, max_gap] to [-sensitivity, sensitivity] or similar.\n\n        # Alternative: Use the reciprocal of gap + epsilon, then normalize/sigmoid.\n        # `tightness_factor = 1.0 / (gaps + 1e-6)`\n        # `tightness_score = sigmoid(k_tight * (normalized_tightness_factor))`\n\n        # Let's stick to the reflection's idea of sigmoid on a measure.\n        # Measure of \"how tight is it\": higher value for smaller positive gap.\n        # Let `tightness_measure = -gaps`.\n        # `tightness_score = sigmoid(k_tight * tightness_measure)`\n        # If gap = 0, measure = 0, score = 0.5\n        # If gap = small positive, measure = small neg, score < 0.5\n        # If gap = large positive, measure = large neg, score -> 0.\n\n        # This is inverted again. The mapping needs to be correct.\n        # Let's re-evaluate sigmoid(X) for desired mapping:\n        # We want `f(gap)` such that `f(0)` is high, `f(large)` is low.\n\n        # Option 1: `sigmoid(k * (-gap))` -> Low for small gaps.\n        # Option 2: `1 - sigmoid(k * gap)` -> High for small gaps.\n        #   If gap=0, 1-0.5 = 0.5\n        #   If gap=small pos, 1-sigmoid(pos) = 1 - ( >0.5 ) = <0.5. This is inverted!\n\n        # Let's consider the quantity `1 / (1 + exp(-k * x))` for `x`.\n        # If we want high score for small `x`, we can use `1 / (1 + exp(k * x))`.\n        # Let `x = gaps`.\n        # `tightness_score = 1 / (1 + np.exp(k_tight * gaps))`\n        #   If gap = 0, score = 1 / (1 + 1) = 0.5\n        #   If gap = small positive, score < 0.5\n        #   If gap = large positive, score -> 0. This is still inverted.\n\n        # How about `sigmoid(k * (C - gap))`? Let C be the max possible gap or just a constant.\n        # Let C = 10 (assume max gap won't exceed 10 significantly).\n        # `tightness_score = sigmoid(k_tight * (10 - gaps))`\n        #   If gap = 0, input = 10*k_tight. Score ~ 1.\n        #   If gap = 1, input = k_tight*(10-1). Score is lower.\n        #   If gap = 10, input = 0. Score = 0.5.\n        #   If gap = 11, input = k_tight*(10-11) = -k_tight. Score < 0.5.\n\n        # This seems to work! Higher score for smaller gaps.\n        # However, we must ensure that unfit bins (negative gap if we didn't mask) are handled.\n        # The `can_fit_mask` already handles this by only processing eligible bins.\n        # So, `gaps` are always non-negative here.\n\n        # Let's normalize gaps to be more robust, or choose C carefully.\n        # Max possible gap could be `bin_capacity_limit - min_item_size`.\n        # For simplicity, let's just use `k_tight` to control sensitivity.\n        # `tightness_score = sigmoid(k_tight * (item - gaps))` --> this is `sigmoid(k_tight * (2*item - eligible_rem_cap))`\n        # Let's use `sigmoid(k_tight * (target_gap - gaps))` where `target_gap` is near 0.\n        # Let `target_gap = 0`.\n        # `tightness_score = sigmoid(k_tight * (0 - gaps))` is wrong.\n\n        # Let's define tightness as `(remaining_capacity - item)`. Smaller is better.\n        # We want a function `f(x)` where `f(0)` is high, `f(large)` is low.\n        # `f(x) = 1 / (1 + x)` is decreasing. `f(0)=1, f(large)->0`.\n        # `f(x) = exp(-k * x)` is decreasing. `f(0)=1, f(large)->0`.\n        # We can use these directly or pass them through a sigmoid.\n        # Using `exp(-k * x)` for tightness:\n        tightness_score = np.exp(-k_tight * gaps)\n\n        # Using sigmoid for flexibility, to keep scores bounded and smooth.\n        flexibility_score = sigmoid(k_flex * eligible_rem_cap)\n\n        # Combine scores\n        composite_priorities = w_tight * tightness_score + w_flex * flexibility_score\n        priorities[eligible_bins_indices] = composite_priorities\n\n    # Normalize priorities so the max is 1, for easier comparison if needed.\n    # This is optional, as relative values matter for selection.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n    # If all priorities are 0, then priorities remains all zeros.\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements the 'Almost Full Fit' priority function for online Bin Packing.\n\n    This strategy prioritizes bins that will have the least remaining capacity\n    after the item is packed, provided they can fit the item. This aims to\n    minimize wasted space in each bin.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: A NumPy array containing the remaining capacities of each bin.\n\n    Returns:\n        A NumPy array of priority scores for each bin. Bins that can fit the item\n        will have higher scores (closer to 0) if their remaining capacity after\n        packing is smaller. Bins that cannot fit the item will have a score of -inf.\n    \"\"\"\n    # Initialize priorities to negative infinity, as bins that cannot fit the item\n    # should have the lowest possible priority.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that have enough remaining capacity to accommodate the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the 'slack' (remaining capacity\n    # after the item is placed). The goal of 'Almost Full Fit' is to minimize this slack.\n    # We want bins with the smallest non-negative slack to have the highest priority.\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity in the bins *after* the item is placed.\n        remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n\n        # To prioritize bins with the smallest remaining capacity after packing,\n        # we can use the negative of this remaining capacity as the priority.\n        # A smaller remaining_after_packing (e.g., 0) will result in a higher priority (-0).\n        # A larger remaining_after_packing (e.g., 5) will result in a lower priority (-5).\n        priorities[can_fit_mask] = -remaining_after_packing\n\n    return priorities\n\n[Reflection]\nPrioritize small residual capacities; explicitly handle un-fittable bins.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}