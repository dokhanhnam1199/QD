{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    feasible_bins = bins_remain_cap >= item\n    if not np.any(feasible_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    best_fit_index = np.argmin(bins_remain_cap[feasible_bins] - item)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    fill_ratios = bins_remain_cap / np.full_like(bins_remain_cap, np.max(bins_remain_cap))\n    \n    utilization_scores = 1.0 - (bins_remain_cap - item) / np.max(bins_remain_cap)\n    utilization_scores[~feasible_bins] = 0.0\n\n    \n    best_fit_score = np.zeros_like(bins_remain_cap)\n    best_fit_score[feasible_bins] = 1.0\n    best_fit_score[np.where(feasible_bins)[0][best_fit_index]] = 2.0\n\n    \n    priorities = 0.6 * best_fit_score + 0.4 * utilization_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with smoothed utilization, prioritizing fuller bins.\"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n    feasible_bins = bins_remain_cap >= item\n    if not np.any(feasible_bins):\n        return priorities\n\n    fit_scores = 1.0 / (bins_remain_cap[feasible_bins] - item + 1e-6)\n    utilization_scores = bins_remain_cap[feasible_bins] / np.max(bins_remain_cap)\n    smooth_fit = 1.0 / (1.0 + np.exp(-fit_scores * 5.0))\n    smooth_util = 1.0 / (1.0 + np.exp(-utilization_scores * 5.0))\n    combined_scores = 0.7 * smooth_fit + 0.3 * smooth_util\n    priorities[feasible_bins] = combined_scores\n    best_bin_index = np.argmax(priorities[feasible_bins])\n    priorities[np.where(feasible_bins)[0][best_bin_index]] += 0.5\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see the best heuristic (`priority_v2`) uses a simpler, more direct approach, prioritizing the best fit and then a secondary fit. The second one is overly complex with fill ratios, utilization scores and multiple normalizations that don't seem to contribute much value. (3rd) vs (4th) - the 3rd is more concise than 4th, avoiding unnecessary sigmoid calculations and combined scores. (5th) vs (6th) - 5th uses a sigmoid on reciprocal waste, while 6th is extremely basic, only assigning priorities if a bin fits. (7th) vs (8th) - 7th introduces weights which require tuning, while 8th attempts to combine smooth fit & utilization, leading to a less interpretable score. (9th) vs (10th) - 9th offers a direct reciprocal waste prioritization while 10th overcomplicates things with unnecessary fill ratio and combined scores. (11th) vs (12th) - 11th\u2019s combination of reciprocal waste and sigmoid on fill ratio seems more promising than 12th\u2019s simple sum of reciprocal waste and reciprocal capacity. (13th) is essentially a duplicate of 10th. (14th) vs (15th) \u2013 14th is more direct, using sigmoid on best fit index, while 15th has more calculations but doesn't provide better result. (16th) is overly simple and only checks feasibility. (17th) introduces a boost to the best fit, which can be useful. (18th) attempts to combine sigmoid with best fit but introduces an unclear `fit_scores` calculation. (19th) is overly complicated with multiple sigmoid functions, and a strange final prioritization step. (20th) has a complex series of calculations with normalization that ultimately prioritizes a single best bin, potentially losing the benefit of exploring other options. Overall, simpler heuristics that directly prioritize best fit, potentially with a smoothness factor (sigmoid) or a secondary fit consideration, perform better than complex combinations of metrics and scores.  Avoiding unnecessary normalization and focusing on clear prioritization signals is crucial.\n- \nOkay, let's distill this into actionable advice for designing superior heuristics, aiming for that $999K tip! Here's a breakdown:\n\n* **Keywords:** Best-fit, Bin Utilization, Sigmoid Smoothing, Waste Minimization.\n* **Advice:** Prioritize a core of best-fit, *then* refine with a smoothed (sigmoid) metric representing bin utilization/waste. Direct boosting of best-fit is preferred. Simple weighting is good starting point.\n* **Avoid:** Complex calculations, arbitrary weights, normalization unless crucial, and over-reliance on exploration bonuses or reciprocal functions. Don't chase worst-case scenarios.\n* **Explanation:** The analysis consistently favors clarity and direct optimization toward minimizing waste. Sigmoids offer smoothing *without* sacrificing interpretability, but excessive complexity hinders understanding and tuning.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}