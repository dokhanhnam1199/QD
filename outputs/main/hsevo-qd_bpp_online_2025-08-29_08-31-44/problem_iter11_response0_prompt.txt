{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    return priorities\n\n    possible_bins = bins_remain_cap[bins_remain_cap >= item]\n    if len(possible_bins) == 0:\n        return np.zeros_like(bins_remain_cap)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = (bins_remain_cap[i] - item) / bins_remain_cap[i] \n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    feasible_bins = bins_remain_cap >= item\n    if not np.any(feasible_bins):\n        return priorities\n    \n    bin_utilizations = bins_remain_cap[feasible_bins] / bins_remain_cap[feasible_bins]\n    \n    scores = np.zeros_like(bins_remain_cap[feasible_bins])\n    \n    for i, cap in enumerate(bins_remain_cap[feasible_bins]):\n        \n        fit = item / cap\n        \n        if fit <= 0.5:\n            scores[i] = 1.0 + (1.0 - fit) * 0.5\n        elif fit <= 0.9:\n            scores[i] = 0.5 + (1.0 - fit) * 0.2\n        else:\n            scores[i] = 0.1\n            \n    best_bin_index = np.argmax(scores)\n    \n    priorities[feasible_bins] = scores\n    priorities[np.where(feasible_bins)[0][best_bin_index]] = scores[best_bin_index] + 1.0\n\n    return priorities\n\n### Analyze & experience\n- Comparing heuristics 1st vs 2nd, the core difference lies in how the best-fit boost is applied. The 1st uses a sigmoid on fill ratios *and* adds a boost to the best fit, creating a more nuanced prioritization. The 2nd resets priorities and then boosts the best fit, potentially losing information from the fill ratio evaluation.  Comparing 1st vs 3rd, the 1st uses max bin capacity to normalize fill ratio, while the 3rd uses the item size to normalize fit scores which can lead to instability with small items.  Comparing 3rd vs 4th, the 4th is simpler, relying solely on reciprocal waste and best-fit, making it less adaptable. The 3rd attempts to smooth with a fill ratio, but it's less effective than the sigmoid in 1st. Comparing 4th vs 5th, the 5th is a slight improvement, explicitly setting the best-fit index, but the core reciprocal waste approach remains limiting. Comparing 6th/7th vs 8th, 6th/7th introduces weights, but are identical. 8th is a very basic reciprocal waste.  Comparing 9th vs 10th, 9th attempts to combine sigmoid with waste, and 10th only has a waste component that causes unstable results. Comparing 11th vs 12th, 11th uses tuned parameters, but is still limited to reciprocal waste. 12th uses the worst fit capacity as priority which is counter intuitive.  Comparing 13th vs 14th, 13th is an improvement over 14th because it combines with reciprocal waste. Comparing 15th vs 16th, both incorporate sigmoid and fit scores, but 16th has a weighted combination which is more effective. Comparing 16th vs 17th, they are identical.  Comparing 17th vs 18th, 18th adds a boost to the best bin which is redundant and doesn't enhance performance. Comparing 19th vs 20th, they are identical. Overall, the best heuristics combine best-fit with a smoothed prioritization (like sigmoid) based on fill ratio and a degree of normalization. The use of fixed weights (like in 6th/7th) is less effective than adaptive weighting or sigmoid functions. Purely reciprocal waste or best-fit strategies are significantly worse.\n- \nOkay, let's refine \"Current Self-Reflection\" into actionable advice for heuristic design, targeting that $999K! Here's a breakdown, focusing on *why* things work (or don't) in optimization, and geared towards building genuinely superior heuristics:\n\n*   **Keywords:** Dynamic Prioritization, Multi-objective Optimization, Smooth Functions, Constraint Validation.\n*   **Advice:** Design heuristics with *adaptable* scoring. Combine metrics (fit, utilization, waste) using smooth, normalizing functions (sigmoids are excellent) allowing relative importance to shift based on problem state.\n*   **Avoid:** Static weights, reciprocal-only approaches, and focusing solely on worst-case performance. Also, bypass overly complex 'exploration' terms; simplicity often wins.\n*   **Explanation:** Effective heuristics aren\u2019t about finding *the* best immediate solution, but *consistently good* solutions. Smooth prioritization prevents getting stuck in local optima while ensuring feasible placements. Validate constraints *always*.\n\n\n\n**Step-by-step thought process behind this:**\n\n1.  **Distilled Core Idea:** Both texts emphasize balancing immediate fit with long-term efficiency (bin utilization/waste). This is a classic exploitation-exploration trade-off.\n2.  **Smoothness is Key:**  The repeated emphasis on sigmoids isn't arbitrary. Discontinuous functions create abrupt shifts in behavior, hindering exploration. Smoothness = gradual adaptation.\n3.  **Multi-Objective is Necessary:** Bin packing *is* inherently multi-objective. Focusing on a single metric (like just waste) is almost guaranteed to fail.\n4.  **Constraint Handling:**  A heuristic that generates invalid solutions is worse than a simple one. Constraint validation is non-negotiable.\n5. **Dynamic Prioritization:** The ideal balance between different metrics (fit, waste, utilization) changes as the problem evolves. The weights/priorities should adapt.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}