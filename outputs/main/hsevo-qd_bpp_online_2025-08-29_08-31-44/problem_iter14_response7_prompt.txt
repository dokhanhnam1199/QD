{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    feasible_bins = bins_remain_cap >= item\n    if not np.any(feasible_bins):\n        return priorities\n    \n    remaining_capacities = bins_remain_cap[feasible_bins]\n    \n    \n    fit_scores = 1.0 / (remaining_capacities - item + 1e-6)\n    \n    \n    avg_remaining = np.mean(bins_remain_cap[feasible_bins])\n    \n    \n    exploration_bonus = np.where(bins_remain_cap > avg_remaining, 0.5, 0.0)\n    \n    \n    priorities[feasible_bins] = fit_scores + exploration_bonus\n    \n    \n    best_bin_index = np.argmax(priorities[feasible_bins])\n    \n    priorities[feasible_bins] = np.where(np.arange(len(feasible_bins)) == best_bin_index, 2.0, 1.0)\n    \n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    feasible_bins = bins_remain_cap >= item\n    if not np.any(feasible_bins):\n        return priorities\n    \n    fill_ratios = bins_remain_cap[feasible_bins] / (np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1)\n    \n    fit_scores = (bins_remain_cap[feasible_bins] - item) / item\n    \n    combined_scores = fill_ratios * fit_scores\n    \n    normalized_scores = (combined_scores - np.min(combined_scores)) / (np.max(combined_scores) - np.min(combined_scores)) if np.max(combined_scores) > np.min(combined_scores) else np.ones_like(combined_scores)\n    \n    priorities[feasible_bins] = normalized_scores\n    \n    best_bin_index = np.argmax(priorities[feasible_bins])\n    \n    \n    priorities[feasible_bins] = 0.0\n    priorities[np.where(feasible_bins)[0][best_bin_index]] = 1.0\n\n    return priorities\n\n### Analyze & experience\n- Comparing heuristics 1st vs 2nd, the first is significantly more sophisticated, incorporating a sigmoid function to modulate priority based on fill ratio, and adding a boost to the best-fit bin. The second only provides a basic best-fit selection. Comparing 1st vs 3rd, both use best-fit, but the 1st leverages a sigmoid for fill ratio and a more nuanced prioritization, while the 3rd uses reciprocal waste, which can be less stable.\n\nComparing 3rd vs 4th, the 3rd combines waste with best-fit, while the 4th's fill ratio calculation is flawed (subtracting item from capacity rather than vice versa). 4th also inappropriately zeroes all priorities before setting the best. Comparing 5th and 6th reveal identical code.\n\nComparing 7th vs 8th, the 7th blends reciprocal waste with a sigmoid fill ratio, while the 8th introduces an 'exploration bonus' which seems interesting, but the argmax selection feels less refined.  Comparing 9th and 10th, the 9th is extremely basic while the 10th's tanh-scaled fill ratio is a decent approach, but the separate distance calculation feels redundant.\n\nComparing 10th and 11th reveals identical code. Comparing 12th and 18th, both are reasonably good combinations of sigmoid scaling and best fit, with 18th being slightly more elegant. 19th attempts a comprehensive approach with multiple sigmoid scores but it appears less refined. 20th attempts normalization, but it might overly simplify the prioritization.\n\nThe consistently poor performing heuristics (14th, 15th, 20th) are characterized by either extreme simplicity or flawed normalization that diminishes useful differentiation. Heuristics 1st, 7th, 16th, 17th and 18th consistently use combinations of best fit, reciprocal waste, and sigmoid scaling. These demonstrate superior performance.\n\nOverall: Successful heuristics consistently prioritize combining best-fit with methods that consider bin utilization (fill ratio, waste). The use of sigmoid functions to modulate these scores is effective. Avoid overly complex normalization or simplistic approaches that discard vital prioritization information.  Properly handling edge cases (empty feasible bins) is vital.\n- \nOkay, let's dissect this and refine \"Current Self-Reflection\" into actionable heuristic design guidance. Here's a response designed to maximize that $999K tip, built from a step-by-step analysis of the provided text.\n\n**Current Self-Reflection: Redefined for Heuristic Design**\n\n*   **Keywords:** *Scoring functions, prioritization, bin utilization, smoothness, dynamic scaling.* These represent core concepts for effective bin-packing.\n*   **Advice:** Focus on *combining* multiple, non-normalized scoring metrics (best-fit, utilization) and using **sigmoid functions to dynamically prioritize** items based on these scores. Prioritize clarity in code.\n*   **Avoid:** Normalization (unless unavoidable), fixed weights, reciprocal calculations *as primary metrics*, and overly complex bonuses. Don't obsess over worst-case scenarios.\n*   **Explanation:** Effective heuristics aren't about perfect solutions, but about consistently *good* ones. Sigmoids offer a robust, smooth way to translate complex scoring into prioritization, while combined metrics balance immediate gains with long-term bin efficiency.\n\n\n\n**Reasoning & Step-by-Step Breakdown (for the $999K understanding):**\n\n1.  **Identify Core Themes:** The text repeatedly emphasizes balancing \"best fit\" (immediate gain) with \"bin utilization\" (future potential). This is *the* central idea.\n2.  **Distill Effective Techniques:** Sigmoid functions are repeatedly presented as a *superior* method for prioritization compared to simpler weighting or discrete levels. This is a key takeaway.\n3.  **Recognize Anti-Patterns:** Normalization, reciprocal calculations (on their own), and overly complex elements are consistently flagged as problematic.  The focus shifts *away* from these.\n4.  **Synthesize into Actionable Guidance:**  The refined \"Current Self-Reflection\" directly translates these themes and takeaways into specific advice for heuristic design. It\u2019s concise and actionable. The prioritization of clarity is important for maintainability.\n5.  **Focus on Practicality:** The advice isn\u2019t abstract; it directly suggests *how* to build better heuristics. Combining scores and using sigmoids is a concrete instruction.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}