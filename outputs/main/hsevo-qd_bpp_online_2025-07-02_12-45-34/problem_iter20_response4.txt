```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes bins considering waste, fullness, and item size."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0
    avg_cap = np.mean(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0

    fit_reward: float = 1.8
    overflow_penalty: float = 0.2
    fullness_bonus: float = 0.25
    close_fit_boost: float = 0.75
    close_fit_threshold: float = 0.3
    empty_bin_penalty: float = 0.18
    large_item_threshold: float = 0.6
    reduced_empty_bin_penalty_factor: float = 0.09
    diversity_bonus_factor: float = 0.005
    near_empty_threshold: float = 0.88

    # Reward bins where the item fits
    fit_mask = bins_remain_cap >= item
    waste = bins_remain_cap - item
    priorities[fit_mask] += fit_reward / (waste[fit_mask] + 0.000001)

    # Penalize overflow
    overflow_mask = ~fit_mask
    overflow = item - bins_remain_cap[overflow_mask]
    priorities[overflow_mask] -= overflow_penalty * overflow / (max_cap + 0.000001)

    # Bonus for fullness
    fullness = 1 - bins_remain_cap / (max_cap + 0.000001)
    priorities += fullness_bonus * fullness

    # Boost bins with close fit
    close_fit_mask = fit_mask & (waste <= (close_fit_threshold * max_cap))
    if np.any(close_fit_mask):
        ratios = item / bins_remain_cap[close_fit_mask]
        priorities[close_fit_mask] += close_fit_boost * np.log(ratios)

    # Adaptive empty bin handling
    near_empty_mask = bins_remain_cap > (near_empty_threshold * max_cap)
    if item > large_item_threshold * max_cap:
        priorities[near_empty_mask] -= reduced_empty_bin_penalty_factor * empty_bin_penalty
    else:
        priorities[near_empty_mask] -= empty_bin_penalty

    # Bin diversity
    cap_diff = np.abs(bins_remain_cap - avg_cap)
    diversity_bonus = diversity_bonus_factor * (max_cap - cap_diff)
    priorities += diversity_bonus

    return priorities
```
