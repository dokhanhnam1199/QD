```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritizes bins using waste, overflow, fullness, and item size.
    Dynamically adjusts weights based on item size.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    waste = bins_remain_cap - item
    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0
    
    fit_reward = 1.2
    overflow_penalty = 0.6
    fullness_bonus = 0.25
    close_fit_boost = 0.8
    close_fit_threshold = 0.2
    item_size_penalty_factor = 0.5
    
    # Item size scaling for weights
    item_scale = min(1.0, item / max_cap)
    
    # Reward fitting bins
    fit_mask = waste >= 0
    priorities[fit_mask] += fit_reward / (waste[fit_mask] + 0.000001)

    # Penalize overflow
    overflow_mask = ~fit_mask
    overflow = item - bins_remain_cap[overflow_mask]
    priorities[overflow_mask] -= overflow_penalty * overflow / (max_cap + 0.000001)

    # Bonus for fullness
    fullness = 1 - bins_remain_cap / (max_cap + 0.000001)
    priorities += fullness_bonus * fullness * (1 + item_scale)  # Scale by item size

    # Boost close fits
    close_fit_mask = fit_mask & (waste <= (close_fit_threshold * max_cap))
    if np.any(close_fit_mask):
        ratios = item / bins_remain_cap[close_fit_mask]
        priorities[close_fit_mask] += close_fit_boost * np.log(ratios)

    # Item size penalty
    slightly_larger_mask = fit_mask & (waste < (0.5 * item))
    priorities[slightly_larger_mask] -= item_size_penalty_factor * (item / (max_cap + 0.000001))
    
    return priorities
```
