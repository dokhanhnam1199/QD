{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins using adaptive weighting, multiple factors, and bin utilization awareness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    avg_cap = np.mean(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    min_cap = np.min(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    num_bins = len(bins_remain_cap)\n    total_capacity = np.sum(bins_remain_cap)\n\n    # Hyperparameters with adaptive adjustments\n    fit_reward = 1.0\n    overflow_penalty = 0.5\n    fullness_bonus = 0.2\n    close_fit_boost = 0.7\n    close_fit_threshold = 0.2\n    empty_bin_penalty = 0.3\n    diversity_bonus_weight = 0.01\n    item_size_penalty = 0.4\n    capacity_utilization_bonus = 0.1\n\n    # Adaptive adjustments based on item size\n    if item > 0.7 * max_cap:\n        fit_reward *= 1.1\n        overflow_penalty *= 0.9\n        close_fit_boost *= 0.9\n    elif item < 0.3 * max_cap:\n        fullness_bonus *= 1.2\n        empty_bin_penalty *= 1.3\n        item_size_penalty *= 0.6\n\n    # Fit Reward\n    fit_mask = waste >= 0\n    priorities[fit_mask] += fit_reward / (waste[fit_mask] + 0.000001)\n\n    # Overflow Penalty\n    overflow_mask = ~fit_mask\n    overflow = item - bins_remain_cap[overflow_mask]\n    priorities[overflow_mask] -= overflow_penalty * overflow / (max_cap + 0.000001)\n\n    # Fullness Bonus\n    fullness = 1 - bins_remain_cap / (max_cap + 0.000001)\n    priorities += fullness_bonus * fullness\n\n    # Close Fit Boost\n    close_fit_mask = fit_mask & (waste <= (close_fit_threshold * max_cap))\n    if np.any(close_fit_mask):\n        ratios = item / bins_remain_cap[close_fit_mask]\n        priorities[close_fit_mask] += close_fit_boost * np.log(ratios)\n\n    # Adaptive Empty Bin Handling\n    near_empty_mask = bins_remain_cap > (0.9 * max_cap)\n    if item > 0.5 * max_cap:\n        priorities[near_empty_mask] -= 0.05 * empty_bin_penalty\n    else:\n        priorities[near_empty_mask] -= empty_bin_penalty\n\n    # Bin Diversity Consideration\n    cap_diff = np.abs(bins_remain_cap - avg_cap)\n    diversity_bonus = diversity_bonus_weight * (max_cap - cap_diff)\n    priorities += diversity_bonus\n    \n    # Item Size penalty\n    slightly_larger_mask = fit_mask & (waste < (0.5 * item))\n    priorities[slightly_larger_mask] -= item_size_penalty * (item / (max_cap + 0.000001))\n\n    # Capacity Utilization Bonus - encourages filling bins when overall utilization is low\n    overall_utilization = (1 - (total_capacity / (num_bins * max_cap))) if num_bins > 0 else 0.0\n    priorities += capacity_utilization_bonus * overall_utilization * (1 - bins_remain_cap / (max_cap + 0.000001))\n    \n    # Prioritize bins with closer capacity to item when utilization is low.\n    if overall_utilization < 0.3 and np.any(fit_mask):\n      capacity_difference = np.abs(bins_remain_cap[fit_mask] - item)\n      priorities[fit_mask] += (1 - capacity_difference/ (max_cap + 0.000001)) * 0.1\n\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins based on a combination of factors, with adaptive weighting to improve performance.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    avg_cap = np.mean(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    min_cap = np.min(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    capacity_std = np.std(bins_remain_cap) if len(bins_remain_cap) > 1 else 0.0\n    \n    # Adaptive Weighting Factors (Initialized, to be potentially modified based on conditions)\n    fit_reward_weight = 1.2\n    overflow_penalty_weight = 0.7\n    fullness_bonus_weight = 0.3\n    close_fit_boost_weight = 0.9\n    empty_bin_penalty_weight = 0.35\n    item_size_penalty_weight = 0.6\n    std_dev_penalty_weight = 0.06\n    diversity_bonus_weight = 0.01\n\n    close_fit_threshold = 0.2\n\n    # Scenario-Specific Adjustments (Example: Adapt weights based on item size relative to bin sizes)\n    if item > 0.7 * max_cap:\n        # Increase importance of fitting and reduce penalty for some waste\n        fit_reward_weight *= 1.1\n        overflow_penalty_weight *= 0.9\n        close_fit_boost_weight *= 0.9  # Closer fit is less critical with larger items\n    elif item < 0.3 * max_cap:\n        # Emphasize fullness and penalize using almost empty bins\n        fullness_bonus_weight *= 1.2\n        empty_bin_penalty_weight *= 1.3\n        item_size_penalty_weight *= 0.8 # Reduce size penalty for small item\n\n    # Reward bins where the item fits\n    fit_mask = waste >= 0\n    priorities[fit_mask] += fit_reward_weight / (waste[fit_mask] + 0.000001)\n\n    # Penalize overflow, relative to the maximum bin capacity\n    overflow_mask = ~fit_mask\n    overflow = item - bins_remain_cap[overflow_mask]\n    priorities[overflow_mask] -= overflow_penalty_weight * overflow / (max_cap + 0.000001)\n\n    # Bonus for bins that are already relatively full\n    fullness = 1 - bins_remain_cap / (max_cap+0.000001)\n    priorities += fullness_bonus_weight * fullness\n\n    # Further boost bins with small waste, using a ratio-based approach\n    close_fit_mask = fit_mask & (waste <= (close_fit_threshold * max_cap))\n    if np.any(close_fit_mask):\n        ratios = item / bins_remain_cap[close_fit_mask]\n        priorities[close_fit_mask] += close_fit_boost_weight * np.log(ratios)\n\n    # Adaptive Empty Bin Handling: Penalize near-empty bins less if item is large\n    empty_bin_threshold = 0.1 * max_cap\n    near_empty_mask = bins_remain_cap > (0.9 * max_cap)\n    if item > 0.5 * max_cap:  # If item is relatively large\n          priorities[near_empty_mask] -= 0.05 * empty_bin_penalty_weight  # Reduced penalty\n    else:\n          priorities[near_empty_mask] -= empty_bin_penalty_weight  # Standard penalty\n\n    # Item Size Relative to Bin Size Penalty:\n    # Penalize bins that are only slightly larger than the item. This encourages using larger bins\n    # for larger items and smaller bins for smaller items\n    slightly_larger_mask = fit_mask & (waste < (0.5 * item))\n    priorities[slightly_larger_mask] -= item_size_penalty_weight * (item / (max_cap + 0.000001))\n\n    #Bin Diversity Consideration\n    cap_diff = np.abs(bins_remain_cap - avg_cap)\n    diversity_bonus = diversity_bonus_weight * (max_cap - cap_diff) # Bias toward bins that have capacities closer to the average\n    priorities += diversity_bonus\n    \n    # Capacity standard deviation penalty.\n    priorities -= std_dev_penalty_weight * capacity_std / (max_cap + 0.000001)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (16th), we see the introduction of adaptive adjustments based on item size relative to max capacity is beneficial. (2nd) vs (20th) reveals the same pattern. Comparing (1st) vs (2nd), we observe the slight variation in hyperparameter values. Comparing (3rd) vs (4th), we see no difference, indicating identical code. Comparing (second worst) vs (worst), they are identical.\n\n(5th) introduces `min_cap` and `fragmentation_penalty`, along with adjustments based on `item_ratio_avg` and item-aware adjustments.  This shows more sophisticated handling of item size relative to bin capacities. This is an improvement over the earlier heuristics, which primarily focus on `max_cap`.\n\n(6th) incorporates `num_bins` and `total_capacity` to introduce a `capacity_utilization_bonus`. It prioritizes bins based on overall utilization, showing an awareness of the global state, which improves overall bin packing.\n\n(8th) introduces adaptive weighting factors and scenario-specific adjustments based on item size relative to bin sizes. It includes a penalty based on capacity standard deviation, aiming to reduce variance in bin fullness.\n\n(9th) focuses on tuning hyperparameters through manual exploration and intuition and emphasizes a balance between fitting, overflow, and fullness.\n\nOverall: The better heuristics progressively incorporate more factors: adapting weights based on item size, considering global bin utilization, and tuning hyperparameters, while penalizing the capacity standard deviation. The less effective heuristics focus primarily on immediate fit and waste, without considering the broader context of bin utilization and item characteristics. The most successful heuristics use adaptive strategies that adjust weights and penalties based on the item size and bin characteristics.\n- \nOkay, let's redefine self-reflection for better heuristic design, focusing on actionable insights and avoiding common pitfalls.\n\n*   **Keywords:** Adaptive, contextual, incremental, hyperparameter tuning, multi-objective, problem characteristics, trade-offs, diversification.\n*   **Advice:** Systematically build complexity by adding relevant factors one at a time and by introducing adaptive parameters. Prioritize adaptability to system state. Explicitly account for trade-offs by considering penalties/bonuses for each objective.\n*   **Avoid:** Sole reliance on simple ratios, premature complexity, ignoring problem-specific context, and insufficient hyperparameter tuning.\n*   **Explanation:** Heuristic design should be an iterative process, moving from simple to complex, driven by data, and always aware of the specific problem characteristics to ensure adaptability and effectiveness.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}