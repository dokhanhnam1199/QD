```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritizes bins considering waste, overflow, fullness, item size relative to bin sizes, and adaptive strategies.
    This version dynamically adjusts hyperparameters based on item size and bin capacity distribution.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    waste = bins_remain_cap - item
    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0
    avg_cap = np.mean(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0
    min_cap = np.min(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0
    capacity_std = np.std(bins_remain_cap) if len(bins_remain_cap) > 1 else 0.0

    # Adaptive Hyperparameters (Dynamically adjusted)
    item_size_ratio = item / max_cap if max_cap > 0 else 0.0
    capacity_range = max_cap - min_cap

    # Base values (can be adjusted based on performance)
    fit_reward_base = 1.2
    overflow_penalty_base = 0.6
    fullness_bonus_base = 0.25
    close_fit_boost_base = 0.8
    empty_bin_penalty_base = 0.3
    item_size_penalty_factor_base = 0.5
    std_dev_penalty_base = 0.05

    # Adaptive Adjustment Factors (Tuned for better performance)
    fit_reward = fit_reward_base * (1 + 0.2 * item_size_ratio) # Larger items get higher fit reward
    overflow_penalty = overflow_penalty_base * (1 + 0.1 * (1 - item_size_ratio)) # Smaller items get lower overflow penalty
    fullness_bonus = fullness_bonus_base * (1 + 0.1 * (capacity_range / max_cap)) # More diverse capacities reward fullness more.
    close_fit_boost = close_fit_boost_base * (1 + 0.1 * (1 - capacity_range / max_cap)) # If capacity is consistent boost close fit
    empty_bin_penalty = empty_bin_penalty_base * (1 + 0.2 * item_size_ratio) # Larger items penalized less for near empty bins
    item_size_penalty_factor = item_size_penalty_factor_base * (1 + 0.1 * item_size_ratio) # Larger items penalize larger bins.
    std_dev_penalty = std_dev_penalty_base * (1 + 0.05 * (capacity_range / max_cap)) # more std penalty where capacity range is diverse.

    close_fit_threshold = 0.2

    # Reward bins where the item fits
    fit_mask = waste >= 0
    priorities[fit_mask] += fit_reward / (waste[fit_mask] + 0.000001)

    # Penalize overflow, relative to the maximum bin capacity
    overflow_mask = ~fit_mask
    overflow = item - bins_remain_cap[overflow_mask]
    priorities[overflow_mask] -= overflow_penalty * overflow / (max_cap + 0.000001)

    # Bonus for bins that are already relatively full
    fullness = 1 - bins_remain_cap / (max_cap+0.000001)
    priorities += fullness_bonus * fullness

    # Further boost bins with small waste, using a ratio-based approach
    close_fit_mask = fit_mask & (waste <= (close_fit_threshold * max_cap))
    if np.any(close_fit_mask):
        ratios = item / bins_remain_cap[close_fit_mask]
        priorities[close_fit_mask] += close_fit_boost * np.log(ratios)

    # Adaptive Empty Bin Handling: Penalize near-empty bins less if item is large
    empty_bin_threshold = 0.1 * max_cap
    near_empty_mask = bins_remain_cap > (0.9 * max_cap)
    if item > 0.5 * max_cap:  # If item is relatively large
          priorities[near_empty_mask] -= 0.05 * empty_bin_penalty  # Reduced penalty
    else:
          priorities[near_empty_mask] -= empty_bin_penalty  # Standard penalty

    # Item Size Relative to Bin Size Penalty:
    # Penalize bins that are only slightly larger than the item. This encourages using larger bins
    # for larger items and smaller bins for smaller items
    slightly_larger_mask = fit_mask & (waste < (0.5 * item))
    priorities[slightly_larger_mask] -= item_size_penalty_factor * (item / (max_cap + 0.000001))

    #Bin Diversity Consideration
    cap_diff = np.abs(bins_remain_cap - avg_cap)
    diversity_bonus = 0.01 * (max_cap - cap_diff) # Bias toward bins that have capacities closer to the average
    priorities += diversity_bonus
    
    # Capacity standard deviation penalty.
    priorities -= std_dev_penalty * capacity_std / (max_cap + 0.000001)

    return priorities
```
