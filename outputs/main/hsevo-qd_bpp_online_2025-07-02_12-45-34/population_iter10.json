[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate waste if item is placed in each bin\n    waste = bins_remain_cap - item\n\n    # Give high priority to bins where item fits and waste is minimized\n    fit_mask = waste >= 0\n    priorities[fit_mask] = 1 / (waste[fit_mask] + 0.000001)  # Add a small constant to avoid division by zero\n\n    # Give slightly lower priority to bins where item doesn't fit, but the overflow is minimized\n    # This encourages splitting items across bins less often but still allows it when needed\n    overflow_mask = ~fit_mask\n    priorities[overflow_mask] = - (item - bins_remain_cap[overflow_mask]) / (np.max(bins_remain_cap) + 0.000001) #Prioritize bins closer to fitting the item\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 92.0,
    "mi": 83.94080546850132,
    "token_count": 115.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste and overflow, improved version.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n\n    fit_mask = waste >= 0\n    priorities[fit_mask] = 1 / (waste[fit_mask] + 0.000001)\n\n    overflow_mask = ~fit_mask\n    overflow = item - bins_remain_cap[overflow_mask]\n    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0 # avoid empty array\n    priorities[overflow_mask] = - overflow / (max_cap + 0.000001)\n\n    # Introduce a small bonus for bins that are already relatively full\n    fullness = 1 - bins_remain_cap / (np.max(bins_remain_cap)+0.000001) # Avoid zero division and normalized to max bin size\n    priorities += 0.1 * fullness  # scale fullness\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 159.81495041679716,
    "mi": 88.77760257484631,
    "token_count": 118.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate waste if item is placed in each bin\n    waste = bins_remain_cap - item\n    \n    # Give high priority to bins where item fits and waste is minimized\n    fit_mask = waste >= 0\n    \n    # Prioritize bins with smaller waste, but also consider the fill ratio\n    # Encourage filling bins as much as possible\n    fill_ratio = (bins_remain_cap[fit_mask] - waste[fit_mask]) / bins_remain_cap[fit_mask]\n    priorities[fit_mask] = (1 / (waste[fit_mask] + 0.000001)) * (1 + fill_ratio) # Combine waste and fill ratio\n\n    # Adjust priority based on the item size relative to the bin capacity\n    # If the item is relatively large, prioritize bins that are closer to being full.\n    large_item_threshold = 0.5 * np.max(bins_remain_cap)  # Define a threshold for \"large\" items\n    if item > large_item_threshold:\n        priorities[fit_mask] *= (bins_remain_cap[fit_mask] / np.max(bins_remain_cap)) #Prioritize almost full bins\n\n    # Give negative priority to bins where item doesn't fit, proportional to overflow\n    overflow_mask = ~fit_mask\n    overflow = item - bins_remain_cap[overflow_mask]\n    priorities[overflow_mask] = -overflow / (np.max(bins_remain_cap) + 0.000001)  # Prioritize bins with smaller overflow\n\n    # Add a small bonus to bins with capacity close to the item size\n    # This encourages perfect fits\n    close_fit_mask = (bins_remain_cap >= (item - 0.1 * item)) & (bins_remain_cap <= (item + 0.1 * item)) & fit_mask\n    priorities[close_fit_mask] += 0.5\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 177.87213211613133,
    "mi": 79.3725642842327,
    "token_count": 165.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, fit_priority_scale: float = 3.2155309410593764, waste_epsilon: float = 3.241139675159933e-05, overflow_priority_scale: float = 9.976943356947597, max_cap_epsilon: float = 0.0001001235545987124) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        fit_priority_scale: Scale of the priority when the item fits.\n        waste_epsilon: Small constant to avoid division by zero when calculating waste priority.\n        overflow_priority_scale: Scale of the priority when the item doesn't fit.\n        max_cap_epsilon: Small constant to avoid division by zero when prioritizing bins closer to fitting.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate waste if item is placed in each bin\n    waste = bins_remain_cap - item\n\n    # Give high priority to bins where item fits and waste is minimized\n    fit_mask = waste >= 0\n    priorities[fit_mask] = fit_priority_scale / (waste[fit_mask] + waste_epsilon)  # Add a small constant to avoid division by zero\n\n    # Give slightly lower priority to bins where item doesn't fit, but the overflow is minimized\n    # This encourages splitting items across bins less often but still allows it when needed\n    overflow_mask = ~fit_mask\n    priorities[overflow_mask] = -overflow_priority_scale * (item - bins_remain_cap[overflow_mask]) / (np.max(bins_remain_cap) + max_cap_epsilon) #Prioritize bins closer to fitting the item\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 128.3789500201924,
    "mi": 67.81667210426089,
    "token_count": 139.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, overflow, and fill level.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n    fit_mask = waste >= 0\n\n    #Prioritize bins where item fits, minimizing waste.\n    priorities[fit_mask] = 1 / (waste[fit_mask] + 0.000001)\n\n    #Penalize overflow, but prioritize bins closer to fitting.\n    overflow_mask = ~fit_mask\n    priorities[overflow_mask] = - (item - bins_remain_cap[overflow_mask]) / (np.max(bins_remain_cap) + 0.000001)\n\n    #Incentivize filling bins that are already relatively full.\n    fullness = (1 - bins_remain_cap / np.max(bins_remain_cap))\n    priorities += fullness * 0.1 #Scale down to avoid dominating other factors\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 175.93083758004835,
    "mi": 90.27968087310084,
    "token_count": 129.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Enhanced priority function considering multiple factors for better bin packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_count = len(bins_remain_cap)\n\n    # Calculate waste if item is placed in each bin\n    waste = bins_remain_cap - item\n\n    # Fit Heuristic: Prioritize bins where the item fits.\n    fit_mask = waste >= 0\n    if np.any(fit_mask):  # Only apply if at least one bin can fit the item\n        priorities[fit_mask] = (1 / (waste[fit_mask] + 0.000001)) + 0.1  # Increate priority compared to overflow. Avoid zero division.\n\n        # Best Fit Improvement:  Slightly boost the priority of bins with minimal waste.\n        min_waste = np.min(waste[fit_mask])\n        best_fit_mask = (waste == min_waste) & fit_mask\n        priorities[best_fit_mask] += 0.2  # A small bonus for the best fit\n\n        # Reward near-full bins:\n        near_full_threshold = 0.1  # Define a threshold for \"near full\" (e.g., 10% of bin capacity)\n        near_full_mask = (bins_remain_cap <= (item + near_full_threshold)) & fit_mask\n        priorities[near_full_mask] += 0.3 #Big bonus for filling near-full bins.\n    # Overflow Heuristic: Only used when NO bin fits.\n    else:\n        overflow_mask = ~fit_mask\n        priorities[overflow_mask] = - (item - bins_remain_cap[overflow_mask]) / (np.max(bins_remain_cap) + 0.000001)\n        # Try to balance load (least overflow)\n        min_overflow = np.min(item - bins_remain_cap[overflow_mask])\n        least_overflow_mask = (item - bins_remain_cap == min_overflow) & overflow_mask\n        priorities[least_overflow_mask] += 0.2 #Bonus for minimizing overflow when no fit\n\n    # Bin balancing. Incentivize bins with higher remaining capacity (avoid using bins too unevenly if possible)\n    priorities += bins_remain_cap / (np.sum(bins_remain_cap) + 0.000001) #Added term for load balancing across bins\n\n    return priorities",
    "response_id": 2,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 317.77665530336594,
    "mi": 78.8165571098739,
    "token_count": 209.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering waste, overflow, and fullness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n\n    # Reward bins where the item fits\n    fit_mask = waste >= 0\n    priorities[fit_mask] = 1 / (waste[fit_mask] + 0.000001)\n\n    # Penalize overflow, relative to the maximum bin capacity\n    overflow_mask = ~fit_mask\n    overflow = item - bins_remain_cap[overflow_mask]\n    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    priorities[overflow_mask] = - overflow / (max_cap + 0.000001)\n\n    # Bonus for bins that are already relatively full\n    fullness = 1 - bins_remain_cap / (max_cap+0.000001)\n    priorities += 0.1 * fullness\n\n    # Further boost bins with small waste, using a ratio-based approach\n    close_fit_mask = fit_mask & (waste <= (0.2 * max_cap)) #tune threshold\n    if np.any(close_fit_mask):  # Check if close_fit_mask is not empty\n        ratios = item / bins_remain_cap[close_fit_mask]\n        priorities[close_fit_mask] += 0.5 * np.log(ratios)  # Boost priority\n\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 3.520143597925803,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 322.4095353505972,
    "mi": 83.84711046495362,
    "token_count": 198.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins considering waste, overflow, fullness, and adaptive strategies.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    avg_cap = np.mean(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0\n    \n    #Hyperparameters (Tuned using some manual exploration and intuition)\n    fit_reward = 1.0\n    overflow_penalty = 0.5\n    fullness_bonus = 0.2\n    close_fit_boost = 0.7\n    close_fit_threshold = 0.2\n    empty_bin_penalty = 0.3\n    \n    # Reward bins where the item fits\n    fit_mask = waste >= 0\n    priorities[fit_mask] += fit_reward / (waste[fit_mask] + 0.000001)\n\n    # Penalize overflow, relative to the maximum bin capacity\n    overflow_mask = ~fit_mask\n    overflow = item - bins_remain_cap[overflow_mask]\n    priorities[overflow_mask] -= overflow_penalty * overflow / (max_cap + 0.000001)\n\n    # Bonus for bins that are already relatively full\n    fullness = 1 - bins_remain_cap / (max_cap+0.000001)\n    priorities += fullness_bonus * fullness\n\n    # Further boost bins with small waste, using a ratio-based approach\n    close_fit_mask = fit_mask & (waste <= (close_fit_threshold * max_cap))\n    if np.any(close_fit_mask):\n        ratios = item / bins_remain_cap[close_fit_mask]\n        priorities[close_fit_mask] += close_fit_boost * np.log(ratios)\n\n    # Adaptive Empty Bin Handling: Penalize near-empty bins less if item is large\n    empty_bin_threshold = 0.1 * max_cap\n    near_empty_mask = bins_remain_cap > (0.9 * max_cap) # or > (max_cap - empty_bin_threshold)\n    if item > 0.5 * max_cap:  # If item is relatively large\n          priorities[near_empty_mask] -= 0.05 * empty_bin_penalty #Reduced penalty\n    else:\n          priorities[near_empty_mask] -= empty_bin_penalty  #Standard penalty\n          \n    #Bin Diversity Consideration\n    cap_diff = np.abs(bins_remain_cap - avg_cap)\n    diversity_bonus = 0.01 * (max_cap - cap_diff) # Bias toward bins that have capacities closer to the average\n    priorities += diversity_bonus\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 1.6753091344236206,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 504.05700000156156,
    "mi": 76.9490152829919,
    "token_count": 310.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, fit_priority_increase: float = 0.05871897898152656, best_fit_bonus: float = 0.3269301550449213, near_full_threshold: float = 0.03397489112635859, near_full_bonus: float = 0.31739300030762885, least_overflow_bonus: float = 0.46884437566482223) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Enhanced priority function considering multiple factors for better bin packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        fit_priority_increase: Increase in priority for bins where the item fits.\n        best_fit_bonus: Bonus for bins with minimal waste.\n        near_full_threshold: Threshold for considering a bin as \"near full\".\n        near_full_bonus: Bonus for filling near-full bins.\n        least_overflow_bonus: Bonus for minimizing overflow when no fit is found.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_count = len(bins_remain_cap)\n\n    # Calculate waste if item is placed in each bin\n    waste = bins_remain_cap - item\n\n    # Fit Heuristic: Prioritize bins where the item fits.\n    fit_mask = waste >= 0\n    if np.any(fit_mask):  # Only apply if at least one bin can fit the item\n        priorities[fit_mask] = (1 / (waste[fit_mask] + 0.000001)) + fit_priority_increase  # Increate priority compared to overflow. Avoid zero division.\n\n        # Best Fit Improvement:  Slightly boost the priority of bins with minimal waste.\n        min_waste = np.min(waste[fit_mask])\n        best_fit_mask = (waste == min_waste) & fit_mask\n        priorities[best_fit_mask] += best_fit_bonus  # A small bonus for the best fit\n\n        # Reward near-full bins:\n        near_full_mask = (bins_remain_cap <= (item + near_full_threshold)) & fit_mask\n        priorities[near_full_mask] += near_full_bonus #Big bonus for filling near-full bins.\n    # Overflow Heuristic: Only used when NO bin fits.\n    else:\n        overflow_mask = ~fit_mask\n        priorities[overflow_mask] = - (item - bins_remain_cap[overflow_mask]) / (np.max(bins_remain_cap) + 0.000001)\n        # Try to balance load (least overflow)\n        min_overflow = np.min(item - bins_remain_cap[overflow_mask])\n        least_overflow_mask = (item - bins_remain_cap == min_overflow) & overflow_mask\n        priorities[least_overflow_mask] += least_overflow_bonus #Bonus for minimizing overflow when no fit\n\n    # Bin balancing. Incentivize bins with higher remaining capacity (avoid using bins too unevenly if possible)\n    priorities += bins_remain_cap / (np.sum(bins_remain_cap) + 0.000001) #Added term for load balancing across bins\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 400.90527603206624,
    "mi": 73.20578358461792,
    "token_count": 280.0,
    "exec_success": true
  }
]