```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes bins using advanced adaptive weighting, considering fragmentation,
    bin utilization, and item characteristics."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    waste = bins_remain_cap - item
    max_cap = np.max(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0
    avg_cap = np.mean(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0
    min_cap = np.min(bins_remain_cap) if len(bins_remain_cap) > 0 else 1.0

    # Hyperparameters (Tunable)
    fit_reward = 1.2
    overflow_penalty = 0.6
    fullness_bonus = 0.3
    close_fit_boost = 0.8
    close_fit_threshold = 0.2
    empty_bin_penalty = 0.4
    fragmentation_penalty = 0.5
    item_size_penalty = 0.5
    bin_level_reward = 0.1

    # Adaptive Adjustments
    item_ratio = item / max_cap

    if item_ratio > 0.7:
        fit_reward *= 1.15
        overflow_penalty *= 0.85
        close_fit_boost *= 0.9
        fragmentation_penalty *= 1.1
    elif item_ratio < 0.3:
        fullness_bonus *= 1.25
        empty_bin_penalty *= 1.2
        item_size_penalty *= 0.7
        bin_level_reward *= 1.1

    # Fit Reward
    fit_mask = waste >= 0
    priorities[fit_mask] += fit_reward / (waste[fit_mask] + 0.000001)

    # Overflow Penalty
    overflow_mask = ~fit_mask
    overflow = item - bins_remain_cap[overflow_mask]
    priorities[overflow_mask] -= overflow_penalty * overflow / (max_cap + 0.000001)

    # Fullness Bonus (Scaled to encourage balanced utilization)
    fullness = 1 - bins_remain_cap / (max_cap + 0.000001)
    priorities += fullness_bonus * fullness

    # Close Fit Boost
    close_fit_mask = fit_mask & (waste <= (close_fit_threshold * max_cap))
    if np.any(close_fit_mask):
        ratios = item / bins_remain_cap[close_fit_mask]
        priorities[close_fit_mask] += close_fit_boost * np.log(ratios)

    # Empty Bin Handling
    near_empty_mask = bins_remain_cap > (0.9 * max_cap)
    priorities[near_empty_mask] -= empty_bin_penalty

    # Fragmentation Penalty (Discourage leaving small gaps)
    remaining_ratio = waste / (max_cap + 0.000001)
    fragmentation_mask = fit_mask & (remaining_ratio > 0)
    priorities[fragmentation_mask] -= fragmentation_penalty * remaining_ratio[fragmentation_mask]

    # Item Size Penalty (Avoid very small wastes relative to item size)
    slightly_larger_mask = fit_mask & (waste < (0.5 * item))
    priorities[slightly_larger_mask] -= item_size_penalty * (item / (max_cap + 0.000001))

    # Bin Level Reward: Reward bins that already have some items in them.

    priorities += bin_level_reward * (1 - bins_remain_cap/(max_cap + 0.000001))

    return priorities
```
