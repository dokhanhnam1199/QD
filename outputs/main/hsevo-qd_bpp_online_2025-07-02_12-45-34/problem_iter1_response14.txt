```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    This function prioritizes bins that have a remaining capacity slightly larger than the item size,
    while penalizing bins that are either too small or too large.  It also factors in the fullness
    of the bin (higher is better, up to a point). It attempts to balance space utilization
    with avoiding extreme fragmentation.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Parameters to fine-tune the heuristic
    capacity_similarity_weight = 1.0
    fullness_weight = 0.5
    small_bin_penalty = -10.0
    large_bin_penalty = -2.0


    for i, remaining_capacity in enumerate(bins_remain_cap):
        if remaining_capacity < item:
            priorities[i] = small_bin_penalty  # Significantly penalize bins too small
        else:
            # Capacity similarity score (how close is the remaining capacity to the item size?)
            capacity_similarity = np.exp(-abs(remaining_capacity - 1.1 * item) / item) #exp(-abs(remaining_capacity-item)/item) # Gaussian-like similarity; preferred capacity slightly larger

            # Fullness score (how full would the bin be after adding the item?)
            fullness = 1 - (remaining_capacity - item)  # Normalize (assuming bin size is 1)

            priorities[i] = (capacity_similarity_weight * capacity_similarity +
                             fullness_weight * np.clip(fullness, 0, 1))  # Combine scores

            # Penalize very large bins (relatively) to encourage better utilization
            if remaining_capacity > 2*item: # or similar threshold for "large"
                 priorities[i] += large_bin_penalty

    return priorities
```
