[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 2.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a Best-Fit-like heuristic.\n    Bins that fit the item are prioritized based on how little space\n    would be left after placing the item (i.e., tighter fits get higher scores).\n    Bins that cannot fit the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after placement.\n    # We want to minimize this remaining capacity to achieve a \"best fit\".\n    # By taking the negative of the remaining capacity, a smaller positive remainder\n    # (i.e., a tighter fit) results in a larger (less negative) priority score.\n    # A perfect fit (remaining_capacity == 0) results in a score of 0.\n    # A bin that is barely larger than the item will get a score close to 0.\n    # A bin much larger than the item will get a more negative score.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = -remaining_capacity_after_fit\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing an enhanced Best-Fit-like heuristic with a non-linear\n    scoring function that strongly incentivizes perfect fits and applies\n    a decaying reward for other tight fits.\n\n    This version goes beyond a simple linear 'minimizing leftover space'\n    by introducing a multi-objective perspective through:\n    1. A significant bonus for perfect utilization of a bin.\n    2. A non-linear (inverse) reward for non-perfect fits,\n       making very tight fits significantly more desirable than slightly looser ones.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Define a small epsilon for robust floating-point comparisons\n    # and to prevent division by zero for actual perfect fits.\n    epsilon = 1e-9\n\n    # --- Multi-Objective / Non-Linear Scoring Strategy ---\n\n    # 1. Identify \"perfect fits\" (remaining capacity is effectively zero).\n    #    These are critical outcomes as they fully utilize a bin and reduce fragmentation.\n    is_perfect_fit = remaining_capacity_after_fit < epsilon\n\n    # 2. Calculate scores for non-perfect fits using an inverse relationship.\n    #    This ensures a non-linear decay: smaller remaining capacities get\n    #    disproportionately higher positive scores. Adding epsilon to the denominator\n    #    ensures numerical stability and provides a very high but finite score\n    #    for nearly perfect non-zero fits.\n    scores_for_non_perfect_fits = 1.0 / (remaining_capacity_after_fit + epsilon)\n\n    # Initialize combined scores with the non-perfect fit calculations.\n    combined_scores = scores_for_non_perfect_fits\n\n    # 3. Apply a significant, overriding bonus for truly perfect fits.\n    #    This ensures that a perfect fit is always chosen over any non-perfect fit,\n    #    no matter how small the remaining capacity in other bins might be.\n    #    The value (e.g., 2.0 / epsilon) is chosen to be orders of magnitude\n    #    larger than the highest possible score from `1.0 / (remaining + epsilon)`.\n    PERFECT_FIT_SCORE_BONUS = 2.0 / epsilon\n    combined_scores[is_perfect_fit] = PERFECT_FIT_SCORE_BONUS\n\n    # Assign the calculated scores to the bins that can fit the item.\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                default_low_priority: float = -13.732882263687515,\n                fit_score_weight: float = -4.7273623240749325) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a Best-Fit-like heuristic.\n    Bins that fit the item are prioritized based on how little space\n    would be left after placing the item (i.e., tighter fits get higher scores).\n    Bins that cannot fit the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        default_low_priority: The priority assigned to bins that cannot accommodate the item.\n                              Should be a very low number (e.g., -np.inf) to ensure they are\n                              not chosen if any valid bin exists.\n        fit_score_weight: A multiplier applied to the negative remaining capacity after fit.\n                          A negative value (e.g., -1.0) ensures that tighter fits (smaller\n                          remaining capacity) receive higher scores.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using default_low_priority makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after placement.\n    # We want to minimize this remaining capacity to achieve a \"best fit\".\n    # By taking the remaining capacity and multiplying by fit_score_weight,\n    # a smaller positive remainder (i.e., a tighter fit) results in a larger priority score\n    # when fit_score_weight is negative.\n    # A perfect fit (remaining_capacity == 0) results in a score of 0.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = remaining_capacity_after_fit * fit_score_weight\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version enhances the Best-Fit heuristic by incorporating a \"consolidation\"\n    bias. It subtly prioritizes placing items into bins that are already partially\n    filled, over opening entirely new bins (or using effectively \"new\" bins that are\n    still at their maximum initial capacity), provided the fit is comparable.\n    This promotes filling existing bins first to reduce the total bin count,\n    aligning with the goal of \"Global Flexibility\" and \"overall solution quality\"\n    by preventing fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot fit\n    # the item will effectively not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Best-Fit (Base Logic) ---\n    # Calculate the remaining capacity if the item is placed.\n    # A smaller remaining capacity indicates a tighter fit.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # The base score is the negative of the remaining capacity.\n    # A perfect fit (0 remaining) gets a score of 0. Tighter fits (smaller positive\n    # remaining capacity) get scores closer to 0 (less negative), making them higher priority.\n    base_scores = -remaining_capacity_after_fit\n\n    # --- Consolidation Bias (Domain Intelligence & Global Flexibility) ---\n    # To encourage consolidation, we add a small bonus to bins that are already\n    # partially filled. This nudges the algorithm to prefer an existing bin\n    # over a new one (or one that's still at its maximum capacity) if the\n    # Best-Fit scores are very close.\n\n    # Infer \"newly opened\" bins: We assume that any bin whose remaining capacity\n    # is equal to the maximum remaining capacity among all *currently available*\n    # bins (that can fit the item) is considered effectively \"new\" or \"empty\".\n    # This heuristic works well if bins are opened with a fixed capacity.\n    max_current_capacity = np.max(bins_remain_cap[can_fit_mask])\n\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity.\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity\n\n    # Define a small positive bonus. This value should be small enough not to\n    # override a significantly better Best-Fit score, but large enough to\n    # differentiate between closely scoring bins or break ties.\n    # The choice of 0.01 is a simple, robust constant for floating-point comparisons.\n    consolidation_bonus = 0.01\n\n    # Apply the bonus to partially filled bins.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, unfit_bin_priority_value: float = -7523322707.098899, fit_score_weight: float = -5.045411058574856) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a Best-Fit-like heuristic.\n    Bins that fit the item are prioritized based on how little space\n    would be left after placing the item (i.e., tighter fits get higher scores).\n    Bins that cannot fit the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        unfit_bin_priority_value: The priority score assigned to bins that\n                                   cannot accommodate the item. Default is -np.inf,\n                                   ensuring they are never chosen if any valid bin exists.\n        fit_score_weight: A weighting factor applied to the remaining capacity\n                          of fitting bins. A negative value ensures that tighter fits\n                          (smaller remaining capacity) result in higher priority scores.\n                          Default is -1.0, which means a perfect fit (0 remaining capacity)\n                          scores 0, and larger remaining capacities get more negative scores.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    priorities = np.full_like(bins_remain_cap, unfit_bin_priority_value, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after placement.\n    # We want to minimize this remaining capacity to achieve a \"best fit\".\n    # By applying the fit_score_weight to the remaining capacity, a smaller positive remainder\n    # (i.e., a tighter fit) results in a larger priority score when fit_score_weight is negative.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = fit_score_weight * remaining_capacity_after_fit\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fit_score_weight: float = 1.0,\n                consolidation_bonus_weight: float = 0.01,\n                default_low_priority: float = -np.inf) -> np.ndarray:\n    \"\"\"Returns priority for adding an item, combining Best-Fit with a tunable consolidation bias.\n    Prioritizes tight fits and rewards using existing, partially-filled bins to consolidate space,\n    enhancing global flexibility through adaptable parameters.\n    \"\"\"\n    # Initialize all priorities to a very low number for bins that cannot fit.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Tunable Best-Fit Logic ---\n    # Calculate the remaining capacity if the item is placed in fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Base score: Smaller remaining capacity means a tighter fit, which is better.\n    # The score is amplified by 'fit_score_weight', which should be positive to\n    # promote tighter fits (i.e., a smaller negative value is a higher priority).\n    base_scores = fit_score_weight * (-remaining_capacity_after_fit)\n\n    # --- Tunable Consolidation Bias ---\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity\n    # among *currently available* bins that can fit the item.\n    max_current_capacity_among_fitting_bins = np.max(bins_remain_cap[can_fit_mask])\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity_among_fitting_bins\n\n    # Apply a tunable bonus to partially filled bins to encourage consolidation.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus_weight\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                w_tight_fit: float = 1.0, w_fullness: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a tunable heuristic combining a Best-Fit-like approach with a\n    preference for fuller bins.\n\n    Bins that fit the item are prioritized based on two weighted components:\n    1.  **Tight Fit:** How little space would be left after placing the item (i.e., tighter fits get higher scores).\n        This component directly relates to the Best-Fit heuristic.\n    2.  **Bin Fullness:** How full the bin already is (i.e., smaller remaining capacity means a fuller bin, getting a higher score).\n        This component encourages \"closing\" bins by filling those that are already significantly utilized.\n\n    Bins that cannot fit the item receive a very low priority, effectively preventing their selection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        w_tight_fit: Weight for the \"tight fit\" component. A higher value emphasizes\n                     minimizing leftover space after placement.\n        w_fullness: Weight for the \"bin fullness\" component. A higher value emphasizes\n                    using bins that are already more filled.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate scores only for bins that can fit the item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Component 1: Tight Fit (Best-Fit-like)\n    # The goal is to minimize (bins_remain_cap - item), which is the space left after placement.\n    # To maximize this, we use the negative: -(bins_remain_cap - item) = item - bins_remain_cap.\n    # A smaller remaining capacity after fit results in a higher score.\n    score_tight_fit = item - fitting_bins_remain_cap\n\n    # Component 2: Bin Fullness\n    # The goal is to prefer bins that already have a smaller remaining capacity\n    # (i.e., are closer to being full).\n    # To maximize this, we use the negative of remaining capacity: -fitting_bins_remain_cap.\n    # A smaller current remaining capacity results in a higher score.\n    score_fullness = -fitting_bins_remain_cap\n\n    # Combine the scores using tunable weights.\n    # The overall priority is a weighted sum of these two components.\n    combined_score = (w_tight_fit * score_tight_fit) + (w_fullness * score_fullness)\n\n    # Apply the calculated scores to the valid bins in the priorities array.\n    priorities[can_fit_mask] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 24.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                default_low_priority: float = float('-inf'),\n                fit_score_weight: float = -4.7273623240749325,\n                current_fullness_weight: float = -1.0) -> np.ndarray:\n    \"\"\"Returns priority for each bin, combining Best-Fit with a preference for already fuller bins.\n    Uses tunable weights for adaptive control, promoting tight fits and bin consolidation for efficient packing.\n    \"\"\"\n    # Initialize all priorities to a very low number for bins that cannot fit.\n    # Using float('-inf') ensures they are never chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate scores only for bins that can fit the item.\n    if np.any(can_fit_mask):\n        # Component 1: Best-Fit score (prioritizing tightest fits)\n        # Calculates the remaining capacity after placing the item.\n        # A negative fit_score_weight makes smaller remaining_capacity_after_fit (tighter fits) result in higher scores.\n        remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n        fit_score = remaining_capacity_after_fit * fit_score_weight\n\n        # Component 2: Current Bin Fullness score (prioritizing already fuller bins)\n        # Uses the current remaining capacity. A smaller current_remaining_capacity means the bin is fuller.\n        # A negative current_fullness_weight makes smaller current_remaining_capacity (fuller bins) result in higher scores.\n        current_remaining_capacity = bins_remain_cap[can_fit_mask]\n        fullness_score = current_remaining_capacity * current_fullness_weight\n\n        # Combine the scores using a weighted sum for continuous integration.\n        priorities[can_fit_mask] = fit_score + fullness_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a hybrid heuristic that prioritizes perfect fits,\n    then encourages leaving large, versatile spaces, and heavily\n    penalizes leaving very small, potentially useless spaces.\n\n    This heuristic is designed to be more \"contextual\" and \"adaptive\"\n    than a simple Best-Fit. It aims to avoid local optima (e.g.,\n    a tight fit that leaves a fragmented, unusable space) by shaping\n    the remaining capacities in a more strategic way.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot\n    # accommodate the item are effectively deprioritized.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_remain_cap - item\n\n    # --- Heuristic Parameters (Tunable) ---\n    # Assuming standard bin capacity is 1.0. This is a common assumption\n    # for normalized item sizes in BPP unless specified otherwise.\n    BIN_CAPACITY = 1.0\n\n    # Score for a perfect fit (remaining_capacity_after_fit == 0).\n    # This should be the highest possible score, ensuring it's always chosen.\n    PERFECT_FIT_SCORE = 1000.0\n\n    # Threshold for what constitutes a \"small, potentially useless\" remainder.\n    # If the remaining space is less than this fraction of the bin capacity,\n    # it's considered poor and heavily penalized.\n    # This avoids creating many bins with tiny, unusable gaps.\n    FRAGMENT_THRESHOLD = 0.05 * BIN_CAPACITY # e.g., 5% of bin capacity\n\n    # Multiplier for the penalty applied to small, non-zero remainders.\n    # Higher values lead to stronger discouragement of such fits.\n    SMALL_REMAINDER_PENALTY_MULTIPLIER = 50.0\n\n    # Multiplier for the score applied to larger, versatile remainders.\n    # This encourages leaving substantial space in a bin for future items,\n    # akin to a \"Worst-Fit\" approach for non-tight fits.\n    LARGE_REMAINDER_MULTIPLIER = 2.0\n    # --- End Heuristic Parameters ---\n\n    # Apply scores based on different conditions for `remaining_after_fit`:\n\n    # 1. Perfect Fit: `remaining_after_fit` is approximately zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=1e-9)\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. Small, Potentially Useless Remainder: `0 < remaining_after_fit < FRAGMENT_THRESHOLD`.\n    # These are fits that are not perfect, but leave very little space,\n    # which might be too small for most subsequent items, leading to fragmentation.\n    small_remainder_mask = (remaining_after_fit > 1e-9) & (remaining_after_fit < FRAGMENT_THRESHOLD)\n    \n    # The penalty increases as `remaining_after_fit` gets closer to zero (from the positive side).\n    # This creates a \"valley\" in the scoring function just after zero.\n    penalty_scores = - (FRAGMENT_THRESHOLD - remaining_after_fit[small_remainder_mask]) * SMALL_REMAINDER_PENALTY_MULTIPLIER\n    priorities[can_fit_mask][small_remainder_mask] = penalty_scores\n\n    # 3. Large, Versatile Remainder: `remaining_after_fit >= FRAGMENT_THRESHOLD`.\n    # For these cases, we prefer leaving larger remaining spaces, as they are\n    # more likely to accommodate future, larger items, maintaining bin versatility.\n    # This is a Worst-Fit-like component for non-tight fits.\n    large_remainder_mask = remaining_after_fit >= FRAGMENT_THRESHOLD\n    \n    # Linear scoring: higher `remaining_after_fit` leads to a higher score.\n    # These scores are designed to be positive but lower than the `PERFECT_FIT_SCORE`.\n    large_remainder_scores = remaining_after_fit[large_remainder_mask] * LARGE_REMAINDER_MULTIPLIER\n    priorities[can_fit_mask][large_remainder_mask] = large_remainder_scores\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 15.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best-Fit with a continuous consolidation bias.\n    Prioritizes tight fits and actively filling existing bins by adding a bonus\n    proportional to a bin's current fullness, with tunable weights.\n    \"\"\"\n    # Initialize all priorities to a very low number, effectively deprioritizing\n    # bins that cannot fit the item or are not considered.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Extract remaining capacities for only the fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Tunable Heuristic Parameters ---\n    # Weight for the Best-Fit component. A negative value is used because a smaller\n    # `remaining_after_fit` is better, leading to a higher (less negative) score.\n    WEIGHT_BEST_FIT = -1.0 \n\n    # Weight for the consolidation component. This encourages filling bins that are\n    # already partially full. It should be a positive value, typically small enough\n    # not to completely override a significantly better Best-Fit, but large enough\n    # to influence decisions, especially in near-tie scenarios.\n    WEIGHT_CONSOLIDATION = 0.01 \n    \n    # Assumed maximum capacity of a bin. This is common for normalized BPP instances.\n    # Used to calculate the \"current fullness\" of a bin.\n    BIN_CAPACITY = 1.0 \n    # --- End Tunable Heuristic Parameters ---\n\n    # 1. Best-Fit Component:\n    # Calculate the remaining capacity if the item is placed.\n    remaining_after_fit = fitting_bins_remain_cap - item\n    # The score is proportional to the negative of this value:\n    # A smaller `remaining_after_fit` (tighter fit) results in a score closer to 0 (less negative),\n    # which is a higher priority.\n    best_fit_scores = remaining_after_fit * WEIGHT_BEST_FIT\n\n    # 2. Consolidation Component (Bin Fullness):\n    # Calculate how full each bin currently is. A higher value means the bin is more full.\n    current_fullness = BIN_CAPACITY - fitting_bins_remain_cap\n    # Add a bonus proportional to the current fullness. This biases towards\n    # filling existing, partially used bins.\n    consolidation_scores = current_fullness * WEIGHT_CONSOLIDATION\n\n    # Combine the two components to get the final priority score for fitting bins.\n    combined_scores = best_fit_scores + consolidation_scores\n    \n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response2.txt_stdout.txt",
    "code_path": "problem_iter15_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_MAX_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add an item to each bin.\n    This heuristic is designed to be an adaptive variant of Best-Fit,\n    considering 'Structural Integrity' and 'Emergent Properties' of the\n    overall bin packing solution, moving beyond rigid local optimization.\n\n    It improves upon a simple Best-Fit by:\n    1.  **Strongly Prioritizing Perfect Fits:** Bins that can precisely fit the\n        item (leaving zero remainder) receive the highest possible score.\n    2.  **Penalizing Fragmentation:** It applies a significant penalty to bins\n        where placing the item would leave a very small, non-zero, and\n        potentially unusable remainder (a \"fragment\"). This aims to prevent\n        the creation of many tiny, difficult-to-fill pockets of space, which\n        can lead to an increased total number of bins used (a negative\n        emergent property for the global solution).\n    3.  **Adaptive Thresholding:** The definition of a \"small fragment\" is\n        adaptive, considering both a small absolute value (relative to the\n        bin's maximum capacity, providing 'Global Context') and a value relative\n        to the current item's size ('Adaptive Design').\n    4.  **Best-Fit Tendency for Other Cases:** For all other valid fits (perfect\n        fits, or fits leaving remainders larger than the fragmentation threshold),\n        it reverts to the Best-Fit principle, favoring tighter fits to minimize\n        wasted space, while implicitly encouraging closure of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: A NumPy array containing the remaining capacities\n                         for each bin.\n        BIN_MAX_CAPACITY: The maximum capacity of any bin. This parameter\n                          provides crucial global context for evaluating\n                          remainder sizes and setting penalty scales.\n                          Defaults to 1.0, assuming item and bin sizes are normalized.\n\n    Returns:\n        A NumPy array of the same size as `bins_remain_cap`, where each\n        element is the calculated priority score for the corresponding bin.\n        Bins that cannot fit the item will have a very low priority (-np.inf).\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed not to be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # If no bin can accommodate the item, return the initialized priorities.\n        # This implies that a new bin must be opened in the broader packing algorithm.\n        return priorities\n\n    # Calculate the remaining capacity for bins where the item can be placed.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # --- Component 1: Best-Fit Base Score ---\n    # Tighter fits (smaller `remaining_capacity_after_fit`) are more desirable.\n    # A perfect fit (remainder = 0) gets a score of 0. Larger remainders get\n    # increasingly negative scores.\n    base_fit_score = -remaining_capacity_after_fit\n\n    # --- Component 2: Fragmentation Penalty ---\n    # This component penalizes solutions that lead to 'Structural Degradation'\n    # by creating very small, likely unusable, fragments of space.\n    # Define an adaptive threshold for what constitutes a \"small fragment\".\n    # It considers both an absolute minimum size (e.g., 1% of max bin capacity)\n    # and a relative minimum size (e.g., 5% of the current item's size).\n    # Using `max` ensures it meets at least a minimum absolute size criterion,\n    # while `min` prevents the threshold from becoming too large for very small items.\n    FRAGMENT_THRESHOLD = max(0.01 * BIN_MAX_CAPACITY, 0.05 * item)\n    FRAGMENT_THRESHOLD = min(FRAGMENT_THRESHOLD, 0.5 * item) # Cap threshold to avoid penalizing useful mid-range remainders\n\n    fragment_penalty = np.zeros_like(remaining_capacity_after_fit)\n\n    # Identify bins where the item fits, but leaves a small, non-zero fragment.\n    # Using a small epsilon (1e-9) to account for floating-point inaccuracies\n    # when checking for truly zero remainder.\n    is_fragmented_remainder = (remaining_capacity_after_fit > 1e-9) & \\\n                              (remaining_capacity_after_fit < FRAGMENT_THRESHOLD)\n\n    # Determine the magnitude of the penalty. This value is relative to the\n    # `BIN_MAX_CAPACITY` to scale appropriately across different problem sizes.\n    # A larger magnitude means fragmented bins are heavily discouraged.\n    PENALTY_MAGNITUDE = 0.2 * BIN_MAX_CAPACITY  # This is a key tunable parameter\n\n    # Apply the penalty to identified fragmented remainders.\n    fragment_penalty[is_fragmented_remainder] = -PENALTY_MAGNITUDE\n\n    # --- Combine Scores ---\n    # The final priority combines the best-fit preference with the fragmentation penalty.\n    # This guides the heuristic to make decisions that lead to better 'Emergent Properties'\n    # for the overall packing solution.\n    combined_score = base_fit_score + fragment_penalty\n\n    # Assign the calculated combined scores back to the appropriate bins.\n    priorities[can_fit_mask] = combined_score\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best-Fit with consolidation, perfect fit priority, and small fragment penalty.\n    Prioritizes perfect fits, then consolidates existing bins by penalizing new ones, while avoiding tiny unusable spaces.\n    \"\"\"\n    # Initialize all priorities to a very low number, effectively deprioritizing non-fitting bins.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Get indices and current capacities of fitting bins for targeted operations.\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    fitting_bins_current_caps = bins_remain_cap[fitting_bins_indices]\n    remaining_after_fit = fitting_bins_current_caps - item\n\n    # Heuristic Parameters (Based on \"Analyze & experience\" for effective values)\n    BIN_CAPACITY = 1.0  # Common assumption for normalized item/bin sizes\n    PERFECT_FIT_SCORE = 1000.0  # Ensures perfect fits are always chosen\n    FRAGMENT_THRESHOLD = 0.05 * BIN_CAPACITY  # Remaining space smaller than this is penalized\n    SMALL_REMAINDER_PENALTY_MULTIPLIER = 50.0  # Controls severity of fragment penalty\n    CONSOLIDATION_BONUS = 0.01  # Small bonus for filling existing (partially used) bins\n\n    # --- Apply scoring based on categories of remaining capacity after fit ---\n\n    # 1. Perfect Fit: `remaining_after_fit` is approximately zero.\n    perfect_fit_sub_mask = np.isclose(remaining_after_fit, 0.0, atol=1e-9)\n    priorities[fitting_bins_indices[perfect_fit_sub_mask]] = PERFECT_FIT_SCORE\n\n    # 2. Small, Potentially Useless Remainder: `0 < remaining_after_fit < FRAGMENT_THRESHOLD`.\n    # These fits create very little space, which might be too small for future items.\n    small_remainder_sub_mask = (remaining_after_fit > 1e-9) & (remaining_after_fit < FRAGMENT_THRESHOLD)\n    \n    # The penalty increases (becomes more negative) as remaining_after_fit gets closer to zero.\n    penalty_scores = - (FRAGMENT_THRESHOLD - remaining_after_fit[small_remainder_sub_mask]) * SMALL_REMAINDER_PENALTY_MULTIPLIER\n    priorities[fitting_bins_indices[small_remainder_sub_mask]] = penalty_scores\n\n    # 3. Other Valid Fits: `remaining_after_fit >= FRAGMENT_THRESHOLD`.\n    # For these, apply Best-Fit logic enhanced with a consolidation bias.\n    general_fit_sub_mask = remaining_after_fit >= FRAGMENT_THRESHOLD\n\n    if np.any(general_fit_sub_mask):\n        # Base Best-Fit score: Negative of remaining capacity. A tighter fit (smaller positive remainder)\n        # results in a score closer to 0 (less negative), indicating higher priority.\n        base_scores = -remaining_after_fit[general_fit_sub_mask]\n\n        # Consolidation Bias: Add a small bonus to bins that are already partially filled.\n        # This nudges the algorithm to prefer an existing bin over a 'new' (full capacity) one.\n        \n        # Determine the maximum current capacity among these \"general fit\" bins.\n        # Any bin with this maximum capacity is considered effectively \"new\" or \"empty\".\n        max_current_fitting_capacity = np.max(fitting_bins_current_caps[general_fit_sub_mask])\n        \n        # Identify bins that are NOT at their maximum capacity (i.e., they are partially filled).\n        is_partially_filled_for_general_fits = fitting_bins_current_caps[general_fit_sub_mask] < max_current_fitting_capacity\n        \n        # Apply the consolidation bonus.\n        adjusted_scores = base_scores\n        adjusted_scores[is_partially_filled_for_general_fits] += CONSOLIDATION_BONUS\n        \n        priorities[fitting_bins_indices[general_fit_sub_mask]] = adjusted_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add an item to each bin,\n    implementing a sophisticated heuristic that combines the Best-Fit principle\n    with strategic considerations for bin consolidation, perfect fits, and\n    the avoidance of small, unfillable gaps.\n\n    This heuristic aims to:\n    1. Strongly favor perfect fits to maximize complete bin utilization.\n    2. Prioritize tight fits (Best-Fit) to minimize immediate waste.\n    3. Penalize placements that result in very small, potentially unusable\n       remaining capacities, preventing \"fragmentation\" of bin space.\n    4. Provide a bonus for placing items in bins that are already highly\n       utilized, encouraging the \"consolidation\" and closure of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n                         Assumes capacities are normalized (e.g., bin capacity = 1.0).\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can physically fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Calculate the remaining capacity for bins after placing the item\n    remaining_capacity_after_fit = fitting_bins_remain_cap - item\n\n    # --- Core Scoring Components ---\n\n    # 1. Base Score (Best-Fit principle):\n    #   A smaller remaining capacity (tighter fit) yields a higher base score.\n    #   Scores range from 0 (perfect fit) to negative values.\n    base_scores = -remaining_capacity_after_fit\n\n    # Define constants for heuristic weighting. These can be tuned.\n    PERFECT_FIT_BONUS = 1000.0  # Large bonus for a perfect fit, making it highly desirable.\n    SMALL_GAP_THRESHOLD = 0.05  # A fractional threshold for what constitutes a \"small\" gap.\n                                # E.g., if bin capacity is 1.0, 0.05 means 5% of bin.\n    SMALL_GAP_PENALTY_FACTOR = 200.0 # Multiplier for the penalty applied to small gaps.\n                                    # Higher values mean stronger discouragement.\n    CONSOLIDATION_THRESHOLD = 0.75 # Threshold (as a fraction of total capacity)\n                                   # for a bin to be considered \"highly utilized\".\n    CONSOLIDATION_BONUS_FACTOR = 50.0 # Multiplier for the bonus applied to highly utilized bins.\n\n    # 2. Perfect Fit Bonus:\n    #    If an item perfectly fills a bin, give a substantial bonus. This is a\n    #    highly desirable outcome for bin packing efficiency.\n    perfect_fit_mask = remaining_capacity_after_fit == 0\n    base_scores[perfect_fit_mask] += PERFECT_FIT_BONUS\n\n    # 3. Small Gap Penalty:\n    #    Apply a penalty for placements that leave a very small, non-zero\n    #    remaining capacity. Such small gaps are often \"unfillable\" and\n    #    lead to wasted space/fragmentation. The penalty is higher for smaller gaps.\n    small_gap_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit < SMALL_GAP_THRESHOLD)\n    # Penalty magnitude is inversely proportional to the gap size within the threshold\n    penalty_values = (SMALL_GAP_THRESHOLD - remaining_capacity_after_fit[small_gap_mask]) * SMALL_GAP_PENALTY_FACTOR\n    base_scores[small_gap_mask] -= penalty_values\n\n    # 4. Consolidation Bonus:\n    #    Reward placing items into bins that are already significantly full.\n    #    This encourages \"closing\" bins and reduces the total number of\n    #    active bins, contributing to bin consolidation.\n    #    Assumes a nominal total bin capacity (e.g., 1.0) if not explicitly provided.\n    NOMINAL_BIN_CAPACITY = 1.0 # This needs to be consistent with how bins_remain_cap are scaled.\n    current_fill_level = (NOMINAL_BIN_CAPACITY - fitting_bins_remain_cap) / NOMINAL_BIN_CAPACITY\n\n    consolidation_mask = current_fill_level >= CONSOLIDATION_THRESHOLD\n    # The bonus can scale with how full the bin is beyond the threshold\n    consolidation_bonus = current_fill_level[consolidation_mask] * CONSOLIDATION_BONUS_FACTOR\n    base_scores[consolidation_mask] += consolidation_bonus\n\n    # Assign the calculated scores to the respective bins.\n    priorities[can_fit_mask] = base_scores\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                fit_score_weight: float = 1.0,\n                consolidation_bonus_weight: float = 0.05,\n                default_low_priority: float = -np.inf) -> np.ndarray:\n    \"\"\"\n    Combines Best-Fit with a continuous consolidation strategy. Rewards bins proportional to their\n    current fullness among fitting options to encourage efficient space utilization and adaptability.\n    \"\"\"\n    # Initialize all priorities to a very low number for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Identify all bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can accommodate the item, return the array with deprioritized scores.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Best-Fit Logic ---\n    # Calculate the remaining capacity for bins that can fit the item.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Base score: Prioritize tighter fits (smaller remaining capacity).\n    # The negative sign converts smaller remaining capacity into a higher score.\n    base_scores = fit_score_weight * (-remaining_capacity_after_fit)\n\n    # --- Continuous Consolidation Bias ---\n    # This component rewards bins that are already more \"full\" (i.e., have less remaining capacity)\n    # among the available fitting bins. This promotes filling existing, partially-used bins first,\n    # aligning with adaptive strategies for better space consolidation.\n\n    # Extract remaining capacities for only those bins that can fit the item.\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n\n    # Determine the range of remaining capacities among the fitting bins.\n    min_fitting_cap = np.min(fitting_bins_caps)  # Capacity of the most full fitting bin\n    max_fitting_cap = np.max(fitting_bins_caps)  # Capacity of the most empty fitting bin\n\n    consolidation_scores = np.zeros_like(fitting_bins_caps, dtype=float)\n\n    # If there's a range of capacities (i.e., not all fitting bins are equally full/empty),\n    # calculate a continuous consolidation score.\n    if max_fitting_cap > min_fitting_cap:\n        # The score is higher for bins closer to min_fitting_cap (more full) and lower\n        # for bins closer to max_fitting_cap (more empty). It ranges from 0 to 1.\n        consolidation_scores = (max_fitting_cap - fitting_bins_caps) / (max_fitting_cap - min_fitting_cap)\n    # If all fitting bins have the same capacity, consolidation_scores remains 0, meaning\n    # no differential bonus is applied based on \"fullness\" among them.\n\n    # Combine the base (Best-Fit) scores with the tunable consolidation bonus.\n    adjusted_scores = base_scores + consolidation_bonus_weight * consolidation_scores\n\n    # Assign the calculated scores back to the appropriate bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]