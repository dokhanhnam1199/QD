{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version enhances the Best-Fit heuristic by incorporating a \"consolidation\"\n    bias. It subtly prioritizes placing items into bins that are already partially\n    filled, over opening entirely new bins (or using effectively \"new\" bins that are\n    still at their maximum initial capacity), provided the fit is comparable.\n    This promotes filling existing bins first to reduce the total bin count,\n    aligning with the goal of \"Global Flexibility\" and \"overall solution quality\"\n    by preventing fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot fit\n    # the item will effectively not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Best-Fit (Base Logic) ---\n    # Calculate the remaining capacity if the item is placed.\n    # A smaller remaining capacity indicates a tighter fit.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # The base score is the negative of the remaining capacity.\n    # A perfect fit (0 remaining) gets a score of 0. Tighter fits (smaller positive\n    # remaining capacity) get scores closer to 0 (less negative), making them higher priority.\n    base_scores = -remaining_capacity_after_fit\n\n    # --- Consolidation Bias (Domain Intelligence & Global Flexibility) ---\n    # To encourage consolidation, we add a small bonus to bins that are already\n    # partially filled. This nudges the algorithm to prefer an existing bin\n    # over a new one (or one that's still at its maximum capacity) if the\n    # Best-Fit scores are very close.\n\n    # Infer \"newly opened\" bins: We assume that any bin whose remaining capacity\n    # is equal to the maximum remaining capacity among all *currently available*\n    # bins (that can fit the item) is considered effectively \"new\" or \"empty\".\n    # This heuristic works well if bins are opened with a fixed capacity.\n    max_current_capacity = np.max(bins_remain_cap[can_fit_mask])\n\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity.\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity\n\n    # Define a small positive bonus. This value should be small enough not to\n    # override a significantly better Best-Fit score, but large enough to\n    # differentiate between closely scoring bins or break ties.\n    # The choice of 0.01 is a simple, robust constant for floating-point comparisons.\n    consolidation_bonus = 0.01\n\n    # Apply the bonus to partially filled bins.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (1st) vs (7th), both implement a Best-Fit heuristic with a weighted remaining capacity. The core logic is identical, but (1st) uses different, seemingly better-tuned parameter values for `default_low_priority` and `fit_score_weight`. This highlights that for a given heuristic principle, the **meticulous tuning of its hyper-parameters is critical** for performance. Comparing (2nd) vs (8th), (3rd) vs (4th), and (5th) vs (9th), identical code snippets are ranked differently. This suggests either external, non-visible parameter tuning was performed, or the problem's solution space is highly sensitive to minute differences, causing very similar heuristics to rank slightly apart.\n\nComparing (1st) (Best-Fit with tunable weight) vs (10th) (fixed Best-Fit), the introduction of a **tunable `fit_score_weight`** in (1st) enables superior performance. This allows the heuristic to be calibrated for specific problem instances, demonstrating the value of flexible design.\n\nComparing (1st) (tuned Best-Fit) vs (2nd) (Best-Fit + Bin Fullness), the simpler, well-tuned pure Best-Fit (1st) outperforms the more complex multi-objective approach (2nd) with its default weights. This suggests that a **highly optimized, focused heuristic can be more effective than a broader, combined strategy** if the latter's components are not perfectly balanced.\n\nComparing (2nd) (Best-Fit + Bin Fullness) vs (3rd) (Best-Fit + Consolidation Bias), the explicit linear combination of \"tight fit\" and \"bin fullness\" in (2nd) performs better than (3rd)'s threshold-based \"consolidation bonus\". This indicates that **direct and continuous integration of secondary objectives through weighted sums** might be more robust than simple additive bonuses.\n\nComparing (6th) (Tunable Best-Fit + Tunable Consolidation Bias) vs (3rd/4th) (Fixed Best-Fit + Fixed Consolidation Bias), the tunable version (6th) ranks higher. This reinforces the importance of **tunability for all significant components** of a multi-faceted heuristic.\n\nFinally, observing the dramatic performance drop from (10th) (basic Best-Fit) to (11th-20th) (trivial \"return zeros\" / no strategy), it's clear that **any strategic placement heuristic significantly outperforms a non-strategic approach**. The core Best-Fit principle, which minimizes individual wasted space, serves as a strong foundation.\n- \nHere's a redefined self-reflection for heuristic design:\n\n*   **Keywords:** Adaptive Control, Singular Focus, Contextual Strategy, Integrated Design.\n*   **Advice:** Prioritize identifying dynamic control points for adaptive behavior. Focus heuristics on a singular, primary objective to avoid diluted efforts. Implement context-aware decision processes instead of fixed rules. Ensure all components are synergistically integrated for holistic performance.\n*   **Avoid:** Prescribing fixed algorithms (e.g., Best-Fit), hardcoding specific scoring functions, or overly incentivizing local optima that hinder global solutions. Do not rely on static, pre-defined decision rules.\n*   **Explanation:** This fosters robust, adaptable heuristics that dynamically respond to problem specifics, avoiding brittle, pre-conceived notions of \"best\" strategies or scoring, thus promoting true global optimization.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}