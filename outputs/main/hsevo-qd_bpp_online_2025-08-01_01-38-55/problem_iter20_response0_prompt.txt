{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                fit_score_weight: float = 1.0,\n                consolidation_bonus_weight: float = 0.01,\n                default_low_priority: float = -np.inf) -> np.ndarray:\n    \"\"\"Returns priority for adding an item, combining Best-Fit with a tunable consolidation bias.\n    Prioritizes tight fits and rewards using existing, partially-filled bins to consolidate space,\n    enhancing global flexibility through adaptable parameters.\n    \"\"\"\n    # Initialize all priorities to a very low number for bins that cannot fit.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Tunable Best-Fit Logic ---\n    # Calculate the remaining capacity if the item is placed in fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Base score: Smaller remaining capacity means a tighter fit, which is better.\n    # The score is amplified by 'fit_score_weight', which should be positive to\n    # promote tighter fits (i.e., a smaller negative value is a higher priority).\n    base_scores = fit_score_weight * (-remaining_capacity_after_fit)\n\n    # --- Tunable Consolidation Bias ---\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity\n    # among *currently available* bins that can fit the item.\n    max_current_capacity_among_fitting_bins = np.max(bins_remain_cap[can_fit_mask])\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity_among_fitting_bins\n\n    # Apply a tunable bonus to partially filled bins to encourage consolidation.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus_weight\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (best) [Heuristics 1st] vs (worst) [Heuristics 11th], we observe that explicit heuristic logic, even a simple Best-Fit, is vastly superior to no logic at all. Heuristic 1st combines Best-Fit with a consolidation bias, while 11th simply returns zero priorities, leading to arbitrary bin selection.\n\nComparing (second best) [Heuristics 2nd] vs (second worst) [Heuristics 13th], Heuristic 2nd employs a continuous weighted sum of tight-fit and bin-fullness scores. Heuristic 13th uses a complex, piecewise function with distinct bonuses for perfect fits, penalties for small fragments, and a preference for large remainders. The higher ranking of the simpler, linear combination (2nd) over the more complex, threshold-dependent one (13th) suggests that continuous scoring might be more robust or easier to tune.\n\nComparing (1st) [Heuristics 1st] vs (2nd) [Heuristics 2nd], both combine Best-Fit with consolidation. Heuristic 1st's consolidation targets bins not of maximal available capacity, while 2nd directly targets fuller bins. The subtle difference in consolidation strategy (encouraging use of non-largest bins vs. already-fuller bins) appears to influence performance.\n\nComparing (3rd) [Heuristics 3rd] vs (4th) [Heuristics 4th], this reveals a critical point: Heuristic 4th is an exact duplicate of 1st, yet it ranks lower than 3rd (a pure Best-Fit). This strong contradiction indicates that default parameter values, problem-specific tuning, or environmental factors (e.g., test data distribution, experimental noise) heavily influence performance, potentially outweighing algorithmic sophistication if not properly configured.\n\nComparing (second worst) [Heuristics 13th] vs (worst) [Heuritsics 11th], even a complex heuristic with potential \"valleys\" due to penalties (13th) is far better than a non-heuristic approach (11th). This reinforces the value of any informed decision-making over random placement.\n\nOverall: Effective heuristics combine Best-Fit with strategies for bin consolidation and fragmentation avoidance. Simpler, continuously weighted combinations often outperform complex, piecewise functions, possibly due to robustness or ease of tuning. Critically, parameter optimization is paramount; an algorithmically strong heuristic can perform poorly if its weights are not well-suited for the problem instance.\n- \nHere's a redefined 'Current self-reflection':\n\n*   **Keywords**: Adaptive strategies, emergent properties, state-aware, dynamic.\n*   **Advice**: Design heuristics with inherent adaptability, allowing them to dynamically adjust priorities based on real-time state evolution. Favor simple, local rules that collectively yield robust global behavior. Incorporate mechanisms for recognizing and rectifying accumulating sub-optimality.\n*   **Avoid**: Prescribing fixed scoring biases, over-engineering perfect fit rewards, relying solely on pre-tuned parameters, or generic comparisons of complexity.\n*   **Explanation**: Focusing on dynamic adaptation and emergent properties fosters resilience. Rather than static optimization, heuristics should fluidly respond to changing problem landscapes, moving beyond rigid, pre-defined rules.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}