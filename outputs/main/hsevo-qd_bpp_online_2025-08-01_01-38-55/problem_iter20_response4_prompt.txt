{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add an item to each bin.\n    This heuristic is designed to be an adaptive variant of Best-Fit,\n    considering 'Structural Integrity' and 'Emergent Properties' of the\n    overall bin packing solution, moving beyond rigid local optimization.\n\n    It improves upon a simple Best-Fit by:\n    1.  **Strongly Prioritizing Perfect Fits:** Bins that can precisely fit the\n        item (leaving zero remainder) receive the highest possible score.\n    2.  **Penalizing Fragmentation:** It applies a significant penalty to bins\n        where placing the item would leave a very small, non-zero, and\n        potentially unusable remainder (a \"fragment\"). This aims to prevent\n        the creation of many tiny, difficult-to-fill pockets of space, which\n        can lead to an increased total number of bins used (a negative\n        emergent property for the global solution).\n    3.  **Adaptive Thresholding:** The definition of a \"small fragment\" is\n        adaptive, considering both a small absolute value (relative to the\n        bin's maximum capacity, providing 'Global Context') and a value relative\n        to the current item's size ('Adaptive Design').\n    4.  **Best-Fit Tendency for Other Cases:** For all other valid fits (perfect\n        fits, or fits leaving remainders larger than the fragmentation threshold),\n        it reverts to the Best-Fit principle, favoring tighter fits to minimize\n        wasted space, while implicitly encouraging closure of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: A NumPy array containing the remaining capacities\n                         for each bin.\n        BIN_MAX_CAPACITY: The maximum capacity of any bin. This parameter\n                          provides crucial global context for evaluating\n                          remainder sizes and setting penalty scales.\n                          Defaults to 1.0, assuming item and bin sizes are normalized.\n\n    Returns:\n        A NumPy array of the same size as `bins_remain_cap`, where each\n        element is the calculated priority score for the corresponding bin.\n        Bins that cannot fit the item will have a very low priority (-np.inf).\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed not to be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # If no bin can accommodate the item, return the initialized priorities.\n        # This implies that a new bin must be opened in the broader packing algorithm.\n        return priorities\n\n    # Calculate the remaining capacity for bins where the item can be placed.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # --- Component 1: Best-Fit Base Score ---\n    # Tighter fits (smaller `remaining_capacity_after_fit`) are more desirable.\n    # A perfect fit (remainder = 0) gets a score of 0. Larger remainders get\n    # increasingly negative scores.\n    base_fit_score = -remaining_capacity_after_fit\n\n    # --- Component 2: Fragmentation Penalty ---\n    # This component penalizes solutions that lead to 'Structural Degradation'\n    # by creating very small, likely unusable, fragments of space.\n    # Define an adaptive threshold for what constitutes a \"small fragment\".\n    # It considers both an absolute minimum size (e.g., 1% of max bin capacity)\n    # and a relative minimum size (e.g., 5% of the current item's size).\n    # Using `max` ensures it meets at least a minimum absolute size criterion,\n    # while `min` prevents the threshold from becoming too large for very small items.\n    FRAGMENT_THRESHOLD = max(0.01 * BIN_MAX_CAPACITY, 0.05 * item)\n    FRAGMENT_THRESHOLD = min(FRAGMENT_THRESHOLD, 0.5 * item) # Cap threshold to avoid penalizing useful mid-range remainders\n\n    fragment_penalty = np.zeros_like(remaining_capacity_after_fit)\n\n    # Identify bins where the item fits, but leaves a small, non-zero fragment.\n    # Using a small epsilon (1e-9) to account for floating-point inaccuracies\n    # when checking for truly zero remainder.\n    is_fragmented_remainder = (remaining_capacity_after_fit > 1e-9) & \\\n                              (remaining_capacity_after_fit < FRAGMENT_THRESHOLD)\n\n    # Determine the magnitude of the penalty. This value is relative to the\n    # `BIN_MAX_CAPACITY` to scale appropriately across different problem sizes.\n    # A larger magnitude means fragmented bins are heavily discouraged.\n    PENALTY_MAGNITUDE = 0.2 * BIN_MAX_CAPACITY  # This is a key tunable parameter\n\n    # Apply the penalty to identified fragmented remainders.\n    fragment_penalty[is_fragmented_remainder] = -PENALTY_MAGNITUDE\n\n    # --- Combine Scores ---\n    # The final priority combines the best-fit preference with the fragmentation penalty.\n    # This guides the heuristic to make decisions that lead to better 'Emergent Properties'\n    # for the overall packing solution.\n    combined_score = base_fit_score + fragment_penalty\n\n    # Assign the calculated combined scores back to the appropriate bins.\n    priorities[can_fit_mask] = combined_score\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (best) [Heuristics 1st] vs (worst) [Heuristics 11th], we observe that explicit heuristic logic, even a simple Best-Fit, is vastly superior to no logic at all. Heuristic 1st combines Best-Fit with a consolidation bias, while 11th simply returns zero priorities, leading to arbitrary bin selection.\n\nComparing (second best) [Heuristics 2nd] vs (second worst) [Heuristics 13th], Heuristic 2nd employs a continuous weighted sum of tight-fit and bin-fullness scores. Heuristic 13th uses a complex, piecewise function with distinct bonuses for perfect fits, penalties for small fragments, and a preference for large remainders. The higher ranking of the simpler, linear combination (2nd) over the more complex, threshold-dependent one (13th) suggests that continuous scoring might be more robust or easier to tune.\n\nComparing (1st) [Heuristics 1st] vs (2nd) [Heuristics 2nd], both combine Best-Fit with consolidation. Heuristic 1st's consolidation targets bins not of maximal available capacity, while 2nd directly targets fuller bins. The subtle difference in consolidation strategy (encouraging use of non-largest bins vs. already-fuller bins) appears to influence performance.\n\nComparing (3rd) [Heuristics 3rd] vs (4th) [Heuristics 4th], this reveals a critical point: Heuristic 4th is an exact duplicate of 1st, yet it ranks lower than 3rd (a pure Best-Fit). This strong contradiction indicates that default parameter values, problem-specific tuning, or environmental factors (e.g., test data distribution, experimental noise) heavily influence performance, potentially outweighing algorithmic sophistication if not properly configured.\n\nComparing (second worst) [Heuristics 13th] vs (worst) [Heuritsics 11th], even a complex heuristic with potential \"valleys\" due to penalties (13th) is far better than a non-heuristic approach (11th). This reinforces the value of any informed decision-making over random placement.\n\nOverall: Effective heuristics combine Best-Fit with strategies for bin consolidation and fragmentation avoidance. Simpler, continuously weighted combinations often outperform complex, piecewise functions, possibly due to robustness or ease of tuning. Critically, parameter optimization is paramount; an algorithmically strong heuristic can perform poorly if its weights are not well-suited for the problem instance.\n- \nHere's a redefined 'Current self-reflection':\n\n*   **Keywords**: Adaptive strategies, emergent properties, state-aware, dynamic.\n*   **Advice**: Design heuristics with inherent adaptability, allowing them to dynamically adjust priorities based on real-time state evolution. Favor simple, local rules that collectively yield robust global behavior. Incorporate mechanisms for recognizing and rectifying accumulating sub-optimality.\n*   **Avoid**: Prescribing fixed scoring biases, over-engineering perfect fit rewards, relying solely on pre-tuned parameters, or generic comparisons of complexity.\n*   **Explanation**: Focusing on dynamic adaptation and emergent properties fosters resilience. Rather than static optimization, heuristics should fluidly respond to changing problem landscapes, moving beyond rigid, pre-defined rules.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}