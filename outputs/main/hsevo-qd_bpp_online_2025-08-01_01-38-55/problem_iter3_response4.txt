```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin,
    implementing an adaptive, multi-objective heuristic with non-linear rewards.

    This function builds upon a Best-Fit-like heuristic by:
    1.  **Strongly incentivizing perfect fits:** Bins that can be perfectly filled
        by the item receive a very high, dedicated bonus, making them the top priority.
    2.  **Applying non-linear rewards for tight fits:** For bins that are not perfect fits
        but can accommodate the item, the priority is inversely proportional to the
        remaining space. This means smaller remaining space (tighter fit) is
        rewarded disproportionately more than larger remaining space, offering
        "granular incentives."
    3.  **Contextual Exploitation / Adaptive Scoring:** A subtle penalty is applied
        to bins that are initially more empty (have a larger remaining capacity)
        for non-perfect fits. This encourages placing items into already partially-used
        bins, promoting consolidation and aiming to leave fresh bins for potentially
        larger or future items, without overriding the primary goal of achieving tight fits.
        This provides a multi-objective approach.

    Bins that cannot fit the item receive a very low priority.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Initialize all priorities to a very low number. This ensures that
    # bins which cannot accommodate the item are effectively deprioritized.
    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Create a boolean mask for bins where the item can actually fit.
    can_fit_mask = bins_remain_cap >= item

    # Get the indices of bins that can fit the item.
    valid_bins_indices = np.where(can_fit_mask)[0]

    # Process only if there are bins that can accommodate the item.
    if valid_bins_indices.size > 0:
        # Calculate the remaining capacity after placing the item for eligible bins.
        remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item

        # --- Objective 1: Non-linear reward for tight fits (Best-Fit principle) ---
        # Use a non-linear inverse relationship to strongly reward smaller remainders.
        # Add a small epsilon to prevent division by zero for values very close to zero
        # when not a perfect fit.
        epsilon = 1e-6 # A small constant to ensure denominator is never exactly zero.
        base_scores = 1.0 / (remaining_capacity_after_fit + epsilon)

        # Apply the calculated base scores to the priorities of valid bins.
        priorities[can_fit_mask] = base_scores

        # --- Objective 2: Strong bonus for perfect fits ---
        # Identify perfect fits where remaining_capacity_after_fit is extremely close to 0.
        # Use numpy.isclose for robust floating-point comparison.
        is_perfect_fit = np.isclose(remaining_capacity_after_fit, 0.0, atol=1e-9)
        # Assign a very high fixed bonus for perfect fits. This makes them
        # unequivocally the highest priority, overriding other factors.
        # This bonus must be significantly larger than any possible base_score.
        # Max base_score (1/epsilon) is ~1e6, so 1e9 is a safe choice.
        perfect_fit_bonus = 1e9
        priorities[can_fit_mask][is_perfect_fit] += perfect_fit_bonus

        # --- Objective 3: Granular incentive for consolidation (Contextual Exploitation) ---
        # Apply a small penalty proportional to the *initial* remaining capacity of the bin
        # for non-perfect fits. This subtly encourages using bins that are already partially
        # filled over fresh, mostly empty bins, promoting consolidation.
        # This penalty should be much smaller than the base_scores.
        initial_cap_penalty_factor = 0.01 # A small constant to control the penalty's influence.

        # Create a mask for valid bins that are NOT perfect fits.
        non_perfect_fit_mask = can_fit_mask & (~is_perfect_fit)

        # Apply the penalty: larger initial remaining capacity (more empty bin) gets a larger penalty.
        # This effectively slightly favors bins that are already more full when comparing similar tight fits.
        priorities[non_perfect_fit_mask] -= initial_cap_penalty_factor * bins_remain_cap[non_perfect_fit_mask]

    return priorities
```
