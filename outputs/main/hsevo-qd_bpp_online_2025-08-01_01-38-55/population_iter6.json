[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 2.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a Best-Fit-like heuristic.\n    Bins that fit the item are prioritized based on how little space\n    would be left after placing the item (i.e., tighter fits get higher scores).\n    Bins that cannot fit the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after placement.\n    # We want to minimize this remaining capacity to achieve a \"best fit\".\n    # By taking the negative of the remaining capacity, a smaller positive remainder\n    # (i.e., a tighter fit) results in a larger (less negative) priority score.\n    # A perfect fit (remaining_capacity == 0) results in a score of 0.\n    # A bin that is barely larger than the item will get a score close to 0.\n    # A bin much larger than the item will get a more negative score.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = -remaining_capacity_after_fit\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing an enhanced Best-Fit-like heuristic with a non-linear\n    scoring function that strongly incentivizes perfect fits and applies\n    a decaying reward for other tight fits.\n\n    This version goes beyond a simple linear 'minimizing leftover space'\n    by introducing a multi-objective perspective through:\n    1. A significant bonus for perfect utilization of a bin.\n    2. A non-linear (inverse) reward for non-perfect fits,\n       making very tight fits significantly more desirable than slightly looser ones.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Define a small epsilon for robust floating-point comparisons\n    # and to prevent division by zero for actual perfect fits.\n    epsilon = 1e-9\n\n    # --- Multi-Objective / Non-Linear Scoring Strategy ---\n\n    # 1. Identify \"perfect fits\" (remaining capacity is effectively zero).\n    #    These are critical outcomes as they fully utilize a bin and reduce fragmentation.\n    is_perfect_fit = remaining_capacity_after_fit < epsilon\n\n    # 2. Calculate scores for non-perfect fits using an inverse relationship.\n    #    This ensures a non-linear decay: smaller remaining capacities get\n    #    disproportionately higher positive scores. Adding epsilon to the denominator\n    #    ensures numerical stability and provides a very high but finite score\n    #    for nearly perfect non-zero fits.\n    scores_for_non_perfect_fits = 1.0 / (remaining_capacity_after_fit + epsilon)\n\n    # Initialize combined scores with the non-perfect fit calculations.\n    combined_scores = scores_for_non_perfect_fits\n\n    # 3. Apply a significant, overriding bonus for truly perfect fits.\n    #    This ensures that a perfect fit is always chosen over any non-perfect fit,\n    #    no matter how small the remaining capacity in other bins might be.\n    #    The value (e.g., 2.0 / epsilon) is chosen to be orders of magnitude\n    #    larger than the highest possible score from `1.0 / (remaining + epsilon)`.\n    PERFECT_FIT_SCORE_BONUS = 2.0 / epsilon\n    combined_scores[is_perfect_fit] = PERFECT_FIT_SCORE_BONUS\n\n    # Assign the calculated scores to the bins that can fit the item.\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                default_low_priority: float = -13.732882263687515,\n                fit_score_weight: float = -4.7273623240749325) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a Best-Fit-like heuristic.\n    Bins that fit the item are prioritized based on how little space\n    would be left after placing the item (i.e., tighter fits get higher scores).\n    Bins that cannot fit the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        default_low_priority: The priority assigned to bins that cannot accommodate the item.\n                              Should be a very low number (e.g., -np.inf) to ensure they are\n                              not chosen if any valid bin exists.\n        fit_score_weight: A multiplier applied to the negative remaining capacity after fit.\n                          A negative value (e.g., -1.0) ensures that tighter fits (smaller\n                          remaining capacity) receive higher scores.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using default_low_priority makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after placement.\n    # We want to minimize this remaining capacity to achieve a \"best fit\".\n    # By taking the remaining capacity and multiplying by fit_score_weight,\n    # a smaller positive remainder (i.e., a tighter fit) results in a larger priority score\n    # when fit_score_weight is negative.\n    # A perfect fit (remaining_capacity == 0) results in a score of 0.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = remaining_capacity_after_fit * fit_score_weight\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version enhances the Best-Fit heuristic by incorporating a \"consolidation\"\n    bias. It subtly prioritizes placing items into bins that are already partially\n    filled, over opening entirely new bins (or using effectively \"new\" bins that are\n    still at their maximum initial capacity), provided the fit is comparable.\n    This promotes filling existing bins first to reduce the total bin count,\n    aligning with the goal of \"Global Flexibility\" and \"overall solution quality\"\n    by preventing fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot fit\n    # the item will effectively not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Best-Fit (Base Logic) ---\n    # Calculate the remaining capacity if the item is placed.\n    # A smaller remaining capacity indicates a tighter fit.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # The base score is the negative of the remaining capacity.\n    # A perfect fit (0 remaining) gets a score of 0. Tighter fits (smaller positive\n    # remaining capacity) get scores closer to 0 (less negative), making them higher priority.\n    base_scores = -remaining_capacity_after_fit\n\n    # --- Consolidation Bias (Domain Intelligence & Global Flexibility) ---\n    # To encourage consolidation, we add a small bonus to bins that are already\n    # partially filled. This nudges the algorithm to prefer an existing bin\n    # over a new one (or one that's still at its maximum capacity) if the\n    # Best-Fit scores are very close.\n\n    # Infer \"newly opened\" bins: We assume that any bin whose remaining capacity\n    # is equal to the maximum remaining capacity among all *currently available*\n    # bins (that can fit the item) is considered effectively \"new\" or \"empty\".\n    # This heuristic works well if bins are opened with a fixed capacity.\n    max_current_capacity = np.max(bins_remain_cap[can_fit_mask])\n\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity.\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity\n\n    # Define a small positive bonus. This value should be small enough not to\n    # override a significantly better Best-Fit score, but large enough to\n    # differentiate between closely scoring bins or break ties.\n    # The choice of 0.01 is a simple, robust constant for floating-point comparisons.\n    consolidation_bonus = 0.01\n\n    # Apply the bonus to partially filled bins.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]