```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add an item to each bin,
    mutating the Best-Fit heuristic to promote Global Flexibility and Simplicity.

    This version softens the strict preference for the absolute tightest fit
    by using a non-linear scaling of the remaining capacity after placement.
    Specifically, it penalizes larger remaining capacities more aggressively than
    smaller ones (when compared to a linear penalty), making 'good enough' fits
    (those with small but not necessarily zero remainder) relatively more competitive
    against perfect fits than in Best-Fit (priority_v1). This design aims to
    avoid creating numerous bins with extremely tiny, hard-to-use residual capacities
    by slightly diversifying choices for similarly good fits.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin. Assumed to be
                         positive and normalized (e.g., within [0, 1]).

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Initialize all priorities to a very low number. This ensures that
    # bins which cannot accommodate the item are effectively deprioritized.
    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Create a boolean mask for bins where the item can actually fit.
    can_fit_mask = bins_remain_cap >= item

    # For bins that can fit the item, calculate the remaining capacity after placement.
    # This value will be non-negative for all bins in the `can_fit_mask`.
    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item

    # The core mutation: Instead of a linear penalty (as in priority_v1: -x),
    # we use a power function (e.g., -x^2).
    #
    # Rationale:
    # - If remaining_capacity_after_fit (x) is 0 (perfect fit), x^2 is also 0. Score: 0.
    # - If 0 < x < 1 (common for normalized bin capacities): x^2 < x.
    #   Therefore, -x^2 > -x. This means the penalty for a non-perfect fit
    #   (but still a good fit, i.e., small x) is relatively *less severe*
    #   compared to a linear penalty.
    # Example:
    #   If x = 0.1: priority_v1 score = -0.1. priority_v2 score = -(0.1^2) = -0.01.
    #   If x = 0.5: priority_v1 score = -0.5. priority_v2 score = -(0.5^2) = -0.25.
    #
    # This change means that a bin leaving 0.1 space is much closer in score to a perfect fit
    # (0 space) than it would be in priority_v1. This encourages slightly looser, but still
    # efficient, fits to be competitive, promoting global flexibility by potentially
    # preventing an excessive number of bins with tiny, unusable remnants.
    #
    # The exponent (e.g., 2.0) is a context-driven parameter. A value > 1 will flatten
    # the penalty curve for smaller remaining capacities, while maintaining the
    # core Best-Fit principle of minimizing waste.
    EXPONENT_FOR_REMAINDER_PENALTY = 2.0

    priorities[can_fit_mask] = -(remaining_capacity_after_fit ** EXPONENT_FOR_REMAINDER_PENALTY)

    return priorities
```
