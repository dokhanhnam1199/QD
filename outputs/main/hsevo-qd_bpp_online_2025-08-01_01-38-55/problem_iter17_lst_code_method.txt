{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version enhances the Best-Fit heuristic by incorporating a \"consolidation\"\n    bias. It subtly prioritizes placing items into bins that are already partially\n    filled, over opening entirely new bins (or using effectively \"new\" bins that are\n    still at their maximum initial capacity), provided the fit is comparable.\n    This promotes filling existing bins first to reduce the total bin count,\n    aligning with the goal of \"Global Flexibility\" and \"overall solution quality\"\n    by preventing fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot fit\n    # the item will effectively not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Best-Fit (Base Logic) ---\n    # Calculate the remaining capacity if the item is placed.\n    # A smaller remaining capacity indicates a tighter fit.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # The base score is the negative of the remaining capacity.\n    # A perfect fit (0 remaining) gets a score of 0. Tighter fits (smaller positive\n    # remaining capacity) get scores closer to 0 (less negative), making them higher priority.\n    base_scores = -remaining_capacity_after_fit\n\n    # --- Consolidation Bias (Domain Intelligence & Global Flexibility) ---\n    # To encourage consolidation, we add a small bonus to bins that are already\n    # partially filled. This nudges the algorithm to prefer an existing bin\n    # over a new one (or one that's still at its maximum capacity) if the\n    # Best-Fit scores are very close.\n\n    # Infer \"newly opened\" bins: We assume that any bin whose remaining capacity\n    # is equal to the maximum remaining capacity among all *currently available*\n    # bins (that can fit the item) is considered effectively \"new\" or \"empty\".\n    # This heuristic works well if bins are opened with a fixed capacity.\n    max_current_capacity = np.max(bins_remain_cap[can_fit_mask])\n\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity.\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity\n\n    # Define a small positive bonus. This value should be small enough not to\n    # override a significantly better Best-Fit score, but large enough to\n    # differentiate between closely scoring bins or break ties.\n    # The choice of 0.01 is a simple, robust constant for floating-point comparisons.\n    consolidation_bonus = 0.01\n\n    # Apply the bonus to partially filled bins.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fit_score_weight: float = 1.0,\n                consolidation_bonus_weight: float = 0.01,\n                default_low_priority: float = -np.inf) -> np.ndarray:\n    \"\"\"Returns priority for adding an item, combining Best-Fit with a tunable consolidation bias.\n    Prioritizes tight fits and rewards using existing, partially-filled bins to consolidate space,\n    enhancing global flexibility through adaptable parameters.\n    \"\"\"\n    # Initialize all priorities to a very low number for bins that cannot fit.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Tunable Best-Fit Logic ---\n    # Calculate the remaining capacity if the item is placed in fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Base score: Smaller remaining capacity means a tighter fit, which is better.\n    # The score is amplified by 'fit_score_weight', which should be positive to\n    # promote tighter fits (i.e., a smaller negative value is a higher priority).\n    base_scores = fit_score_weight * (-remaining_capacity_after_fit)\n\n    # --- Tunable Consolidation Bias ---\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity\n    # among *currently available* bins that can fit the item.\n    max_current_capacity_among_fitting_bins = np.max(bins_remain_cap[can_fit_mask])\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity_among_fitting_bins\n\n    # Apply a tunable bonus to partially filled bins to encourage consolidation.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus_weight\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                default_low_priority: float = -13.732882263687515,\n                fit_score_weight: float = -4.7273623240749325) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a Best-Fit-like heuristic.\n    Bins that fit the item are prioritized based on how little space\n    would be left after placing the item (i.e., tighter fits get higher scores).\n    Bins that cannot fit the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        default_low_priority: The priority assigned to bins that cannot accommodate the item.\n                              Should be a very low number (e.g., -np.inf) to ensure they are\n                              not chosen if any valid bin exists.\n        fit_score_weight: A multiplier applied to the negative remaining capacity after fit.\n                          A negative value (e.g., -1.0) ensures that tighter fits (smaller\n                          remaining capacity) receive higher scores.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using default_low_priority makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after placement.\n    # We want to minimize this remaining capacity to achieve a \"best fit\".\n    # By taking the remaining capacity and multiplying by fit_score_weight,\n    # a smaller positive remainder (i.e., a tighter fit) results in a larger priority score\n    # when fit_score_weight is negative.\n    # A perfect fit (remaining_capacity == 0) results in a score of 0.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n    priorities[can_fit_mask] = remaining_capacity_after_fit * fit_score_weight\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fit_score_weight: float = 1.0,\n                consolidation_bonus_weight: float = 0.01,\n                default_low_priority: float = -np.inf) -> np.ndarray:\n    \"\"\"Returns priority for adding an item, combining Best-Fit with a tunable consolidation bias.\n    Prioritizes tight fits and rewards using existing, partially-filled bins to consolidate space,\n    enhancing global flexibility through adaptable parameters.\n    \"\"\"\n    # Initialize all priorities to a very low number for bins that cannot fit.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Tunable Best-Fit Logic ---\n    # Calculate the remaining capacity if the item is placed in fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Base score: Smaller remaining capacity means a tighter fit, which is better.\n    # The score is amplified by 'fit_score_weight', which should be positive to\n    # promote tighter fits (i.e., a smaller negative value is a higher priority).\n    base_scores = fit_score_weight * (-remaining_capacity_after_fit)\n\n    # --- Tunable Consolidation Bias ---\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity\n    # among *currently available* bins that can fit the item.\n    max_current_capacity_among_fitting_bins = np.max(bins_remain_cap[can_fit_mask])\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity_among_fitting_bins\n\n    # Apply a tunable bonus to partially filled bins to encourage consolidation.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus_weight\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                default_low_priority: float = float('-inf'),\n                fit_score_weight: float = -4.7273623240749325,\n                current_fullness_weight: float = -1.0) -> np.ndarray:\n    \"\"\"Returns priority for each bin, combining Best-Fit with a preference for already fuller bins.\n    Uses tunable weights for adaptive control, promoting tight fits and bin consolidation for efficient packing.\n    \"\"\"\n    # Initialize all priorities to a very low number for bins that cannot fit.\n    # Using float('-inf') ensures they are never chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, default_low_priority, dtype=float)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate scores only for bins that can fit the item.\n    if np.any(can_fit_mask):\n        # Component 1: Best-Fit score (prioritizing tightest fits)\n        # Calculates the remaining capacity after placing the item.\n        # A negative fit_score_weight makes smaller remaining_capacity_after_fit (tighter fits) result in higher scores.\n        remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n        fit_score = remaining_capacity_after_fit * fit_score_weight\n\n        # Component 2: Current Bin Fullness score (prioritizing already fuller bins)\n        # Uses the current remaining capacity. A smaller current_remaining_capacity means the bin is fuller.\n        # A negative current_fullness_weight makes smaller current_remaining_capacity (fuller bins) result in higher scores.\n        current_remaining_capacity = bins_remain_cap[can_fit_mask]\n        fullness_score = current_remaining_capacity * current_fullness_weight\n\n        # Combine the scores using a weighted sum for continuous integration.\n        priorities[can_fit_mask] = fit_score + fullness_score\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_MAX_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add an item to each bin.\n    This heuristic is designed to be an adaptive variant of Best-Fit,\n    considering 'Structural Integrity' and 'Emergent Properties' of the\n    overall bin packing solution, moving beyond rigid local optimization.\n\n    It improves upon a simple Best-Fit by:\n    1.  **Strongly Prioritizing Perfect Fits:** Bins that can precisely fit the\n        item (leaving zero remainder) receive the highest possible score.\n    2.  **Penalizing Fragmentation:** It applies a significant penalty to bins\n        where placing the item would leave a very small, non-zero, and\n        potentially unusable remainder (a \"fragment\"). This aims to prevent\n        the creation of many tiny, difficult-to-fill pockets of space, which\n        can lead to an increased total number of bins used (a negative\n        emergent property for the global solution).\n    3.  **Adaptive Thresholding:** The definition of a \"small fragment\" is\n        adaptive, considering both a small absolute value (relative to the\n        bin's maximum capacity, providing 'Global Context') and a value relative\n        to the current item's size ('Adaptive Design').\n    4.  **Best-Fit Tendency for Other Cases:** For all other valid fits (perfect\n        fits, or fits leaving remainders larger than the fragmentation threshold),\n        it reverts to the Best-Fit principle, favoring tighter fits to minimize\n        wasted space, while implicitly encouraging closure of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: A NumPy array containing the remaining capacities\n                         for each bin.\n        BIN_MAX_CAPACITY: The maximum capacity of any bin. This parameter\n                          provides crucial global context for evaluating\n                          remainder sizes and setting penalty scales.\n                          Defaults to 1.0, assuming item and bin sizes are normalized.\n\n    Returns:\n        A NumPy array of the same size as `bins_remain_cap`, where each\n        element is the calculated priority score for the corresponding bin.\n        Bins that cannot fit the item will have a very low priority (-np.inf).\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed not to be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # If no bin can accommodate the item, return the initialized priorities.\n        # This implies that a new bin must be opened in the broader packing algorithm.\n        return priorities\n\n    # Calculate the remaining capacity for bins where the item can be placed.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # --- Component 1: Best-Fit Base Score ---\n    # Tighter fits (smaller `remaining_capacity_after_fit`) are more desirable.\n    # A perfect fit (remainder = 0) gets a score of 0. Larger remainders get\n    # increasingly negative scores.\n    base_fit_score = -remaining_capacity_after_fit\n\n    # --- Component 2: Fragmentation Penalty ---\n    # This component penalizes solutions that lead to 'Structural Degradation'\n    # by creating very small, likely unusable, fragments of space.\n    # Define an adaptive threshold for what constitutes a \"small fragment\".\n    # It considers both an absolute minimum size (e.g., 1% of max bin capacity)\n    # and a relative minimum size (e.g., 5% of the current item's size).\n    # Using `max` ensures it meets at least a minimum absolute size criterion,\n    # while `min` prevents the threshold from becoming too large for very small items.\n    FRAGMENT_THRESHOLD = max(0.01 * BIN_MAX_CAPACITY, 0.05 * item)\n    FRAGMENT_THRESHOLD = min(FRAGMENT_THRESHOLD, 0.5 * item) # Cap threshold to avoid penalizing useful mid-range remainders\n\n    fragment_penalty = np.zeros_like(remaining_capacity_after_fit)\n\n    # Identify bins where the item fits, but leaves a small, non-zero fragment.\n    # Using a small epsilon (1e-9) to account for floating-point inaccuracies\n    # when checking for truly zero remainder.\n    is_fragmented_remainder = (remaining_capacity_after_fit > 1e-9) & \\\n                              (remaining_capacity_after_fit < FRAGMENT_THRESHOLD)\n\n    # Determine the magnitude of the penalty. This value is relative to the\n    # `BIN_MAX_CAPACITY` to scale appropriately across different problem sizes.\n    # A larger magnitude means fragmented bins are heavily discouraged.\n    PENALTY_MAGNITUDE = 0.2 * BIN_MAX_CAPACITY  # This is a key tunable parameter\n\n    # Apply the penalty to identified fragmented remainders.\n    fragment_penalty[is_fragmented_remainder] = -PENALTY_MAGNITUDE\n\n    # --- Combine Scores ---\n    # The final priority combines the best-fit preference with the fragmentation penalty.\n    # This guides the heuristic to make decisions that lead to better 'Emergent Properties'\n    # for the overall packing solution.\n    combined_score = base_fit_score + fragment_penalty\n\n    # Assign the calculated combined scores back to the appropriate bins.\n    priorities[can_fit_mask] = combined_score\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                w_tight_fit: float = 1.0, w_fullness: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a tunable heuristic combining a Best-Fit-like approach with a\n    preference for fuller bins.\n\n    Bins that fit the item are prioritized based on two weighted components:\n    1.  **Tight Fit:** How little space would be left after placing the item (i.e., tighter fits get higher scores).\n        This component directly relates to the Best-Fit heuristic.\n    2.  **Bin Fullness:** How full the bin already is (i.e., smaller remaining capacity means a fuller bin, getting a higher score).\n        This component encourages \"closing\" bins by filling those that are already significantly utilized.\n\n    Bins that cannot fit the item receive a very low priority, effectively preventing their selection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        w_tight_fit: Weight for the \"tight fit\" component. A higher value emphasizes\n                     minimizing leftover space after placement.\n        w_fullness: Weight for the \"bin fullness\" component. A higher value emphasizes\n                    using bins that are already more filled.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate scores only for bins that can fit the item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Component 1: Tight Fit (Best-Fit-like)\n    # The goal is to minimize (bins_remain_cap - item), which is the space left after placement.\n    # To maximize this, we use the negative: -(bins_remain_cap - item) = item - bins_remain_cap.\n    # A smaller remaining capacity after fit results in a higher score.\n    score_tight_fit = item - fitting_bins_remain_cap\n\n    # Component 2: Bin Fullness\n    # The goal is to prefer bins that already have a smaller remaining capacity\n    # (i.e., are closer to being full).\n    # To maximize this, we use the negative of remaining capacity: -fitting_bins_remain_cap.\n    # A smaller current remaining capacity results in a higher score.\n    score_fullness = -fitting_bins_remain_cap\n\n    # Combine the scores using tunable weights.\n    # The overall priority is a weighted sum of these two components.\n    combined_score = (w_tight_fit * score_tight_fit) + (w_fullness * score_fullness)\n\n    # Apply the calculated scores to the valid bins in the priorities array.\n    priorities[can_fit_mask] = combined_score\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best-Fit with a continuous consolidation bias.\n    Prioritizes tight fits and actively filling existing bins by adding a bonus\n    proportional to a bin's current fullness, with tunable weights.\n    \"\"\"\n    # Initialize all priorities to a very low number, effectively deprioritizing\n    # bins that cannot fit the item or are not considered.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Extract remaining capacities for only the fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Tunable Heuristic Parameters ---\n    # Weight for the Best-Fit component. A negative value is used because a smaller\n    # `remaining_after_fit` is better, leading to a higher (less negative) score.\n    WEIGHT_BEST_FIT = -1.0 \n\n    # Weight for the consolidation component. This encourages filling bins that are\n    # already partially full. It should be a positive value, typically small enough\n    # not to completely override a significantly better Best-Fit, but large enough\n    # to influence decisions, especially in near-tie scenarios.\n    WEIGHT_CONSOLIDATION = 0.01 \n    \n    # Assumed maximum capacity of a bin. This is common for normalized BPP instances.\n    # Used to calculate the \"current fullness\" of a bin.\n    BIN_CAPACITY = 1.0 \n    # --- End Tunable Heuristic Parameters ---\n\n    # 1. Best-Fit Component:\n    # Calculate the remaining capacity if the item is placed.\n    remaining_after_fit = fitting_bins_remain_cap - item\n    # The score is proportional to the negative of this value:\n    # A smaller `remaining_after_fit` (tighter fit) results in a score closer to 0 (less negative),\n    # which is a higher priority.\n    best_fit_scores = remaining_after_fit * WEIGHT_BEST_FIT\n\n    # 2. Consolidation Component (Bin Fullness):\n    # Calculate how full each bin currently is. A higher value means the bin is more full.\n    current_fullness = BIN_CAPACITY - fitting_bins_remain_cap\n    # Add a bonus proportional to the current fullness. This biases towards\n    # filling existing, partially used bins.\n    consolidation_scores = current_fullness * WEIGHT_CONSOLIDATION\n\n    # Combine the two components to get the final priority score for fitting bins.\n    combined_scores = best_fit_scores + consolidation_scores\n    \n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best-Fit with a continuous consolidation bias.\n    Prioritizes tight fits and actively filling existing bins by adding a bonus\n    proportional to a bin's current fullness, with tunable weights.\n    \"\"\"\n    # Initialize all priorities to a very low number, effectively deprioritizing\n    # bins that cannot fit the item or are not considered.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Extract remaining capacities for only the fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Tunable Heuristic Parameters ---\n    # Weight for the Best-Fit component. A negative value is used because a smaller\n    # `remaining_after_fit` is better, leading to a higher (less negative) score.\n    WEIGHT_BEST_FIT = -1.0 \n\n    # Weight for the consolidation component. This encourages filling bins that are\n    # already partially full. It should be a positive value, typically small enough\n    # not to completely override a significantly better Best-Fit, but large enough\n    # to influence decisions, especially in near-tie scenarios.\n    WEIGHT_CONSOLIDATION = 0.01 \n    \n    # Assumed maximum capacity of a bin. This is common for normalized BPP instances.\n    # Used to calculate the \"current fullness\" of a bin.\n    BIN_CAPACITY = 1.0 \n    # --- End Tunable Heuristic Parameters ---\n\n    # 1. Best-Fit Component:\n    # Calculate the remaining capacity if the item is placed.\n    remaining_after_fit = fitting_bins_remain_cap - item\n    # The score is proportional to the negative of this value:\n    # A smaller `remaining_after_fit` (tighter fit) results in a score closer to 0 (less negative),\n    # which is a higher priority.\n    best_fit_scores = remaining_after_fit * WEIGHT_BEST_FIT\n\n    # 2. Consolidation Component (Bin Fullness):\n    # Calculate how full each bin currently is. A higher value means the bin is more full.\n    current_fullness = BIN_CAPACITY - fitting_bins_remain_cap\n    # Add a bonus proportional to the current fullness. This biases towards\n    # filling existing, partially used bins.\n    consolidation_scores = current_fullness * WEIGHT_CONSOLIDATION\n\n    # Combine the two components to get the final priority score for fitting bins.\n    combined_scores = best_fit_scores + consolidation_scores\n    \n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version enhances the Best-Fit heuristic by incorporating a \"consolidation\"\n    bias. It subtly prioritizes placing items into bins that are already partially\n    filled, over opening entirely new bins (or using effectively \"new\" bins that are\n    still at their maximum initial capacity), provided the fit is comparable.\n    This promotes filling existing bins first to reduce the total bin count,\n    aligning with the goal of \"Global Flexibility\" and \"overall solution quality\"\n    by preventing fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot fit\n    # the item will effectively not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Best-Fit (Base Logic) ---\n    # Calculate the remaining capacity if the item is placed.\n    # A smaller remaining capacity indicates a tighter fit.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # The base score is the negative of the remaining capacity.\n    # A perfect fit (0 remaining) gets a score of 0. Tighter fits (smaller positive\n    # remaining capacity) get scores closer to 0 (less negative), making them higher priority.\n    base_scores = -remaining_capacity_after_fit\n\n    # --- Consolidation Bias (Domain Intelligence & Global Flexibility) ---\n    # To encourage consolidation, we add a small bonus to bins that are already\n    # partially filled. This nudges the algorithm to prefer an existing bin\n    # over a new one (or one that's still at its maximum capacity) if the\n    # Best-Fit scores are very close.\n\n    # Infer \"newly opened\" bins: We assume that any bin whose remaining capacity\n    # is equal to the maximum remaining capacity among all *currently available*\n    # bins (that can fit the item) is considered effectively \"new\" or \"empty\".\n    # This heuristic works well if bins are opened with a fixed capacity.\n    max_current_capacity = np.max(bins_remain_cap[can_fit_mask])\n\n    # Identify bins that are NOT \"newly opened\" (i.e., they are already partially filled).\n    # This is true if their current capacity is strictly less than the maximum observed capacity.\n    is_partially_filled = bins_remain_cap[can_fit_mask] < max_current_capacity\n\n    # Define a small positive bonus. This value should be small enough not to\n    # override a significantly better Best-Fit score, but large enough to\n    # differentiate between closely scoring bins or break ties.\n    # The choice of 0.01 is a simple, robust constant for floating-point comparisons.\n    consolidation_bonus = 0.01\n\n    # Apply the bonus to partially filled bins.\n    adjusted_scores = base_scores\n    adjusted_scores[is_partially_filled] += consolidation_bonus\n\n    # Assign the calculated scores to the fitting bins in the main priority array.\n    priorities[can_fit_mask] = adjusted_scores\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a hybrid heuristic that prioritizes perfect fits,\n    then encourages leaving large, versatile spaces, and heavily\n    penalizes leaving very small, potentially useless spaces.\n\n    This heuristic is designed to be more \"contextual\" and \"adaptive\"\n    than a simple Best-Fit. It aims to avoid local optima (e.g.,\n    a tight fit that leaves a fragmented, unusable space) by shaping\n    the remaining capacities in a more strategic way.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot\n    # accommodate the item are effectively deprioritized.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_remain_cap - item\n\n    # --- Heuristic Parameters (Tunable) ---\n    # Assuming standard bin capacity is 1.0. This is a common assumption\n    # for normalized item sizes in BPP unless specified otherwise.\n    BIN_CAPACITY = 1.0\n\n    # Score for a perfect fit (remaining_capacity_after_fit == 0).\n    # This should be the highest possible score, ensuring it's always chosen.\n    PERFECT_FIT_SCORE = 1000.0\n\n    # Threshold for what constitutes a \"small, potentially useless\" remainder.\n    # If the remaining space is less than this fraction of the bin capacity,\n    # it's considered poor and heavily penalized.\n    # This avoids creating many bins with tiny, unusable gaps.\n    FRAGMENT_THRESHOLD = 0.05 * BIN_CAPACITY # e.g., 5% of bin capacity\n\n    # Multiplier for the penalty applied to small, non-zero remainders.\n    # Higher values lead to stronger discouragement of such fits.\n    SMALL_REMAINDER_PENALTY_MULTIPLIER = 50.0\n\n    # Multiplier for the score applied to larger, versatile remainders.\n    # This encourages leaving substantial space in a bin for future items,\n    # akin to a \"Worst-Fit\" approach for non-tight fits.\n    LARGE_REMAINDER_MULTIPLIER = 2.0\n    # --- End Heuristic Parameters ---\n\n    # Apply scores based on different conditions for `remaining_after_fit`:\n\n    # 1. Perfect Fit: `remaining_after_fit` is approximately zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=1e-9)\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. Small, Potentially Useless Remainder: `0 < remaining_after_fit < FRAGMENT_THRESHOLD`.\n    # These are fits that are not perfect, but leave very little space,\n    # which might be too small for most subsequent items, leading to fragmentation.\n    small_remainder_mask = (remaining_after_fit > 1e-9) & (remaining_after_fit < FRAGMENT_THRESHOLD)\n    \n    # The penalty increases as `remaining_after_fit` gets closer to zero (from the positive side).\n    # This creates a \"valley\" in the scoring function just after zero.\n    penalty_scores = - (FRAGMENT_THRESHOLD - remaining_after_fit[small_remainder_mask]) * SMALL_REMAINDER_PENALTY_MULTIPLIER\n    priorities[can_fit_mask][small_remainder_mask] = penalty_scores\n\n    # 3. Large, Versatile Remainder: `remaining_after_fit >= FRAGMENT_THRESHOLD`.\n    # For these cases, we prefer leaving larger remaining spaces, as they are\n    # more likely to accommodate future, larger items, maintaining bin versatility.\n    # This is a Worst-Fit-like component for non-tight fits.\n    large_remainder_mask = remaining_after_fit >= FRAGMENT_THRESHOLD\n    \n    # Linear scoring: higher `remaining_after_fit` leads to a higher score.\n    # These scores are designed to be positive but lower than the `PERFECT_FIT_SCORE`.\n    large_remainder_scores = remaining_after_fit[large_remainder_mask] * LARGE_REMAINDER_MULTIPLIER\n    priorities[can_fit_mask][large_remainder_mask] = large_remainder_scores\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a hybrid heuristic that prioritizes perfect fits,\n    then encourages leaving large, versatile spaces, and heavily\n    penalizes leaving very small, potentially useless spaces.\n\n    This heuristic is designed to be more \"contextual\" and \"adaptive\"\n    than a simple Best-Fit. It aims to avoid local optima (e.g.,\n    a tight fit that leaves a fragmented, unusable space) by shaping\n    the remaining capacities in a more strategic way.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot\n    # accommodate the item are effectively deprioritized.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_remain_cap - item\n\n    # --- Heuristic Parameters (Tunable) ---\n    # Assuming standard bin capacity is 1.0. This is a common assumption\n    # for normalized item sizes in BPP unless specified otherwise.\n    BIN_CAPACITY = 1.0\n\n    # Score for a perfect fit (remaining_capacity_after_fit == 0).\n    # This should be the highest possible score, ensuring it's always chosen.\n    PERFECT_FIT_SCORE = 1000.0\n\n    # Threshold for what constitutes a \"small, potentially useless\" remainder.\n    # If the remaining space is less than this fraction of the bin capacity,\n    # it's considered poor and heavily penalized.\n    # This avoids creating many bins with tiny, unusable gaps.\n    FRAGMENT_THRESHOLD = 0.05 * BIN_CAPACITY # e.g., 5% of bin capacity\n\n    # Multiplier for the penalty applied to small, non-zero remainders.\n    # Higher values lead to stronger discouragement of such fits.\n    SMALL_REMAINDER_PENALTY_MULTIPLIER = 50.0\n\n    # Multiplier for the score applied to larger, versatile remainders.\n    # This encourages leaving substantial space in a bin for future items,\n    # akin to a \"Worst-Fit\" approach for non-tight fits.\n    LARGE_REMAINDER_MULTIPLIER = 2.0\n    # --- End Heuristic Parameters ---\n\n    # Apply scores based on different conditions for `remaining_after_fit`:\n\n    # 1. Perfect Fit: `remaining_after_fit` is approximately zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=1e-9)\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. Small, Potentially Useless Remainder: `0 < remaining_after_fit < FRAGMENT_THRESHOLD`.\n    # These are fits that are not perfect, but leave very little space,\n    # which might be too small for most subsequent items, leading to fragmentation.\n    small_remainder_mask = (remaining_after_fit > 1e-9) & (remaining_after_fit < FRAGMENT_THRESHOLD)\n    \n    # The penalty increases as `remaining_after_fit` gets closer to zero (from the positive side).\n    # This creates a \"valley\" in the scoring function just after zero.\n    penalty_scores = - (FRAGMENT_THRESHOLD - remaining_after_fit[small_remainder_mask]) * SMALL_REMAINDER_PENALTY_MULTIPLIER\n    priorities[can_fit_mask][small_remainder_mask] = penalty_scores\n\n    # 3. Large, Versatile Remainder: `remaining_after_fit >= FRAGMENT_THRESHOLD`.\n    # For these cases, we prefer leaving larger remaining spaces, as they are\n    # more likely to accommodate future, larger items, maintaining bin versatility.\n    # This is a Worst-Fit-like component for non-tight fits.\n    large_remainder_mask = remaining_after_fit >= FRAGMENT_THRESHOLD\n    \n    # Linear scoring: higher `remaining_after_fit` leads to a higher score.\n    # These scores are designed to be positive but lower than the `PERFECT_FIT_SCORE`.\n    large_remainder_scores = remaining_after_fit[large_remainder_mask] * LARGE_REMAINDER_MULTIPLIER\n    priorities[can_fit_mask][large_remainder_mask] = large_remainder_scores\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a hybrid heuristic that prioritizes perfect fits,\n    then encourages leaving large, versatile spaces, and heavily\n    penalizes leaving very small, potentially useless spaces.\n\n    This heuristic is designed to be more \"contextual\" and \"adaptive\"\n    than a simple Best-Fit. It aims to avoid local optima (e.g.,\n    a tight fit that leaves a fragmented, unusable space) by shaping\n    the remaining capacities in a more strategic way.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot\n    # accommodate the item are effectively deprioritized.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_remain_cap - item\n\n    # --- Heuristic Parameters (Tunable) ---\n    # Assuming standard bin capacity is 1.0. This is a common assumption\n    # for normalized item sizes in BPP unless specified otherwise.\n    BIN_CAPACITY = 1.0\n\n    # Score for a perfect fit (remaining_capacity_after_fit == 0).\n    # This should be the highest possible score, ensuring it's always chosen.\n    PERFECT_FIT_SCORE = 1000.0\n\n    # Threshold for what constitutes a \"small, potentially useless\" remainder.\n    # If the remaining space is less than this fraction of the bin capacity,\n    # it's considered poor and heavily penalized.\n    # This avoids creating many bins with tiny, unusable gaps.\n    FRAGMENT_THRESHOLD = 0.05 * BIN_CAPACITY # e.g., 5% of bin capacity\n\n    # Multiplier for the penalty applied to small, non-zero remainders.\n    # Higher values lead to stronger discouragement of such fits.\n    SMALL_REMAINDER_PENALTY_MULTIPLIER = 50.0\n\n    # Multiplier for the score applied to larger, versatile remainders.\n    # This encourages leaving substantial space in a bin for future items,\n    # akin to a \"Worst-Fit\" approach for non-tight fits.\n    LARGE_REMAINDER_MULTIPLIER = 2.0\n    # --- End Heuristic Parameters ---\n\n    # Apply scores based on different conditions for `remaining_after_fit`:\n\n    # 1. Perfect Fit: `remaining_after_fit` is approximately zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=1e-9)\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. Small, Potentially Useless Remainder: `0 < remaining_after_fit < FRAGMENT_THRESHOLD`.\n    # These are fits that are not perfect, but leave very little space,\n    # which might be too small for most subsequent items, leading to fragmentation.\n    small_remainder_mask = (remaining_after_fit > 1e-9) & (remaining_after_fit < FRAGMENT_THRESHOLD)\n    \n    # The penalty increases as `remaining_after_fit` gets closer to zero (from the positive side).\n    # This creates a \"valley\" in the scoring function just after zero.\n    penalty_scores = - (FRAGMENT_THRESHOLD - remaining_after_fit[small_remainder_mask]) * SMALL_REMAINDER_PENALTY_MULTIPLIER\n    priorities[can_fit_mask][small_remainder_mask] = penalty_scores\n\n    # 3. Large, Versatile Remainder: `remaining_after_fit >= FRAGMENT_THRESHOLD`.\n    # For these cases, we prefer leaving larger remaining spaces, as they are\n    # more likely to accommodate future, larger items, maintaining bin versatility.\n    # This is a Worst-Fit-like component for non-tight fits.\n    large_remainder_mask = remaining_after_fit >= FRAGMENT_THRESHOLD\n    \n    # Linear scoring: higher `remaining_after_fit` leads to a higher score.\n    # These scores are designed to be positive but lower than the `PERFECT_FIT_SCORE`.\n    large_remainder_scores = remaining_after_fit[large_remainder_mask] * LARGE_REMAINDER_MULTIPLIER\n    priorities[can_fit_mask][large_remainder_mask] = large_remainder_scores\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}