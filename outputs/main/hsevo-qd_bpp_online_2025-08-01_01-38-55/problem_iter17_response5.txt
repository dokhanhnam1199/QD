```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_MAX_CAPACITY: float = 1.0) -> np.ndarray:
    """Combines Best-Fit with strong perfect-fit priority, fragment penalty, and consolidation bias.
    It prioritizes filling existing, partially-used bins and avoids creating tiny, unusable spaces.
    """
    # Initialize all priorities to a very low number. This ensures that
    # bins which cannot accommodate the item are effectively deprioritized.
    # Using -np.inf makes them guaranteed not to be chosen if any valid bin exists.
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Create a boolean mask for bins where the item can actually fit.
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        # If no bin can accommodate the item, return the initialized priorities.
        # This implies that a new bin must be opened in the broader packing algorithm.
        return priorities

    # Get relevant capacities for bins that can fit the item
    current_bins_remain_cap = bins_remain_cap[can_fit_mask]
    remaining_capacity_after_fit = current_bins_remain_cap - item

    # --- Component 1: Best-Fit Base Score ---
    # Tighter fits (smaller `remaining_capacity_after_fit`) are more desirable.
    # A perfect fit (remainder = 0) gets a score of 0. Larger remainders get
    # increasingly negative scores.
    base_fit_score = -remaining_capacity_after_fit

    # --- Component 2: Fragmentation Penalty ---
    # This component penalizes solutions that lead to 'Structural Degradation'
    # by creating very small, likely unusable, fragments of space.
    # Define an adaptive threshold for what constitutes a "small fragment".
    # It considers both an absolute minimum size (e.g., 1% of max bin capacity)
    # and a relative minimum size (e.g., 5% of the current item's size).
    # Using `max` ensures it meets at least a minimum absolute size criterion,
    # while `min` prevents the threshold from becoming too large for very small items.
    FRAGMENT_THRESHOLD = max(0.01 * BIN_MAX_CAPACITY, 0.05 * item)
    FRAGMENT_THRESHOLD = min(FRAGMENT_THRESHOLD, 0.5 * item) # Cap threshold to avoid penalizing useful mid-range remainders

    fragment_penalty = np.zeros_like(remaining_capacity_after_fit)

    # Identify bins where the item fits, but leaves a small, non-zero fragment.
    # Using a small epsilon (1e-9) to account for floating-point inaccuracies
    # when checking for truly zero remainder.
    is_fragmented_remainder = (remaining_capacity_after_fit > 1e-9) & \
                              (remaining_capacity_after_fit < FRAGMENT_THRESHOLD)

    # Determine the magnitude of the penalty. This value is relative to the
    # `BIN_MAX_CAPACITY` to scale appropriately across different problem sizes.
    # A larger magnitude means fragmented bins are heavily discouraged.
    PENALTY_MAGNITUDE = 0.2 * BIN_MAX_CAPACITY  # Key tunable parameter for fragment deterrence

    # Apply the penalty to identified fragmented remainders.
    fragment_penalty[is_fragmented_remainder] = -PENALTY_MAGNITUDE

    # --- Component 3: Consolidation Bias ---
    # This component provides a bonus for placing items into bins that are already
    # partially used (i.e., not completely empty). This encourages consolidating
    # items into existing bins, helping to "close off" bins and reduce the total count.
    consolidation_bonus = np.zeros_like(remaining_capacity_after_fit)
    
    # Check if the bin was NOT completely empty before placing the item.
    # Use a small epsilon for floating-point comparison with BIN_MAX_CAPACITY.
    # A bin is considered 'not empty' if its remaining capacity is less than the max capacity.
    was_not_empty_mask = (current_bins_remain_cap < BIN_MAX_CAPACITY - 1e-9)

    # Define the magnitude of the consolidation bonus.
    # This should be significant enough to break ties between similarly good 'Best-Fit'
    # options, favoring already-in-use bins over opening new ones, but not so large
    # that it overrides strong Best-Fit or fragment avoidance.
    CONSOLIDATION_BONUS_MAGNITUDE = 0.05 * BIN_MAX_CAPACITY # Key tunable parameter for consolidation
    
    consolidation_bonus[was_not_empty_mask] = CONSOLIDATION_BONUS_MAGNITUDE

    # --- Combine Scores ---
    # The final priority combines best-fit preference, fragmentation penalty,
    # and the consolidation bonus, for a comprehensive decision.
    combined_score = base_fit_score + fragment_penalty + consolidation_bonus

    # Assign the calculated combined scores back to the appropriate bins.
    priorities[can_fit_mask] = combined_score

    return priorities
```
