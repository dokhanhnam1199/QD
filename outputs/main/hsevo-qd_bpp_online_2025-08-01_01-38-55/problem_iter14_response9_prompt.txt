{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing an enhanced Best-Fit-like heuristic with a non-linear\n    scoring function that strongly incentivizes perfect fits and applies\n    a decaying reward for other tight fits.\n\n    This version goes beyond a simple linear 'minimizing leftover space'\n    by introducing a multi-objective perspective through:\n    1. A significant bonus for perfect utilization of a bin.\n    2. A non-linear (inverse) reward for non-perfect fits,\n       making very tight fits significantly more desirable than slightly looser ones.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. This ensures that\n    # bins which cannot accommodate the item are effectively deprioritized.\n    # Using -np.inf makes them guaranteed to not be chosen if any valid bin exists.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Define a small epsilon for robust floating-point comparisons\n    # and to prevent division by zero for actual perfect fits.\n    epsilon = 1e-9\n\n    # --- Multi-Objective / Non-Linear Scoring Strategy ---\n\n    # 1. Identify \"perfect fits\" (remaining capacity is effectively zero).\n    #    These are critical outcomes as they fully utilize a bin and reduce fragmentation.\n    is_perfect_fit = remaining_capacity_after_fit < epsilon\n\n    # 2. Calculate scores for non-perfect fits using an inverse relationship.\n    #    This ensures a non-linear decay: smaller remaining capacities get\n    #    disproportionately higher positive scores. Adding epsilon to the denominator\n    #    ensures numerical stability and provides a very high but finite score\n    #    for nearly perfect non-zero fits.\n    scores_for_non_perfect_fits = 1.0 / (remaining_capacity_after_fit + epsilon)\n\n    # Initialize combined scores with the non-perfect fit calculations.\n    combined_scores = scores_for_non_perfect_fits\n\n    # 3. Apply a significant, overriding bonus for truly perfect fits.\n    #    This ensures that a perfect fit is always chosen over any non-perfect fit,\n    #    no matter how small the remaining capacity in other bins might be.\n    #    The value (e.g., 2.0 / epsilon) is chosen to be orders of magnitude\n    #    larger than the highest possible score from `1.0 / (remaining + epsilon)`.\n    PERFECT_FIT_SCORE_BONUS = 2.0 / epsilon\n    combined_scores[is_perfect_fit] = PERFECT_FIT_SCORE_BONUS\n\n    # Assign the calculated scores to the bins that can fit the item.\n    priorities[can_fit_mask] = combined_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin,\n    implementing a hybrid heuristic that prioritizes perfect fits,\n    then encourages leaving large, versatile spaces, and heavily\n    penalizes leaving very small, potentially useless spaces.\n\n    This heuristic is designed to be more \"contextual\" and \"adaptive\"\n    than a simple Best-Fit. It aims to avoid local optima (e.g.,\n    a tight fit that leaves a fragmented, unusable space) by shaping\n    the remaining capacities in a more strategic way.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low number. Bins that cannot\n    # accommodate the item are effectively deprioritized.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a boolean mask for bins where the item can actually fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the deprioritized array.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity after placing the item for fitting bins.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_remain_cap - item\n\n    # --- Heuristic Parameters (Tunable) ---\n    # Assuming standard bin capacity is 1.0. This is a common assumption\n    # for normalized item sizes in BPP unless specified otherwise.\n    BIN_CAPACITY = 1.0\n\n    # Score for a perfect fit (remaining_capacity_after_fit == 0).\n    # This should be the highest possible score, ensuring it's always chosen.\n    PERFECT_FIT_SCORE = 1000.0\n\n    # Threshold for what constitutes a \"small, potentially useless\" remainder.\n    # If the remaining space is less than this fraction of the bin capacity,\n    # it's considered poor and heavily penalized.\n    # This avoids creating many bins with tiny, unusable gaps.\n    FRAGMENT_THRESHOLD = 0.05 * BIN_CAPACITY # e.g., 5% of bin capacity\n\n    # Multiplier for the penalty applied to small, non-zero remainders.\n    # Higher values lead to stronger discouragement of such fits.\n    SMALL_REMAINDER_PENALTY_MULTIPLIER = 50.0\n\n    # Multiplier for the score applied to larger, versatile remainders.\n    # This encourages leaving substantial space in a bin for future items,\n    # akin to a \"Worst-Fit\" approach for non-tight fits.\n    LARGE_REMAINDER_MULTIPLIER = 2.0\n    # --- End Heuristic Parameters ---\n\n    # Apply scores based on different conditions for `remaining_after_fit`:\n\n    # 1. Perfect Fit: `remaining_after_fit` is approximately zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=1e-9)\n    priorities[can_fit_mask][perfect_fit_mask] = PERFECT_FIT_SCORE\n\n    # 2. Small, Potentially Useless Remainder: `0 < remaining_after_fit < FRAGMENT_THRESHOLD`.\n    # These are fits that are not perfect, but leave very little space,\n    # which might be too small for most subsequent items, leading to fragmentation.\n    small_remainder_mask = (remaining_after_fit > 1e-9) & (remaining_after_fit < FRAGMENT_THRESHOLD)\n    \n    # The penalty increases as `remaining_after_fit` gets closer to zero (from the positive side).\n    # This creates a \"valley\" in the scoring function just after zero.\n    penalty_scores = - (FRAGMENT_THRESHOLD - remaining_after_fit[small_remainder_mask]) * SMALL_REMAINDER_PENALTY_MULTIPLIER\n    priorities[can_fit_mask][small_remainder_mask] = penalty_scores\n\n    # 3. Large, Versatile Remainder: `remaining_after_fit >= FRAGMENT_THRESHOLD`.\n    # For these cases, we prefer leaving larger remaining spaces, as they are\n    # more likely to accommodate future, larger items, maintaining bin versatility.\n    # This is a Worst-Fit-like component for non-tight fits.\n    large_remainder_mask = remaining_after_fit >= FRAGMENT_THRESHOLD\n    \n    # Linear scoring: higher `remaining_after_fit` leads to a higher score.\n    # These scores are designed to be positive but lower than the `PERFECT_FIT_SCORE`.\n    large_remainder_scores = remaining_after_fit[large_remainder_mask] * LARGE_REMAINDER_MULTIPLIER\n    priorities[can_fit_mask][large_remainder_mask] = large_remainder_scores\n\n    return priorities\n\n### Analyze & experience\n- Comparing (Heuristics 1st) vs (Heuristics 2nd), Heuristics 1st, which applies a fixed small bonus (0.01) for consolidation by identifying partially filled bins (those with remaining capacity less than the maximum current capacity among fitting bins), slightly outperforms Heuristics 2nd. Heuristics 2nd uses a continuously tunable weighted sum of Best-Fit (`remaining_capacity_after_fit`) and `current_fullness` (current remaining capacity), with specific tuned weights (`-4.72...`, `-1.0`). Both successfully integrate a consolidation bias, but the simple, hard-coded conditional bonus in 1st proved marginally more effective in this ranking than 2nd's continuously weighted sum, even with its tuned parameters.\n\nComparing (Heuristics 2nd) vs (Heuristics 3rd), Heuristics 2nd (tuned weighted sum including bin fullness) is superior to Heuristics 3rd (tuned pure Best-Fit). Heuristics 3rd's `fit_score_weight` of `-5.04...` indicates it's a strongly tuned Best-Fit. However, the explicit inclusion of the `current_fullness_weight` component in Heuristics 2nd, favoring bins that are already fuller, demonstrates that a multi-objective scoring combining tight fit with bin consolidation (filling existing bins) provides better performance than a purely Best-Fit approach, even when both are highly tuned.\n\nComparing (Heuristics 3rd) vs (Heuristics 8th), Heuristics 3rd (tuned pure Best-Fit) significantly outperforms Heuristics 8th, which is also a pure Best-Fit but with a generic `fit_score_weight` of `-1.0`. This stark difference highlights the immense value of hyperparameter tuning: even a simple heuristic can become very powerful when its parameters are meticulously optimized for the problem instance.\n\nComparing (Heuristics 4th) vs (Heuristics 5th), both are \"tunable\" with default parameters. Heuristics 4th implements a Best-Fit with a *binary* consolidation bonus based on whether a bin is \"partially filled\" relative to the maximum capacity. Heuristics 5th employs a *continuous* weighted sum of \"tight fit\" and \"bin fullness.\" Heuristics 5th (continuous weighting) outranks Heuristics 4th (binary bonus with similar defaults), suggesting that a continuous scoring for fullness is generally more robust or effective than a binary bonus when parameters are not specifically tuned.\n\nComparing (Heuristics 5th) vs (Heuristics 7th), Heuristics 5th (tunable weighted sum, default weights) performs better than Heuristics 7th, which uses a non-linear scoring function with a significant bonus for perfect fits and an inverse relationship for other tight fits. This indicates that while the *idea* of strongly prioritizing perfect fits and non-linear rewards might seem beneficial, the specific implementation in Heuristics 7th might lead to sub-optimal choices globally, perhaps by overly favoring very rare perfect fits or by creating less versatile remaining spaces compared to a more balanced linear combination.\n\nComparing (Heuristics 11th) vs (Heuristics 13th), Heuristics 11th, a highly complex \"hybrid adaptive\" heuristic that attempts to manage fragmentation by penalizing small remainders and rewarding large ones, is still vastly superior to Heuristics 13th. Heuristics 13th simply assigns zero priority to all bins, effectively leading to arbitrary or random bin selection among fitting bins. This confirms that any structured heuristic, no matter how poorly optimized or overly complex, offers more strategic guidance than a complete lack of strategy. The repeated instances of Heuristics 11th (11th, 12th, 14th, 16th, 17th, 19th, 20th) at the bottom ranks (excluding the dummy zero function) suggest its complex logic with its default parameters is often counter-productive, possibly opening too many bins prematurely or leaving too much usable space unused to avoid \"fragmentation,\" thereby increasing the overall bin count.\n\nOverall: The best-performing heuristics are those that combine the core \"Best-Fit\" principle with a mechanism for \"consolidation\" or \"bin fullness.\" Crucially, even simple heuristics can achieve top performance if their parameters are meticulously tuned. Overly complex or non-linear scoring functions, while conceptually appealing, can underperform if not perfectly calibrated, sometimes leading to worse results than simpler, robust approaches.\n- \nTo redefine 'Current self-reflection' avoiding 'Ineffective self-reflection' points:\n\n*   **Keywords:** Emergent Properties, Adaptive Design, Global Context, Structural Integrity.\n*   **Advice:** Design heuristics to foster beneficial emergent behaviors and maintain solution flexibility, prioritizing adaptive decision rules that consider global context over rigid local optimizations.\n*   **Avoid:** Over-reliance on isolated parameter tuning, prescriptive scoring functions for local \"perfect fits,\" or specific algorithmic choices as universal solutions.\n*   **Explanation:** A focus on systemic design and adaptability enables heuristics to navigate complex landscapes more effectively, preventing local optima traps and fostering robust, globally superior outcomes.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}