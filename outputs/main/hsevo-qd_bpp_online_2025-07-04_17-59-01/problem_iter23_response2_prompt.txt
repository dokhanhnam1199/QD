{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Enhanced priority function with adaptive weighting, state-awareness, and robust normalization.\"\"\"\n\n    # Handle edge case: empty bins_remain_cap array\n    if bins_remain_cap.size == 0:\n        return np.array([])\n\n    # Ensure no division by zero\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap; penalize infeasible bins\n    gap = bins_remain_cap - item\n    feasible = gap >= 0\n    gap = np.where(feasible, gap, -1)\n\n    # Ratio priority (item size / bin capacity)\n    ratios = item / bins_remain_cap\n    ratio_priority = -np.log(ratios)\n    ratio_priority = np.where(feasible, ratio_priority, -1e9)\n\n    # Dynamic almost-full penalty based on remaining capacity\n    avg_cap = np.mean(bins_remain_cap)\n    almost_full_penalty = np.exp(-50 * gap / (avg_cap + 1e-9))\n    almost_full_penalty = np.where(feasible, almost_full_penalty, 0)\n    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9)\n\n    # Capacity priority (normalized)\n    max_cap = np.max(bins_remain_cap)\n    capacity_priority = bins_remain_cap / (max_cap + 1e-9)\n    capacity_priority = np.where(feasible, capacity_priority, -1e9)\n    \n    # Adaptive weights based on item size and remaining capacity variance.\n    item_size_factor = min(1.0, item)\n    capacity_variance = np.var(bins_remain_cap)\n\n    # Adjust weights based on item size and remaining capacity variance.\n    weight_ratio = 0.2 + 0.2 * item_size_factor # Range: [0.2, 0.4]\n    weight_gap = 0.5 - 0.1 * item_size_factor + 0.1 * min(1.0, capacity_variance) #Range: [0.4, 0.6]\n    weight_capacity = 0.3 - 0.1 * capacity_variance #Ensure sum to 1. Range: [0.1, 0.3]\n\n    # Combined priority with adaptive weights\n    combined_priority = (\n        weight_ratio * ratio_priority +\n        weight_gap * gap_priority +\n        weight_capacity * capacity_priority\n    )\n\n    # Apply a small penalty to bins close to full to encourage better distribution.\n    close_to_full = (gap > 0) & (gap < 0.1)\n    combined_priority = np.where(close_to_full, combined_priority - 0.05, combined_priority)\n\n    return combined_priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines ratio-based and gravity-inspired approaches for bin selection.\"\"\"\n    # Ensure no division by zero\n    bins_remain_cap = np.where(bins_remain_cap == 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap\n    gap = bins_remain_cap - item\n    gap = np.where(gap < 0, -1, gap)\n\n    # Ratio-based priority (normalized)\n    ratios = np.where(bins_remain_cap > 0, item / bins_remain_cap, 0)\n    normalized_ratios = ratios / np.max(ratios) if np.max(ratios) > 0 else np.zeros_like(ratios)\n\n    # \"Gravitational\" attraction with added constant\n    gravity = np.where(gap >= 0, bins_remain_cap / (gap**2 + 0.0001), -1e9)\n\n    # Combine the two priorities\n    priorities = 0.5 * normalized_ratios + 0.5 * (gravity / np.max(gravity) if np.max(gravity) > 0 else np.zeros_like(gravity))\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first heuristic combines several factors (ratio, gap, capacity, fullness, perfect fit) with adaptive weights, while the last only considers the ratio of item size to bin capacity. (2nd) vs (19th) shows that the second heuristic combines ratio, gap, capacity, best-fit, and dynamic weights, while the 19th focuses on ratio and a \"gravitational\" attraction with some added constants. Comparing (1st) vs (2nd), we see the first one explicitly favors bins that can be perfectly filled, and includes dynamic adjustment to handle almost-full bins using an exponential penalty, it also uses adaptive weights based on item size and average capacity. In contrast, the second version lacks perfect fit consideration, uses different method to dynamically weigh best fit and introduces bin fill level concept. (3rd) vs (4th) show that the 4th one explicitly normalizes the best-fit priority and uses bin fill level to adjust weights for best-fit, ratio, gap and capacity. Heuristic 3rd lacks this normalization of best fit priority. Comparing (second worst) vs (worst), we see the second worst `priority_v2` function considers gap and ratio, and applies penalty, the worst function only considers ratio of item size to bin capacity. Overall: The better heuristics incorporate more factors, use adaptive weighting, include normalization, handle edge cases carefully (division by zero, empty input), and demonstrate state awareness (e.g., considering how full bins already are). They penalize nearly full bins more effectively.\n- \nOkay, let's refine \"Current Self-Reflection\" for better heuristic design, avoiding the pitfalls of \"Ineffective Self-Reflection.\" Here's a revised approach:\n\n*   **Keywords:** Multi-factor heuristics, adaptive weighting, normalization, state-awareness, penalty functions, edge case handling, exploration-exploitation balance.\n\n*   **Advice:** Design heuristics that intelligently combine multiple problem-relevant factors. Prioritize adaptive weighting mechanisms driven by the current problem state to dynamically adjust the influence of each factor.\n\n*   **Avoid:** Relying on single-factor metrics or analogies without strong problem relevance. Don't neglect normalization or robust edge case handling, as these are fundamental.\n\n*   **Explanation:** Effective heuristics need to be flexible and responsive to the changing problem landscape. By combining multiple normalized factors and adaptively weighting them based on the state, you create a more nuanced and powerful decision-making process. Penalties discourage undesirable outcomes, and careful edge case handling ensures robustness.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}