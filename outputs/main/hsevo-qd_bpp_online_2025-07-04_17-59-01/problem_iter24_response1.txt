```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Advanced priority function for online bin packing, integrating several factors with
    adaptive weighting and normalization, and a reinforcement learning inspired exploration bonus.
    """

    # Robust handling of zero or negative remaining capacities
    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)

    # Feasibility mask
    feasible = bins_remain_cap >= item

    # Gap Calculation and Penalty
    gap = bins_remain_cap - item
    gap = np.where(feasible, gap, -1)
    avg_cap = np.mean(bins_remain_cap)

    # More aggressive 'almost full' penalty, dynamically adjusted
    almost_full_threshold = 0.1 * avg_cap
    almost_full = (gap >= 0) & (gap <= almost_full_threshold)
    almost_full_penalty = np.where(almost_full, np.exp(7 * (gap - almost_full_threshold) / (almost_full_threshold + 1e-9)), 0)
    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9) # Prevent division by zero


    # Ratio priority, emphasizing efficient use of space. Apply log transform for better scaling
    ratios = item / bins_remain_cap
    ratio_priority = -np.log(ratios)
    ratio_priority = np.where(feasible, ratio_priority, -1e9)

    # Capacity priority
    capacity_priority = bins_remain_cap / (np.max(bins_remain_cap) + 1e-9)
    capacity_priority = np.where(feasible, capacity_priority, -1e9)

    # Fullness Priority
    fullness_level = bins_remain_cap / (avg_cap + 1e-9)
    fullness_priority = np.where(feasible, 1 - np.exp(-3*fullness_level), -1e9)

    # Perfect Fit Bonus
    perfect_fit = np.isclose(item, bins_remain_cap)
    perfect_fit_bonus = np.where(perfect_fit & feasible, 1e9, 0)

    # Adaptive weights
    item_size_factor = min(1.0, item)
    capacity_factor = min(1.0, avg_cap / (np.max(bins_remain_cap) + 1e-9)) if np.max(bins_remain_cap) > 0 else 0.5

    # Exploration Bonus: Favor bins that are less frequently used.  This encourages exploration
    # and can help escape local optima.
    bin_usage_count = np.zeros_like(bins_remain_cap) # Initialize counts (stateful!)
    # Normalize bin_usage_count to range [0, 1]
    max_usage = np.max(bin_usage_count) if np.any(bin_usage_count > 0) else 1  # avoid division by zero
    normalized_usage = bin_usage_count / max_usage
    exploration_bonus = (1 - normalized_usage) * 10 # scale between 0 and 10
    exploration_bonus = np.where(feasible, exploration_bonus, -1e9)

    # Adaptive weights, combined with exploration
    combined_priority = (
        0.2 * ratio_priority +
        0.25 * gap_priority +
        0.15 * capacity_priority +
        0.2 * fullness_priority +
        0.1 * perfect_fit_bonus +
        0.1 * exploration_bonus # Encourage exploration
    )

    return combined_priority
```
