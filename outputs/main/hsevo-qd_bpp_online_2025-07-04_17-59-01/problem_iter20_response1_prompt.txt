{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines ratio, gap, and capacity with dynamic penalty.\"\"\"\n\n    # Handle zero capacities\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap, mark infeasible bins\n    gap = bins_remain_cap - item\n    feasible = gap >= 0\n    gap = np.where(feasible, gap, -1)\n\n    # Ratio-based priority\n    ratios = item / bins_remain_cap\n    ratio_priority = -np.log(ratios)\n    ratio_priority = np.where(feasible, ratio_priority, -1e9)\n\n    # Gap-based priority + dynamic almost full penalty\n    almost_full_penalty_scale = np.mean(bins_remain_cap)\n    almost_full_penalty = np.exp(-50 * gap / (almost_full_penalty_scale + 1e-9))\n    almost_full_penalty = np.where(feasible, almost_full_penalty, 0)\n    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9)\n    \n    # Capacity-based priority\n    capacity_priority = bins_remain_cap / (np.max(bins_remain_cap) + 1e-9)\n    capacity_priority = np.where(feasible, capacity_priority, -1e9)\n\n    # Combined priority\n    combined_priority = (\n        0.4 * ratio_priority +\n        0.4 * gap_priority +\n        0.2 * capacity_priority\n    )\n\n    return combined_priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A priority function for the online bin packing problem that combines ratio,\n    gap, capacity, dynamic penalty, and adaptive weights, with improved\n    handling of edge cases and state awareness.\n    \"\"\"\n\n    # Small constant to avoid division by zero and other numerical issues\n    epsilon = 1e-9\n\n    # 1. Feasibility check and basic preprocessing\n    feasible = bins_remain_cap >= item\n    num_feasible = np.sum(feasible)\n    \n    # If no bin is feasible, return a low priority for all bins, prioritizing the least full one\n    if num_feasible == 0:\n        return -bins_remain_cap  # Prioritize bins with more remaining capacity\n\n    # 2. Ratio priority (item size / bin capacity), only for feasible bins\n    ratios = item / np.where(bins_remain_cap <= 0, epsilon, bins_remain_cap)\n    ratio_priority = -np.log(ratios)\n    ratio_priority = np.where(feasible, ratio_priority, -1e9)\n\n    # 3. Gap priority with dynamic almost-full penalty and scaled gap\n    gap = bins_remain_cap - item\n    gap = np.where(feasible, gap, -1)\n\n    # Dynamic almost-full penalty, scaled by the item size and the number of feasible bins\n    avg_cap = np.mean(bins_remain_cap[feasible]) if num_feasible > 0 else np.mean(bins_remain_cap) # Only consider feasible bins for average cap\n    almost_full_penalty = np.exp(-50 * gap / (avg_cap + epsilon))\n    almost_full_penalty = np.where(feasible, almost_full_penalty, 0)\n    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9)\n\n    # 4. Capacity priority (normalized remaining capacity), only for feasible bins\n    max_cap = np.max(bins_remain_cap[feasible]) if num_feasible > 0 else np.max(bins_remain_cap) # Max capacity only among feasible bins\n    capacity_priority = bins_remain_cap / (max_cap + epsilon)\n    capacity_priority = np.where(feasible, capacity_priority, -1e9)\n\n    # 5. Introduce a \"balancing\" term to encourage more even bin utilization\n    #   This is a state-aware component to avoid filling one bin completely\n    #   before others have had a chance to be used.\n    fill_level = 1.0 - (bins_remain_cap / (np.max(bins_remain_cap) + epsilon))  # Fill level of each bin (0 to 1)\n    fill_level_priority = -fill_level # Prefer bins with lower fill levels\n\n    fill_level_priority = np.where(feasible, fill_level_priority, -1e9)\n\n    # 6. Adaptive weights based on item size and bin diversity\n    item_size_factor = min(1.0, item)\n    \n    # Standard deviation of remaining capacities. Higher std means more diverse bins\n    bin_diversity = np.std(bins_remain_cap)\n    diversity_factor = min(1.0, bin_diversity) # Normalize std\n\n    # 7. Combined priority calculation with more emphasis on gap\n    combined_priority = (\n        0.15 * ratio_priority +\n        0.55 * gap_priority +\n        0.15 * capacity_priority +\n        0.15 * fill_level_priority\n    )\n    \n    return combined_priority\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines ratio, gap, capacity, best-fit, and dynamic weights, while the worst only considers the ratio of item size to bin capacity. (2nd best) vs (second worst) also shows a similar contrast. Comparing (1st) vs (2nd), we see that both heuristics are exactly identical, suggesting their performance is statistically similar. (3rd) vs (4th) are also identical. Comparing (second worst) vs (worst), both heuristics only considers the ratio between item and bins capacity, however the former uses log and the latter doesn't. Overall: The better heuristics incorporate more factors (gap, capacity, dynamic penalties, adaptive weights) and use normalization techniques. They also dynamically adjust weights based on item size and bin state. Simpler heuristics relying solely on ratios tend to perform worse. The dynamic \"almost full\" penalty and the fill level balancing term appear in the higher-ranked heuristics.\n- \nOkay, let's redefine \"Current self-reflection\" to guide the design of better heuristics, focusing on actionable advice and avoiding common pitfalls highlighted in the \"Ineffective self-reflection.\"\n\nHere's a refined perspective:\n\n*   **Keywords:** Multi-factor, Normalization, Dynamic penalties, Adaptive weighting, State-aware.\n\n*   **Advice:** Design heuristics that synthesize several relevant factors, normalized to a common scale. Use dynamic penalties to discourage undesirable states, adapting to the problem's current state via adaptive weights. Incorporate state-aware components to make decisions based on current state.\n\n*   **Avoid:** Single-factor metrics, relying on domain-specific analogies without rigorous justification, ignoring edge cases or infeasible solutions, and failing to normalize values.\n\n*   **Explanation:** Combining normalized factors provides a more nuanced view than single metrics. Adaptive strategies allow the heuristic to adjust its behavior based on the current problem state, leading to more robust and effective solutions.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}