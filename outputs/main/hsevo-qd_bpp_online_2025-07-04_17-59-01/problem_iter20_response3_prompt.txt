{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n       This version considers a combination of factors:\n       - Remaining capacity after placing the item (gap).\n       - Bin capacity.\n       - A penalty for bins that are almost full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Ensure no division by zero\n    bins_remain_cap = np.where(bins_remain_cap == 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap (remaining capacity after placing the item)\n    gap = bins_remain_cap - item\n    # bins where gap < 0 are not feasible: assign a very small priority.\n    gap = np.where(gap < 0, -1, gap)\n    \n    # Calculate a penalty for bins that will be almost full after placing the item\n    almost_full_penalty = np.exp(-50 * gap)  # Exponential penalty, sharp drop-off as gap -> 0\n    almost_full_penalty = np.where(gap >= 0, almost_full_penalty, 0) # only applies to feasible bins\n\n    # Calculate priority score.  Combine bin capacity, gap, and the almost full penalty.\n    priorities = np.where(gap >= 0, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9) # Added constant to prevent possible 0 division.\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines ratio, gap, capacity, best-fit, and dynamic weights, while the worst only considers the ratio of item size to bin capacity. (2nd best) vs (second worst) also shows a similar contrast. Comparing (1st) vs (2nd), we see that both heuristics are exactly identical, suggesting their performance is statistically similar. (3rd) vs (4th) are also identical. Comparing (second worst) vs (worst), both heuristics only considers the ratio between item and bins capacity, however the former uses log and the latter doesn't. Overall: The better heuristics incorporate more factors (gap, capacity, dynamic penalties, adaptive weights) and use normalization techniques. They also dynamically adjust weights based on item size and bin state. Simpler heuristics relying solely on ratios tend to perform worse. The dynamic \"almost full\" penalty and the fill level balancing term appear in the higher-ranked heuristics.\n- \nOkay, let's redefine \"Current self-reflection\" to guide the design of better heuristics, focusing on actionable advice and avoiding common pitfalls highlighted in the \"Ineffective self-reflection.\"\n\nHere's a refined perspective:\n\n*   **Keywords:** Multi-factor, Normalization, Dynamic penalties, Adaptive weighting, State-aware.\n\n*   **Advice:** Design heuristics that synthesize several relevant factors, normalized to a common scale. Use dynamic penalties to discourage undesirable states, adapting to the problem's current state via adaptive weights. Incorporate state-aware components to make decisions based on current state.\n\n*   **Avoid:** Single-factor metrics, relying on domain-specific analogies without rigorous justification, ignoring edge cases or infeasible solutions, and failing to normalize values.\n\n*   **Explanation:** Combining normalized factors provides a more nuanced view than single metrics. Adaptive strategies allow the heuristic to adjust its behavior based on the current problem state, leading to more robust and effective solutions.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}