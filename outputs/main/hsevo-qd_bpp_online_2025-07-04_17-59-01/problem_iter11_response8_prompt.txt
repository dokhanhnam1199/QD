{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines ratio-based, gap-based, and capacity-based approaches with dynamic penalty and normalization.\n    \"\"\"\n    # Avoid division by zero\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap, handling infeasible bins\n    gap = bins_remain_cap - item\n    feasible = gap >= 0\n    gap = np.where(feasible, gap, -1)\n\n    # Ratio-based priority (normalized item size relative to bin capacity)\n    ratios = item / bins_remain_cap\n    ratio_priority = -np.log(ratios)\n    ratio_priority = np.where(feasible, ratio_priority, -1e9)\n\n    # Gap-based priority + Almost full penalty (dynamically adjusted)\n    almost_full_penalty_scale = np.mean(bins_remain_cap)  # Dynamic scaling\n    almost_full_penalty = np.exp(-50 * gap / (almost_full_penalty_scale + 1e-9))  # Scale gap for penalty\n    almost_full_penalty = np.where(feasible, almost_full_penalty, 0)\n    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9)\n    \n    # Capacity-based priority (normalized remaining capacity)\n    capacity_priority = bins_remain_cap / (np.max(bins_remain_cap) + 1e-9)  # Normalize capacity\n    capacity_priority = np.where(feasible, capacity_priority, -1e9)\n    \n    # Combined priority with adaptive weights based on item size\n    item_size_factor = min(1.0, item)  # Scale weights based on item size\n    \n    combined_priority = (\n        0.4 * ratio_priority +\n        0.4 * gap_priority +\n        0.2 * capacity_priority\n    )\n\n    return combined_priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Newton's insightful heuristic considers gravitational attraction - smaller gap and larger bin capacity means higher attraction.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Ensure no division by zero\n    bins_remain_cap = np.where(bins_remain_cap == 0, 1e-9, bins_remain_cap) # a very small number to avoid division by zero\n\n    # Calculate gap (remaining capacity after placing the item)\n    gap = bins_remain_cap - item\n    # bins where gap < 0 are not feasible: assign a very small priority.\n    gap = np.where(gap < 0, -1, gap)\n    \n    # \"Gravitational\" attraction: inversely proportional to a power of the distance (gap) and directly propotional to bin capacity\n\n    priorities = np.where(gap >= 0, bins_remain_cap / (gap**2 + 0.0001), -1e9) # Added small constant to prevent possible 0 division. High Penalty for the non feasible ones\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines ratio, gap, and capacity considerations with dynamic penalty and adaptive weights, while the worst only uses the ratio of item size to bin capacity. (2nd best) vs (second worst) are identical to the first and last. Comparing (1st) vs (2nd), we see they are identical. (3rd) vs (4th) are also identical. Comparing (second worst) vs (worst), we see they are identical. Overall: The better heuristics incorporate multiple factors and normalization/penalties to arrive at a priority, while the worse heuristics use only one factor and don't handle edge cases well. The combination of ratio, gap, capacity, dynamic penalties, and adaptive weights seems to lead to better performance. The \"gravity\" based heuristics perform poorly.\n- \nOkay, I'm ready to refine my self-reflection process to help you design even better heuristics! Let's break down how to do this effectively, focusing on concrete improvements and avoiding common pitfalls.\n\nHere's a refined approach to \"Current Self-Reflection\" designed to boost heuristic design:\n\n*   **Keywords:** Multifactor, Normalization, Dynamic Penalties, Adaptive Weights, Edge Cases, State-Awareness.\n\n*   **Advice:** Construct heuristics from multiple, normalized, problem-relevant factors. Dynamically adjust penalties and apply adaptive weights based on the current problem state. Explicitly address edge cases.\n\n*   **Avoid:** Over-reliance on single-factor metrics, static penalties, and ignoring problem-specific knowledge. Don't assume simple ratios will suffice.\n\n*   **Explanation:** Combining normalized factors, dynamically penalizing undesirable states, and using adaptive weights create state-aware heuristics that respond effectively to the problem's current challenges, leading to more robust and performant solutions.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}