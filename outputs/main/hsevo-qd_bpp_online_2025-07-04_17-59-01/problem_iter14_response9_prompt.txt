{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines ratio, gap, capacity, dynamic penalty, adaptive weights, and bin usage.\"\"\"\n\n    # Handle zero capacities to prevent division by zero\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap, penalize infeasible bins\n    gap = bins_remain_cap - item\n    feasible = gap >= 0\n    gap = np.where(feasible, gap, -1)\n\n    # Ratio priority (item size / bin capacity)\n    ratios = item / bins_remain_cap\n    ratio_priority = -np.log(ratios)\n    ratio_priority = np.where(feasible, ratio_priority, -1e9)\n\n    # Gap priority with dynamic almost-full penalty and relative gap\n    avg_cap = np.mean(bins_remain_cap)\n    almost_full_penalty = np.exp(-50 * gap / (avg_cap + 1e-9))\n    almost_full_penalty = np.where(feasible, almost_full_penalty, 0)\n    relative_gap = gap / (bins_remain_cap + 1e-9) # Normalize gap by bin capacity\n    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty + relative_gap , -1e9)\n\n    # Capacity priority (normalized remaining capacity)\n    max_cap = np.max(bins_remain_cap)\n    capacity_priority = bins_remain_cap / (max_cap + 1e-9)\n    capacity_priority = np.where(feasible, capacity_priority, -1e9)\n\n    # Bin usage priority (Prioritize bins closer to full but still feasible.)\n    bin_usage_priority = (max_cap - bins_remain_cap) / (max_cap + 1e-9) # Normalize used capacity\n    bin_usage_priority = np.where(feasible, bin_usage_priority, -1e9)\n\n    # Adaptive weights based on item size and avg bin capacity\n    item_size_factor = min(1.0, item)\n    capacity_factor = min(1.0, avg_cap / (max_cap + 1e-9)) # Adjust sensitivity based on bin utilization\n\n    # Combined priority calculation with dynamic weights\n    combined_priority = (\n        0.25 * ratio_priority +\n        0.45 * gap_priority +\n        0.15 * capacity_priority +\n        0.15 * bin_usage_priority\n    )\n\n    return combined_priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines ratio, gap, capacity, dynamic penalty, and adaptive weights.\"\"\"\n\n    # Handle zero capacities to prevent division by zero\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap, penalize infeasible bins\n    gap = bins_remain_cap - item\n    feasible = gap >= 0\n    gap = np.where(feasible, gap, -1)\n\n    # Ratio priority (item size / bin capacity)\n    ratios = item / bins_remain_cap\n    ratio_priority = -np.log(ratios)\n    ratio_priority = np.where(feasible, ratio_priority, -1e9)\n\n    # Gap priority with dynamic almost-full penalty\n    avg_cap = np.mean(bins_remain_cap)\n    almost_full_penalty = np.exp(-50 * gap / (avg_cap + 1e-9))\n    almost_full_penalty = np.where(feasible, almost_full_penalty, 0)\n    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9)\n\n    # Capacity priority (normalized remaining capacity)\n    capacity_priority = bins_remain_cap / (np.max(bins_remain_cap) + 1e-9)\n    capacity_priority = np.where(feasible, capacity_priority, -1e9)\n\n    # Adaptive weights based on item size\n    item_size_factor = min(1.0, item)\n    \n    # Combined priority calculation\n    combined_priority = (\n        0.3 * ratio_priority +\n        0.5 * gap_priority +\n        0.2 * capacity_priority\n    )\n\n    return combined_priority\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic combines ratio, gap, capacity, dynamic penalty, bin usage, and adaptive weights, while the worst only considers the ratio between item size and remaining bin capacity. (2nd) is identical to (1st). Comparing (1st) vs (6th), the 1st includes bin usage and adaptive weights based on item size and average bin capacity, while the 6th lacks bin usage and uses adaptive weights based only on item size. Comparing (6th) vs (17th), 6th includes gap, capacity, and dynamic penalty, while the 17th only considers ratio. Comparing (14th) vs (17th), we see that (14th) uses both ratio-based and gravity-inspired approaches, while (17th) is purely ratio-based. Comparing (15th) vs (14th), (15th) introduces tunable parameters and penalties. Comparing (11th) vs (14th), (11th) includes feasibility checks, comprehensive priorities (ratio, gap, capacity, fill level), and handles edge cases, while (14th) simplifies to ratio and gravity. The handling of infeasible bins and the diversity/balancing term are also unique to the higher-ranked heuristics. Overall: More sophisticated heuristics consider multiple factors like ratio, gap, capacity, bin usage, and dynamically adjust weights and penalties, and carefully handles edge cases such as infeasibility. Simpler heuristics only focus on a single factor like ratio or a limited combination of factors. Introducing tunable parameters does not guarantee better performance.\n- \nOkay, let's refine \"Current Self-Reflection\" to maximize its usefulness in heuristic design. We'll focus on actionable advice and avoid vague suggestions.\n\n*   **Keywords:** Factor Combination, Normalization, Dynamic Penalties, Adaptive Weights, Edge Case Handling, Problem State, Multi-Factor.\n\n*   **Advice:** Prioritize combining multiple *normalized* factors, and adjust their relative importance (weights/penalties) *dynamically* based on the current problem state to reflect its context and needs.\n\n*   **Avoid:** Relying on single factor, static approaches, unscaled values, or ignoring edge cases/infeasibility. Avoid vague, domain-specific suggestions.\n\n*   **Explanation:** Combining normalized factors allows a more holistic view. Dynamic penalties and adaptive weights enable the heuristic to react intelligently to the search space and problem features by emphasizing the most critical factor at a given moment.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}