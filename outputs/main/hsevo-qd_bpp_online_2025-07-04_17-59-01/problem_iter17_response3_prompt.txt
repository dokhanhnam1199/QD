{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A priority function for the online bin packing problem that combines ratio,\n    gap, capacity, dynamic penalty, and adaptive weights, with improved\n    handling of edge cases and state awareness.\n    \"\"\"\n\n    # Small constant to avoid division by zero and other numerical issues\n    epsilon = 1e-9\n\n    # 1. Feasibility check and basic preprocessing\n    feasible = bins_remain_cap >= item\n    num_feasible = np.sum(feasible)\n    \n    # If no bin is feasible, return a low priority for all bins, prioritizing the least full one\n    if num_feasible == 0:\n        return -bins_remain_cap  # Prioritize bins with more remaining capacity\n\n    # 2. Ratio priority (item size / bin capacity), only for feasible bins\n    ratios = item / np.where(bins_remain_cap <= 0, epsilon, bins_remain_cap)\n    ratio_priority = -np.log(ratios)\n    ratio_priority = np.where(feasible, ratio_priority, -1e9)\n\n    # 3. Gap priority with dynamic almost-full penalty and scaled gap\n    gap = bins_remain_cap - item\n    gap = np.where(feasible, gap, -1)\n\n    # Dynamic almost-full penalty, scaled by the item size and the number of feasible bins\n    avg_cap = np.mean(bins_remain_cap[feasible]) if num_feasible > 0 else np.mean(bins_remain_cap) # Only consider feasible bins for average cap\n    almost_full_penalty = np.exp(-50 * gap / (avg_cap + epsilon))\n    almost_full_penalty = np.where(feasible, almost_full_penalty, 0)\n    gap_priority = np.where(feasible, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9)\n\n    # 4. Capacity priority (normalized remaining capacity), only for feasible bins\n    max_cap = np.max(bins_remain_cap[feasible]) if num_feasible > 0 else np.max(bins_remain_cap) # Max capacity only among feasible bins\n    capacity_priority = bins_remain_cap / (max_cap + epsilon)\n    capacity_priority = np.where(feasible, capacity_priority, -1e9)\n\n    # 5. Introduce a \"balancing\" term to encourage more even bin utilization\n    #   This is a state-aware component to avoid filling one bin completely\n    #   before others have had a chance to be used.\n    fill_level = 1.0 - (bins_remain_cap / (np.max(bins_remain_cap) + epsilon))  # Fill level of each bin (0 to 1)\n    fill_level_priority = -fill_level # Prefer bins with lower fill levels\n\n    fill_level_priority = np.where(feasible, fill_level_priority, -1e9)\n\n    # 6. Adaptive weights based on item size and bin diversity\n    item_size_factor = min(1.0, item)\n    \n    # Standard deviation of remaining capacities. Higher std means more diverse bins\n    bin_diversity = np.std(bins_remain_cap)\n    diversity_factor = min(1.0, bin_diversity) # Normalize std\n\n    # 7. Combined priority calculation with more emphasis on gap\n    combined_priority = (\n        0.15 * ratio_priority +\n        0.55 * gap_priority +\n        0.15 * capacity_priority +\n        0.15 * fill_level_priority\n    )\n    \n    return combined_priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n       This version considers a combination of factors:\n       - Remaining capacity after placing the item (gap).\n       - Bin capacity.\n       - A penalty for bins that are almost full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Ensure no division by zero\n    bins_remain_cap = np.where(bins_remain_cap == 0, 1e-9, bins_remain_cap)\n\n    # Calculate gap (remaining capacity after placing the item)\n    gap = bins_remain_cap - item\n    # bins where gap < 0 are not feasible: assign a very small priority.\n    gap = np.where(gap < 0, -1, gap)\n    \n    # Calculate a penalty for bins that will be almost full after placing the item\n    almost_full_penalty = np.exp(-50 * gap)  # Exponential penalty, sharp drop-off as gap -> 0\n    almost_full_penalty = np.where(gap >= 0, almost_full_penalty, 0) # only applies to feasible bins\n\n    # Calculate priority score.  Combine bin capacity, gap, and the almost full penalty.\n    priorities = np.where(gap >= 0, (bins_remain_cap / (gap + 0.0001)) - almost_full_penalty, -1e9) # Added constant to prevent possible 0 division.\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic combines ratio, gap, and capacity with dynamic penalty and normalization, while the worst only considers the ratio of item size to bin capacity. (2nd best) vs (second worst) reveals that the (2nd best) incorporates best-fit and adjusts weights based on bin fill level, features absent in (second worst). Comparing (1st) vs (2nd), we see the second best heuristics incorporates Best-fit priority and adjusts weights based on bin fill level. Comparing (3rd) vs (4th), show that the 3rd heuristics also incorporates Best-fit priority and adjusts weights based on bin fill level. Comparing (second worst) vs (worst), we see that the second worst calculates \"Gravitational\" attraction with added constant. Overall: The better heuristics consider multiple factors (ratio, gap, capacity, fill level) and use adaptive weights to dynamically adjust the importance of each factor. Handling of edge cases (division by zero, infeasible bins) with `np.where` is crucial. Normalization is also important.\n- \nHere's a redefinition of \"Current Self-Reflection\" tailored for designing effective heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection\":\n\n*   **Keywords:** Multi-factor, normalization, adaptive weights, state-awareness, edge-case handling, robustness, dynamic penalties.\n\n*   **Advice:** Prioritize heuristics that combine multiple normalized, relevant factors with adaptive weights determined by the current problem state. Explicitly address edge cases and infeasible solution handling.\n\n*   **Avoid:** Relying on single-factor metrics, solely domain-specific analogies without quantitative justification.\n\n*   **Explanation:** Combines multiple relevant factors, normalizes inputs, and uses dynamic penalties to handle edge cases. Adaptive weighting can further improve performance by emphasizing different factors based on the problem's state. Edge case handling and normalization are essential for numerical stability and performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}