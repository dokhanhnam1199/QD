```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # First Fit Decreasing heuristic-inspired component: prefer bins with enough space
    eligible_bins = bins_remain_cap >= item
    priorities[eligible_bins] += 1.0  # Give a base priority to eligible bins

    # Best Fit heuristic-inspired component: prioritize bins with minimum wasted space
    waste = bins_remain_cap - item
    waste[waste < 0] = np.inf  # Ignore bins where item doesn't fit.
    min_waste = np.min(waste)
    best_fit_bins = np.isclose(waste, min_waste)
    priorities[best_fit_bins] += 2.0  # Give high priority to bins with minimal waste

    # Capacity Utilization heuristic-inspired: Prefer using bins that are almost full, but not too full (avoid very small remaining capacity)
    capacity_utilization = item / bins_remain_cap
    capacity_utilization[~eligible_bins] = 0  # Ignore ineligible bins
    priorities += capacity_utilization

    # Add a penalty for bins that will have very small remaining capacity after placing the item
    nearly_full_penalty = np.zeros_like(bins_remain_cap, dtype=float)
    nearly_full_bins = (bins_remain_cap - item) <= 0.1
    nearly_full_penalty[nearly_full_bins & eligible_bins] = -0.5  # Slightly reduce priority

    priorities += nearly_full_penalty

    # Never pick a bin that's already full.
    priorities[bins_remain_cap == 0] = -np.inf

    # Prioritize bins that have already had items placed in them, without overfilling.
    already_used_bins = (bins_remain_cap < 1) & eligible_bins  # Assume bin capacity is 1. Bins less than 1 but eligible.
    priorities[already_used_bins] += 0.75

    # Introduce a small bias towards bins with larger remaining capacity if multiple bins have similar scores, preventing excessive fragmentation
    # Scale remaining capacity to a reasonable range to avoid dominating other heuristics.
    scaled_remaining_capacity = bins_remain_cap / np.max(bins_remain_cap, initial=1)
    priorities += 0.1 * scaled_remaining_capacity

    #Refine best fit: give slight boost to bins closer to item size (but still large enough)
    proximity_score = np.zeros_like(bins_remain_cap, dtype=float)
    proximity = bins_remain_cap - item
    proximity[proximity<0] = 0 #Only consider bins large enough.

    #Apply the boost in priority, with smaller proximity giving higher boost

    proximity_score[eligible_bins] = np.exp(-5 * proximity[eligible_bins]) #Exponential decay rewards bins close to item size.
    priorities += 0.5*proximity_score

    return priorities
```
