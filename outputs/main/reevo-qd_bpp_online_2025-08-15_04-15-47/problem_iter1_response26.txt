```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Sigmoid Fit Score.

    The Sigmoid Fit Score prioritizes bins that are a "good fit" for the item.
    A "good fit" is defined by a sigmoid function applied to the ratio of
    item size to remaining bin capacity. Bins that are almost full or
    almost empty relative to the item size receive lower scores. Bins
    where the item size is a significant fraction of the remaining capacity
    receive higher scores.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Avoid division by zero or very small numbers for capacities
    # Consider bins with capacity >= item size only
    valid_bins_mask = bins_remain_cap >= item
    
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Calculate the ratio of item size to remaining capacity for valid bins
    # This ratio indicates how much of the remaining space the item would occupy.
    # A ratio closer to 1 (but not exceeding it) indicates a better fit.
    ratios = np.where(valid_bins_mask, item / bins_remain_cap, 0)

    # Apply a sigmoid-like transformation. We want to favor ratios that are
    # close to, but not exceeding, 1. A standard sigmoid (1 / (1 + exp(-x)))
    # squashes values to (0, 1). We can shift and scale it to our needs.
    # Let's use a scaled and shifted sigmoid: 1 / (1 + exp(-k * (x - c)))
    # where k controls the steepness and c controls the center.
    # We want the peak around x=1. Let's use k=10 and c=0.8 to emphasize
    # fits where the item takes up at least 80% of the remaining capacity,
    # with diminishing returns as it gets closer to 100%.
    # The factor 2 is to stretch the output range to [-1, 1] if we used c=0
    # and then shift and scale. A simpler approach for our purpose is to focus
    # on the "gap" left. If the gap (bins_remain_cap - item) is small, it's a good fit.
    # Let's directly penalize large remaining gaps.

    # A more intuitive approach for "good fit" in BPP: prioritize bins
    # where the remaining capacity is just enough or slightly more than the item.
    # The 'waste' when placing the item should be minimized.
    # waste = bins_remain_cap - item
    # We want to minimize waste, but also consider that very small remaining capacity
    # might be restrictive for future items.

    # Let's try a score that is high when (bins_remain_cap - item) is small,
    # but not negative, and also not excessively large.
    # This can be achieved by a function that peaks at waste = 0.
    # A negative exponential or a reversed parabola shape might work.

    # Sigmoid Fit Score: Prioritize bins where the remaining capacity is
    # just sufficient for the item. The "fit score" could be thought of
    # as how well the item "completes" the bin.

    # Consider the remaining capacity relative to the *item size*.
    # A bin with capacity 10 and item size 8 has a ratio of 0.8.
    # A bin with capacity 5 and item size 4 has a ratio of 0.8.
    # We want to give a higher score to ratios closer to 1.

    # Let's define a scoring function `f(r)` where `r = item / bins_remain_cap`.
    # We want `f(r)` to be high for `r` close to 1 (but `r <= 1`).
    # A sigmoid can do this.
    # `sigmoid(x) = 1 / (1 + exp(-x))`
    # Let's map `r` to `x`. If `r=1`, `x` should be large positive. If `r=0`, `x` should be negative.
    # A simple mapping could be `x = a * (r - b)`.
    # If `r=1`, `x = a * (1 - b)`. We want this to be large.
    # If `r=0`, `x = a * (-b)`. We want this to be small (negative).

    # Let's consider the inverse: ratio of remaining capacity to item size.
    # `ratio_inv = bins_remain_cap / item`
    # For valid bins, this ratio is >= 1. We want this ratio to be close to 1.
    # Let's call this `fit_ratio`.
    fit_ratios = np.where(valid_bins_mask, bins_remain_cap / item, 0)

    # Now, we want a function `g(fit_ratio)` that is high when `fit_ratio` is close to 1.
    # A Gaussian-like function centered at 1 could work.
    # Or a transformed sigmoid: if `x = 1 - fit_ratio`, we want high scores for small `x`.
    # `sigmoid(-k * x)` where `k > 0` gives high scores for small `x`.
    # `sigmoid(-k * (1 - fit_ratio))` = `sigmoid(k * (fit_ratio - 1))`
    # Let's use k=10 (steepness).
    # For fit_ratio = 1, sigmoid(0) = 0.5.
    # For fit_ratio = 1.1 (remaining cap is 10% more than item), sigmoid(1) = 0.73.
    # For fit_ratio = 0.9 (this case is excluded by valid_bins_mask), it would be sigmoid(-1) = 0.27.
    # For fit_ratio = 2.0, sigmoid(10) is close to 1. This is not ideal. We don't want bins with massive excess capacity to be top priority.

    # Let's refine the sigmoid. We want to penalize bins that are too large.
    # So, a high score when `bins_remain_cap - item` is small and positive.
    # Let `gap = bins_remain_cap - item`. We want `gap` to be close to 0.
    # Let's transform `gap`.
    # For valid bins: `gaps = bins_remain_cap - item`
    gaps = np.where(valid_bins_mask, bins_remain_cap - item, np.inf) # Penalize invalid bins

    # Now we want a function that is high for `gaps` close to 0.
    # Let's use a sigmoid on the negative gap, shifted and scaled.
    # `sigmoid(k * (c - gap))`
    # Choose `k` for steepness, `c` for center.
    # We want peak at `gap = 0`. So, `c=0`.
    # `sigmoid(k * (-gap))` = `1 / (1 + exp(k * gap))`
    # For `gap = 0`, score = 0.5.
    # For `gap = small_positive` (e.g., 0.1), score = `1 / (1 + exp(0.1k))`. If k=10, exp(1) = 2.7, score = 1/3.7 = 0.27. This is lower than 0.5. We want higher.

    # Let's use `sigmoid(-k * gap)` for `gap > 0` and assign 0 otherwise.
    # If `gap` is small and positive, `-k * gap` is small and negative. Sigmoid will be < 0.5.
    # We need the sigmoid to peak at gap=0.

    # Let's rethink the input to sigmoid.
    # Consider `x = item / bins_remain_cap`. We want `x` close to 1.
    # `sigmoid(k * (x - c))`.
    # Let `k = 5`, `c = 0.8`.
    # If `r = 0.8`, `x = 5 * (0.8 - 0.8) = 0`. Sigmoid(0) = 0.5.
    # If `r = 0.9`, `x = 5 * (0.9 - 0.8) = 0.5`. Sigmoid(0.5) = 0.62.
    # If `r = 0.95`, `x = 5 * (0.95 - 0.8) = 0.75`. Sigmoid(0.75) = 0.68.
    # If `r = 1.0`, `x = 5 * (1.0 - 0.8) = 1.0`. Sigmoid(1.0) = 0.73.
    # If `r = 0.7`, `x = 5 * (0.7 - 0.8) = -0.5`. Sigmoid(-0.5) = 0.38.
    # If `r = 0.5`, `x = 5 * (0.5 - 0.8) = -1.5`. Sigmoid(-1.5) = 0.18.

    # This function prioritizes bins where the item takes up a good chunk of remaining capacity,
    # favoring ratios closer to 1. It penalizes bins where the item is too small for the remaining capacity.

    # Parameters for the sigmoid function:
    # `k`: Controls the steepness of the sigmoid curve. Higher k means a sharper transition.
    # `c`: The center of the sigmoid curve. We want the peak around `item / remaining_cap = 1`.
    # Let's set `c` slightly below 1 to prioritize bins that are not *exactly* full,
    # but have some residual space. For example, if `c=0.9`, bins where `item/cap >= 0.9` get higher scores.
    # If we want bins that are *almost* full, `c` should be close to 1. Let's use `c=0.95`.
    # If we want bins where the item fits reasonably well, `c` could be lower.
    # Let's make `c` a parameter that depends on the item size relative to bin size,
    # or simply set a fixed heuristic value.

    # Let's use `k=10` and `c=0.9` as a starting point.
    k = 10.0
    c = 0.90

    # Calculate `x = k * (item / bins_remain_cap - c)` for valid bins
    # Where bins_remain_cap is sufficient for the item.
    # For bins where item > bins_remain_cap, the ratio is effectively infinity,
    # leading to very small sigmoid values (close to 0).
    
    # Handle the case where bins_remain_cap is 0 or very small leading to division by zero.
    # We've already filtered for bins_remain_cap >= item, so this is less of an issue
    # unless item itself is 0 or very small.
    
    # Calculate ratios where valid:
    ratios = np.zeros_like(bins_remain_cap, dtype=float)
    valid_mask = bins_remain_cap >= item
    ratios[valid_mask] = item / bins_remain_cap[valid_mask]

    # Calculate the sigmoid input:
    sigmoid_input = k * (ratios - c)

    # Apply the sigmoid function:
    # `priorities = 1 / (1 + np.exp(-sigmoid_input))`
    # This function gives values between 0 and 1.
    # High priority for ratios closer to `c` and then increasing towards 1.
    # Ratios significantly below `c` get low scores.
    # Ratios above `c` (but <= 1) get higher scores.
    # For ratios > 1, sigmoid_input is large positive, sigmoid value is close to 1.
    # We need to cap this or handle it.

    # Let's redefine. Prioritize bins with minimal remaining capacity *after* placing the item,
    # provided that capacity is non-negative.
    # remaining_after_item = bins_remain_cap - item
    # We want to maximize `1 / (1 + remaining_after_item)` if `remaining_after_item >= 0`.
    # This penalizes large remaining capacities.
    
    # Let's use a modified sigmoid that focuses on the 'waste' or 'gap'.
    # `score = sigmoid(k * (c - gap))` where `gap = bins_remain_cap - item`.
    # `k > 0`, `c > 0`. Peak at `gap = c`.
    # We want peak at `gap = 0`. So, `sigmoid(k * (0 - gap)) = sigmoid(-k * gap)`.
    # This gives high scores for negative gaps (invalid). We want high for `gap = 0`.
    
    # Let's consider the "tightness" of the fit.
    # A bin is "tightly fitting" if `bins_remain_cap - item` is small.
    # Let `tightness = 1 / (1 + bins_remain_cap - item)`.
    # This is high when `bins_remain_cap - item` is small.
    # But this doesn't penalize bins that are too large for the item.

    # Final approach: Sigmoid on the ratio `item / bins_remain_cap`.
    # We want scores to be high when this ratio is close to 1.
    # Use a sigmoid shifted and scaled.
    # `score = sigmoid(a * (ratio - b))`
    # `ratio = item / bins_remain_cap`
    # If `ratio = 1`, score should be high.
    # If `ratio < 1`, score should still be relatively high if `ratio` is close to 1.
    # If `ratio` is much less than 1, score should be low.
    # If `ratio > 1`, this bin is invalid, score should be 0.

    scores = np.zeros_like(bins_remain_cap, dtype=float)
    
    # Consider only bins where item can fit
    can_fit_mask = bins_remain_cap >= item
    
    # For bins that can fit the item:
    # Calculate the "fit quality". We want the remaining capacity to be as close to zero as possible
    # *after* placing the item.
    # Let `remaining_space_after = bins_remain_cap[can_fit_mask] - item`
    # We want to prioritize bins where `remaining_space_after` is small.
    # Use a sigmoid function that maps small positive `remaining_space_after` to high values.
    
    # Let's try a score based on `1 - (remaining_space_after / bin_capacity)`
    # This is related to `1 - waste / capacity`
    
    # A good heuristic is to prioritize bins that are nearly full but can still accommodate the item.
    # This is often called the "Best Fit" strategy.
    # The Sigmoid Fit Score aims to formalize this "best fit" intuition.
    
    # Let's define the score as: `sigmoid(k * ( (bin_capacity - item) - (bin_capacity_avg - item_avg) ))`
    # This is getting complicated. Let's stick to a simpler, more direct sigmoid application.

    # The core idea: Score should be high when `item` is close to `bins_remain_cap`.
    # Let `x = bins_remain_cap / item`. We want `x` close to 1.
    # `score = sigmoid(k * (1 - x))` for `x >= 1`.
    # `x` here is `bins_remain_cap / item`.
    
    x_vals = np.zeros_like(bins_remain_cap, dtype=float)
    valid_mask_for_x = bins_remain_cap >= item
    
    # Avoid division by zero if item is 0, though unlikely for BPP
    if item > 0:
        x_vals[valid_mask_for_x] = bins_remain_cap[valid_mask_for_x] / item
    else: # If item size is 0, any bin works, priority could be uniform or based on capacity
        x_vals[valid_mask_for_x] = 1.0 # Treat as a perfect fit for 0-size items

    # Now, `x_vals` contains `bins_remain_cap / item` for valid bins.
    # We want scores to be high when `x_vals` is close to 1.
    # `sigmoid(k * (1 - x_vals))`
    # If `x_vals = 1`, score = sigmoid(0) = 0.5.
    # If `x_vals = 1.1` (remaining cap is 10% more than item), score = sigmoid(-0.1) = 0.47.
    # If `x_vals = 2.0` (remaining cap is twice the item), score = sigmoid(-1) = 0.27.
    # This prioritizes bins that are closer to `item` size, and penalizes larger bins.
    # This aligns with a "Best Fit" like strategy.
    
    # Let's use `k=5` to make it a bit smoother.
    k_sigmoid = 5.0
    
    scores = 1 / (1 + np.exp(k_sigmoid * (x_vals - 1)))

    # The scores range from 0 to 1.
    # Values where `bins_remain_cap < item` will have `x_vals = 0`,
    # leading to `1 / (1 + exp(k * (-1)))` which is ~0.27 for k=5.
    # We want these invalid bins to have a score of 0.

    final_priorities = np.zeros_like(bins_remain_cap, dtype=float)
    final_priorities[valid_mask_for_x] = scores[valid_mask_for_x]

    return final_priorities

```
