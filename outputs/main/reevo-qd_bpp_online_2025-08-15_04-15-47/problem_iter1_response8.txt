```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Epsilon-Greedy.

    The strategy aims to balance exploration (trying less-filled bins) and exploitation
    (placing items in bins where they fit best).

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    epsilon = 0.2  # Probability of exploration
    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    suitable_bins_mask = bins_remain_cap >= item

    if not np.any(suitable_bins_mask):
        # No bin can fit the item, return all zeros (or handle as an error/special case)
        return priorities

    # Exploitation: Prioritize bins that leave minimal remaining space after packing
    # This is a greedy choice aiming to fill bins efficiently.
    # We want to minimize the remaining capacity after placing the item,
    # so a smaller (bins_remain_cap - item) is better.
    # We can represent this as a negative value to use max on priorities.
    # However, for simplicity and to avoid potential issues with zero remaining capacity,
    # let's consider the *percentage* of remaining capacity or simply the
    # *remaining capacity itself* after placing the item.
    # The goal is to get 'closer' to zero remaining capacity without overshooting.
    # A simple heuristic is to maximize the (bins_remain_cap - item).
    # However, a more effective heuristic for minimizing bins is often to pick the
    # bin that results in the *least* remaining capacity, which is equivalent to
    # maximizing (bins_remain_cap - item). This is the "Best Fit" strategy.

    # Let's adapt this to be more "epsilon-greedy"
    # We'll have a "greedy" part and an "exploratory" part.

    # Greedy part: Calculate the benefit of placing the item in each suitable bin.
    # A good greedy metric could be the remaining capacity after placing the item.
    # We want to minimize this, so we can score it as the negative of this value,
    # or more simply, consider the "tightness" of the fit.
    # The tighter the fit (less remaining capacity), the higher the priority.
    # Let's use (bins_remain_cap - item) and normalize/invert it.
    # A common approach is to use a value inversely proportional to remaining capacity
    # or directly proportional to the fill percentage.
    # For Best Fit, we want to maximize (bins_remain_cap - item).
    # Let's use a metric that is higher for bins that are nearly full but still fit.
    # A simple greedy score could be related to (bin_capacity - item_size) / bin_capacity,
    # or just prioritize bins that are "closest" to fitting the item without being too full.
    # The "best fit" strategy aims to leave the *least* remaining space.
    # So, a higher priority should go to bins where `bins_remain_cap - item` is smallest.
    # We can achieve this by maximizing `-(bins_remain_cap - item)` which is `item - bins_remain_cap`.
    # Or, for simplicity, we can just directly maximize `bins_remain_cap - item` and
    # handle the selection from there.

    # Let's define the greedy scores for suitable bins.
    # A good "best fit" score would be how much space is left after placing the item.
    # We want to MINIMIZE this remaining space.
    # So, a HIGHER priority should correspond to SMALLER `bins_remain_cap - item`.
    # Let's create scores that are higher for better fits.
    # We can do `-(bins_remain_cap[suitable_bins_mask] - item)`
    # Or, perhaps more intuitively, a higher priority for bins with capacity *just enough* for the item.
    # Let's consider `bins_remain_cap[suitable_bins_mask] - item`. We want to MINIMIZE this.
    # So, we can invert it or use it as a negative score.
    # A robust way is to use `1 / (1 + (bins_remain_cap[suitable_bins_mask] - item))` for minimization.
    # Or simply, we want to pick the smallest positive value of `bins_remain_cap - item`.
    # Let's consider the "fitness" as `bins_remain_cap[suitable_bins_mask] - item`.
    # We want to pick the smallest positive value.
    # So, let's define scores as: `scores = -(bins_remain_cap[suitable_bins_mask] - item)` which means higher score for smaller remaining space.

    greedy_scores = -(bins_remain_cap[suitable_bins_mask] - item)
    priorities[suitable_bins_mask] = greedy_scores

    # Exploration part: With probability epsilon, choose a random suitable bin.
    if np.random.rand() < epsilon:
        # Pick a random suitable bin and assign it a very high priority,
        # or simply override the greedy scores.
        # Let's add a random exploration bonus to a random suitable bin.
        random_suitable_bin_index = np.random.choice(np.where(suitable_bins_mask)[0])
        # Add a positive boost to this randomly selected bin.
        # The magnitude of the boost can be arbitrary, as long as it's positive
        # and potentially enough to make it stand out.
        # Or, we can simply assign a high constant priority.
        # Let's make the priority for the randomly chosen bin higher than any possible greedy score.
        # Max possible greedy score is `item - min_positive_remaining_capacity`.
        # A simple way: give a random boost.
        priorities[suitable_bins_mask] += np.random.uniform(0, 1) # Add a small random value to all, then boost one further?
                                                                 # Or, more directly, assign a random priority.

        # Let's assign random priorities to all suitable bins and then pick one randomly.
        # Or, simpler: choose one random suitable bin and give it a high priority,
        # then the rest of the suitable bins have their greedy priority.
        # This means the random choice will likely win.

        # A more common epsilon-greedy implementation for selection:
        # 1. Calculate greedy scores.
        # 2. With probability epsilon, pick a random *suitable* bin.
        # 3. With probability 1-epsilon, pick the *best* suitable bin based on greedy scores.

        # Let's implement that logic directly for *selection*, not for generating priorities array.
        # The function is supposed to RETURN priorities, from which a selection will be made.
        # So, we need to modify the `priorities` array itself.

        # Option 1: Add random noise to all suitable bins, ensuring some randomness in selection.
        # priorities[suitable_bins_mask] += np.random.normal(0, 0.1, size=np.sum(suitable_bins_mask))

        # Option 2: Assign random priorities to a fraction of suitable bins.
        num_exploratory_bins = int(epsilon * np.sum(suitable_bins_mask))
        if num_exploratory_bins > 0:
            exploratory_indices = np.random.choice(np.where(suitable_bins_mask)[0], size=num_exploratory_bins, replace=False)
            # Assign random priorities to these bins. These could be higher or lower than greedy.
            # To ensure exploration, let's assign them *lower* priorities so that a random choice might pick them
            # if they also have a decent greedy score, or higher priorities if we want to force exploration.
            # For epsilon-greedy for *selection*, we mean pick a random bin *instead* of the best.
            # So, to simulate that in the priority list: make the chosen random bins have artificially high priority.
            priorities[exploratory_indices] = np.random.uniform(np.max(priorities[suitable_bins_mask]) + 1,
                                                              np.max(priorities[suitable_bins_mask]) + 10,
                                                              size=num_exploratory_bins)


    # Normalize priorities so that higher value means higher priority
    # This isn't strictly necessary if the selection logic just picks the max,
    # but can be useful for other selection methods.
    # Let's ensure all suitable bins have positive priorities, and unsuitable ones are zero.
    priorities[~suitable_bins_mask] = -np.inf # Make sure unsuitable bins are never chosen

    # The greedy scores were set up such that higher means better (less remaining space).
    # Exploration part is tricky when modifying the whole priority array.
    # If the goal is to modify the priority array to reflect an epsilon-greedy choice strategy:
    # With prob epsilon, select a random suitable bin, give it highest priority.
    # With prob 1-epsilon, select best greedy bin, give it highest priority.

    # Let's re-approach: The output IS the priority array. The selection mechanism will pick from this.
    # If we want to influence the selection via priorities:
    # For suitable bins:
    #   With prob epsilon: assign a "random" high priority (to encourage selection)
    #   With prob 1-epsilon: assign the "greedy" priority

    # This approach is more direct in modifying the priority list itself to reflect the strategy.
    final_priorities = np.zeros_like(bins_remain_cap, dtype=float)
    final_priorities[~suitable_bins_mask] = -np.inf # Unsuitable bins have no chance

    if np.any(suitable_bins_mask):
        suitable_indices = np.where(suitable_bins_mask)[0]
        num_suitable = len(suitable_indices)

        # Calculate greedy priorities for all suitable bins
        greedy_values = -(bins_remain_cap[suitable_bins_mask] - item)
        # Convert to probabilities or direct priorities. Let's assume higher is better.

        # Determine how many bins will get an "exploratory" boost
        num_exploratory_bins = int(np.ceil(epsilon * num_suitable)) # Using ceil to ensure at least one if epsilon is small but num_suitable > 0

        # Identify which bins will be "randomly" chosen for exploration
        exploratory_indices_in_suitable = np.random.choice(num_suitable, size=min(num_exploratory_bins, num_suitable), replace=False)
        exploratory_absolute_indices = suitable_indices[exploratory_indices_in_suitable]

        # Assign "high random" priorities to exploratory bins
        max_greedy_value = np.max(greedy_values) if num_suitable > 0 else 0
        exploration_priority_boost = np.random.uniform(max_greedy_value + 1, max_greedy_value + 10, size=len(exploratory_absolute_indices))
        final_priorities[exploratory_absolute_indices] = exploration_priority_boost

        # Assign greedy priorities to the rest of the suitable bins
        non_exploratory_suitable_indices = np.setdiff1d(suitable_indices, exploratory_absolute_indices)

        if len(non_exploratory_suitable_indices) > 0:
            greedy_values_for_non_exploratory = -(bins_remain_cap[non_exploratory_suitable_indices] - item)
            final_priorities[non_exploratory_suitable_indices] = greedy_values_for_non_exploratory

    # Ensure that if epsilon is 0 or 1, or if num_suitable is 0, it behaves correctly.
    # If epsilon is 0, all suitable bins get greedy priorities.
    # If epsilon is 1, all suitable bins get random high priorities.
    # If num_suitable is 0, all are -inf.

    return final_priorities

```
