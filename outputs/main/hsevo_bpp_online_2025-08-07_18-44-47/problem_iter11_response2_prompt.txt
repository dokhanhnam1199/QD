{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n_rng = np.random.default_rng(42)\n\n    \"\"\"Score bins: inverse leftover, deterministic index bias, and tiny jitter.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-9\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    # Inverse leftover capacity favors tighter fits\n    priority[feasible] = 1.0 / (remaining[feasible] + eps)\n    # Deterministic tie\u2011breaker: prefer lower indices\n    priority[feasible] += -np.arange(n)[feasible] * 1e-5\n    # Reproduc: tiny jitter scaled by item size for residual ties\n    jitter = _rng.random(n) * 0.01 * item\n    priority[feasible] += jitter[feasible]\n    return priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    item: float,\n    bins_remain_cap: np.ndarray,\n    epsilon: float = 0.0008901746596746403,\n    index_weight: float = 0.000698131900325939,\n    jitter_factor: float = 0.0088999467674249,\n    rng_seed: int = 710.3559746240198,\n) -> np.ndarray:\n    \"\"\"Score bins based on inverse leftover capacity, deterministic index bias, and jitter.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to be placed.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of bins.\n    epsilon : float, optional\n        Small constant to avoid division by zero.\n    index_weight : float, optional\n        Weight applied to the deterministic index bias (lower index = higher priority).\n    jitter_factor : float, optional\n        Scaling factor for the random jitter term.\n    rng_seed : int, optional\n        Seed for the internal random number generator.\n    \"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n\n### Analyze & experience\n- - **Best (1st) vs. Worst (20th)** \u2013 The 1st heuristic\u2019s docstring accurately describes its scoring: \u201cinverse leftover, deterministic index bias, and jitter.\u201d It implements this with a seeded RNG, an \u03b5\u2011guarded inverse\u2011leftover term, a negative index bias (\u20111e\u20115), a tiny positive offset (\u2011idx\u00b71e\u201112) for tie\u2011breaks, and reproducible jitter (0.01\u00b7item). It also handles empty inputs gracefully. The 20th heuristic, despite a similar docstring, contains no implementation beyond a size check, returning an empty array; it provides no scoring, no tie\u2011break, and no jitter, rendering it non\u2011functional.\n\n- **2nd vs. 2nd\u2011worst (19th)** \u2013 The 2nd heuristic mirrors the 1st but omits the tiny positive offset (\u2011idx\u00b71e\u201112). It still follows the docstring, uses the same seeded jitter, and respects feasibility. The 19th heuristic defines many parameters and a detailed docstring but never computes a priority; it exits after the size check, making it effectively \u201cdead code.\u201d  \n\n- **1st vs. 2nd** \u2013 Both use the same core formula (1/(remaining+\u03b5)) and identical jitter. The only difference lies in the extra positive offset in the 1st (`+ idx\u00b71e\u201112`). This micro\u2011offset can resolve rare ties where the index bias alone is insufficient, offering a marginally more deterministic ordering without affecting performance.\n\n- **3rd vs. 4th** \u2013 These two are essentially duplicates of the 1st. Their docstrings and comments match, and the code performs the same inverse\u2011leftover calculation, identical index bias, and jitter. Variable naming differs (`idx` vs. direct `np.arange`), but the functional behavior and deterministic properties are the same, illustrating redundancy rather than improvement.\n\n- **2nd\u2011worst (19th) vs. Worst (20th)** \u2013 Both are stubs. The 19th includes a richer signature and explanatory docstring, yet after the size guard it returns an empty array, providing no priority values. The 20th is even more minimal but equally non\u2011functional. Neither contributes to bin\u2011selection decisions, making them equally ineffective.\n\n- **Overall** \u2013 The top\u2011ranked heuristics consistently: clear docstrings that match the implementation, a primary inverse\u2011leftover score favoring tight fits, a deterministic low\u2011index bias for reproducible tie\u2011breaking, a tiny reproducible jitter scaled by item size, proper handling of empty inputs, and avoidance of unnecessary imports. Lower\u2011ranked versions either drop essential components (e.g., inverse scoring, jitter), introduce dead code, or add superfluous complexity, leading to poorer or undefined behavior.\n- \n- **Keywords** \u2013 Adaptive stochasticity, dynamic weighting, iterative refinement, feature\u2011rich candidate space.  \n- **Advice** \u2013 Employ a multi\u2011arm bandit for bin selection, calibrate jitter on residual capacity, allow controlled randomness, integrate heuristic history, use vectorized operations.  \n- **Avoid** \u2013 Fixed RNG seeds, minimal jitter, over\u2011simplified heuristics, limiting exploration without empirical evidence, strictly deterministic logic.  \n- **Explanation** \u2013 Dynamic randomness explores the space, calibrated jitter reduces bias, feedback loops accelerate convergence, a richer candidate set improves feasibility, vectorization keeps performance high.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}