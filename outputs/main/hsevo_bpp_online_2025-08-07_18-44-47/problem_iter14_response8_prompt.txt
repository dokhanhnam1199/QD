{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n_item_counter = 0\n\n    global _item_counter\n    _item_counter += 1\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    priority = np.full(n, -np.inf, dtype=float)\n    if n == 0:\n        return priority\n    remaining = bins - item\n    feasible = remaining >= 0\n    if not np.any(feasible):\n        return priority\n    eps = 1e-9\n    base_temp = 0.5\n    decay = 0.001\n    temp = max(0.05, base_temp * np.exp(-decay * _item_counter))\n    gumbel = -np.log(-np.log(np.random.rand(feasible.sum())))\n    priority[feasible] = -remaining[feasible] / temp + gumbel\n    priority[feasible] -= np.arange(n)[feasible] * 1e-6\n    jitter = np.random.rand(feasible.sum()) * (remaining[feasible] / (remaining[feasible].max() + eps)) * 0.01\n    priority[feasible] += jitter\n    return priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Scores bins by inverse remaining capacity, low-index bias, and jitter.\n    \"\"\"\n    rng = np.random.default_rng(42)  # deterministic jitter for reproducibility\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n\n    base = 1.0 / (remaining[feasible] + eps)          # inverse leftover\n    bias = np.arange(n)[feasible] * 1e-6                # low-index bias\n    jitter = rng.random(feasible.sum()) * 0.01 * item  # exploration jitter\n    idx_offset = np.arange(n)[feasible] * 1e-12        # tiny tie\u2011break\n\n    priority[feasible] = base - bias + jitter + idx_offset\n    return priority\n\n### Analyze & experience\n- - **Comparing (best) vs (worst):** The best heuristic (1st) returns a full priority vector using inverse leftover, a negative index bias, a reproducible random jitter, and an ultra\u2011small deterministic jitter, giving reproducible yet diversified tie\u2011breaking. The worst heuristic (20th) stops after size\u2011check and returns an empty array, providing no scoring at all.  \n- **Comparing (second best) vs (second worst):** The second best (2nd) still computes a well\u2011defined priority with inverse leftover, index bias, and reproducible jitter. The second worst (19th) defines many hyper\u2011parameters but never computes any priority, leaving the function effectively non\u2011functional.  \n- **Comparing (1st) vs (2nd):** The only difference is the extra deterministic jitter term in (1st), which supplies a stable, deterministic tie\u2011breaker without altering the main score, making (1st) marginally more robust.  \n- **Comparing (3rd) vs (4th):** (3rd) duplicates the top heuristic (identical to 1st). (4th) replaces the deterministic jitter with a sinusoidal term and reduces the index\u2011bias magnitude; the sinusoid adds negligible influence, yielding a slightly weaker tie\u2011break.  \n- **Comparing (second worst) vs (worst):** Heuristics (19th) and (20th) are essentially identical stubs that lack any priority computation; (19th) merely has a richer docstring, but both are equally ineffective.  \n- **Overall:** The ranking follows a clear gradient: heuristics that combine a solid primary score (inverse leftover) with deterministic tie\u2011breakers and bounded random jitter perform best, while those that omit the primary score or leave core logic unfinished perform worst.\n- \n- **Keywords:** capacity\u2011aware, adaptive stochastic tie\u2011breakers, dynamic jitter, vectorized scoring.  \n- **Advice:** use inverse\u2011leftover as primary score, add jitter proportional to item size, layer a deterministic tie\u2011breaker for reproducibility, and include early\u2011exit checks with fully vectorized operations.  \n- **Avoid:** fixed RNG seeds, static index bias, constant tiny jitter, unused imports, over\u2011parameterization, dead\u2011code, and any logic that remains deterministic\u2011only.  \n- **Explanation:** adaptive jitter balances exploration with item scale, stochastic tie\u2011breakers prevent systematic bias, deterministic fallbacks keep runs reproducible, and vectorized logic ensures high performance.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}