[
  {
    "stdout_filepath": "problem_iter23_response0.txt_stdout.txt",
    "code_path": "problem_iter23_code0.py",
    "code": "import numpy as np\n\n_item_avg = None\n_item_avg_count = 0\n\n# Adaptive jitter with variance penalty for online BPP\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid: negative leftover, variance penalty, index bias, and adaptive jitter.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    global _item_avg, _item_avg_count\n    if _item_avg is None:\n        _item_avg = item\n        _item_avg_count = 1\n    else:\n        _item_avg += (item - _item_avg) / (_item_avg_count + 1)\n        _item_avg_count += 1\n    feas_rem = remaining[feasible]\n    mean_rem = feas_rem.mean()\n    std_rem = feas_rem.std()\n    cv = std_rem / (mean_rem + 1e-12)\n    noise_sigma = item * np.exp(-cv)\n    factor = abs(item - _item_avg) / (_item_avg + 1e-12)\n    noise_sigma *= (1 + factor)\n    rng = np.random.default_rng()\n    jitter = rng.normal(0, noise_sigma, size=feasible.sum())\n    base = -feas_rem\n    var_penalty = -((feas_rem - mean_rem) ** 2) * 1e-4\n    idx_bias = np.arange(n)[feasible] * 1e-6\n    priority[feasible] = base + var_penalty + jitter + idx_bias\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 9.8923015556442,
    "SLOC": 30.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response1.txt_stdout.txt",
    "code_path": "problem_iter23_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive inverse leftover priority with variance\u2011scaled random jitter, golden\u2011ratio deterministic jitter, and index tie\u2011break.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins - item\n    feasible = remaining >= 0\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    idx = np.arange(n, dtype=float)\n    eps = 1e-12\n    primary = 1.0 / (remaining[feasible] + eps)\n    bias = -idx[feasible] * 1e-6\n    phi = (1 + np.sqrt(5)) / 2\n    jitter = (((phi * (idx[feasible] + 1) * item) % 1.0) - 0.5) * 1e-5 * item\n    mean = np.mean(remaining[feasible])\n    std = np.std(remaining[feasible])\n    coeff = std / (mean + eps)\n    random_weight = 0.01 * (1.0 + coeff)\n    load_scale = remaining[feasible] / (np.max(remaining[feasible]) + eps)\n    rng = np.random.default_rng()\n    rand_jitter = rng.standard_normal(feasible.sum()) * random_weight * item * load_scale\n    scores[feasible] = primary + bias + jitter + rand_jitter\n    return scores",
    "response_id": 1,
    "tryHS": false,
    "obj": 85.43079377742322,
    "SLOC": 25.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response2.txt_stdout.txt",
    "code_path": "problem_iter23_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, tiny index bias, golden\u2011ratio jitter,\n    adaptive random jitter scaled by load variance, and a small variance penalty.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n\n    # remaining capacity after placing the item\n    remaining = bins - item\n    feasible = remaining >= 0\n    eps = 1e-12\n\n    # primary score: higher for tighter fit (inverse leftover)\n    primary = np.full(n, -np.inf, dtype=float)\n    primary[feasible] = 1.0 / (remaining[feasible] + eps)\n\n    # tiny index bias to break ties (favor earlier bins)\n    idx = np.arange(n, dtype=float)\n    bias = -idx * 1e-7\n\n    # deterministic golden\u2011ratio jitter (very small)\n    phi = (1 + np.sqrt(5)) / 2\n    phi_jitter = ((phi * (idx + 1) * item) % 1.0) * 1e-7 * item\n\n    # adaptive random jitter scaled by coefficient of variation of feasible leftovers\n    if feasible.any():\n        rem_feas = remaining[feasible]\n        mean = np.mean(rem_feas)\n        std = np.std(rem_feas)\n        cv = std / (mean + eps)\n        random_weight = 0.01 * (1.0 + cv)\n        rng = np.random.default_rng()\n        rand_jitter = rng.random(n) * random_weight * item\n    else:\n        rand_jitter = np.zeros(n, dtype=float)\n\n    # small variance penalty to discourage outlier leftovers\n    var_penalty = np.zeros(n, dtype=float)\n    if feasible.any():\n        var_penalty[feasible] = -((remaining[feasible] - mean) ** 2) * 1e-5\n\n    # combine all components\n    score = primary + bias + phi_jitter + rand_jitter + var_penalty\n    score[~feasible] = -np.inf\n    return score",
    "response_id": 2,
    "tryHS": false,
    "obj": 3.2409254088552055,
    "SLOC": 30.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response3.txt_stdout.txt",
    "code_path": "problem_iter23_code3.py",
    "code": "import numpy as np\n\n_rng = np.random.default_rng()\n\n# Priority: inverse leftover + variance\u2011scaled jitter + tiny index bias\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins by inverse leftover, jitter scaled with remaining variance, and tiny index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not feasible.any():\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -np.arange(n)[feasible] * 1e-6\n    var_rem = np.var(remaining[feasible])\n    jitter_scale = item * 0.01 * (1.0 + np.sqrt(var_rem))\n    jitter = (_rng.random(remaining.shape)[feasible] - 0.5) * jitter_scale\n    priority[feasible] = base + bias + jitter\n    return priority",
    "response_id": 3,
    "tryHS": false,
    "obj": 2.8619864379736786,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response4.txt_stdout.txt",
    "code_path": "problem_iter23_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritize bins using inverse leftover, index bias, adaptive deterministic and random jitter weighted by remaining variance.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    idx = np.arange(n, dtype=float)\n    eps = 1e-12\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -idx[feasible] * 1e-6\n    phi = 0.6180339887498949\n    phi_jitter = (np.mod(phi * (idx[feasible] + 1) * item, 1.0) - 0.5)\n    sin_jitter = np.sin((item + idx[feasible]) * 0.01)\n    det_jitter = (phi_jitter + sin_jitter) * 1e-5 * item\n    var_rem = np.var(remaining[feasible])\n    var_factor = np.clip(np.sqrt(var_rem + eps), 0, 1)\n    jitter_scale = 1 + var_factor\n    load_scale = remaining[feasible] / (remaining[feasible].max() + eps)\n    rng = np.random.default_rng()\n    rand_jitter = rng.standard_normal(feasible.sum()) * (1e-5 * item * load_scale * jitter_scale)\n    priority[feasible] = base + bias + det_jitter + rand_jitter\n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response5.txt_stdout.txt",
    "code_path": "problem_iter23_code5.py",
    "code": "import numpy as np\n\n_item_avg = None\n_item_avg_count = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit base with variance\u2011scaled random jitter and deterministic tie\u2011breakers.\"\"\"\n    global _item_avg, _item_avg_count\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    if _item_avg is None:\n        _item_avg = item\n        _item_avg_count = 1\n    else:\n        _item_avg += (item - _item_avg) / (_item_avg_count + 1)\n        _item_avg_count += 1\n    feas_rem = remaining[feasible]\n    mean_rem = feas_rem.mean()\n    std_rem = feas_rem.std()\n    cv = std_rem / (mean_rem + eps)\n    base = 1.0 / (feas_rem + eps)\n    bias = -np.arange(n)[feasible] * 1e-5\n    phi = 0.6180339887498949\n    det_jitter = (np.mod(phi * (np.arange(n)[feasible] + 1) * item, 1.0) - 0.5) * 1e-5 * item\n    sin_jitter = np.sin(item * np.arange(n)[feasible] + 1.0) * 1e-9 * item\n    rng = np.random.default_rng()\n    noise_sigma = item * np.exp(-cv)\n    factor = abs(item - _item_avg) / (_item_avg + eps)\n    noise_sigma *= (1 + factor)\n    rng_jitter = rng.standard_normal(feasible.sum()) * noise_sigma\n    priority[feasible] = base + bias + det_jitter + sin_jitter + rng_jitter\n    return priority",
    "response_id": 5,
    "tryHS": false,
    "obj": 36.85680095731952,
    "SLOC": 33.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response6.txt_stdout.txt",
    "code_path": "problem_iter23_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Bin priority via inverse leftover, index bias, golden\u2011ratio jitter, and variance\u2011scaled random jitter.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins - item\n    feasible = remaining >= 0\n    eps = 1e-9\n    idx = np.arange(n, dtype=float)\n    score = np.full(n, -np.inf, dtype=float)\n    if feasible.any():\n        inv_leftover = 1.0 / (remaining[feasible] + eps)\n        bias = -idx[feasible] * 1e-6\n        phi = (1 + np.sqrt(5)) / 2\n        phi_jitter = ((phi * (idx[feasible] + 1) * item) % 1.0) * 1e-6 * item\n        std = np.std(remaining[feasible])\n        mean = np.mean(remaining[feasible])\n        coeff = std / (mean + eps)\n        random_weight = 0.01 * (1.0 + coeff)\n        rng = np.random.default_rng()\n        rand_jitter = rng.random(feasible.sum()) * random_weight * item\n        score[feasible] = inv_leftover + bias + phi_jitter + rand_jitter\n    return score",
    "response_id": 6,
    "tryHS": false,
    "obj": 3.0913442361388115,
    "SLOC": 23.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response7.txt_stdout.txt",
    "code_path": "problem_iter23_code7.py",
    "code": "import numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, variance\u2011scaled jitter, and index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-9\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    idx_bias = -np.arange(n)[feasible] * 1e-6\n    rem_feas = remaining[feasible]\n    mean_rem = rem_feas.mean()\n    std_rem = rem_feas.std()\n    jitter_scale = item * (0.01 + std_rem * 0.001)\n    jitter = _rng.random(rem_feas.shape) * jitter_scale\n    var_penalty = -((rem_feas - mean_rem) ** 2) * 1e-4\n    priority[feasible] = base + idx_bias + jitter + var_penalty\n    return priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 36.747108097327484,
    "SLOC": 20.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response8.txt_stdout.txt",
    "code_path": "problem_iter23_code8.py",
    "code": "import numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score feasible bins by inverse leftover, variance\u2011penalty, and a jitter scaled to item size and load.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not feasible.any():\n        return priority\n    rem_feas = remaining[feasible]\n    base = 1.0 / (rem_feas a step in the overall solution.) # replace with the correct formula or remove if not needed.",
    "response_id": 8,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 17\n    base = 1.0 / (rem_feas a step in the overall solution.) # replace with the correct formula or remove if not needed.\n                  ^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 17\n    base = 1.0 / (rem_feas a step in the overall solution.) # replace with the correct formula or remove if not needed.\n                  ^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 17\n    base = 1.0 / (rem_feas a step in the overall solution.) # replace with the correct formula or remove if not needed.\n                  ^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\n"
  },
  {
    "stdout_filepath": "problem_iter23_response9.txt_stdout.txt",
    "code_path": "problem_iter23_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Priority combining variance\u2011scaled inverse\u2011leftover, sin\u2011phi jitter, random jitter, and tie\u2011breakers.\"\"\"\n    eps = 1e-12\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    base_score = np.where(feasible, 1.0 / (remaining + eps), -np.inf)\n    mean_rem = bins_remain_cap.mean()\n    var_norm = np.var(bins_remain_cap) / (mean_rem**2 + eps)\n    w_det = 1.0 / (1.0 + var_norm)\n    w_rand = var_norm / (1.0 + var_norm)\n    rng = np.random.default_rng()\n    indices = np.arange(n, dtype=float)\n    sin_jitter = np.sin((item + indices) * 0.01)\n    phi = (np.sqrt(5) - 1) / 2\n    phi_jitter = ((phi * (indices + 1) * item) % 1.0)\n    jitter_det = sin_jitter + phi_jitter\n    max_rem = bins_remain_cap.max()\n    load_factor = (remaining + eps) / (max_rem + eps)\n    jitter_det_scaled = jitter_det * 0.01 * item * load_factor\n    jitter_rand = rng.random(n) * 0.01 * item * load_factor\n    tie_breaker = indices * 1e-6\n    priority = base_score * w_det + jitter_det_scaled * w_det + jitter_rand * w_rand + tie_breaker\n    priority[~feasible] = -np.inf\n    return priority",
    "response_id": 9,
    "tryHS": false,
    "obj": 76.6852812126047,
    "SLOC": 26.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]