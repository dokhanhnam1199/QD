{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priors = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    eligible = bins_remain_cap >= item\n    if np.any(eligible):\n        rng = np.random.default_rng()\n        priors[eligible] = rng.random(np.count_nonzero(eligible))\n    return priors\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority for each bin according to Worst Fit strategy.\"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.where(feasible, bins_remain_cap, -np.inf)\n    return priorities\n\n### Analyze & experience\n- - **#1 vs #20** \u2013 The top heuristic uses an *inverse\u2011remaining\u2011capacity* score (`1/(leftover+\u03b5)`) and returns `\u2011inf` for infeasible bins, guaranteeing that only bins that can hold the item are considered and that the bin left almost full\u2011filled is chosen. The worst heuristic (#20) is a pure *worst\u2011fit* (`bins_remain_cap`), favoring the most empty bin, which is antagonistic to bin\u2011packing objectives and lacks any documentation.  \n\n- **#2 vs #19** \u2013 #2 computes `\u2011residual` (negative leftover), a linear version of #1 that still respects feasibility via `\u2011inf`. #19 also uses `\u2011residual` deterministically but falls back to a random score with probability `\u03b5`. While the random fallback adds exploration, the deterministic part is identical; however, #19\u2019s random branch can select any feasible bin, diluting the quality of the placement.  \n\n- **#3 vs #18** \u2013 #3 builds on #2 by adding a small random perturbation (`rand*0.1*item`) to break ties, preserving the deterministic ordering while injecting controlled stochasticity. #18 squares the bin capacity (`bins_remain_cap**2`) for feasible bins, an extreme *worst\u2011fit* variant that heavily biases toward the largest bins, worsening packing efficiency.  \n\n- **#4 vs #17** \u2013 #4 mirrors #2 but adds a guard for empty input arrays, demonstrating defensive programming. #17 is another *worst\u2011fit* approach (`bins_remain_cap`), lacking any tie\u2011breaker or feasibility safety beyond `\u2011inf`.  \n\n- **#5 vs #16** \u2013 #5 returns `1/(residual+\u03b5)` for feasible bins but `0` for infeasible ones; `0` can be higher than `\u2011inf`, risking selection of an impossible bin. #16 correctly uses `\u2011inf` for infeasible bins and generates a pure random priority for feasible bins, which is safe but lacks deterministic guidance.  \n\n- **#6 vs #12** \u2013 #6\u2019s type hint (`-> np.inf`) is outright wrong and misleading, though the implementation matches #2. #12 implements a classic *first\u2011fit* by using negative indices (`\u2011idx`) as priorities; it is deterministic and simple but ignores how tightly the item fits, making it less effective than capacity\u2011aware scores.  \n\n- **#7 vs #9** \u2013 #7 mixes deterministic waste (`\u2011waste`) with random noise weighted by `\u03b5=0.1`. #9 (and duplicate #10) adopt an \u03b5\u2011greedy scheme: with probability `\u03b5` choose a random feasible bin, otherwise use deterministic waste. Both inject exploration, but #7\u2019s continuous blend is smoother than #9\u2019s abrupt switch.  \n\n- **#8 vs #1** \u2013 #8 is essentially a copy of #1 with a more elaborate docstring; both achieve the same optimal *almost\u2011full\u2011fit* behavior.  \n\n- **Duplicates (#9/10, #13/14/15)** \u2013 Repeating the same random\u2011only heuristic (no deterministic component) demonstrates diminishing returns; they occupy lower ranks despite being functionally identical.  \n\n- **General observations** \u2013 The highest\u2011ranked functions provide clear docstrings, proper edge\u2011case handling, deterministic capacity\u2011aware scoring, and only minimal, well\u2011controlled randomness. Lower\u2011ranked ones suffer from missing documentation, incorrect type hints, unsafe fallback values (`0` instead of `\u2011inf`), or strategies that deliberately pick the least\u2011filled bins.\n- \n- **Keywords:** feasibility, capacity\u2011aware, tie\u2011breaking, documentation, deterministic, modular  \n- **Advice:** build modular components, test on synthetic data, use deterministic tie\u2011breakers, validate against known optima, log decisions, iterate systematically  \n- **Avoid:** arbitrary random seeds, hard\u2011coded weights, ignoring edge cases, overfitting, undocumented heuristics  \n- **Explanation:** these guidelines reduce bias, improve reproducibility, enhance maintainability, and support continuous improvement.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}