{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Module\u2011level RNG for reproducible pseudo\u2011random jitter\n_rng = np.random.default_rng(42)\n\n    \"\"\"\n    Inverse leftover priority with tiny index bias, small deterministic sinusoid,\n    and reproducible jitter.\n    \"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-9\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    indices = np.arange(n)\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -indices[feasible] * 1e-5\n    jitter = _rng.random(n)[feasible] * 0.01 * item\n    det_jitter = (np.sin((item + indices[feasible]) * 7.0) + 1) * 0.5 * 1e-9 * item\n    priority[feasible] = base + bias + jitter + det_jitter\n    return priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    rng = np.random.default_rng()\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    inv_leftover = np.where(remaining > 0, 1.0 / remaining, np.finfo(float).max)\n    total_remain = bins_remain_cap.sum()\n    mean_remain = total_remain / n\n    variance = np.where(total_remain > 0, ((bins_remain_cap - mean_remain)**2).sum() / n, 0.0)\n    var_norm = np.where(mean_remain > 0, variance / (mean_remain**2), 0.0)\n    forecast = np.where(mean_remain > 0, np.exp(-item / mean_remain), 0.0)\n    w_inv = 1.0 / (item if item > 0 else 1.0)\n    w_var = 1.0 / (mean_remain if mean_remain > 0 else 1.0)\n    w_forecast = 1.0 / (total_remain if total_remain > 0 else 1.0)\n    total_w = w_inv + w_var + w_forecast\n    inv_weight = w_inv / total_w\n    var_weight = w_var / total_w\n    fore_weight = w_forecast / total_w\n    score = inv_leftover * inv_weight + (1.0 - var_norm) * var_weight + forecast * fore_weight\n    max_remain = bins_remain_cap.max() if n > 0 else 0\n    jitter_scale = np.where(max_remain > 0, 1.0 - (remaining / max_remain), 0.0)\n    jitter = rng.random(n) * jitter_scale * item * 0.1\n    bin_indices = np.arange(n)\n    hash_val = ((bin_indices * 9301 + 49297) % 233280) / 233280\n    tie_breaker = rng.normal(size=n) * hash_val * 1e-3\n    priority[feasible] = score[feasible] + jitter[feasible] + tie_breaker[feasible]\n    return priority\n\n### Analyze & experience\n- - **Best (1st) vs Worst (20th)**  \n  The best heuristic uses a concise, deterministic scheme: inverse leftover priority, a tiny index bias, and a small reproducible jitter scaled by the item size. Its docstring clearly outlines these components. The worst heuristic adds redundant assignments (`base = 0.0` before re\u2011assignment), a non\u2011deterministic RNG (no seed), and a load\u2011scaled jitter term, increasing computational overhead without clear benefit. The complexity can slow execution and obscure reproducibility.\n\n- **Second Best (2nd) vs Second Worst (19th)**  \n  The second best is identical to the best, offering the same deterministic, lightweight priority computation. The second worst incorporates an additional mean\u2011centered load term and uses `rng = np.random.default_rng()` without seeding. Its bias term (`bias = idx[feasible] * 1e-6`) is added then subtracted, making its effect unclear. The extra arithmetic and the non\u2011deterministic jitter add noise and potential instability.\n\n- **1st vs 2nd**  \n  These two functions are identical; no difference exists. Both are simple, deterministic, and efficient.\n\n- **3rd vs 4th**  \n  The third and fourth heuristics are also identical. They introduce sinusoidal jitter (`np.sin((item + np.arange(n)) * 0.01)`) and a random jitter term. While deterministic in scale, the additional trigonometric computation and jitter add marginal overhead with no demonstrated performance gain.\n\n- **Second Worst (19th) vs Worst (20th)**  \n  The 19th heuristic adds a mean\u2011centered load term to bias toward bins closer to the mean remaining capacity, while the 20th focuses on a load\u2011scaled random jitter. Both lack deterministic seeding, making runs non\u2011reproducible. The 20th contains a redundant base assignment and uses a somewhat arbitrary load scaling factor, increasing code complexity.\n\n**Overall:**  \nThe top heuristic stands out for its minimalism, deterministic behavior, and efficient vectorized operations. The lower\u2011ranked heuristics introduce unnecessary complexity, non\u2011deterministic jitter, and redundant calculations, which can degrade performance and reproducibility. Effective design should prioritize simplicity, clear docstrings, and deterministic tie\u2011breaking.\n- \n- **Keywords:** adaptive scoring, stochastic tie\u2011breakers, instance\u2011aware features, feedback\u2011driven tuning, vectorized exploration.  \n- **Advice:** blend a primary capacity\u2011aware metric with dynamically weighted random perturbations that adapt to bin load distribution; update weights online based on observed packing success; use per\u2011iteration RNG streams without fixed seeds.  \n- **Avoid:** static index bias, fixed deterministic jitter, global seed reuse, hard\u2011coded hyper\u2011parameters, neglecting performance feedback.  \n- **Explanation:** adaptive randomness and feedback prevent systematic bias, improve solution diversity, and maintain high throughput while still leveraging vectorized operations.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}