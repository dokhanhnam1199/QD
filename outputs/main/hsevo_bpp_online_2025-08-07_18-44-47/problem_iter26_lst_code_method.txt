{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\n# Priority: inverse leftover + variance\u2011scaled jitter + tiny index bias\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins by inverse leftover, jitter scaled with remaining variance, and tiny index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not feasible.any():\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -np.arange(n)[feasible] * 1e-6\n    var_rem = np.var(remaining[feasible])\n    jitter_scale = item * 0.01 * (1.0 + np.sqrt(var_rem))\n    jitter = (_rng.random(remaining.shape)[feasible] - 0.5) * jitter_scale\n    priority[feasible] = base + bias + jitter\n    return priority\n\n[Heuristics 2nd]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\n# Priority: inverse leftover + variance\u2011scaled jitter + tiny index bias\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins by inverse leftover, jitter scaled with remaining variance, and tiny index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not feasible.any():\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -np.arange(n)[feasible] * 1e-6\n    var_rem = np.var(remaining[feasible])\n    jitter_scale = item * 0.01 * (1.0 + np.sqrt(var_rem))\n    jitter = (_rng.random(remaining.shape)[feasible] - 0.5) * jitter_scale\n    priority[feasible] = base + bias + jitter\n    return priority\n\n[Heuristics 3rd]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\n# Priority: inverse leftover + variance\u2011scaled jitter + tiny index bias\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins by inverse leftover, jitter scaled with remaining variance, and tiny index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not feasible.any():\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -np.arange(n)[feasible] * 1e-6\n    var_rem = np.var(remaining[feasible])\n    jitter_scale = item * 0.01 * (1.0 + np.sqrt(var_rem))\n    jitter = (_rng.random(remaining.shape)[feasible] - 0.5) * jitter_scale\n    priority[feasible] = base + bias + jitter\n    return priority\n\n[Heuristics 4th]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\n# Priority: inverse leftover + variance\u2011scaled jitter + tiny index bias\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins by inverse leftover, jitter scaled with remaining variance, and tiny index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not feasible.any():\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -np.arange(n)[feasible] * 1e-6\n    var_rem = np.var(remaining[feasible])\n    jitter_scale = item * 0.01 * (1.0 + np.sqrt(var_rem))\n    jitter = (_rng.random(remaining.shape)[feasible] - 0.5) * jitter_scale\n    priority[feasible] = base + bias + jitter\n    return priority\n\n[Heuristics 5th]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\n# Priority: inverse leftover + variance\u2011scaled jitter + tiny index bias\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins by inverse leftover, jitter scaled with remaining variance, and tiny index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not feasible.any():\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    bias = -np.arange(n)[feasible] * 1e-6\n    var_rem = np.var(remaining[feasible])\n    jitter_scale = item * 0.01 * (1.0 + np.sqrt(var_rem))\n    jitter = (_rng.random(remaining.shape)[feasible] - 0.5) * jitter_scale\n    priority[feasible] = base + bias + jitter\n    return priority\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    n = bins_remain_cap.size\n    priority = np.full(n, -np.inf, dtype=float)\n    if n == 0:\n        return priority\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    if not np.any(feasible):\n        return priority\n    eps = 1e-12\n    rem = remaining[feasible]\n    base = 1.0 / (rem + eps)\n    tight = item / (item + rem + eps)\n    base = base * tight\n    var_rem = np.var(rem) if rem.size > 1 else 0.0\n    rng = np.random.default_rng()\n    jitter_scale = item * 0.005 * (1.0 + np.sqrt(var_rem))\n    jitter = (rng.random(rem.size) - 0.5) * jitter_scale\n    priority[feasible] = base + jitter\n    return priority\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    n = bins_remain_cap.size\n    priority = np.full(n, -np.inf, dtype=float)\n    if n == 0:\n        return priority\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    if not np.any(feasible):\n        return priority\n    eps = 1e-12\n    rem = remaining[feasible]\n    base = 1.0 / (rem + eps)\n    tight = item / (item + rem + eps)\n    base = base * tight\n    var_rem = np.var(rem) if rem.size > 1 else 0.0\n    rng = np.random.default_rng()\n    jitter_scale = item * 0.005 * (1.0 + np.sqrt(var_rem))\n    jitter = (rng.random(rem.size) - 0.5) * jitter_scale\n    priority[feasible] = base + jitter\n    return priority\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Bin priority via inverse leftover, index bias, golden\u2011ratio jitter, and variance\u2011scaled random jitter.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins - item\n    feasible = remaining >= 0\n    eps = 1e-9\n    idx = np.arange(n, dtype=float)\n    score = np.full(n, -np.inf, dtype=float)\n    if feasible.any():\n        inv_leftover = 1.0 / (remaining[feasible] + eps)\n        bias = -idx[feasible] * 1e-6\n        phi = (1 + np.sqrt(5)) / 2\n        phi_jitter = ((phi * (idx[feasible] + 1) * item) % 1.0) * 1e-6 * item\n        std = np.std(remaining[feasible])\n        mean = np.mean(remaining[feasible])\n        coeff = std / (mean + eps)\n        random_weight = 0.01 * (1.0 + coeff)\n        rng = np.random.default_rng()\n        rand_jitter = rng.random(feasible.sum()) * random_weight * item\n        score[feasible] = inv_leftover + bias + phi_jitter + rand_jitter\n    return score\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Bin priority via inverse leftover, index bias, golden\u2011ratio jitter, and variance\u2011scaled random jitter.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins - item\n    feasible = remaining >= 0\n    eps = 1e-9\n    idx = np.arange(n, dtype=float)\n    score = np.full(n, -np.inf, dtype=float)\n    if feasible.any():\n        inv_leftover = 1.0 / (remaining[feasible] + eps)\n        bias = -idx[feasible] * 1e-6\n        phi = (1 + np.sqrt(5)) / 2\n        phi_jitter = ((phi * (idx[feasible] + 1) * item) % 1.0) * 1e-6 * item\n        std = np.std(remaining[feasible])\n        mean = np.mean(remaining[feasible])\n        coeff = std / (mean + eps)\n        random_weight = 0.01 * (1.0 + coeff)\n        rng = np.random.default_rng()\n        rand_jitter = rng.random(feasible.sum()) * random_weight * item\n        score[feasible] = inv_leftover + bias + phi_jitter + rand_jitter\n    return score\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Bin priority via inverse leftover, index bias, golden\u2011ratio jitter, and variance\u2011scaled random jitter.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins - item\n    feasible = remaining >= 0\n    eps = 1e-9\n    idx = np.arange(n, dtype=float)\n    score = np.full(n, -np.inf, dtype=float)\n    if feasible.any():\n        inv_leftover = 1.0 / (remaining[feasible] + eps)\n        bias = -idx[feasible] * 1e-6\n        phi = (1 + np.sqrt(5)) / 2\n        phi_jitter = ((phi * (idx[feasible] + 1) * item) % 1.0) * 1e-6 * item\n        std = np.std(remaining[feasible])\n        mean = np.mean(remaining[feasible])\n        coeff = std / (mean + eps)\n        random_weight = 0.01 * (1.0 + coeff)\n        rng = np.random.default_rng()\n        rand_jitter = rng.random(feasible.sum()) * random_weight * item\n        score[feasible] = inv_leftover + bias + phi_jitter + rand_jitter\n    return score\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, tiny index bias, golden\u2011ratio jitter,\n    adaptive random jitter scaled by load variance, and a small variance penalty.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n\n    # remaining capacity after placing the item\n    remaining = bins - item\n    feasible = remaining >= 0\n    eps = 1e-12\n\n    # primary score: higher for tighter fit (inverse leftover)\n    primary = np.full(n, -np.inf, dtype=float)\n    primary[feasible] = 1.0 / (remaining[feasible] + eps)\n\n    # tiny index bias to break ties (favor earlier bins)\n    idx = np.arange(n, dtype=float)\n    bias = -idx * 1e-7\n\n    # deterministic golden\u2011ratio jitter (very small)\n    phi = (1 + np.sqrt(5)) / 2\n    phi_jitter = ((phi * (idx + 1) * item) % 1.0) * 1e-7 * item\n\n    # adaptive random jitter scaled by coefficient of variation of feasible leftovers\n    if feasible.any():\n        rem_feas = remaining[feasible]\n        mean = np.mean(rem_feas)\n        std = np.std(rem_feas)\n        cv = std / (mean + eps)\n        random_weight = 0.01 * (1.0 + cv)\n        rng = np.random.default_rng()\n        rand_jitter = rng.random(n) * random_weight * item\n    else:\n        rand_jitter = np.zeros(n, dtype=float)\n\n    # small variance penalty to discourage outlier leftovers\n    var_penalty = np.zeros(n, dtype=float)\n    if feasible.any():\n        var_penalty[feasible] = -((remaining[feasible] - mean) ** 2) * 1e-5\n\n    # combine all components\n    score = primary + bias + phi_jitter + rand_jitter + var_penalty\n    score[~feasible] = -np.inf\n    return score\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, tiny index bias, golden\u2011ratio jitter,\n    adaptive random jitter scaled by load variance, and a small variance penalty.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n\n    # remaining capacity after placing the item\n    remaining = bins - item\n    feasible = remaining >= 0\n    eps = 1e-12\n\n    # primary score: higher for tighter fit (inverse leftover)\n    primary = np.full(n, -np.inf, dtype=float)\n    primary[feasible] = 1.0 / (remaining[feasible] + eps)\n\n    # tiny index bias to break ties (favor earlier bins)\n    idx = np.arange(n, dtype=float)\n    bias = -idx * 1e-7\n\n    # deterministic golden\u2011ratio jitter (very small)\n    phi = (1 + np.sqrt(5)) / 2\n    phi_jitter = ((phi * (idx + 1) * item) % 1.0) * 1e-7 * item\n\n    # adaptive random jitter scaled by coefficient of variation of feasible leftovers\n    if feasible.any():\n        rem_feas = remaining[feasible]\n        mean = np.mean(rem_feas)\n        std = np.std(rem_feas)\n        cv = std / (mean + eps)\n        random_weight = 0.01 * (1.0 + cv)\n        rng = np.random.default_rng()\n        rand_jitter = rng.random(n) * random_weight * item\n    else:\n        rand_jitter = np.zeros(n, dtype=float)\n\n    # small variance penalty to discourage outlier leftovers\n    var_penalty = np.zeros(n, dtype=float)\n    if feasible.any():\n        var_penalty[feasible] = -((remaining[feasible] - mean) ** 2) * 1e-5\n\n    # combine all components\n    score = primary + bias + phi_jitter + rand_jitter + var_penalty\n    score[~feasible] = -np.inf\n    return score\n\n[Heuristics 13th]\nimport numpy as np\n\n_item_avg = None\n_item_avg_count = 0\n\n# Adaptive jitter with variance penalty for online BPP\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid: negative leftover, variance penalty, index bias, and adaptive jitter.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    global _item_avg, _item_avg_count\n    if _item_avg is None:\n        _item_avg = item\n        _item_avg_count = 1\n    else:\n        _item_avg += (item - _item_avg) / (_item_avg_count + 1)\n        _item_avg_count += 1\n    feas_rem = remaining[feasible]\n    mean_rem = feas_rem.mean()\n    std_rem = feas_rem.std()\n    cv = std_rem / (mean_rem + 1e-12)\n    noise_sigma = item * np.exp(-cv)\n    factor = abs(item - _item_avg) / (_item_avg + 1e-12)\n    noise_sigma *= (1 + factor)\n    rng = np.random.default_rng()\n    jitter = rng.normal(0, noise_sigma, size=feasible.sum())\n    base = -feas_rem\n    var_penalty = -((feas_rem - mean_rem) ** 2) * 1e-4\n    idx_bias = np.arange(n)[feasible] * 1e-6\n    priority[feasible] = base + var_penalty + jitter + idx_bias\n    return priority\n\n[Heuristics 14th]\nimport numpy as np\n\n_item_avg = None\n_item_avg_count = 0\n\n# Adaptive jitter with variance penalty for online BPP\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid: negative leftover, variance penalty, index bias, and adaptive jitter.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    global _item_avg, _item_avg_count\n    if _item_avg is None:\n        _item_avg = item\n        _item_avg_count = 1\n    else:\n        _item_avg += (item - _item_avg) / (_item_avg_count + 1)\n        _item_avg_count += 1\n    feas_rem = remaining[feasible]\n    mean_rem = feas_rem.mean()\n    std_rem = feas_rem.std()\n    cv = std_rem / (mean_rem + 1e-12)\n    noise_sigma = item * np.exp(-cv)\n    factor = abs(item - _item_avg) / (_item_avg + 1e-12)\n    noise_sigma *= (1 + factor)\n    rng = np.random.default_rng()\n    jitter = rng.normal(0, noise_sigma, size=feasible.sum())\n    base = -feas_rem\n    var_penalty = -((feas_rem - mean_rem) ** 2) * 1e-4\n    idx_bias = np.arange(n)[feasible] * 1e-6\n    priority[feasible] = base + var_penalty + jitter + idx_bias\n    return priority\n\n[Heuristics 15th]\nimport numpy as np\n\n_item_avg = None\n_item_avg_count = 0\n\n# Adaptive jitter with variance penalty for online BPP\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid: negative leftover, variance penalty, index bias, and adaptive jitter.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    global _item_avg, _item_avg_count\n    if _item_avg is None:\n        _item_avg = item\n        _item_avg_count = 1\n    else:\n        _item_avg += (item - _item_avg) / (_item_avg_count + 1)\n        _item_avg_count += 1\n    feas_rem = remaining[feasible]\n    mean_rem = feas_rem.mean()\n    std_rem = feas_rem.std()\n    cv = std_rem / (mean_rem + 1e-12)\n    noise_sigma = item * np.exp(-cv)\n    factor = abs(item - _item_avg) / (_item_avg + 1e-12)\n    noise_sigma *= (1 + factor)\n    rng = np.random.default_rng()\n    jitter = rng.normal(0, noise_sigma, size=feasible.sum())\n    base = -feas_rem\n    var_penalty = -((feas_rem - mean_rem) ** 2) * 1e-4\n    idx_bias = np.arange(n)[feasible] * 1e-6\n    priority[feasible] = base + var_penalty + jitter + idx_bias\n    return priority\n\n[Heuristics 16th]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, variance\u2011scaled jitter, and index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-9\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    idx_bias = -np.arange(n)[feasible] * 1e-6\n    rem_feas = remaining[feasible]\n    mean_rem = rem_feas.mean()\n    std_rem = rem_feas.std()\n    jitter_scale = item * (0.01 + std_rem * 0.001)\n    jitter = _rng.random(rem_feas.shape) * jitter_scale\n    var_penalty = -((rem_feas - mean_rem) ** 2) * 1e-4\n    priority[feasible] = base + idx_bias + jitter + var_penalty\n    return priority\n\n[Heuristics 17th]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, variance\u2011scaled jitter, and index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-9\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    idx_bias = -np.arange(n)[feasible] * 1e-6\n    rem_feas = remaining[feasible]\n    mean_rem = rem_feas.mean()\n    std_rem = rem_feas.std()\n    jitter_scale = item * (0.01 + std_rem * 0.001)\n    jitter = _rng.random(rem_feas.shape) * jitter_scale\n    var_penalty = -((rem_feas - mean_rem) ** 2) * 1e-4\n    priority[feasible] = base + idx_bias + jitter + var_penalty\n    return priority\n\n[Heuristics 18th]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, variance\u2011scaled jitter, and index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-9\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    idx_bias = -np.arange(n)[feasible] * 1e-6\n    rem_feas = remaining[feasible]\n    mean_rem = rem_feas.mean()\n    std_rem = rem_feas.std()\n    jitter_scale = item * (0.01 + std_rem * 0.001)\n    jitter = _rng.random(rem_feas.shape) * jitter_scale\n    var_penalty = -((rem_feas - mean_rem) ** 2) * 1e-4\n    priority[feasible] = base + idx_bias + jitter + var_penalty\n    return priority\n\n[Heuristics 19th]\nimport numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse leftover, variance\u2011scaled jitter, and index bias.\"\"\"\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-9\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    base = 1.0 / (remaining[feasible] + eps)\n    idx_bias = -np.arange(n)[feasible] * 1e-6\n    rem_feas = remaining[feasible]\n    mean_rem = rem_feas.mean()\n    std_rem = rem_feas.std()\n    jitter_scale = item * (0.01 + std_rem * 0.001)\n    jitter = _rng.random(rem_feas.shape) * jitter_scale\n    var_penalty = -((rem_feas - mean_rem) ** 2) * 1e-4\n    priority[feasible] = base + idx_bias + jitter + var_penalty\n    return priority\n\n[Heuristics 20th]\nimport numpy as np\n\n_item_avg = None\n_item_avg_count = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit base with variance\u2011scaled random jitter and deterministic tie\u2011breakers.\"\"\"\n    global _item_avg, _item_avg_count\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    eps = 1e-12\n    remaining = bins_remain_cap - item\n    feasible = remaining >= 0\n    priority = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priority\n    if _item_avg is None:\n        _item_avg = item\n        _item_avg_count = 1\n    else:\n        _item_avg += (item - _item_avg) / (_item_avg_count + 1)\n        _item_avg_count += 1\n    feas_rem = remaining[feasible]\n    mean_rem = feas_rem.mean()\n    std_rem = feas_rem.std()\n    cv = std_rem / (mean_rem + eps)\n    base = 1.0 / (feas_rem + eps)\n    bias = -np.arange(n)[feasible] * 1e-5\n    phi = 0.6180339887498949\n    det_jitter = (np.mod(phi * (np.arange(n)[feasible] + 1) * item, 1.0) - 0.5) * 1e-5 * item\n    sin_jitter = np.sin(item * np.arange(n)[feasible] + 1.0) * 1e-9 * item\n    rng = np.random.default_rng()\n    noise_sigma = item * np.exp(-cv)\n    factor = abs(item - _item_avg) / (_item_avg + eps)\n    noise_sigma *= (1 + factor)\n    rng_jitter = rng.standard_normal(feasible.sum()) * noise_sigma\n    priority[feasible] = base + bias + det_jitter + sin_jitter + rng_jitter\n    return priority\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}