```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) using stochastic solution sampling principles.
    This version combines several factors, including centrality measures and adaptive sparsification,
    to estimate the "promise" of each edge and reduce the search space. It refines centrality using a geometric mean and degree centrality.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix between cities.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as the distance matrix, where each element indicates
                      the heuristic promise of including that edge in the solution.
    """

    n = distance_matrix.shape[0]

    # Initialize the heuristic matrix
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Calculate the inverse distance (closer is better)
    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero

    # Calculate row and column sums (representing how far away a node is on average from others)
    row_sums = np.sum(distance_matrix, axis=1, keepdims=True)
    col_sums = np.sum(distance_matrix, axis=0, keepdims=True)

    # Normalize row and column sums - smaller row/col sums imply the node is more centrally located
    row_normalized = 1 / (row_sums + 1e-9)
    col_normalized = 1 / (col_sums + 1e-9)

    # Combine these factors:
    # 1. Inverse distance: Encourages shorter edges
    # 2. Node centrality:  Encourages edges connected to centrally located nodes
    heuristic_matrix = inverse_distance * np.sqrt(row_normalized * col_normalized)  # Geometric mean of normalized row/col sums

    # Sparsification: set unpromising entries to zero to reduce the search space
    # Adaptive threshold based on the distribution of heuristic values
    flattened_heuristic = heuristic_matrix[np.triu_indices_from(heuristic_matrix, k=1)]
    flattened_heuristic = flattened_heuristic[flattened_heuristic > 0]  # Consider only positive values

    if len(flattened_heuristic) > 0:
        threshold = np.quantile(flattened_heuristic, 0.25)  # 25th percentile as threshold
        heuristic_matrix[heuristic_matrix < threshold] = 0  # sparsify

    # Remove self-loops (diagonal elements)
    np.fill_diagonal(heuristic_matrix, 0)

    # Further enhance centrality using degree centrality approximation
    degree_centrality = np.sum(heuristic_matrix > 0, axis=1)
    degree_centrality_normalized = degree_centrality / (n - 1 + 1e-9) #avoid division by zero in case n==1

    # Refine heuristic matrix using degree centrality
    for i in range(n):
        for j in range(n):
            if heuristic_matrix[i, j] > 0:
                heuristic_matrix[i, j] *= np.sqrt(degree_centrality_normalized[i] * degree_centrality_normalized[j])


    # Re-apply sparsification after degree centrality boost

    flattened_heuristic = heuristic_matrix[np.triu_indices_from(heuristic_matrix, k=1)]
    flattened_heuristic = flattened_heuristic[flattened_heuristic > 0]

    if len(flattened_heuristic) > 0:
        threshold = np.quantile(flattened_heuristic, 0.25)
        heuristic_matrix[heuristic_matrix < threshold] = 0

    # Normalize heuristic matrix (optional, but can be helpful)
    row_sums = np.sum(heuristic_matrix, axis=1, keepdims=True)
    heuristic_matrix = np.where(row_sums > 0, heuristic_matrix / row_sums, heuristic_matrix)

    return heuristic_matrix
```
