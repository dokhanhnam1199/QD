```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:

    """
    Heuristic function for TSP using a combination of factors and sparsification.
    This version incorporates adaptive weighting, normalization, and independent row sparsification.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as distance_matrix,
                     representing the heuristic values (prior indicators).
    """

    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Calculate nearest neighbors for each node.
    nearest_neighbors = []
    for i in range(n):
        distances = distance_matrix[i].copy()
        distances[i] = np.inf  # Exclude self-loop
        nearest_neighbors.append(np.argsort(distances))

    # Calculate a centrality measure (degree of connectivity).
    degree_centrality = np.sum(1 / (distance_matrix + 1e-9), axis=0)
    degree_centrality_normalized = (degree_centrality - np.min(degree_centrality)) / (np.max(degree_centrality) - np.min(degree_centrality) + 1e-9)

    # Inverse distance factor
    inverse_distance = 1 / (distance_matrix + 1e-9)
    inverse_distance_normalized = (inverse_distance - np.min(inverse_distance)) / (np.max(inverse_distance) - np.min(inverse_distance) + 1e-9)

    # Combine factors: inverse distance, nearest neighbor rank, and centrality.
    for i in range(n):
        for j in range(n):
            if i != j:
                # Rank of j in i's nearest neighbors and vice versa
                rank_i = np.where(nearest_neighbors[i] == j)[0][0]
                rank_j = np.where(nearest_neighbors[j] == i)[0][0]
                rank_factor = 1 / (rank_i + rank_j + 1)

                # Adaptive weights (adjust based on problem characteristics)
                weight_distance = 0.6
                weight_rank = 0.2
                weight_centrality = 0.2

                heuristic_matrix[i, j] = (
                    weight_distance * inverse_distance_normalized[i, j] +
                    weight_rank * rank_factor +
                    weight_centrality * (degree_centrality_normalized[i] + degree_centrality_normalized[j])
                )

    # Sparsify the matrix: keep only the top k edges for each node using a quantile.
    quantile_threshold = 0.75  # Keep edges above this quantile for each row
    for i in range(n):
        row = heuristic_matrix[i].copy()
        threshold = np.quantile(row[row > 0], quantile_threshold)  # Consider only positive values for quantile
        heuristic_matrix[i][row < threshold] = 0

    # Normalize each row
    for i in range(n):
        row_sum = np.sum(heuristic_matrix[i])
        if row_sum > 0:
            heuristic_matrix[i] /= row_sum

    return heuristic_matrix
```
