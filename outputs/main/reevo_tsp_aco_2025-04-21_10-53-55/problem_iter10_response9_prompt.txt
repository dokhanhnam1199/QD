{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using normalized inverse distance, geometric mean centrality,\n    rank-based information, adaptive sparsification, and row-wise processing.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                     representing the heuristic values (prior indicators).\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Normalized Inverse Distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Row-wise normalization\n    row_sums = np.sum(inverse_distance, axis=1, keepdims=True)\n    inverse_distance = inverse_distance / (row_sums + 1e-9)\n\n    # Column-wise normalization\n    col_sums = np.sum(inverse_distance, axis=0, keepdims=True)\n    inverse_distance = inverse_distance / (col_sums + 1e-9)\n\n    # 2. Geometric Mean Centrality\n    centrality = np.zeros(n)\n    for i in range(n):\n        product = 1.0\n        for j in range(n):\n            if i != j:\n                product *= inverse_distance[i, j] + 1e-9\n        centrality[i] = product**(1/(n-1)) if n > 1 else 0.0  # Geometric mean\n    centrality = (centrality - np.min(centrality)) / (np.max(centrality) - np.min(centrality) + 1e-9) # Normalize\n\n    # 3. Rank-Based Information (Nearest Neighbors)\n    nearest_neighbors = []\n    for i in range(n):\n        distances = distance_matrix[i].copy()\n        distances[i] = np.inf  # Exclude self-loop\n        nearest_neighbors.append(np.argsort(distances))\n\n    # Combine factors and compute heuristic matrix\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                rank_i = np.where(nearest_neighbors[i] == j)[0][0]\n                rank_j = np.where(nearest_neighbors[j] == i)[0][0]\n                rank_factor = 1 / (rank_i + rank_j + 1)  # rank based\n\n                centrality_factor = np.sqrt(centrality[i] * centrality[j])\n\n                heuristic_matrix[i, j] = inverse_distance[i, j] * rank_factor * centrality_factor\n\n    # 4. Adaptive Sparsification\n    quantile_level = 0.7 # adjust sparsity here.\n    threshold = np.quantile(heuristic_matrix[heuristic_matrix > 0], quantile_level)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 5. Row-wise normalization (maintain connectivity)\n    for i in range(n):\n        row_sum = np.sum(heuristic_matrix[i])\n        if row_sum > 0:\n            heuristic_matrix[i] = heuristic_matrix[i] / row_sum\n        else:\n            # Ensure at least one edge is selected from each row.\n            min_dist_idx = np.argmin(distance_matrix[i])\n            heuristic_matrix[i, min_dist_idx] = 1.0 # default value\n            heuristic_matrix[i] = heuristic_matrix[i] / np.sum(heuristic_matrix[i])\n\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using node ranking, centrality, adaptive sparsification,\n    and row-wise normalization. Geometric mean centrality is prioritized, and includes a penalty\n    for long edges.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                     representing the heuristic values (prior indicators).\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate nearest neighbors for each node.\n    nearest_neighbors = []\n    for i in range(n):\n        distances = distance_matrix[i].copy()\n        distances[i] = np.inf  # Exclude self-loop\n        nearest_neighbors.append(np.argsort(distances))\n\n    # Calculate geometric mean centrality. Add a small constant to avoid zero values.\n    centrality = np.zeros(n)\n    for i in range(n):\n        centrality[i] = np.exp(np.mean(np.log(1 / (distance_matrix[i, :] + 0.001))))\n    centrality = centrality / np.max(centrality) # Normalize\n\n    # Inverse distance factor\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n    inverse_distance = inverse_distance / np.max(inverse_distance)  # Normalize\n\n    # Edge length penalty (longer edges are penalized more)\n    edge_penalty = np.exp(-distance_matrix / np.mean(distance_matrix))\n\n    # Combine factors: inverse distance, nearest neighbor rank, and centrality.\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Rank of j in i's nearest neighbors and vice versa\n                rank_i = np.where(nearest_neighbors[i] == j)[0][0]\n                rank_j = np.where(nearest_neighbors[j] == i)[0][0]\n                rank_factor = 1 / (rank_i + rank_j + 1)\n\n                # Prioritize Geometric Mean Centrality\n                centrality_factor = np.sqrt(centrality[i] * centrality[j])\n\n                heuristic_matrix[i, j] = inverse_distance[i, j] * rank_factor * centrality_factor * edge_penalty[i,j]\n\n    # Adaptive Sparsification - Adjusted Threshold\n    quantile_level = 0.75 # Reduced Sparsity compared to v1 to avoid unconnected components\n    positive_values = heuristic_matrix[heuristic_matrix > 0]\n    if positive_values.size > 0: # Avoid errors if heuristic_matrix is all zeros.\n        threshold = np.quantile(positive_values, quantile_level)\n        heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Row-wise normalization to avoid zero rows after sparsification\n    for i in range(n):\n        row_sum = np.sum(heuristic_matrix[i])\n        if row_sum > 0:\n            heuristic_matrix[i] = heuristic_matrix[i] / row_sum\n        else:\n            # If row is all zeros, connect to a few nearest neighbors to ensure connectivity\n            k = 3 # Connect to top k nearest neighbours\n            top_k_indices = nearest_neighbors[i][:k]\n            for neighbor in top_k_indices:\n                heuristic_matrix[i, neighbor] = 0.01 #Assign small probability\n            heuristic_matrix[i] = heuristic_matrix[i] / np.sum(heuristic_matrix[i]) # renormalize\n\n    return heuristic_matrix\n\n[Reflection]\nPrioritize centrality, penalize long edges, and reduce sparsification to maintain connectivity.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}