{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n\n    \"\"\"\n    Heuristic function for TSP using a combination of factors and adaptive sparsification.\n    Version 3: Enhanced normalization, robust handling of edge cases, and parameter tuning.\n    Includes additional diversification and uses a more focused nearest neighbor consideration.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                     representing the heuristic values (prior indicators).\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate nearest neighbors for each node, limiting to top k.\n    k_nearest = min(5, n - 1)  # Consider only a limited number of nearest neighbors\n    nearest_neighbors = []\n    for i in range(n):\n        distances = distance_matrix[i].copy()\n        distances[i] = np.inf  # Exclude self-loop\n        nearest_neighbors.append(np.argsort(distances)[:k_nearest])\n\n    # Calculate a centrality measure (degree of connectivity).\n    degree_centrality = np.sum(1 / (distance_matrix + 1e-9), axis=0)\n    degree_centrality = (degree_centrality - np.min(degree_centrality)) / (np.max(degree_centrality) - np.min(degree_centrality) + 1e-9) # Normalize to [0,1]\n\n    # Inverse distance factor\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n    inverse_distance = (inverse_distance - np.min(inverse_distance)) / (np.max(inverse_distance) - np.min(inverse_distance) + 1e-9)  # Normalize to [0,1]\n\n    # Combine factors: inverse distance, nearest neighbor rank, and centrality.\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Rank of j in i's nearest neighbors and vice versa\n                try:\n                    rank_i = np.where(nearest_neighbors[i] == j)[0][0] + 1  # Rank starts from 1\n                except IndexError:\n                    rank_i = k_nearest + 1 # Assign worst rank if not in top k\n\n                try:\n                    rank_j = np.where(nearest_neighbors[j] == i)[0][0] + 1\n                except IndexError:\n                    rank_j = k_nearest + 1\n\n                rank_factor = 1 / (rank_i + rank_j)\n\n                centrality_factor = (degree_centrality[i] + degree_centrality[j]) / 2 # Avg centrality\n\n                # Geometric mean of factors for robustness\n                heuristic_matrix[i, j] = (inverse_distance[i,j] * rank_factor * centrality_factor)**(1/3)\n\n                # Introduce a small diversification factor\n                heuristic_matrix[i, j] *= (1 + 0.01 * np.random.rand())\n\n    # Adaptive Sparsification\n    quantile_level = 0.75  # Adjust as needed - more aggressive sparsification\n    non_zero_values = heuristic_matrix[heuristic_matrix > 0]\n    threshold = np.quantile(non_zero_values, quantile_level) if non_zero_values.size > 0 else 0\n\n    heuristic_matrix[heuristic_matrix < threshold] = 0 #sparsify\n\n    # Row-wise normalization to avoid zero rows after sparsification\n    for i in range(n):\n        row_sum = np.sum(heuristic_matrix[i])\n        if row_sum > 0:\n            heuristic_matrix[i] = heuristic_matrix[i] / row_sum\n        else:\n            # Assign equal probability if all edges are zero after sparsification\n            heuristic_matrix[i] = np.ones(n) / n\n            heuristic_matrix[i,i] = 0 # Self loop should have zero probability\n\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP) using stochastic solution sampling principles.\n    This version combines several factors, including centrality measures and adaptive sparsification,\n    to estimate the \"promise\" of each edge and reduce the search space. It refines centrality using a geometric mean and degree centrality.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix between cities.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as the distance matrix, where each element indicates\n                      the heuristic promise of including that edge in the solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # Initialize the heuristic matrix\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate the inverse distance (closer is better)\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # Calculate row and column sums (representing how far away a node is on average from others)\n    row_sums = np.sum(distance_matrix, axis=1, keepdims=True)\n    col_sums = np.sum(distance_matrix, axis=0, keepdims=True)\n\n    # Normalize row and column sums - smaller row/col sums imply the node is more centrally located\n    row_normalized = 1 / (row_sums + 1e-9)\n    col_normalized = 1 / (col_sums + 1e-9)\n\n    # Combine these factors:\n    # 1. Inverse distance: Encourages shorter edges\n    # 2. Node centrality:  Encourages edges connected to centrally located nodes\n    heuristic_matrix = inverse_distance * np.sqrt(row_normalized * col_normalized)  # Geometric mean of normalized row/col sums\n\n    # Sparsification: set unpromising entries to zero to reduce the search space\n    # Adaptive threshold based on the distribution of heuristic values\n    flattened_heuristic = heuristic_matrix[np.triu_indices_from(heuristic_matrix, k=1)]\n    flattened_heuristic = flattened_heuristic[flattened_heuristic > 0]  # Consider only positive values\n\n    if len(flattened_heuristic) > 0:\n        threshold = np.quantile(flattened_heuristic, 0.25)  # 25th percentile as threshold\n        heuristic_matrix[heuristic_matrix < threshold] = 0  # sparsify\n\n    # Remove self-loops (diagonal elements)\n    np.fill_diagonal(heuristic_matrix, 0)\n\n    # Further enhance centrality using degree centrality approximation\n    degree_centrality = np.sum(heuristic_matrix > 0, axis=1)\n    degree_centrality_normalized = degree_centrality / (n - 1 + 1e-9) #avoid division by zero in case n==1\n\n    # Refine heuristic matrix using degree centrality\n    for i in range(n):\n        for j in range(n):\n            if heuristic_matrix[i, j] > 0:\n                heuristic_matrix[i, j] *= np.sqrt(degree_centrality_normalized[i] * degree_centrality_normalized[j])\n\n\n    # Re-apply sparsification after degree centrality boost\n\n    flattened_heuristic = heuristic_matrix[np.triu_indices_from(heuristic_matrix, k=1)]\n    flattened_heuristic = flattened_heuristic[flattened_heuristic > 0]\n\n    if len(flattened_heuristic) > 0:\n        threshold = np.quantile(flattened_heuristic, 0.25)\n        heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize heuristic matrix (optional, but can be helpful)\n    row_sums = np.sum(heuristic_matrix, axis=1, keepdims=True)\n    heuristic_matrix = np.where(row_sums > 0, heuristic_matrix / row_sums, heuristic_matrix)\n\n    return heuristic_matrix\n\n[Reflection]\nGeometric mean centrality, adaptive sparsification, and degree centrality refinement yield better heuristics. Normalization is crucial.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}