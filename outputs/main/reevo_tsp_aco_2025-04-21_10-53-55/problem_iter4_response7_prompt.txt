{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP) that combines\n    multiple factors to estimate the \"promise\" of including each edge in a solution.\n    This version incorporates local neighborhood density, tunable combination weights,\n    and careful normalization to avoid unintended side effects.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where element (i, j) represents\n                                      the distance between city i and city j.  It is\n                                      assumed that the diagonal elements are zero or very large\n                                      to discourage self-loops.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                      (i, j) indicates the desirability of including the edge (i, j) in\n                      the TSP tour. Higher values indicate more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse distance: Shorter distances are generally more desirable.\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero\n\n    # 2. Local neighborhood density:  Cities in denser areas are likely to have\n    #    more alternative paths.  Edges connecting to sparser areas are more crucial.\n    #    Calculate the average distance to the k nearest neighbors for each city.\n\n    k = min(5, n - 1)  # Consider up to the 5th nearest neighbor, or fewer if n is small\n    neighbor_densities = np.zeros(n)\n    for i in range(n):\n        distances = distance_matrix[i, :]\n        nearest_neighbors = np.partition(distances, k + 1)[1:k + 1]  # Exclude self (0th)\n        neighbor_densities[i] = np.mean(nearest_neighbors)  # Average dist to k nearest\n\n    density_influence = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            density_influence[i, j] = neighbor_densities[i] + neighbor_densities[j]\n\n    # 3. Combination and scaling: Combine the factors with tunable weights.\n    weight_distance = 0.6  # Weight for inverse distance\n    weight_density = 0.4  # Weight for density influence\n\n    heuristic_matrix = (weight_distance * inverse_distance +\n                        weight_density * (1 / (density_influence + 1e-9))) #Add constant to avoid zero division\n\n\n    # 4. Sparsification: Zero out edges that are very unlikely to be in the optimal tour\n    #    based on a threshold derived from the mean of the heuristic matrix. This promotes\n    #    exploration of more focused search spaces.\n\n    threshold = np.mean(heuristic_matrix) * 0.2  # Tune this threshold multiplier\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 5. Normalization: Normalize to [0, 1] *only if there are non-zero values*\n    #    and only *after* sparsification. This prevents small values from being\n    #    eliminated due to floating-point precision issues.\n\n    max_val = np.max(heuristic_matrix)\n    if max_val > 0:\n        heuristic_matrix = heuristic_matrix / max_val\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP) using stochastic solution sampling principles.\n    This version combines several factors to estimate the \"promise\" of each edge and sparsifies the resulting matrix.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix between cities.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as the distance matrix, where each element indicates\n                      the heuristic promise of including that edge in the solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # Initialize the heuristic matrix\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate the inverse distance (closer is better)\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # Calculate row and column sums (representing how far away a node is on average from others)\n    row_sums = np.sum(distance_matrix, axis=1, keepdims=True)\n    col_sums = np.sum(distance_matrix, axis=0, keepdims=True)\n\n    # Normalize row and column sums - smaller row/col sums imply the node is more centrally located\n    row_normalized = 1 / (row_sums + 1e-9)\n    col_normalized = 1 / (col_sums + 1e-9)\n\n    # Combine these factors:\n    # 1. Inverse distance: Encourages shorter edges\n    # 2. Node centrality:  Encourages edges connected to centrally located nodes\n    heuristic_matrix = inverse_distance * np.sqrt(row_normalized * col_normalized)  # Geometric mean of normalized row/col sums\n\n    #Sparsification: set unpromising entries to zero to reduce the search space\n    # Adaptive threshold based on the distribution of heuristic values\n    flattened_heuristic = heuristic_matrix[np.triu_indices_from(heuristic_matrix, k=1)]\n    if len(flattened_heuristic) > 0:\n        threshold = np.quantile(flattened_heuristic[flattened_heuristic > 0], 0.25)  # Consider only positive values for sparsification\n        heuristic_matrix[heuristic_matrix < threshold] = 0  # sparsify\n    # Remove self-loops (diagonal elements)\n    np.fill_diagonal(heuristic_matrix, 0)\n\n    return heuristic_matrix\n\n[Reflection]\nCentrality, adaptive sparsification, and geometric means often improve TSP heuristic performance.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}