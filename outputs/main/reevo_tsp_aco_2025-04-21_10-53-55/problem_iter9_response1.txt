```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for TSP using normalized inverse distance, geometric mean centrality,
    rank-based information, adaptive sparsification, and degree centrality refinement with row-wise processing.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as distance_matrix,
                     representing the heuristic values (prior indicators).
    """

    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # 1. Row and Column Normalization
    row_normalized = distance_matrix / (np.min(distance_matrix, axis=1, keepdims=True) + 1e-9)
    col_normalized = distance_matrix / (np.min(distance_matrix, axis=0, keepdims=True) + 1e-9)
    normalized_distance = (row_normalized + col_normalized) / 2

    # 2. Geometric Mean Centrality
    centrality = np.zeros(n)
    for i in range(n):
        centrality[i] = np.exp(np.mean(np.log(distance_matrix[i, :] + 1e-9)))
    centrality = 1 / (centrality + 1e-9)  # Inverse for centrality
    centrality = centrality / np.max(centrality)  # Normalize

    # 3. Rank-Based Information (Nearest Neighbors)
    nearest_neighbors = []
    for i in range(n):
        distances = distance_matrix[i].copy()
        distances[i] = np.inf  # Exclude self-loop
        nearest_neighbors.append(np.argsort(distances))

    # Combined factors
    for i in range(n):
        for j in range(n):
            if i != j:
                rank_i = np.where(nearest_neighbors[i] == j)[0][0]
                rank_j = np.where(nearest_neighbors[j] == i)[0][0]
                rank_factor = 1 / (rank_i + rank_j + 1)

                # Geometric Mean Centrality Factor
                centrality_factor = np.sqrt(centrality[i] * centrality[j])

                heuristic_matrix[i, j] = (1 / (normalized_distance[i, j] + 1e-9)) * rank_factor * centrality_factor

    # 4. Adaptive Sparsification (Connectivity Maintained)
    quantile_level = 0.7  # Adjust as needed
    threshold = np.quantile(heuristic_matrix[heuristic_matrix > 0], quantile_level)
    heuristic_matrix[heuristic_matrix < threshold] = 0

    # Ensure no zero rows or columns by adding back top 2 connections
    for i in range(n):
        row = heuristic_matrix[i, :].copy()
        top_indices = np.argsort(row)[-2:]  # Indices of two largest values

        if np.sum(heuristic_matrix[i, :]) == 0: #Zero row
            heuristic_matrix[i, top_indices[0]] = 0.01 # assign very small values
            heuristic_matrix[i, top_indices[1]] = 0.01
        
    # 5. Degree Centrality Refinement and Row-wise Normalization
    degree_centrality = np.sum(heuristic_matrix, axis=0)
    degree_centrality = degree_centrality / (np.max(degree_centrality) + 1e-9)

    for i in range(n):
        heuristic_matrix[i, :] = heuristic_matrix[i, :] * degree_centrality  # Refine with degree centrality
        row_sum = np.sum(heuristic_matrix[i, :])
        if row_sum > 0:
            heuristic_matrix[i, :] = heuristic_matrix[i, :] / row_sum

    return heuristic_matrix
```
