```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for TSP using node ranking, centrality, adaptive sparsification,
    geometric mean centrality and rank-based information. Emphasizes normalization and parameter tuning.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as distance_matrix,
                     representing the heuristic values (prior indicators).
    """

    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Calculate nearest neighbors for each node.
    nearest_neighbors = []
    for i in range(n):
        distances = distance_matrix[i].copy()
        distances[i] = np.inf  # Exclude self-loop
        nearest_neighbors.append(np.argsort(distances))

    # Calculate degree centrality
    degree_centrality = np.sum(1 / (distance_matrix + 1e-9), axis=0)
    degree_centrality = degree_centrality / np.max(degree_centrality)  # Normalize

    # Calculate geometric mean centrality
    geo_mean_centrality = np.power(np.prod(1 / (distance_matrix + 1e-9), axis=0), 1/n)
    geo_mean_centrality = geo_mean_centrality / np.max(geo_mean_centrality)

    # Inverse distance
    inverse_distance = 1 / (distance_matrix + 1e-9)
    inverse_distance = inverse_distance / np.max(inverse_distance)  # Normalize

    # Rank based information
    rank_matrix = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                rank_i = np.where(nearest_neighbors[i] == j)[0][0]
                rank_j = np.where(nearest_neighbors[j] == i)[0][0]
                rank_matrix[i, j] = 1 / (rank_i + rank_j + 1)
    rank_matrix = rank_matrix / np.max(rank_matrix) # Normalize

    # Combine factors: inverse distance, rank, degree and geometric mean centrality
    alpha = 0.4 # Weight for inverse distance
    beta = 0.3 # Weight for rank
    gamma = 0.15 # Weight for degree centrality
    delta = 0.15 # Weight for geometric mean centrality

    for i in range(n):
        for j in range(n):
            if i != j:
                heuristic_matrix[i, j] = (alpha * inverse_distance[i, j]
                                           + beta * rank_matrix[i, j]
                                           + gamma * (0.5 * degree_centrality[i] + 0.5 * degree_centrality[j])
                                           + delta * (0.5 * geo_mean_centrality[i] + 0.5 * geo_mean_centrality[j]))

    # Adaptive Sparsification
    quantile_level = 0.6  # Adjust as needed. Lower values leads to more sparse matrices.
    threshold = np.quantile(heuristic_matrix[heuristic_matrix > 0], quantile_level)
    heuristic_matrix[heuristic_matrix < threshold] = 0

    # Row-wise normalization
    for i in range(n):
        row_sum = np.sum(heuristic_matrix[i])
        if row_sum > 0:
            heuristic_matrix[i] = heuristic_matrix[i] / row_sum

    return heuristic_matrix
```
