```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) that combines
    multiple factors to estimate the "promise" of including each edge in a solution.
    This version focuses on neighborhood density, implicitly avoids hub nodes, and
    normalizes heuristics for robust sampling.

    Args:
        distance_matrix (np.ndarray): A square matrix where element (i, j) represents
                                      the distance between city i and city j.  It is
                                      assumed that the diagonal elements are zero or very large
                                      to discourage self-loops.

    Returns:
        np.ndarray: A matrix of the same shape as distance_matrix, where each element
                      (i, j) indicates the desirability of including the edge (i, j) in
                      the TSP tour. Higher values indicate more promising edges.
    """

    n = distance_matrix.shape[0]

    # 1. Inverse distance: Shorter distances are generally more desirable.
    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero

    # 2. Neighborhood density:  Encourage edges connecting to less dense areas.
    #    Calculate the average distance to the k nearest neighbors for each city.
    #    Cities in sparser areas will have larger average nearest neighbor distances.
    k = min(5, n - 1)  # Consider up to the 5th nearest neighbor, or fewer if n is small
    avg_neighbor_distances = np.zeros(n)
    for i in range(n):
        distances = distance_matrix[i, :]
        nearest_neighbor_distances = np.partition(distances, k + 1)[1:k + 1] # Exclude self-loop (distance=0)
        avg_neighbor_distances[i] = np.mean(nearest_neighbor_distances)

    neighbor_density_factor = np.zeros_like(distance_matrix)
    for i in range(n):
        for j in range(n):
            neighbor_density_factor[i, j] = avg_neighbor_distances[i] + avg_neighbor_distances[j]

    # 3. Implicit Hub Avoidance: Penalize edges if either node has many close neighbors.
    hub_penalty = np.zeros_like(distance_matrix)
    degree_threshold = np.median(distance_matrix[distance_matrix>0]) #Dynamic Threshold
    for i in range(n):
        for j in range(n):
              degree_i = np.sum(distance_matrix[i, :] < degree_threshold)
              degree_j = np.sum(distance_matrix[j, :] < degree_threshold)
              hub_penalty[i,j] = (degree_i + degree_j)

    # 4. Combination and scaling: Combine the factors with adjusted weights
    # Adaptive Weighting
    alpha = 0.6  # Weight for inverse distance
    beta = 0.3   # Weight for neighbor density
    gamma = 0.1  # Weight for hub penalty

    heuristic_matrix = alpha * inverse_distance + beta * neighbor_density_factor - gamma * hub_penalty

    # 5. Sparsification: Zero out edges that are very unlikely to be in the optimal tour
    #    based on a threshold derived from the mean of the heuristic matrix. This promotes
    #    exploration of more focused search spaces.

    threshold = np.mean(heuristic_matrix) * 0.2  # Tune this threshold multiplier
    heuristic_matrix[heuristic_matrix < threshold] = 0

    # 6. Normalize the matrix to have values between 0 and 1.
    max_val = np.max(heuristic_matrix)
    if max_val > 0:
        heuristic_matrix = heuristic_matrix / max_val

    return heuristic_matrix
```
