{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    Random Fit: choose a bin at random among those that can fit the item.\n    We add a weighted random component to prioritize bins with less free space.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if np.any(fit):\n        remaining = bins_remain_cap[fit] - item\n        eps = 1e-6\n        weights = 1.0 / (remaining + eps)\n        random_vals = np.random.rand(np.count_nonzero(fit))\n        priorities[fit] = weights * random_vals\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    mask = bins_remain_cap >= item\n    if not np.any(mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    residual = bins_remain_cap - item\n    temperature = 1.0\n    raw = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    raw[mask] = -residual[mask] / temperature\n    max_raw = np.max(raw[mask])\n    exp_raw = np.exp(raw - max_raw)\n    sum_exp = np.sum(exp_raw)\n    if sum_exp == 0:\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    priorities = exp_raw / sum_exp\n    return priorities\n\n### Analyze & experience\n- - **(best) vs (worst):** *Heuristic\u202f1* uses a random weighted score\u202f`1/(remaining+\u03b5)` and masks infeasible bins with `-inf`, encouraging tight fits while preserving diversity. *Heuristic\u202f20* simply returns the bin\u2019s remaining capacity for feasible bins (worst\u2011fit) and `-inf` otherwise, deterministically choosing the most empty bin \u2013 a strategy that typically degrades packing quality.  \n- **(second best) vs (second worst):** *Heuristic\u202f2* is identical to\u202f1, while *Heuristic\u202f19* mirrors\u202f20; the same conclusions apply.  \n- **(1st) vs (2nd):** Both functions are byte\u2011for\u2011byte copies; the ranking difference likely reflects perceived robustness rather than functional change.  \n- **(3rd) vs (4th):** Again identical code; no observable distinction.  \n- **(second worst) vs (worst):** *Heuristic\u202f19* and *Heuristic\u202f20* are identical implementations, showing the list contains duplicate entries.  \n\n*Intermediate observations*:  \n- *Heuristic\u202f8* applies a sigmoid on normalized residuals, offering a smooth deterministic bias toward tighter fits.  \n- *Heuristics\u202f9\u201112* use a simple linear negative leftover (`- (capacity\u2011item)`) with `-inf` masking, a deterministic best\u2011fit approach.  \n- *Heuristics\u202f13\u201115* compute a softmax over `-residual`, yielding probabilistic selection with proper numeric stabilization (`max_raw` subtraction).  \n- *Heuristic\u202f16* repeats the linear negative leftover with `-inf` masking.  \n- *Heuristic\u202f17* uses a logistic function on normalized leftover, introducing tunable thresholds (`thresh`, `scale`).  \n- *Heuristics\u202f18\u201120* adopt a worst\u2011fit policy, directly favoring bins with the most free space.  \n\nOverall, the top\u2011ranked heuristics blend stochasticity with a bias toward tight packing and robust infeasibility handling; mid\u2011ranked methods progressively shift toward deterministic or smoother probabilistic schemes; the lowest rank adopts a counter\u2011productive worst\u2011fit strategy.\n- \n- **Keywords**: stochastic bias, tight\u2011fit, \u2013inf masking, epsilon stabilization, sigmoid/softmax, adaptive randomness.  \n- **Advice**: Use adaptive probability distributions for bin selection, gradually tighten fit constraints, incorporate learning rates for mask thresholds, and blend deterministic with probabilistic moves.  \n- **Avoid**: Fixed deterministic worst\u2011fit, static masks, overly aggressive tightening that causes infeasibility, and ignoring numerical precision.  \n- **Explanation**: Adaptive stochasticity keeps solution diversity while steering toward tight packs; dynamic masks and smooth transforms prevent overflow/underflow and preserve feasibility.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}