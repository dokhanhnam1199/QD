{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    Random Fit: choose a bin at random among those that can fit the item.\n    We add a weighted random component to prioritize bins with less free space.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if np.any(fit):\n        remaining = bins_remain_cap[fit] - item\n        eps = 1e-6\n        weights = 1.0 / (remaining + eps)\n        random_vals = np.random.rand(np.count_nonzero(fit))\n        priorities[fit] = weights * random_vals\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    Random Fit: choose a bin at random among those that can fit the item.\n    We add a weighted random component to prioritize bins with less free space.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if np.any(fit):\n        remaining = bins_remain_cap[fit] - item\n        eps = 1e-6\n        weights = 1.0 / (remaining + eps)\n        random_vals = np.random.rand(np.count_nonzero(fit))\n        priorities[fit] = weights * random_vals\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                min_priority: float = -950042335873.0067,\n                eps: float = 0.000436714846983465,\n                weight: float = 9.093301174060638) -> np.ndarray:\n    priorities = np.full_like(bins_remain_cap, min_priority, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if np.any(fit):\n        remaining = bins_remain_cap[fit] - item\n        weights = weight / (remaining + eps)\n        random_vals = np.random.rand(np.count_nonzero(fit))\n        priorities[fit] = weights * random_vals\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine inverse residual, linear bias, variance\u2011scaled jitter and uniform randomness for online BPP.\"\"\"\n    if bins_remain_cap.size == 0:\n        return np.empty(0, dtype=np.float64)\n    eps = 1e-12\n    fit = bins_remain_cap >= item\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=np.float64)\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    inv_weight = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max()\n    bias = 1.0 - remaining / (max_rem + eps)  # bias towards larger bins\n    var_factor = np.clip(np.std(remaining) / (np.mean(remaining) + eps), 0.0, 1.0)\n    jitter = var_factor * (np.random.rand(remaining.size) - 0.5)\n    rand_factor = np.random.rand(remaining.size)\n    priorities[fit] = inv_weight * bias * (1.0 + jitter) * rand_factor\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine inverse residual, linear bias, variance\u2011scaled jitter and uniform randomness for online BPP.\"\"\"\n    if bins_remain_cap.size == 0:\n        return np.empty(0, dtype=np.float64)\n    eps = 1e-12\n    fit = bins_remain_cap >= item\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=np.float64)\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    inv_weight = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max()\n    bias = 1.0 - remaining / (max_rem + eps)  # bias towards larger bins\n    var_factor = np.clip(np.std(remaining) / (np.mean(remaining) + eps), 0.0, 1.0)\n    jitter = var_factor * (np.random.rand(remaining.size) - 0.5)\n    rand_factor = np.random.rand(remaining.size)\n    priorities[fit] = inv_weight * bias * (1.0 + jitter) * rand_factor\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    available = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if available.any():\n        priorities[available] = -(bins_remain_cap[available] - item)\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes tight fits with inverse remaining capacity, a two\u2011step sigmoid bias toward bins with small residuals, and modest random jitter.\"\"\"\n    eps = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    inv_weight = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max() + eps\n    norm_rem = remaining / max_rem\n    k1 = 20.0\n    exp_term1 = np.exp(np.clip(k1 * (norm_rem - 0.1), -50, 50))\n    weight1 = 1.0 / (1.0 + exp_term1)\n    k2 = 8.0\n    exp_term2 = np.exp(np.clip(k2 * (norm_rem - 0.1), -50, 50))\n    weight2 = 1.0 / (1.0 + exp_term2)\n    combined_weight = weight1 * weight2\n    rand = np.random.rand(remaining.shape[0])\n    combined = inv_weight * combined_weight * (1 + 0.1 * rand)\n    priorities[fit] = combined\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    available = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if available.any():\n        priorities[available] = -(bins_remain_cap[available] - item)\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    eps = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    weight1 = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max() + eps\n    norm_left = remaining / max_rem\n    thresh = 0.2\n    scale = 0.05\n    weight2 = 1.0 / (1.0 + np.exp((norm_left - thresh) / scale))\n    random_vals = np.random.rand(np.count_nonzero(fit))\n    combined = weight1 * weight2 * (1 + 0.1 * random_vals)\n    priorities[fit] = combined\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    available = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if available.any():\n        priorities[available] = -(bins_remain_cap[available] - item)\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    eps = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    weight1 = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max() + eps\n    norm_left = remaining / max_rem\n    thresh = 0.2\n    scale = 0.05\n    weight2 = 1.0 / (1.0 + np.exp((norm_left - thresh) / scale))\n    random_vals = np.random.rand(np.count_nonzero(fit))\n    combined = weight1 * weight2 * (1 + 0.1 * random_vals)\n    priorities[fit] = combined\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    residual = bins_remain_cap - item\n    mask = residual >= 0\n    cap = bins_remain_cap.max() if bins_remain_cap.size else 0.0\n    if cap <= 0:\n        return np.zeros_like(bins_remain_cap)\n    norm_res = residual / cap\n    k = 12.0\n    offset = 0.15\n    raw_score = 1.0 / (1.0 + np.exp(k * (norm_res - offset)))\n    return raw_score * mask\n\n[Heuristics 13th]\nimport numpy as np\n\n# Hybrid priority: tight-fit weight, sigmoid scaling, and random perturbation.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine 1/(remaining+\u03b5) weight, sigmoid of normalized residual, and small random factor.\"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    eps = 1e-12\n    weight = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max() if bins_remain_cap.size else 1.0\n    normalized = remaining / (max_rem + eps)\n    k = 12.0\n    offset = 0.2\n    sigmoid = 1.0 / (1.0 and 1.0 + np.exp(k * (normalized - offset)))  # sigmoid bias toward tight fit\n    beta = 0.2\n    random_factor = 1.0 + beta * (np.random.rand(remaining.shape[0]) - 0.5)\n    priorities[fit] = weight * sigmoid * random_factor\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\n# Hybrid priority: tight-fit weight, sigmoid scaling, and random perturbation.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine 1/(remaining+\u03b5) weight, sigmoid of normalized residual, and small random factor.\"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    eps = 1e-12\n    weight = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max() if bins_remain_cap.size else 1.0\n    normalized = remaining / (max_rem + eps)\n    k = 12.0\n    offset = 0.2\n    sigmoid = 1.0 / (1.0 and 1.0 + np.exp(k * (normalized - offset)))  # sigmoid bias toward tight fit\n    beta = 0.2\n    random_factor = 1.0 + beta * (np.random.rand(remaining.shape[0]) - 0.5)\n    priorities[fit] = weight * sigmoid * random_factor\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\n# Hybrid priority: tight-fit weight, sigmoid scaling, and random perturbation.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine 1/(remaining+\u03b5) weight, sigmoid of normalized residual, and small random factor.\"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    fit = bins_remain_cap >= item\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    eps = 1e-12\n    weight = 1.0 / (remaining + eps)\n    max_rem = bins_remain_cap.max() if bins_remain_cap.size else 1.0\n    normalized = remaining / (max_rem + eps)\n    k = 12.0\n    offset = 0.2\n    sigmoid = 1.0 / (1.0 and 1.0 + np.exp(k * (normalized - offset)))  # sigmoid bias toward tight fit\n    beta = 0.2\n    random_factor = 1.0 + beta * (np.random.rand(remaining.shape[0]) - 0.5)\n    priorities[fit] = weight * sigmoid * random_factor\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    fit = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64) if bins_remain_cap.dtype != np.float64 else np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    if not np.any(fit):\n        return priorities\n    remaining = bins_remain_cap[fit] - item\n    eps = 1e-9\n    inv_weight = 1.0 / (remaining + eps)\n    cap = bins_remain_cap.max()\n    norm_rem = remaining / cap if cap > 0 else remaining\n    k = 10.0\n    offset = 0.1\n    exp_term = np.exp(np.clip(k * (norm_rem - offset), -50, 50))\n    sigmoid = 1.0 / (1.0 + exp_term)\n    rand = np.random.rand(remaining.shape[0])\n    priorities[fit] = inv_weight * sigmoid * rand\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\n# Combined inverse\u2011residual weighting, small capacity bonus, and jitter.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse residual, a tiny larger\u2011bin bonus, and jitter.\"\"\"\n    feasible = bins_remain_cap >= item\n    remaining = bins_remain_cap - item\n    weight = np.where(\n        feasible,\n        np.where(remaining > 0, 1.0 / remaining, 1e9),\n        0.0,\n    )\n    bias = np.where(feasible, 0.001 * bins_remain_cap, 0.0)\n    jitter = weight * np.random.rand(*bins_remain_cap.shape) * 0.005\n    return weight + bias + jitter\n\n[Heuristics 18th]\nimport numpy as np\n\n# Combined inverse\u2011residual weighting, small capacity bonus, and jitter.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse residual, a tiny larger\u2011bin bonus, and jitter.\"\"\"\n    feasible = bins_remain_cap >= item\n    remaining = bins_remain_cap - item\n    weight = np.where(\n        feasible,\n        np.where(remaining > 0, 1.0 / remaining, 1e9),\n        0.0,\n    )\n    bias = np.where(feasible, 0.001 * bins_remain_cap, 0.0)\n    jitter = weight * np.random.rand(*bins_remain_cap.shape) * 0.005\n    return weight + bias + jitter\n\n[Heuristics 19th]\nimport numpy as np\n\n# Combined inverse\u2011residual weighting, small capacity bonus, and jitter.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse residual, a tiny larger\u2011bin bonus, and jitter.\"\"\"\n    feasible = bins_remain_cap >= item\n    remaining = bins_remain_cap - item\n    weight = np.where(\n        feasible,\n        np.where(remaining > 0, 1.0 / remaining, 1e9),\n        0.0,\n    )\n    bias = np.where(feasible, 0.001 * bins_remain_cap, 0.0)\n    jitter = weight * np.random.rand(*bins_remain_cap.shape) * 0.005\n    return weight + bias + jitter\n\n[Heuristics 20th]\nimport numpy as np\n\n# Combined inverse\u2011residual weighting, small capacity bonus, and jitter.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse residual, a tiny larger\u2011bin bonus, and jitter.\"\"\"\n    feasible = bins_remain_cap >= item\n    remaining = bins_remain_cap - item\n    weight = np.where(\n        feasible,\n        np.where(remaining > 0, 1.0 / remaining, 1e9),\n        0.0,\n    )\n    bias = np.where(feasible, 0.001 * bins_remain_cap, 0.0)\n    jitter = weight * np.random.rand(*bins_remain_cap.shape) * 0.005\n    return weight + bias + jitter\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}