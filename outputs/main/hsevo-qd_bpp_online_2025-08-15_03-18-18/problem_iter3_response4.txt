```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Calculates priority scores for each bin using an adaptive strategy for the
    online Bin Packing Problem. This version aims to balance fitting tightly
    (Best Fit) with spreading items (Worst Fit) and incorporating an element
    of exploration.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array where each element represents the
                         remaining capacity of a bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        is the priority score for placing the item in the corresponding bin.
    """
    valid_bins_mask = bins_remain_cap >= item
    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    if valid_bins_remain_cap.size == 0:
        return np.zeros_like(bins_remain_cap)

    # --- Core Strategy: Balancing Best Fit and Worst Fit ---
    # Best Fit component: Prioritize bins that leave minimal remaining space.
    # We want to minimize (remaining_capacity - item).
    # A good score for BF would be proportional to -(remaining_capacity - item).
    # For Softmax, we want higher scores for better options. So, let's use
    # a score that increases as remaining_capacity - item decreases.
    # A simple inversion: 1 / (remaining_capacity - item + epsilon)
    # Or, to keep it related to the previous approach: maximize -(remaining_capacity - item)
    # To promote diversification, let's also consider the "emptiness" of the bin.
    # Worst Fit component: Prioritize bins with *more* remaining capacity.
    # This encourages spreading items.
    # A score for WF could be proportional to remaining_capacity.

    # Let's create a blended score.
    # For Best Fit: prioritize small remaining capacity after placing the item.
    # For Worst Fit: prioritize large initial remaining capacity.
    # We want to maximize the utility.
    # Let's consider the utility as a function of remaining capacity:
    # utility = alpha * (1 / (valid_bins_remain_cap - item + 1e-9)) + beta * valid_bins_remain_cap

    # For simplicity and to adapt the softmax approach, let's define scores
    # where higher means more desirable.
    # High score for small (remaining_capacity - item) => Best Fit tendency
    # High score for large remaining_capacity => Worst Fit tendency (for exploration/diversification)

    # Let's try a score that is a combination:
    # Score = (large_capacity_bonus) * (remaining_capacity) - (misfit_penalty) * (remaining_capacity - item)
    # A simpler approach:
    # Prioritize bins where remaining_capacity - item is small (BF)
    # BUT, also give a boost to bins that are "more open" (WF) to avoid early convergence.

    # Let's combine the ideas:
    # We want to favor small (remaining_capacity - item).
    # Let's define a score for "tightness": TightnessScore = -(valid_bins_remain_cap - item)
    # And a score for "openness": OpennessScore = valid_bins_remain_cap

    # We can create a combined score, for example, by averaging or taking a weighted sum.
    # A more robust approach is to introduce a "temperature" or "exploration factor"
    # that modulates the influence of the Best Fit vs. Worst Fit tendencies.

    # Let's try a score that is a compromise. We want to minimize (remaining_capacity - item).
    # Let's use a function that is high when (remaining_capacity - item) is small.
    # Consider a function like: `exp(-k * (remaining_capacity - item))`
    # `k` can be an exploration parameter. A large `k` makes it more like Best Fit.
    # A small `k` makes it flatter, more exploratory.

    # To balance exploration and exploitation, let's make the "tightness" score
    # have an exploratory element.
    # Let's use a score that is high for bins that are "good" fits, but also
    # has some preference for bins that aren't *too* full if an exact fit isn't available.

    # --- Adaptive Exploration/Exploitation ---
    # We can adapt the strength of the "Best Fit" tendency based on the distribution of remaining capacities.
    # If capacities are very diverse, lean more towards Best Fit.
    # If capacities are very similar, lean more towards diversification.

    # A simple adaptation: Use a parameter `epsilon` that smooths the selection.
    # Larger epsilon makes it more uniform (exploratory). Smaller epsilon makes it more greedy (exploitative).
    # We can define epsilon based on the variance of remaining capacities.
    variance_remain_cap = np.var(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0
    # Scale variance to a reasonable epsilon range. Higher variance -> higher epsilon for more exploration.
    epsilon = 0.1 + 0.5 * (1 / (1 + np.exp(-0.1 * variance_remain_cap))) # Sigmoid to bound epsilon

    # Calculate scores:
    # Score for "good fit" (lower remaining_capacity - item is better)
    # Using a negative exponential for a sharp decrease in score as misfit increases.
    # Adding epsilon for numerical stability and exploration.
    goodness_of_fit_scores = np.exp(-10.0 * (valid_bins_remain_cap - item) / (item + 1e-9)) # Scale by item size

    # Score for "openness" (higher remaining_capacity is better for spreading)
    # Using a scaled exponential to give a significant boost to very open bins.
    openness_scores = np.exp(0.1 * valid_bins_remain_cap / (np.max(bins_remain_cap) + 1e-9)) # Scale by max capacity

    # Combine scores using epsilon for adaptive weighting
    # When epsilon is high (diverse capacities), openness_scores have more weight.
    # When epsilon is low (similar capacities), goodness_of_fit_scores have more weight.
    combined_scores = (1 - epsilon) * goodness_of_fit_scores + epsilon * openness_scores

    # Softmax transformation to get priorities
    # Shift scores to prevent overflow/underflow before exponentiation
    shifted_scores = combined_scores - np.max(combined_scores)
    exp_scores = np.exp(shifted_scores)
    probabilities = exp_scores / np.sum(exp_scores)

    # Create the final priority array
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    priorities[valid_bins_mask] = probabilities

    return priorities
```
