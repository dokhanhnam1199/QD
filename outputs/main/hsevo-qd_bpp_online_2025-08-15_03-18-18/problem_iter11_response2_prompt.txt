{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Calculates priority scores for each bin using an adaptive Softmax-Based Fit strategy\n    for the online Bin Packing Problem.\n\n    This strategy aims to improve upon v1 by:\n    1. Incorporating an adaptive scaling factor to balance exploration (trying less\n       optimal bins) and exploitation (fitting into the best available bins).\n    2. Handling near-perfect fits more explicitly to avoid unnecessary fragmentation.\n    3. Using a more robust score calculation that considers the inverse of remaining\n       capacity to better differentiate between bins, especially when items are small.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    # --- Adaptive Scoring Mechanism ---\n    # We want to assign higher priorities to bins that are good fits.\n    # A \"good fit\" means the remaining capacity after placing the item is small.\n    # The value (bins_remain_cap - item) represents the slack. We want to minimize this slack.\n    # Using 1 / (slack + epsilon) can work, but can be sensitive to small slacks.\n    # A better approach is to use a function that is high for small slacks and decreases.\n    # Consider the \"waste\" or \"difference\" from a perfect fit:\n    # A perfect fit would have remaining_capacity == item.\n    # Let's define a score related to the 'badness' of the fit.\n    # A very small positive slack is good. A large slack is bad.\n    # Score: - (remaining_capacity - item) - we want to maximize this, so smaller remaining is better.\n\n    # To make it adaptive, let's introduce a \"preference\" or \"temperature\" parameter\n    # that controls how much we favor the best fit vs. exploring other options.\n    # A higher 'beta' will make the distribution sharper (more greedy),\n    # a lower 'beta' will make it flatter (more exploratory).\n    # We can make beta dependent on the item size or the distribution of bin capacities.\n    # For simplicity, let's start with an inverse relationship to the average slack.\n    # This encourages exploration when slacks are generally large, and exploitation when slacks are small.\n\n    # Calculate slack for valid bins\n    slacks = valid_bins_remain_cap - item\n\n    # Calculate an adaptive beta.\n    # If average slack is small, we want to be more greedy (higher beta).\n    # If average slack is large, we want to explore more (lower beta).\n    # We can use 1 / (mean_slack + small_constant) or a similar inverse relationship.\n    mean_slack = np.mean(slacks)\n    # Add a small epsilon to avoid division by zero if all slacks are zero\n    epsilon = 1e-9\n    # Scale beta to avoid extremely sharp or flat distributions from raw inverse.\n    # A scaling factor can be tuned. Let's use a modest scaling.\n    beta = 1.0 / (mean_slack + epsilon)\n    beta = np.clip(beta, 0.1, 10.0) # Clamp beta to a reasonable range\n\n    # Softmax preparation:\n    # We want to maximize the \"goodness\" of fit. Goodness is inversely related to slack.\n    # A very small slack is highly desirable. A slightly larger slack is less desirable.\n    # A large slack is undesirable.\n    # Let's use a transformed score that is high for small slacks.\n    # Example: -slack, or 1/(slack + epsilon), or a sigmoid-like function of slack.\n    # Using -slack directly as in v1 is a good start.\n    # To make it more nuanced, consider a score that penalizes larger slacks more heavily.\n    # A transformation like exp(-k * slack) or a polynomial might be considered,\n    # but let's refine the base score and apply beta.\n\n    # Base scores: favor bins with smaller slacks.\n    # Negative slack means perfect or near-perfect fit.\n    # Positive slack means some remaining capacity.\n    # We want to maximize `goodness`.\n    # A good measure of goodness is minimizing `slack`.\n    # So, let's use `-slack` as a base score. Higher values are better.\n    base_scores = -slacks\n\n    # Handle near-perfect fits more explicitly:\n    # If slack is very close to zero (e.g., < 1% of item size or a small absolute threshold),\n    # give these bins a significant boost. This encourages using bins that are almost full.\n    near_perfect_fit_threshold = 0.01 * item + epsilon\n    near_perfect_mask = slacks < near_perfect_fit_threshold\n    # Add a bonus to near-perfect fits. The magnitude of the bonus should be substantial\n    # to dominate the beta-scaled scores but not so large to always pick them if they are few.\n    bonus = 10.0\n    base_scores[near_perfect_mask] += bonus\n\n    # Apply the adaptive beta to the base scores for Softmax\n    # The beta controls the \"sharpness\" of the probability distribution.\n    # Higher beta means probabilities concentrate on bins with higher base scores.\n    # Lower beta means probabilities are more spread out.\n    scaled_scores = beta * base_scores\n\n    # Apply Softmax\n    # Shift scores to prevent overflow/underflow issues with exp()\n    max_scaled_score = np.max(scaled_scores)\n    exp_scores = np.exp(scaled_scores - max_scaled_score)\n    sum_exp_scores = np.sum(exp_scores)\n\n    if sum_exp_scores == 0:\n        # This can happen if all scaled_scores are extremely negative.\n        # In such a case, distribute probability evenly among valid bins.\n        probabilities = np.ones_like(valid_bins_remain_cap) / len(valid_bins_remain_cap)\n    else:\n        probabilities = exp_scores / sum_exp_scores\n\n    # Construct the final priority array\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    effective_capacities = bins_remain_cap[valid_bins] - item\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = np.exp(effective_capacities)\n    \n    if np.sum(priorities) == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    return priorities / np.sum(priorities)\n\n### Analyze & experience\n- Comparing Heuristics 1 and 2: Heuristic 2 introduces an \"adaptive diversification\" component based on the variance of remaining capacities. This is a more sophisticated attempt at balancing exploration and exploitation than Heuristic 1's fixed diversification bonus.\n\nComparing Heuristics 2 and 3: Heuristic 3 refines the adaptive strategy by making the \"beta\" parameter (controlling Softmax sharpness) adaptive to the mean slack. It also explicitly handles near-perfect fits with a bonus, which is a valuable addition for reducing fragmentation.\n\nComparing Heuristics 3 and 4: Heuristic 4 introduces a \"penalty for overly full bins\" and a stronger \"bonus for perfect fits\" using a scaled sigmoid. It's more complex than Heuristic 3's adaptive beta but might over-penalize tight fits.\n\nComparing Heuristics 4 and 5: Heuristic 5 is a basic \"Softmax-Based Fit\" and lacks the adaptive or penalty mechanisms of Heuristics 3 and 4. It's a good baseline but less sophisticated.\n\nComparing Heuristics 5 and 6: Heuristic 6 is very similar to Heuristic 5, essentially a cleaner implementation of Softmax-Based Fit with slightly better handling of edge cases (e.g., all scores being identical).\n\nComparing Heuristics 6 and 7: Heuristic 7 introduces a \"perfect fit bonus\" and uses \"inverse proximity\" for non-perfect fits. This is simpler than Heuristic 3's adaptive beta but explicitly rewards perfect fits, which is beneficial. However, its scaling might be less nuanced than Heuristic 3's adaptive beta.\n\nComparing Heuristics 7 and 19: Heuristic 19 attempts a more complex balance between \"Best Fit\" and \"Worst Fit\" using an adaptive `epsilon` based on variance. This is a sophisticated attempt at balancing exploration and exploitation. Heuristic 7's \"perfect fit bonus\" is more direct.\n\nComparing Heuristics 19 and 20: Heuristics 19 and 20 are identical.\n\nComparing Heuristics 2 and 10: Heuristic 10 combines \"Best Fit\" with a \"diversification bonus\" proportional to remaining capacity, aiming to balance fitting tightly and spreading items. This is a more direct approach to diversification than Heuristic 2's variance-based method.\n\nComparing Heuristics 10 and 11-15: Heuristics 11-15 are all very similar, implementing a basic \"inverse remaining capacity\" heuristic, often without Softmax normalization or sophisticated adaptive strategies. They are simple but potentially less robust than Softmax-based approaches.\n\nComparing Heuristics 11-15 and 16-18: Heuristics 16-18 use `np.exp(effective_capacities)` which is essentially a form of Softmax but without explicit negative scaling for Best Fit. This might prioritize larger remaining capacities too much.\n\nOverall: Heuristics that dynamically adjust parameters (like beta or epsilon) based on the current state (variance, slack) and explicitly handle \"perfect fits\" tend to be better. The complexity in Heuristics 3, 4, and 19/20 suggests a trend towards more adaptive and nuanced scoring. Simple inversions (Heuristics 11-15) are generally less effective.\n- \nHere's a redefined \"Current Self-Reflection\" focused on designing better heuristics:\n\n*   **Keywords:** Adaptive Parameters, Hybridization, Reward Structures, Numerical Stability.\n*   **Advice:** Design adaptive strategies that dynamically tune parameters based on problem characteristics (e.g., variance, resource slack) to balance exploitation and exploration. Integrate hybrid selection mechanisms that combine greedy \"best fit\" with probabilistic diversification.\n*   **Avoid:** Overly simple scoring, ignoring perfect fits, fragile parameter tuning, and neglecting numerical precision.\n*   **Explanation:** This approach emphasizes sophisticated, state-aware adaptation and balanced selection, drawing from robust techniques like Softmax and explicitly valuing efficient solutions (perfect fits) while ensuring computational reliability.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}