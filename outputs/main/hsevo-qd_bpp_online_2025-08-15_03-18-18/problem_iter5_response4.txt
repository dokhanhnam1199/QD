```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with a penalty for overly full bins and explicit perfect fit reward.
    Prioritizes bins that fit the item well, penalizes excessive remaining space,
    and gives a strong boost to perfect fits before Softmax normalization.
    """
    valid_bins_mask = bins_remain_cap >= item
    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    if valid_bins_remain_cap.size == 0:
        return np.zeros_like(bins_remain_cap)

    # Base score: Prioritize bins that leave less remaining space (Best Fit).
    # Maximize (item - remaining_capacity_after_fit), equivalent to minimize (remaining_capacity_after_fit).
    # Use negative remaining capacity after fit as a base score for maximization.
    base_scores = -(valid_bins_remain_cap - item)

    # Add bonus for perfect fits
    perfect_fit_bonus = 0.5  # A significant bonus
    perfect_fit_mask = (valid_bins_remain_cap - item) < 1e-9
    base_scores[perfect_fit_mask] += perfect_fit_bonus

    # Add a slight penalty for bins that would become "too empty" after fitting.
    # This encourages using bins that are already somewhat full.
    # For example, if remaining_cap - item > threshold, subtract a penalty.
    # Let's define "too empty" as having more than 75% of the original bin capacity remaining
    # after the item is placed. This is a tunable parameter.
    too_empty_threshold_ratio = 0.75
    original_bin_capacities = bins_remain_cap[valid_bins_mask] # This assumes we know original bin sizes, which we don't have directly.
    # A proxy: Penalize if remaining_cap - item is large relative to the item size itself,
    # or relative to the original bin capacity if we had it.
    # Let's use a penalty if the remaining space after fitting is large relative to the bin's *current* capacity.
    # This might be problematic if current capacity is very small.
    # A simpler approach is to penalize based on the resulting 'waste' if the fit is not tight.
    # Let's penalize bins where `remaining_cap - item` is large.
    # We want to *minimize* this value. So, we add a penalty to the score if it's large.
    # This means subtracting a positive value from the score if `remaining_cap - item` is large.
    large_remaining_penalty_factor = 0.1 # Tune this
    penalty_threshold = 0.5 # Penalize if remaining space > 50% of original bin capacity (proxy: current remaining capacity)
    
    # Calculate penalty: if (valid_bins_remain_cap - item) > penalty_threshold * valid_bins_remain_cap
    # This means remaining space is more than 50% of what was available.
    # We want to penalize these. Subtract a value.
    penalty = np.maximum(0, (valid_bins_remain_cap - item) - penalty_threshold * valid_bins_remain_cap) * large_remaining_penalty_factor
    
    scores = base_scores - penalty

    # Softmax normalization
    shifted_scores = scores - np.max(scores)
    exp_scores = np.exp(shifted_scores)
    probabilities = exp_scores / np.sum(exp_scores)

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    priorities[valid_bins_mask] = probabilities

    return priorities
```
