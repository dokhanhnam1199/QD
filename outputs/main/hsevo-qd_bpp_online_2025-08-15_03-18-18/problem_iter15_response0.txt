```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Calculates priority scores for each bin using a multi-objective Softmax-Based Fit strategy
    for the online Bin Packing Problem.

    This strategy prioritizes bins that can accommodate the item, balancing:
    1.  **Best Fit:** Minimizing leftover space after packing.
    2.  **Diversity/Spread:** Slightly favoring bins that are not already extremely full,
        to potentially improve overall packing efficiency and avoid prematurely filling
        bins with very little remaining capacity unless necessary. This also helps in
        handling cases where an item might fit perfectly into multiple bins.
    3.  **Softness/Adaptability:** Using a temperature parameter for the Softmax to control
        the greediness of the selection.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array where each element represents the
                         remaining capacity of a bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        is the priority score for placing the item in the corresponding bin.
    """
    valid_bins_mask = bins_remain_cap >= item
    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    if valid_bins_remain_cap.size == 0:
        return np.zeros_like(bins_remain_cap)

    # --- Objective 1: Best Fit ---
    # Score based on how little space is left after placing the item.
    # Lower leftover space is better, so we want to maximize -(leftover_space).
    leftover_space = valid_bins_remain_cap - item
    best_fit_scores = -leftover_space

    # --- Objective 2: Diversity/Spread ---
    # Slightly penalize bins that are already very full (low remaining capacity).
    # A simple way is to use the negative of the remaining capacity itself.
    # A larger negative value (closer to zero) is preferred, meaning more capacity.
    # However, we only care about *valid* bins here.
    # We can use a reciprocal or a transformation of remaining capacity.
    # Let's use a transformation that is sensitive to low capacities but doesn't
    # explode for high capacities. A simple inverse might be too sensitive.
    # Consider a function that is large for small capacities and approaches zero.
    # Example: 1 / (1 + remaining_capacity) or similar.
    # For this heuristic, let's consider the 'fullness' *before* placing the item.
    # Bins that are already very full (low remaining capacity) might be less desirable
    # if there are other options, unless they offer a better fit.
    # Let's define a "fullness score" where higher is more full.
    # We can use `item / valid_bins_remain_cap` for bins that can fit the item.
    # However, this can be unstable if remaining_cap is close to item.
    # A more stable approach related to spread could be related to the *current* state.
    # Let's try a score that favors bins that are *not* nearly full.
    # i.e., favor bins with larger remaining capacity.
    # We want to *minimize* the remaining capacity for best fit, but *maximize* it for spread.
    # This is a conflict. Let's refine the diversity aspect:
    # We want to avoid bins that are *almost full* if possible, unless they are the *best* fit.
    # Let's define a "risk" score for bins that are too full.
    # `risk = item / valid_bins_remain_cap`. Smaller is better (less risk of being too full).
    # This is tricky because it conflicts with best-fit.

    # Let's rethink diversity: The goal is to distribute items, not just pack tightly.
    # A common approach for diversity is to encourage using bins that have *more* space
    # if they are not significantly worse fits.
    # Let's use the *negative* of the remaining capacity for the diversity score:
    # `-valid_bins_remain_cap`. Larger values (less negative, closer to 0) are preferred.
    # This favors bins with more remaining capacity.
    diversity_scores = valid_bins_remain_cap * 0.1 # Scale down the diversity contribution

    # --- Combine Objectives ---
    # Combine best_fit_scores and diversity_scores. We want to maximize both.
    # Let's weigh them. Best fit is usually primary.
    # A simple linear combination: `w1 * best_fit + w2 * diversity`
    # Let's try `base_score = best_fit_scores + diversity_scores`
    # Or, perhaps better, modify the best fit score based on diversity.
    # If a bin has a lot of space, it might be slightly less preferred for a tight fit.
    # Let's try a multiplicative approach or a prioritized scoring.

    # Alternative combination: modify best_fit score.
    # The "gap" is `leftover_space`. We want to minimize this.
    # Let's add a term that slightly penalizes small gaps if the bin has very little space left *initially*.
    # This is getting complicated. Let's simplify: Combine the primary objectives directly.

    # Re-evaluating the advice: "integrate multiple criteria (e.g., fit quality, diversity)".
    # Let's combine Best Fit with a penalty for *very low* remaining capacity *before* packing.
    # This is a form of "Worst Fit Decreasing" idea, but applied dynamically.
    # Let's consider the *absolute* remaining capacity. Bins with very little capacity might be problematic later.
    # Let's add a penalty proportional to `1 / (valid_bins_remain_cap + epsilon)` for bins that are very full.
    # Or, perhaps simpler: Use `best_fit_scores` and add a small bonus to bins with more capacity.
    # `combined_scores = best_fit_scores + (valid_bins_remain_cap * weight_diversity)`
    # Let's try to make diversity a modifier. If a bin is almost full, its best-fit score is good,
    # but we want to slightly downplay it if other options exist.

    # Let's define a single combined score:
    # Maximize `-leftover_space` (Best Fit)
    # Maximize `valid_bins_remain_cap` (Diversity - favors more space)
    # Combine these, ensuring Best Fit is dominant.
    # `score = -leftover_space + alpha * valid_bins_remain_cap`
    # Alpha controls the influence of diversity. Small alpha means primarily best fit.
    # Larger alpha means diversity plays a bigger role.
    alpha = 0.2 # Tunable parameter for diversity influence

    # Calculate combined scores for valid bins
    # We want to maximize this score.
    combined_scores = best_fit_scores + alpha * valid_bins_remain_cap

    # --- Softmax with Temperature ---
    # Use a temperature parameter to control the "sharpness" of the probability distribution.
    # T > 1: Softer probabilities, more exploration.
    # T < 1: Sharper probabilities, more exploitation (greedy).
    # T = 1: Standard Softmax.
    temperature = 0.5 # Tunable parameter: Lower temperature makes it more greedy towards best scores.

    # Shift scores to prevent numerical overflow/underflow before exponentiation.
    # Subtracting the maximum score is a standard technique.
    if combined_scores.size > 0:
        shifted_scores = combined_scores - np.max(combined_scores)
        exp_scores = np.exp(shifted_scores / temperature)
        probabilities = exp_scores / np.sum(exp_scores)
    else:
        probabilities = np.array([])

    # Create the final priority array, mapping probabilities back to original bin indices.
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    if probabilities.size > 0:
        priorities[valid_bins_mask] = probabilities

    return priorities
```
