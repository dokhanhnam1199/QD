```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Calculates priority scores for each bin using a combined strategy for
    the online Bin Packing Problem, balancing "best fit" with a penalty for
    bins that would become excessively full.

    This strategy prioritizes bins that can accommodate the item, favoring those
    that result in less remaining capacity ("best fit"). Additionally, it
    introduces a penalty for bins that, after packing the item, would have
    very little remaining capacity, encouraging a more diversified packing
    strategy to potentially avoid early bin exhaustion.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array where each element represents the
                         remaining capacity of a bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        is the priority score for placing the item in the corresponding bin.
    """
    valid_bins_mask = bins_remain_cap >= item
    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    if valid_bins_remain_cap.size == 0:
        return np.zeros_like(bins_remain_cap)

    # "Best Fit" component: Minimize remaining capacity after placing the item.
    # Higher score for smaller remaining capacity.
    best_fit_scores = -(valid_bins_remain_cap - item)

    # Diversification component: Penalize bins that become too full.
    # A threshold can be used, e.g., if remaining_capacity - item < threshold.
    # Here, we use a sigmoid-like function to penalize as remaining capacity decreases.
    # This encourages not filling bins too tightly unless absolutely necessary.
    # We want to *reduce* the score if the bin becomes too full.
    # A smaller (remaining_capacity - item) means a fuller bin.
    # Let's create a penalty that is high when (remaining_capacity - item) is low.
    # Using exp(-x) where x is a scaled version of (remaining_capacity - item)
    # Smaller x (tighter fit) leads to larger penalty.
    # We need to be careful with scaling to avoid numerical issues.
    # Let's use a threshold-based penalty that is smooth.
    # Consider remaining capacity after packing: `rem_after_pack = valid_bins_remain_cap - item`
    # We want to penalize small `rem_after_pack`.
    # A simple penalty could be `penalty = 1 / (1 + exp(k * rem_after_pack))`
    # where k controls the steepness. A small `rem_after_pack` results in large penalty.
    # Let's use a small value for k to make it a soft penalty.
    # Scale remaining capacity to avoid overflow in exp.
    # For example, map to [0, 10] range.
    min_rem_after_pack = 0.0
    max_rem_after_pack = np.max(valid_bins_remain_cap) - item if np.max(valid_bins_remain_cap) >= item else 0.0
    
    if max_rem_after_pack == min_rem_after_pack: # Avoid division by zero if all valid bins have same remaining capacity
        diversification_penalty = np.zeros_like(best_fit_scores)
    else:
        rem_after_pack = valid_bins_remain_cap - item
        # Scale remaining capacity to a reasonable range for the penalty function
        # e.g., map to [0, 10] to control the steepness of the penalty
        scaled_rem_after_pack = 10 * (rem_after_pack - min_rem_after_pack) / (max_rem_after_pack - min_rem_after_pack)
        # Penalty is high for small remaining capacity (tight fit)
        diversification_penalty = 1.0 / (1.0 + np.exp(5.0 * (1.0 - scaled_rem_after_pack))) # penalty ~ 1 for tight fit, ~ 0 for loose fit

    # Combine scores: Favor best fit, but penalize overly tight fits.
    # We subtract the penalty from the best_fit_scores.
    # A higher combined score is better.
    combined_scores = best_fit_scores - diversification_penalty * 2.0 # Adjust multiplier for penalty strength

    # Apply Softmax to convert scores into probabilities (priorities)
    # Shift scores to avoid numerical overflow/underflow in exp
    shifted_scores = combined_scores - np.max(combined_scores)
    exp_scores = np.exp(shifted_scores)
    probabilities = exp_scores / np.sum(exp_scores)

    # Create the final priority array
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    priorities[valid_bins_mask] = probabilities

    return priorities
```
