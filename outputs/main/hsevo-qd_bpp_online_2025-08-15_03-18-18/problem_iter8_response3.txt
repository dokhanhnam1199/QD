```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with an adaptive penalty for large remaining capacities,
    using Softmax for probabilistic selection to balance exploitation and exploration.
    """
    valid_bins_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    if not np.any(valid_bins_mask):
        return priorities

    suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    # Best Fit component: Minimize remaining capacity (larger negative value is better)
    bf_scores = -(suitable_bins_remain_cap - item)

    # Adaptive Penalty component: Penalize bins with significantly larger remaining capacity
    # Use a scaled version of remaining capacity to create a penalty that's less aggressive
    # for slightly larger gaps, but still discourages very large ones.
    # The scaling factor 's' can be tuned. Here, we use a simple approach
    # and use a negative exponential to make larger gaps have smaller scores.
    # We add a small epsilon to avoid log(0) if a bin has exactly the item's size.
    penalty_scores = -np.exp((suitable_bins_remain_cap - item) / 1.0) # 1.0 is a scale factor, can be tuned

    # Combine scores. Weight BF more heavily for direct fit, but incorporate penalty.
    combined_scores = bf_scores + penalty_scores

    # Softmax for normalization to get probabilities
    if np.max(combined_scores) - np.min(combined_scores) > 1e-9:
        shifted_scores = combined_scores - np.max(combined_scores)
        exp_scores = np.exp(shifted_scores)
        sum_exp_scores = np.sum(exp_scores)
        if sum_exp_scores > 1e-9:
            probabilities = exp_scores / sum_exp_scores
        else:
            probabilities = np.ones_like(combined_scores) / len(combined_scores)
    else:
        probabilities = np.ones_like(combined_scores) / len(combined_scores)

    priorities[valid_bins_mask] = probabilities

    return priorities
```
