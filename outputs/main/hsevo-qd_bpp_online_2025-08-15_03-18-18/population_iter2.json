[
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities[suitable_bins_mask] = 1.0 / (bins_remain_cap[suitable_bins_mask] - item + 1e-9)\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \n    bin_capacities = 1.0  # Assuming a standard bin capacity of 1.0, can be generalized.\n    \n    potential_fits = bins_remain_cap - item\n    \n    valid_bins_mask = potential_fits >= 0\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(valid_bins_mask):\n        \n        priorities[valid_bins_mask] = 1.0 / (potential_fits[valid_bins_mask] + 1e-9) # Add epsilon to avoid division by zero\n\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 43.01955000865388,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for each bin using a Softmax-Based Fit strategy\n    for the online Bin Packing Problem.\n\n    This strategy prioritizes bins that have remaining capacity, with a higher\n    priority given to bins that can accommodate the item without significant\n    wastage, and also considers the overall \"fullness\" of bins.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    # Filter out bins that cannot fit the item\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        # If no bin can fit the item, return zero priorities for all bins\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate a score for each valid bin:\n    # We want to favor bins that are nearly full after placing the item.\n    # (capacity - item) represents the remaining capacity after placement.\n    # Smaller values of (capacity - item) are better.\n    # We can invert this by taking the negative or by calculating (item - capacity) if capacity < item.\n    # For simplicity and Softmax compatibility, let's focus on the 'goodness' of fit.\n    # A good fit means small remaining capacity. So, we can use 1 / (remaining_after_fit)\n    # or something similar.\n\n    # A common heuristic for BPP is \"Best Fit\": choosing the bin that leaves the least empty space.\n    # So, remaining_capacity - item should be minimized.\n    # We want to maximize the \"suitability\" score.\n    # Let's consider the negative of the remaining capacity after fitting as a base score.\n    # Larger negative values (closer to zero) are better.\n    base_scores = -(valid_bins_remain_cap - item)\n\n    # Add a penalty for bins that are already very full, encouraging spreading items if possible,\n    # unless an item perfectly fits. This can be tricky.\n    # For simplicity in v2, let's focus on the immediate fit.\n\n    # Apply Softmax to convert scores into probabilities (priorities)\n    # Softmax: exp(score) / sum(exp(all_scores))\n    # To avoid numerical instability with very large or small scores, we can shift scores.\n    # Subtracting the maximum score before exponentiation is a common technique.\n    shifted_scores = base_scores - np.max(base_scores)\n    exp_scores = np.exp(shifted_scores)\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    # Create the final priority array, placing calculated priorities in their original positions\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by rewarding perfect fits and then favoring tighter fits using inverse proximity, normalized via Softmax.\n\n    Combines the 'perfect fit' bonus from priority_v0 with the normalized inverse proximity of priority_v1.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate effective remaining capacities for fitting bins\n    effective_capacities = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign scores: perfect fits get a bonus, others get inverse proximity\n    scores = np.zeros_like(effective_capacities, dtype=float)\n    \n    perfect_fit_mask = effective_capacities == 0\n    scores[perfect_fit_mask] = 1.0  # High priority for perfect fits\n    \n    # For non-perfect fits, use inverse proximity to reward tighter fits\n    non_perfect_fit_mask = ~perfect_fit_mask\n    scores[non_perfect_fit_mask] = 1.0 / (effective_capacities[non_perfect_fit_mask] + 1e-9)\n    \n    # Apply scores to the corresponding bins\n    priorities[can_fit_mask] = scores\n    \n    # If no bins can fit the item, return uniform probabilities\n    if not np.any(can_fit_mask):\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    # Normalize priorities using Softmax to get a probability distribution\n    # Subtract max score for numerical stability before exponentiation\n    max_score = np.max(priorities[can_fit_mask])\n    exp_scores = np.exp(priorities[can_fit_mask] - max_score)\n    \n    normalized_priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    normalized_priorities[can_fit_mask] = exp_scores / np.sum(exp_scores)\n    \n    return normalized_priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 128.3789500201924,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            \n            remaining_cap = bins_remain_cap[i]\n            \n            \n            if remaining_cap == item:\n                priorities[i] = 1.0  # Perfect fit, highest priority\n            else:\n                \n                priorities[i] = 1.0 / (remaining_cap - item + 1e-9) # Inverse proximity, higher score for bins that are closer to fitting the item without being perfect\n                \n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 4.0,
    "halstead": 53.77443751081735,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    effective_capacities = bins_remain_cap[valid_bins] - item\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = np.exp(effective_capacities)\n    \n    if np.sum(priorities) == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    return priorities / np.sum(priorities)",
    "response_id": 19,
    "tryHS": false,
    "obj": 19.186278420422827,
    "cyclomatic_complexity": 3.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit inverse proximity with explicit perfect-fit handling\n    and Softmax normalization for robust bin selection.\n    Prioritizes bins that are a perfect fit, then bins with minimal remaining\n    space, normalized using Softmax for probabilistic selection.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(valid_bins_mask):\n        return priorities\n\n    valid_bins_capacities = bins_remain_cap[valid_bins_mask]\n    \n    perfect_fits_mask = valid_bins_capacities == item\n    \n    if np.any(perfect_fits_mask):\n        perfect_fit_indices = np.where(valid_bins_mask)[0][perfect_fits_mask]\n        priorities[perfect_fit_indices] = 1.0 \n\n    non_perfect_fit_indices = np.where(valid_bins_mask)[0][~perfect_fits_mask]\n    \n    if len(non_perfect_fit_indices) > 0:\n        non_perfect_capacities = bins_remain_cap[non_perfect_fit_indices]\n        effective_capacities = non_perfect_capacities - item\n        \n        # Use inverse proximity for non-perfect fits, preventing division by zero\n        priorities[non_perfect_fit_indices] = 1.0 / (effective_capacities + 1e-9)\n\n    # Softmax normalization to ensure probabilities sum to 1, or handle all-zero case\n    # Subtracting max before exp for numerical stability\n    max_priority = np.max(priorities)\n    exp_priorities = np.exp(priorities - max_priority)\n    \n    sum_exp_priorities = np.sum(exp_priorities)\n    \n    if sum_exp_priorities == 0:\n        # If all calculated priorities are zero (e.g., only invalid bins), return uniform distribution\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n    else:\n        return exp_priorities / sum_exp_priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 5.0,
    "halstead": 159.81495041679716,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines 'best fit' with a small random element for improved exploration\n    and handles perfect fits explicitly. Prioritizes bins with minimal remaining\n    capacity after placing the item, while introducing some randomness to\n    avoid premature convergence.\n    \"\"\"\n    epsilon = 0.05  # Small factor for random exploration\n    bin_capacity = 1.0 # Assuming a standard bin capacity of 1.0\n\n    potential_fits = bins_remain_cap - item\n    valid_bins_mask = potential_fits >= -1e-9 # Allow for slight floating point inaccuracies\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(valid_bins_mask):\n        suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        suitable_potential_fits = potential_fits[valid_bins_mask]\n\n        # Explicitly reward perfect fits with a high priority\n        perfect_fit_mask = np.abs(suitable_potential_fits) < 1e-9\n        priorities[valid_bins_mask][perfect_fit_mask] = 1.0 / (1e-9) # Very high priority\n\n        # For non-perfect fits, use inverse proximity with a small random component\n        non_perfect_fit_mask = ~perfect_fit_mask\n        if np.any(non_perfect_fit_mask):\n            non_perfect_potential_fits = suitable_potential_fits[non_perfect_fit_mask]\n            greedy_scores = 1.0 / (non_perfect_potential_fits + 1e-9)\n            random_scores = np.random.rand(np.sum(non_perfect_fit_mask))\n            combined_scores = epsilon * random_scores + (1 - epsilon) * greedy_scores\n            priorities[valid_bins_mask][non_perfect_fit_mask] = combined_scores\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 155.88872502451935,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit (minimizing waste) with a Softmax approach for robust priority.\n\n    Prioritizes bins that leave minimal remaining capacity after item placement,\n    using Softmax for smooth probability distribution and better exploration.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(valid_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    # Base score: Negative of remaining capacity after fitting (closer to 0 is better)\n    # This embodies the \"Best Fit\" principle.\n    base_scores = -(suitable_bins_remain_cap - item)\n\n    # Softmax for normalization: Convert scores to a probability-like distribution\n    # Shift scores to prevent overflow/underflow before exponentiation\n    if np.max(base_scores) - np.min(base_scores) > 1e-9: # Avoid issues if all scores are identical\n        shifted_scores = base_scores - np.max(base_scores)\n        exp_scores = np.exp(shifted_scores)\n        # Ensure sum is not zero to avoid division by zero\n        sum_exp_scores = np.sum(exp_scores)\n        if sum_exp_scores > 1e-9:\n            probabilities = exp_scores / sum_exp_scores\n        else:\n            # Fallback if all exponentiated scores are effectively zero\n            probabilities = np.ones_like(base_scores) / len(base_scores)\n    else:\n        # If all base scores are the same, assign equal probability\n        probabilities = np.ones_like(base_scores) / len(base_scores)\n\n\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 140.2304206377674,
    "exec_success": true
  }
]