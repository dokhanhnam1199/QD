{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for each bin using a Softmax-Based Fit strategy\n    for the online Bin Packing Problem.\n\n    This strategy prioritizes bins that have remaining capacity, with a higher\n    priority given to bins that can accommodate the item without significant\n    wastage, and also considers the overall \"fullness\" of bins.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    # Filter out bins that cannot fit the item\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        # If no bin can fit the item, return zero priorities for all bins\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate a score for each valid bin:\n    # We want to favor bins that are nearly full after placing the item.\n    # (capacity - item) represents the remaining capacity after placement.\n    # Smaller values of (capacity - item) are better.\n    # We can invert this by taking the negative or by calculating (item - capacity) if capacity < item.\n    # For simplicity and Softmax compatibility, let's focus on the 'goodness' of fit.\n    # A good fit means small remaining capacity. So, we can use 1 / (remaining_after_fit)\n    # or something similar.\n\n    # A common heuristic for BPP is \"Best Fit\": choosing the bin that leaves the least empty space.\n    # So, remaining_capacity - item should be minimized.\n    # We want to maximize the \"suitability\" score.\n    # Let's consider the negative of the remaining capacity after fitting as a base score.\n    # Larger negative values (closer to zero) are better.\n    base_scores = -(valid_bins_remain_cap - item)\n\n    # Add a penalty for bins that are already very full, encouraging spreading items if possible,\n    # unless an item perfectly fits. This can be tricky.\n    # For simplicity in v2, let's focus on the immediate fit.\n\n    # Apply Softmax to convert scores into probabilities (priorities)\n    # Softmax: exp(score) / sum(exp(all_scores))\n    # To avoid numerical instability with very large or small scores, we can shift scores.\n    # Subtracting the maximum score before exponentiation is a common technique.\n    shifted_scores = base_scores - np.max(base_scores)\n    exp_scores = np.exp(shifted_scores)\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    # Create the final priority array, placing calculated priorities in their original positions\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for each bin using a Softmax-Based Fit strategy\n    for the online Bin Packing Problem.\n\n    This strategy prioritizes bins that have remaining capacity, with a higher\n    priority given to bins that can accommodate the item without significant\n    wastage, and also considers the overall \"fullness\" of bins.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    # Filter out bins that cannot fit the item\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        # If no bin can fit the item, return zero priorities for all bins\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate a score for each valid bin:\n    # We want to favor bins that are nearly full after placing the item.\n    # (capacity - item) represents the remaining capacity after placement.\n    # Smaller values of (capacity - item) are better.\n    # We can invert this by taking the negative or by calculating (item - capacity) if capacity < item.\n    # For simplicity and Softmax compatibility, let's focus on the 'goodness' of fit.\n    # A good fit means small remaining capacity. So, we can use 1 / (remaining_after_fit)\n    # or something similar.\n\n    # A common heuristic for BPP is \"Best Fit\": choosing the bin that leaves the least empty space.\n    # So, remaining_capacity - item should be minimized.\n    # We want to maximize the \"suitability\" score.\n    # Let's consider the negative of the remaining capacity after fitting as a base score.\n    # Larger negative values (closer to zero) are better.\n    base_scores = -(valid_bins_remain_cap - item)\n\n    # Add a penalty for bins that are already very full, encouraging spreading items if possible,\n    # unless an item perfectly fits. This can be tricky.\n    # For simplicity in v2, let's focus on the immediate fit.\n\n    # Apply Softmax to convert scores into probabilities (priorities)\n    # Softmax: exp(score) / sum(exp(all_scores))\n    # To avoid numerical instability with very large or small scores, we can shift scores.\n    # Subtracting the maximum score before exponentiation is a common technique.\n    shifted_scores = base_scores - np.max(base_scores)\n    exp_scores = np.exp(shifted_scores)\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    # Create the final priority array, placing calculated priorities in their original positions\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for each bin using a Softmax-Based Fit strategy\n    for the online Bin Packing Problem.\n\n    This strategy prioritizes bins that have remaining capacity, with a higher\n    priority given to bins that can accommodate the item without significant\n    wastage, and also considers the overall \"fullness\" of bins.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    # Filter out bins that cannot fit the item\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        # If no bin can fit the item, return zero priorities for all bins\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate a score for each valid bin:\n    # We want to favor bins that are nearly full after placing the item.\n    # (capacity - item) represents the remaining capacity after placement.\n    # Smaller values of (capacity - item) are better.\n    # We can invert this by taking the negative or by calculating (item - capacity) if capacity < item.\n    # For simplicity and Softmax compatibility, let's focus on the 'goodness' of fit.\n    # A good fit means small remaining capacity. So, we can use 1 / (remaining_after_fit)\n    # or something similar.\n\n    # A common heuristic for BPP is \"Best Fit\": choosing the bin that leaves the least empty space.\n    # So, remaining_capacity - item should be minimized.\n    # We want to maximize the \"suitability\" score.\n    # Let's consider the negative of the remaining capacity after fitting as a base score.\n    # Larger negative values (closer to zero) are better.\n    base_scores = -(valid_bins_remain_cap - item)\n\n    # Add a penalty for bins that are already very full, encouraging spreading items if possible,\n    # unless an item perfectly fits. This can be tricky.\n    # For simplicity in v2, let's focus on the immediate fit.\n\n    # Apply Softmax to convert scores into probabilities (priorities)\n    # Softmax: exp(score) / sum(exp(all_scores))\n    # To avoid numerical instability with very large or small scores, we can shift scores.\n    # Subtracting the maximum score before exponentiation is a common technique.\n    shifted_scores = base_scores - np.max(base_scores)\n    exp_scores = np.exp(shifted_scores)\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    # Create the final priority array, placing calculated priorities in their original positions\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \n    bin_capacities = 1.0  # Assuming a standard bin capacity of 1.0, can be generalized.\n    \n    potential_fits = bins_remain_cap - item\n    \n    valid_bins_mask = potential_fits >= 0\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(valid_bins_mask):\n        \n        priorities[valid_bins_mask] = 1.0 / (potential_fits[valid_bins_mask] + 1e-9) # Add epsilon to avoid division by zero\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \n    bin_capacities = 1.0  # Assuming a standard bin capacity of 1.0, can be generalized.\n    \n    potential_fits = bins_remain_cap - item\n    \n    valid_bins_mask = potential_fits >= 0\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(valid_bins_mask):\n        \n        priorities[valid_bins_mask] = 1.0 / (potential_fits[valid_bins_mask] + 1e-9) # Add epsilon to avoid division by zero\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \n    bin_capacities = 1.0  # Assuming a standard bin capacity of 1.0, can be generalized.\n    \n    potential_fits = bins_remain_cap - item\n    \n    valid_bins_mask = potential_fits >= 0\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(valid_bins_mask):\n        \n        priorities[valid_bins_mask] = 1.0 / (potential_fits[valid_bins_mask] + 1e-9) # Add epsilon to avoid division by zero\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            \n            remaining_cap = bins_remain_cap[i]\n            \n            \n            if remaining_cap == item:\n                priorities[i] = 1.0  # Perfect fit, highest priority\n            else:\n                \n                priorities[i] = 1.0 / (remaining_cap - item + 1e-9) # Inverse proximity, higher score for bins that are closer to fitting the item without being perfect\n                \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \n    bin_capacities = 1.0  # Assuming a standard bin capacity of 1.0, can be generalized.\n    \n    potential_fits = bins_remain_cap - item\n    \n    valid_bins_mask = potential_fits >= 0\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(valid_bins_mask):\n        \n        priorities[valid_bins_mask] = 1.0 / (potential_fits[valid_bins_mask] + 1e-9) # Add epsilon to avoid division by zero\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            \n            remaining_cap = bins_remain_cap[i]\n            \n            \n            if remaining_cap == item:\n                priorities[i] = 1.0  # Perfect fit, highest priority\n            else:\n                \n                priorities[i] = 1.0 / (remaining_cap - item + 1e-9) # Inverse proximity, higher score for bins that are closer to fitting the item without being perfect\n                \n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            \n            remaining_cap = bins_remain_cap[i]\n            \n            \n            if remaining_cap == item:\n                priorities[i] = 1.0  # Perfect fit, highest priority\n            else:\n                \n                priorities[i] = 1.0 / (remaining_cap - item + 1e-9) # Inverse proximity, higher score for bins that are closer to fitting the item without being perfect\n                \n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            \n            remaining_cap = bins_remain_cap[i]\n            \n            \n            if remaining_cap == item:\n                priorities[i] = 1.0  # Perfect fit, highest priority\n            else:\n                \n                priorities[i] = 1.0 / (remaining_cap - item + 1e-9) # Inverse proximity, higher score for bins that are closer to fitting the item without being perfect\n                \n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(valid_bins_mask):\n        \n        suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        greedy_scores = 1 / (suitable_bins_remain_cap - item + 1e-6) \n        \n        random_scores = np.random.rand(np.sum(valid_bins_mask))\n        \n        combined_scores = epsilon * random_scores + (1 - epsilon) * greedy_scores\n        \n        priorities[valid_bins_mask] = combined_scores\n        \n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(valid_bins_mask):\n        \n        suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        greedy_scores = 1 / (suitable_bins_remain_cap - item + 1e-6) \n        \n        random_scores = np.random.rand(np.sum(valid_bins_mask))\n        \n        combined_scores = epsilon * random_scores + (1 - epsilon) * greedy_scores\n        \n        priorities[valid_bins_mask] = combined_scores\n        \n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(valid_bins_mask):\n        \n        suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        greedy_scores = 1 / (suitable_bins_remain_cap - item + 1e-6) \n        \n        random_scores = np.random.rand(np.sum(valid_bins_mask))\n        \n        combined_scores = epsilon * random_scores + (1 - epsilon) * greedy_scores\n        \n        priorities[valid_bins_mask] = combined_scores\n        \n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(valid_bins_mask):\n        \n        suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        greedy_scores = 1 / (suitable_bins_remain_cap - item + 1e-6) \n        \n        random_scores = np.random.rand(np.sum(valid_bins_mask))\n        \n        combined_scores = epsilon * random_scores + (1 - epsilon) * greedy_scores\n        \n        priorities[valid_bins_mask] = combined_scores\n        \n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    effective_capacities = bins_remain_cap[valid_bins] - item\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = np.exp(effective_capacities)\n    \n    if np.sum(priorities) == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    return priorities / np.sum(priorities)\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    effective_capacities = bins_remain_cap[valid_bins] - item\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = np.exp(effective_capacities)\n    \n    if np.sum(priorities) == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    return priorities / np.sum(priorities)\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    effective_capacities = bins_remain_cap[valid_bins] - item\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = np.exp(effective_capacities)\n    \n    if np.sum(priorities) == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    return priorities / np.sum(priorities)\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    effective_capacities = bins_remain_cap[valid_bins] - item\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = np.exp(effective_capacities)\n    \n    if np.sum(priorities) == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    return priorities / np.sum(priorities)\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}