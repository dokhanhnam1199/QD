```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Calculates priority scores for each bin using a Hybrid Softmax-Based Fit strategy
    for the online Bin Packing Problem.

    This strategy aims to balance 'Best Fit' (minimizing waste) with a
    'First Fit' tendency for larger items by introducing a penalty for
    bins that would leave very little space after packing. It also incorporates
    a diversification element by slightly favoring less full bins to avoid
    prematurely filling a few bins.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array where each element represents the
                         remaining capacity of a bin.

    Returns:
        A numpy array of the same size as bins_remain_cap, where each element
        is the priority score for placing the item in the corresponding bin.
    """
    valid_bins_mask = bins_remain_cap >= item
    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    if valid_bins_remain_cap.size == 0:
        return np.zeros_like(bins_remain_cap)

    # Base score: Invert remaining capacity after fitting. Lower remaining is better.
    # This promotes 'Best Fit'.
    best_fit_scores = -(valid_bins_remain_cap - item)

    # Diversification/Exploration score:
    # Favor bins that are not already too full. This encourages spreading items.
    # A higher score for bins with more remaining capacity (but still fitting the item).
    # We use a sigmoid-like function to bound this influence.
    # The idea is to give a slight boost to bins that are not nearly full,
    # especially if the item is large.
    # We can use 1 / (1 + exp(-(capacity - item - threshold))) where threshold is some value
    # or more simply, a transformation of the remaining capacity after packing.
    # Let's consider the remaining capacity itself as a measure. Higher remaining capacity
    # after packing is less preferred for 'Best Fit', but might be good for diversification.
    # We can create a score that is inversely related to how "full" the bin becomes.
    # A bin that becomes almost full (low remaining cap) is good for BF, bad for diversity.
    # A bin that remains very open (high remaining cap) is bad for BF, good for diversity.

    # Let's create a score that penalizes bins that will have very little remaining space.
    # This is a form of "near miss" avoidance for the next items.
    # A small remaining capacity after packing (e.g., < item/2) could be penalized.
    # Let's map the remaining capacity after packing `rem_after_fit` to a score.
    rem_after_fit = valid_bins_remain_cap - item
    
    # Soft penalty for small remaining capacities. If rem_after_fit is small, this score is high.
    # We want to *reduce* the priority for bins that leave very little space.
    # Use a sigmoid-like function that maps small positive values to a range close to 0,
    # and larger values to a range close to 1.
    # We want to penalize small `rem_after_fit`.
    # So, a function that is high for small `rem_after_fit` and low for large `rem_after_fit`
    # is needed, and this should be subtracted from the main score.
    
    # A simple penalty: penalize if remaining capacity is less than item/2.
    # More nuanced: exponential decay of penalty as remaining capacity increases.
    # Let's use a logistic function scaled to penalize small positive remaining capacities.
    # f(x) = 1 / (1 + exp(-k * (x - x0)))
    # We want a function that is high when rem_after_fit is low.
    # So we can use: penalty = 1 / (1 + exp(k * rem_after_fit)) where k is positive.
    # Or, more simply, we can use a score that increases with remaining capacity,
    # but we want to *reduce* the priority of bins with low remaining capacity.
    
    # Let's refine the score:
    # Primary goal: Minimize `rem_after_fit` (Best Fit). Score = -rem_after_fit.
    # Secondary goal: Avoid making bins too full if possible (Diversification).
    # This means, if multiple bins offer similar "best fit", prefer the one that
    # was initially less full.
    # This is tricky to encode directly in a simple priority score.

    # Alternative approach: Combine Best Fit with a bonus for initial capacity.
    # Score = -rem_after_fit + alpha * initial_capacity_of_bin
    # However, we don't have initial capacity, only remaining.

    # Let's try a score that is good for Best Fit, but has a "decay" for being too full.
    # Consider the "gap" created: `valid_bins_remain_cap - item`.
    # We want to minimize this gap.
    # Let's add a term that slightly favors bins that are less full initially.
    # We can use the *current* remaining capacity as a proxy for how full the bin is.
    # Higher `valid_bins_remain_cap` means the bin is less full.
    
    # Let's try a composite score:
    # Score = w1 * (- (valid_bins_remain_cap - item)) + w2 * (valid_bins_remain_cap)
    # The first term is Best Fit. The second term favors less full bins.
    # Let's normalize these to avoid one dominating the other.

    # Normalization factor for Best Fit: The maximum possible "goodness" is 0 (perfect fit).
    # The worst "goodness" is -(max_capacity - min_item_size).
    # Let's normalize `-(valid_bins_remain_cap - item)` to be between 0 and 1 (roughly).
    # Or, more simply, let's use the raw negative remaining capacity.

    # Let's introduce a "diversification bonus" that is proportional to the remaining capacity
    # of the bin *before* packing. This encourages using bins that have more space available,
    # as long as they fit the item.
    # `bonus = alpha * valid_bins_remain_cap` where alpha is a small positive weight.
    # This bonus counters the Best Fit score if the remaining capacity is significantly large.

    alpha = 0.1  # Weight for diversification bonus. Tune this parameter.
    diversification_bonus = alpha * valid_bins_remain_cap
    
    # Combined score: Best Fit score + diversification bonus
    # Higher score is better.
    # We want to minimize `valid_bins_remain_cap - item`. So we want to maximize `-(valid_bins_remain_cap - item)`.
    # Higher `valid_bins_remain_cap` is better for diversification.
    
    # So, we want to maximize `-(valid_bins_remain_cap - item) + alpha * valid_bins_remain_cap`
    # This simplifies to `alpha * valid_bins_remain_cap - valid_bins_remain_cap + item`
    # which is `(alpha - 1) * valid_bins_remain_cap + item`.
    # This still favors larger `valid_bins_remain_cap` if `alpha < 1`, which is the case.
    
    # Let's reconsider the goal. We want bins that are *almost* full (good fit),
    # but not *too* full such that the remaining space is almost unusable.
    # This suggests a function that peaks for intermediate remaining capacities after packing.

    # A refined approach:
    # 1. Best Fit score: `-(valid_bins_remain_cap - item)`. Maximize this.
    # 2. Penalty for "too little" remaining space: `exp(-beta * (valid_bins_remain_cap - item))`
    #    where beta is a positive constant. This term is high for small remaining space,
    #    and we want to penalize high values. So, we subtract this penalty.
    
    beta = 2.0  # Penalty factor for small remaining space.
    # We want to penalize small positive remaining capacities.
    # Let rem_cap_after_packing = valid_bins_remain_cap - item
    # Penalty increases as rem_cap_after_packing approaches 0.
    # A function like `exp(-beta * rem_cap_after_packing)` works.
    # If rem_cap_after_packing = 0, penalty is 1. If rem_cap_after_packing is large, penalty approaches 0.
    # So, we subtract this penalty.
    
    # Let's combine:
    # Score = -(valid_bins_remain_cap - item) - penalty_factor * exp(-beta * (valid_bins_remain_cap - item))
    # This aims to reward good fits, but slightly disincentivize fits that leave almost no space.

    # Let's try a simpler form that is more directly interpretable with Softmax.
    # We want to prioritize bins where `valid_bins_remain_cap - item` is small.
    # Let's introduce a "niceness" score.
    # `niceness = 1.0 / (1.0 + (valid_bins_remain_cap - item))` -- this is high for small remaining space.
    # But Softmax needs scores that can be positive/negative.

    # Let's go back to the composite score idea, but ensure Softmax handles it well.
    # We want to prioritize bins with small `(remaining_capacity - item)`.
    # We also want to slightly favor bins that have more overall capacity (less full).
    # So, we want to maximize `-(remaining_capacity - item) + alpha * remaining_capacity`.
    
    # Let's re-evaluate the original v1's Softmax base: `-(valid_bins_remain_cap - item)`.
    # This encourages Best Fit.
    # To add diversification, we can add a term that is higher for bins that are less full.
    # `current_remaining_capacity` is a proxy for "less full".
    # So, `score = -(valid_bins_remain_cap - item) + gamma * valid_bins_remain_cap`.
    # `gamma` is a small positive number.
    
    gamma = 0.2  # Weight for diversification (favoring less full bins).
    
    # The score is `-(valid_bins_remain_cap - item) + gamma * valid_bins_remain_cap`
    # = `-valid_bins_remain_cap + item + gamma * valid_bins_remain_cap`
    # = `(gamma - 1) * valid_bins_remain_cap + item`.
    
    # This score will be higher for larger `valid_bins_remain_cap` if `gamma < 1`,
    # which is the intended effect of diversification.
    # However, we also want to prioritize Best Fit.

    # Let's normalize the contribution of each term to prevent one from dominating.
    # Best Fit contribution: `-(valid_bins_remain_cap - item)`
    # Diversification contribution: `valid_bins_remain_cap`

    # Maximum possible best fit score: 0 (perfect fit). Minimum: -(max_cap - min_item).
    # Maximum possible diversification contribution: max_capacity. Minimum: min_fitting_capacity.

    # A common strategy is to use a weighted sum, and then apply softmax.
    # Let's use the raw scores and rely on Softmax scaling.
    
    # Final proposed score for each valid bin:
    # Score = w_bf * BestFitScore + w_div * DiversificationScore
    # BestFitScore = -(remaining_capacity_after_packing) = -(valid_bins_remain_cap - item)
    # DiversificationScore = current_remaining_capacity = valid_bins_remain_cap
    
    w_bf = 1.0
    w_div = 0.3 # Tune this weight. Higher means more preference for less full bins.
    
    composite_scores = w_bf * (-(valid_bins_remain_cap - item)) + w_div * valid_bins_remain_cap

    # Softmax transformation:
    # Shift scores to avoid numerical instability (large positive/negative values)
    # Subtracting the maximum score is standard.
    if composite_scores.size > 0:
        shifted_scores = composite_scores - np.max(composite_scores)
        exp_scores = np.exp(shifted_scores)
        probabilities = exp_scores / np.sum(exp_scores)
    else:
        probabilities = np.array([])

    # Create the final priority array, placing calculated priorities in their original positions
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    priorities[valid_bins_mask] = probabilities

    return priorities
```
