```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with adaptive diversification using Softmax.
    Prioritizes tight fits but allows exploration of emptier bins based on capacity variance.
    """
    valid_bins_mask = bins_remain_cap >= item
    
    if not np.any(valid_bins_mask):
        return np.zeros_like(bins_remain_cap)

    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]
    
    # Calculate remaining capacity after fitting the item
    rem_after_fit = valid_bins_remain_cap - item

    # Best Fit component: Smaller remaining capacity is better (higher score)
    # Use negative remaining capacity to achieve this. Add epsilon for stability.
    best_fit_scores = -rem_after_fit

    # Adaptive Diversification component:
    # Penalize bins that have very large remaining capacity, but this penalty
    # should be less severe when there's high variance in remaining capacities.
    # We use a sigmoid-like penalty that is smaller for smaller capacities.
    # Scale capacities to a stable range for the penalty function.
    min_rem = 0.0
    max_rem = np.max(valid_bins_remain_cap) - item if np.max(valid_bins_remain_cap) >= item else 0.0

    if max_rem == min_rem:
        diversification_scores = np.zeros_like(best_fit_scores)
    else:
        scaled_rem = 5.0 * (rem_after_fit - min_rem) / (max_rem - min_rem)
        # Penalty is higher for larger remaining capacity.
        # exp(-x) decreases as x increases.
        # We want to reduce the score for bins with larger remaining capacity.
        diversification_scores = np.exp(-scaled_rem) # Lower score for larger remaining capacity

    # Combine scores: Favor best fit, slightly penalize large remaining capacities.
    # The penalty is weighted. A higher score is better.
    # We subtract a scaled diversification score from the best_fit_score.
    # Higher positive values in `diversification_scores` (meaning tighter fits) 
    # contribute less negatively to the combined score.
    # Higher negative values (meaning looser fits) contribute more negatively.
    combined_scores = best_fit_scores + diversification_scores * 0.5 # Adjust multiplier for penalty strength

    # Softmax normalization for probabilistic selection
    # Shift scores to avoid numerical issues with exp
    shifted_scores = combined_scores - np.max(combined_scores)
    exp_scores = np.exp(shifted_scores)
    probabilities = exp_scores / np.sum(exp_scores)

    # Create the final priority array
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    priorities[valid_bins_mask] = probabilities

    return priorities
```
