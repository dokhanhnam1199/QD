```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with an adaptive diversification strategy.
    Prioritizes bins that fit the item well, while also considering
    the variance of remaining capacities to balance exploration and exploitation.
    """
    valid_bins_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    if not np.any(valid_bins_mask):
        return priorities

    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    # Best Fit Component: Similarity to perfect fit. Smaller difference is better.
    bf_scores = -(valid_bins_remain_cap - item)

    # Adaptive Diversification Component: Use variance to adjust exploration.
    # If variance is low (bins are similar), encourage exploration by rewarding larger capacities.
    # If variance is high (bins are dissimilar), reduce exploration by penalizing larger capacities.
    if len(valid_bins_remain_cap) > 1:
        variance_capacity = np.var(valid_bins_remain_cap)
        # Normalize variance to be a small value, can be a hyperparameter
        normalized_variance = variance_capacity / np.mean(valid_bins_remain_cap)**2 if np.mean(valid_bins_remain_cap) > 0 else 0
        # Heuristic: if variance is low, we want to diversify more by favoring emptier bins
        # so we add a positive term proportional to capacity. If variance is high, we want to
        # exploit good fits more, so we add a negative term proportional to capacity.
        # This is a simplified approach to adaptive diversification.
        adaptive_div_scores = -normalized_variance * valid_bins_remain_cap
    else:
        adaptive_div_scores = np.zeros_like(valid_bins_remain_cap)

    # Combine components. Tune weights based on empirical performance.
    w_bf = 1.0
    w_adapt_div = 0.5 # Weight for adaptive diversification
    
    combined_scores = w_bf * bf_scores + w_adapt_div * adaptive_div_scores

    # Apply Softmax for probabilistic selection. Shift for numerical stability.
    if combined_scores.size > 0:
        shifted_scores = combined_scores - np.max(combined_scores)
        exp_scores = np.exp(shifted_scores)
        probabilities = exp_scores / np.sum(exp_scores)
    else:
        probabilities = np.array([])

    priorities[valid_bins_mask] = probabilities

    return priorities
```
