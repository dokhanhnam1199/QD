[
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities[suitable_bins_mask] = 1.0 / (bins_remain_cap[suitable_bins_mask] - item + 1e-9)\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \n    bin_capacities = 1.0  # Assuming a standard bin capacity of 1.0, can be generalized.\n    \n    potential_fits = bins_remain_cap - item\n    \n    valid_bins_mask = potential_fits >= 0\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(valid_bins_mask):\n        \n        priorities[valid_bins_mask] = 1.0 / (potential_fits[valid_bins_mask] + 1e-9) # Add epsilon to avoid division by zero\n\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 43.01955000865388,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for each bin using a Softmax-Based Fit strategy\n    for the online Bin Packing Problem.\n\n    This strategy prioritizes bins that have remaining capacity, with a higher\n    priority given to bins that can accommodate the item without significant\n    wastage, and also considers the overall \"fullness\" of bins.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    # Filter out bins that cannot fit the item\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        # If no bin can fit the item, return zero priorities for all bins\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate a score for each valid bin:\n    # We want to favor bins that are nearly full after placing the item.\n    # (capacity - item) represents the remaining capacity after placement.\n    # Smaller values of (capacity - item) are better.\n    # We can invert this by taking the negative or by calculating (item - capacity) if capacity < item.\n    # For simplicity and Softmax compatibility, let's focus on the 'goodness' of fit.\n    # A good fit means small remaining capacity. So, we can use 1 / (remaining_after_fit)\n    # or something similar.\n\n    # A common heuristic for BPP is \"Best Fit\": choosing the bin that leaves the least empty space.\n    # So, remaining_capacity - item should be minimized.\n    # We want to maximize the \"suitability\" score.\n    # Let's consider the negative of the remaining capacity after fitting as a base score.\n    # Larger negative values (closer to zero) are better.\n    base_scores = -(valid_bins_remain_cap - item)\n\n    # Add a penalty for bins that are already very full, encouraging spreading items if possible,\n    # unless an item perfectly fits. This can be tricky.\n    # For simplicity in v2, let's focus on the immediate fit.\n\n    # Apply Softmax to convert scores into probabilities (priorities)\n    # Softmax: exp(score) / sum(exp(all_scores))\n    # To avoid numerical instability with very large or small scores, we can shift scores.\n    # Subtracting the maximum score before exponentiation is a common technique.\n    shifted_scores = base_scores - np.max(base_scores)\n    exp_scores = np.exp(shifted_scores)\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    # Create the final priority array, placing calculated priorities in their original positions\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(valid_bins_mask):\n        \n        suitable_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        greedy_scores = 1 / (suitable_bins_remain_cap - item + 1e-6) \n        \n        random_scores = np.random.rand(np.sum(valid_bins_mask))\n        \n        combined_scores = epsilon * random_scores + (1 - epsilon) * greedy_scores\n        \n        priorities[valid_bins_mask] = combined_scores\n        \n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 4.2181890706023095,
    "cyclomatic_complexity": 2.0,
    "halstead": 100.07820003461549,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            \n            remaining_cap = bins_remain_cap[i]\n            \n            \n            if remaining_cap == item:\n                priorities[i] = 1.0  # Perfect fit, highest priority\n            else:\n                \n                priorities[i] = 1.0 / (remaining_cap - item + 1e-9) # Inverse proximity, higher score for bins that are closer to fitting the item without being perfect\n                \n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 4.0,
    "halstead": 53.77443751081735,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    effective_capacities = bins_remain_cap[valid_bins] - item\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = np.exp(effective_capacities)\n    \n    if np.sum(priorities) == 0:\n        return np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n        \n    return priorities / np.sum(priorities)",
    "response_id": 19,
    "tryHS": false,
    "obj": 19.186278420422827,
    "cyclomatic_complexity": 3.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  }
]