{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Calculates priority scores for each bin using a combined strategy for\n    the online Bin Packing Problem, balancing \"best fit\" with a penalty for\n    bins that would become excessively full.\n\n    This strategy prioritizes bins that can accommodate the item, favoring those\n    that result in less remaining capacity (\"best fit\"). Additionally, it\n    introduces a penalty for bins that, after packing the item, would have\n    very little remaining capacity, encouraging a more diversified packing\n    strategy to potentially avoid early bin exhaustion.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    # \"Best Fit\" component: Minimize remaining capacity after placing the item.\n    # Higher score for smaller remaining capacity.\n    best_fit_scores = -(valid_bins_remain_cap - item)\n\n    # Diversification component: Penalize bins that become too full.\n    # A threshold can be used, e.g., if remaining_capacity - item < threshold.\n    # Here, we use a sigmoid-like function to penalize as remaining capacity decreases.\n    # This encourages not filling bins too tightly unless absolutely necessary.\n    # We want to *reduce* the score if the bin becomes too full.\n    # A smaller (remaining_capacity - item) means a fuller bin.\n    # Let's create a penalty that is high when (remaining_capacity - item) is low.\n    # Using exp(-x) where x is a scaled version of (remaining_capacity - item)\n    # Smaller x (tighter fit) leads to larger penalty.\n    # We need to be careful with scaling to avoid numerical issues.\n    # Let's use a threshold-based penalty that is smooth.\n    # Consider remaining capacity after packing: `rem_after_pack = valid_bins_remain_cap - item`\n    # We want to penalize small `rem_after_pack`.\n    # A simple penalty could be `penalty = 1 / (1 + exp(k * rem_after_pack))`\n    # where k controls the steepness. A small `rem_after_pack` results in large penalty.\n    # Let's use a small value for k to make it a soft penalty.\n    # Scale remaining capacity to avoid overflow in exp.\n    # For example, map to [0, 10] range.\n    min_rem_after_pack = 0.0\n    max_rem_after_pack = np.max(valid_bins_remain_cap) - item if np.max(valid_bins_remain_cap) >= item else 0.0\n    \n    if max_rem_after_pack == min_rem_after_pack: # Avoid division by zero if all valid bins have same remaining capacity\n        diversification_penalty = np.zeros_like(best_fit_scores)\n    else:\n        rem_after_pack = valid_bins_remain_cap - item\n        # Scale remaining capacity to a reasonable range for the penalty function\n        # e.g., map to [0, 10] to control the steepness of the penalty\n        scaled_rem_after_pack = 10 * (rem_after_pack - min_rem_after_pack) / (max_rem_after_pack - min_rem_after_pack)\n        # Penalty is high for small remaining capacity (tight fit)\n        diversification_penalty = 1.0 / (1.0 + np.exp(5.0 * (1.0 - scaled_rem_after_pack))) # penalty ~ 1 for tight fit, ~ 0 for loose fit\n\n    # Combine scores: Favor best fit, but penalize overly tight fits.\n    # We subtract the penalty from the best_fit_scores.\n    # A higher combined score is better.\n    combined_scores = best_fit_scores - diversification_penalty * 2.0 # Adjust multiplier for penalty strength\n\n    # Apply Softmax to convert scores into probabilities (priorities)\n    # Shift scores to avoid numerical overflow/underflow in exp\n    shifted_scores = combined_scores - np.max(combined_scores)\n    exp_scores = np.exp(shifted_scores)\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    # Create the final priority array\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \n    bin_capacities = 1.0  # Assuming a standard bin capacity of 1.0, can be generalized.\n    \n    potential_fits = bins_remain_cap - item\n    \n    valid_bins_mask = potential_fits >= 0\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(valid_bins_mask):\n        \n        priorities[valid_bins_mask] = 1.0 / (potential_fits[valid_bins_mask] + 1e-9) # Add epsilon to avoid division by zero\n\n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 vs. 2:** Heuristic 1 attempts a more nuanced approach by penalizing \"too empty\" bins and rewarding \"perfect fits\" explicitly, whereas Heuristic 2 uses a simple weighted sum of Best Fit and a diversification score (rewarding ample capacity). Heuristic 1's complexity in defining \"too empty\" and its reliance on `original_bin_capacities` (which are not directly available in the function signature, suggesting a potential flaw or assumption) makes it less robust than Heuristic 2's clearer combination of BF and diversification.\n\n*   **Heuristics 2 vs. 3:** Heuristic 2 combines Best Fit (minimizing remaining capacity) with a diversification component (favoring more initial capacity). Heuristic 3 is purely Best Fit, using Softmax for exploration. Heuristic 2 is likely better as it explicitly balances exploitation (BF) with exploration/diversification, whereas Heuristic 3 relies solely on Softmax's inherent exploration for BF.\n\n*   **Heuristics 3 vs. 7:** Both are pure Best Fit with Softmax. Heuristic 3 has slightly more robust Softmax implementation, handling cases where all scores are identical or near-identical. Heuristic 7 is conceptually similar but might be slightly less robust in edge cases of score distribution.\n\n*   **Heuristics 4 vs. 6:** Heuristic 4 tries to penalize overly tight fits using a sigmoid-like function on scaled remaining capacity. Heuristic 6 also penalizes tight fits but does so with a fixed bonus for perfect fits and a different penalty function. Heuristic 6 appears more structured with explicit components (perfect fit bonus, BF, diversification penalty) and more direct handling of edge cases in its penalty calculation. The scaling in Heuristic 4 for the penalty might be overly complex or sensitive.\n\n*   **Heuristics 5 vs. 1:** These appear to be identical implementations, both attempting a complex combination of BF, perfect fit bonus, and a penalty for large remaining space. The `original_bin_capacities` proxy issue is present in both.\n\n*   **Heuristics 8, 9, 10, 11, 12, 13, 16, 17:** These are all identical and implement a very basic \"inverse proximity\" heuristic: `1.0 / (bins_remain_cap - item + 1e-9)`. This is a simple Best Fit variant but lacks any Softmax normalization or explicit diversification, making it prone to exploitation and potentially unstable if capacities are very small. They are clearly inferior to those using Softmax. Heuristic 11-13 also incorrectly assume a fixed `bin_capacities = 1.0` which is not used.\n\n*   **Heuristics 14 & 15:** These are identical, implementing a loop-based Best Fit with a perfect fit bonus. They are less efficient than vectorized NumPy operations seen in others and lack Softmax, making selection purely greedy for \"perfect fit\" and then inverse proximity.\n\n*   **Heuristics 18:** This uses `np.exp(effective_capacities)` which is essentially an exponential Best Fit. It normalizes using division by the sum, similar to Softmax but without the temperature parameter or explicit score shifting for stability. It's better than the simple inverse proximity but less sophisticated than other Softmax variants.\n\n*   **Heuristics 19 & 20:** These are identical and represent the most sophisticated approach. They combine Best Fit (goodness of fit) and a diversification/Worst Fit tendency (openness) adaptively using an `epsilon` parameter derived from the variance of remaining capacities. This \"adaptive exploration/exploitation\" strategy, coupled with scaled exponential scoring and Softmax, is the most promising for balancing greedy choices with broader exploration.\n\n*   **Overall:** The ranking reflects a progression from simple inverse proximity (worst) to weighted sums of heuristics, explicit component-based combinations, and finally to adaptive, scaled, and diversified Softmax approaches (best). The top heuristics (19/20) are clearly superior due to their adaptive strategy and well-defined scoring components.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Adaptive, Probabilistic, Hybrid, Robustness.\n*   **Advice:** Focus on adaptive parameter tuning for dynamic exploration-exploitation balance, leverage normalized probabilistic selection (e.g., Softmax with careful scaling) for diverse yet informed choices, and integrate hybrid strategies that blend greedy exploitation with systematic exploration.\n*   **Avoid:** Overly simplistic selection mechanisms (e.g., pure greedy), fixed parameter settings, and heuristics that don't account for edge cases like perfect fits or numerical instability.\n*   **Explanation:** Effective self-reflection identifies *how* to dynamically adapt heuristic behavior to problem characteristics, moving beyond static rules to create more generalizable and performant solutions.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}