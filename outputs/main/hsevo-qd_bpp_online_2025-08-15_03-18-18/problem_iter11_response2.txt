```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines adaptive Softmax with a bonus for near-perfect fits and inverse slack.

    This heuristic uses an adaptive beta for Softmax and rewards bins with minimal slack
    after packing, balancing exploration and exploitation for online BPP.
    """
    valid_bins_mask = bins_remain_cap >= item
    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]

    if valid_bins_remain_cap.size == 0:
        return np.zeros_like(bins_remain_cap)

    slacks = valid_bins_remain_cap - item
    epsilon = 1e-9

    # Adaptive beta: higher when slacks are small, lower when large
    mean_slack = np.mean(slacks)
    beta = 1.0 / (mean_slack + epsilon)
    beta = np.clip(beta, 0.1, 10.0)

    # Base scores: reward small slacks using inverse relationship (higher is better)
    # Add epsilon to denominator to avoid division by zero
    base_scores = 1.0 / (slacks + epsilon)

    # Bonus for near-perfect fits
    near_perfect_fit_threshold = 0.01 * item + epsilon
    near_perfect_mask = slacks < near_perfect_fit_threshold
    bonus = 5.0  # Significant bonus for near-perfect fits
    base_scores[near_perfect_mask] += bonus

    scaled_scores = beta * base_scores

    # Softmax calculation
    max_scaled_score = np.max(scaled_scores)
    exp_scores = np.exp(scaled_scores - max_scaled_score)
    sum_exp_scores = np.sum(exp_scores)

    if sum_exp_scores == 0:
        probabilities = np.ones_like(valid_bins_remain_cap) / len(valid_bins_remain_cap)
    else:
        probabilities = exp_scores / sum_exp_scores

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    priorities[valid_bins_mask] = probabilities

    return priorities
```
