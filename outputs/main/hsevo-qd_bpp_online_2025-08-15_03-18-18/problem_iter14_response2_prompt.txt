{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Calculates priority scores for each bin using an adaptive, sensitivity-aware\n    strategy for the online Bin Packing Problem.\n\n    This heuristic aims to balance \"Best Fit\" (minimizing waste) with a\n    \"First Fit Decreasing\"-like tendency by slightly favoring bins that are\n    less full initially, but can still accommodate the item. It also incorporates\n    an adaptive component that can subtly shift focus based on the diversity\n    of available bin capacities.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element represents the\n                         remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item in the corresponding bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    # --- Core Heuristic Component: Best Fit / Least Waste ---\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    # A lower (valid_bins_remain_cap - item) is better.\n    waste = valid_bins_remain_cap - item\n    best_fit_scores = -waste  # Maximize this score (minimize waste)\n\n    # --- Adaptive Component: Sensitivity to Bin Fullness ---\n    # Introduce a term that favors bins that are not excessively full *before*\n    # packing, but are still valid. This encourages spreading items initially,\n    # while still respecting the 'best fit' for the current item.\n    # We can achieve this by looking at the distribution of current bin capacities.\n    # If there's high variance in remaining capacities, we might slightly favor\n    # bins with more remaining capacity (but still fit the item).\n    # If capacities are very similar, focus more on best fit.\n\n    # Calculate a 'spread' factor based on the standard deviation of *all* bins' remaining capacities.\n    # A higher std dev means more diverse capacities.\n    if bins_remain_cap.size > 1:\n        std_dev_all_bins = np.std(bins_remain_cap)\n        # Normalize std_dev by the average capacity to make it somewhat scale-invariant.\n        # Add a small epsilon to avoid division by zero.\n        avg_cap_all_bins = np.mean(bins_remain_cap) + 1e-9\n        spread_factor = std_dev_all_bins / avg_cap_all_bins\n    else:\n        spread_factor = 0 # No spread if only one bin\n\n    # The adaptive score component:\n    # We want to increase the priority of bins with *more* remaining capacity\n    # when the spread_factor is high.\n    # Let's use the relative remaining capacity (valid_bins_remain_cap / bin_capacity_max_possible)\n    # for this term. Or simpler, just the raw remaining capacity.\n    # We want to positively correlate with remaining capacity, scaled by spread_factor.\n    # A simple approach: `spread_factor * (valid_bins_remain_cap / max_possible_capacity)`\n    # Let's use a simplified approach focusing on relative difference for now.\n    # We want to favor bins that are \"less full\" when spread is high.\n    # `valid_bins_remain_cap` is a proxy for \"less full\".\n    # So, a term like `spread_factor * valid_bins_remain_cap` could be added.\n\n    # A more nuanced approach: use the 'gap' (capacity - item)\n    # We want to penalize bins that result in a very small gap (best fit).\n    # Consider `spread_factor * (item / valid_bins_remain_cap)` - encourages using bins with more space\n    # when spread is high.\n\n    # Let's combine the two:\n    # Priority = w1 * (-waste) + w2 * (adaptive_term)\n    # We want to favor smaller waste.\n    # The adaptive term should make bins with *more* remaining capacity more attractive\n    # when `spread_factor` is high.\n\n    # Let's try a score that combines best-fit and a tendency to use bins\n    # that are not *critically* full.\n    # Score = BestFitScore - PenaltyForBeingTooFull\n    # PenaltyForBeingTooFull could be related to `1 / valid_bins_remain_cap` or `(max_cap - valid_bins_remain_cap)`.\n\n    # A new composite score:\n    # Base score: -(waste)  (favors minimal waste)\n    # Adaptive modifier: A term that slightly boosts bins with more remaining capacity,\n    # but this boost is stronger when `spread_factor` is higher.\n    # Consider `spread_factor * (valid_bins_remain_cap / average_remaining_capacity_of_valid_bins)`\n    # This gives a relative measure of how much space is left in a bin compared to average.\n\n    avg_valid_remain_cap = np.mean(valid_bins_remain_cap) + 1e-9\n    relative_remaining_cap = valid_bins_remain_cap / avg_valid_remain_cap\n\n    # The adaptive score: a multiplicative boost based on spread and relative remaining capacity.\n    # We want to amplify the priority of bins that are relatively spacious when diversity is high.\n    # This is a soft preference, not overriding best-fit entirely.\n    # A small additive term is safer for Softmax stability.\n    adaptive_scores = spread_factor * (relative_remaining_cap - 1.0) # Center around 0, positive for more remaining cap\n\n    # Combine scores: best_fit_scores are already designed to be maximized.\n    # adaptive_scores are also designed to be maximized (positive means good)\n    combined_scores = best_fit_scores + adaptive_scores\n\n    # Softmax to convert scores into probabilities (priorities)\n    # Shift scores to prevent overflow/underflow in exp.\n    if np.all(np.isfinite(combined_scores)):\n        shifted_scores = combined_scores - np.max(combined_scores)\n        exp_scores = np.exp(shifted_scores)\n        probabilities = exp_scores / np.sum(exp_scores)\n    else:\n        # Handle potential NaNs or Infs by reverting to a simple best-fit if calculation fails\n        # (though the logic above should prevent this with epsilon)\n        shifted_scores = best_fit_scores - np.max(best_fit_scores)\n        exp_scores = np.exp(shifted_scores)\n        probabilities = exp_scores / np.sum(exp_scores)\n\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[valid_bins_mask] = probabilities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities[suitable_bins_mask] = 1.0 / (bins_remain_cap[suitable_bins_mask] - item + 1e-9)\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1 and 5: Heuristic 1 uses `-(valid_bins_remain_cap - item)` as its base score, which directly implements the \"Best Fit\" principle by maximizing this value (minimizing waste). Heuristic 5 also uses this, but adds robustness checks for identical scores and zero sums, making it slightly more stable.\n\nComparing Heuristics 2 and 6: Both introduce an \"adaptive diversification\" component. Heuristic 2 uses variance to adjust the score, aiming to diversify when variance is low. Heuristic 6 refines this by adding a specific \"perfect fit bonus\" and a more complex adaptive diversification score tied to relative variance, making it more nuanced.\n\nComparing Heuristics 3 and 4: Heuristic 3 attempts to balance \"Best Fit\" with a tendency to favor less full bins based on overall bin capacity spread. It introduces a `spread_factor` and `relative_remaining_cap`. Heuristic 4 introduces an adaptive temperature parameter for Softmax, controlled by the number of valid bins and their standard deviation, along with a diversity bonus. Heuristic 4's adaptive temperature is a more sophisticated mechanism for controlling exploration/exploitation.\n\nComparing Heuristics 7 and 20: Heuristic 7 is identical to Heuristic 5. Heuristic 20 introduces a blend of \"Best Fit\" and \"Worst Fit\" tendencies, adapting the balance using an `epsilon` parameter derived from the variance of remaining capacities. This adaptive blending is a strong strategy for managing exploration vs. exploitation.\n\nComparing Heuristics 9-16 (repeated implementations of `1 / (potential_fits + epsilon)`) with Heuristics 1, 2, 3, 4, 6, 8, 20: The latter group uses more sophisticated scoring mechanisms, often involving combinations of factors (Best Fit, diversification, adaptive elements) and applying Softmax for probabilistic selection. Heuristics 9-16 are simple, potentially prone to extreme values and don't incorporate adaptive strategies or explicit diversification. Heuristic 17-19 use `np.exp(effective_capacities)` which would disproportionately favor bins with very large remaining capacities, not necessarily ideal for packing efficiency.\n\nOverall: Heuristics 1, 2, 3, 4, 6, 8, and 20 demonstrate a progression towards more complex, adaptive, and robust strategies. Heuristics 20, 4, and 6 appear to be the most advanced, incorporating adaptive parameters (temperature, epsilon) and multi-faceted scoring. Heuristics 1, 5, and 7 represent a solid \"Best Fit\" baseline with Softmax. Heuristics 9-16 are simplistic and less effective. Heuristics 17-19 have an unusual scoring mechanism.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective, Adaptive, Probabilistic, Hybridization.\n*   **Advice:** Focus on heuristics that integrate multiple criteria (e.g., fit quality, diversity) and dynamically adjust their behavior based on problem instance characteristics. Leverage robust probabilistic selection methods like Softmax with careful parameterization.\n*   **Avoid:** Simplistic, static scoring functions, neglecting numerical stability, and overly complex, untuned adaptive mechanisms.\n*   **Explanation:** The goal is to create intelligent, flexible heuristics that balance exploration and exploitation by understanding and responding to the problem's evolving state, ensuring both efficiency and robustness.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}