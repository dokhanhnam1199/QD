```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Calculates bin priorities using a hybrid approach:
    1. Prioritizes perfect fits (zero remaining capacity).
    2. Favors "best fit" bins by penalizing remaining capacity.
    3. Applies a penalty to avoid overly tight fits, promoting diversity.
    4. Normalizes scores using Softmax for a probabilistic distribution.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    
    # Mask for bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item
    
    # Handle the case where no bins can fit the item
    if not np.any(can_fit_mask):
        return priorities
    
    # Extract capacities of bins that can fit the item
    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]
    
    # Calculate remaining capacity after packing for valid bins
    rem_after_pack = valid_bins_remain_cap - item
    
    # --- Component 1: Perfect Fit Bonus ---
    # High score for bins that become exactly full
    perfect_fit_bonus = np.where(rem_after_pack == 0, 10.0, 0.0)
    
    # --- Component 2: Best Fit (Inverse Proximity) ---
    # Score inversely proportional to remaining capacity (smaller remaining capacity is better)
    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0 (handled by bonus)
    best_fit_score = -rem_after_pack
    
    # --- Component 3: Diversification Penalty ---
    # Penalize bins that would have very little remaining capacity after packing,
    # but only if they are not a perfect fit.
    # We use a sigmoid-like function to penalize as remaining capacity decreases.
    # Scale remaining capacity to avoid large exponential values.
    # The penalty is higher for smaller `rem_after_pack`.
    min_rem = np.min(rem_after_pack[rem_after_pack > 0]) if np.any(rem_after_pack > 0) else 0
    max_rem = np.max(rem_after_pack) if np.any(rem_after_pack > 0) else 0
    
    diversification_penalty = np.zeros_like(valid_bins_remain_cap)
    if max_rem > min_rem: # Avoid division by zero if all valid bins have the same remaining capacity > 0
        # Scale non-zero remaining capacities to a range like [0, 10]
        scaled_rem = 10 * (rem_after_pack[rem_after_pack > 0] - min_rem) / (max_rem - min_rem)
        # Apply penalty: higher penalty for smaller scaled_rem (tighter fits)
        # Using exp(k * (1 - x)) makes the penalty high when x is small.
        penalty_strength = 5.0
        diversification_penalty[rem_after_pack > 0] = 1.0 / (1.0 + np.exp(penalty_strength * (1.0 - scaled_rem)))
    elif np.any(rem_after_pack == 0): # If there are perfect fits but no other valid fits, no diversification penalty needed
        pass
    elif np.any(rem_after_pack > 0): # If all valid fits have the same positive remaining capacity
        pass # No penalty needed as they are all equally "open"

    # Combine scores: perfect_fit_bonus + best_fit_score - diversification_penalty * weight
    # The weight controls how strongly we penalize tight fits.
    penalty_weight = 2.0
    combined_scores = perfect_fit_bonus + best_fit_score - diversification_penalty * penalty_weight
    
    # --- Component 4: Softmax Normalization ---
    # Convert scores to probabilities (priorities)
    # Shift scores to avoid numerical instability with exp
    shifted_scores = combined_scores - np.max(combined_scores)
    exp_scores = np.exp(shifted_scores)
    probabilities = exp_scores / np.sum(exp_scores)
    
    # Place probabilities back into the original priority array structure
    priorities[can_fit_mask] = probabilities
    
    return priorities
```
