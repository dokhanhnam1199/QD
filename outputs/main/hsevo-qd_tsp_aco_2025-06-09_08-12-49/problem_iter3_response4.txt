```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Combines several factors, including distance, node degree, and clustering coefficient
    to prioritize edges for the TSP, and sparsifies the result.
    """
    n = distance_matrix.shape[0]
    heuristics = np.zeros_like(distance_matrix)
    epsilon = 1e-9
    safe_distance_matrix = distance_matrix + epsilon

    # 1. Inverse Distance: Shorter edges are generally better
    inverse_distance = 1 / safe_distance_matrix

    # 2. Node Degree Heuristic:  Prefer edges connected to nodes with low degree
    #    (encourages exploration, avoids getting stuck in dense clusters early)
    degree = np.sum(distance_matrix < np.mean(distance_matrix), axis=1) #simplified degree
    degree_matrix = np.outer(degree, degree)
    degree_heuristic = 1 / (degree_matrix + epsilon)  # Lower degree -> higher value

    # 3. Clustering Coefficient Approximation:  Nodes in sparse regions are more valuable
    #    (a very basic approximation)
    neighbor_similarity = np.zeros((n, n))
    for i in range(n):
        neighbors_i = np.where(distance_matrix[i, :] < np.mean(distance_matrix))[0]
        for j in range(n):
            if i != j:
                neighbors_j = np.where(distance_matrix[j, :] < np.mean(distance_matrix))[0]
                common_neighbors = np.intersect1d(neighbors_i, neighbors_j).size
                neighbor_similarity[i, j] = common_neighbors / (min(neighbors_i.size, neighbors_j.size) + epsilon)


    #4. Combine the Heuristics
    heuristics = (0.6 * inverse_distance +
                  0.2 * degree_heuristic +
                  0.2 * (1 - neighbor_similarity))


    # 5. Sparsification: Remove edges that are unlikely to be in the optimal tour.
    # Keep only the top k edges for each node (reduces search space)
    k = int(np.sqrt(n))  # Adjust k as needed - crucial hyperparameter
    for i in range(n):
        row = heuristics[i, :]
        indices = np.argpartition(row, -k)[-k:] #Indices of k largest elements

        mask = np.ones(n, dtype=bool)
        mask[indices] = False
        heuristics[i, mask] = 0
        heuristics[i, i] = 0   # Ensure no self-loops


    # 6. Normalization (after sparsification)
    min_heuristic = np.min(heuristics)
    max_heuristic = np.max(heuristics)
    if max_heuristic > min_heuristic:
        heuristics = (heuristics - min_heuristic) / (max_heuristic - min_heuristic)
    else:
        heuristics = np.ones_like(heuristics) #Handles the edge case where all values are the same

    return heuristics
```
