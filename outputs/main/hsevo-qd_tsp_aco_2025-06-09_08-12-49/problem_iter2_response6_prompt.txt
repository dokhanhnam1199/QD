{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Newtonian Heuristic for TSP Edge Prioritization.\n\n    This heuristic combines elements inspired by gravitational attraction and\n    energy minimization to guide TSP solution sampling.  Edges connecting nodes\n    that are \"attracted\" to each other more strongly (closer distance, higher\n    pseudo-mass) are favored. A term discouraging long edges (high potential\n    energy) is also included.\n\n    Args:\n        distance_matrix (np.ndarray): A symmetric numpy array representing the\n            pairwise distances between cities. distance_matrix[i, j] is the\n            distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, representing\n            the heuristic \"promise\" of each edge. Higher values indicate\n            more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # Avoid division by zero by adding a small epsilon to distances.\n    epsilon = 1e-9\n    safe_distance_matrix = distance_matrix + epsilon\n\n    # Gravitational attraction component (inverse square law): cities closer together are more attracted\n    attraction = 1 / (safe_distance_matrix**2)\n\n    # Node \"mass\" proxy: how \"central\" is a city. We assign mass using degree centrality:\n    # sum the inverse distance to all other cities. A city close to many others is more important.\n\n    mass = np.sum(1 / safe_distance_matrix, axis=1) #mass of the city\n\n    # Create a matrix M[i][j] = mass[i]*mass[j]\n    M = np.outer(mass, mass)\n\n    # Potential energy penalty: long edges are less desirable. Scale to be compatible with the 'gravitational' term\n    potential_energy = safe_distance_matrix / np.mean(safe_distance_matrix) # normalized distance\n\n\n    heuristics = (attraction * M) / potential_energy\n\n    # Normalize to range [0, 1] for numerical stability and interpretability, and to bound effect during search\n    min_heuristic = np.min(heuristics)\n    max_heuristic = np.max(heuristics)\n    heuristics = (heuristics - min_heuristic) / (max_heuristic - min_heuristic)\n\n\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first heuristic uses a Newtonian approach, considering gravitational attraction and potential energy, along with normalization, while the last one simply returns the inverse of the distance matrix.\n(2nd) vs (19th) - Same as above. The second heuristic is identical to the first, and the 19th is the simple inverse distance heuristic.\nComparing (1st) vs (2nd), we see they are identical. The Newtonian heuristic is repeated multiple times.\nComparing (3rd) vs (4th), we see they are identical to the 1st and 2nd.\nComparing (2nd worst) vs (worst), we see they are identical, all just returning the inverse of the distance matrix.\nOverall: The top 10 heuristics are identical, implementing a Newtonian-inspired approach. The bottom 10 heuristics are also identical, using a simple inverse distance calculation. The difference in ranking stems from the more sophisticated approach of the Newtonian heuristic compared to the basic inverse distance method. The repeated code suggests a failure in properly evaluating and differentiating heuristic performance.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine \"Current Self-Reflection\" to make it more effective for designing better heuristics. We'll focus on actionability and avoiding common pitfalls.\n\nHere's a redefined \"Current Self-Reflection\":\n\n*   **Keywords:** Feature Engineering, Analogical Thinking, Normalization, Empirical Validation, Code Efficiency, Adaptive Learning.\n*   **Advice:** Rigorously analyze problem structure, leverage domain knowledge for feature selection, draw inspiration from diverse fields, and adapt heuristic parameters based on performance feedback.\n*   **Avoid:** Premature optimization, relying solely on intuition, neglecting edge cases, and insufficient performance benchmarking.\n*   **Explanation:** Prioritize deep problem understanding, informed feature creation, adaptable strategies, and robust validation for superior heuristic design.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}