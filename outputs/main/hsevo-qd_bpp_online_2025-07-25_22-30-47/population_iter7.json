[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines fit penalty, balance heuristic, and sigmoid functions for efficient bin placement.\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    fit_penalty = 1 - (space_left / bins_remain_cap)\n    close_fit_factor = np.clip(bins_remain_cap - item, 0, 1)\n    \n    # Balance heuristic: Penalize bins that are too full or too empty\n    average_remain_cap = np.mean(bins_remain_cap)\n    balance_penalty = np.exp(-((bins_remain_cap - average_remain_cap) ** 2) / (2 * (average_remain_cap / 4) ** 2))\n    \n    # Combined score using sigmoid for balance and fit\n    priority_score = can_fit * (fit_penalty + close_fit_factor) * balance_penalty\n    return priority_score",
    "response_id": 0,
    "tryHS": false,
    "obj": 57.21978460311129,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances fit-check with a sigmoid penalty for larger remaining space to optimize bin usage.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    sigmoid_steepness = 5.0  # Adjusted for better performance\n    sigmoid_offset = 1.5     # Adjusted for better performance\n    penalty = 1 / (1 + np.exp(sigmoid_steepness * (space_left - sigmoid_offset)))\n    priority = can_fit * penalty\n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines fit penalty, balance heuristic, and sigmoid to prioritize bins efficiently.\n\n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    fit_penalty = 1 - (space_left / bins_remain_cap)\n    close_fit_factor = np.clip(bins_remain_cap - item, 0, 1)\n    sigmoid_penalty = 1 / (1 + np.exp(-5 * (space_left - np.min(space_left))))\n    average_remain_cap = np.mean(bins_remain_cap)\n    balance_score = np.exp(-((bins_remain_cap - average_remain_cap) ** 2) / (2 * (average_remain_cap / 4) ** 2))\n    priority = can_fit * (fit_penalty + close_fit_factor + sigmoid_penalty + balance_score)\n    return priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 49.321898683685696,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances fit suitability and leftover space using adaptive sigmoid penalties.\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    fit_priority = can_fit * (1 - (space_left / bins_remain_cap))\n    close_fit_priority = np.clip(bins_remain_cap - item, 0, 1)\n    sigmoid_penalty = 1.0 / (bins_remain_cap + 1e-6) * np.sin(np.pi / 2 * (bins_remain_cap / (np.max(bins_remain_cap) + 1e-6)))\n    priority = 0.6 * fit_priority + 0.2 * close_fit_priority + 0.2 * sigmoid_penalty\n    return priority",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.876346230554457,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines fit suitability and adaptive balancing to prioritize bins for online BPP.\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    # Adaptive fit priority with sigmoid penalty for leftover space\n    fit_priority = can_fit * (1 - (space_left / bins_remain_cap))\n    # Balance priority to avoid extreme tightness or emptiness\n    avg_remain_cap = np.mean(bins_remain_cap_safe)\n    balance_priority = 1 - np.abs(bins_remain_cap - avg_remain_cap) / avg_remain_cap\n    # Combine priorities with adaptive weights\n    priority = 0.6 * fit_priority + 0.4 * balance_priority\n    return priority",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 19, in priority_v2\n    0.5 * scaled_remaining_capacity +\nNameError: name 'bins_remain_cap_safe' is not defined. Did you mean: 'bins_remain_cap'?\n16\n2\n"
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines scaled remaining capacity, balance factor, and waste reduction to prioritize bins effectively.\n    \"\"\"\n    # Scaled Remaining Capacity: Lower capacity -> Higher priority\n    scaled_remaining_capacity = 1.0 / (bins_remain_cap + 1e-6)\n    \n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap)\n    \n    # Waste Reduction: Prioritize bins that fit the item well\n    waste_reduction = np.where(bins_remain_cap - item >= 0, bins_remain_cap - item, -1000)\n    \n    # Combine heuristics\n    priority_scores = (\n        0.5 * scaled_remaining_capacity +\n        0.3 * (1 - balance_factor / np.max(balance_factor + 1e-6)) +\n        0.2 * waste_reduction\n    )\n    \n    return priority_scores",
    "response_id": 5,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fit-check with adaptive sigmoid penalty to minimize leftover space and avoid new bins.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    penalty = 1 / (1 + np.exp(space_left / np.max(bins_remain_cap)))  # Adaptive sigmoid penalty\n    priority = can_fit * penalty - (bins_remain_cap < item) * np.max(bins_remain_cap) / 2.0\n    return priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances fit and leftover space with a penalty for excessive waste and a sigmoid to fit items well.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    fit_penalty = 1 - (space_left / bins_remain_cap)\n    close_fit_factor = np.clip(bins_remain_cap - item, 0, 1)\n    waste_reduction = space_left\n    balance_factor = 1.0 / (bins_remain_cap + 1e-6)\n    priority = can_fit * (fit_penalty + close_fit_factor) * balance_factor\n    return priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.926206621459921,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritize bins by balancing the remaining capacity and leftover space efficiency with adaptive penalties.\"\"\"\n    ifbinsfit = bins_remain_cap >= item\n    leftover_space = bins_remain_cap - item\n    # Sigmoid penalty for leftover space\n    sigmoid_penalty = 1.0 / (leftover_space + 1e-6)\n    # Adjusted priority combining fit and penalty\n    priority = np.where(ifbinsfit, sigmoid_penalty * (bins_remain_cap / np.max(bins_remain_cap, initial=1.0)), -np.inf)\n    return priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by combining adaptive learning, balance factor, and sigmoid penalty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Parameters for adaptive learning\n    alpha = 0.6  # Weight for Scaled Remaining Capacity\n    beta = 0.3   # Weight for Balance Factor\n    gamma = 0.1  # Weight for Last Fit Decrease\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1.0 / (bins_remain_cap - item + 1e-6), -np.inf)\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 9,
    "tryHS": true,
    "obj": 3.7295572397287686,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty, with refined parameters.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Refined Parameters for adaptive learning\n    alpha = 0.7  # Increased weight for Scaled Remaining Capacity\n    beta = 0.2   # Reduced weight for Balance Factor\n    gamma = 0.1  # Weight for Last Fit Decrease remains the same\n\n    # Scaled Remaining Capacity with sigmoid penalty: refine sigmoid to avoid steep gradients\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1.0 / (bins_remain_cap - item + 1e-3), -np.inf)\n\n    # Balance Factor: Encourage balanced distribution with a quadratic penalty\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = (bins_remain_cap - mean_cap) ** 2 / (np.max(np.abs(bins_remain_cap - mean_cap))**2 + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic: refine to penalize larger gaps more aggressively\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = np.where(bins_remain_cap[:-1] - bins_remain_cap[1:] > 0, \n                                         (bins_remain_cap[:-1] - bins_remain_cap[1:]) ** 2, 0)\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        (1 - beta) * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.457518946948548,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty while refining parameters.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Enhanced parameters for adaptive learning\n    alpha = 0.65  # Higher weight for Scaled Remaining Capacity to prioritize tighter fits\n    beta = 0.3   # Balanced weight for Balance Factor to maintain efficiency\n    gamma = 0.05  # Lower weight for Last Fit Decrease to avoid overly penalizing variation\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    # Sigmoid function parameters adjusted for better discrimination\n    sigmoid_k = 1.5  # Steepness of the sigmoid curve\n    sigmoid_x0 = item  # Midpoint of the sigmoid curve\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1 / (1 + np.exp(sigmoid_k * (bins_remain_cap - sigmoid_x0))), -np.inf)\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 1,
    "tryHS": false,
    "obj": 5.913442361388109,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty, with refined parameters.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Enhanced Parameters for adaptive learning\n    alpha = 0.7  # Slightly increase weight for Scaled Remaining Capacity\n    beta = 0.25  # Slightly decrease weight for Balance Factor\n    gamma = 0.05 # Further reduce weight for Last Fit Decrease\n\n    # Scaled Remaining Capacity with enhanced sigmoid penalty\n    # Adjusted to emphasize bins with more space left\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1.0 / (bins_remain_cap - item + 1e-6), -np.inf)\n\n    # Enhanced Balance Factor: More aggressive towards balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n    balance_factor = np.power(balance_factor, 0.5)  # Introduce non-linearity to enhance balance\n\n    # Enhanced Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = (bins_remain_cap[:-1] - bins_remain_cap[1:]) / (bins_remain_cap[:-1] + 1e-6)\n\n    # Combine heuristics with enhanced adaptive learning\n    priority_scores = (\n        alpha * (scaled_remaining_capacity - np.min(scaled_remaining_capacity) + 1e-6) +  # Normalize scaled capacity\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 2,
    "tryHS": false,
    "obj": 39.449541284403686,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty, with refined parameters.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Enhanced Parameters for adaptive learning\n    alpha = 0.7  # Slightly increase weight for Scaled Remaining Capacity\n    beta = 0.25  # Slightly decrease weight for Balance Factor\n    gamma = 0.05 # Further reduce weight for Last Fit Decrease\n\n    # Scaled Remaining Capacity with enhanced sigmoid penalty\n    # Adjusted to emphasize bins with more space left\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1.0 / (bins_remain_cap - item + 1e-6), -np.inf)\n\n    # Enhanced Balance Factor: More aggressive towards balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n    balance_factor = np.clip(balance_factor, 0, 1)  # Ensure balance_factor is within [0, 1]\n\n    # Last Fit Decrease (LFD) Heuristic with slight adjustment\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = np.maximum(bins_remain_cap[:-1] - bins_remain_cap[1:], 0)\n\n    # Combined heuristics with refined adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        -beta * balance_factor +  # Invert the balance factor to positive impact\n        gamma * last_fit_decrease\n    )\n\n    # Adjust priority scores to prioritize less filled bins slightly more\n    priority_scores -= 0.01 * (1 - (bins_remain_cap / np.max(bins_remain_cap)))\n    \n    return priority_scores",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.287993617869964,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty dynamically.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Parameters for adaptive learning\n    alpha = 0.7  # Increased weight for Scaled Remaining Capacity\n    beta = 0.2   # Reduced weight for Balance Factor\n    gamma = 0.1  # Reduced weight for Last Fit Decrease\n\n    # Enhanced Scaled Remaining Capacity with adaptive sigmoid penalty\n    sigmoid_penalty = np.exp(-np.power((bins_remain_cap - item) / (np.std(bins_remain_cap) + 1e-6), 2))\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, sigmoid_penalty, -np.inf)\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic with dynamic adjustment\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = np.log(bins_remain_cap[:-1] - bins_remain_cap[1:] + 1)\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 4,
    "tryHS": false,
    "obj": 3.948942959712818,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response4.txt_stdout.txt",
    "code_path": "problem_iter7_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float, \n    bins_remain_cap: np.ndarray, \n    alpha: float = 0.4499271859778464, \n    beta: float = 0.04843602212790765, \n    gamma: float = 0.2684362640521154, \n    sigmoid_penalty_threshold: float = 2.7985568202021485e-06, \n    balance_factor_threshold: float = 2.129867250402941e-06) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by combining adaptive learning, balance factor, and sigmoid penalty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        alpha: Weight for Scaled Remaining Capacity.\n        beta: Weight for Balance Factor.\n        gamma: Weight for Last Fit Decrease.\n        sigmoid_penalty_threshold: Threshold for sigmoid penalty calculation.\n        balance_factor_threshold: Threshold for balance factor calculation.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + balance_factor_threshold)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 4,
    "tryHS": true,
    "obj": 3.5500598324691004,
    "SLOC": 24.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]