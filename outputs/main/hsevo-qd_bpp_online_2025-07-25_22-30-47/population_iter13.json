[
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by combining adaptive learning, balance factor, and sigmoid penalty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Parameters for adaptive learning\n    alpha = 0.6  # Weight for Scaled Remaining Capacity\n    beta = 0.3   # Weight for Balance Factor\n    gamma = 0.1  # Weight for Last Fit Decrease\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1.0 / (bins_remain_cap - item + 1e-6), -np.inf)\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 9,
    "tryHS": true,
    "obj": 3.7295572397287686,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response1.txt_stdout.txt",
    "code_path": "problem_iter10_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float, \n    bins_remain_cap: np.ndarray, \n    alpha: float = 0.8703526170915381, \n    beta: float = 0.26928992154797116, \n    gamma: float = 0.015623035472155156, \n    sigmoid_penalty_threshold: float = 7.870147266070587e-06, \n    balance_factor_threshold: float = 8.54060876899628e-06) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by combining adaptive learning, balance factor, and sigmoid penalty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        alpha: Weight for Scaled Remaining Capacity.\n        beta: Weight for Balance Factor.\n        gamma: Weight for Last Fit Decrease.\n        sigmoid_penalty_threshold: Threshold for sigmoid penalty calculation.\n        balance_factor_threshold: Threshold for balance factor calculation.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + balance_factor_threshold)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 1,
    "tryHS": true,
    "obj": 3.1013163143199183,
    "SLOC": 24.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive learning with sigmoid penalties and balance factor for efficient bin placement.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    alpha = 0.5  # Weight for Scaled Remaining Capacity\n    beta = 0.3   # Weight for Balance Factor\n    gamma = 0.2  # Weight for Last Fit Decrease\n    sigmoid_penalty_threshold = 1e-6\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 5,
    "tryHS": true,
    "obj": 3.6298364579178393,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by dynamically adjusting weights based on real-time feedback and using\n    smooth sigmoid penalties to enhance bin packing efficiency.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Dynamic weights based on current system state\n    system_load = np.mean(bins_remain_cap)\n    total_capacity = np.sum(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n    load_factor = system_load / (total_capacity / num_bins) if total_capacity > 0 else 1.0\n    \n    # Adaptive learning: adjust weights based on load factor\n    alpha = np.clip(0.5 + 0.5 * np.tanh((load_factor - 0.5) * 2), 0.0, 1.0)  # Scaled Remaining Capacity\n    beta = np.clip(0.5 - 0.4 * np.tanh((load_factor - 0.5) * 2), 0.0, 1.0)  # Balance Factor\n    gamma = np.clip(0.2 + 0.3 * np.tanh((load_factor - 0.5) * 3), 0.0, 1.0)  # Last Fit Decrease\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    sigmoid_penalty_threshold = 1e-6\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.380534503390516,
    "SLOC": 28.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins using a combination of adaptive learning and dynamic balance factors.\n    \n    Args:\n        item: Size of item to be added to a bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Adaptive weights for heuristics components\n    alpha = 0.8703526170915381  # Scaled Remaining Capacity\n    beta = 0.26928992154797116   # Balance Factor\n    gamma = 0.015623035472155156  # Last Fit Decrease\n\n    # Dynamic thresholds\n    sigmoid_penalty_threshold = 7.870147266070587e-06\n    balance_factor_threshold = 8.54060876899628e-06\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Dynamic Balance Factor: Encourage balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + balance_factor_threshold)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 4,
    "tryHS": false,
    "obj": 3.1013163143199183,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritize bins by combining adaptive learning, dynamic balance factor, and refined penalty mechanisms.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Adaptive Threshold Calculation\n    max_bin_capacity = np.max(bins_remain_cap)\n    threshold_factor = 0.05  # Dynamic adjustment factor\n    sigmoid_penalty_threshold = max_bin_capacity * threshold_factor\n    balance_factor_threshold = max_bin_capacity * threshold_factor\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Refined Balance Factor: Encourage a more balanced distribution with adaptive threshold\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.where(\n        np.abs(mean_cap - bins_remain_cap) < balance_factor_threshold, \n        0, \n        np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + balance_factor_threshold)\n    )\n\n    # Last Fit Decrease (LFD) Heuristic with dynamic weighting\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n    last_fit_decrease_weight = 0.02  # Dynamic weight for LFD\n\n    # Dynamic Weights for heuristics based on the number of bins and average remaining capacity\n    alpha = 2 / (1 + np.exp(-0.5 * len(bins_remain_cap)))  # Scaled Remaining Capacity weight\n    beta = 1 - alpha  # Balance Factor weight\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        last_fit_decrease_weight * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.2181890706023095,
    "SLOC": 30.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_hs3.txt_stdout.txt",
    "code_path": "problem_iter13_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float, \n    bins_remain_cap: np.ndarray,\n    alpha: float = 0.6889072020207402,  # Weight for Scaled Remaining Capacity\n    beta: float = 0.27864877187020565,   # Weight for Balance Factor\n    gamma: float = 0.1859532598991715,  # Weight for Last Fit Decrease\n    sigmoid_penalty_threshold: float = 2.595177488362933e-06) -> np.ndarray:\n    \"\"\"\n    Combines adaptive learning with sigmoid penalties and balance factor for efficient bin placement.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        alpha: Weight for Scaled Remaining Capacity.\n        beta: Weight for Balance Factor.\n        gamma: Weight for Last Fit Decrease.\n        sigmoid_penalty_threshold: Threshold for sigmoid penalty.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores",
    "response_id": 0,
    "tryHS": true,
    "obj": 3.470283207020339,
    "SLOC": 23.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]