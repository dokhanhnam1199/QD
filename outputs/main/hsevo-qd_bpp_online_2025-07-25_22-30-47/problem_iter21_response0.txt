```python
import numpy as np
from sklearn.linear_model import LinearRegression

class AdaptivePriorityV2:
    def __init__(self):
        self.alpha = 0.8703526170915381
        self.beta = 0.26928992154797116
        self.gamma = 0.015623035472155156
        self.sigmoid_penalty_threshold = 7.870147266070587e-06
        self.balance_factor_threshold = 8.54060876899628e-06
        self.model = LinearRegression()
        self.performance_data = []

    def update_weights(self):
        if len(self.performance_data) > 10:  # Only retrain after some data has been collected
            X = np.array([p[:3] for p in self.performance_data])
            y = np.array([p[3] for p in self.performance_data])
            self.model.fit(X, y)
            self.alpha, self.beta, self.gamma = self.model.predict([[self.alpha, self.beta, self.gamma]])[0]
            # Ensure weights remain non-negative and sum to 1
            total_weight = self.alpha + self.beta + self.gamma
            if total_weight > 0:
                self.alpha /= total_weight
                self.beta /= total_weight
                self.gamma /= total_weight
            self.performance_data = []  # Reset performance data after updating

    def priority_v2(self, item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
        # Scaled Remaining Capacity with sigmoid penalty
        scaled_remaining_capacity = np.where(
            bins_remain_cap >= item, 
            item / (bins_remain_cap - item + self.sigmoid_penalty_threshold),  # Adjusted to favor larger items
            -np.inf
        )

        # Balance Factor: Encourage a more balanced distribution
        mean_cap = np.mean(bins_remain_cap)
        balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + self.balance_factor_threshold)

        # Last Fit Decrease (LFD) Heuristic
        last_fit_decrease = np.zeros_like(bins_remain_cap)
        if len(bins_remain_cap) > 1:
            last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]

        # Combine heuristics with adaptive learning
        priority_scores = (
            self.alpha * scaled_remaining_capacity +
            self.beta * (1 - balance_factor) +
            self.gamma * last_fit_decrease
        )

        # Record performance data (example: number of bins used, could be more sophisticated)
        num_bins_used = np.sum(priority_scores != -np.inf)
        self.performance_data.append([self.alpha, self.beta, self.gamma, num_bins_used])

        # Periodically update weights
        self.update_weights()

        return priority_scores

# Usage
# bpp_solver = AdaptivePriorityV2()
# item_size = 0.5
# bins_remaining_capacities = np.array([1.0, 0.8, 0.6])
# priority_scores = bpp_solver.priority_v2(item_size, bins_remaining_capacities)
```
