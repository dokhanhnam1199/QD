```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, adaptation_factor: float = 0.05, item_size_history: list = []) -> np.ndarray:
    """
    Prioritize bins by combining adaptive learning, balance factor, and sigmoid penalty with dynamic weights and thresholds.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.
        adaptation_factor: Factor to adjust weights based on historical data.
        item_size_history: List of historical item sizes for adaptive learning.

    Returns:
        Array of priority scores for each bin.
    """
    # Initialize adaptive weights
    if not hasattr(priority_v2, "weights"):
        priority_v2.weights = [0.8703526170915381, 0.26928992154797116, 0.015623035472155156]

    # Update weights based on historical item sizes
    if item_size_history:
        item_size_avg = np.mean(item_size_history)
        item_size_std = np.std(item_size_history, ddof=1)
        if item_size_std > 0:
            priority_v2.weights[0] += adaptation_factor * (item - item_size_avg) / item_size_std
            priority_v2.weights[1] += adaptation_factor * (item - item_size_avg) / item_size_std
            priority_v2.weights[2] += adaptation_factor * (item - item_size_avg) / item_size_std

    # Normalize weights
    priority_v2.weights = np.clip(priority_v2.weights, 0, 1)
    priority_v2.weights /= sum(priority_v2.weights)

    alpha, beta, gamma = priority_v2.weights

    # Dynamic sigmoid penalty threshold
    sigmoid_penalty_threshold = 1e-6 * (1 + len(item_size_history) / 1000)

    # Scaled Remaining Capacity with sigmoid penalty
    scaled_remaining_capacity = np.where(
        bins_remain_cap >= item, 
        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), 
        -np.inf
    )

    # Balance Factor: Encourage a more balanced distribution
    mean_cap = np.mean(bins_remain_cap)
    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap)) if np.max(np.abs(mean_cap - bins_remain_cap)) != 0 else np.zeros_like(bins_remain_cap)

    # Last Fit Decrease (LFD) Heuristic
    last_fit_decrease = np.zeros_like(bins_remain_cap)
    if len(bins_remain_cap) > 1:
        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]

    # Combine heuristics with adaptive learning
    priority_scores = (
        alpha * scaled_remaining_capacity +
        beta * (1 - balance_factor) +
        gamma * last_fit_decrease
    )

    return priority_scores

# Example usage
# item_size_history should be maintained across function calls if applicable
bins_remain_cap = np.array([10, 8, 5, 2])
item = 3
item_size_history = [2, 4, 3, 6, 1]
priority_scores = priority_v2(item, bins_remain_cap, item_size_history=item_size_history)
```
