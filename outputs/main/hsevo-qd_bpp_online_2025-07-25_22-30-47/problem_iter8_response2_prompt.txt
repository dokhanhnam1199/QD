{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty, with refined parameters.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Enhanced Parameters for adaptive learning\n    alpha = 0.7  # Slightly increase weight for Scaled Remaining Capacity\n    beta = 0.25  # Slightly decrease weight for Balance Factor\n    gamma = 0.05 # Further reduce weight for Last Fit Decrease\n\n    # Scaled Remaining Capacity with enhanced sigmoid penalty\n    # Adjusted to emphasize bins with more space left\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1.0 / (bins_remain_cap - item + 1e-6), -np.inf)\n\n    # Enhanced Balance Factor: More aggressive towards balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n    balance_factor = np.clip(balance_factor, 0, 1)  # Ensure balance_factor is within [0, 1]\n\n    # Last Fit Decrease (LFD) Heuristic with slight adjustment\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = np.maximum(bins_remain_cap[:-1] - bins_remain_cap[1:], 0)\n\n    # Combined heuristics with refined adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        -beta * balance_factor +  # Invert the balance factor to positive impact\n        gamma * last_fit_decrease\n    )\n\n    # Adjust priority scores to prioritize less filled bins slightly more\n    priority_scores -= 0.01 * (1 - (bins_remain_cap / np.max(bins_remain_cap)))\n    \n    return priority_scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty, with refined parameters.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Enhanced Parameters for adaptive learning\n    alpha = 0.7  # Slightly increase weight for Scaled Remaining Capacity\n    beta = 0.25  # Slightly decrease weight for Balance Factor\n    gamma = 0.05 # Further reduce weight for Last Fit Decrease\n\n    # Scaled Remaining Capacity with enhanced sigmoid penalty\n    # Adjusted to emphasize bins with more space left\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, 1.0 / (bins_remain_cap - item + 1e-6), -np.inf)\n\n    # Enhanced Balance Factor: More aggressive towards balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n    balance_factor = np.power(balance_factor, 0.5)  # Introduce non-linearity to enhance balance\n\n    # Enhanced Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = (bins_remain_cap[:-1] - bins_remain_cap[1:]) / (bins_remain_cap[:-1] + 1e-6)\n\n    # Combine heuristics with enhanced adaptive learning\n    priority_scores = (\n        alpha * (scaled_remaining_capacity - np.min(scaled_remaining_capacity) + 1e-6) +  # Normalize scaled capacity\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores\n\n### Analyze & experience\n- Comparing (best) Heuristics 1st vs (worst) Heuristics 20th, we see that the best approach dynamically adjusts weights and penalties using adaptive learning and handles balance more effectively with a sigmoid penalty. The worst one lacks adaptive modification and relies on fixed coefficients.\nSecond best Heuristics 4th vs second worst Heuristics 19th, we see the second best uses a more nuanced approach with dynamically adjusted penalty and adaptive learning, whereas the second worst repeats similar penalization and balance factor calculation without improvements.\nComparing (1st) vs (2nd), we see minor differences in parameter tuning and similar structures, but the first one has slight advantages due to more refined parameter adjustments and enhanced sigmoid penalties.\n(3rd) vs (4th) shows the third one replicates the second with no changes, while the fourth introduces new enhancements like adjusted sigmoid penalties and better balance factors.\nComparing (second worst) vs (worst), we see the second worst uses enhanced but similar techniques to the worst, adding only minor new dynamic adjustments, while the worst remains static in its calculations.\nOverall: The best approaches incorporate dynamic adjustments, refined parameter settings, and improved balance factor calculations, whereas the worst lack these complexities.\n- \n- **Keywords**: Adaptive learning, dynamic adjustments, balanced penalties, sigmoid functions, bin packing efficiency\n- **Advice**: Focus on integrating real-time data feedback to dynamically adjust weights in balance factor calculations, incorporating sigmoid functions to adjust penalty scales smoothly based on current performance metrics.\n- **Avoid**: Statistically insignificant transformations, overly random element incorporations, and duplicate techniques without additional value.\n- **Explanation**: By continuously adapting based on feedback and using smooth, mathematically justified functions for adjustments, heuristics can evolve to perform optimally, mitigating inefficiencies and improving bin packing outcomes significantly.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}