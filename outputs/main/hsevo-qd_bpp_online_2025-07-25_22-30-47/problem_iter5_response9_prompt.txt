{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritize bins by balancing the remaining capacity and leftover space efficiency.\"\"\"\n    ifbinsfit = bins_remain_cap >= item\n    priority = np.where(ifbinsfit, 1.0 / (bins_remain_cap - item + 1e-6), -np.inf)\n    relative_space_left_factor = bins_remain_cap / np.max(bins_remain_cap, initial=1.0)\n    return priority * relative_space_left_factor\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This heuristic combines several modular sub-heuristics:\n    1. Scaled Remaining Capacity: Prioritizes bins with less remaining capacity.\n    2. Balance Factor: Encourages a more balanced distribution of items across bins.\n    3. Last Fit Decrease (LFD) Heuristic: Gives priority to bins where the last fit was larger.\n    4. Adaptive Learning: Weights the heuristics based on past performance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Parameters for adaptive learning\n    alpha = 0.5  # Weight for Scaled Remaining Capacity\n    beta = 0.3   # Weight for Balance Factor\n    gamma = 0.2  # Weight for Last Fit Decrease\n\n    # Scaled Remaining Capacity: Lower capacity -> Higher priority\n    scaled_remaining_capacity = 1.0 / (bins_remain_cap + 1e-6)\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor / np.max(balance_factor + 1e-6)) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores\n\n### Analyze & experience\n- Comparing (best) vs (worst), we see that the best heuristic (1st) effectively combines a sigmoid penalty to minimize leftover space while fitting the item, balancing tight bins and avoiding overflow elegantly. The worst (20th) repeats logic seen in weaker heuristics, without proper adjustments or penalties for larger remaining spaces.\n(second best) vs (second worst) illustrates the superiority of using modular sub-heuristics with adaptive learning (12th) compared to simplistic waste reduction strategies (19th) without balancing factors or penalties.\nComparing (1st) vs (2nd), we see the first uses a sigmoid function with specific parameters for penalty, which is more flexible and performance-driven than the sinusoidal inverse capacity method in the second.\n(3rd) vs (4th) highlights the necessity of specific parameters for sigmoid functions to effectively penalize larger spaces, as the third achieves better tuning than the fourth\u2019s generic handling.\nComparing (second worst) vs (worst), we see repetitive wasteful strategies without penalty mechanisms, underscoring the value of advanced heuristics with balanced approaches and penalties.\nOverall: Advanced heuristics combining multiple factors like adaptive learning, balance penalties, and sigmoid functions outperform simpler strategies.\n- \n- **Keywords**: Adaptive learning, balanced penalties, sigmoid functions, bin packing efficiency, heuristic design.\n- **Advice**: Focus on refining and fine-tuning the parameters of the adaptive learning mechanism to better address specific bin packing patterns and scenarios. Continuously assess and adjust penalties for inefficiencies dynamically without introducing unnecessary complexity.\n- **Avoid**: Overly complex transformations that complicate the heuristic without providing significant benefits. Random elements or changes that lack a clear rationale for improving performance.\n- **Explanation**: Effective self-reflection involves understanding the strengths and limitations of current strategies while making informed adjustments. By concentrating on refining adaptive learning and penalties dynamically, we can enhance efficiency without adding unnecessary complexity or randomness, which could degrade performance.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}