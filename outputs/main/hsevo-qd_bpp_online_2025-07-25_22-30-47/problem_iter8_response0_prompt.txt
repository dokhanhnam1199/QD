{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritize bins by enhancing adaptive learning, balance factor, and sigmoid penalty dynamically.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Parameters for adaptive learning\n    alpha = 0.7  # Increased weight for Scaled Remaining Capacity\n    beta = 0.2   # Reduced weight for Balance Factor\n    gamma = 0.1  # Reduced weight for Last Fit Decrease\n\n    # Enhanced Scaled Remaining Capacity with adaptive sigmoid penalty\n    sigmoid_penalty = np.exp(-np.power((bins_remain_cap - item) / (np.std(bins_remain_cap) + 1e-6), 2))\n    scaled_remaining_capacity = np.where(bins_remain_cap >= item, sigmoid_penalty, -np.inf)\n\n    # Balance Factor: Encourage a more balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)\n\n    # Last Fit Decrease (LFD) Heuristic with dynamic adjustment\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = np.log(bins_remain_cap[:-1] - bins_remain_cap[1:] + 1)\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Balances fit suitability and leftover space using adaptive sigmoid penalties.\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    fit_priority = can_fit * (1 - (space_left / bins_remain_cap))\n    close_fit_priority = np.clip(bins_remain_cap - item, 0, 1)\n    sigmoid_penalty = 1.0 / (bins_remain_cap + 1e-6) * np.sin(np.pi / 2 * (bins_remain_cap / (np.max(bins_remain_cap) + 1e-6)))\n    priority = 0.6 * fit_priority + 0.2 * close_fit_priority + 0.2 * sigmoid_penalty\n    return priority\n\n### Analyze & experience\n- Comparing (best) Heuristics 1st vs (worst) Heuristics 20th, we see that the best approach dynamically adjusts weights and penalties using adaptive learning and handles balance more effectively with a sigmoid penalty. The worst one lacks adaptive modification and relies on fixed coefficients.\nSecond best Heuristics 4th vs second worst Heuristics 19th, we see the second best uses a more nuanced approach with dynamically adjusted penalty and adaptive learning, whereas the second worst repeats similar penalization and balance factor calculation without improvements.\nComparing (1st) vs (2nd), we see minor differences in parameter tuning and similar structures, but the first one has slight advantages due to more refined parameter adjustments and enhanced sigmoid penalties.\n(3rd) vs (4th) shows the third one replicates the second with no changes, while the fourth introduces new enhancements like adjusted sigmoid penalties and better balance factors.\nComparing (second worst) vs (worst), we see the second worst uses enhanced but similar techniques to the worst, adding only minor new dynamic adjustments, while the worst remains static in its calculations.\nOverall: The best approaches incorporate dynamic adjustments, refined parameter settings, and improved balance factor calculations, whereas the worst lack these complexities.\n- \n- **Keywords**: Adaptive learning, dynamic adjustments, balanced penalties, sigmoid functions, bin packing efficiency\n- **Advice**: Focus on integrating real-time data feedback to dynamically adjust weights in balance factor calculations, incorporating sigmoid functions to adjust penalty scales smoothly based on current performance metrics.\n- **Avoid**: Statistically insignificant transformations, overly random element incorporations, and duplicate techniques without additional value.\n- **Explanation**: By continuously adapting based on feedback and using smooth, mathematically justified functions for adjustments, heuristics can evolve to perform optimally, mitigating inefficiencies and improving bin packing outcomes significantly.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}