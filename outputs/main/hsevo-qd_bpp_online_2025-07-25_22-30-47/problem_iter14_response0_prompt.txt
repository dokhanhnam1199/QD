{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritize bins using a combination of adaptive learning and dynamic balance factors.\n    \n    Args:\n        item: Size of item to be added to a bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Adaptive weights for heuristics components\n    alpha = 0.8703526170915381  # Scaled Remaining Capacity\n    beta = 0.26928992154797116   # Balance Factor\n    gamma = 0.015623035472155156  # Last Fit Decrease\n\n    # Dynamic thresholds\n    sigmoid_penalty_threshold = 7.870147266070587e-06\n    balance_factor_threshold = 8.54060876899628e-06\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Dynamic Balance Factor: Encourage balanced distribution\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + balance_factor_threshold)\n\n    # Last Fit Decrease (LFD) Heuristic\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        gamma * last_fit_decrease\n    )\n\n    return priority_scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritize bins by combining adaptive learning, dynamic balance factor, and refined penalty mechanisms.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    # Adaptive Threshold Calculation\n    max_bin_capacity = np.max(bins_remain_cap)\n    threshold_factor = 0.05  # Dynamic adjustment factor\n    sigmoid_penalty_threshold = max_bin_capacity * threshold_factor\n    balance_factor_threshold = max_bin_capacity * threshold_factor\n\n    # Scaled Remaining Capacity with sigmoid penalty\n    scaled_remaining_capacity = np.where(\n        bins_remain_cap >= item, \n        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), \n        -np.inf\n    )\n\n    # Refined Balance Factor: Encourage a more balanced distribution with adaptive threshold\n    mean_cap = np.mean(bins_remain_cap)\n    balance_factor = np.where(\n        np.abs(mean_cap - bins_remain_cap) < balance_factor_threshold, \n        0, \n        np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + balance_factor_threshold)\n    )\n\n    # Last Fit Decrease (LFD) Heuristic with dynamic weighting\n    last_fit_decrease = np.zeros_like(bins_remain_cap)\n    if len(bins_remain_cap) > 1:\n        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]\n    last_fit_decrease_weight = 0.02  # Dynamic weight for LFD\n\n    # Dynamic Weights for heuristics based on the number of bins and average remaining capacity\n    alpha = 2 / (1 + np.exp(-0.5 * len(bins_remain_cap)))  # Scaled Remaining Capacity weight\n    beta = 1 - alpha  # Balance Factor weight\n\n    # Combine heuristics with adaptive learning\n    priority_scores = (\n        alpha * scaled_remaining_capacity +\n        beta * (1 - balance_factor) +\n        last_fit_decrease_weight * last_fit_decrease\n    )\n\n    return priority_scores\n\n### Analyze & experience\n- Comparing (best) vs (worst), we see that the best heuristics dynamically adjusts weights based on system state, which allows for more intelligent adaptation to varying conditions. In contrast, the worst heuristics use fixed weights and thresholds, reducing their flexibility and optimization potential. (Second best) vs (second worst) highlights a significant improvement in adaptability and dynamic weighting, showing the benefit of responsive design. Comparing (1st) vs (2nd), we see that the first maintains the adaptive approach without unnecessary imports and parameters, streamlining the process. (3rd) vs (4th) also follows this pattern, emphasizing the importance of simplification while retaining adaptive features. Comparing (second worst) vs (worst), we see the latter lacks in adapting weights and thresholds, making it less effective under varying loads. Overall: Dynamic adjustment of weights and thresholds outperforms static configurations, and simpler implementations maintain efficiency.\n- \n- **Keywords**: Adaptive learning, dynamic adjustments, balanced penalties, domain-specific data, parameter tuning\n- **Advice**: Focus on integrating advanced learning techniques that adaptively adjust heuristics based on feedback. Ensure that the dynamic adjustments are informed by domain-specific data to optimize performance.\n- **Avoid**: Overly complex models or transformations that do not offer significant benefits. Steer clear of static coefficients and repetitive, unenhanced techniques.\n- **Explanation**: By leveraging adaptive learning and dynamic adjustments tailored to specific domains, heuristics can better balance placement efficiencies and penalize inefficiencies. This approach minimizes unnecessary complexity and maintains the effectiveness of the heuristic, leading to improved bin packing solutions.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}