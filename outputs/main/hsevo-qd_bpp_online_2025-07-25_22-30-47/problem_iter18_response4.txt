```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, adaptation_factor: float = 0.01, recent_fits: list = []) -> np.ndarray:
    """
    Prioritize bins by combining adaptive learning, balance factor, and sigmoid penalty with dynamic weights and thresholds.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.
        adaptation_factor: Rate at which weights and thresholds adapt to past fits.
        recent_fits: List of recent items added to bins for adaptive learning.

    Returns:
        Array of priority scores for each bin.
    """
    # Initialize or update thresholds based on recent fits
    if recent_fits:
        sigmoid_penalty_threshold = np.std(recent_fits) + 1e-6
        balance_factor_threshold = np.mean(recent_fits) / 100 + 1e-6
    else:
        sigmoid_penalty_threshold = 1e-5
        balance_factor_threshold = 1e-5

    # Initialize or update weights dynamically
    if len(recent_fits) > 10:  # Start adapting after a certain number of fits
        alpha = np.clip(np.mean(recent_fits) / (np.sum(recent_fits) + 1e-6), 0.5, 1.5)
        beta = np.clip(1 - alpha, 0.5, 1.5)
        gamma = 1 - alpha - beta
    else:  # Initial weights
        alpha = 0.87
        beta = 0.27
        gamma = 0.015

    # Scaled Remaining Capacity with sigmoid penalty
    scaled_remaining_capacity = np.where(
        bins_remain_cap >= item, 
        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), 
        -np.inf
    )

    # Balance Factor: Encourage a more balanced distribution
    mean_cap = np.mean(bins_remain_cap)
    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + balance_factor_threshold)

    # Last Fit Decrease (LFD) Heuristic
    last_fit_decrease = np.zeros_like(bins_remain_cap)
    if len(bins_remain_cap) > 1:
        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]

    # Combine heuristics with adaptive learning
    priority_scores = (
        alpha * scaled_remaining_capacity +
        beta * (1 - balance_factor) +
        gamma * last_fit_decrease
    )

    # Record the current item for future adaptation
    recent_fits.append(item)

    return priority_scores
```
