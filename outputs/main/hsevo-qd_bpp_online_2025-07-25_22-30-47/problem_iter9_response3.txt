```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritize bins by dynamically adjusting weights based on real-time feedback and using
    smooth penalty functions to optimize bin packing efficiency.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Returns:
        Array of priority scores for each bin.
    """
    # Dynamic adjustment of weights based on current state
    total_capacity = np.sum(bins_remain_cap)
    mean_cap = np.mean(bins_remain_cap)
    std_dev_cap = np.std(bins_remain_cap)
    
    # Calculate number of bins
    num_bins = len(bins_remain_cap)
    
    # Adaptive learning parameters
    alpha = 0.5 / (1 + np.exp(-0.1 * (total_capacity - num_bins)))  # Sigmoid function for alpha
    beta = 0.3 / (1 + np.exp(-0.1 * std_dev_cap))                   # Sigmoid function for beta
    gamma = 0.2 * np.exp(-0.1 * np.abs(mean_cap - item))             # Exponential decay for gamma

    # Scaled Remaining Capacity with sigmoid penalty
    sigmoid_penalty_threshold = 1e-6
    scaled_remaining_capacity = np.where(
        bins_remain_cap >= item, 
        1.0 / (bins_remain_cap - item + sigmoid_penalty_threshold), 
        -np.inf
    )

    # Balance Factor: Encourage a more balanced distribution
    balance_factor = np.abs(mean_cap - bins_remain_cap) / np.max(np.abs(mean_cap - bins_remain_cap) + 1e-6)

    # Dynamic Last Fit Decrease (LFD) Heuristic
    last_fit_decrease = np.zeros_like(bins_remain_cap)
    if num_bins > 1:
        last_fit_decrease[1:] = bins_remain_cap[:-1] - bins_remain_cap[1:]
    last_fit_decrease = np.clip(last_fit_decrease, 0, None)  # Only consider positive LFD

    # Combine heuristics with adaptive learning
    priority_scores = (
        alpha * scaled_remaining_capacity +
        beta * (1 - balance_factor) +
        gamma * last_fit_decrease
    )

    # Include a penalty for bins that are more empty than the average
    empty_penalty_threshold = mean_cap * 0.2
    empty_penalty = np.where(bins_remain_cap > mean_cap + empty_penalty_threshold, -np.inf, 0)
    
    priority_scores += empty_penalty

    return priority_scores
```
