```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) that combines
    multiple factors, including edge diversity, global tour properties, and
    adaptive weighting, to determine the likelihood of including an edge in a solution.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance
            matrix between cities.  distance_matrix[i][j] is the distance
            between city i and city j.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as distance_matrix,
            where each element represents the prior probability or desirability
            of including the corresponding edge in a TSP tour.
    """

    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Heuristic 1: Inverse distance (shorter distances are more desirable)
    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero

    # Heuristic 2: Nearest neighbor desirability
    nearest_neighbors = np.argsort(distance_matrix, axis=1)
    nearest_neighbor_bonus = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(1, min(4, n)):  # Give a bonus to the first 3 nearest neighbors
            neighbor_index = nearest_neighbors[i, j]
            nearest_neighbor_bonus[i, neighbor_index] = 1.0 / j  # closer neighbors get higher bonus

    # Heuristic 3: Avoidance of edges that are part of very long distances for the current city (penalty)
    farthest_neighbors = np.argsort(distance_matrix, axis=1)[:, ::-1]
    farthest_neighbor_penalty = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(min(3, n)):
            neighbor_index = farthest_neighbors[i, j]
            farthest_neighbor_penalty[i, neighbor_index] = -0.5  # Negative penalty

    # Heuristic 4: Edge Diversity - Encourages exploration of less-used edges.
    # Initialize edge usage counts (this would ideally be updated during the search process)
    edge_usage = np.ones_like(distance_matrix, dtype=float)  # Start with a small count
    edge_diversity_bonus = 1.0 / (edge_usage + 0.1) #Add small constant to avoid division by zero

    # Combine heuristics with adaptive weights (example weights)
    w1, w2, w3, w4 = 0.4, 0.3, 0.1, 0.2  # Weights can be tuned or learned
    heuristic_matrix = (
        w1 * inverse_distance
        + w2 * nearest_neighbor_bonus
        + w3 * farthest_neighbor_penalty
        + w4 * edge_diversity_bonus
    )

    # Sparsify the matrix (keep only top k edges for each node)
    k = min(5, n - 1)  #keep at least 1 edge
    for i in range(n):
        row = heuristic_matrix[i, :]
        threshold = np.sort(row)[-k]  # Find the kth largest value
        heuristic_matrix[i, row < threshold] = 0.0  # set the value below k to zero.

    # Normalize to 0-1 range
    max_val = np.max(heuristic_matrix)
    min_val = np.min(heuristic_matrix)

    if max_val > min_val:
        heuristic_matrix = (heuristic_matrix - min_val) / (max_val - min_val)
    else:
        heuristic_matrix[:] = 1.0  # if all heuristics are equal

    return heuristic_matrix
```
