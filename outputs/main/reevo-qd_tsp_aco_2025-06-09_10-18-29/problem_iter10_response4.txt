```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) that combines
    multiple factors to determine the likelihood of including an edge in a solution.
    This version prioritizes stronger, direct neighbor bonuses/penalties, simpler
    combinations, and aggressive sparsification with robust normalization.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance
            matrix between cities.  distance_matrix[i][j] is the distance
            between city i and city j.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as distance_matrix,
            where each element represents the prior probability or desirability
            of including the corresponding edge in a TSP tour.
    """

    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Heuristic 1: Inverse distance (shorter distances are more desirable)
    inverse_distance = 1.0 / (distance_matrix + 1e-9)

    # Heuristic 2: Nearest neighbor bonus (focus on immediate neighbors)
    nearest_neighbors = np.argsort(distance_matrix, axis=1)
    nearest_neighbor_bonus = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        # Graded bonus for top 2 nearest neighbors
        for j in range(1, min(3, n)):  # Check only top 2
            neighbor_index = nearest_neighbors[i, j]
            nearest_neighbor_bonus[i, neighbor_index] = (3 - j) / 3.0  # Bonus decreases with rank

    # Heuristic 3: Farthest neighbor penalty (avoid long edges) - stronger penalty
    farthest_neighbors = np.argsort(distance_matrix, axis=1)[:, -1]
    farthest_neighbor_penalty = np.zeros_like(distance_matrix, dtype=float)

    for i in range(n):
        neighbor_index = farthest_neighbors[i]
        farthest_neighbor_penalty[i, neighbor_index] = -1.0

    # Combined Heuristic (dynamically tuned weights)
    alpha = 0.6  # Weight for inverse distance
    beta = 0.4  # Weight for nearest neighbor bonus
    gamma = 0.2  # Weight for farthest neighbor penalty
    heuristic_matrix = alpha * inverse_distance + beta * nearest_neighbor_bonus + gamma * farthest_neighbor_penalty

    # Aggressive Sparsification: Keep only top 2 candidates per row
    for i in range(n):
        row = heuristic_matrix[i, :]
        top_indices = np.argsort(row)[-2:]  # Indices of the top 2 values
        mask = np.ones_like(row, dtype=bool)
        mask[top_indices] = False
        heuristic_matrix[i, mask] = 0.0
        
    # Robust Normalization (row-wise softmax)
    for i in range(n):
        row = heuristic_matrix[i, :]
        row_exp = np.exp(row - np.max(row))  # for numerical stability
        row_sum = np.sum(row_exp)
        if row_sum > 0:
            heuristic_matrix[i, :] = row_exp / row_sum
        else:
            heuristic_matrix[i, :] = 1.0 / n  # Handle the case where all values are -inf

    return heuristic_matrix
```
