```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) that combines
    multiple factors to determine the likelihood of including an edge in a solution.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance
            matrix between cities.  distance_matrix[i][j] is the distance
            between city i and city j.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as distance_matrix,
            where each element represents the prior probability or desirability
            of including the corresponding edge in a TSP tour.
    """

    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Heuristic 1: Inverse distance (shorter distances are more desirable)
    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero

    # Heuristic 2: Nearest neighbor bonus (stronger penalty for further neighbors)
    nearest_neighbors = np.argsort(distance_matrix, axis=1)
    nearest_neighbor_bonus = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(1, min(4, n)):  # Give a bonus to the first 3 nearest neighbors
            neighbor_index = nearest_neighbors[i, j]
            nearest_neighbor_bonus[i, neighbor_index] = 1.0 / (j*j)  # Quadratic decay

    # Heuristic 3: Farthest neighbor penalty (more direct summation, stronger)
    farthest_neighbors = np.argsort(distance_matrix, axis=1)[:, ::-1]
    farthest_neighbor_penalty = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        neighbor_index = farthest_neighbors[i, 0]
        farthest_neighbor_penalty[i, neighbor_index] = -1.0 # Strong penalty for farthest neighbor

    # Combine heuristics with adjusted weights
    heuristic_matrix = inverse_distance + nearest_neighbor_bonus + farthest_neighbor_penalty

    # Sparsify the matrix (keep only top k edges for each node)
    k = min(4, n - 1) # Reduced k for stronger sparsification
    for i in range(n):
        row = heuristic_matrix[i, :]
        threshold = np.sort(row)[-k]
        heuristic_matrix[i, row < threshold] = 0.0

    # Dynamic weight adjustment (example: focus more on inverse distance if variance is low)
    variance = np.var(distance_matrix)
    if variance < np.mean(distance_matrix): #low variance, favor inverse distance.
        heuristic_matrix = 0.7 * inverse_distance + 0.2 * nearest_neighbor_bonus + 0.1 * farthest_neighbor_penalty
    
    #Alternative Normalization: RobustScaler-like approach (more resilient to outliers)
    median = np.median(heuristic_matrix)
    abs_dev = np.median(np.abs(heuristic_matrix - median))

    if abs_dev > 0:
        heuristic_matrix = (heuristic_matrix - median) / (1.4826 * abs_dev) #Scale by median absolute deviation
        heuristic_matrix = np.clip(heuristic_matrix, -5, 5) # Clip outliers
        heuristic_matrix = (heuristic_matrix + 5) / 10 #Scale to 0-1

    else:
        heuristic_matrix[:] = 1.0  # If all values are equal

    return heuristic_matrix
```
