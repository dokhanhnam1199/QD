{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances immediate tight packing (item/remaining_ratio) with future \n    flexibility (sqrt residual space), using geometric mean for synergy.\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Core efficiency metric: item fills current bin proportion\n    fill_efficiency = item / (bins_remain_cap + 1e-9)  # +eps prevents div0\n    \n    # Flexibility metric: sqrt residual space allows mid-sized future items\n    residual_potential = np.sqrt(np.maximum(remaining_after, 0) + 1e-9)\n    \n    # Geometric mean creates balanced synergy between competing objectives\n    synergy_score = np.sqrt(fill_efficiency * residual_potential)\n    \n    # Precision-aware exact fit bonus (better than ==0 for floating point)\n    perfection_bonus = np.isclose(remaining_after, 0, atol=1e-8) * 2.0\n    \n    # Combine components only for valid bins\n    scores = np.where(valid_mask, synergy_score + perfection_bonus, -np.inf)\n    \n    return scores\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances immediate tight packing (item/remaining_ratio) with future \n    flexibility (sqrt residual space), using geometric mean for synergy.\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Core efficiency metric: item fills current bin proportion\n    fill_efficiency = item / (bins_remain_cap + 1e-9)  # +eps prevents div0\n    \n    # Flexibility metric: sqrt residual space allows mid-sized future items\n    residual_potential = np.sqrt(np.maximum(remaining_after, 0) + 1e-9)\n    \n    # Geometric mean creates balanced synergy between competing objectives\n    synergy_score = np.sqrt(fill_efficiency * residual_potential)\n    \n    # Precision-aware exact fit bonus (better than ==0 for floating point)\n    perfection_bonus = np.isclose(remaining_after, 0, atol=1e-8) * 2.0\n    \n    # Combine components only for valid bins\n    scores = np.where(valid_mask, synergy_score + perfection_bonus, -np.inf)\n    \n    return scores\n\n[Heuristics 3rd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    eps_fill: float = 3.994701447986276e-07,\n    eps_residual: float = 2.3510843011108968e-07,\n    atol_perfection: float = 5.422500394179024e-06,\n    perfection_bonus_weight: float = 2.812461784777218) -> np.ndarray:\n    \"\"\"Balances immediate tight packing (item/remaining_ratio) with future \n    flexibility (sqrt residual space), using geometric mean for synergy.\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    fill_efficiency = item / (bins_remain_cap + eps_fill)\n    residual_potential = np.sqrt(np.maximum(remaining_after, 0) + eps_residual)\n    synergy_score = np.sqrt(fill_efficiency * residual_potential)\n    perfection_bonus = np.isclose(remaining_after, 0, atol=atol_perfection) * perfection_bonus_weight\n    scores = np.where(valid_mask, synergy_score + perfection_bonus, -np.inf)\n    \n    return scores\n\n[Heuristics 4th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    eps_fill: float = 3.994701447986276e-07,\n    eps_residual: float = 2.3510843011108968e-07,\n    atol_perfection: float = 5.422500394179024e-06,\n    perfection_bonus_weight: float = 2.812461784777218) -> np.ndarray:\n    \"\"\"Balances immediate tight packing (item/remaining_ratio) with future \n    flexibility (sqrt residual space), using geometric mean for synergy.\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    fill_efficiency = item / (bins_remain_cap + eps_fill)\n    residual_potential = np.sqrt(np.maximum(remaining_after, 0) + eps_residual)\n    synergy_score = np.sqrt(fill_efficiency * residual_potential)\n    perfection_bonus = np.isclose(remaining_after, 0, atol=atol_perfection) * perfection_bonus_weight\n    scores = np.where(valid_mask, synergy_score + perfection_bonus, -np.inf)\n    \n    return scores\n\n[Heuristics 5th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    eps_fill: float = 3.994701447986276e-07,\n    eps_residual: float = 2.3510843011108968e-07,\n    atol_perfection: float = 5.422500394179024e-06,\n    perfection_bonus_weight: float = 2.812461784777218) -> np.ndarray:\n    \"\"\"Balances immediate tight packing (item/remaining_ratio) with future \n    flexibility (sqrt residual space), using geometric mean for synergy.\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    fill_efficiency = item / (bins_remain_cap + eps_fill)\n    residual_potential = np.sqrt(np.maximum(remaining_after, 0) + eps_residual)\n    synergy_score = np.sqrt(fill_efficiency * residual_potential)\n    perfection_bonus = np.isclose(remaining_after, 0, atol=atol_perfection) * perfection_bonus_weight\n    scores = np.where(valid_mask, synergy_score + perfection_bonus, -np.inf)\n    \n    return scores\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    eps_fill: float = 3.994701447986276e-07,\n    eps_residual: float = 2.3510843011108968e-07,\n    atol_perfection: float = 5.422500394179024e-06,\n    perfection_bonus_weight: float = 2.812461784777218) -> np.ndarray:\n    \"\"\"Balances immediate tight packing (item/remaining_ratio) with future \n    flexibility (sqrt residual space), using geometric mean for synergy.\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    fill_efficiency = item / (bins_remain_cap + eps_fill)\n    residual_potential = np.sqrt(np.maximum(remaining_after, 0) + eps_residual)\n    synergy_score = np.sqrt(fill_efficiency * residual_potential)\n    perfection_bonus = np.isclose(remaining_after, 0, atol=atol_perfection) * perfection_bonus_weight\n    scores = np.where(valid_mask, synergy_score + perfection_bonus, -np.inf)\n    \n    return scores\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balanced packing heuristic: Prioritizes exact fits (with float tolerance), \n    then geometric mean of tightness (1/remaining_space) and bin utilization (1/remaining_capacity).\"\"\"\n    remaining_space = bins_remain_cap - item\n    exact_fit = np.isclose(remaining_space, 0, atol=1e-9)\n    valid = remaining_space >= 0\n    \n    # Calculate components with epsilon smoothing\n    tightness = 1 / (np.abs(remaining_space) + 1e-9)  # Prefer minimal leftover space\n    utilization = 1 / (bins_remain_cap + 1e-9)        # Prefer bins closer to being full\n    \n    # Geometric mean balances both objectives\n    combined_score = np.sqrt(tightness * utilization)\n    \n    priorities = np.where(\n        exact_fit,\n        np.inf,  # Absolute priority for perfect fits\n        np.where(\n            valid,\n            combined_score,\n            -np.inf  # Exclude bins without capacity\n        )\n    )\n    \n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Dynamic multi-objective heuristic with adaptive weight balancing and residual \n    space forecasting. Features three key innovations:\n    1. Context-aware synergy: Weighted power mean adapts to item size\n    2. Predictive residual scoring: Cube root + linear combo handles multiple future item scenarios\n    3. Precision-gradient exact fit: Smooth bonus proportional to item significance\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Adaptive normalization base using item-aware sigmoid\n    norm_base = 0.5 + 1/(1 + np.exp(-10*(item-0.2)))\n    \n    # Core packing efficiency with non-linear scaling\n    fill_ratio = item / (bins_remain_cap + 1e-12)\n    fill_power = np.where(bins_remain_cap > 0.5, fill_ratio**0.7, fill_ratio**1.2)\n    \n    # Residual space value estimator with multi-horizon forecasting\n    residual_space = np.maximum(remaining_after, 0)\n    residual_value = (residual_space**0.4 + 0.6*residual_space**0.8) / (1.6 + 0.1*item)\n    \n    # Dynamic weight interpolation between objectives\n    weight = np.clip(item * 1.8, 0.2, 0.8)\n    synergy = (fill_power**weight) * (residual_value**(1-weight)) * norm_base\n    \n    # Precision-aware exact fit with smooth gradient\n    near_exact = np.exp(-(remaining_after**2)/(1e-7 + 0.01*item**2))\n    exact_bonus = near_exact * (0.5 + 1.5*item)  # Scales with item importance\n    \n    # Final score composition\n    scores = np.where(valid_mask, synergy + exact_bonus, -np.inf)\n    \n    return scores\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit detection (with float tolerance) with harmonic efficiency\n    and residual potential scoring using geometric mean for balanced packing.\n    \"\"\"\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    exact_fit = np.isclose(remaining_after, 0, atol=1e-9)\n    \n    # Base score combines harmonic efficiency (1/gap) and residual potential (sqrt(original capacity))\n    harmonic = 1 / (remaining_after + 1e-9)  # +epsilon prevents div0\n    residual = np.sqrt(bins_remain_cap)  # Reward using larger available bins\n    combined = harmonic * residual  # Geometric mean via multiplication\n    \n    # Boost exact fits to maximum priority\n    return np.where(exact_fit, np.inf, np.where(valid_mask, combined, -np.inf))\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines geometric mean of harmonic tightness (1/remaining) and residual \n    potential (\u221aoriginal capacity) with exact-fit nuclear binding bonus.\"\"\"\n    \n    remaining_after = bins_remain_cap - item\n    feasible = remaining_after >= 0\n    epsilon = 1e-9\n    \n    # Core balance: Geometric mean between tight packing and residual flexibility\n    harmonic_tightness = 1 / (remaining_after + epsilon)\n    residual_potential = np.sqrt(bins_remain_cap + epsilon)  # \u221a(original capacity - used)\n    balanced_score = np.sqrt(harmonic_tightness * residual_potential)\n    \n    # Nuclear binding bonus: Extreme priority for exact fits (0 remaining)\n    exact_fit = np.isclose(remaining_after, 0, atol=1e-9, rtol=0)\n    nuclear_bonus = exact_fit * 1e20  # Physically inspired dominance\n    \n    return np.where(feasible, balanced_score + nuclear_bonus, -np.inf)\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balanced packing heuristic: Prioritizes exact fits (with float tolerance), \n    then geometric mean of tightness (1/remaining_space) and bin utilization (1/remaining_capacity).\"\"\"\n    remaining_space = bins_remain_cap - item\n    exact_fit = np.isclose(remaining_space, 0, atol=1e-9)\n    valid = remaining_space >= 0\n    \n    # Calculate components with epsilon smoothing\n    tightness = 1 / (np.abs(remaining_space) + 1e-9)  # Prefer minimal leftover space\n    utilization = 1 / (bins_remain_cap + 1e-9)        # Prefer bins closer to being full\n    \n    # Geometric mean balances both objectives\n    combined_score = np.sqrt(tightness * utilization)\n    \n    priorities = np.where(\n        exact_fit,\n        np.inf,  # Absolute priority for perfect fits\n        np.where(\n            valid,\n            combined_score,\n            -np.inf  # Exclude bins without capacity\n        )\n    )\n    \n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit detection (with float tolerance) with harmonic efficiency\n    and residual potential scoring using geometric mean for balanced packing.\n    \"\"\"\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    exact_fit = np.isclose(remaining_after, 0, atol=1e-9)\n    \n    # Base score combines harmonic efficiency (1/gap) and residual potential (sqrt(original capacity))\n    harmonic = 1 / (remaining_after + 1e-9)  # +epsilon prevents div0\n    residual = np.sqrt(bins_remain_cap)  # Reward using larger available bins\n    combined = harmonic * residual  # Geometric mean via multiplication\n    \n    # Boost exact fits to maximum priority\n    return np.where(exact_fit, np.inf, np.where(valid_mask, combined, -np.inf))\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    eps = 1e-9\n    \n    # Adaptive fill efficiency with non-linear scaling\n    fill_efficiency = (item ** 1.5) / (bins_remain_cap + eps)  # Favors substantial fills\n    \n    # Dynamic residual potential with item-size modulated exponent\n    residual_base = np.maximum(remaining_after, 0) + eps\n    adaptive_exponent = 0.3 + 0.7 * (1 - item)  # Range [0.3-1.0] based on item size\n    residual_potential = residual_base ** adaptive_exponent\n    \n    # Synergy score with dimensional balance\n    dimensional_synergy = (fill_efficiency * residual_potential) ** 0.7  # Sublinear combination\n    \n    # Progressive exact fit bonus (scales with bin utilization)\n    perfection_bonus = np.isclose(remaining_after, 0, atol=1e-8) * (2.5 + 3 * (1 - bins_remain_cap))\n    \n    # Anti-fragmentation penalty for micro gaps\n    micro_gap_penalty = np.exp(-residual_base * 15) * 0.8  # Strong penalty near zero residual\n    \n    # Combine components with validity masking\n    scores = np.where(\n        valid_mask,\n        dimensional_synergy + perfection_bonus - micro_gap_penalty,\n        -np.inf\n    )\n    \n    return scores\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Dynamic residual potential with item-size modulated exponent\n    residual_exponent = np.clip(1.2 - 0.7*item, 0.4, 1.2)  # Adaptive curvature control\n    residual_potential = (np.maximum(remaining_after, 0) + 1e-12) ** residual_exponent\n    \n    # Density efficiency with non-linear scaling\n    fill_efficiency = (item / (bins_remain_cap + 1e-12)) ** np.sqrt(item + 0.2)\n    \n    # Multi-objective synergy with dynamic weights\n    synergy_score = fill_efficiency * residual_potential\n    \n    # Precision-stable exact fit bonus with size-proportional reward\n    perfection_bonus = np.isclose(remaining_after, 0, atol=1e-8, rtol=0) * (2.5 + 3*item)\n    \n    # Future capacity alignment bonus (encourage divisible residuals)\n    alignment_bonus = 0.4 * np.exp(-np.abs(remaining_after/(item + 1e-9) - 1.0))\n    \n    scores = np.where(\n        valid_mask, \n        synergy_score + perfection_bonus + alignment_bonus,\n        -np.inf\n    )\n    \n    return scores\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Dynamic residual potential with item-size modulated exponent\n    residual_exponent = np.clip(1.2 - 0.7*item, 0.4, 1.2)  # Adaptive curvature control\n    residual_potential = (np.maximum(remaining_after, 0) + 1e-12) ** residual_exponent\n    \n    # Density efficiency with non-linear scaling\n    fill_efficiency = (item / (bins_remain_cap + 1e-12)) ** np.sqrt(item + 0.2)\n    \n    # Multi-objective synergy with dynamic weights\n    synergy_score = fill_efficiency * residual_potential\n    \n    # Precision-stable exact fit bonus with size-proportional reward\n    perfection_bonus = np.isclose(remaining_after, 0, atol=1e-8, rtol=0) * (2.5 + 3*item)\n    \n    # Future capacity alignment bonus (encourage divisible residuals)\n    alignment_bonus = 0.4 * np.exp(-np.abs(remaining_after/(item + 1e-9) - 1.0))\n    \n    scores = np.where(\n        valid_mask, \n        synergy_score + perfection_bonus + alignment_bonus,\n        -np.inf\n    )\n    \n    return scores\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances tight packing with future flexibility using:\n    1. Exponential decay for near-exact fits\n    2. Square root residual capacity preservation\n    3. Dynamic large-item penalty with exponential scaling\"\"\"\n    \n    fit_mask = bins_remain_cap >= item\n    remaining_after = bins_remain_cap - item\n    \n    # Base score combines tightness and preservation components\n    tightness = np.exp(-6 * remaining_after)  # Strong preference for <0.1 residual\n    preservation = np.sqrt(np.maximum(remaining_after, 1e-9))  # Protect usable capacity\n    scores = np.where(fit_mask, tightness * preservation, -np.inf)\n    \n    # Dynamic penalty for items that could fragment large bins\n    if item > 0.3:  # Applies penalty gradient starting at lower threshold\n        penalty_scale = np.exp(-4 * (bins_remain_cap - item))  # Penalize bins that would leave <0.25 capacity\n        scores = np.where(fit_mask, scores * (1 - 0.6*penalty_scale), scores)\n    \n    return scores\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances tight fit (1/remaining_space) with bin utilization (1 - bin_cap_remain)\n    using geometric mean. Applies exponential boost for perfect fits while maintaining\n    smooth gradient for near-optimal placements.\"\"\"\n    \n    remaining_space = bins_remain_cap - item\n    valid_mask = remaining_space >= 0\n    eps = 1e-9  # Prevent division by zero\n    \n    # Core components\n    tightness = 1 / (remaining_space + eps)  # Hyperbolic fit priority\n    utilization = 1 - bins_remain_cap  # Existing bin fullness (assuming bin size=1)\n    \n    # Geometric mean balances immediate fit vs existing utilization\n    combined = np.sqrt(tightness * utilization)\n    \n    scores = np.where(valid_mask, combined, -np.inf)\n    \n    # Exponential boost for perfect fits using tolerance-aware check\n    perfect_fits = np.isclose(remaining_space, 0, atol=eps)\n    scores = np.where(perfect_fits, scores * 2 + 1e6, scores)  # Maintain relative ordering\n    \n    return scores\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Dynamic residual valuation using hyperbolic tangent for smooth thresholding\n    residual_space = np.maximum(remaining_after, 0)\n    residual_utility = np.tanh(residual_space / (item + 1e-9))  # Normalize by item size\n    \n    # Dual-aspect packing density using logistic transform\n    capacity_ratio = item / (bins_remain_cap + 1e-9)\n    anti_fragility = 1 - np.exp(-5 * residual_space)  # Penalizes near-zero residuals\n    density_score = capacity_ratio * anti_fragility\n    \n    # Quantum-inspired superposition of objectives\n    entanglement = np.where(\n        residual_space > item,\n        np.sqrt(residual_space * density_score),  # Future-flexible regime\n        density_score ** 2  # Tight-packing regime\n    )\n    \n    # Precision-robust exact fit detection with magnitude awareness\n    exact_fit = np.isclose(remaining_after, 0, atol=1e-8) * (1 + np.log1p(item))\n    \n    # Topological scoring combining local and global features\n    scores = np.where(\n        valid_mask,\n        entanglement + residual_utility + exact_fit,\n        -np.inf\n    )\n    \n    # Entropic smoothing to prevent degenerate comparisons\n    scores = np.where(valid_mask, scores * (1 + 0.1 * np.log1p(residual_space)), -np.inf)\n    \n    return scores\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Dynamic residual valuation using hyperbolic tangent for smooth thresholding\n    residual_space = np.maximum(remaining_after, 0)\n    residual_utility = np.tanh(residual_space / (item + 1e-9))  # Normalize by item size\n    \n    # Dual-aspect packing density using logistic transform\n    capacity_ratio = item / (bins_remain_cap + 1e-9)\n    anti_fragility = 1 - np.exp(-5 * residual_space)  # Penalizes near-zero residuals\n    density_score = capacity_ratio * anti_fragility\n    \n    # Quantum-inspired superposition of objectives\n    entanglement = np.where(\n        residual_space > item,\n        np.sqrt(residual_space * density_score),  # Future-flexible regime\n        density_score ** 2  # Tight-packing regime\n    )\n    \n    # Precision-robust exact fit detection with magnitude awareness\n    exact_fit = np.isclose(remaining_after, 0, atol=1e-8) * (1 + np.log1p(item))\n    \n    # Topological scoring combining local and global features\n    scores = np.where(\n        valid_mask,\n        entanglement + residual_utility + exact_fit,\n        -np.inf\n    )\n    \n    # Entropic smoothing to prevent degenerate comparisons\n    scores = np.where(valid_mask, scores * (1 + 0.1 * np.log1p(residual_space)), -np.inf)\n    \n    return scores\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Dynamic residual valuation using hyperbolic tangent for smooth thresholding\n    residual_space = np.maximum(remaining_after, 0)\n    residual_utility = np.tanh(residual_space / (item + 1e-9))  # Normalize by item size\n    \n    # Dual-aspect packing density using logistic transform\n    capacity_ratio = item / (bins_remain_cap + 1e-9)\n    anti_fragility = 1 - np.exp(-5 * residual_space)  # Penalizes near-zero residuals\n    density_score = capacity_ratio * anti_fragility\n    \n    # Quantum-inspired superposition of objectives\n    entanglement = np.where(\n        residual_space > item,\n        np.sqrt(residual_space * density_score),  # Future-flexible regime\n        density_score ** 2  # Tight-packing regime\n    )\n    \n    # Precision-robust exact fit detection with magnitude awareness\n    exact_fit = np.isclose(remaining_after, 0, atol=1e-8) * (1 + np.log1p(item))\n    \n    # Topological scoring combining local and global features\n    scores = np.where(\n        valid_mask,\n        entanglement + residual_utility + exact_fit,\n        -np.inf\n    )\n    \n    # Entropic smoothing to prevent degenerate comparisons\n    scores = np.where(valid_mask, scores * (1 + 0.1 * np.log1p(residual_space)), -np.inf)\n    \n    return scores\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}