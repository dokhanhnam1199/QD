<think>
Okay, I need to create an improved priority_v2 function by combining elements from the better code (v0) and the worse code (v1), based on the analysis provided. Let me start by understanding what each version does.

The better code (v0) uses a geometric mean of tightness and utilization. It prioritizes exact fits first, then valid bins using the combined score. The worse code (v1) has more complex elements like dynamic exponents, non-linear scaling, and alignment bonuses, which the analysis says introduce noise.

The analysis mentions that top heuristics balance simplicity with precision-tuned components. So, I should take the core idea from v0 (geometric mean of tightness and utilization) and maybe incorporate some of the better elements from v1 without overcomplicating.

Looking at v1, some parts like the perfection_bonus (rewarding exact fits) might be useful. But in v0, exact fits are already handled with np.inf. However, v1's perfection_bonus adds a size-proportional reward. Wait, but in v0, exact fits get the highest priority. Maybe combining that with a bonus for exact fits could be redundant. Alternatively, perhaps the way v0 handles exact fits is sufficient.

The analysis also mentions that v0's geometric mean works better than exponential boosts. So, avoid the dynamic exponents and non-linear scaling from v1. However, maybe the alignment bonus in v1 (encourage divisible residuals) could be useful if simplified. The analysis says that adaptive weight balancing can help if calibrated carefully.

So, the key is to keep the core of v0 but add some elements from v1 that are beneficial without overcomplicating. Let's think:

1. Keep exact fit priority as in v0.
2. Use the geometric mean of tightness and utilization from v0.
3. Maybe add a small bonus for bins where the remaining space after placing the item is a multiple of the item size (divisible residuals), but simplified. This is from v1's alignment_bonus, which was 0.4 * exp(...). But perhaps a simpler version, like a bonus if remaining space is a multiple of the item size, to encourage future packing.

Wait, but how to calculate that? For example, if after placing the item, the remaining space is divisible by the item size, that might help in future placements. But this could be too specific. Alternatively, maybe a bonus based on how much the remaining space is close to a multiple of the item size. But that might add complexity.

Alternatively, maybe a small bonus for bins that have remaining capacity close to the item size, which could help in future placements. But this is similar to the tightness component. Hmm.

Alternatively, the analysis mentioned that the better heuristics use calibrated constants. So perhaps adding a small alignment bonus but with a lower weight than in v1. For example, in v1, alignment_bonus is 0.4 * exp(...). Maybe reduce that to 0.1 or 0.2 to avoid overcomplicating.

But the analysis also says that overparameterization is bad. So maybe it's better to avoid adding too many terms. The v0's approach is simple and effective. Maybe the only thing to add is a small bonus for exact fits beyond just setting to infinity, but that's already handled.

Wait, in v0, exact fits get np.inf, which ensures they are chosen first. But in v1, there's a perfection_bonus that adds a value scaled by the item size. However, since exact fits are already prioritized, maybe that's redundant. So perhaps the main improvement is to keep the geometric mean but add a small bonus for bins that, after placing the item, have remaining space that's a multiple of some value, which could help future items. But how to implement that without overcomplicating.

Alternatively, maybe use the residual potential from v1 but in a simplified way. The residual_exponent in v1 is dynamic, which the analysis says is overengineered. So perhaps use a fixed exponent. For example, residual_potential = remaining_after ** 0.5 (sqrt) to encourage leaving space that's more likely to fit future items. But how to integrate that with the existing scores.

Alternatively, the analysis says that the best heuristics use geometric mean of tightness and utilization. So perhaps stick to that, but add a small term that considers the future potential of the bin's remaining space. For example, if the remaining space after placing the item is more likely to fit future items, give a higher score. But how to quantify that.

Another idea: The tightness is 1/(remaining_space), which prefers bins with minimal space left. Utilization is 1/(bin's remaining capacity), which prefers bins that are fuller. The geometric mean balances both. But maybe adding a term that considers the remaining space's potential. For example, if the remaining space is a common item size, that's good. But without knowing future items, it's hard. So perhaps a heuristic is to prefer remaining spaces that are larger than a certain threshold, but that's unclear.

Alternatively, take inspiration from the "alignment_bonus" in v1 but simplify it. The alignment_bonus in v1 was 0.4 * exp(-abs(remaining_after/(item + 1e-9) - 1.0)), which encourages the remaining space to be equal to the item size. The idea is that if the remaining space is the same as the current item size, it might fit a future item of the same size. But this is speculative. However, the analysis says that the worst code has "arbitrary scaling" which is bad. So perhaps a simplified version: a bonus if the remaining space is close to the item size. For example, compute how close remaining_after is to the item size, and add a small bonus based on that.

But how to implement this without making the code too complex. Let's see:

In v0's code, after calculating combined_score, maybe add a term like:

alignment_bonus = 0.2 * np.exp(-np.abs(remaining_space - item)/ (item + 1e-9))

But this would give a bonus when remaining_space (after placing the item) is close to the item size. However, this adds another component. But according to the analysis, overcomplicating is bad. So perhaps this is not necessary.

Alternatively, the analysis mentions that the better heuristics use "calibrated constants" and "smooth gradients". So perhaps adding a small alignment bonus with a lower weight could help without introducing too much complexity.

Another point from the analysis: the best heuristics use "focused geometric mean" and avoid "unnecessary complexity". So perhaps the main improvement is to keep the v0 approach but adjust the way the combined score is calculated, maybe with a slight modification.

Wait, in v0, the combined_score is the geometric mean of tightness and utilization. Tightness is 1/(remaining_space + eps), utilization is 1/(bin_remain_cap + eps). The geometric mean is sqrt(tightness * utilization). But maybe there's a better way to combine these two factors. For example, using a weighted geometric mean, but the original uses equal weights.

Alternatively, the analysis says that "adaptive weight balancing can help but requires careful calibration". So perhaps using a fixed weight that slightly favors one component. But the original v0 uses equal weights, which is simple.

Another idea: The v1 code uses a "perfection_bonus" which adds a reward for exact fits. But in v0, exact fits are already given infinity priority, so they are selected first. However, in cases where there are multiple exact fits, perhaps the perfection_bonus could prioritize bins that are more full. But in v0, all exact fits have the same priority (inf), so they are chosen arbitrarily. Maybe adding a tie-breaker for exact fits based on utilization. For example, among bins with exact fits, prefer the one with the smallest remaining capacity (i.e., the most full bin). But in v0, all exact fits are treated equally. However, in practice, this might not matter much since exact fits are rare.

Alternatively, the perfection_bonus in v1 adds a size-proportional reward. But since exact fits are already prioritized, this might not be necessary.

Hmm. The analysis says that the better code uses "exact fits with float tolerance" and "geometric mean of tightness and utilization". The worse code has "dynamic residual potential" and "non-linear scaling" which are bad.

So, to improve upon v0, perhaps the key is to keep the core approach but add a small, well-calibrated component from v1 that doesn't overcomplicate. For example, the alignment_bonus in v1, but simplified.

Let me try to draft the code:

1. Calculate remaining_space and exact_fit as in v0.
2. Calculate tightness and utilization as in v0.
3. Combined_score as geometric mean.
4. Add a small alignment bonus for bins where remaining_space after placing the item is close to the item's size. This would encourage leaving space that could fit another item of the same size, which is a common heuristic in bin packing (like the "first fit decreasing" method, which groups similar items).

But how to compute this. For example, the alignment bonus could be a function that is higher when remaining_space is close to the item size. Using a Gaussian-like function: exp(- (remaining_space - item)^2 / (item^2 + eps)), scaled by a small factor.

But this adds complexity. Let's see:

alignment_bonus = 0.1 * np.exp( - (remaining_space - item)**2 / (item**2 + 1e-9) )

This would give a bonus when remaining_space is close to item. The 0.1 is a small weight to not overpower the main score.

Then, the priorities would be:

priorities = np.where(
    exact_fit,
    np.inf,
    np.where(
        valid,
        combined_score + alignment_bonus,
        -np.inf
    )
)

But this adds a new term. However, according to the analysis, adding such terms should be done with care. The analysis says that "adaptive weight balancing and residual forecasting can help, but requires careful calibration to avoid overparameterization".

So, perhaps this is acceptable if the weight is small and the term is simple.

Alternatively, the alignment_bonus could be based on the remaining_space being a multiple of the item size. For example, if remaining_space is divisible by the item size (within a tolerance), then add a bonus. But checking divisibility with floating points is tricky.

Alternatively, compute how many times the item fits into the remaining space. For example, count = remaining_space // item. But again, with floating points, this is not straightforward.

Another approach: The alignment bonus could be higher if the remaining_space is larger than or equal to the item size. But that's already handled by the valid mask. Hmm.

Alternatively, the bonus could be higher if the remaining_space is a multiple of a certain value, but without knowing future items, this is speculative.

Alternatively, the bonus could be based on the remaining_space being a certain fraction of the bin size. For example, if the bin's remaining capacity after placing the item is a common fraction, like half the bin size, which might be useful for future items. But this is again speculative and adds complexity.

Given the analysis, the best approach is to keep the core of v0 and add a small, well-calibrated component from v1 that doesn't overcomplicate. Let's proceed with the alignment_bonus idea but with a small weight.

So, the code would look like:

def priority_v2(...):
    # Compute remaining_space, exact_fit, valid as in v0
    # Compute tightness and utilization
    combined_score = sqrt(tightness * utilization)
    # Compute alignment_bonus
    alignment_bonus = 0.2 * np.exp( - np.abs(remaining_space - item) / (item + 1e-9) )
    # Combine with combined_score
    adjusted_score = combined_score + alignment_bonus
    # Then set priorities as before, with exact_fit as inf, valid as adjusted_score, else -inf

But wait, the remaining_space here is bins_remain_cap - item. So remaining_space is the space left after placing the item. The alignment_bonus in this case would be higher when remaining_space is close to the item's size. For example, if after placing the item, there's space equal to the item's size, then another item of the same size can fit. This is a common heuristic in bin packing, known as the "best fit" or "matching" strategy.

But in the analysis, the worse code had "alignment_bonus = 0.4 * np.exp(...)", which was considered overengineered. So reducing the weight to 0.2 and simplifying the calculation might make it acceptable.

Another consideration: the alignment_bonus should only apply to valid bins (those where remaining_space >=0). But in the code, valid is already handled in the np.where.

Putting it all together:

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Balanced packing with future alignment: Prioritizes exact fits, combines
    tightness/utilization via geometric mean, adds bonus for divisible residuals."""
    remaining_space = bins_remain_cap - item
    exact_fit = np.isclose(remaining_space, 0, atol=1e-9)
    valid = remaining_space >= 0
    
    # Core components from v0
    tightness = 1 / (np.abs(remaining_space) + 1e-9)
    utilization = 1 / (bins_remain_cap + 1e-9)
    combined_score = np.sqrt(tightness * utilization)
    
    # Inspired by v1's alignment bonus but simplified
    # Bonus when remaining space matches current item size (helps future packing)
    alignment_bonus = 0.2 * np.exp(-np.abs(remaining_space - item)/(item + 1e-9))
    
    priorities = np.where(
        exact_fit,
        np.inf,
        np.where(
            valid,
            combined_score + alignment_bonus,
            -np.inf
        )
    )
    return priorities

The docstring mentions combining tightness/utilization and adding a bonus for divisible residuals (i.e., remaining_space matching item size). The alignment_bonus is simplified from v1's version, using a smaller weight (0.2 instead of 0.4) and a simpler calculation. The exponential term encourages remaining_space to be close to the item size, which could help in fitting another item of the same size in the future.

This combines elements from both v0 and v1, keeping the core of v0's approach while adding a small, calibrated component from v1 that addresses future packing potential without overcomplicating the heuristic.
</think>

```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Hybrid heuristic: Prioritizes exact fits, combines geometric mean of 
    tightness/utilization from v0 with v1's residual alignment bonus (simplified)."""
    remaining_space = bins_remain_cap - item
    exact_fit = np.isclose(remaining_space, 0, atol=1e-9)
    valid = remaining_space >= 0
    
    # Core geometric mean calculation from v0
    tightness = 1 / (np.abs(remaining_space) + 1e-9)
    utilization = 1 / (bins_remain_cap + 1e-9)
    combined_score = np.sqrt(tightness * utilization)
    
    # Simplified residual alignment from v1: Encourage space matching item size
    alignment_bonus = 0.15 * np.exp(-np.abs(remaining_space - item)/(item + 1e-9))
    
    priorities = np.where(
        exact_fit,
        np.inf,  # Absolute priority for perfect fits
        np.where(
            valid,
            combined_score + alignment_bonus,  # Balanced core + alignment bonus
            -np.inf  # Exclude invalid bins
        )
    )
    
    return priorities
```
