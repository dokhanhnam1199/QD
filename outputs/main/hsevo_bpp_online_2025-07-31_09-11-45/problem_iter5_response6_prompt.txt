{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Balanced packing heuristic: Prioritizes exact fits (with float tolerance), \n    then geometric mean of tightness (1/remaining_space) and bin utilization (1/remaining_capacity).\"\"\"\n    remaining_space = bins_remain_cap - item\n    exact_fit = np.isclose(remaining_space, 0, atol=1e-9)\n    valid = remaining_space >= 0\n    \n    # Calculate components with epsilon smoothing\n    tightness = 1 / (np.abs(remaining_space) + 1e-9)  # Prefer minimal leftover space\n    utilization = 1 / (bins_remain_cap + 1e-9)        # Prefer bins closer to being full\n    \n    # Geometric mean balances both objectives\n    combined_score = np.sqrt(tightness * utilization)\n    \n    priorities = np.where(\n        exact_fit,\n        np.inf,  # Absolute priority for perfect fits\n        np.where(\n            valid,\n            combined_score,\n            -np.inf  # Exclude bins without capacity\n        )\n    )\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    remaining_after = bins_remain_cap - item\n    valid_mask = remaining_after >= 0\n    \n    # Dynamic residual potential with item-size modulated exponent\n    residual_exponent = np.clip(1.2 - 0.7*item, 0.4, 1.2)  # Adaptive curvature control\n    residual_potential = (np.maximum(remaining_after, 0) + 1e-12) ** residual_exponent\n    \n    # Density efficiency with non-linear scaling\n    fill_efficiency = (item / (bins_remain_cap + 1e-12)) ** np.sqrt(item + 0.2)\n    \n    # Multi-objective synergy with dynamic weights\n    synergy_score = fill_efficiency * residual_potential\n    \n    # Precision-stable exact fit bonus with size-proportional reward\n    perfection_bonus = np.isclose(remaining_after, 0, atol=1e-8, rtol=0) * (2.5 + 3*item)\n    \n    # Future capacity alignment bonus (encourage divisible residuals)\n    alignment_bonus = 0.4 * np.exp(-np.abs(remaining_after/(item + 1e-9) - 1.0))\n    \n    scores = np.where(\n        valid_mask, \n        synergy_score + perfection_bonus + alignment_bonus,\n        -np.inf\n    )\n    \n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses a focused geometric mean of fill efficiency and residual potential with calibrated constants, while the worst introduces unnecessary complexity (quantum-inspired terms, hyperbolic transforms) that likely introduces noise. (2nd vs 19th) shows duplicated simple synergy scoring outperforms topological scoring with entropic smoothing. (8th vs 13th) reveals adaptive weight balancing and residual forecasting can help, but requires careful calibration to avoid overparameterization. (7th vs 17th) demonstrates that geometric mean of tightness/utilization works better than exponential boosts with arbitrary scaling. Overall: Top heuristics balance simplicity with precision-tuned components, while lower-ranked ones suffer from either under-calibration or overengineering.\n- \n<think>\nOkay, let's tackle this. The user wants to redefine 'Current self-reflection' for designing better heuristics, avoiding the ineffective aspects mentioned. First, I need to understand the existing points in Current self-reflection. They mention things like synergistic balance using multiplicative means, precision handling, calibrated epsilon, avoiding ungrounded complexity.\n\nThe effective heuristics list includes balancing packing with flexibility, rigorous floating precision, smooth gradients, multiplicative factors for independence, and using physics/math metaphors. The ineffective part is empty, so maybe the user wants to ensure that the new reflection doesn't include any of the common pitfalls that weren't listed here.\n\nSo, the task is to take the current points and rephrase or enhance them, making sure to avoid ineffective elements. The user probably wants concise, actionable advice. Let me break down each part.\n\nFirst, the original points stress multiplicative balance. Maybe emphasize that multiplicative combination should be only when variables are independent. Also, calibrated epsilon constants for numerical stability\u2014so numerical rigor is key. Avoid quantum/entropic metaphors, so stick to grounded math.\n\nThe advice should include using geometric means for balance, handling precision with care, smooth gradients over abrupt changes, and using physics-based models. Avoid additive features, ungrounded metaphors, ignoring precision, and independent variables combined additively.\n\nWait, the user's example response has keywords, advice, avoid, explanation. So each bullet should have those four parts. Let me structure each point accordingly. Need four bullet points. Let me think of the main points from the current reflection and translate them into the required format, ensuring they avoid the ineffective aspects (even though ineffective wasn't specified, but perhaps common pitfalls in heuristics design).\n\nFirst keyword could be Multiplicative Balance. Advice: Use geometric means for competing objectives. Avoid additive combinations. Explanation: Geometric means prevent dominance by single factors and maintain proportional trade-offs.\n\nSecond keyword: Numerical Rigor. Advice: Implement precision-aware epsilon calibration. Avoid ignoring floating-point errors. Explanation: Ensures stability in calculations and prevents underflow/overflow.\n\nThird: Smooth Transitions. Advice: Design gradual score gradients. Avoid abrupt threshold-based boosts. Explanation: Smoothness allows for nuanced optimization paths, avoiding local minima traps.\n\nFourth: Grounded Metaphors. Advice: Use physics/math principles. Avoid biological/cosmic analogies. Explanation: Physics-based models provide verifiable, interpretable relationships.\n\nCheck if these points cover the original current reflection and avoid the ineffective parts. The original mentions avoiding ungrounded complexity (like quantum metaphors), so Grounded Metaphors bullet addresses that. Also, precision handling and multiplicative balance are covered. The advice points should each have a keyword, advice, what to avoid, and a brief explanation. That should fit the user's request.\n</think>\n\n- **Keywords**: Multiplicative balance, Numerical rigor, Smooth transitions, Grounded metaphors  \n- **Advice**: 1) Combine independent objectives via geometric means 2) Embed precision-aware error bounds 3) Use gradual scoring to enable adaptive tradeoffs 4) Anchor in verifiable physics (e.g., spring models, friction coefficients).  \n- **Avoid**: Additive objective stacking, arbitrary \"quantum-inspired\" terms, hard thresholds, unvalidated constants.  \n- **Explanation**: Geometric balancing preserves proportionality between dimensions, numerical rigor prevents instability, smooth gradients enable robust optimization, and physics metaphors ensure testable causality over mystical analogies.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}