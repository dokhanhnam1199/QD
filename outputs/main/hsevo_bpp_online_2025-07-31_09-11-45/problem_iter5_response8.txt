<think>
Okay, I need to create an improved priority_v2 function by combining elements from the better (v0) and worse (v1) codes, based on the analysis provided. Let me start by understanding what made v0 better and v1 worse.

From the analysis, the best heuristics use a focused approach with geometric mean of tightness and utilization, calibrated constants, and avoid overengineering. The worse code had unnecessary complexity like hyperbolic tangent, quantum terms, and overparameterization.

So, the goal is to take the good parts from v0 and possibly integrate any useful elements from v1 without adding noise. Let's look at v0's key points: it uses geometric mean of tightness (1/remaining_space) and utilization (1 - bin_cap_remain), applies an exponential boost for perfect fits, and uses valid_mask to filter bins.

v1 had some elements like residual_space, but with hyperbolic tangent and other complex terms. The analysis mentioned that adaptive weight balancing and residual forecasting could help if calibrated properly. However, v1's approach was too complex.

Maybe I can enhance v0 by adding a component that considers future flexibility, but in a simple way. For example, after placing the item, the remaining space in the bin could be a factor. But how to balance that with the current fit.

Wait, v0's tightness is 1/(remaining_space), which prioritizes bins where the item fits tightly. Utilization is how full the bin is already. The geometric mean balances these two. The perfect fit boost is good.

In v1, they used residual_space (remaining_after) and tried to compute some utility, but with hyperbolic tangent which might not add much. However, the analysis mentioned that "adaptive weight balancing and residual forecasting can help, but require careful calibration".

Perhaps adding a term that encourages leaving bins with more residual space (for future items) could be useful, but without overcomplicating. For example, a small weight on the residual space to prefer bins that leave room for future items, but only if it doesn't compromise the tight fit and utilization.

Alternatively, maybe use a weighted product instead of a pure geometric mean. Or add a term that considers the residual space in a way that's complementary to the existing factors.

Another idea: the analysis mentioned that the best heuristics balance simplicity with precision-tuned components. So, perhaps combine the geometric mean from v0 with a slight adjustment based on residual space, but in a simple way.

Wait, in v0, the combined score is sqrt(tightness * utilization). What if we add a term that rewards bins with more residual space after placing the item, but scaled appropriately? For example, residual_space (which is bins_remain_cap - item) could be a positive factor, but only if it's balanced with the other terms.

But how to integrate that without complicating the formula. Maybe multiply by a function of residual_space. For instance, (1 + residual_space) to slightly prefer bins that have more space left, but this might conflict with the tightness.

Alternatively, since residual_space is the remaining capacity after placing the item, a higher residual_space means more room for future items. But in bin packing, once an item is placed, the residual space is fixed. So, if a bin has more residual space after placing the current item, it might be better for future items. However, the online problem requires immediate placement without knowledge of future items. So, this is a trade-off between current efficiency (tight fit) and future flexibility.

But how to model that. Maybe the priority should balance between tight fit (to not waste space) and leaving some room for potential future items. However, without knowing future items, this is tricky.

In the analysis, the better code uses the geometric mean of tightness and utilization. Utilization is how full the bin is before placing the item. Tightness is how well the item fits. The geometric mean ensures both are considered.

Perhaps adding a third factor that considers the residual space after placement, but in a simple multiplicative way. For example, the combined score could be the geometric mean of tightness, utilization, and residual_space_utility, where residual_space_utility is a function that rewards some residual space.

But how to define residual_space_utility. Maybe 1/(1 + residual_space) to prefer smaller residuals (tighter fits), but that's similar to tightness. Alternatively, maybe residual_space itself, but normalized. Wait, but tightness is already 1/(residual_space + eps). So adding residual_space as a factor would conflict.

Alternatively, perhaps the residual space can be used to adjust the weight between tightness and utilization. For example, if residual_space is large, maybe weight utilization more, but if it's small, weight tightness more. But this adds complexity.

Alternatively, take inspiration from the "anti_fragility" term in v1, which was 1 - exp(-5 * residual_space). This term penalizes near-zero residuals. But in v1, this was part of a more complex formula. However, if used carefully, it might help.

Wait, the analysis said that "adaptive weight balancing and residual forecasting can help, but requires careful calibration". So perhaps adding a term that slightly penalizes bins with very little residual space (to avoid creating bins that are almost full but not quite, which can't fit future items). But how to do that without overcomplicating.

In v0, the combined score is sqrt(tightness * utilization). Maybe multiply this by a factor that is (1 + residual_space) to give a slight boost to bins that leave more space, but this might reduce the priority for tight fits. Alternatively, use a factor that is 1/(1 + residual_space) to give higher scores to bins with less residual space (tighter fits), but that's already captured by tightness.

Hmm. Alternatively, the analysis mentioned that the better heuristics use "calibrated constants". So perhaps adjust the weights in the geometric mean or add a small term that considers residual space in a controlled way.

Another angle: the analysis of the worse code (v1) mentioned that "quantum-inspired superposition" introduced noise. So avoid such terms. The better code (v0) uses a simple geometric mean and a boost for perfect fits.

So, the improved function should stick to the core of v0 but perhaps enhance it with a carefully calibrated additional factor. For example, in v0, after computing the combined score, maybe multiply by a term that encourages leaving some residual space, but only if it's not too much.

Wait, but how to balance that. For example, if a bin has a residual space of 0.5 after placing the item, that's a lot of space left. But in online bin packing, we don't know if future items can fit there. So, perhaps it's better to prioritize bins that, after placing the current item, have a residual space that is a multiple of the average item size. But without knowing future items, this is not possible.

Alternatively, perhaps assume that future items are of similar size, and prefer bins where the residual space is a multiple of the current item's size. But this is speculative.

Alternatively, use the item size to weight the residual space. For example, residual_space / item_size could indicate how many such items could fit in the remaining space. But again, without knowing future items, this is a guess.

Alternatively, in the combined score, add a term that is the residual_space multiplied by a small weight. For example:

combined = sqrt(tightness * utilization) + alpha * residual_space

But this would require tuning alpha. However, the analysis warns against overparameterization. So perhaps this is not the way.

Wait, the analysis says that the best heuristics use "synergistic balance using multiplicative means". So multiplicative combination is better than additive. So perhaps instead of adding terms, find a multiplicative way to include residual_space.

Alternatively, the residual_space could be part of the utilization. Wait, utilization in v0 is 1 - bin_remain_cap, which is the current utilization before placing the item. After placing the item, the bin's remaining capacity is bin_remain_cap - item. So the new utilization would be 1 - (bin_remain_cap - item) = 1 - bin_remain_cap + item = utilization_before + item. But this is not directly helpful.

Alternatively, the residual_space after placing the item could be considered as part of the score. For example, a bin that, after placing the item, has a residual space that is a multiple of the average item size (but again, we don't know future items).

Alternatively, think of the residual space as a measure of how much 'waste' there is. So, lower residual space is better. But that's already captured by tightness (1/residual_space).

Hmm. Maybe the key is to stick with the v0 approach but enhance the perfect fit handling. The v0 code applies an exponential boost for perfect fits. The analysis says that "exponential boost for perfect fits while maintaining smooth gradient for near-optimal placements" is good.

In v1, they had an 'exact_fit' term that added a log term. But the analysis says that the better code's approach is better.

So, perhaps the improved function can take the core of v0, and add a small adjustment based on the residual space, but in a simple way. For example, after computing the combined score, multiply by (1 + residual_space) to slightly prefer bins with more residual space, but this would actually lower the priority for tight fits, which is counterintuitive. Wait, no: if residual_space is larger, then (1 + residual_space) is larger, which would increase the score. But tightness is 1/(residual_space), so for a larger residual_space, tightness is smaller. So multiplying by (1 + residual_space) would create a balance. Let's see:

Suppose combined = sqrt( (1/(residual_space)) * utilization ) * (1 + residual_space)

This would be equivalent to sqrt( utilization / residual_space ) * (1 + residual_space )

But this might not be the right approach. Alternatively, maybe the residual_space can be incorporated into the utilization term. For example, utilization after placing the item is (1 - (bin_remain_cap - item)) = 1 - bin_remain_cap + item. But the original utilization is 1 - bin_remain_cap. So after placing the item, the utilization increases by the item's size. But since we're evaluating before placing, the utilization is the current utilization, and the tightness is based on the remaining space after placing.

Alternatively, perhaps the residual space can be used to adjust the utilization. For example, if a bin is more utilized after placing the item, that's better. But utilization in v0 is the current utilization before placing. So after placing, the utilization would be higher. But we can't know that in advance. Wait, no: the utilization in v0 is 1 - bin_remain_cap, which is the current utilization. When we place the item, the bin's remaining capacity becomes bin_remain_cap - item. So the new utilization would be 1 - (bin_remain_cap - item) = 1 - bin_remain_cap + item = utilization_before + item. But since we are scoring before placing, the utilization is the current utilization, and the tightness is based on the remaining space after placing.

Hmm. Maybe the key is to keep the v0 approach but add a term that considers the new utilization (after placing the item). For example, the utilization after placing would be (original_utilization + item). But since the original utilization is 1 - bin_remain_cap, adding the item gives 1 - bin_remain_cap + item = 1 - (bin_remain_cap - item) = 1 - residual_space. So the new utilization is 1 - residual_space. But residual_space is the remaining capacity after placing the item.

So, the new utilization is 1 - residual_space. But how to incorporate that into the score. The v0 approach uses the current utilization (before placing) and the tightness (after placing). Maybe the new utilization (after placing) could be a factor. For example, the score could be a combination of tightness (1/residual_space) and the new utilization (1 - residual_space). But that's similar to the original approach but with a different utilization term.

Wait, in v0, utilization is 1 - bin_remain_cap (current), and tightness is 1/(residual_space). The new utilization after placing would be 1 - (bin_remain_cap - item) = 1 - residual_space. So, perhaps instead of using the current utilization, use the new utilization. But that would change the formula. Let's see:

If we compute tightness as 1/residual_space and new_utilization as 1 - residual_space, then the geometric mean would be sqrt( (1/residual_space) * (1 - residual_space) ). But this is different from v0's approach.

Alternatively, maybe the new utilization is a better measure because it reflects how full the bin will be after placing the item. So, combining tightness (which is about the fit) and new_utilization (how full the bin is after placing) via geometric mean.

But in that case, the formula would be:

tightness = 1 / residual_space
new_utilization = 1 - residual_space
combined = sqrt(tightness * new_utilization)

But residual_space is bins_remain_cap - item. So new_utilization is 1 - (bins_remain_cap - item) = 1 - bins_remain_cap + item. Wait, but bins_remain_cap is the current remaining capacity. So 1 - bins_remain_cap is the current utilization. Adding the item gives the new utilization. So new_utilization = current_utilization + item.

But in this case, new_utilization is not bounded. For example, if the bin had 0.5 remaining, and the item is 0.6, then residual_space is negative, which is invalid. But in valid cases, residual_space is >=0, so new_utilization would be 1 - residual_space, which is 1 - (bin_remain_cap - item) = 1 - bin_remain_cap + item = current_utilization + item.

But since the bin's total capacity is 1 (assuming normalized), the new_utilization can't exceed 1. Because item <= bin_remain_cap (valid), so bin_remain_cap - item >=0. So new_utilization = 1 - residual_space = 1 - (bin_remain_cap - item) = 1 - bin_remain_cap + item. But 1 - bin_remain_cap is the current utilization (u), so new_utilization = u + item. But since u = 1 - bin_remain_cap, and item <= bin_remain_cap, then u + item <= 1 - bin_remain_cap + bin_remain_cap = 1. So new_utilization is between u and 1.

So, using new_utilization (which is u + item) in the geometric mean with tightness (1/residual_space) would give:

combined = sqrt( (1/residual_space) * (u + item) )

But u is 1 - bin_remain_cap. So this becomes sqrt( (1/(bin_remain_cap - item)) * (1 - bin_remain_cap + item) )

But how does this compare to v0's approach? In v0, the combined score is sqrt( (1/(residual_space)) * (1 - bin_remain_cap) )

So the difference is whether we use the current utilization (1 - bin_remain_cap) or the new utilization (1 - bin_remain_cap + item) in the geometric mean.

Using the new utilization might be better because it reflects how full the bin will be after placing the item, which is a better measure of utilization. For example, a bin that is currently 0.5 utilized and receives a 0.3 item will be 0.8 utilized, which is better than a bin that is 0.6 utilized and receives a 0.3 item (0.9 utilized). But the tightness is 1/(0.2) vs 1/(0.1), so the second bin has higher tightness. The combined score would be sqrt(5 * 0.8) ≈ 2 vs sqrt(10 * 0.9) ≈ 3, so the second bin is preferred, which is correct.

In v0's approach, the current utilization is 0.5 and 0.6. The tightness is 1/0.2=5 and 1/0.1=10. The combined scores are sqrt(5*0.5)=sqrt(2.5)≈1.58 and sqrt(10*0.6)=sqrt(6)≈2.45. So the second bin is preferred. With the new approach, the combined scores are sqrt(5*0.8)=sqrt(4)=2 and sqrt(10*0.9)=sqrt(9)=3. So the preference is the same, but the scores are higher. However, the relative ordering is preserved. So using new_utilization might not change the bin selection but could affect the scores' magnitudes.

But why would using new_utilization be better? Because it represents the actual utilization after placing the item, which is a more accurate reflection of how well the bin is packed. So this could be an improvement over v0.

So, modifying v0 to use new_utilization instead of current utilization might be a way to improve it. Let's try that.

Another point from the analysis: the best heuristics use "synergistic balance using multiplicative means". So combining tightness and new_utilization via geometric mean is synergistic.

Additionally, the analysis mentioned that the worse code had "arbitrary scaling" in the exponential boost. The better code uses a calibrated boost for perfect fits. So retaining that part is important.

So, the improved function would:

1. Compute residual_space = bins_remain_cap - item
2. valid_mask = residual_space >=0
3. Compute tightness = 1/(residual_space + eps)
4. Compute new_utilization = 1 - residual_space (which is 1 - (bin_remain_cap - item) = 1 - bin_remain_cap + item = current_utilization + item)
5. combined = sqrt(tightness * new_utilization)
6. Apply perfect fit boost where residual_space is close to zero.

Wait, but new_utilization is 1 - residual_space. So when residual_space is 0 (perfect fit), new_utilization is 1. So in that case, tightness is 1/eps (very large), and new_utilization is 1. So the combined score would be sqrt( (1/eps) * 1 ) = very large, which already gives a high score. But in v0, they explicitly boost perfect fits by multiplying by 2 and adding 1e6. Maybe this is redundant if the combined score already accounts for it. However, in practice, due to floating-point precision, even a tiny residual_space (like 1e-16) might not trigger the perfect fit check, but the tightness would be 1e16, leading to a very high score. So perhaps the explicit boost is not needed. But in v0, they added it to ensure that perfect fits are prioritized.

Alternatively, the explicit boost can be retained to make sure that exact fits are chosen even if there's a tiny residual due to floating-point errors.

So, putting it all together:

def priority_v2(...):
    residual_space = bins_remain_cap - item
    valid_mask = residual_space >=0
    eps = 1e-9
    tightness = 1/(residual_space + eps)
    new_utilization = 1 - residual_space  # This is 1 - (bin_remain_cap - item) = current_utilization + item
    combined = np.sqrt(tightness * new_utilization)
    scores = np.where(valid_mask, combined, -np.inf)
    # Boost perfect fits
    perfect_fits = np.isclose(residual_space, 0, atol=eps)
    scores = np.where(perfect_fits, scores * 2 + 1e6, scores)
    return scores

But wait, new_utilization is 1 - residual_space. For example, if residual_space is 0.1, new_utilization is 0.9. So the combined score is sqrt( (1/0.1) * 0.9 ) = sqrt(9) = 3. If residual_space is 0.2, new_utilization is 0.8, combined is sqrt(5 * 0.8) = sqrt(4) = 2. So the smaller the residual_space, the higher the score, which is correct.

But in v0, the utilization was 1 - bin_remain_cap (current utilization). For example, if a bin has 0.5 remaining (current utilization 0.5), and the item is 0.3, then residual_space is 0.2. new_utilization is 0.8. In v0, utilization is 0.5, tightness is 5. combined is sqrt(5 * 0.5) = ~1.58. In v2, combined is sqrt(5 * 0.8) = ~2. So v2 gives a higher score for the same bin, which might be better because the new utilization is higher.

This could lead to better overall packing because it prefers bins that, after placing the item, have higher utilization. So this seems like a good improvement.

Another consideration: when the residual_space is very small but not zero, the tightness term dominates. For example, residual_space=1e-8, tightness=1e8, new_utilization=1-1e-8≈1. So combined is sqrt(1e8 * 1) = 1e4. But if another bin has residual_space=0 (perfect fit), the combined score would be sqrt(1e9 * 1) = ~3e4, but then multiplied by 2 and added 1e6, making it much higher. So the explicit boost for perfect fits ensures they are chosen even if another bin has a near-perfect fit.

This seems reasonable.

So, the key improvements in v2 over v0 are:

- Using new_utilization (after placing the item) instead of current utilization (before placing), which better reflects the bin's packed state.
- Retaining the perfect fit boost to handle floating-point precision issues.

This combines the strengths of v0's simplicity and calibrated constants with a more accurate utilization metric.

Now, let's code this with appropriate comments and docstring.
</think>

```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Optimizes tight fit vs post-packing utilization via geometric mean. Explicitly
    prioritizes perfect fits while maintaining smooth gradients for near-optimal cases.
    """
    residual_space = bins_remain_cap - item
    valid_mask = residual_space >= 0
    eps = 1e-9  # Numerical stability
    
    # Core synergy: Balance immediate fit with final packed density
    tightness = 1 / (residual_space + eps)
    post_utilization = 1 - residual_space  # Utilization after packing
    combined = np.sqrt(tightness * post_utilization)  # Geometric mean preserves proportionality
    
    scores = np.where(valid_mask, combined, -np.inf)
    
    # Strategic perfect fit prioritization
    exact_fits = np.isclose(residual_space, 0, atol=eps)
    scores = np.where(exact_fits, scores * 5 + 1e9, scores)  # Dominant boost while preserving order
    
    return scores
```
