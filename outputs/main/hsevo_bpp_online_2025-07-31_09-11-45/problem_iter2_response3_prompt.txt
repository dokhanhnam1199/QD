{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Best Fit with utilization boost: Prioritizes bins that minimize wasted space\n    after placement, with preference for bins that would become nearly full.\"\"\"\n    # Calculate remaining capacity after potential placement\n    after_placement = bins_remain_cap - item\n    \n    # Create mask for valid bins that can accommodate the item\n    valid_mask = bins_remain_cap >= item\n    \n    # Calculate utilization ratio (1 - remaining_after_placement/original_capacity)\n    # Assuming original bin capacity is 1.0 (common normalized scenario)\n    utilization = 1.0 - after_placement\n    \n    # Boost score for bins that would become highly utilized (>90%)\n    utilization_boost = np.where(utilization > 0.9, 2.0, 1.0)\n    \n    # Base score is inverse of wasted space (higher = better fit)\n    # Add boosted utilization as tiebreaker for nearly-full bins\n    scores = np.where(\n        valid_mask,\n        (1 / (after_placement + 1e-9)) * utilization_boost,\n        -np.inf\n    )\n    \n    return scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins that would be nearly filled, with exponential boost for perfect fits.\"\"\"\n    remain_after = bins_remain_cap - item\n    feasible_mask = remain_after >= 0\n    \n    # Base score combines remaining space efficiency and square of utilization\n    utilization = 1.0 - (bins_remain_cap - item)  # Assuming bin capacity = 1.0\n    space_efficiency = 1 / (remain_after + 1e-9)\n    \n    # Boost for bins that would be 95%+ full\n    fill_boost = np.where(utilization >= 0.95, 10, 1)\n    \n    # Extreme boost for perfect fits\n    perfect_fit_boost = np.where(remain_after == 0, 1000, 1)\n    \n    scores = utilization**2 * space_efficiency * fill_boost * perfect_fit_boost\n    return np.where(feasible_mask, scores, -np.inf)\n\n### Analyze & experience\n- Comparing 1st (quantum-inspired) vs 20th (radioactive decay): The best heuristic combines harmonic efficiency (1/remaining) with residual potential (\u221acapacity) via geometric mean, creating balanced packing/flexibility tradeoffs. The worst uses multiplicative terms (tightness \u00d7 utilization \u00d7 decay) that over-penalize mid-range bins.  \n\n2nd (celestial harmony) vs 19th: 2nd's golden ratio weighting (0.618/0.382) between tight fits and future flexibility shows mathematically informed balance, while 19th's exponential decay bonus lacks theoretical grounding and overfits to near-exact matches.  \n\n4th (gravitational) vs 16th (black hole): Both use inverse-square prioritization, but 4th cleanly separates exact fits from others, while 16th introduces unstable density penalties that disrupt ordering.  \n\n13th (exact fit + reciprocal) vs 10th: 13th handles floating-point tolerance properly (np.isclose) and scales priorities appropriately, while 10th's 1e9 boost creates artificial score cliffs.\n- \n<think>\nOkay, let's tackle this. The user wants to redefine 'Current self-reflection' for designing better heuristics, making sure to avoid the ineffective aspects mentioned. The existing effective heuristics include things like balancing tight packing with flexibility, handling floating precision, smooth gradients, multiplicative factors for independence, and using physics/math metaphors.\n\nFirst, I need to identify what's missing in the current self-reflection. The ineffective part isn't listed, but maybe the current points could be too rigid. For example, using only multiplicative combinations when factors are independent might limit some scenarios where a different combination could work better. Also, relying solely on physics/math metaphors might exclude other useful analogies that are still interpretable.\n\nNext, the advice should build on the current strengths but address potential gaps. Maybe emphasize dynamic adaptation instead of fixed ratios. Also, ensuring that even if factors aren't perfectly independent, there's a way to combine them without forcing multiplication. Testing heuristic robustness under varying conditions could be another point. And while metaphors are good, grounding them in empirical validation would make them more reliable.\n\nAvoiding things like static ratios, over-reliance on independence assumptions, neglecting empirical checks, and forcing metaphors that don't fit. The explanation should tie these together, showing how the new advice leads to more adaptable and robust heuristics without the pitfalls of the old approach.\n</think>\n\n**Keywords**: Dynamic adaptation, empirical validation, dimensional synergy, constraint robustness  \n**Advice**: 1) Replace fixed ratios with *adaptive thresholds* that evolve with problem scale 2) Test heuristics under *extreme precision edge cases* (e.g., near-zero values) 3) Quantify independence between factors before choosing combination operators 4) Use metaphors only when they enable *actionable geometric intuition*.  \n**Avoid**: Static \"golden ratios\", blind multiplicative blending, assuming dimension independence without proof, poetic analogies without operational mappings.  \n**Explanation**: Enhances adaptability through responsive thresholds while maintaining rigor via stress-testing and explicit dependency analysis. Metaphors become tools rather than dogma when tied to verifiable spatial reasoning.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}