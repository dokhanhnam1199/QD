<think>
Okay, I need to create a priority function for the online bin packing problem by combining elements from the better and worse code examples, while incorporating the analysis and experience provided. Let me start by understanding the existing versions.

The better code (v0) focuses on the fill ratio (item divided by remaining capacity) and adds a bonus for perfect fits. It uses a valid mask to exclude bins that can't fit the item. The worse code (v1) uses tightness factor (inverse remaining space), utilization factor, and an exponential decay bonus. But according to the analysis, multiplicative terms can over-penalize mid-range bins, so that's a problem.

The analysis mentions that the best heuristics combine harmonic efficiency with residual potential via geometric mean. The worst ones use multiplicative terms. So I should avoid just multiplying factors together. The better approach is to balance tight packing with flexibility.

Looking at the experience points: the 13th version handles floating-point tolerance properly, which v0 does with the epsilon. The v0 also has a perfection bonus. The analysis also mentions that the geometric mean creates balanced tradeoffs. 

So, perhaps combine the fill ratio from v0 with some form of residual potential (like sqrt of remaining capacity) using a geometric mean. Also, include the perfection bonus for exact fits. Avoid multiplicative terms and instead use additive or balanced combinations.

Wait, the analysis says that the best heuristic uses harmonic efficiency (1/remaining) and residual potential (sqrt(capacity)) via geometric mean. So maybe the fill ratio (item/remaining) is part of that. Let me think: harmonic efficiency might refer to the inverse of remaining space, but in v0, it's item/(remaining capacity). Hmm.

Alternatively, maybe the geometric mean of two terms: one being the fill ratio (item / remaining) and another being the square root of the remaining capacity after placement. That way, it balances tight packing (high fill ratio) with residual potential (sqrt(remaining_after)), which could allow for future flexibility.

Wait, the residual potential might refer to the remaining capacity after placing the item. If we take the square root of that, it's a way to value bins that have some remaining space but not too much, encouraging a balance. So combining the fill ratio (how much this item fills the bin) with the sqrt of the remaining capacity (to leave room for future items) via geometric mean.

Also, the analysis mentions that the perfection bonus (exact fits) should be handled properly. So adding a bonus when remaining_after is zero.

So the steps would be:

1. Calculate remaining_after as bins_remain_cap - item.
2. Create a valid mask where remaining_after >=0.
3. For valid bins, compute two factors:
   a. Fill efficiency: item / (bins_remain_cap + epsilon) to avoid division by zero.
   b. Residual potential: sqrt(remaining_after + epsilon) to avoid zero.
4. Take the geometric mean of these two factors. The geometric mean is the square root of (a * b), which balances both factors.
5. Add a bonus for exact fits (remaining_after == 0), scaled appropriately.
6. For invalid bins, set score to -inf.

This approach combines the tight packing (fill efficiency) with future flexibility (residual potential) using a geometric mean, which the analysis mentioned as effective. The exact fit bonus encourages perfect packing.

Let me check the analysis again. The better code uses fill_ratio and perfection_bonus. The worse code uses multiple factors multiplied, which is bad. The analysis says that combining via geometric mean is better than multiplicative terms. So the geometric mean approach should be better.

Now, implement this in code. Also, handle floating-point precision with np.isclose for exact fits instead of ==0, as per the analysis note about 13th vs 10th.

So, in code:

- remaining_after = bins_remain_cap - item
- valid_mask = remaining_after >=0
- fill_efficiency = item / (bins_remain_cap + 1e-9)
- residual_potential = np.sqrt(remaining_after + 1e-9)
- geometric_mean = np.sqrt(fill_efficiency * residual_potential)
- perfection_bonus = np.isclose(remaining_after, 0, atol=1e-9) * 2.0
- scores = np.where(valid_mask, geometric_mean + perfection_bonus, -np.inf)

This combines the two factors with geometric mean and adds a bonus for exact fits. The epsilon (1e-9) is used to prevent division by zero and sqrt of negative numbers. Using np.isclose with a tolerance handles floating-point precision for exact fits.

This should address the analysis points: avoiding multiplicative penalties, using geometric mean for balance, proper exact fit handling, and combining tightness with flexibility.
</think>

```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Balances immediate tight packing (item/remaining_ratio) with future 
    flexibility (sqrt residual space), using geometric mean for synergy."""
    
    remaining_after = bins_remain_cap - item
    valid_mask = remaining_after >= 0
    
    # Core efficiency metric: item fills current bin proportion
    fill_efficiency = item / (bins_remain_cap + 1e-9)  # +eps prevents div0
    
    # Flexibility metric: sqrt residual space allows mid-sized future items
    residual_potential = np.sqrt(np.maximum(remaining_after, 0) + 1e-9)
    
    # Geometric mean creates balanced synergy between competing objectives
    synergy_score = np.sqrt(fill_efficiency * residual_potential)
    
    # Precision-aware exact fit bonus (better than ==0 for floating point)
    perfection_bonus = np.isclose(remaining_after, 0, atol=1e-8) * 2.0
    
    # Combine components only for valid bins
    scores = np.where(valid_mask, synergy_score + perfection_bonus, -np.inf)
    
    return scores
```
