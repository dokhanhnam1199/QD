{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritize bins that exactly fit the item, then use inverse remaining capacity.\"\"\"\n    remaining_after = bins_remain_cap - item\n    can_fit = remaining_after >= 0\n    exact_fit = (remaining_after == 0)\n    \n    # Give extreme priority to exact fits, then prioritize smallest remaining space\n    priority = np.where(\n        can_fit,\n        -remaining_after + 1e9 * exact_fit,  # Exact fits get +1e9 boost\n        -np.inf  # Infeasible bins get lowest priority\n    )\n    return priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritize exact fits, then bins with smallest leftover space using reciprocal.\"\"\"\n    leftover = bins_remain_cap - item\n    can_fit = bins_remain_cap >= (item - 1e-9)  # Floating point tolerance\n    exact_fit = np.isclose(leftover, 0, atol=1e-9, rtol=0)\n    \n    scores = np.full_like(bins_remain_cap, -np.inf)\n    valid_bins = can_fit\n    \n    # Apply massive priority boost for exact fits, reciprocal of leftover otherwise\n    scores[valid_bins] = np.where(\n        exact_fit[valid_bins],\n        1e9,  # Arbitrarily large value to prioritize exact fits\n        1.0 / (leftover[valid_bins] + 1e-9)  # +epsilon to avoid division by zero\n    )\n    \n    return scores\n\n### Analyze & experience\n- Comparing 1st (quantum-inspired) vs 20th (radioactive decay): The best heuristic combines harmonic efficiency (1/remaining) with residual potential (\u221acapacity) via geometric mean, creating balanced packing/flexibility tradeoffs. The worst uses multiplicative terms (tightness \u00d7 utilization \u00d7 decay) that over-penalize mid-range bins.  \n\n2nd (celestial harmony) vs 19th: 2nd's golden ratio weighting (0.618/0.382) between tight fits and future flexibility shows mathematically informed balance, while 19th's exponential decay bonus lacks theoretical grounding and overfits to near-exact matches.  \n\n4th (gravitational) vs 16th (black hole): Both use inverse-square prioritization, but 4th cleanly separates exact fits from others, while 16th introduces unstable density penalties that disrupt ordering.  \n\n13th (exact fit + reciprocal) vs 10th: 13th handles floating-point tolerance properly (np.isclose) and scales priorities appropriately, while 10th's 1e9 boost creates artificial score cliffs.\n- \n<think>\nOkay, let's tackle this. The user wants to redefine 'Current self-reflection' for designing better heuristics, making sure to avoid the ineffective aspects mentioned. The existing effective heuristics include things like balancing tight packing with flexibility, handling floating precision, smooth gradients, multiplicative factors for independence, and using physics/math metaphors.\n\nFirst, I need to identify what's missing in the current self-reflection. The ineffective part isn't listed, but maybe the current points could be too rigid. For example, using only multiplicative combinations when factors are independent might limit some scenarios where a different combination could work better. Also, relying solely on physics/math metaphors might exclude other useful analogies that are still interpretable.\n\nNext, the advice should build on the current strengths but address potential gaps. Maybe emphasize dynamic adaptation instead of fixed ratios. Also, ensuring that even if factors aren't perfectly independent, there's a way to combine them without forcing multiplication. Testing heuristic robustness under varying conditions could be another point. And while metaphors are good, grounding them in empirical validation would make them more reliable.\n\nAvoiding things like static ratios, over-reliance on independence assumptions, neglecting empirical checks, and forcing metaphors that don't fit. The explanation should tie these together, showing how the new advice leads to more adaptable and robust heuristics without the pitfalls of the old approach.\n</think>\n\n**Keywords**: Dynamic adaptation, empirical validation, dimensional synergy, constraint robustness  \n**Advice**: 1) Replace fixed ratios with *adaptive thresholds* that evolve with problem scale 2) Test heuristics under *extreme precision edge cases* (e.g., near-zero values) 3) Quantify independence between factors before choosing combination operators 4) Use metaphors only when they enable *actionable geometric intuition*.  \n**Avoid**: Static \"golden ratios\", blind multiplicative blending, assuming dimension independence without proof, poetic analogies without operational mappings.  \n**Explanation**: Enhances adaptability through responsive thresholds while maintaining rigor via stress-testing and explicit dependency analysis. Metaphors become tools rather than dogma when tied to verifiable spatial reasoning.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}