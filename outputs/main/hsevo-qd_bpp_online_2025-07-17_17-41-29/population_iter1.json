[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Feasibility: Give -inf priority if item doesn't fit\n    infeasible_mask = item > bins_remain_cap\n    priorities[infeasible_mask] = -np.inf\n    \n    # 2. Best Fit: Prioritize bins where the remaining space after placing the item is small.\n    feasible_mask = ~infeasible_mask\n    remaining_space = bins_remain_cap[feasible_mask] - item\n    priorities[feasible_mask] = -remaining_space # Smaller remaining space -> higher priority\n\n    # 3. Avoidance of very small spaces: Penalize bins leaving very small spaces, but only if other bins are more reasonable fits\n    small_space_threshold = 0.1 # Tuneable parameter: Avoid leaving spaces smaller than 10% of bin capacity\n    very_small_space_mask = (remaining_space > 0) & (remaining_space < small_space_threshold) & (np.sum(bins_remain_cap[feasible_mask] -item >small_space_threshold) > 0)\n    if np.any(very_small_space_mask): #reduce the priorities by a tiny amount only when you know more fits are feasible\n      priorities[feasible_mask][very_small_space_mask] -=0.01\n    # 4. Utilize Almost Full Bins: Reward bins that are almost full, encouraging complete filling of existing bins\n\n    almost_full_threshold = 0.9  # Define what constitutes an \"almost full\" bin after placing the item\n    almost_full_mask = (bins_remain_cap[feasible_mask] - item) / bins_remain_cap[feasible_mask] < (1- almost_full_threshold) \n    priorities[feasible_mask][almost_full_mask]+=0.02\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function introduces a nuanced approach considering several factors:\n    1.  The space utilization efficiency if the item were placed in a bin.  It favors bins where the item fills a large portion of the remaining capacity, maximizing immediate space usage.\n    2.  A penalty for near-full bins, avoiding leaving tiny, unusable spaces behind.  This promotes long-term space efficiency.  A 'near_full_threshold' defines how close to full a bin must be to incur this penalty.\n    3.  A very small bonus to bins that exactly fit the item.  This can prevent fragmentation of available space when a perfect fit exists.\n    4. A strong penalty for bins that cannot contain the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    near_full_threshold = 0.95  # Define \"near full\" - e.g., 95% capacity used\n\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if item > remaining_cap:\n            priorities[i] = -np.inf  # Cannot fit, lowest priority\n\n        elif item == remaining_cap:\n            priorities[i] = 10 # perfect fit bonus\n        else:\n\n            utilization_ratio = item / remaining_cap\n            priorities[i] = utilization_ratio  # Primary driver:  efficiency\n\n            # Apply near-full penalty.\n            if remaining_cap > 0 and (remaining_cap - item) / remaining_cap < (1-near_full_threshold): # Equivalent to (remaining_cap - item) < (1 - near_full_threshold) * remaining_cap.\n                priorities[i] -= 5 * (near_full_threshold - (1 - (remaining_cap - item) / remaining_cap)) #Subtract a penalty\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997390000044 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    A more nuanced approach, considering multiple factors inspired by physics:\n\n    1.  Inverse Capacity Gap: Prioritizes bins where the item fits reasonably well.  Smaller gaps yield higher attraction.\n    2.  Bin Fill Percentage: Encourages filling bins that are already partially full. This relates to minimizing potential energy in the system.\n    3.  Penalty for Near Overfill: Applies a severe penalty to bins where adding the item would almost cause overflow. This is akin to a strong repulsive force near the edge.\n    4.  Handling Exact Fits: Provides the best score when item perfectly fits in the bin.\n    5.  Avoidance of Overfull Bins: Zero priority if the item does not fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            # Item doesn't fit: Zero priority (avoid overfilling)\n            priorities[i] = 0.0\n        elif cap == item:\n             # Item fits perfectly: highest priority\n            priorities[i] = 10.0 # arbitrary large number for perfection\n        else:\n            gap = cap - item\n            fill_percentage = 1 - (cap / (cap + item)) #percentage of original bin size that would be filled\n            priorities[i] = (1.0 / (gap + 0.001)) + (fill_percentage*2)\n\n            # Severe penalty if the item almost overfills the bin\n            if item > (cap * 0.9): #If the item utilizes more than 90% capacity of existing bin\n                 priorities[i] /=5\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997443000029 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Prioritize bins that can fit the item. If not possible, assign a low score.\n    can_fit = bins_remain_cap >= item\n    priorities[~can_fit] = -np.inf # Very low priority if cannot fit\n\n    # For bins that CAN fit, prioritize based on how FULL they will be.  Aim for density.\n    remaining_after_fit = bins_remain_cap[can_fit] - item\n    fill_ratios = (bins_remain_cap[can_fit] - remaining_after_fit) / bins_remain_cap[can_fit]\n\n    # Slightly penalize nearly full bins (risk of small items not fitting later) using a log-like transform\n    # Only impact when close to full, and not if almost empty.\n    # Scale fill_ratios so max fill_ratio maps to -1 * some small scaling\n    overfill_penalty_scale = 0.1\n\n    priorities[can_fit] = fill_ratios - overfill_penalty_scale * np.exp(10*(fill_ratios-0.95))  # Add penalty that only gets large when very full\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.547267650578394,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can accommodate the item with minimal wasted space,\n    while also considering bins that are already relatively full to encourage consolidation.\n    Bins that are too small receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, invalidate bins that are too small.  Avoid div-by-zero.\n    invalid_mask = bins_remain_cap < item\n    priorities[invalid_mask] = -np.inf  #Very low priority\n    \n    # Calculate wasted space if the item were added to each valid bin\n    wasted_space = bins_remain_cap - item\n    wasted_space[invalid_mask] = np.inf # Ensure these are never chosen\n\n    # Give higher priority to bins with less wasted space (more efficient packing).  Small values map to high priorities\n    priorities[~invalid_mask] += -np.abs(wasted_space[~invalid_mask])\n\n    # Give higher priority to bins that are already relatively full, to encourage consolidation.\n    # This is a \"fill-up\" strategy.\n    fill_ratio = (bins_remain_cap - wasted_space) / bins_remain_cap\n    fill_ratio[invalid_mask] = 0.  # No ratio for bins that can't fit\n    priorities[~invalid_mask] += fill_ratio[~invalid_mask] * 10 # Scale fill ratio to weigh more\n\n    #Add an additional heuristic that favors bins that are almost full (but can accomodate the item)\n    almost_full_bonus = np.where((bins_remain_cap >= item) & (bins_remain_cap < (item * 1.1)), 5, 0)\n    priorities += almost_full_bonus\n\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can accommodate the item with minimal waste\n    but also avoids overly tight fits to leave room for future items. We incorporate\n    a 'sweet spot' for remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            # Calculate the remaining space after adding the item\n            remaining_space = capacity - item\n\n            # Define a \"sweet spot\" as a fraction of the bin size, avoid being too close to 0\n            sweet_spot_lower = 0.1  # Avoid filling bins too tightly initially.\n            sweet_spot_upper = 0.5\n\n            # Normalize by remaining capacity if possible. If not, leave priorities alone.\n            normalized_remaining = remaining_space / capacity\n\n            if sweet_spot_lower <= normalized_remaining <= sweet_spot_upper:\n                # Prioritize bins with remaining capacity in the sweet spot\n                priorities[i] = 1 + (sweet_spot_upper - normalized_remaining)  # Higher priority the closer we are to the lower end of the sweet spot\n\n            else:\n                #If bins not in sweet spot, then prioritize bins with more space if item is smaller than average capacity or prioritize bins with less space if item is larger than average capacity to better balance filling bins.\n                average_capacity = np.mean(bins_remain_cap)\n                if item < average_capacity:\n                  priorities[i] = 0.5 - abs(normalized_remaining - sweet_spot_lower) if normalized_remaining < sweet_spot_lower else 0.5 - abs(normalized_remaining - sweet_spot_upper) if normalized_remaining > sweet_spot_upper else 0\n                else:\n                  priorities[i] = 0.5 + (sweet_spot_upper - normalized_remaining) if normalized_remaining < sweet_spot_upper else 0\n        else:\n            priorities[i] = -1  # Assign a low priority to bins that can't fit the item\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999973740000314 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Find bins where the item fits\n    fits = bins_remain_cap >= item\n\n    if np.any(fits):\n        # Prioritize bins where the item fits closest to filling the bin completely.\n        # Avoid creating tiny residual space, because small residuals are useless.\n        residual_space = bins_remain_cap - item\n        priorities[fits] = 1.0 / (residual_space[fits] + 1e-9)  # Avoid division by zero\n\n        # Apply sigmoid to boost priorities for almost-full bins\n        almost_full_mask = (residual_space > 0) & (residual_space < 0.1)  # Tolerance for almost full, tweak this parameter.\n        if np.any(almost_full_mask): # Avoid evaluating when there is no relevant entry.\n            priorities[almost_full_mask] += 1.0 / (residual_space[almost_full_mask] + 1e-9)\n\n\n    else:\n        # If item doesn't fit in any bins, heavily penalize assigning it\n        # This encourages new bins over overfilling.\n        priorities = -1e9 * np.ones_like(bins_remain_cap)\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing heuristics inspired by physical systems:\n\n    1.  A \"force\" inversely proportional to the 'distance' (capacity difference).\n    2.  Penalize bins that would have very little space left after packing (waste).\n    3.  A 'temperature' parameter to control exploration vs. exploitation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    temperature = 1.0  # Adjust for exploration/exploitation. Higher -> more exploration.\n    epsilon = 1e-6  # Avoid division by zero\n\n    # 1. \"Force\" component: Higher priority for bins with closer capacity\n    capacity_diff = np.abs(bins_remain_cap - item) + epsilon\n    force = 1.0 / capacity_diff\n\n    # 2. Waste penalization: Penalize bins leading to small remaining capacity.\n    remaining_after = bins_remain_cap - item\n    waste_penalty = np.exp(-10 * np.maximum(0, remaining_after))  # Exponential penalty\n\n    #3. Favor bins that can accommodate the item\n    can_accommodate = (bins_remain_cap >= item).astype(float)\n\n    #Combine\n    priorities = can_accommodate * force * waste_penalty\n\n    # \"Boltzmann distribution\" to modulate probabilities based on temperature\n    priorities = np.exp(priorities / temperature)\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.078579976067022,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a very low value\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    # Find bins that can accommodate the item\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Calculate remaining capacity after adding the item for valid bins\n        remaining_capacity = bins_remain_cap[valid_bins] - item\n\n        # Prioritize bins that leave the smallest remaining capacity\n        # to fully utilize the bins and minimize fragmentation.\n        priorities[valid_bins] = -remaining_capacity\n\n        # Boost the priority of bins that fit the item perfectly.  This encourages full utilization.\n        perfect_fit = remaining_capacity == 0\n        priorities[valid_bins][perfect_fit] = np.inf\n\n        # Introduce a small bias favoring bins that are already somewhat full (lower remaining capacity).\n        # This helps in avoiding the creation of too many almost-empty bins. This is done on valid_bins, after perfect_fit\n        # is handled\n        priorities[valid_bins] += (1 / bins_remain_cap[valid_bins])\n\n    # If no bin can accommodate the item, assign a very low priority.  This essentially means creating a new bin.\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a small value to avoid division by zero\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Iterate over each bin and calculate its priority\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # First Fit Decreasing (FFD) inspired heuristic: favor bins where the item fits best\n            # Minimize wasted space:\n            wasted_space = cap - item\n            priorities[i] = 1.0 / (wasted_space + 0.0001)  # Avoid division by zero and encourage tighter fits. Higher priority to bins with smallest waste\n            # Alternately could prioritize almost-full bins.\n            # Example: priorities[i] = cap / (wasted_space + 0.0001) # Favors bins closest to being full\n\n            # Could also incorporate a 'lookahead' - see if this bin placement will make future placements easier/harder\n            # (difficult to do online, since future items unknown, but a weighting based on item_size could help)\n        else:\n            # Item doesn't fit; very low priority\n            priorities[i] = -1000  # Or -np.inf, to ensure these bins are never selected.\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            priorities[i] = (cap - item) / (cap + item)  # Favor bins where item fits well, relative to bin size\n            priorities[i] += 1 / (1 + np.exp(-10*(cap-item))) # Sigmoid to favor nearly full bins\n        else:\n            priorities[i] = -1e9  # Very low priority if item doesn't fit\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997430000076 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version considers both the remaining capacity and a preference for\n    bins that are already somewhat filled, but avoids near-full bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            # Reward bins with capacity larger than the item\n            priority = (cap - item)  # Smaller diff gives higher priority\n            # Scale this with a factor related to current fill-level.\n            # Favour bins that have some capacity used already, but not too much\n            fill_level = 1 - (cap / 1.0)  # Assuming bin size of 1.0\n\n            # Apply a bell curve centered around 0.5 fill level.\n\n            bell_factor = np.exp(-((fill_level - 0.5)**2) / (2 * 0.2**2))  # Standard Deviation of 0.2 to avoid extremes\n\n            priority *= bell_factor # Weight based on the fill level\n            priorities[i] = priority\n        else:\n            priorities[i] = -np.inf # Heavily penalize bins that are too small\n\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997665000046 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the laws of gravity and potential energy:\n    A smaller difference between item size and remaining capacity yields higher attraction (priority).\n    Empty bins are strongly discouraged.\n    Also introduces a component akin to simulated annealing:\n    Acceptance probability influenced by a 'temperature' that decreases with filled bins\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero by adding a tiny epsilon\n    epsilon = 1e-9\n    \n    # Remaining capacity after potentially placing the item\n    potential_remaining_cap = bins_remain_cap - item\n    \n    # Calculate 'gravitational potential' - smaller remaining cap is 'lower'\n    potential = -potential_remaining_cap  # Negative, higher value is preferred\n\n    # Penalize bins that become too full\n    overfill_penalty = np.where(potential_remaining_cap < 0, -np.inf, 0)  # Large negative if item doesn't fit\n\n    # Encourage filling empty bins if the item fills it sufficiently. If after filling there will be some capacity left, do nothing.\n    nearly_full_bonus = np.where((bins_remain_cap > 0) & (potential_remaining_cap > 0) & (potential_remaining_cap < 0.1), 1 / (potential_remaining_cap + epsilon), 0)\n\n    # Penalize use of almost empty bins.\n    almost_empty_penalty = np.where(bins_remain_cap >=0.95, -10, 0)\n\n    # Combine effects - potential energy + overfill penalty + almost empty penalty+ nearly_full_bonus\n    priorities = potential + overfill_penalty + nearly_full_bonus + almost_empty_penalty\n    \n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Employs a heuristic that favors bins that can accommodate the item\n       with minimal remaining capacity, but also penalizes near-full bins\n       to encourage even distribution. Avoids divisions by zero.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Only consider bins that can fit the item. Give them a small initial priority boost.\n    eligible_bins = bins_remain_cap >= item\n    priorities[eligible_bins] += 0.1\n\n    #Calculate the wasted space if the item is placed in a given bin. Smaller waste is better.\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = np.inf  # Ensure only bins that fit are considered\n\n    #Prioritize bins with minimal waste, using the inverse of the waste as a priority component.  Add a small constant to waste to avoid division by zero.\n    priorities[eligible_bins] += 1.0 / (wasted_space[eligible_bins] + 0.01)\n\n    # Penalize bins that are too full (leaving little capacity).\n    # This avoids packing one or two bins very tightly while others remain empty.\n    remaining_capacity_ratio = bins_remain_cap / np.max(bins_remain_cap) # Scale it so we can compare different remaining bin sizes\n\n    priorities -= (1 - remaining_capacity_ratio) * 0.5 # Decrease priority for close to full.\n\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 81.48185081771044,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Utilizes a combination of remaining capacity, item size relative to bin size,\n    and a slight preference for bins that are already partially filled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Calculate the remaining space after placing the item\n            remaining_space = cap - item\n\n            # Prioritize bins with smallest remaining space but penalize almost full.\n            space_priority = np.exp(-remaining_space)\n\n            # Ratio of item size to bin capacity (higher is better but needs scaling)\n            item_ratio = item / cap\n            item_priority = item_ratio #Linear scaling already helps.\n            # Add a small bonus for bins that are already partially filled (to encourage filling).\n            #The higher `bonus_scale`, the more likely almost full bins will be used.\n            #The higher `exponent`, the quicker bins will fill up because preference to partially full bins increases faster.\n            #Choosing parameters below (1,1) leads to less waste\n            bonus_scale = 1 #1, 10. 100 were tested\n            exponent = 1 # 1, 2, 0.5 were tested\n\n            if cap < 1:\n                fill_level = 1 - cap\n            else:\n                 fill_level = 1 - (cap/np.max(bins_remain_cap)) #Cap relative to max\n\n            fill_priority = bonus_scale * (fill_level**exponent) #Prefer bins already partially filled\n\n\n            priorities[i] = space_priority + item_priority + fill_priority\n        else:\n            priorities[i] = -np.inf  # Disqualify bins that are too small\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999714100004 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function considers several factors to determine bin priority:\n    1. Remaining capacity: Bins with capacity closer to the item size are preferred.\n    2. Item size relative to bin size: A bin is preferred if the item fills a significant portion of its capacity.\n    3. Avoidance of near-full bins after placement: Placing into near-full bins leads to fragmentation; less desirable.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Capacity Factor: Give preference to bins closer to the item's size\n            capacity_factor = 1 / abs(cap - item + 0.00001)  # Avoid division by zero\n\n            # Fill Ratio Factor: Favor bins where item fills significant portion of bin\n            fill_ratio = item / cap\n            fill_ratio_factor = fill_ratio\n\n            # Fragmentation Penalty: Discourage near-full bin after placement\n            remaining_after = cap - item\n            if remaining_after < 0.1: # If not enough room for small items, avoid\n                fragmentation_penalty = -10 # A high negative penalty\n\n            elif remaining_after < 0.25 :\n                fragmentation_penalty = -5  # Moderate negative penalty\n            else:\n                fragmentation_penalty = 0 # No penalty if adequate room remaining\n\n            priorities[i] = capacity_factor + fill_ratio_factor + fragmentation_penalty\n\n        else:\n            priorities[i] = -np.inf  # Item doesn't fit, lowest priority\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Prioritizes bins that can accommodate the item with minimal waste,\n    but also avoids filling bins completely to allow for flexibility with\n    future, potentially smaller, items. Uses a sigmoid function to\n    balance waste minimization and future packing potential.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Option 1: Penalize bins that are too small\n    infeasible = bins_remain_cap < item\n    priorities[infeasible] = -np.inf  # Significantly disincentivize\n\n    #Option 2: Waste minimization (bins that fit the item with less waste gets higher priority)\n    waste = bins_remain_cap - item\n    #Avoid bins that would be filled to the brim. Encourage some flexibility for future smaller items.\n    #Use a sigmoid function to model this preference.\n    sigmoid = 1 / (1 + np.exp(-10 * (waste - 0.1))) #waste of 0.1 gets a score of ~0.5, smaller waste -> closer to 1, larger waste -> closer to 0\n    priorities[~infeasible] = sigmoid[~infeasible] # only calculate for feasible bins\n\n    # Option 3: Consider number of items already present in bin\n    # This could potentially avoid spreading single items across multiple bins,\n    # although requires additional information regarding the already present items in bins which may or may not be easy.\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 8.944954128440372,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version introduces a more nuanced priority scheme that considers:\n    1.  How well the item fits (closer to filling the bin is better, but avoid overflow).\n    2.  A \"desperation\" factor if many bins are already close to full.\n    3. A randomized kick to break ties and explore the solution space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    n_bins = len(bins_remain_cap)\n\n    for i in range(n_bins):\n        remaining_cap = bins_remain_cap[i]\n\n        if item <= remaining_cap:\n            # Fit Score: Higher if the item fills the bin more completely\n            fit_score = (item / remaining_cap)**0.5  # Squaring to emphasize close fits, less punishing near-misses\n\n            # Desperation Score: Penalize bins that are very empty if others are close to full.\n            desperation_factor = np.sum(bins_remain_cap < (1.1 * item)) / n_bins # Slightly more forgiving overflow allowed here\n\n            priorities[i] = fit_score + 0.1*desperation_factor  # Small impact from desperation\n\n    # Avoid selecting bins that have insufficient capacity. Give extremely low priority if the item won't fit.\n    priorities[bins_remain_cap < item] = -1e9\n\n    # Randomized tie-breaking to explore search space and prevent stagnation\n    priorities += np.random.rand(n_bins) * 0.01 # Introduce small random variation\n\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997086999974 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(valid_bins):\n        # If no bin can accommodate the item, prioritize bins with largest remaining capacity.\n        priorities = bins_remain_cap #prioritize largest available.\n    else:\n        # Prioritize bins where the item fits reasonably well, avoiding both near-empty and almost-full bins\n        # Calculate fill ratio: item size / remaining capacity\n        fill_ratios = item / bins_remain_cap\n        fill_ratios[~valid_bins] = np.inf  # set fill ratio of invalid bins to inf\n\n        # Prioritize bins with fill ratios closest to a target (e.g., 0.75, aim for filling about 3/4 of the bin)\n        target_fill_ratio = 0.75\n        priority_valid = np.exp(-np.abs(fill_ratios - target_fill_ratio)) #Gaussian like behavior\n\n        priorities[valid_bins] = priority_valid[valid_bins]\n\n\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 7.947746310331078,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # First-Fit Decreasing heuristic inspiration: prioritize bins that can fit the item reasonably well,\n    # but penalize bins that are left with very little space after packing.\n    \n    # 1. Filter out bins that can't fit the item.\n    fit_indices = bins_remain_cap >= item\n    \n    if not np.any(fit_indices):\n        # If no bin can fit the item, return a very low priority for all bins. This effectively signals\n        # that a new bin must be opened.  Return minimum float value to allow comparisons later.\n        return np.full_like(bins_remain_cap, np.finfo(float).min)\n        \n\n    # 2. Calculate the remaining capacity after placing the item in each eligible bin.\n    remaining_capacity = bins_remain_cap - item\n    remaining_capacity[~fit_indices] = -1  # Set remaining capacity to -1 for bins that can't fit.\n\n    # 3. Prioritize based on remaining capacity. Bins with smaller remaining capacity should get higher priority\n    # since we want to fill them as much as possible. The priority is scaled by the original remaining\n    # to prioritize bins with smaller cap and able to fit item.\n    \n    priorities[fit_indices] = bins_remain_cap[fit_indices] / (0.00001 + remaining_capacity[fit_indices])\n    # 4. Add a small constant to remaining capacity to avoid division by zero.\n\n\n    # 5. Return the priorities. Note bins that cannot fit the item have priority=0\n\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate waste if the item is placed in the bin\n    waste = bins_remain_cap - item\n\n    # Give high priority to bins where the item fits and waste is minimized\n    for i, w in enumerate(waste):\n        if w >= 0:\n            priorities[i] = 1 / (w + 0.00001)  # Adding a small constant to avoid division by zero\n\n    # Penalize bins where the item doesn't fit heavily\n    priorities[bins_remain_cap < item] = -1000  # or some other large negative number\n\n    #Boost the bins which has higher capacity closer to item size\n    cap_diff = np.abs(bins_remain_cap-item)\n    priorities = priorities - cap_diff/ np.max(bins_remain_cap)\n\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a base value (e.g., 0).\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    feasible_bins = bins_remain_cap >= item\n\n    # Give significantly higher priority to bins that can fit the item.  The smaller the remaining space after packing, the higher the priority\n    remaining_space = bins_remain_cap[feasible_bins] - item\n    priorities[feasible_bins] = 1.0 / (1e-9 + remaining_space)  # Avoid division by zero\n\n    # Penalize bins that cannot accommodate the item, making them less attractive.\n    priorities[~feasible_bins] = -np.inf\n\n    # Further refine the priority based on remaining capacity. Larger remaining cap after placing this item is preferable (up to a limit).\n    # Small penalty for unused capacity up to 50% of item size, but rapidly decreasing value if capacity > item*0.5\n    large_capacity = bins_remain_cap[feasible_bins] > item\n    remaining_over_cap = bins_remain_cap[feasible_bins][large_capacity] - item\n    priorities[feasible_bins][large_capacity] -= np.clip(remaining_over_cap**2, 0, (item * 0.5)**2) # Quadratic penalty\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that have enough space to accommodate the item,\n    favoring bins with smaller remaining capacity after the item is placed.\n    Bins that cannot fit the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    fit_indices = bins_remain_cap >= item\n\n    if np.any(fit_indices):\n        # Calculate remaining capacity after placing the item (only for fitting bins)\n        remaining_capacity = bins_remain_cap[fit_indices] - item\n\n        # Prioritize bins with smaller remaining capacity after placement\n        # Use a negative exponential to amplify the difference. A smaller remaining capacity becomes a bigger (less negative) number, therefore higher priority.\n        #A smaller value of scale, e.g. 0.2, would amplify the sensitivity to small remaining capacities (high reward for tightly packing), while larger ones decrease sensitivity and smooth scores.\n        scale = np.mean(bins_remain_cap) if np.mean(bins_remain_cap) > 0 else 1 #Dynamically adjust scale, if all the bins are empty, the scale would be 1, avoiding a division by 0\n        priorities[fit_indices] = np.exp(-remaining_capacity / scale)\n\n    # Non-fitting bins get a very low priority (close to zero, but not exactly zero to avoid potential division by zero errors downstream)\n    #priorities[~fit_indices] = 1e-9  #Assign very low priorites instead of zero, which prevent potential ZeroDivisionErrors in later calculations.\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # First, prioritize bins that can actually fit the item.\n    fit_indices = np.where(bins_remain_cap >= item)[0]\n    \n    if len(fit_indices) > 0:\n        # Among the bins that can fit, prioritize those with the smallest remaining capacity\n        # after placing the item (i.e., minimize wasted space). This is a \"best fit\" approach.\n        remaining_capacities_after_fit = bins_remain_cap[fit_indices] - item\n        priorities[fit_indices] = 1 / (remaining_capacities_after_fit + 0.00001) # Adding a small constant to avoid division by zero\n\n        # Alternatively, prioritize bins where item size is closest to half of bin capacity\n        # optimal_fill_diffs = np.abs((bins_remain_cap[fit_indices]/2) - item)\n        # priorities[fit_indices] = 1 / (optimal_fill_diffs + 0.00001)\n\n    else:\n        #If it doesnt fit, use lowest remaining\n        priorities = 1 / (bins_remain_cap + 0.00001)\n    \n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Considers both remaining capacity and fragmentation. A higher\n    score indicates a higher priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Prioritize bins that can fit the item.\n            remaining = cap - item\n            # Prioritize bins with less remaining space (better fit), but also consider\n            # if the remaining space is useful for other items (fragmentation).\n            # We use a combined score.\n            priorities[i] = (1 / (remaining + 1e-9)) + (remaining > item/2) # 1e-9 to avoid division by zero\n        else:\n            # Bin cannot fit the item, give it a negative (low) priority.\n            priorities[i] = -np.inf\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 5.12564818508178,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the celestial dance, we favor bins that are 'near' the item's size\n    but also consider the overall 'harmony' by looking at how full the bin would be.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Distance from the item's size, but relative to remaining capacity to account for bin size differences\n            distance_penalty = np.abs(cap - item) / (item + 1e-9) #Avoid division by zero. Add small constant to prevent infinities\n\n            # Harmony term: favors bins that, when filled, wouldn't be too full or too empty\n            future_capacity = cap - item\n            harmony_factor = 1.0 - np.abs(future_capacity - (np.sum(bins_remain_cap) - cap)) / (np.sum(bins_remain_cap)+1e-9)  # Bin near average future cap\n            #Prioritize the bins based on factors inspired by the music of the spheres.\n            priorities[i] = (1.0 - distance_penalty) + 0.5*harmony_factor\n\n            #Prioritize better fit to empty bins better. Helps with spreading the bin capacity usage.\n            if cap > 0:\n                 priorities[i] *= (cap / np.sum(bins_remain_cap) +1e-9)\n\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99995241099987 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a combination of factors to determine priority:\n    - How full the bin would be after adding the item.  Favors near-full bins, avoiding fragmentation.\n    - Whether the item fits at all.  Assigns very low priority if it doesn't fit.\n    - A small bias towards bins that are already somewhat full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = item <= bins_remain_cap\n\n    # Assign very low priority to bins where the item doesn't fit.  A large negative number.\n    priorities[~fits] = -1e9\n\n    # Calculate fill ratios if the item were added\n    hypothetical_remaining = bins_remain_cap - item\n    hypothetical_fill_ratio = 1 - (hypothetical_remaining / np.max(bins_remain_cap)) # Use max bin cap to normalise\n    hypothetical_fill_ratio[~fits] = 0  # Ensure zero when the item does not fit.\n\n    # Give preference to bins that would become nearly full\n    priorities[fits] = hypothetical_fill_ratio[fits] ** 2  # Make the higher ratios more significant\n    \n    #A slight adjustment to improve the chance that the bin fits tightly\n    space_left = bins_remain_cap - item\n    close_fits = (space_left >= 0) & (space_left < 0.1) #Prioritise fits where we leave a space under 0.1\n    priorities[close_fits] += 1 #Significant Boost\n\n    # Slightly penalize bins that would become almost empty\n    nearly_empty = (hypothetical_remaining > 0) & (hypothetical_remaining < 0.1)  # if remaining under 0.1 then penalise\n    priorities[nearly_empty] -= 0.05\n\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates a 'fitability' score and randomness\n    inspired by quantum probabilities.  We also include a preference\n    for bins that are nearly full *after* the item is placed, mimicking\n    a 'least waste' approach, and a penalty for exceeding bin capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Fitability Score: How well the item fits (lower is better, but small)\n    fitability = np.abs(bins_remain_cap - item)\n\n    # Remaining Capacity Ratio:  Smaller ratio means almost full bin.\n    remaining_ratio = np.clip((bins_remain_cap - item) / np.mean(bins_remain_cap), a_min=0.0, a_max=1.0)  #prevent negative and scaling issues\n    # Preference for bins that are nearly full AFTER placement. Logarithm amplifies the preference for nearly empty space after placement\n    nearly_full_priority = -np.log(remaining_ratio + 0.001)  # Avoid log(0)\n\n    # Penalty for exceeding capacity\n    overfill_penalty = np.where(item > bins_remain_cap, -1e9, 0) # Large negative penalty\n\n    # \"Quantum\" Randomness: add tiny random variations\n    randomness = np.random.rand(len(bins_remain_cap)) * 0.01\n\n    # Combining Scores: weighted sum\n    priorities = (\n        -fitability * 0.5\n        + nearly_full_priority * 1.0\n        + overfill_penalty\n        + randomness\n    )\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate remaining capacity after adding the item to each bin.\n    remaining_after_add = bins_remain_cap - item\n\n    # Identify bins that can accommodate the item.\n    valid_bins = remaining_after_add >= 0\n\n    # Initialize priority scores with a low value for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Calculate priority for valid bins based on remaining capacity.\n    # Smaller remaining capacity means a tighter fit, which is preferred (higher priority).\n    # Adding a small constant to avoid division by zero.\n    priorities[valid_bins] = 1 / (remaining_after_add[valid_bins] + 1e-9)\n\n    # Alternatively, prioritize bins based on the fill ratio after adding the item:\n    # fill_ratio = (bins_remain_cap[valid_bins] - remaining_after_add[valid_bins]) / bins_remain_cap[valid_bins]\n    # priorities[valid_bins] = fill_ratio\n\n    # A heuristic that balances utilization and fragmentation:\n    # If remaining capacity is less than item/2 after placing item into bin then give highest priority.\n    near_full = remaining_after_add[valid_bins] < item / 2\n    priorities[valid_bins][near_full] = np.max(priorities) + 1 if np.any(priorities != -np.inf) else 1\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a small default value to avoid division by zero and negative infinity issues.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - 1e9 # Large negative value makes them very low priority by default.\n    \n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n    \n    # Prioritize bins with tighter fits (minimize wasted space). Use a softmax approach for this.\n    # The idea is to assign higher priority to bins whose remaining capacity after placement will be small.\n    remaining_space = bins_remain_cap - item\n    remaining_space[~fit_mask] = np.inf # Make invalid spaces effectively infinitely large for softmax calculation\n\n    # Apply softmax after subtracting the minimum from remaining_space, which adds stability\n    remaining_space_shifted = remaining_space - np.min(remaining_space[fit_mask]) if np.any(fit_mask) else remaining_space\n    priorities[fit_mask] = np.exp(-remaining_space_shifted[fit_mask]) / np.sum(np.exp(-remaining_space_shifted[fit_mask])) if np.any(fit_mask) else 0.\n\n    # Boost the priority of bins that are nearly full to try and complete them, provided the item fits\n    nearly_full_threshold = 0.1  # e.g., Bin is considered nearly full if remaining capacity is less than 10% of item size\n    nearly_full_bins = (bins_remain_cap <= item * (1 + nearly_full_threshold)) & fit_mask\n\n    priorities[nearly_full_bins] += 1.0  # Add a boost to priority of nearly full bins\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "mi": 76.12344793300358,
    "token_count": 176.0,
    "exec_success": true
  }
]