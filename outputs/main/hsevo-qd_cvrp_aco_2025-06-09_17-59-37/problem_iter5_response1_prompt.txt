{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Enhanced heuristics combining distance, demand, location, and depot proximity.\n    Sparsifies matrix adaptively.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # Distance: Shorter distances are preferred.\n    distance_factor = 1 / (distance_matrix + 1e-6)\n    heuristic_matrix = distance_factor.copy()\n\n    # Demand: Penalize edges connecting to high-demand nodes, with non-linear scaling.\n    demand_penalty = np.ones((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            combined_demand = demands[i] + demands[j]\n            if combined_demand > capacity:\n                demand_penalty[i, j] = 0.01  # Very strong penalty for exceeding capacity\n            else:\n                demand_penalty[i, j] = max(0.1, 1 - (combined_demand / capacity)**0.5) #Nonlinear scaling\n    heuristic_matrix *= demand_penalty\n\n    # Location: Encourage edges between spatially close nodes, but less aggressively than before.\n    spatial_proximity = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            if i != j:\n                delta_x = coordinates[i, 0] - coordinates[j, 0]\n                delta_y = coordinates[i, 1] - coordinates[j, 1]\n                spatial_proximity[i, j] = 1 / (np.sqrt(delta_x**2 + delta_y**2) + 1e-6)\n    heuristic_matrix *= (0.5 * spatial_proximity + 0.5)  # Dampen the effect\n\n    # Depot Connections: Strongly promote connections to and from the depot, with distance decay.\n    depot_boost = np.ones((n, n))\n    for i in range(1, n):\n        depot_boost[0, i] = 1 + (1 / (distance_matrix[0, i] + 1e-6)) #Proximity aware\n        depot_boost[i, 0] = 1 + (1 / (distance_matrix[i, 0] + 1e-6)) #Proximity aware\n    heuristic_matrix *= depot_boost\n\n    # Connectivity Prior: Favor connections to nodes that are currently less connected\n    degree = np.sum(heuristic_matrix > 0, axis=0) + np.sum(heuristic_matrix > 0, axis=1)\n    connectivity_boost = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            connectivity_boost[i, j] = (1 / (degree[i] + 1e-6)) + (1 / (degree[j] + 1e-6))\n    heuristic_matrix *= connectivity_boost\n    \n    # Adaptive Sparsification: Zero out edges based on a dynamic threshold per node\n    for i in range(n):\n        row = heuristic_matrix[i, :]\n        threshold = np.mean(row[row > 0]) * 0.3 #Dynamic threshold based on row average\n        heuristic_matrix[i, row < threshold] = 0\n        col = heuristic_matrix[:, i]\n        threshold = np.mean(col[col > 0]) * 0.3\n        heuristic_matrix[col < threshold, i] = 0\n\n    # Normalize\n    max_val = np.max(heuristic_matrix)\n    if max_val > 0:\n        heuristic_matrix = heuristic_matrix / max_val\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n    return 1 / distance_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (17th), we see the best heuristic incorporates distance, demand, location, depot proximity, and connectivity, with adaptive sparsification and normalization, while the worst only considers inverse distance. (2nd) vs (18th), (3rd) vs (19th), (4th) vs (20th) are similar to (1st) vs (17th). Comparing (1st) vs (2nd), we see no differences. (3rd) vs (4th), (5th) vs (6th) are similar to (1st) vs (2nd). Comparing (16th) vs (17th), we see the 16th uses distance, demand and location-based factors and boost depot connection, while the worst only considers inverse distance. Comparing (7th) vs (17th), we see the 7th combines distance, demand, location with a sparsification based on a dynamic threshold, while the worst only considers inverse distance. Comparing (7th) vs (8th), (9th) vs (10th), (11th) vs (12th), (13th) vs (14th), (15th) vs (16th), we see no differences. Comparing (second worst) vs (worst), we see no differences. Overall: The top heuristics are significantly more complex, incorporating multiple factors and adaptive techniques, while the worst relies solely on distance. The adaptive sparsification and connectivity prior appear to be distinguishing factors among the better heuristics. The enhanced heuristics (1st to 6th) also seem to normalize the matrix.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine \"Current Self-Reflection\" for designing better heuristics.\n\n*   **Keywords:** Multifactorial, Adaptive, Incremental, Evaluation, Normalization, Baselines.\n*   **Advice:** Start with a simple, robust baseline. Systematically integrate factors (distance, demand, location, etc.) using adaptive weighting and sparsification techniques. Rigorously evaluate each addition against the baseline.\n*   **Avoid:** Premature complexity. Avoid ad-hoc adjustments without performance measurement.\n*   **Explanation:** Incremental refinement grounded in empirical evaluation ensures informed heuristic design. Baselines provide a vital reference point for gauging improvement.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}