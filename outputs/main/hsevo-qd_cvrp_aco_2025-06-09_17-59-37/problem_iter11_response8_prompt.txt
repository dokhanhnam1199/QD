{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Enhanced heuristic combining distance, demand, location, depot proximity, connectivity and adaptive sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # Distance: Shorter distances are preferred.\n    distance_factor = 1 / (distance_matrix + 1e-6)\n    heuristic_matrix = distance_factor.copy()\n\n    # Demand: Penalize edges connecting to high-demand nodes.\n    demand_penalty = np.ones((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            combined_demand = demands[i] + demands[j]\n            if combined_demand > capacity:\n                demand_penalty[i, j] = 0.01\n            else:\n                demand_penalty[i, j] = max(0.1, 1 - (combined_demand / capacity)**0.5)\n\n    heuristic_matrix *= demand_penalty\n\n    # Location: Encourage edges between spatially close nodes.\n    spatial_proximity = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            if i != j:\n                delta_x = coordinates[i, 0] - coordinates[j, 0]\n                delta_y = coordinates[i, 1] - coordinates[j, 1]\n                spatial_proximity[i, j] = 1 / (np.sqrt(delta_x**2 + delta_y**2) + 1e-6)\n    heuristic_matrix *= (0.5 * spatial_proximity + 0.5)\n\n    # Depot Connections: Promote connections to and from the depot\n    depot_boost = np.ones((n, n))\n    for i in range(1, n):\n        depot_boost[0, i] = 1 + (1 / (distance_matrix[0, i] + 1e-6))\n        depot_boost[i, 0] = 1 + (1 / (distance_matrix[i, 0] + 1e-6))\n    heuristic_matrix *= depot_boost\n\n    # Connectivity Prior: Favor connections to nodes that are currently less connected\n    degree = np.sum(heuristic_matrix > 0, axis=0) + np.sum(heuristic_matrix > 0, axis=1)\n    connectivity_boost = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            connectivity_boost[i, j] = (1 / (degree[i] + 1e-6)) + (1 / (degree[j] + 1e-6))\n    heuristic_matrix *= connectivity_boost\n\n    # Adaptive Sparsification: Zero out edges based on a dynamic threshold per node\n    for i in range(n):\n        row = heuristic_matrix[i, :]\n        mean_val = np.mean(row[row > 0]) if np.any(row > 0) else 0\n        median_val = np.median(row[row > 0]) if np.any(row > 0) else 0\n        threshold = min(mean_val, median_val) * 0.3\n        heuristic_matrix[i, row < threshold] = 0\n\n        col = heuristic_matrix[:, i]\n        mean_val = np.mean(col[col > 0]) if np.any(col > 0) else 0\n        median_val = np.median(col[col > 0]) if np.any(col > 0) else 0\n        threshold = min(mean_val, median_val) * 0.3\n        heuristic_matrix[col < threshold, i] = 0\n        \n    # Depot Sparsification: Remove less promising direct connections to depot to diversify routes.\n    depot_threshold = np.mean(heuristic_matrix[0, 1:]) * 0.2\n    for i in range(1, n):\n        if heuristic_matrix[0, i] < depot_threshold:\n            heuristic_matrix[0, i] = 0\n        if heuristic_matrix[i, 0] < depot_threshold:\n            heuristic_matrix[i, 0] = 0\n\n    # Normalize\n    max_val = np.max(heuristic_matrix)\n    if max_val > 0:\n        heuristic_matrix = heuristic_matrix / max_val\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Enhanced heuristic combining distance, demand, location, depot proximity, connectivity and adaptive sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # Distance: Shorter distances are preferred.\n    distance_factor = 1 / (distance_matrix + 1e-6)\n    heuristic_matrix = distance_factor.copy()\n\n    # Demand: Penalize edges connecting to high-demand nodes.\n    demand_penalty = np.ones((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            combined_demand = demands[i] + demands[j]\n            if combined_demand > capacity:\n                demand_penalty[i, j] = 0.01\n            else:\n                demand_factor = combined_demand / capacity\n                demand_penalty[i, j] = max(0.1, 1 / (demand_factor + 1)) # Use inverse of demand factor\n\n    heuristic_matrix *= demand_penalty\n\n    # Location: Encourage edges between spatially close nodes.\n    spatial_proximity = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            if i != j:\n                delta_x = coordinates[i, 0] - coordinates[j, 0]\n                delta_y = coordinates[i, 1] - coordinates[j, 1]\n                spatial_proximity[i, j] = 1 / (np.sqrt(delta_x**2 + delta_y**2) + 1e-6)\n    heuristic_matrix *= spatial_proximity\n\n    # Depot Connections: Promote connections to and from the depot\n    depot_boost = np.ones((n, n))\n    for i in range(1, n):\n        depot_boost[0, i] = 1 + (1 / (distance_matrix[0, i] + 1e-6))\n        depot_boost[i, 0] = 1 + (1 / (distance_matrix[i, 0] + 1e-6))\n    heuristic_matrix *= depot_boost\n\n    # Connectivity Prior: Favor connections to nodes that are currently less connected\n    degree = np.sum(heuristic_matrix > 0, axis=0) + np.sum(heuristic_matrix > 0, axis=1)\n    connectivity_boost = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            connectivity_boost[i, j] = (1 / (degree[i] + 1e-6)) + (1 / (degree[j] + 1e-6))\n    heuristic_matrix *= connectivity_boost\n    \n    # Adaptive Sparsification: Zero out edges based on a dynamic threshold per node\n    for i in range(n):\n        row = heuristic_matrix[i, :]\n        threshold = np.mean(row[row > 0]) * 0.2 \n        heuristic_matrix[i, row < threshold] = 0\n        col = heuristic_matrix[:, i]\n        threshold = np.mean(col[col > 0]) * 0.2\n        heuristic_matrix[col < threshold, i] = 0\n\n    # Normalize\n    max_val = np.max(heuristic_matrix)\n    if max_val > 0:\n        heuristic_matrix = heuristic_matrix / max_val\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing heuristics 1st to 5th vs heuristics 15th to 20th, we see that the top performers incorporate several factors (distance, demand, location, depot proximity, connectivity, and adaptive sparsification), while the worst only consider distance. The better heuristics use more complex calculations and normalizations. The better heuristics use loops in the logic. Comparing 1st vs 2nd, we observe the removal of distant high demand edges. Comparing 6th vs 7th, and 11th vs 12th, there are no differences. Comparing 9th vs 10th, there are no differences. Comparing 13th vs 14th, 15th, 16th, 17th, 18th, and 19th, there are no differences. Comparing 1st and 6th, we see that the more aggressive sparsification is removed. Comparing 1st vs 9th, some changes related to demand penalty are noted. Overall: The best heuristics consider more factors and more sophisticated interactions between those factors. Sparsification seems useful to an extent.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine self-reflection for designing better heuristics, focusing on actionable improvements.\n\n*   **Keywords:** Iterative refinement, factor integration, adaptive strategies, impact evaluation, normalization.\n\n*   **Advice:** Systematically evaluate the impact of each added factor or adaptive component on heuristic performance. Track performance metrics rigorously.\n\n*   **Avoid:** Intuitive leaps without empirical validation; premature optimization without a solid baseline.\n\n*   **Explanation:** Focus on incremental improvements with data-driven decisions. Each change must be justified by its impact on solution quality. Normalize data to ensure fair comparison.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}