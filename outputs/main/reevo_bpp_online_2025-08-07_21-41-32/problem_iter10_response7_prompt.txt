{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    tolerance: float = 1e-12,\n    tie_breaker: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Deterministic tight\u2011fit priority for the online Bin Packing Problem.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array (or array\u2011like) of remaining capacities of the currently open bins.\n    tolerance : float, optional\n        Numerical tolerance for feasibility checks; a bin is feasible if its\n        remaining capacity is at least ``item - tolerance``.\n    tie_breaker : float, optional\n        Tiny positive value used to break ties deterministically in favour of\n        bins with smaller original indices.  Must be smaller than any meaningful\n        leftover value (e.g., ``tolerance``).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin. Higher scores indicate more attractive bins.\n        Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Ensure a 1\u2011D float array\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.size\n\n    # Feasibility mask: bins that can hold the item (within tolerance)\n    feasible = caps >= (item - tolerance)\n\n    # Initialise all priorities to -inf (infeasible by default)\n    priorities = np.full(n_bins, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin \u2013 return all -inf\n        return priorities\n\n    # Compute leftover capacity for feasible bins\n    leftover = caps[feasible] - item\n    # Clip tiny negative leftovers caused by floating\u2011point noise\n    leftover = np.maximum(leftover, 0.0)\n\n    # Original indices of feasible bins (preserve order)\n    idx_feas = np.nonzero(feasible)[0]\n\n    # Tight\u2011fit bias: smaller leftover \u2192 higher priority.\n    # Subtract a tiny index\u2011dependent term to break ties in favour of lower indices.\n    # The overall priority is negative leftover (so larger is better) minus tie_breaker*index.\n    priorities[feasible] = -leftover - idx_feas * tie_breaker\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Random Fit priority for online bin packing.\n\n    Each feasible bin (with enough remaining capacity) receives a random score.\n    Infeasible bins receive -inf so they are never selected. This implements a\n    pure random fit strategy, optionally biased toward tighter fits.\n\n    Args:\n        item: Size of the incoming item.\n        bins_remain_cap: 1\u2011D array of remaining capacities for each bin.\n\n    Returns:\n        A 1\u2011D array of priority scores, one per bin.\n    \"\"\"\n    # Ensure capacities are a float array.\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    feasible = caps >= item\n\n    # Initialise all priorities to -inf (so infeasible bins are never chosen).\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    # Generate independent random numbers for each bin.\n    rand_scores = np.random.rand(caps.size)\n\n    # Bias towards tighter fits: less slack -> larger bias.\n    # Small epsilon avoids division by zero for exact fits.\n    epsilon = 1e-12\n    slack = caps - item\n    bias = np.zeros_like(caps)\n    bias[feasible] = 1.0 / (slack[feasible] + epsilon)  # higher when slack is small\n\n    # Combine random component with bias.\n    # Multiplying emphasizes bins with higher bias while preserving randomness.\n    priorities[feasible] = bias[feasible] * rand_scores[feasible]\n\n    return priorities\n\n[Reflection]\nBias toward tight fits, add randomness for diversification, adapt bias by slack, use tiny tie\u2011breakers, fine\u2011tune epsilon.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}