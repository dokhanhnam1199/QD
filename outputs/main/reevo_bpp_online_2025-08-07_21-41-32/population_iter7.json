[
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\nfrom typing import Optional, Union\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    tolerance: float = 1e-12,\n    tie_breaker: float = 1e-12,\n    random_state: Optional[Union[int, np.random.Generator]] = None,\n) -> np.ndarray:\n    \"\"\"\n    Blend exact\u2011fit scoring with a random bias for online bin packing.\n\n    For each bin the function returns a priority score (higher = more attractive).\n    Infeasible bins receive ``-np.inf`` so they are never chosen.\n\n    The priority consists of three parts:\n      * Exact\u2011fit component: prefers bins with smaller remaining slack.\n      * Random bias component: 1/(slack+\u03b5) gives a larger random boost to tighter\n        fits, encouraging diversification when no near\u2011exact fit exists.\n      * Deterministic tie\u2011breaker: a tiny index\u2011dependent penalty ensures\n        reproducible ordering for otherwise equal scores.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacity for each currently open bin.\n    tolerance : float, optional\n        Numerical tolerance for feasibility checks and exact\u2011fit detection.\n    tie_breaker : float, optional\n        Tiny positive constant used to break ties deterministically\n        (lower\u2011indexed bins are slightly preferred).\n    random_state : int or np.random.Generator, optional\n        Seed or generator for reproducible randomness. If ``None`` the global\n        NumPy RNG is used.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores, one per bin (shape matches ``bins_remain_cap``).\n    \"\"\"\n    # Normalise input to a flat float array.\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.size\n\n    # Feasibility mask: bins that can accommodate the item (within tolerance).\n    feasible = caps >= (item - tolerance)\n\n    # Initialise priorities with -inf (infeasible bins).\n    priorities = np.full(n_bins, -np.inf, dtype=float)\n\n    # Early exit if nothing fits.\n    if not np.any(feasible):\n        return priorities\n\n    # Slack for feasible bins (non\u2011negative, with tiny negatives clipped).\n    slack = caps[feasible] - item\n    slack = np.maximum(slack, 0.0)\n\n    # Exact\u2011fit score: larger when slack is smaller (exact fit => 0).\n    exact_score = -slack\n\n    # Random bias: larger for tighter fits.\n    epsilon = tolerance\n    bias = 1.0 / (slack + epsilon)               # shape = (n_feasible,)\n    # Normalise bias to [0, 1] to keep the random term comparable across bins.\n    bias_norm = bias / bias.max()\n\n    # Random generator handling.\n    if isinstance(random_state, np.random.Generator):\n        rng = random_state\n    else:\n        rng = np.random.default_rng(random_state)\n\n    rand_vals = rng.random(n_bins)               # one random number per bin\n    rand_feasible = rand_vals[feasible]\n\n    random_component = bias_norm * rand_feasible  # in [0, 1]\n\n    # Adaptive weighting of the random part.\n    # If an (almost) exact fit exists, we reduce randomness to favour it.\n    if np.min(slack) <= tolerance:\n        w_random = 0.1   # favour exact fits\n    else:\n        w_random = 0.5 if False else 0.5  # balanced exploration\n\n    # Deterministic tie\u2011breaker (lower index slightly preferred).\n    idx_feasible = np.where(feasible)[0]\n    tie_term = idx_feasible.astype(float) * tie_breaker\n\n    # Combine the components.\n    combined = exact_score + w_random * random_component - tie_term\n\n    # Populate the result array.\n    priorities[feasible] = combined\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 35.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    low_percentile: float = 0.10,\n    boost_factor: float = 5.0,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Priority function for the online Bin Packing Problem (BPP).\n\n    For each existing bin the function returns a score; the bin with the highest\n    score is selected for the incoming ``item``.  The heuristic combines:\n\n    1. **Adaptive inverse\u2011slack bias** \u2013 bins that would have less remaining\n       capacity after placement receive a larger base score.\n    2. **Low\u2011percentile slack boost** \u2013 bins whose post\u2011placement slack falls\n       below a low percentile (default 10\u202f%) are boosted, encouraging the\n       algorithm to fill \u201calmost full\u2019\u2019 bins.\n    3. **Tiny random tie\u2011breaker** \u2013 a minute random perturbation to break ties\n       while preserving the deterministic bias.\n\n    Infeasible bins (those that cannot accommodate the item) receive ``-np.inf``,\n    guaranteeing they are never chosen.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n    low_percentile : float, optional\n        Percentile (0\u20111) used to define \u201calmost full\u2019\u2019 bins. Default is 0.10.\n    boost_factor : float, optional\n        Multiplier controlling the magnitude of the low\u2011percentile boost.\n        Default is 5.0.\n    random_state : int, optional\n        Seed for reproducible random tie\u2011breaking.\n\n    Returns\n    -------\n    np.ndarray\n        1\u2011D array of priority scores (higher is better). Infeasible bins are\n        marked with ``-np.inf``.\n    \"\"\"\n    # Convert to float array and handle empty input\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    if caps.size == 0:\n        return np.array([], dtype=float)\n\n    # Slack after hypothetically placing the item\n    slack = caps - item\n    feasible = slack >= 0\n\n    # Initialise all scores as -inf (infeasible)\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    # Early exit if no bin can accommodate the item\n    if not np.any(feasible):\n        return priorities\n\n    # ------------------------------------------------------------------\n    # 1) Adaptive epsilon and inverse\u2011slack bias\n    # ------------------------------------------------------------------\n    slack_feas = slack[feasible]\n    mean_slack = np.mean(slack_feas)\n    # Scale epsilon with typical slack magnitude to avoid division\u2011by\u2011zero\n    eps = max(1e-12, 1e-6 * mean_slack)\n    inv_slack = 1.0 / (slack_feas + eps)  # larger when slack is smaller\n\n    # ------------------------------------------------------------------\n    # 2) Low\u2011percentile slack boost\n    # ------------------------------------------------------------------\n    # Determine threshold below which bins are considered \u201calmost full\u201d\n    if slack_feas.size > 0:\n        threshold = np.quantile(slack_feas, low_percentile)\n    else:\n        threshold = 0.0\n\n    # Linear boost proportional to distance below the threshold\n    boost = np.zeros_like(slack_feas)\n    low_mask = slack_feas <= threshold\n    boost[low_mask] = boost_factor * (threshold - slack_feas[low_mask])\n\n    # ------------------------------------------------------------------\n    # 3) Combine deterministic components\n    # ------------------------------------------------------------------\n    combined = inv_slack + boost\n\n    # Normalise to the range [0, 1] (preserves ordering)\n    max_combined = np.max(combined) + eps\n    combined_norm = combined / max_combined\n\n    # ------------------------------------------------------------------\n    # 4) Tiny random tie\u2011breaker\n    # ------------------------------------------------------------------\n    rng = np.random.default_rng(random_state)\n    tie_eps = 1e-8\n    jitter = tie_eps * rng.random(combined_norm.shape)\n    final_score = combined_norm + jitter\n\n    # Store the computed scores back into the full array\n    priorities[feasible] = final_score\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 35.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    tolerance: float = 1e-12,\n    tie_breaker: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing that favours an exact fit.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining capacity of each open bin.\n    tolerance : float, optional\n        Numerical tolerance when deciding feasibility.  Bins whose remaining\n        capacity is at least ``item - tolerance`` are considered feasible.\n    tie_breaker : float, optional\n        Small deterministic bias to break ties between bins with the same\n        leftover capacity.  The bias is proportional to the bin index, so\n        lower\u2011indexed bins are favoured when the leftovers are equal.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better).  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Ensure a 1\u2011D float array\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n\n    # Feasibility mask\n    feasible = caps >= (item - tolerance)\n\n    # Prepare the priority array with -inf for infeasible bins\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        return priorities\n\n    # Leftover capacity after placing the item (never negative)\n    leftover = caps[feasible] - item\n    leftover = np.maximum(leftover, 0.0)\n\n    # Deterministic tie\u2011breaker: lower index => higher priority\n    indices = np.arange(caps.size)\n    priorities[feasible] = -leftover - indices[feasible] * tie_breaker\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                tolerance: float = 1e-12, tie_breaker: float = 1e-12) -> np.ndarray:\n    \"\"\"\n    Priority function for the online Bin Packing Problem.\n\n    The function prefers bins that fit the item exactly (or as close as\n    numerically possible), penalises any leftover capacity, and breaks ties\n    deterministically in favour of lower\u2011indexed bins. No randomness or\n    percentile boosts are used.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    tolerance : float, optional\n        Numerical tolerance for feasibility and exact\u2011fit detection.\n        Bins whose remaining capacity is at least ``item - tolerance`` are\n        considered feasible. A leftover smaller than ``tolerance`` is treated\n        as an exact fit.\n    tie_breaker : float, optional\n        Tiny positive value used to break ties deterministically. It must be\n        smaller than the smallest meaningful leftover (e.g., ``tolerance``).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        Higher values indicate more attractive bins. Infeasible bins receive\n        ``-np.inf``.\n    \"\"\"\n    # Ensure a flat NumPy array of floats.\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n\n    # Feasibility mask: bins that can accommodate the item within tolerance.\n    feasible = caps >= (item - tolerance)\n\n    # Initialise all priorities as -inf (infeasible bins).\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    # If there are no feasible bins, return immediately.\n    if not np.any(feasible):\n        return priorities\n\n    # Compute leftover capacity for feasible bins.\n    # Clip tiny negatives (caused by tolerance) to zero.\n    leftover = caps[feasible] - item\n    leftover = np.maximum(leftover, 0.0)\n\n    # Indices of all bins (preserves original ordering).\n    idx = np.arange(caps.size)\n\n    # Exact\u2011fit\u2011first: smaller leftover \u2192 higher priority.\n    # Use negative leftover so that a perfect fit (leftover == 0) yields the\n    # highest raw score. Subtract a tiny index\u2011dependent term to break ties in\n    # favour of lower\u2011indexed bins.\n    priorities[feasible] = -leftover - idx[feasible] * tie_breaker\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing that biases random choice\n    towards bins with small remaining slack. It adapts the bias to the\n    current distribution of leftover capacities and adds a tiny random\n    perturbation for deterministic tie\u2011breaking.\n    \"\"\"\n    # Ensure the input is a float array\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Remaining slack after placing the item\n    slack = caps - item\n\n    # Feasibility mask\n    feasible = slack >= 0\n\n    # Prepare output array with -inf for infeasible bins\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        return priorities\n\n    eps = 1e-12\n\n    # Inverse\u2011slack bias (larger when slack is smaller)\n    bias = np.zeros_like(caps)\n    bias[feasible] = 1.0 / (slack[feasible] + eps)\n\n    # Adapt scaling based on the current slack distribution\n    min_slack = np.min(slack[feasible])\n    max_slack = np.max(slack[feasible])\n    scale_den = max_slack - min_slack\n\n    scaling = np.ones_like(caps)\n    if scale_den >= eps:\n        scaling[feasible] = (max_slack - slack[feasible]) / (scale_den + eps)\n    else:\n        # When all feasible bins have identical slack, keep scaling 1\n        scaling[feasible] = 1.0\n\n    # Combine bias and scaling\n    scores = bias * scaling\n\n    # Tiny random tie\u2011breaker (only on feasible bins)\n    tie_break = _rng.random(feasible.sum()) * 1e-12\n    scores[feasible] += tie_break\n\n    # Place scores into the output array\n    priorities[feasible] = scores[feasible]\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 23.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response5.txt_stdout.txt",
    "code_path": "problem_iter6_code5.py",
    "code": "import numpy as np\n\n# Global RNG for tie\u2011breaking\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each bin in the online Bin Packing Problem.\n    The score is biased toward bins with smaller slack (remaining capacity after\n    placing the item) by using an inverse\u2011slack weighting. The weights are\n    normalised to avoid extreme values, a tiny random perturbation is added\n    for deterministic tie\u2011breaking, and infeasible bins receive -inf.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin. The bin with the highest score should be\n        selected for the item.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.size\n    priority = np.full_like(caps, -np.inf, dtype=float)\n\n    if n == 0:\n        return priority\n\n    slack = caps - item\n    feasible = slack >= 0\n    if not np.any(feasible):\n        return priority\n\n    eps = 1e-12\n    slack_f = slack[feasible]\n    # Inverse\u2011slack weighting (larger when slack is smaller)\n    inv_slack = 1.0 / (slack_f + eps)\n\n    # Normalise to keep values bounded (max weight becomes 1.0)\n    max_inv = np.max(inv_slack)\n    if max_inv > 0:\n        inv_slack /= max_inv\n\n    # Random component to bias the decision while retaining some randomness\n    rand = _rng.random(inv_slack.shape)\n\n    # Combine bias with randomness; tiny tie\u2011breaker added for deterministic tie\u2011breaks\n    scores = inv_slack * rand\n    scores += _rng.random(inv_slack.shape) * 1e-12\n\n    priority[feasible] = scores\n    return priority",
    "response_id": 5,
    "obj": 4.028719585161557,
    "SLOC": 21.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response6.txt_stdout.txt",
    "code_path": "problem_iter6_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                tolerance: float = 1e-12, tie_breaker: float = 1e-12) -> np.ndarray:\n    \"\"\"\n    Deterministic priority function for the online Bin Packing Problem.\n\n    The priority scores favor bins that can accommodate the incoming item with\n    the smallest leftover capacity.  If multiple bins have the same leftover,\n    the one with the smallest original index receives the highest score.\n    Infeasible bins (those that cannot hold the item) are given ``-np.inf``.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    tolerance : float, optional\n        Numerical tolerance for feasibility checks.  A bin is considered\n        feasible if its remaining capacity is at least ``item - tolerance``.\n    tie_breaker : float, optional\n        Tiny positive value used to break ties deterministically.  It must\n        be smaller than the smallest meaningful leftover (e.g., ``tolerance``).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Higher values indicate more attractive\n        bins.  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Flatten the input to a 1\u2011D array of floats\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n\n    # Feasibility mask: bins that can hold the item within tolerance\n    feasible = caps >= (item - tolerance)\n\n    # Initialise priorities as -inf (infeasible bins)\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No bin can accommodate the item; return -inf array\n        return priorities\n\n    # Compute leftover capacity for feasible bins\n    leftover = caps[feasible] - item\n    # Clip tiny negatives caused by floating\u2011point errors to zero\n    leftover = np.maximum(leftover, 0.0)\n\n    # Indices of feasible bins (preserve original order)\n    idx = np.where(feasible)[0]\n\n    # Exact\u2011fit first: lower leftover => higher priority.\n    # Subtract a tiny index\u2011dependent term to break ties in favour of lower indices.\n    priorities[feasible] = -leftover - idx * tie_breaker\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response7.txt_stdout.txt",
    "code_path": "problem_iter6_code7.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Priority function for online Bin Packing.\n\n    Each feasible bin (i.e. a bin with enough remaining capacity) receives a\n    score that blends a tight\u2011fit bias with a random component.  The relative\n    weight of the bias adapts online based on the current packing situation:\n    when few bins can accommodate the item we trust the bias more (tight fit);\n    when many bins are feasible we rely more on randomness to explore diverse\n    placements.\n\n    Infeasible bins receive a score of -inf so they are never selected.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n    random_state : int, optional\n        Seed for reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better) for each bin.\n    \"\"\"\n    eps = 1e-12                     # avoid division by zero\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = caps.size\n\n    # Initialise all priorities to -inf (infeasible by default)\n    priorities = np.full(n_bins, -np.inf, dtype=float)\n\n    # Identify feasible bins\n    feasible = caps >= item\n    if not np.any(feasible):\n        # Nothing fits \u2013 return all -inf\n        return priorities\n\n    # Slack after placing the item in each feasible bin\n    slack = caps - item\n\n    # ---- 1. Tight\u2011fit bias -------------------------------------------------\n    # Bias is higher when the remaining slack is small.\n    bias = np.zeros_like(caps)\n    bias[feasible] = 1.0 / (slack[feasible] + eps)\n\n    # Normalise bias to the range [0, 1] for a fair combination with randomness.\n    max_bias = bias[feasible].max()\n    bias_norm = np.zeros_like(caps)\n    bias_norm[feasible] = bias[feasible] / (max_bias + eps)\n\n    # ---- 2. Random component -----------------------------------------------\n    rng = np.random.default_rng(random_state)\n    rand_scores = rng.random(n_bins)          # uniform [0, 1) for every bin\n\n    # ---- 3. Adaptive weighting -----------------------------------------------\n    # Weight of the tight\u2011fit bias depends on how many bins are feasible.\n    # Few feasible bins \u2192 high bias weight (focus on tight fit).\n    # Many feasible bins \u2192 lower bias weight (more exploration).\n    feasible_frac = feasible.sum() / n_bins          # \u2208 (0, 1]\n    w_bias = 1.0 - feasible_frac                      # larger when few bins fit\n\n    # Clamp the weight to avoid extreme domination of one term.\n    w_bias = np.clip(w_bias, 0.1, 0.9)\n\n    # ---- 4. Combine bias and randomness ---------------------------------------\n    # Linear blend of the two components for feasible bins.\n    combined = np.zeros_like(caps)\n    combined[feasible] = (\n        w_bias * bias_norm[feasible] + (1.0 - w_bias) * rand_scores[feasible]\n    )\n\n    # ---- 5. Tiny random tie\u2011breaker (numerical stability) --------------------\n    tie_eps = 1e-8\n    combined[feasible] += rng.random(combined[feasible].shape) * tie_eps\n\n    # Fill the output array\n    priorities[feasible] = combined[feasible]\n\n    return priorities",
    "response_id": 7,
    "obj": 23.57399282010372,
    "SLOC": 31.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response8.txt_stdout.txt",
    "code_path": "problem_iter6_code8.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, random_state: Optional[int] = None) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each bin in an online bin\u2011packing setting.\n\n    This version uses a simple leftover\u2011based exponential boost with an\n    adaptive epsilon. Infeasible bins receive ``-np.inf`` so they are never\n    selected. A tiny random perturbation is added for deterministic\n    tie\u2011breaking.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each currently open bin.\n    random_state : int, optional\n        Seed for the random number generator used for tie\u2011breaking noise.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; higher values indicate a more\n        desirable placement. Infeasible bins have ``-np.inf``.\n    \"\"\"\n    # Ensure capacities are a float array\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute leftover capacity after placing the item\n    leftover = caps - item\n\n    # Feasible bins are those that can accommodate the item\n    feasible = leftover >= 0\n\n    # Adaptive epsilon: use mean leftover of feasible bins, with a lower bound\n    if np.any(feasible):\n        eps = max(np.mean(leftover[feasible]), 1e-9)\n    else:\n        # No feasible bin \u2013 epsilon is irrelevant but must be > 0\n        eps = 1e-9\n\n    # Exponential boost: highest when leftover \u2248 0, decays for larger leftovers\n    boost = np.exp(-leftover / eps)\n\n    # Assemble priority: boost for feasible bins, -inf otherwise\n    priority = np.where(feasible, boost, -np.inf)\n\n    # Tiny random noise for tie\u2011breaking (deterministic if random_state set)\n    rng = np.random.default_rng(random_state)\n    noise = rng.random(priority.shape) * 1e-12\n    priority[feasible] += noise[feasible]\n\n    return priority",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response9.txt_stdout.txt",
    "code_path": "problem_iter6_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing.\n\n    For each feasible bin, compute a bias based on the remaining slack\n    (1 / (slack + eps)), optionally amplified for bins that are already\n    more full (smaller remaining capacity).  The amplification factor\n    grows over time to encourage tighter packing as the problem progresses.\n\n    A small random perturbation is added to the scores to break ties\n    stochastically.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more attractive).  Infeasible\n        bins receive ``-np.inf``.\n    \"\"\"\n    # Ensure a flat float array\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.size\n\n    # Feasibility mask\n    feasible = caps >= item\n    priorities = np.full(n_bins, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        return priorities\n\n    # Compute slack and bias\n    slack = caps[feasible] - item\n    eps = 1e-12\n    bias = 1.0 / (slack + eps)  # larger when slack is small\n\n    # Adaptation over time: progressively emphasize bins that are already\n    # more full (smaller remaining capacity).  The adaptation factor\n    # grows linearly with the number of calls up to a maximum.\n    if not hasattr(priority_v2, \"_call_count\"):\n        priority_v2._call_count = 0\n    priority_v2._call_count += 1\n    alpha = min(1.0, priority_v2._call_count / 2000.0)  # increase over ~2000 calls\n\n    # Weight factor based on remaining capacity relative to the maximum\n    # among feasible bins.  Bins with smaller remaining get a higher weight.\n    max_remain = caps[feasible].max()\n    weight_factor = 1.0 + alpha * (max_remain - caps[feasible]) / max_remain\n\n    # Combine bias and weight\n    scores = bias * weight_factor\n\n    # Stochastic tie\u2011breaking: add tiny random noise.\n    rng = np.random.default_rng()\n    # Scale noise relative to the magnitude of the scores to keep it small.\n    max_score = np.max(scores)\n    noise_scale = 1e-6 * (max_score if max_score > 0 else 1.0)\n    noise = rng.uniform(-noise_scale, noise_scale, size=scores.shape)\n    scores += noise\n\n    # Assign to the output array\n    priorities[feasible] = scores\n    return priorities",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 24.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each bin in an online bin\u2011packing setting.\n\n    The score favours bins where the item fits exactly (slack = 0) by using\n    the inverse of the slack plus an adaptive epsilon.  An adaptive epsilon,\n    proportional to the total remaining capacity, guards against division by\n    zero and scales the scores to the current waste.  A tiny random perturbation\n    (scaled by epsilon) is added only to bins that are tied for the tightest\n    fit, and a deterministic index\u2011based penalty resolves any remaining ties\n    in favour of lower\u2011indexed bins.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        1\u2011D array of priority scores (same length as ``bins_remain_cap``).\n        Infeasible bins (capacity < item) receive ``-np.inf``.\n    \"\"\"\n    # Ensure we are working with a float array.\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Feasibility mask: bins that can accommodate the item.\n    feasible = caps >= item\n\n    # Initialise priority vector with -inf for infeasible bins.\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No bin can hold the item; return all -inf.\n        return priorities\n\n    # Slack (unused capacity) if the item were placed in each bin.\n    slack = caps - item\n\n    # Adaptive epsilon: small positive number that grows with the total\n    # remaining capacity (i.e., current waste).  This keeps scores numerically\n    # stable across problem scales.\n    total_remain = caps.sum()\n    epsilon = max(1e-12, total_remain * 1e-12)\n\n    # Base score: inverse slack (higher for tighter fits; exact fits get\n    # the maximal value 1/epsilon).\n    base_score = np.zeros_like(caps, dtype=float)\n    base_score[feasible] = 1.0 / (slack[feasible] + epsilon)\n\n    # Identify bins with the smallest slack among feasible bins (tightest fits).\n    min_slack = np.min(slack[feasible])\n    tie_mask = feasible & np.isclose(slack, min_slack, atol=1e-12)\n\n    # Add a tiny random noise only to the tied bins to break stochastic ties.\n    # Scale the noise by epsilon so it never overwhelms the base score.\n    noise_scale = epsilon * 1e-6\n    random_noise = np.random.rand(np.sum(tie_mask)) * noise_scale\n    base_score[tie_mask] += random_noise\n\n    # Deterministic tie\u2011breaker: small penalty proportional to bin index.\n    # The penalty is far smaller than any meaningful score difference.\n    index_penalty = np.arange(caps.size, dtype=float) * (epsilon * 1e-7)\n    base_score[feasible] -= index_penalty[feasible]\n\n    # Assign the computed scores to the output array.\n    priorities[feasible] = base_score[feasible]\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]