[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing that blends worst\u2011fit,\n    slack\u2011biased randomness, and an anticipation term based on the\n    distribution of current slack values.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin. The bin with the maximum score\n        will be chosen to hold the item. Bins that cannot accommodate\n        the item receive a score of -np.inf.\n    \"\"\"\n    # Ensure a float array for calculations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Feasible bins that can accommodate the item\n    feasible = caps >= item\n\n    # Initialise all priorities to -inf (ensures infeasible bins are never selected)\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin, return the -inf array\n        return priorities\n\n    # Extract capacities and slack for feasible bins\n    rem = caps[feasible]\n    slack = rem - item\n    eps = 1e-12\n\n    # Normalise remaining capacity (worst\u2011fit component)\n    rem_min, rem_max = rem.min(), rem.max()\n    norm_rem = (rem - rem_min) / (rem_max - rem_min + eps)\n\n    # Normalise inverse slack (tight\u2011fit component)\n    inv_slack = 1.0 / (slack + eps)\n    inv_min, inv_max = inv_slack.min(), inv_slack.max()\n    norm_inv_slack = (inv_slack - inv_min) / (inv_max - inv_min + eps)\n\n    # Anticipation term: bins whose slack is close to the mean slack\n    slack_mean = slack.mean()\n    slack_std = slack.std() + eps\n    closeness = 1.0 - np.abs(slack - slack_mean) / slack_std\n    closeness = np.clip(closeness, 0.0, 1.0)\n\n    # Weight parameters (can be tuned)\n    alpha, beta, gamma = 0.4, 0.4, 0.2   # sum to 1\n    exploration_factor = 0.05\n\n    # Combine components\n    score = (\n        alpha * norm_rem\n        + beta * norm_inv_slack\n        + gamma * closeness\n    )\n\n    # Add small random exploration noise\n    rng = np.random.default_rng()\n    noise = rng.random(size=score.size) * exploration_factor\n    score += noise\n\n    # Assign the computed priorities to the feasible bins\n    priorities[feasible] = score\n\n    return priorities",
    "response_id": 0,
    "obj": 103.74950139609096,
    "SLOC": 30.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\nclass PriorityV2:\n    \"\"\"\n    Adaptive priority function for the online Bin Packing Problem.\n\n    Features:\n    - Epsilon\u2011greedy exploration with a decaying epsilon.\n    - Exploitation uses a Best\u2011Fit rule (minimise waste) plus a small bias\n      towards older bins (lower index) to encourage closing bins early.\n    - A tiny random tie\u2011breaker prevents deterministic ties.\n\n    The instance is callable so it can be used directly as:\n        score = priority_v2(item, bins_remain_cap)\n    \"\"\"\n\n    def __init__(self,\n                 init_epsilon: float = 0.5,\n                 min_epsilon: float = 0.01,\n                 decay: float = 0.99,\n                 age_weight: float = 1e-3,\n                 tie_noise: float = 1e-6):\n        \"\"\"\n        Parameters\n        ----------\n        init_epsilon : float\n            Starting exploration probability.\n        min_epsilon : float\n            Lower bound for epsilon (ensures occasional exploration).\n        decay : float\n            Multiplicative decay factor applied each call (0 < decay \u2264 1).\n        age_weight : float\n            Weight of the age bias (smaller values give a weaker bias).\n        tie_noise : float\n        \"\"\"\n        self.init_epsilon = init_epsilon\n        self.min_epsilon = min_epsilon\n        self.decay = decay\n        self.age_weight = age_weight\n        self.tie_noise = tie_noise\n        self.step = 0  # number of items processed\n\n    def __call__(self, item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n        \"\"\"Return a priority vector for the given item.\"\"\"\n        # Update step counter and compute the current epsilon\n        self.step += 1\n        epsilon = max(self.min_epsilon,\n                      self.init_epsilon * (self.decay ** self.step))\n\n        # Ensure a 1\u2011D float array\n        caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n        n_bins = caps.size\n\n        # Feasibility mask\n        feasible = caps >= item\n\n        # Initialise priorities with -inf for infeasible bins\n        priorities = np.full(n_bins, -np.inf, dtype=float)\n\n        # No feasible bin \u2013 return all -inf\n        if not np.any(feasible):\n            return priorities\n\n        # Decide between exploration and exploitation\n        if np.random.rand() < epsilon:\n            # Exploration: assign random scores to feasible bins\n            priorities[feasible] = np.random.rand(np.sum(feasible))\n        else:\n            # Exploitation: Best\u2011Fit + age bias + tiny random tie\u2011breaker\n            waste = caps[feasible] - item          # leftover space if item placed\n            base_priority = -waste                 # smaller waste \u2192 larger priority\n\n            # Age bias: earlier (older) bins get a small boost.\n            feasible_indices = np.nonzero(feasible)[0]\n            age_bias = -self.age_weight * feasible_indices.astype(float)\n\n            # Combine and add tie\u2011breaker noise\n            priorities[feasible] = (\n                base_priority + age_bias +\n                np.random.rand(np.sum(feasible)) * self.tie_noise\n            )\n\n        return priorities\n\n\n# Reusable instance \u2013 can be imported and called directly\npriority_v2 = PriorityV2()",
    "response_id": 1,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 10, in <module>\n    source = inspect.getsource(priority)\n  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n    lines, lnum = getsourcelines(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n    lines, lnum = findsource(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 940, in findsource\n    file = getsourcefile(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 817, in getsourcefile\n    filename = getfile(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 797, in getfile\n    raise TypeError('module, class, method, function, traceback, frame, or '\nTypeError: module, class, method, function, traceback, frame, or code object was expected, got PriorityV2\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 10, in <module>\n    source = inspect.getsource(priority)\n  File \"/usr/lib/python3.10/inspect.py\", line 1139, in getsource\n    lines, lnum = getsourcelines(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n    lines, lnum = findsource(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 940, in findsource\n    file = getsourcefile(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 817, in getsourcefile\n    filename = getfile(object)\n  File \"/usr/lib/python3.10/inspect.py\", line 797, in getfile\n    raise TypeError('module, class, method, function, traceback, frame, or '\nTypeError: module, class, method, function, traceback, frame, or code object was expected, got PriorityV2\n"
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    tolerance: float = 1e-12,\n    tie_breaker: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Deterministic Exact\u2011Fit\u2011First priority function for online Bin Packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array (or array\u2011like) of remaining capacities of the currently open bins.\n    tolerance : float, optional\n        Numerical tolerance for feasibility and exact\u2011fit detection.\n        Bins whose remaining capacity is at least ``item - tolerance`` are considered feasible.\n        A leftover smaller than ``tolerance`` is treated as an exact fit.\n    tie_breaker : float, optional\n        Tiny value used to break ties deterministically in favour of lower\u2011indexed bins.\n        Must be sufficiently smaller than the smallest possible leftover.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        Higher values indicate more attractive bins. Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Ensure a flat NumPy array of floats.\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n\n    # Feasibility mask: bins that can accommodate the item within tolerance.\n    feasible = caps >= (item - tolerance)\n\n    # Initialise priorities with -inf for infeasible bins.\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin; return all -inf.\n        return priorities\n\n    # Compute leftover capacity for feasible bins.\n    leftover = caps[feasible] - item\n    # Clip tiny negative leftovers caused by tolerance to zero.\n    leftover = np.maximum(leftover, 0.0)\n\n    # Indices of feasible bins (used for deterministic tie\u2011breaking).\n    idx = np.where(feasible)[0]\n\n    # Exact\u2011Fit\u2011First: smaller leftover \u2192 higher priority.\n    # Use negative leftover so exact fit (leftover == 0) yields the highest raw score.\n    # Subtract a tiny index\u2011dependent term to break ties in favour of lower\u2011indexed bins.\n    priorities[feasible] = -leftover - idx * tie_breaker\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for online Bin Packing using inverse waste.\n\n    For each bin that can accommodate the item, the priority is proportional\n    to 1/(remaining_capacity - item + eps). Bins that cannot accommodate the \n    item receive -inf. Scores are shifted to be non\u2011negative.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (same shape as bins_remain_cap). Higher values indicate\n        more desirable bins.\n    \"\"\"\n    eps = 1e-9  # avoid division by zero when waste is zero\n\n    # Ensure a 1\u2011D float array\n    caps = np.asarray(bins_remain_cap, dtype=float).reshape(-1)\n\n    # Feasibility mask\n    feasible = caps >= item\n\n    # Compute waste (remaining capacity after placing the item)\n    waste = caps - item\n\n    # Inverse waste priority for feasible bins, -inf otherwise\n    priorities = np.where(feasible, 1.0 / (waste + eps), -np.inf)\n\n    # Shift to non\u2011negative values if any finite priority is negative\n    if np.any(np.isfinite(priorities)):\n        min_finite = np.min(priorities[np.isfinite(priorities)])\n        if min_finite < 0:\n            priorities = np.where(\n                np.isfinite(priorities),\n                priorities - min_finite,\n                priorities\n            )\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    bin_capacity: float = 1.0,\n    avg_item_size: float | None = None,\n    epsilon: float = 0.05,\n    small_leftover_penalty_factor: float = 10.0,\n    lookahead_penalty_factor: float = 5.0,\n) -> np.ndarray:\n    \"\"\"\n    Compute a composite priority score for each bin in an online bin\u2011packing\n    setting.\n\n    The score blends best\u2011fit and worst\u2011fit considerations, adds an adaptive\n    penalty for creating tiny fragments, and optionally penalises bins that\n    would be unable to accommodate a typical future item (look\u2011ahead).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n    bin_capacity : float, optional\n        Fixed capacity of each bin.  Required for normalising weights and\n        computing penalties.  Defaults to 1.0.\n    avg_item_size : float | None, optional\n        Estimate of the average size of items that will arrive later.\n        If provided, bins that would leave less remaining space than this\n        average are penalised (simple look\u2011ahead).  If ``None``, the look\u2011ahead\n        term is omitted.\n    epsilon : float, optional\n        Fraction of ``bin_capacity`` below which leftover space is considered\n        a fragment and penalised.  Default is 0.05 (i.e., 5\u202f% of a bin).\n    small_leftover_penalty_factor : float, optional\n        Multiplicative factor for the fragment\u2011penalty term.\n    lookahead_penalty_factor : float, optional\n        Multiplicative factor for the look\u2011ahead penalty term.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  The bin with the highest score should\n        be selected for the item.  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Ensure array type\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute leftover capacity after placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask: only bins that can hold the item\n    feasible = leftover >= 0\n\n    # Base scores\n    # Best\u2011fit: tighter fit -> larger score for smaller leftover (negative leftover)\n    best_fit_score = -leftover\n    # Worst\u2011fit: prefer bins with more free space\n    worst_fit_score = bins_remain_cap\n\n    # Weight between best\u2011fit and worst\u2011fit based on item size relative to bin capacity\n    w_best = np.clip(item / bin_capacity, 0.0, 1.0)  # large items -> more best\u2011fit\n    w_worst = 1.0 - w_best\n\n    # Combine the two scores\n    priority = w_best * best_fit_score + w_worst * worst_fit_score\n\n    # --- Adaptive penalty for tiny fragments ---\n    # Leftover smaller than epsilon*bin_capacity is considered wasteful\n    fragment_mask = (leftover > 0) & (leftover < epsilon * bin_capacity)\n    fragment_penalty = np.zeros_like(priority)\n    fragment_penalty[fragment_mask] = (\n        small_leftover_penalty_factor *\n        (epsilon * bin_capacity - leftover[fragment_mask])\n    )\n    priority -= fragment_penalty\n\n    # --- Simple look\u2011ahead penalty (optional) ---\n    if avg_item_size is not None:\n        # Penalise bins that would not have enough space for a typical future item\n        lookahead_mask = (leftover > 0) & (leftover < avg_item_size)\n        lookahead_penalty = np.zeros_like(priority)\n        lookahead_penalty[lookahead_mask] = (\n            lookahead_penalty_factor *\n            (avg_item_size - leftover[lookahead_mask])\n        )\n        priority -= lookahead_penalty\n\n    # Infeasible bins get -inf so they are never selected\n    priority[~feasible] = -np.inf\n\n    return priority",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 34.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for assigning ``item`` to each bin in ``bins_remain_cap``.\n\n    This heuristic blends a tight\u2011fit bias (inverse slack) with a controlled\n    random component.  The boost for \u201calmost full\u201d bins is set dynamically\n    based on a low\u2011percentile slack threshold, and the epsilon used in the\n    inverse\u2011slack term adapts to the typical slack magnitude.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n\n    Returns\n    -------\n    np.ndarray\n        A 1\u2011D array of priority scores (higher is better).  Infeasible bins\n        receive ``-np.inf`` so they are never selected.\n    \"\"\"\n    # Ensure a float array\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Slack after hypothetically placing the item\n    slack = caps - item\n\n    # Feasibility mask: only bins that can hold the item\n    feasible = slack >= 0\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    # If no feasible bin exists, return the all -inf array early\n    if not np.any(feasible):\n        return priorities\n\n    # ------------------------------------------------------------------\n    # 1) Tight\u2011fit bias: inverse of slack (smaller slack \u2192 larger priority)\n    #    epsilon adapts to the typical slack magnitude to avoid division\u2011by\u2011zero\n    # ------------------------------------------------------------------\n    mean_slack = np.mean(slack[feasible]) if np.any(feasible) else 0.0\n    eps = max(1e-12, 1e-6 * mean_slack)               # adaptive epsilon\n    inv_slack = 1.0 / (slack[feasible] + eps)        # larger for tighter fits\n\n    # ------------------------------------------------------------------\n    # 2) Dynamic boost for \u201calmost full\u201d bins\n    #    Use a low percentile (e.g., 10th) of the slack distribution as a threshold\n    # ------------------------------------------------------------------\n    low_percentile = 0.10\n    slack_feas = slack[feasible]\n    threshold = np.quantile(slack_feas, low_percentile) if slack_feas.size > 0 else 0.0\n\n    boost_factor = 5.0                               # magnitude of boost\n    boost = np.zeros_like(slack_feas)\n    low_slack_mask = slack_feas <= threshold\n    boost[low_slack_mask] = boost_factor * (threshold - slack_feas[low_slack_mask])\n\n    # ------------------------------------------------------------------\n    # 3) Combine bias and boost\n    # ------------------------------------------------------------------\n    combined = inv_slack + boost\n\n    # ------------------------------------------------------------------\n    # 4) Controlled randomness: a random factor close to 1 (e.g., [0.8, 1.0])\n    #    This keeps the bias dominant while providing tie\u2011breaking randomness.\n    # ------------------------------------------------------------------\n    rand_vals = np.random.rand(caps.size)\n    rand_factor = 0.8 + 0.2 * rand_vals               # range [0.8, 1.0]\n    final_feasible = combined * rand_factor[feasible]\n\n    # Assign computed priorities back to the full array\n    priorities[feasible] = final_feasible\n\n    return priorities",
    "response_id": 5,
    "obj": 4.208216992421225,
    "SLOC": 23.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin\u2011packing that scores each bin by\n    how *tight* the fit would be, normalised between 0 and 1 for\n    feasible bins, with a tiny tie\u2011breaking bias and a hard penalty\n    for infeasible bins.\n\n    The score is highest for a bin that would become the most full\n    after placing the item (i.e. the smallest leftover capacity).\n    Bins that cannot accommodate the item receive -\u221e and are never\n    chosen.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to be packed.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        An array of the same shape as ``bins_remain_cap`` containing\n        a priority score for each bin.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute leftover capacity after placing the item.\n    leftover = bins_remain_cap - item\n\n    # Which bins can accept the item?\n    feasible = leftover >= 0\n\n    # Handle the case where no bin can fit the item.\n    if not np.any(feasible):\n        # All bins are infeasible \u2013 return a constant negative score\n        # (or -np.inf) for every bin.\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Normalise feasible leftovers to a 0\u20111 range:\n    # 1.0 corresponds to zero leftover (perfect fit).\n    # 0.0 corresponds to the largest leftover among feasible bins.\n    max_leftover = leftover[feasible].max()\n    eps = 1e-12  # avoid division by zero\n    denom = max_leftover if max_leftover > eps else eps\n    norm_scores = np.where(\n        feasible,\n        1.0 - leftover / denom,  # higher score for smaller leftover\n        -np.inf\n    )\n\n    # Tiny bias that prefers bins with *larger* remaining capacity\n    # (i.e. smaller indices when bins are sorted by capacity).\n    bias = 1e-6 * (bins_remain_cap.max() - bins_remain_cap)\n    return norm_scores + bias",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing that blends residual capacity\n    with a stochastic tie\u2011breaker. Feasible bins receive a score that is a\n    weighted sum of their normalized residual capacity and a uniform random\n    value. Infeasible bins are assigned -inf so they are never chosen.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining capacity of each existing bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores of the same shape as `bins_remain_cap`.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    can_fit = caps >= item\n\n    # If no feasible bins, return all -inf\n    if not np.any(can_fit):\n        return np.full_like(caps, -np.inf)\n\n    residual = caps - item\n\n    # Normalize residuals among feasible bins to [0, 1]\n    max_res = residual[can_fit].max()\n    if max_res > 0:\n        residual_norm = residual / max_res\n    else:\n        residual_norm = np.zeros_like(residual)\n\n    # Random component uniform in [0, 1)\n    random_comp = _rng.random(size=caps.shape)\n\n    # Weight between deterministic residual and stochastic tie\u2011breaker\n    alpha = 0.9\n    priority = np.where(can_fit,\n                        alpha * residual_norm + (1 - alpha) * random_comp,\n                        -np.inf)\n\n    return priority",
    "response_id": 7,
    "obj": 149.28201037096133,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    gamma: float = 1.0,\n    temperature: float = 1.0,\n    random_seed: int | None = None,\n    tie_break: bool = False,\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for each bin using a soft\u2011max over negative waste.\n\n    The score is high for bins that leave the least waste after placing the item.\n    Infeasible bins receive a score of zero.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacities of each existing bin.\n    gamma : float, optional\n        Scale factor for waste penalty; larger values favor tighter fits more\n        aggressively. Default is 1.0.\n    temperature : float, optional\n        Temperature for the soft\u2011max; lower values make the distribution\n        sharper (more greedy), higher values make it smoother (more\n        exploratory). Must be > 0. Default is 1.0.\n    random_seed : int or None, optional\n        If provided and `tie_break` is True, random noise will be added to the\n        logits in a reproducible way to break ties.\n    tie_break : bool, optional\n        If True, add a very small random perturbation to the logits to avoid\n        deterministic ties when multiple bins have identical waste.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores of the same shape as `bins_remain_cap`.  The array\n        contains values in [0, 1] that sum to 1 over the feasible bins; all\n        infeasible bins receive 0.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=np.float64, copy=False)\n    feasible = caps >= item\n\n    if not np.any(feasible):\n        return np.zeros_like(caps, dtype=np.float64)\n\n    waste = caps - item\n    logits = np.full_like(caps, -np.inf, dtype=np.float64)\n    logits[feasible] = -gamma * waste[feasible] / temperature\n\n    if tie_break:\n        rng = np.random.default_rng(random_seed)\n        noise = rng.uniform(low=-1e-12, high=1e-12, size=feasible.sum())\n        logits[feasible] += noise\n\n    max_logit = np.max(logits)\n    exp_vals = np.exp(logits - max_logit)\n    priorities = exp_vals / np.sum(exp_vals)\n\n    return priorities",
    "response_id": 8,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 44, in priority_v2\n    eps = max(eps, 1e-6)\nValueError: Unable to avoid copy while creating an array as requested.\nIf using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x).\nFor more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword.\n23\n3\n"
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each bin for the online Bin Packing Problem.\n\n    The heuristic favours bins that become *almost full* after placing the item,\n    applying an adaptive boost that grows when the leftover capacity is small.\n    Infeasible bins receive a large negative priority so they are never chosen.\n    A tiny random perturbation is added to break ties in a non\u2011deterministic way.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores, one per bin. The bin with the highest score\n        should be selected for the item.\n    \"\"\"\n    # Ensure a floating point array\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Leftover capacity after hypothetically placing the item\n    leftover = caps - item\n\n    # Feasibility mask: True if the bin can accommodate the item\n    feasible = leftover >= 0\n\n    # Base priority: higher when leftover is smaller (negative leftover)\n    base_priority = -leftover\n\n    # Adaptive boost: decays quickly as leftover grows.\n    # Use a scale (eps) that adapts to the current distribution of feasible leftovers.\n    if np.any(feasible):\n        # Use a low percentile of feasible leftovers as a scale.\n        # This makes the boost more aggressive when many bins are nearly full.\n        eps = np.percentile(leftover[feasible], 25)  # 25th percentile\n        # Guard against eps being zero (e.g., when a perfect fit exists)\n        eps = max(eps, 1e-6)\n    else:\n        eps = 0.05  # fallback scale when no bin can hold the item\n\n    boost_factor = 5.0  # magnitude of the boost\n\n    # Exponential decay boost: maximum boost_factor when leftover \u2248 0,\n    # decays to near\u2011zero for leftover \u226b eps.\n    boost = boost_factor * np.exp(-leftover / eps)\n\n    # Combine base priority and boost, penalise infeasible bins with -inf\n    priority = np.where(feasible, base_priority + boost, -np.inf)\n\n    # Add a tiny random perturbation for tie\u2011breaking (only on feasible bins)\n    rng = np.random.default_rng()\n    tie_break = rng.random(priority.shape) * 1e-12\n    priority = np.where(feasible, priority + tie_break, priority)\n\n    return priority",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    bin_ages: Optional[np.ndarray] = None,\n    temperature: float = 1.0,\n    lookahead_items: Optional[np.ndarray] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each bin in an online bin\u2011packing setting.\n\n    The heuristic blends an exact\u2011fit bias with a weighted worst\u2011fit component,\n    optionally incorporates look\u2011ahead information, bin age, and a temperature\n    parameter for exploration/exploitation control.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n    bin_ages : np.ndarray or None, optional\n        1\u2011D array (same length as bins_remain_cap) indicating the age of each bin\n        (e.g., number of items already placed). Older bins receive a small boost\n        to encourage closing them.\n    temperature : float, optional\n        Controls the softness of the selection. Lower values make the algorithm\n        greedier (higher scores dominate). Must be > 0.\n    lookahead_items : np.ndarray or None, optional\n        Array of sizes of upcoming items. A bin that can still accommodate many\n        look\u2011ahead items receives a boost.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better). Infeasible bins receive -inf.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Prepare inputs and guard against pathological values\n    # ------------------------------------------------------------------\n    eps = 1e-12                     # tiny epsilon to avoid division by zero\n    temperature = max(temperature, eps)\n\n    caps = np.asarray(bins_remain_cap, dtype=float).copy()\n    n_bins = caps.size\n\n    # Initialise all priorities to -inf (infeasible by default)\n    priorities = np.full(n_bins, -np.inf, dtype=float)\n\n    # Feasibility mask\n    feasible = caps >= item\n    if not np.any(feasible):\n        return priorities  # nothing fits\n\n    # ------------------------------------------------------------------\n    # 2. Core exact\u2011fit / worst\u2011fit scores\n    # ------------------------------------------------------------------\n    slack = caps - item                     # remaining space after placement\n    slack_feas = slack[feasible]\n\n    # Exact\u2011fit component: larger when slack is tiny\n    exact_fit = 1.0 / (slack_feas + eps)    # 1/(waste+eps)\n\n    # Worst\u2011fit component: larger when slack is large (normalized)\n    max_cap = np.max(caps) + eps\n    worst_fit = slack_feas / max_cap        # in [0,1]\n\n    # Blend the two with configurable weights\n    w_exact = 0.6\n    w_worst = 0.4\n    core_score = w_exact * exact_fit + w_worst * worst_fit\n\n    # ------------------------------------------------------------------\n    # 3. Optional look\u2011ahead boost\n    # ------------------------------------------------------------------\n    if lookahead_items is not None and lookahead_items.size > 0:\n        # Count how many future items could still fit after placing the current one\n        lookahead = np.asarray(lookahead_items, dtype=float)\n        # Broadcast: (n_feasible, n_lookahead) -> bool matrix\n        fits = lookahead[None, :] <= slack_feas[:, None]\n        # Fraction of look\u2011ahead items that fit each bin\n        lookahead_frac = fits.mean(axis=1)      # in [0,1]\n        lookahead_weight = 0.3\n        core_score *= (1.0 + lookahead_weight * lookahead_frac)\n\n    # ------------------------------------------------------------------\n    # 4. Optional bin\u2011age boost\n    # ------------------------------------------------------------------\n    if bin_ages is not None:\n        ages = np.asarray(bin_ages, dtype=float)\n        if ages.shape != caps.shape:\n            raise ValueError(\"bin_ages must have the same shape as bins_remain_cap\")\n        # Normalise ages to [0,1]\n        age_norm = ages / (np.max(ages) + eps)\n        age_weight = 0.2\n        age_factor = 1.0 + age_weight * age_norm\n        # Apply only to feasible bins\n        core_score *= age_factor[feasible]\n\n    # ------------------------------------------------------------------\n    # 5. Temperature\u2011scaled softmax (or exponential) for exploration\n    # ------------------------------------------------------------------\n    # Using exponential scaling; higher temperature smooths differences\n    exp_score = np.exp(core_score / temperature)\n\n    # ------------------------------------------------------------------\n    # 6. Tiny random tie\u2011breaker for numerical stability\n    # ------------------------------------------------------------------\n    tie_eps = 1e-8\n    exp_score += np.random.rand(exp_score.size) * tie_eps\n\n    # Fill the priority array\n    priorities[feasible] = exp_score\n\n    return priorities",
    "response_id": 0,
    "obj": 83.27682489030715,
    "SLOC": 42.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  }
]