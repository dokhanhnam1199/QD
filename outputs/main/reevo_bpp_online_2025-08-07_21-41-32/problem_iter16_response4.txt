```python
import numpy as np
from typing import Optional

def priority_v2(
    item: float,
    bins_remain_cap: np.ndarray,
    tolerance: float = 1e-12,
    epsilon: float = 1e-12,
    tie_breaker: float = 1e-12,
    random_state: Optional[np.random.Generator] = None,
) -> np.ndarray:
    """
    Compute priority scores for each open bin in an online bin packing scenario.

    The score favours:
      * Feasibility (the bin must have enough remaining capacity).
      * Tight fits (small slack after insertion) via a bias term.
      * Random diversification to avoid deterministic patterns.
      * A tiny deterministic tie‑breaker based on bin index.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of currently open bins (float or int).
    tolerance : float, optional
        Numerical tolerance for feasibility checks (default 1e-12).
    epsilon : float, optional
        Small constant added to slack to avoid division by zero (default 1e-12).
    tie_breaker : float, optional
        Tiny weight applied to bin index to break exact ties (default 1e-12).
    random_state : Optional[np.random.Generator], optional
        Random generator for reproducibility; if None, a default generator is used.

    Returns
    -------
    np.ndarray
        Array of priority scores for each bin; infeasible bins receive -inf.
    """
    # Ensure a random generator is available.
    rng = random_state if random_state is not None else np.random.default_rng()

    # Flatten capacities and cast to float.
    caps = np.asarray(bins_remain_cap, dtype=float).ravel()
    n_bins = caps.size

    # Determine feasibility: bin must have enough remaining capacity.
    feasible = caps >= (item - tolerance)

    # Initialise all scores to -inf (infeasible by default).
    scores = np.full(n_bins, -np.inf, dtype=float)

    # Early exit if no bin can hold the item.
    if not np.any(feasible):
        return scores

    # Slack after placing the item, clipped at zero to handle floating‑point noise.
    slack = np.maximum(caps - item, 0.0)

    # Bias favouring tighter fits (smaller slack). epsilon avoids division by zero.
    bias = 1.0 / (slack + epsilon)

    # Random component for diversification.
    rand = rng.random(n_bins)

    # Deterministic tie‑breaker: lower index gets a tiny advantage.
    idx_factor = np.arange(n_bins, dtype=float) * tie_breaker

    # Combine components: bias * random - idx_factor.
    scores[feasible] = bias[feasible] * rand[feasible] - idx_factor[feasible]

    return scores
```
