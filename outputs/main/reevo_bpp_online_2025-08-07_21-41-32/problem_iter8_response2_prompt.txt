{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Priority function for online Bin Packing.\n\n    Each feasible bin (i.e. a bin with enough remaining capacity) receives a\n    score that blends a tight\u2011fit bias with a random component.  The relative\n    weight of the bias adapts online based on the current packing situation:\n    when few bins can accommodate the item we trust the bias more (tight fit);\n    when many bins are feasible we rely more on randomness to explore diverse\n    placements.\n\n    Infeasible bins receive a score of -inf so they are never selected.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n    random_state : int, optional\n        Seed for reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better) for each bin.\n    \"\"\"\n    eps = 1e-12                     # avoid division by zero\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = caps.size\n\n    # Initialise all priorities to -inf (infeasible by default)\n    priorities = np.full(n_bins, -np.inf, dtype=float)\n\n    # Identify feasible bins\n    feasible = caps >= item\n    if not np.any(feasible):\n        # Nothing fits \u2013 return all -inf\n        return priorities\n\n    # Slack after placing the item in each feasible bin\n    slack = caps - item\n\n    # ---- 1. Tight\u2011fit bias -------------------------------------------------\n    # Bias is higher when the remaining slack is small.\n    bias = np.zeros_like(caps)\n    bias[feasible] = 1.0 / (slack[feasible] + eps)\n\n    # Normalise bias to the range [0, 1] for a fair combination with randomness.\n    max_bias = bias[feasible].max()\n    bias_norm = np.zeros_like(caps)\n    bias_norm[feasible] = bias[feasible] / (max_bias + eps)\n\n    # ---- 2. Random component -----------------------------------------------\n    rng = np.random.default_rng(random_state)\n    rand_scores = rng.random(n_bins)          # uniform [0, 1) for every bin\n\n    # ---- 3. Adaptive weighting -----------------------------------------------\n    # Weight of the tight\u2011fit bias depends on how many bins are feasible.\n    # Few feasible bins \u2192 high bias weight (focus on tight fit).\n    # Many feasible bins \u2192 lower bias weight (more exploration).\n    feasible_frac = feasible.sum() / n_bins          # \u2208 (0, 1]\n    w_bias = 1.0 - feasible_frac                      # larger when few bins fit\n\n    # Clamp the weight to avoid extreme domination of one term.\n    w_bias = np.clip(w_bias, 0.1, 0.9)\n\n    # ---- 4. Combine bias and randomness ---------------------------------------\n    # Linear blend of the two components for feasible bins.\n    combined = np.zeros_like(caps)\n    combined[feasible] = (\n        w_bias * bias_norm[feasible] + (1.0 - w_bias) * rand_scores[feasible]\n    )\n\n    # ---- 5. Tiny random tie\u2011breaker (numerical stability) --------------------\n    tie_eps = 1e-8\n    combined[feasible] += rng.random(combined[feasible].shape) * tie_eps\n\n    # Fill the output array\n    priorities[feasible] = combined[feasible]\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                tolerance: float = 1e-12, tie_breaker: float = 1e-12) -> np.ndarray:\n    \"\"\"\n    Deterministic priority function for the online Bin Packing Problem.\n\n    The priority scores favor bins that can accommodate the incoming item with\n    the smallest leftover capacity.  If multiple bins have the same leftover,\n    the one with the smallest original index receives the highest score.\n    Infeasible bins (those that cannot hold the item) are given ``-np.inf``.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    tolerance : float, optional\n        Numerical tolerance for feasibility checks.  A bin is considered\n        feasible if its remaining capacity is at least ``item - tolerance``.\n    tie_breaker : float, optional\n        Tiny positive value used to break ties deterministically.  It must\n        be smaller than the smallest meaningful leftover (e.g., ``tolerance``).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Higher values indicate more attractive\n        bins.  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Flatten the input to a 1\u2011D array of floats\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n\n    # Feasibility mask: bins that can hold the item within tolerance\n    feasible = caps >= (item - tolerance)\n\n    # Initialise priorities as -inf (infeasible bins)\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No bin can accommodate the item; return -inf array\n        return priorities\n\n    # Compute leftover capacity for feasible bins\n    leftover = caps[feasible] - item\n    # Clip tiny negatives caused by floating\u2011point errors to zero\n    leftover = np.maximum(leftover, 0.0)\n\n    # Indices of feasible bins (preserve original order)\n    idx = np.where(feasible)[0]\n\n    # Exact\u2011fit first: lower leftover => higher priority.\n    # Subtract a tiny index\u2011dependent term to break ties in favour of lower indices.\n    priorities[feasible] = -leftover - idx * tie_breaker\n\n    return priorities\n\n[Reflection]\nUse deterministic tight\u2011fit priority, simple index tie\u2011breaker, avoid random weighting, handle floating errors.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}