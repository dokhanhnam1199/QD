```python
import numpy as np
from typing import Optional


def priority_v2(
    item: float,
    bins_remain_cap: np.ndarray,
    low_percentile: float = 0.10,
    boost_factor: float = 5.0,
    random_state: Optional[int] = None,
) -> np.ndarray:
    """
    Priority function for the online Bin Packing Problem (BPP).

    For each existing bin a score is computed; the bin with the highest score
    is selected for the incoming ``item``.  The heuristic combines several
    ideas:

    1. **Inverse‑slack bias** – bins that would have less remaining capacity
       after placement receive a larger base score.
    2. **Low‑percentile slack boost** – bins whose post‑placement slack falls
       below ``low_percentile`` (default 10 %) are boosted, encouraging the
       algorithm to fill “almost full’’ bins.
    3. **Adaptive weighting** – the relative weight of the bias and the boost
       adapts to the current packing situation: when few bins can accommodate
       the item, the inverse‑slack bias dominates; when many bins are feasible,
       the boost gets a larger share.
    4. **Normalization** – deterministic components are normalised to the
       interval ``[0, 1]`` before blending, preserving ordering while keeping
       scores comparable across instances.
    5. **Tiny random tie‑breaker** – a minute random perturbation (≈1e‑8) breaks
       ties without affecting the deterministic ordering.

    Infeasible bins (those that cannot accommodate the item) receive
    ``-np.inf`` guaranteeing they are never chosen.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities for each bin.
    low_percentile : float, optional
        Percentile (in [0, 1]) used to define “almost full’’ bins.
        Default is ``0.10`` (10 %).
    boost_factor : float, optional
        Multiplier controlling the magnitude of the low‑percentile boost.
        Default is ``5.0``.
    random_state : int or None, optional
        Seed for reproducible random tie‑breaking.

    Returns
    -------
    np.ndarray
        1‑D array of priority scores (higher is better). Infeasible bins are
        marked with ``-np.inf``.
    """
    # ------------------------------------------------------------------
    # 0) Pre‑processing & feasibility mask
    # ------------------------------------------------------------------
    caps = np.asarray(bins_remain_cap, dtype=float).ravel()
    n_bins = caps.size

    # Edge case: no bins at all
    if n_bins == 0:
        return np.array([], dtype=float)

    # Slack after hypothetically placing the item
    slack = caps - item
    feasible = slack >= 0

    # Initialise all scores as -inf (infeasible)
    priorities = np.full(n_bins, -np.inf, dtype=float)

    # Early exit if nothing fits
    if not feasible.any():
        return priorities

    # ------------------------------------------------------------------
    # 1) Inverse‑slack bias (tight‑fit component)
    # ------------------------------------------------------------------
    slack_feas = slack[feasible]

    # Scale epsilon with typical slack magnitude to avoid division‑by‑zero
    mean_slack = np.mean(slack_feas)
    eps = max(1e-12, 1e-6 * mean_slack)

    inv_slack = 1.0 / (slack_feas + eps)          # larger when slack is smaller

    # Normalise to [0, 1]
    inv_slack_norm = inv_slack / (inv_slack.max() + eps)

    # ------------------------------------------------------------------
    # 2) Low‑percentile slack boost
    # ------------------------------------------------------------------
    low_percentile = np.clip(low_percentile, 0.0, 1.0)

    if slack_feas.size > 0:
        threshold = np.quantile(slack_feas, low_percentile)
    else:
        threshold = 0.0

    boost = np.zeros_like(slack_feas)
    low_mask = slack_feas <= threshold
    boost[low_mask] = boost_factor * (threshold - slack_feas[low_mask])

    # Normalise boost (if any boost is non‑zero)
    if boost.max() > eps:
        boost_norm = boost / (boost.max() + eps)
    else:
        boost_norm = boost  # all zeros

    # ------------------------------------------------------------------
    # 3) Adaptive weighting between bias and boost
    # ------------------------------------------------------------------
    feasible_frac = feasible.sum() / n_bins  # ∈ (0, 1]
    # Inverse‑slack gets more weight when few bins are feasible,
    # boost gets more weight when many bins are feasible.
    w_inv = 1.0 - feasible_frac
    w_boost = feasible_frac

    # Clamp weights to avoid domination of a single term
    w_inv = np.clip(w_inv, 0.1, 0.9)
    w_boost = 1.0 - w_inv

    # Weighted combination (still in [0, 1] because components are normalised)
    combined = w_inv * inv_slack_norm + w_boost * boost_norm

    # ------------------------------------------------------------------
    # 4) Normalisation of the combined score
    # ------------------------------------------------------------------
    combined_norm = combined / (combined.max() + eps)

    # ------------------------------------------------------------------
    # 5) Tiny random tie‑breaker
    # ------------------------------------------------------------------
    rng = np.random.default_rng(random_state)
    tie_eps = 1e-8
    jitter = tie_eps * rng.random(combined_norm.shape[0])

    final_score = combined_norm + jitter

    # ------------------------------------------------------------------
    # 6) Write back to full priorities array
    # ------------------------------------------------------------------
    priorities[feasible] = final_score

    return priorities
```
