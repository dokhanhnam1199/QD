Boost nearly‑full bins via exponential decay with adaptive epsilon; add tiny random tie‑breaker; avoid normalizing residuals.
Prefer inverse waste only; avoid complex normalisation, random noise; minimal tunable parameters.
Blend exact‑fit and worst‑fit, add lookahead and age, normalise, temperature‑scale, tune weights, add noise.
Favor deterministic exact‑fit with simple tie‑breakers; drop random, temperature, look‑ahead, age for speed and predictability.
Normalize leftover for tightness, penalise infeasible bins, add tiny bias, avoid heavy stats or randomness.
Prefer tight‑fit bias with modest random factor, adapt epsilon to slack, skip costly quantiles, keep computation linear.
Prioritize exact‑fit, deterministic tie‑breaking; keep heuristic simple, avoid extra weights, randomness, and look‑ahead.
Use adaptive exponential boost, tiny tie‑breaking noise; keep computation lightweight, avoid extra percentile/inverse‑slack calculations.
Prioritize exact fits, penalize leftover, use tiny deterministic tie‑breakers, avoid randomness.
Use adaptive epsilon, percentile‑based boost, inverse slack bias, and limited randomness for tie‑breaking.
