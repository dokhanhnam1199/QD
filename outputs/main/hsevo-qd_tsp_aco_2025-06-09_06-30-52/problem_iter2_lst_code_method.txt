{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 4th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 5th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 6th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 7th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 8th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 9th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 10th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP, version 2: A symphony of inverse distances,\n    node degrees, and a touch of gravitational potential.\n\n    This heuristic combines several factors to estimate the desirability of each edge:\n\n    1. Inverse Distance:  Shorter distances are more desirable.\n    2. Node Degree Penalty:  Penalizes edges connected to nodes with a high \"degree\"\n        (number of nearby nodes). This discourages premature closing of subtours.  We're\n        analogizing this to a high \"gravitational potential\" - nodes with too many\n        connections are avoided until absolutely necessary.\n    3. Global Average Distance: Uses the average distance in the matrix to normalize\n       the effect of very short and very long distances, making it scale-invariant.\n    4.  Add a small constant to avoid division by zero\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where distance_matrix[i, j]\n            is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n            represents the desirability score of including the corresponding edge\n            in the TSP tour. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0]) #Avoid including self-loops when computing the mean\n    small_constant = 1e-9  # Add to the denominator for stability\n\n    # Calculate \"node degree\" based on proximity. Number of other cities within\n    # certain threshold distance. The intuition here is nodes which are very central\n    # should not be immediately visited to prevent early sub-cycles.\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Node degree penalty is computed to suppress visiting very central nodes before necessary.\n                degree_penalty = (node_degrees[i] + node_degrees[j])  # Total degree of the two nodes\n                # Combine inverse distance with node degree penalty. The degree penalty is scaled with avg distance so that when average distance is large\n                # the suppression due to degree penalty is also large.\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0  # Self-loops are undesirable\n\n    return heuristics\n\n[Heuristics 11th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}