{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines inverse distance with node degree penalty to avoid subtours.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    avg_distance = np.mean(distance_matrix[distance_matrix != 0])\n    small_constant = 1e-9\n\n    node_degrees = np.sum(distance_matrix < avg_distance, axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_penalty = (node_degrees[i] + node_degrees[j])\n                heuristics[i, j] = (1 / (distance_matrix[i, j] + small_constant)) / (1 + (degree_penalty * (distance_matrix[i, j]/avg_distance)))\n            else:\n                heuristics[i, j] = 0\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic incorporates a node degree penalty and scaling by the average distance, along with a small constant to prevent division by zero, while the worst simply returns the inverse of the distance matrix. This suggests that considering node connectivity and normalizing distances are crucial for good performance.\nComparing (2nd) vs (17th), the only difference are the docstrings, imports and defined default values of `avg_distance_weight` and `small_constant`.\nComparing (13th) vs (17th), we see that the 13th heuristic adds a local search inspired factor and sparsification, alongside the node degree penalty of the 1st heuristic. The 17th heuristic only calculates the inverse of the distance matrix. This suggests that adding local search factors and sparsification will improve performance of the heuristic.\nComparing (1st) vs (13th), we see that 13th heuristic adjust node degree threshold to `avg_distance * 1.5`, adds an exponent to the degree penalty and calculates a local search inspired factor. After computing the heuristics matrix, the function sparsifies the matrix by setting the lower values to zero. The 1st heuristics only calculates a node degree penalty to discourage subtours.\n\nOverall: More sophisticated heuristics for the TSP consider not only the distance between nodes but also the network structure around each node and performs sparsification. Penalizing high-degree nodes and incorporating local search-inspired factors significantly improve the quality of the heuristic. Sparsification can help focusing the search on more promising edges.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's redefine \"Current self-reflection\" to be more effective for designing heuristics, keeping your generous tip in mind!\n\n*   **Keywords:** Iterative refinement, problem-specific knowledge, constraint integration, global perspective, solution landscape.\n*   **Advice:** Start with a basic heuristic, then iteratively refine it by incorporating constraints, considering global solution properties, and adapting based on the solution landscape.\n*   **Avoid:** Sole reliance on immediate edge costs, neglecting global solution structure, premature optimization, ignoring problem-specific insights.\n*   **Explanation:** Effective self-reflection means systematically improving a heuristic by learning from both successful and failed iterations, considering a broader context, and deeply understanding problem constraints.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}