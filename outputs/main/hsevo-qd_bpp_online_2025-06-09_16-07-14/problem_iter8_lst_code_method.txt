{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, iteration: int = 0, total_items: int = 0) -> np.ndarray:\n    \"\"\"Combines Gaussian fit, capacity ratio, and adaptive exploration for bin selection.\"\"\"\n\n    mu = item\n    sigma = item / 3.0  # Scale sigma relative to item size.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    ratios = item / (bins_remain_cap + 1e-9) # Add small value to avoid division by zero.\n    priorities = gaussian + 0.1 * (1 - ratios)  # Combine Gaussian and capacity ratio\n\n    # Adaptive exploration: Perturb priorities based on iteration and bin utilization.\n    # As we pack more items or iterate more, explore less.\n    exploration_factor = np.exp(-iteration / (total_items + 1e-9)) if total_items > 0 else 1.0\n\n    # Give a small bonus to almost full bins to encourage their use.\n    almost_full_bonus = np.where((bins_remain_cap - item) < 0.1 * item, 0.2, 0)\n    priorities += almost_full_bonus * exploration_factor\n\n    priorities[bins_remain_cap < item] = -np.inf  # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Gaussian fit and capacity ratio for bin selection.\"\"\"\n\n    mu = item\n    sigma = item / 3.0\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Combine Gaussian with capacity ratio. Add small value to prevent divide by zero.\n    ratios = item / (bins_remain_cap + 1e-9)\n    priorities = gaussian + 0.1 * (1 - ratios)\n\n    priorities[bins_remain_cap < item] = -np.inf # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, iteration: int = 0, total_items: int = 0) -> np.ndarray:\n    \"\"\"Combines Gaussian fit, capacity ratio, and adaptive exploration for bin selection.\"\"\"\n\n    mu = item\n    sigma = item / 3.0  # Scale sigma relative to item size.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    ratios = item / (bins_remain_cap + 1e-9) # Add small value to avoid division by zero.\n    priorities = gaussian + 0.1 * (1 - ratios)  # Combine Gaussian and capacity ratio\n\n    # Adaptive exploration: Perturb priorities based on iteration and bin utilization.\n    # As we pack more items or iterate more, explore less.\n    exploration_factor = np.exp(-iteration / (total_items + 1e-9)) if total_items > 0 else 1.0\n\n    # Give a small bonus to almost full bins to encourage their use.\n    almost_full_bonus = np.where((bins_remain_cap - item) < 0.1 * item, 0.2, 0)\n    priorities += almost_full_bonus * exploration_factor\n\n    priorities[bins_remain_cap < item] = -np.inf  # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, iteration: int = 0, total_items: int = 0) -> np.ndarray:\n    \"\"\"Combines Gaussian fit, capacity ratio, and adaptive exploration for bin selection.\"\"\"\n\n    mu = item\n    sigma = item / 3.0  # Scale sigma relative to item size.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    ratios = item / (bins_remain_cap + 1e-9) # Add small value to avoid division by zero.\n    priorities = gaussian + 0.1 * (1 - ratios)  # Combine Gaussian and capacity ratio\n\n    # Adaptive exploration: Perturb priorities based on iteration and bin utilization.\n    # As we pack more items or iterate more, explore less.\n    exploration_factor = np.exp(-iteration / (total_items + 1e-9)) if total_items > 0 else 1.0\n\n    # Give a small bonus to almost full bins to encourage their use.\n    almost_full_bonus = np.where((bins_remain_cap - item) < 0.1 * item, 0.2, 0)\n    priorities += almost_full_bonus * exploration_factor\n\n    priorities[bins_remain_cap < item] = -np.inf  # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, iteration: int = 0, total_items: int = 0) -> np.ndarray:\n    \"\"\"Combines Gaussian fit, capacity ratio, and adaptive exploration for bin selection.\"\"\"\n\n    mu = item\n    sigma = item / 3.0  # Scale sigma relative to item size.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    ratios = item / (bins_remain_cap + 1e-9) # Add small value to avoid division by zero.\n    priorities = gaussian + 0.1 * (1 - ratios)  # Combine Gaussian and capacity ratio\n\n    # Adaptive exploration: Perturb priorities based on iteration and bin utilization.\n    # As we pack more items or iterate more, explore less.\n    exploration_factor = np.exp(-iteration / (total_items + 1e-9)) if total_items > 0 else 1.0\n\n    # Give a small bonus to almost full bins to encourage their use.\n    almost_full_bonus = np.where((bins_remain_cap - item) < 0.1 * item, 0.2, 0)\n    priorities += almost_full_bonus * exploration_factor\n\n    priorities[bins_remain_cap < item] = -np.inf  # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                iteration: int = 0,\n                total_items: int = 0,\n                sigma_scale: float = 3.096158909764751,\n                capacity_ratio_weight: float = 0.040438168561486076,\n                almost_full_threshold: float = 0.1709950089505562,\n                almost_full_bonus_value: float = 0.1711699302240409,\n                exploration_decay_rate: float = 0.7339335860767795) -> np.ndarray:\n    \"\"\"Combines Gaussian fit, capacity ratio, and adaptive exploration for bin selection.\"\"\"\n\n    mu = item\n    sigma = item / sigma_scale  # Scale sigma relative to item size.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    ratios = item / (bins_remain_cap + 1e-9) # Add small value to avoid division by zero.\n    priorities = gaussian + capacity_ratio_weight * (1 - ratios)  # Combine Gaussian and capacity ratio\n\n    # Adaptive exploration: Perturb priorities based on iteration and bin utilization.\n    # As we pack more items or iterate more, explore less.\n    exploration_factor = np.exp(-iteration / (total_items + 1e-9)) if total_items > 0 else exploration_decay_rate\n\n    # Give a small bonus to almost full bins to encourage their use.\n    almost_full_bonus = np.where((bins_remain_cap - item) < almost_full_threshold * item, almost_full_bonus_value, 0)\n    priorities += almost_full_bonus * exploration_factor\n\n    priorities[bins_remain_cap < item] = -np.inf  # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function that combines Gaussian fit, capacity ratio, and a near-full bin reward.\n    Adaptively adjusts the Gaussian sigma based on item size, and incorporates a state-based perturbation.\n    \"\"\"\n\n    # Gaussian component, adaptive sigma\n    mu = item\n    sigma = item / 2.0  # Adjust sigma for sensitivity to bins close to item size.  Smaller sigma is more selective\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Capacity ratio component\n    ratios = item / (bins_remain_cap + 1e-9)\n    capacity_priority = 0.1 * (1 - ratios)\n\n    # Near-full bin reward: Increased probability for bins that, after packing, will be over 75% full\n    near_full_threshold = 0.25  # Bin must have remaining capacity within 25% of bin size after placement.  Higher values are more selective\n    near_full_reward = np.where(bins_remain_cap - item <= near_full_threshold, 0.5, 0)  # Stronger reward than capacity ratio\n\n    # Combine components\n    priorities = gaussian + capacity_priority + near_full_reward\n\n    # Never pick impossible bins\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    An enhanced priority function that combines Gaussian fit, capacity ratio, and a near-full bin reward.\n    Adaptively adjusts the Gaussian sigma based on item size, and incorporates a state-based perturbation.\n    \"\"\"\n\n    # Gaussian component, adaptive sigma\n    mu = item\n    sigma = item / 2.0  # Adjust sigma for sensitivity to bins close to item size.  Smaller sigma is more selective\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Capacity ratio component\n    ratios = item / (bins_remain_cap + 1e-9)\n    capacity_priority = 0.1 * (1 - ratios)\n\n    # Near-full bin reward: Increased probability for bins that, after packing, will be over 75% full\n    near_full_threshold = 0.25  # Bin must have remaining capacity within 25% of bin size after placement.  Higher values are more selective\n    near_full_reward = np.where(bins_remain_cap - item <= near_full_threshold, 0.5, 0)  # Stronger reward than capacity ratio\n\n    # Combine components\n    priorities = gaussian + capacity_priority + near_full_reward\n\n    # Never pick impossible bins\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigma_factor: float = 3.0790017642473013, perturbation_strength: float = 0.130191329542565) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a heuristic inspired by the curvature of spacetime. We prefer bins that\n    are 'just right' for the item, avoiding bins that are either too full or too empty.\n    This minimizes wasted space and overall bin usage. We use a Gaussian-like distribution\n    centered around the item size relative to the remaining capacity.  A small perturbation is also added based on remaining capacity to encourage filling more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sigma_factor: Factor to divide the item size by to get the standard deviation for the Gaussian distribution.\n        perturbation_strength: Strength of the perturbation based on remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    mu = item  # Ideal remaining capacity\n    sigma = item / sigma_factor # Standard deviation: smaller values means sharper peak. Prevents being too wide.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Perturbation based on remaining capacity (encourages filling more)\n    perturbation = perturbation_strength * (bins_remain_cap / np.max(bins_remain_cap))\n\n    priorities = gaussian + perturbation\n\n    #Avoid negative values\n    priorities[bins_remain_cap < item] = -np.inf # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigma_factor: float = 3.0790017642473013, perturbation_strength: float = 0.130191329542565) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a heuristic inspired by the curvature of spacetime. We prefer bins that\n    are 'just right' for the item, avoiding bins that are either too full or too empty.\n    This minimizes wasted space and overall bin usage. We use a Gaussian-like distribution\n    centered around the item size relative to the remaining capacity.  A small perturbation is also added based on remaining capacity to encourage filling more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sigma_factor: Factor to divide the item size by to get the standard deviation for the Gaussian distribution.\n        perturbation_strength: Strength of the perturbation based on remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    mu = item  # Ideal remaining capacity\n    sigma = item / sigma_factor # Standard deviation: smaller values means sharper peak. Prevents being too wide.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Perturbation based on remaining capacity (encourages filling more)\n    perturbation = perturbation_strength * (bins_remain_cap / np.max(bins_remain_cap))\n\n    priorities = gaussian + perturbation\n\n    #Avoid negative values\n    priorities[bins_remain_cap < item] = -np.inf # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigma_factor: float = 3.0790017642473013, perturbation_strength: float = 0.130191329542565) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a heuristic inspired by the curvature of spacetime. We prefer bins that\n    are 'just right' for the item, avoiding bins that are either too full or too empty.\n    This minimizes wasted space and overall bin usage. We use a Gaussian-like distribution\n    centered around the item size relative to the remaining capacity.  A small perturbation is also added based on remaining capacity to encourage filling more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sigma_factor: Factor to divide the item size by to get the standard deviation for the Gaussian distribution.\n        perturbation_strength: Strength of the perturbation based on remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    mu = item  # Ideal remaining capacity\n    sigma = item / sigma_factor # Standard deviation: smaller values means sharper peak. Prevents being too wide.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Perturbation based on remaining capacity (encourages filling more)\n    perturbation = perturbation_strength * (bins_remain_cap / np.max(bins_remain_cap))\n\n    priorities = gaussian + perturbation\n\n    #Avoid negative values\n    priorities[bins_remain_cap < item] = -np.inf # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigma_factor: float = 3.0790017642473013, perturbation_strength: float = 0.130191329542565) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a heuristic inspired by the curvature of spacetime. We prefer bins that\n    are 'just right' for the item, avoiding bins that are either too full or too empty.\n    This minimizes wasted space and overall bin usage. We use a Gaussian-like distribution\n    centered around the item size relative to the remaining capacity.  A small perturbation is also added based on remaining capacity to encourage filling more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sigma_factor: Factor to divide the item size by to get the standard deviation for the Gaussian distribution.\n        perturbation_strength: Strength of the perturbation based on remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    mu = item  # Ideal remaining capacity\n    sigma = item / sigma_factor # Standard deviation: smaller values means sharper peak. Prevents being too wide.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Perturbation based on remaining capacity (encourages filling more)\n    perturbation = perturbation_strength * (bins_remain_cap / np.max(bins_remain_cap))\n\n    priorities = gaussian + perturbation\n\n    #Avoid negative values\n    priorities[bins_remain_cap < item] = -np.inf # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigma_factor: float = 3.0790017642473013, perturbation_strength: float = 0.130191329542565) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a heuristic inspired by the curvature of spacetime. We prefer bins that\n    are 'just right' for the item, avoiding bins that are either too full or too empty.\n    This minimizes wasted space and overall bin usage. We use a Gaussian-like distribution\n    centered around the item size relative to the remaining capacity.  A small perturbation is also added based on remaining capacity to encourage filling more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sigma_factor: Factor to divide the item size by to get the standard deviation for the Gaussian distribution.\n        perturbation_strength: Strength of the perturbation based on remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    mu = item  # Ideal remaining capacity\n    sigma = item / sigma_factor # Standard deviation: smaller values means sharper peak. Prevents being too wide.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Perturbation based on remaining capacity (encourages filling more)\n    perturbation = perturbation_strength * (bins_remain_cap / np.max(bins_remain_cap))\n\n    priorities = gaussian + perturbation\n\n    #Avoid negative values\n    priorities[bins_remain_cap < item] = -np.inf # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigma_factor: float = 3.0790017642473013, perturbation_strength: float = 0.130191329542565) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a heuristic inspired by the curvature of spacetime. We prefer bins that\n    are 'just right' for the item, avoiding bins that are either too full or too empty.\n    This minimizes wasted space and overall bin usage. We use a Gaussian-like distribution\n    centered around the item size relative to the remaining capacity.  A small perturbation is also added based on remaining capacity to encourage filling more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sigma_factor: Factor to divide the item size by to get the standard deviation for the Gaussian distribution.\n        perturbation_strength: Strength of the perturbation based on remaining capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    mu = item  # Ideal remaining capacity\n    sigma = item / sigma_factor # Standard deviation: smaller values means sharper peak. Prevents being too wide.\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Perturbation based on remaining capacity (encourages filling more)\n    perturbation = perturbation_strength * (bins_remain_cap / np.max(bins_remain_cap))\n\n    priorities = gaussian + perturbation\n\n    #Avoid negative values\n    priorities[bins_remain_cap < item] = -np.inf # Never pick impossible bins.\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_utilization: np.ndarray = None, iteration: int = 0) -> np.ndarray:\n    \"\"\"\n    Adaptive heuristic that combines Gaussian fit, capacity ratio, and dynamic adjustment\n    based on bin utilization. Also incorporates the iteration number to adapt the exploration/exploitation.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    # Initialize bin utilization if not provided\n    if bin_utilization is None:\n        bin_utilization = np.zeros(num_bins)\n\n    # Adaptive Gaussian parameters based on item size and iteration\n    mu = item\n    # Adjust sigma based on the iteration number to control exploration/exploitation\n    # Earlier iterations have larger sigma for exploration\n    sigma = item / (2.0 + iteration/100)  # Reduce sigma over time\n\n    gaussian = np.exp(-((bins_remain_cap - mu) ** 2) / (2 * sigma**2))\n\n    # Capacity ratio with a small value to prevent division by zero\n    ratios = item / (bins_remain_cap + 1e-9)\n\n    # Dynamic adjustment based on bin utilization.\n    # Penalize bins with high utilization to encourage even packing.\n    utilization_penalty = bin_utilization # Scale as needed\n\n    # Combine Gaussian, capacity ratio, and utilization penalty\n    priorities = gaussian + 0.1 * (1 - ratios) - 0.05 * utilization_penalty # Further weight adjustments might be needed\n\n    # Aggressively enforce feasibility: never pick impossible bins\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Prioritize bins that are almost full (but can still fit the item)\n    almost_full_bonus = np.where((bins_remain_cap >= item) & (bins_remain_cap <= 1.1 * item), 0.2, 0) #The 1.1 factor allows for some fuzziness in the \"almost full\" definition\n    priorities += almost_full_bonus\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}