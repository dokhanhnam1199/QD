{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive epsilon\u2011greedy best\u2011fit priority with near\u2011full boost and infeasibility handling.\"\"\"\n    if not hasattr(priority_v2, \"_epsilon\"):\n        priority_v2._epsilon = 0.2\n        priority_v2._epsilon_min = 0.01\n        priority_v2._epsilon_decay = 0.995\n        priority_v2._step = 0\n    priority_v2._step += 1\n    priority_v2._epsilon = max(priority_v2._epsilon_min, priority_v2._epsilon * priority_v2._epsilon_decay)\n    n = bins_remain_cap.size\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    valid = bins_remain_cap >= item\n    if not np.any(valid):\n        return priorities\n    slack = bins_remain_cap[valid] - item\n    base_priority = -slack\n    near_full_thresh = max(0.02, 0.05 * item)\n    boost = 0.5\n    base_priority[slack <= near_full_thresh] += boost\n    priorities[valid] = base_priority\n    if np.random.rand() < priority_v2._epsilon:\n        rand_scores = np.random.rand(n)\n        rand_scores[~valid] = -np.inf\n        priorities = rand_scores\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Best\u2011fit with small \u03b5\u2011greedy exploration and item\u2011scaled near\u2011full boost.\"\"\"\n    epsilon = 0.1\n    boost = 0.5\n    near_full_thresh = max(0.02, 0.05 * item)\n    feasible = bins_remain_cap >= item\n    n = bins_remain_cap.shape[0]\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    slack = bins_remain_cap[feasible] - item\n    base = -slack\n    near_full = slack <= near_full_thresh\n    base[near_full] += boost\n    scores[feasible] = base\n    if np.random.rand() < epsilon:\n        rand_scores = np.random.rand(n)\n        rand_scores[~feasible] = -np.inf\n        scores = rand_scores\n    return scores\n\n### Analyze & experience\n- Comparing Heuristic\u202f1 (adaptive \u03b5\u2011greedy with decay, near\u2011full boost, clear docstring) vs Heuristic\u202f20 (static \u03b5\u2011greedy, only a near\u2011full boost, generic docstring) shows the impact of adaptive exploration: \u03b5 decays over time, reducing random moves, while Heuristic\u202f20\u2019s \u03b5 stays fixed, leading to unnecessary randomness. Heuristic\u202f1 uses `-np.inf` for infeasible bins, whereas Heuristic\u202f20 uses an arbitrary huge negative sentinel, making infeasibility handling less clean.  \n\nHeuristic\u202f2 is identical to Heuristic\u202f1; the ranking discrepancy likely reflects non\u2011code factors (e.g., runtime overhead) rather than functionality.  \n\nHeuristic\u202f3 employs a simple linear penalty (`-slack`) and computes \u03b5 as `0.05\u202f\u00d7\u202f(1\u202f\u2013\u202fvalid_count/n)`. It lacks a docstring and only adds a tiny random boost, so its guidance is weak. In contrast, Heuristics\u202f4\u20116 contain many unused imports, an enormous default priority (`-5.857e11`), and a high \u03b5\u2011factor (~0.82). Their docstrings mention \u201cepsilon_factor\u201d and \u201ctie_breaker,\u201d but the parameters are arbitrarily large, causing excessive randomness and poorer deterministic decisions.  \n\nHeuristics\u202f7\u20119 use inverse\u2011slack (`1/(slack+\u03b5)`) with a fixed \u03b5\u2011greedy fallback (0.1). They have no near\u2011full or exact\u2011fit boosts, making them less discriminative. Heuristic\u202f10 introduces a smooth boost `0.5/(slack+tiny)` capped at\u202f5, adds jitter, and uses a modest \u03b5\u202f=\u202f0.05 fallback. Its docstring explicitly cites \u201cbest\u2011fit, smooth tightness boost, jitter,\u201d yielding finer granularity and better tie\u2011breaking than Heuristics\u202f7\u20119.  \n\nComparing Heuristic\u202f10 with Heuristic\u202f11 (inverse\u2011slack plus step\u2011wise boosts) highlights that a continuous boost (10) provides smoother ranking than the step\u2011wise 0.5 boost and exact\u2011fit boost of\u202f2.0 in\u202f11. Both use \u03b5\u2011greedy, but only\u202f10 adds jitter, reducing lock\u2011in on equal scores.  \n\nHeuristic\u202f15 adds an exact\u2011fit boost (1.0) and a fixed near\u2011full threshold (0.05) on top of a static \u03b5\u202f=\u202f0.1. Heuristic\u202f16 refines this by separating a relative factor (0.05\u202f\u00d7\u202fitem) and an absolute floor (0.02), and uses `np.isclose` for exact fits. This extra flexibility improves handling of varied item sizes, explaining why\u202f16 outranks\u202f15.  \n\nHeuristic\u202f18 (and duplicates\u202f19\u201120) omit the exact\u2011fit boost altogether and rely solely on a near\u2011full boost, with a static \u03b5. The lack of adaptive \u03b5 decay and smoother boosting makes it the weakest among the best\u2011fit family.  \n\nOverall, the ranking reflects three clear design trends: (1) adaptive \u03b5\u2011decay outperforms static \u03b5; (2) smooth, continuous slack\u2011based boosts with jitter dominate step\u2011wise or purely inverse\u2011slack scores; (3) concise code, purposeful imports, and well\u2011written docstrings correlate with higher ranks, while redundant imports and arbitrary large constants penalize lower ranks.\n- \n- **Keywords:** static\u202f\u03b5, normalized slack ratio, implicit infeasibility, stateless, softmax selection  \n- **Advice:** Use a constant small\u202f\u03b5 for occasional random picks, score each item as (capacity\u2011slack)/capacity, turn scores into probabilities via a softmax, and keep functions pure with no extra parameters.  \n- **Avoid:** per\u2011iteration \u03b5 adjustments, custom near\u2011full bonuses, jitter, stateful objects, explicit infeasibility flags, multiplicative or additive boost terms, random mixing per element, over\u2011parameterized designs.  \n- **Explanation:** These choices keep the heuristic transparent, limit hidden bias, ensure reproducibility and generality, and focus the search on true capacity efficiency without fragile problem\u2011specific tricks.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}