{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Simple epsilon\u2011greedy best\u2011fit with additive near\u2011full boost.\n    \"\"\"Static epsilon\u2011greedy best\u2011fit priority with near\u2011full boost and -inf for infeasible bins.\"\"\"\n    epsilon = 0.1\n    n = bins_remain_cap.size\n    priorities = np.full(n, -np.inf, dtype=float)\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return priorities\n    slack = bins_remain_cap[feasible] - item\n    scores = -slack\n    near_full_thresh = max(0.02, 0.05 * item)\n    boost = 0.5\n    scores[slack <= near_full_thresh] += boost\n    priorities[feasible] = scores\n    if np.random.rand() < epsilon:\n        rand = np.random.rand(n)\n        rand[~feasible] = -np.inf\n        priorities = rand\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.9825005672646011,\n                near_full_abs_thresh: float = 0.10978901021995602,\n                near_full_factor: float = 0.052058968616339074,\n                exact_fit_boost: float = 9.449197182550307,\n                near_full_boost: float = 8.679489449768846) -> np.ndarray:\n    \"\"\"Best\u2011fit scoring with \u03b5\u2011greedy exploration and near\u2011full, exact\u2011fit boosts.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to pack.\n    bins_remain_cap : np.ndarray\n        Remaining capacity of each bin.\n    epsilon : float, optional\n        Exploration probability for \u03b5\u2011greedy selection.\n    near_full_abs_thresh : float, optional\n        Minimum absolute slack threshold for near\u2011full boost.\n    near_full_factor : float, optional\n        Relative factor of item size to compute near\u2011full slack threshold.\n    exact_fit_boost : float, optional\n        Boost added to bins where slack is exactly zero.\n    near_full_boost : float, optional\n        Boost added to bins where slack is less than or equal to the near\u2011full threshold.\n    \"\"\"\n    n = bins_remain_cap.size\n    scores = np.full(n, -np.inf, dtype=float)\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return scores\n\n### Analyze & experience\n- Comparing #1 vs #20, we see that #1's adaptive \u03b5\u2011decay, inverse\u2011slack scoring, and item\u2011specific near\u2011full/exact\u2011fit boosts provide a balanced exploration\u2013exploitation trade\u2011off, while #20's static high \u03b5, linear slack scoring, and global capacity threshold lead to excessive randomness and suboptimal bin selection;  \nComparing #2 vs #19, #2 is identical to the best heuristic, whereas #19 is incomplete (missing return), so #2 clearly outperforms;  \nComparing #1 vs #2, they are functionally identical, yielding no performance difference;  \nComparing #3 vs #4, both use fixed \u03b5\u202f=\u202f0.1, \u2013slack scoring with equal near\u2011full and exact\u2011fit boosts, so no difference;  \nComparing #19 vs #20, #20, though fully implemented, still suffers from high \u03b5 and a less adaptive threshold; #19 is broken, making #20 the worst among the working heuristics;  \nOverall: the ranking reflects a progression from simple, static scoring to adaptive, inverse\u2011slack scoring with item\u2011specific boosts, and the worst heuristics lack adaptive behavior or are incomplete.\n- \n- **Keywords:** adaptive exploration, capacity\u2011aware scoring, infeasibility\u2011aware scoring, minimalistic design.  \n- **Advice:** Employ context\u2011sensitive scoring that rewards fits close to capacity, use a simple exploration scheme that gradually reduces randomness, design clear penalties that avoid masking infeasibility, and avoid worst\u2011fit or unnormalized random scoring. Keep parameters small and code modular to reduce duplication.  \n- **Avoid:** dynamic \u03b5\u2011decay, explicit infeasibility marking, problem\u2011specific boosts, static duplicated code, stateful parameters, over\u2011parameterization, multiplicative boosts, per\u2011element random mixing.  \n- **Explanation:** These practices obfuscate intent, create maintenance burdens, and can hurt performance by over\u2011tuning or poorly penalizing infeasible moves.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}