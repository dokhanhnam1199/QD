{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Compute priority scores for bins: best\u2011fit (-slack) with near\u2011full and exact\u2011fit bonuses, decaying \u03b5\u2011greedy exploration and tiny jitter.\"\"\"\n    # Initialize static \u03b5\u2011greedy parameters on first call\n    if not hasattr(priority_v2, \"_epsilon\"):\n        priority_v2._epsilon = 0.2\n        priority_v2._epsilon_min = 0.01\n        priority_v2._epsilon_decay = 0.995\n        priority_v2._step = 0\n    # Update \u03b5\n    priority_v2._step += 1\n    priority_v2._epsilon = max(priority_v2._epsilon_min,\n                               priority_v2._epsilon * priority_v2._epsilon_decay)\n    n = bins_remain_cap.size\n    # Default to -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return priorities\n    slack = bins_remain_cap[feasible] - item\n    base = -slack\n    # Near\u2011full boost\n    near_full_thresh = max(0.02, 0.05 * item)\n    base[slack <= near_full_thresh] += 0.5\n    # Exact\u2011fit boost\n    base[slack <= 1e-9] += 1.0\n    # Tiny jitter to break ties\n    base += 1e-6 * np.random.rand(base.size)\n    priorities[feasible] = base\n    # \u03b5\u2011greedy random exploration\n    if np.random.rand() < priority_v2._epsilon:\n        rand_scores = np.random.rand(n)\n        rand_scores[~feasible] = -np.inf\n        priorities = rand_scores\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    item: float,\n    bins_remain_cap: np.ndarray,\n    boost_factor: float = 0.7616942763907281,\n    max_boost: float = 5.806140777564599,\n    tiny: float = 0.00034508672935174283,\n    ratio_weight: float = 0.5247167888808204,\n    eps_base: float = 0.08986838647668337,\n    tie_breaker_boost: float = 0.000340990722271134,\n) -> np.ndarray:\n    \"\"\"Combines best\u2011fit slack with item\u2011to\u2011bin ratio, adaptive \u03b5\u2011greedy, and tie\u2011breaker.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacity of each bin.\n    boost_factor : float, optional\n        Weight for the slack\u2011based boost (default 0.5).\n    max_boost : float, optional\n        Upper bound for the boost term (default 5.0).\n    tiny : float, optional\n        Small constant to avoid division\u2011by\u2011zero (default 1e-6).\n    ratio_weight : float, optional\n        Weight applied to the item\u2011to\u2011bin ratio term (default 0.1).\n    eps_base : float, optional\n        Base factor for the adaptive \u03b5\u2011greedy probability (default 0.05).\n    tie_breaker_boost : float, optional\n        Small boost added when the \u03b5\u2011greedy path is taken (default 1e-3).\n\n    Returns\n    -------\n    np.ndarray\n        Scores for each bin (``-inf`` for infeasible bins).\n    \"\"\"\n    n = bins_remain_cap.size\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        return scores\n\n### Analyze & experience\n- - **(Best) vs (Worst) \u2013 #1 vs #5**  \n  *#1* implements an *adaptive \u03b5\u2011greedy best\u2011fit* policy: it initializes static \u03b5 parameters, decays \u03b5 each call, computes `-slack` as the deterministic score, adds a `+0.5` boost for bins whose slack \u2264\u202f`max(0.02,\u202f0.05\u00b7item)`, and falls back to a full\u2011random ranking with probability\u202f\u03b5. It also returns `-inf` for infeasible bins.  \n  *#5* merely returns `item / bins_remain_cap` (or `-inf`) \u2013 no slack, no near\u2011full or exact\u2011fit bonuses, no exploration, and no tie\u2011breaking. The scoring is far less discriminative.\n\n- **(Second best) vs (Second worst) \u2013 #2 vs #8**  \n  *#2* is a verbatim copy of #1, inheriting the same robust design.  \n  *#8* repeats #5\u2019s naive ratio heuristic, offering no adaptive behavior or bonuses, thus clearly inferior.\n\n- **(1st) vs (2nd) \u2013 #1 vs #2**  \n  The two functions are byte\u2011for\u2011byte identical; there is no functional improvement, indicating redundancy rather than a true progression.\n\n- **(3rd) vs (4th) \u2013 #3 vs #4**  \n  *#3* normalizes slack (`-slack / bins_remain_cap`), adds a tiny random noise term, uses `np.isclose` for exact fits, and computes \u03b5 as `0.05\u00b7(1\u2011feasible/n)`. It contains dead code (`np.random0`) and a convoluted epsilon scheme, making it brittle.  \n  *#4* cleanly computes `-slack`, applies a capped boost `min(boost_factor/(slack+tiny), max_boost)`, adds a modest ratio weight (`0.1\u00b7ratio`), and sets \u03b5 based on the feasible\u2011bin proportion. The implementation is clearer, more stable, and mathematically grounded.\n\n- **(Second worst) vs (Worst) \u2013 #8 vs #18**  \n  *#8* repeats the simple ratio approach of #5.  \n  *#18* defines many hyper\u2011parameters and a detailed docstring but aborts after checking feasibility, never assigning scores. It is the least functional of the set.\n\n- **Overall**  \n  The top\u2011ranked heuristics (#1, #2, #4, #6, #9\u2011#17) share key strengths:  \n  1. **Feasibility masking** (`bins_remain_cap >= item`) with `-inf` for infeasible bins.  \n  2. **Deterministic best\u2011fit core** (`-slack`).  \n  3. **Near\u2011full / exact\u2011fit bonuses** (e.g., `+0.5` for small slack, `+1.0` for exact fits).  \n  4. **Adaptive \u03b5\u2011greedy exploration**, often with decay (`\u03b5 = max(\u03b5_min, \u03b5\u00b7decay)`).  \n  5. **Tiny jitter** (`1e\u20116\u00b7rand`) to break ties.  \n  Lower\u2011ranked versions either omit these mechanisms, contain bugs (dead code, undefined symbols), or are incomplete.\n- \n- **Keywords:** best\u2011fit core, capacity\u2011ratio scoring, deterministic selection, look\u2011ahead pruning, vectorized updates, clear documentation.  \n- **Advice:** Use a static capacity\u2011ratio score (item size\u202f/\u202fremaining bin space), apply a simple deterministic tie\u2011breaker, incorporate a one\u2011step look\u2011ahead to reject moves that create dead\u2011space, keep implementation fully vectorized the code and comment intent.  \n- **Avoid:** Adaptive \u03b5\u2011decay, jitter, near\u2011full/exact\u2011fit bonuses, multiplicative boosts, per\u2011item random mixing, stateful parameters, explicit infeasibility masks, heavy softmax, over\u2011parameterization.  \n- **Explanation:** This yields transparent, fast heuristics with minimal hyper\u2011parameters, reduces hidden bias, and eases maintenance while still guiding items toward tight fits.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}