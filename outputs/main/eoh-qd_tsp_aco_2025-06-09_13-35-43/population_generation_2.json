[
     {
          "algorithm": "This algorithm estimates edge inclusion probabilities for TSP by sampling near-optimal solutions using a nearest neighbor heuristic with restarts and accumulating edge frequencies.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm estimates edge inclusion probabilities for TSP by sampling near-optimal solutions using a nearest neighbor heuristic with restarts and accumulating edge frequencies.}\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    num_samples = 100\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        current_node = start_node\n        unvisited = set(range(n))\n        unvisited.remove(current_node)\n        path = [current_node]\n        path_length = 0\n\n        while unvisited:\n            nearest_neighbor = -1\n            min_distance = np.inf\n            for neighbor in unvisited:\n                distance = distance_matrix[current_node, neighbor]\n                if distance < min_distance:\n                    min_distance = distance\n                    nearest_neighbor = neighbor\n\n            path.append(nearest_neighbor)\n            path_length += min_distance\n            unvisited.remove(nearest_neighbor)\n            current_node = nearest_neighbor\n\n        path.append(start_node)\n        path_length += distance_matrix[current_node, start_node]\n\n        # Accumulate edge frequencies for this sample\n        for i in range(n):\n            node1 = path[i]\n            node2 = path[i+1]\n            heuristics_matrix[node1, node2] += 1\n            heuristics_matrix[node2, node1] += 1\n\n    heuristics_matrix /= num_samples\n\n    return heuristics_matrix",
          "objective": 6.20794,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm samples multiple tours using a nearest neighbor heuristic with random starting nodes and edge selection probabilities inversely proportional to edge distances, then averages the frequency of each edge appearing in the sampled tours to create a heuristic matrix.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples multiple tours using a nearest neighbor heuristic with random starting nodes and edge selection probabilities inversely proportional to edge distances, then averages the frequency of each edge appearing in the sampled tours to create a heuristic matrix.}\"\"\"\n    num_nodes = distance_matrix.shape[0]\n    num_samples = 1000\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(num_nodes)\n        current_node = start_node\n        unvisited_nodes = set(range(num_nodes))\n        unvisited_nodes.remove(current_node)\n        tour = [current_node]\n\n        while unvisited_nodes:\n            probabilities = np.zeros(num_nodes)\n            for neighbor in unvisited_nodes:\n                probabilities[neighbor] = 1 / (distance_matrix[current_node, neighbor] + 1e-6)  # Avoid division by zero\n            \n            probabilities /= np.sum(probabilities)\n            \n            next_node = np.random.choice(num_nodes, p=probabilities)\n            if next_node not in unvisited_nodes:\n                possible_next_nodes = list(unvisited_nodes)\n                if not possible_next_nodes:\n                    break\n                next_node = possible_next_nodes[0]  # Fallback: pick the first if sampled node is not in unvisited anymore.\n                \n            \n            tour.append(next_node)\n            unvisited_nodes.remove(next_node)\n            current_node = next_node\n        \n        tour.append(start_node)  # Return to the starting node\n        \n        for i in range(len(tour) - 1):\n            node1 = tour[i]\n            node2 = tour[i+1]\n            heuristics_matrix[node1, node2] += 1\n            heuristics_matrix[node2, node1] += 1\n\n    heuristics_matrix /= num_samples\n    return heuristics_matrix",
          "objective": 6.97309,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm samples potential TSP solutions using a nearest neighbor heuristic with probabilistic selection based on edge distances, iteratively refining edge importance scores.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples potential TSP solutions using a nearest neighbor heuristic with probabilistic selection based on edge distances, iteratively refining edge importance scores.}\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros((n, n))\n    num_samples = 100\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        current_node = start_node\n        unvisited = set(range(n))\n        unvisited.remove(current_node)\n        path = [current_node]\n\n        while unvisited:\n            distances = distance_matrix[current_node, :]\n            probabilities = 1 / (distances + 1e-6)  # Avoid division by zero\n            probabilities[current_node] = 0\n            probabilities = probabilities / np.sum(probabilities) # Normalize probabilities\n            \n            next_node = np.random.choice(n, p=probabilities) # Stochastic Sampling\n            while next_node not in unvisited:\n              probabilities[next_node] = 0\n              if np.sum(probabilities) == 0:\n                next_node = np.random.choice(list(unvisited))\n                break\n              probabilities = probabilities / np.sum(probabilities)\n              next_node = np.random.choice(n, p=probabilities)\n            \n            if next_node in unvisited:\n                heuristics_matrix[current_node, next_node] += 1\n                heuristics_matrix[next_node, current_node] += 1\n                current_node = next_node\n                path.append(current_node)\n                unvisited.remove(current_node)\n\n        heuristics_matrix[current_node, start_node] += 1\n        heuristics_matrix[start_node, current_node] += 1\n\n    return heuristics_matrix",
          "objective": 7.82994,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm constructs a heuristic matrix by iteratively sampling solutions using a nearest neighbor approach with stochastic perturbations and then aggregating the edge frequencies across sampled solutions.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm constructs a heuristic matrix by iteratively sampling solutions using a nearest neighbor approach with stochastic perturbations and then aggregating the edge frequencies across sampled solutions.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 100\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        unvisited = set(range(n))\n        unvisited.remove(start_node)\n        current_node = start_node\n        path = [start_node]\n        \n        while unvisited:\n            distances = distance_matrix[current_node, :]\n            \n            # Find nearest neighbors from unvisited nodes\n            nearest_neighbors = []\n            for neighbor in unvisited:\n                nearest_neighbors.append((neighbor, distances[neighbor]))\n            nearest_neighbors.sort(key=lambda x: x[1])  # Sort by distance\n\n            # Apply stochastic perturbation: select from top k nearest neighbors\n            k = min(5, len(nearest_neighbors))  # Limit the choice\n            \n            selected_neighbors = nearest_neighbors[:k]\n\n            # Choose a neighbor randomly from the selected ones\n            \n            neighbor_idx = np.random.randint(len(selected_neighbors))\n            next_node = selected_neighbors[neighbor_idx][0]\n            \n\n            path.append(next_node)\n            unvisited.remove(next_node)\n            \n            heuristics_matrix[current_node, next_node] += 1\n            heuristics_matrix[next_node, current_node] += 1\n\n            current_node = next_node\n        \n        heuristics_matrix[current_node, start_node] += 1\n        heuristics_matrix[start_node, current_node] += 1\n\n\n    heuristics_matrix = heuristics_matrix / num_samples\n    return heuristics_matrix",
          "objective": 7.90544,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm samples TSP solutions by repeatedly selecting edges with probabilities biased by edge distance and a pheromone-like reinforcement, and uses the observed edge frequency as heuristics.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples TSP solutions by repeatedly selecting edges with probabilities biased by edge distance and a pheromone-like reinforcement, and uses the observed edge frequency as heuristics.}\"\"\"\n    n = len(distance_matrix)\n    heuristics_matrix = np.zeros((n, n))\n    num_samples = 1000\n    pheromone = np.ones((n, n))  # Initialize pheromone trails\n\n    for _ in range(num_samples):\n        current_node = np.random.randint(n)\n        unvisited_nodes = set(range(n))\n        unvisited_nodes.remove(current_node)\n        path = [current_node]\n\n        while unvisited_nodes:\n            probabilities = np.zeros(n)\n            for neighbor in unvisited_nodes:\n                probabilities[neighbor] = (pheromone[current_node, neighbor] / distance_matrix[current_node, neighbor])\n\n            probabilities = probabilities / np.sum(probabilities)\n\n            next_node = np.random.choice(n, p=probabilities)\n\n            if next_node not in unvisited_nodes:\n                available_nodes = list(unvisited_nodes)\n                if len(available_nodes) > 0:\n                    next_node = available_nodes[np.argmin([distance_matrix[current_node, node] for node in available_nodes])]\n                else:\n                    next_node = current_node # Back to start\n                \n            path.append(next_node)\n            unvisited_nodes.remove(next_node)\n            heuristics_matrix[current_node, next_node] += 1\n            heuristics_matrix[next_node, current_node] += 1\n\n            current_node = next_node\n        \n        # Return to the starting node\n        heuristics_matrix[current_node, path[0]] += 1\n        heuristics_matrix[path[0], current_node] += 1\n        path.append(path[0])\n\n        # Pheromone update\n        path_length = 0\n        for i in range(len(path) - 1):\n            path_length += distance_matrix[path[i], path[i+1]]\n        \n        for i in range(len(path) - 1):\n            pheromone[path[i], path[i+1]] = (1 - 0.1) * pheromone[path[i], path[i+1]] + 0.1 * (1 / path_length)\n            pheromone[path[i+1], path[i]] = pheromone[path[i], path[i+1]]\n\n\n    return heuristics_matrix",
          "objective": 8.43571,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm constructs a heuristic matrix by assigning higher probabilities to shorter edges and edges that connect nodes with fewer close neighbors, then refines these probabilities by iteratively sampling solutions and updating edge scores based on their frequency in good solutions.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm constructs a heuristic matrix by assigning higher probabilities to shorter edges and edges that connect nodes with fewer close neighbors, then refines these probabilities by iteratively sampling solutions and updating edge scores based on their frequency in good solutions.}\n    \"\"\"\n    n = len(distance_matrix)\n    heuristics_matrix = np.zeros((n, n))\n\n    # Initial heuristic based on distance and node degree\n    for i in range(n):\n        for j in range(i + 1, n):\n            distance = distance_matrix[i, j]\n            \n            # Calculate a score based on inverse distance\n            heuristics_matrix[i, j] = heuristics_matrix[j, i] = 1 / (distance + 1e-9) \n\n    # Node degree adjustment - penalize nodes with many very close neighbors\n    for i in range(n):\n        close_neighbors = 0\n        for j in range(n):\n            if i != j and distance_matrix[i, j] < np.mean(distance_matrix):\n                close_neighbors += 1\n        \n        for j in range(n):\n            if i != j:\n                heuristics_matrix[i, j] /= (close_neighbors + 1)\n                heuristics_matrix[j, i] /= (close_neighbors + 1)\n    \n    # Normalize heuristics to probabilities (initially)\n    for i in range(n):\n        row_sum = np.sum(heuristics_matrix[i, :])\n        if row_sum > 0:\n            heuristics_matrix[i, :] /= row_sum\n\n    # Iterative sampling and refinement\n    num_iterations = 10\n    num_samples = 50\n    \n    edge_counts = np.zeros((n, n))\n\n    for _ in range(num_iterations):\n        solutions = []\n        costs = []\n\n        # Sample solutions using the current heuristics\n        for _ in range(num_samples):\n            current_node = np.random.randint(n)\n            tour = [current_node]\n            unvisited = set(range(n))\n            unvisited.remove(current_node)\n\n            while unvisited:\n                probabilities = heuristics_matrix[current_node, :]\n                probabilities = np.array([probabilities[i] if i in unvisited else 0 for i in range(n)])\n                \n                if np.sum(probabilities) == 0:\n                    next_node = min(unvisited, key=lambda x: distance_matrix[current_node, x])\n                else:\n                    probabilities /= np.sum(probabilities)\n                    next_node = np.random.choice(n, p=probabilities)\n                    while next_node not in unvisited:\n                        probabilities[next_node] = 0\n                        if np.sum(probabilities) == 0:\n                            next_node = min(unvisited, key=lambda x: distance_matrix[current_node, x])\n                            break\n                        probabilities /= np.sum(probabilities)\n                        next_node = np.random.choice(n, p=probabilities)\n\n                tour.append(next_node)\n                unvisited.remove(next_node)\n                current_node = next_node\n\n            tour.append(tour[0])  # Return to start\n\n            # Calculate cost\n            cost = 0\n            for i in range(n):\n                cost += distance_matrix[tour[i], tour[i+1]]\n            \n            solutions.append(tour)\n            costs.append(cost)\n\n        # Update edge counts based on good solutions\n        threshold = np.mean(costs)  # Consider solutions better than the average\n\n        for i in range(num_samples):\n            if costs[i] <= threshold:\n                tour = solutions[i]\n                for j in range(n):\n                    node1 = tour[j]\n                    node2 = tour[j+1]\n                    edge_counts[node1, node2] += 1\n                    edge_counts[node2, node1] += 1\n\n        # Update heuristics based on edge counts\n        for i in range(n):\n            for j in range(i + 1, n):\n                heuristics_matrix[i, j] = heuristics_matrix[j, i] = edge_counts[i, j] + 1e-9\n        \n        # Normalize heuristics to probabilities\n        for i in range(n):\n            row_sum = np.sum(heuristics_matrix[i, :])\n            if row_sum > 0:\n                heuristics_matrix[i, :] /= row_sum\n                \n    return heuristics_matrix",
          "objective": 9.0392,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm samples many random tours, and for each edge, records how often it appears in the best tours found; edges appearing more frequently in short tours are given higher heuristic scores.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples many random tours, and for each edge, records how often it appears in the best tours found; edges appearing more frequently in short tours are given higher heuristic scores.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    top_k = 100\n\n    edge_counts = np.zeros_like(distance_matrix, dtype=int)\n\n    for _ in range(num_samples):\n        permutation = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[permutation[i], permutation[i+1]]\n        tour_length += distance_matrix[permutation[-1], permutation[0]]\n\n        # Store the tour and its length\n        if _ == 0:\n            top_tours = [(permutation, tour_length)]\n        else:\n            # Insert the current tour if it's better than the worst in top_tours\n            if tour_length < max([t[1] for t in top_tours]):\n                top_tours.append((permutation, tour_length))\n                top_tours = sorted(top_tours, key=lambda x: x[1])\n                if len(top_tours) > top_k:\n                    top_tours = top_tours[:top_k]\n\n    # Count edge occurrences in the top tours\n    for permutation, _ in top_tours:\n        for i in range(n - 1):\n            u, v = permutation[i], permutation[i+1]\n            edge_counts[u, v] += 1\n            edge_counts[v, u] += 1\n        u, v = permutation[-1], permutation[0]\n        edge_counts[u, v] += 1\n        edge_counts[v, u] += 1\n    \n    # Normalize the edge counts to create the heuristics matrix\n    heuristics_matrix = edge_counts / np.max(edge_counts) if np.max(edge_counts) > 0 else edge_counts\n    \n    return heuristics_matrix",
          "objective": 14.73107,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm samples multiple random tours, and for each edge, it counts how often it appears in the shortest tours among the samples, using the inverse rank of tour lengths as probabilities.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples multiple random tours, and for each edge, it counts how often it appears in the shortest tours among the samples, using the inverse rank of tour lengths as probabilities.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    sampled_tours = []\n    tour_lengths = []\n\n    for _ in range(num_samples):\n        tour = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n):\n            tour_length += distance_matrix[tour[i], tour[(i + 1) % n]]\n        sampled_tours.append(tour)\n        tour_lengths.append(tour_length)\n\n    ranked_indices = np.argsort(tour_lengths)\n    heuristics_matrix = np.zeros((n, n))\n    \n    for rank, index in enumerate(ranked_indices):\n        tour = sampled_tours[index]\n        probability = 1.0 / (rank + 1) # Inverse rank as probability\n        for i in range(n):\n            u = tour[i]\n            v = tour[(i + 1) % n]\n            heuristics_matrix[u, v] += probability\n            heuristics_matrix[v, u] += probability # Symmetric\n\n    return heuristics_matrix",
          "objective": 16.72443,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm generates a large number of random tours, evaluates their lengths, and then assigns higher probabilities to edges that appear frequently in shorter tours, returning a matrix representing the likelihood of each edge's inclusion in an optimal tour.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm generates a large number of random tours, evaluates their lengths, and then assigns higher probabilities to edges that appear frequently in shorter tours, returning a matrix representing the likelihood of each edge's inclusion in an optimal tour.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    tour_lengths = []\n    tours = []\n\n    for _ in range(num_samples):\n        tour = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n        tour_lengths.append(tour_length)\n        tours.append(tour)\n\n    # Normalize tour lengths to represent \"fitness\"\n    max_length = max(tour_lengths)\n    fitness = [(max_length - length) for length in tour_lengths]\n    total_fitness = sum(fitness)\n    if total_fitness == 0:\n        weights = [1/num_samples] * num_samples # Assign equal weights if all tours have the same length\n    else:\n        weights = [f / total_fitness for f in fitness]\n    \n    for i, tour in enumerate(tours):\n        weight = weights[i]\n        for j in range(n - 1):\n            u = tour[j]\n            v = tour[j+1]\n            heuristics_matrix[u, v] += weight\n            heuristics_matrix[v, u] += weight  # Ensure symmetry\n        heuristics_matrix[tour[-1], tour[0]] += weight\n        heuristics_matrix[tour[0], tour[-1]] += weight # Ensure symmetry\n\n    return heuristics_matrix",
          "objective": 18.50419,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm iteratively generates random solutions, evaluates their quality based on distance and edge frequency, and updates edge weights to favor edges present in better solutions, finally returning a matrix representing the learned edge heuristic values.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n  \"\"\"{This algorithm iteratively generates random solutions, evaluates their quality based on distance and edge frequency, and updates edge weights to favor edges present in better solutions, finally returning a matrix representing the learned edge heuristic values.}\"\"\"\n  n = distance_matrix.shape[0]\n  heuristics_matrix = np.ones_like(distance_matrix)\n  num_iterations = 100\n  num_samples = 50\n  \n  for _ in range(num_iterations):\n    solutions = []\n    costs = []\n    for _ in range(num_samples):\n      permutation = np.random.permutation(n)\n      cost = 0\n      for i in range(n - 1):\n        cost += distance_matrix[permutation[i], permutation[i+1]]\n      cost += distance_matrix[permutation[-1], permutation[0]]\n      solutions.append(permutation)\n      costs.append(cost)\n    \n    costs = np.array(costs)\n    best_solutions = solutions[np.argmin(costs)]\n    \n    # Update heuristics based on the best solutions\n    scaling_factor = 0.1 # Adjust this scaling factor\n    for i in range(n - 1):\n      heuristics_matrix[best_solutions[i], best_solutions[i+1]] += scaling_factor * (1 - costs.min()/costs.max()) if costs.max() != 0 else 1\n      heuristics_matrix[best_solutions[i+1], best_solutions[i]] = heuristics_matrix[best_solutions[i], best_solutions[i+1]] \n      \n    heuristics_matrix[best_solutions[-1], best_solutions[0]] += scaling_factor * (1 - costs.min()/costs.max()) if costs.max() != 0 else 1\n    heuristics_matrix[best_solutions[0], best_solutions[-1]] = heuristics_matrix[best_solutions[-1], best_solutions[0]]\n\n  return heuristics_matrix",
          "objective": 18.78302,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm samples multiple near-optimal TSP solutions using a combination of nearest neighbor and random swaps, then uses the frequency of each edge's appearance across these samples as an indicator of its likelihood of being in the optimal solution.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples multiple near-optimal TSP solutions using a combination of nearest neighbor and random swaps, then uses the frequency of each edge's appearance across these samples as an indicator of its likelihood of being in the optimal solution.}\"\"\"\n    num_nodes = distance_matrix.shape[0]\n    num_samples = 100\n\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        # Nearest Neighbor initialization\n        current_node = np.random.randint(num_nodes)\n        unvisited_nodes = set(range(num_nodes))\n        unvisited_nodes.remove(current_node)\n        path = [current_node]\n\n        while unvisited_nodes:\n            nearest_neighbor = min(unvisited_nodes, key=lambda node: distance_matrix[current_node, node])\n            path.append(nearest_neighbor)\n            unvisited_nodes.remove(nearest_neighbor)\n            current_node = nearest_neighbor\n\n        path.append(path[0])  # Return to starting node\n\n        # Random swaps to improve the solution\n        for _ in range(num_nodes):\n            i, j = np.random.choice(range(1, len(path) - 1), 2, replace=False)\n            path[i], path[j] = path[j], path[i]\n\n        # Update heuristics matrix\n        for i in range(len(path) - 1):\n            node1 = path[i]\n            node2 = path[i+1]\n            heuristics_matrix[node1, node2] += 1\n            heuristics_matrix[node2, node1] += 1  # Symmetric\n\n    heuristics_matrix /= num_samples  # Normalize to frequency\n\n    return heuristics_matrix",
          "objective": 19.88706,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm estimates edge importance for TSP by sampling random paths and assigning higher scores to edges frequently appearing in shorter paths.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm estimates edge importance for TSP by sampling random paths and assigning higher scores to edges frequently appearing in shorter paths.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        path = np.random.permutation(n)\n        path_length = 0\n        for i in range(n - 1):\n            path_length += distance_matrix[path[i], path[i+1]]\n        path_length += distance_matrix[path[-1], path[0]]\n\n        # Award edges on shorter paths more weight.  Normalize the length.\n        normalized_length = 1 / (path_length + 1e-9)  # Avoid division by zero\n\n        for i in range(n - 1):\n            heuristics_matrix[path[i], path[i+1]] += normalized_length\n            heuristics_matrix[path[i+1], path[i]] += normalized_length\n        heuristics_matrix[path[-1], path[0]] += normalized_length\n        heuristics_matrix[path[0], path[-1]] += normalized_length\n\n    return heuristics_matrix",
          "objective": 20.06597,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm samples many random tours, and for each edge, calculates the inverse of the average tour length including that edge, scaled by the frequency of the edge's appearance in sampled tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples many random tours, and for each edge, calculates the inverse of the average tour length including that edge, scaled by the frequency of the edge's appearance in sampled tours.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    heuristics_matrix = np.zeros((n, n))\n    edge_counts = np.zeros((n, n))\n    total_tour_lengths = np.zeros((n, n))\n\n    for _ in range(num_samples):\n        tour = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n):\n            j = (i + 1) % n\n            u, v = tour[i], tour[j]\n            tour_length += distance_matrix[u, v]\n\n        for i in range(n):\n            j = (i + 1) % n\n            u, v = tour[i], tour[j]\n            edge_counts[u, v] += 1\n            edge_counts[v, u] += 1  # Assuming symmetric distance matrix\n            total_tour_lengths[u, v] += tour_length\n            total_tour_lengths[v, u] += tour_length\n\n    for i in range(n):\n        for j in range(n):\n            if i != j and edge_counts[i, j] > 0:\n                heuristics_matrix[i, j] = (edge_counts[i, j] / num_samples) / (total_tour_lengths[i, j] / edge_counts[i, j])\n            else:\n                heuristics_matrix[i, j] = 0\n\n    return heuristics_matrix",
          "objective": 20.14861,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm estimates edge importance by sampling random tours, and increasing the heuristic value for edges that frequently appear in short tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm estimates edge importance by sampling random tours, and increasing the heuristic value for edges that frequently appear in short tours.}\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    num_samples = 1000\n\n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n\n        # Give higher weight to shorter tours\n        weight = np.exp(-tour_length / np.mean(distance_matrix))\n\n        # Update the heuristics matrix\n        for i in range(n - 1):\n            heuristics_matrix[tour[i], tour[i+1]] += weight\n            heuristics_matrix[tour[i+1], tour[i]] += weight # Symmetric matrix\n        heuristics_matrix[tour[-1], tour[0]] += weight\n        heuristics_matrix[tour[0], tour[-1]] += weight\n\n    return heuristics_matrix",
          "objective": 20.31007,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm iteratively samples random tours, and the heuristic matrix is updated by rewarding edges that appear frequently in shorter tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm iteratively samples random tours, and the heuristic matrix is updated by rewarding edges that appear frequently in shorter tours.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    num_samples = 1000\n\n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n\n        # Calculate the tour length\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n\n        # Update the heuristics matrix based on tour length\n        reward = 1.0 / (tour_length + 1e-6)  # Reward inversely proportional to tour length\n\n        for i in range(n - 1):\n            heuristics_matrix[tour[i], tour[i+1]] += reward\n            heuristics_matrix[tour[i+1], tour[i]] += reward\n        heuristics_matrix[tour[-1], tour[0]] += reward\n        heuristics_matrix[tour[0], tour[-1]] += reward\n    \n    return heuristics_matrix",
          "objective": 20.33057,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm constructs a heuristics matrix by iteratively sampling random tours, and incrementing the corresponding entry in the matrix for each edge present in a sampled short tour.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm constructs a heuristics matrix by iteratively sampling random tours, and incrementing the corresponding entry in the matrix for each edge present in a sampled short tour.}\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros((n, n))\n    num_samples = 1000\n    best_tour_length = float('inf')\n    \n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        tour = np.append(tour, tour[0]) # return to starting node\n\n        # Calculate the length of the tour\n        tour_length = 0\n        for i in range(n):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        \n        # If this tour is shorter than the best tour found so far, update the best tour\n        if tour_length < best_tour_length:\n           \n            # Increment the heuristics matrix for each edge in the current sampled tour\n            for i in range(n):\n                heuristics_matrix[tour[i], tour[i+1]] += 1\n                heuristics_matrix[tour[i+1], tour[i]] += 1\n\n    return heuristics_matrix",
          "objective": 20.51859,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm iteratively samples random tours, and updates a heuristic matrix based on the frequency with which each edge appears in good (short) tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm iteratively samples random tours, and updates a heuristic matrix based on the frequency with which each edge appears in good (short) tours.}\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    num_iterations = 1000\n    \n    for _ in range(num_iterations):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        tour = np.append(tour, tour[0]) # Return to start\n\n        # Calculate the tour length\n        tour_length = 0.0\n        for i in range(n):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n\n        # Update the heuristics matrix if the tour is \"good\"\n        if tour_length < np.mean(distance_matrix) * n * 1.5 : # Consider tours shorter than some multiple of average distance\n          for i in range(n):\n              heuristics_matrix[tour[i], tour[i+1]] += 1.0/num_iterations\n              heuristics_matrix[tour[i+1], tour[i]] += 1.0/num_iterations\n\n    return heuristics_matrix",
          "objective": 20.55439,
          "other_inf": null,
          "SLOC": 25.0,
          "cyclomatic_complexity": 7.0,
          "halstead": 298.0560051675714
     },
     {
          "algorithm": "This algorithm iteratively samples random tours, evaluates their lengths, and updates a heuristic matrix to favor edges appearing in shorter tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm iteratively samples random tours, evaluates their lengths, and updates a heuristic matrix to favor edges appearing in shorter tours.}\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    num_iterations = 1000\n    \n    for _ in range(num_iterations):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        \n        # Calculate the tour length\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[n-1], tour[0]]\n        \n        # Update the heuristics matrix\n        for i in range(n - 1):\n            heuristics_matrix[tour[i], tour[i+1]] += (1 / tour_length)\n            heuristics_matrix[tour[i+1], tour[i]] += (1 / tour_length) # Symmetric\n        heuristics_matrix[tour[n-1], tour[0]] += (1 / tour_length)\n        heuristics_matrix[tour[0], tour[n-1]] += (1 / tour_length)\n\n    return heuristics_matrix",
          "objective": 20.59111,
          "other_inf": null,
          "SLOC": 17.0,
          "cyclomatic_complexity": 4.0,
          "halstead": 183.9358278562653
     },
     {
          "algorithm": "This algorithm samples multiple random solutions, iteratively refines them by swapping edges, and uses the frequency of each edge's appearance in the best solutions as a heuristic indicator of its importance.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples multiple random solutions, iteratively refines them by swapping edges, and uses the frequency of each edge's appearance in the best solutions as a heuristic indicator of its importance.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 100\n    iterations = 50\n    best_solutions = []\n    best_costs = []\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        # Generate a random solution\n        solution = np.random.permutation(n)\n        solution = np.append(solution, solution[0])  # Return to starting node\n        \n        cost = calculate_cost(solution, distance_matrix)\n\n        # Iteratively refine the solution with 2-opt swaps\n        for _ in range(iterations):\n            improved = False\n            for i in range(1, n - 1):\n                for j in range(i + 1, n):\n                    new_solution = solution.copy()\n                    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n                    new_cost = calculate_cost(new_solution, distance_matrix)\n                    if new_cost < cost:\n                        solution = new_solution\n                        cost = new_cost\n                        improved = True\n            if not improved:\n                break\n        \n        # Keep track of the best solutions\n        if len(best_costs) < 10:\n            best_solutions.append(solution)\n            best_costs.append(cost)\n        elif cost < max(best_costs):\n            max_index = best_costs.index(max(best_costs))\n            best_solutions[max_index] = solution\n            best_costs[max_index] = cost\n\n    # Calculate heuristics based on edge frequency in the best solutions\n    for solution in best_solutions:\n        for i in range(n):\n            node1 = solution[i]\n            node2 = solution[i+1]\n            heuristics_matrix[node1, node2] += 1\n            heuristics_matrix[node2, node1] += 1  # Symmetric\n    \n    heuristics_matrix = heuristics_matrix / len(best_solutions) # Normalize by number of best solutions\n\n    return heuristics_matrix\n\ndef calculate_cost(solution, distance_matrix):\n    cost = 0\n    for i in range(len(solution) - 1):\n        cost += distance_matrix[solution[i], solution[i+1]]\n    return heuristics_matrix",
          "objective": Infinity,
          "other_inf": null,
          "SLOC": null,
          "cyclomatic_complexity": null,
          "halstead": null
     },
     {
          "algorithm": "This algorithm generates multiple random tours using a nearest neighbor heuristic with stochasticity, and then calculates a heuristic matrix based on the frequency each edge appears in the sampled tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm generates multiple random tours using a nearest neighbor heuristic with stochasticity, and then calculates a heuristic matrix based on the frequency each edge appears in the sampled tours.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    heuristics_matrix = np.zeros((n, n))\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        tour = [start_node]\n        unvisited = set(range(n))\n        unvisited.remove(start_node)\n\n        current_node = start_node\n        while unvisited:\n            distances = distance_matrix[current_node, :]\n            \n            # Add stochasticity: choose from the k-nearest neighbors\n            k = min(5, len(unvisited))  # Consider top k nearest neighbors (max 5)\n            \n            nearest_neighbors = np.argsort(distances)[1:] # Exclude self-loop\n            \n            \n            candidates = []\n            count = 0\n            for neighbor in nearest_neighbors:\n                if neighbor in unvisited:\n                    candidates.append(neighbor)\n                    count +=1\n                if count == k:\n                    break\n\n            \n            next_node = np.random.choice(candidates)\n\n            tour.append(next_node)\n            unvisited.remove(next_node)\n            current_node = next_node\n\n        tour.append(start_node)  # Return to starting node\n\n        # Update heuristic matrix based on tour\n        for i in range(n):\n            heuristics_matrix[tour[i], tour[(i + 1) % n]] += 1\n            heuristics_matrix[tour[(i + 1) % n], tour[tour[i]]] += 1\n\n    return heuristics_matrix",
          "objective": Infinity,
          "other_inf": null,
          "SLOC": null,
          "cyclomatic_complexity": null,
          "halstead": null
     }
]