```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a refined Sigmoid Fit Score with tunable tie-breaking.

    This heuristic prioritizes bins that offer a "tight fit", meaning the remaining
    capacity is just enough to accommodate the item, minimizing wasted space.
    It uses a sigmoid function to assign higher scores to bins with smaller positive
    residual capacities after packing the item.

    Key features:
    1.  **Sigmoid for Tight Fits**: A tunable sigmoid function assigns higher scores
        to bins where `remaining_capacity - item` is close to a small positive value
        (`ideal_gap`). This encourages packing items into bins that will have minimal
        remaining space.
    2.  **Tie-Breaking with Softmax**: When multiple bins have very similar high
        priority scores, a softmax function is applied to these scores to create
        a probability distribution. This allows for a probabilistic selection among
        the best-fitting bins, introducing a controlled element of exploration.
    3.  **Zero Priority for Non-fitting Bins**: Bins where the item cannot fit
        (remaining capacity < item size) are assigned a priority of 0.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array where each element is the remaining capacity of a bin.

    Returns:
        A numpy array of the same size as `bins_remain_cap`, containing the priority
        score for each bin. Higher scores indicate a more desirable bin for the item.
    """

    def sigmoid(x, steepness=10.0, center=0.0):
        """A custom sigmoid function."""
        return 1 / (1 + np.exp(-steepness * (x - center)))

    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins where the item can fit.
    fits_mask = bins_remain_cap >= item

    if np.any(fits_mask):
        # Calculate the excess capacity (residual space) for fitting bins.
        excess_capacities = bins_remain_cap[fits_mask] - item

        # Parameters for the sigmoid function
        steepness = 20.0  # Increased steepness for a sharper peak.
        ideal_gap = 0.01  # Target small positive residual space for the tightest fit.

        # Calculate argument for sigmoid: we want peak priority when excess_capacity is ideal_gap.
        # argument = steepness * (ideal_gap - excess_capacity)
        argument_values = steepness * (ideal_gap - excess_capacities)

        # Calculate raw sigmoid scores for fitting bins.
        raw_priorities = sigmoid(argument_values, steepness=steepness, center=0.0)

        # Apply Softmax for tie-breaking among high-priority bins.
        # This converts scores into a probability-like distribution,
        # where bins with similar high scores get a chance to be chosen.
        # Adding a small epsilon to avoid log(0) in softmax if all priorities are equal.
        # Softmax is typically applied to logits (unnormalized scores),
        # but applying to sigmoid outputs also works to normalize relative preference.
        # A temperature parameter could be added to control the sharpness of the softmax.
        # For simplicity, we'll apply it directly.

        # To ensure softmax works well and doesn't collapse all probabilities
        # if all raw_priorities are identical and very high, we can normalize first
        # or ensure a small variance if needed. Here, we directly use softmax.
        # A small constant is added to the exponent to avoid issues with identical values.
        # Alternatively, we can simply use the raw priorities directly if a probabilistic
        # selection among the very best is desired without explicit softmax normalization.
        # Let's use the raw priorities and normalize them to sum to 1 for a probabilistic choice.

        # Normalize priorities to sum to 1 for a probabilistic selection among the best.
        # This also handles the case where multiple bins have the same top score.
        sum_priorities = np.sum(raw_priorities)
        if sum_priorities > 0:
            normalized_priorities = raw_priorities / sum_priorities
        else:
            # If all raw priorities are 0 (e.g., item too large for all),
            # distribute probability equally among fitting bins (though this case
            # should not happen if fits_mask has any True).
            normalized_priorities = np.ones_like(raw_priorities) / len(raw_priorities) if len(raw_priorities) > 0 else np.array([])

        priorities[fits_mask] = normalized_priorities

    # Bins where the item does not fit retain their zero priority.
    return priorities
```
