```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a combination of Best Fit and a novel 'Worst Fit Reduction' strategy.

    This heuristic aims to:
    1. Favor bins that result in a tight fit (similar to Best Fit).
    2. Introduce a secondary preference for bins that, after packing, still have substantial remaining capacity,
       thereby "reserving" tighter-fitting bins for potentially smaller future items. This is a form of
       "Worst Fit Reduction" in that we reduce the "waste" by not over-filling bins that could
       accommodate more.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros(num_bins)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # If no bins can fit the item, return all zeros
    if not np.any(can_fit_mask):
        return priorities

    # Calculate scores for bins that can fit the item
    fitting_bins_indices = np.where(can_fit_mask)[0]
    fitting_bins_remain_cap = bins_remain_cap[fitting_bins_indices]

    # Score 1: Best Fit component - prioritize bins that leave less remaining capacity
    # We use the negative of remaining capacity to make larger negative values (smaller remaining capacity) higher.
    best_fit_scores = -(fitting_bins_remain_cap - item)

    # Score 2: Worst Fit Reduction component - penalize bins that are too "full" after packing,
    # giving a slight preference to bins that have more remaining capacity.
    # This can be achieved by adding a small factor of the remaining capacity.
    # We add a small constant to avoid division by zero if remaining capacity is 0.
    # This term should be smaller than the best_fit_scores to ensure best fit is dominant.
    # The scale of this term needs careful tuning; a small positive value is used here.
    worst_fit_reduction_scores = (fitting_bins_remain_cap - item) * 0.1

    # Combine scores. We want to maximize the combined score.
    # Prioritize bins that are a good fit AND don't become too full.
    # Higher scores mean higher priority.
    combined_scores = best_fit_scores + worst_fit_reduction_scores

    # Normalize scores to a probability distribution using softmax.
    # Subtract max to prevent overflow during exponentiation and ensure numerical stability.
    max_score = np.max(combined_scores)
    exp_scores = np.exp(combined_scores - max_score)
    sum_exp_scores = np.sum(exp_scores)

    if sum_exp_scores > 0:
        normalized_priorities = exp_scores / sum_exp_scores
    else:
        # If all scores are effectively -inf after subtractions, assign uniform probability.
        normalized_priorities = np.ones_like(combined_scores) / len(combined_scores)

    # Assign the calculated priorities to the original bins array
    priorities[fitting_bins_indices] = normalized_priorities

    return priorities
```
