{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a tunable sigmoid and softmax.\n\n    This heuristic aims to prioritize bins that offer the \"best fit\" for the item,\n    defined as bins where the remaining capacity is only slightly larger than the item's size.\n    It uses a sigmoid function to assign higher scores to these \"tight fits\".\n    The sigmoid's steepness and ideal gap are tunable.\n\n    To encourage exploration among equally good or near-equally good bins,\n    a softmax function is applied to the sigmoid scores. This normalizes scores\n    into probabilities, allowing for probabilistic selection and exploration.\n    Bins that cannot fit the item are assigned a priority of 0.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element is the remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as `bins_remain_cap`, containing the priority\n        score for each bin. Higher scores indicate a more desirable bin for the item.\n    \"\"\"\n\n    def sigmoid(x, steepness=15.0, ideal_gap=0.02):\n        \"\"\"A sigmoid function that peaks at x=0, and can be scaled and shifted.\n        Here, x is effectively (bin_capacity - item_size - ideal_gap).\n        A smaller positive `ideal_gap` means tighter fits are preferred.\n        A larger `steepness` makes the preference for `ideal_gap` more pronounced.\n        \"\"\"\n        # We want the sigmoid to peak when (bin_cap - item) is close to ideal_gap.\n        # So, we map (bin_cap - item) to the sigmoid's input.\n        # Let sigmoid_input = steepness * (ideal_gap - (bin_cap - item))\n        # This means when bin_cap - item = ideal_gap, sigmoid_input = 0, and sigmoid output = 0.5.\n        # We want higher scores for smaller positive gaps.\n        # If bin_cap - item = 0 (perfect fit), sigmoid_input = steepness * ideal_gap > 0, sigmoid output > 0.5.\n        # If bin_cap - item = 0.1, sigmoid_input = steepness * (ideal_gap - 0.1). If ideal_gap is small, this is negative.\n        return 1 / (1 + np.exp(-x))\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit.\n    fits_mask = bins_remain_cap >= item\n\n    if np.any(fits_mask):\n        # Calculate the excess capacity for fitting bins.\n        excess_capacities = bins_remain_cap[fits_mask] - item\n\n        # Tunable parameters for the sigmoid function.\n        # steepness: controls how quickly the priority drops as excess capacity deviates from ideal_gap.\n        # ideal_gap: the preferred small positive residual capacity after packing the item.\n        steepness = 15.0\n        ideal_gap = 0.02\n\n        # Calculate the argument for the sigmoid.\n        # We want the sigmoid to output higher values for smaller, non-negative `excess_capacities`.\n        # The sigmoid `1 / (1 + exp(-x))` has its midpoint at x=0.\n        # To map `excess_capacities` such that `ideal_gap` gives a good score, we use:\n        # `sigmoid_arg = steepness * (ideal_gap - excess_capacities)`\n        # If `excess_capacities` is slightly less than `ideal_gap` (a good fit), `sigmoid_arg` is positive, sigmoid > 0.5.\n        # If `excess_capacities` is exactly `ideal_gap`, `sigmoid_arg` is 0, sigmoid = 0.5.\n        # If `excess_capacities` is larger than `ideal_gap`, `sigmoid_arg` is negative, sigmoid < 0.5.\n        sigmoid_arg = steepness * (ideal_gap - excess_capacities)\n\n        # Calculate raw sigmoid scores for fitting bins.\n        raw_scores = sigmoid(sigmoid_arg, steepness=steepness, ideal_gap=ideal_gap)\n\n        # Apply softmax to the scores. This normalizes scores into a probability distribution,\n        # allowing for probabilistic exploration. Bins with similar high scores will have\n        # non-zero probabilities assigned, encouraging trying different \"good\" bins.\n        # Add a small epsilon to avoid issues with exp(very large negative numbers) if all are bad fits.\n        # However, since we only calculate for fitting bins, this is less of a concern.\n        # We are using the raw scores as inputs to softmax, not probabilities directly.\n        # The 'temperature' parameter in softmax can be adjusted to control exploration.\n        # A higher temperature leads to more uniform probabilities. A lower temperature\n        # leads to probabilities concentrated on the highest score.\n        temperature = 1.0 # Tunable exploration parameter\n\n        # Avoid numerical instability with softmax if all `sigmoid_arg` are very large negative (unlikely here)\n        # or very large positive.\n        # For this application, `sigmoid_arg` will be mostly negative or slightly positive.\n        # A simple softmax on the `raw_scores` is usually sufficient.\n        exp_scores = np.exp(raw_scores / temperature)\n        sum_exp_scores = np.sum(exp_scores)\n\n        if sum_exp_scores > 0:\n            priorities[fits_mask] = exp_scores / sum_exp_scores\n        else:\n            # Fallback: if all exp_scores are zero or NaN (highly unlikely for valid inputs)\n            # distribute probability uniformly among fitting bins.\n            priorities[fits_mask] = 1.0 / np.sum(fits_mask) if np.sum(fits_mask) > 0 else 0\n\n    # Bins that do not fit have a priority of 0.\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority score for each bin using a hybrid approach prioritizing good fits and balancing exploration.\n\n    This heuristic prioritizes bins that offer a \"good fit\" for the item, meaning\n    their remaining capacity is slightly larger than the item size. It also\n    incorporates an exploration component to occasionally consider less-full bins,\n    balancing the \"best fit\" tendency with exploration of potential future packing\n    opportunities.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of priority scores for each bin. Higher scores indicate a\n        higher preference for placing the item in that bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploration (choosing a bin less greedily)\n    k_steepness = 5.0  # Steepness parameter for the sigmoid function\n    ideal_gap = 0.05  # The preferred remaining capacity beyond the item size\n\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    # Identify bins where the item can fit\n    fits_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(fits_mask)[0]\n\n    # If no bins can fit the item, return all zeros.\n    if len(fitting_bins_indices) == 0:\n        return priorities\n\n    # --- Exploitation Component: Prioritize Good Fits ---\n    # Calculate the \"excess capacity\" for bins where the item fits.\n    # A good fit has a small, positive excess capacity.\n    excess_capacities = bins_remain_cap[fitting_bins_indices] - item\n\n    # Use a sigmoid function to score the \"goodness\" of the fit.\n    # We want the score to peak when `excess_capacities` is close to `ideal_gap`.\n    # The argument for the sigmoid is designed so that:\n    # - When `excess_capacities == ideal_gap`, the argument is 0, sigmoid(0) = 0.5 (peak of the \"good fit\" score).\n    # - When `excess_capacities` deviates from `ideal_gap` (either smaller or larger), the score decreases.\n    # This formulation penalizes bins that are too empty or too full relative to the ideal gap.\n    sigmoid_argument = k_steepness * (ideal_gap - excess_capacities)\n    exploitation_scores = 1 / (1 + np.exp(-sigmoid_argument))\n\n    # Normalize exploitation scores so they sum to 1 among fitting bins.\n    # This helps in combining with exploration probabilities later if needed, or for clearer interpretation.\n    # However, for direct preference scores, normalization might not be strictly required if scaled appropriately.\n    # Let's scale them to be within a reasonable range for prioritization.\n    # We can scale the 0.5 peak to a higher value for better differentiation if needed.\n    # For now, let's use the raw sigmoid output (0 to 1).\n\n    # --- Exploration Component ---\n    # With probability epsilon, we want to explore other options.\n    # We can assign a uniform, lower priority to all fitting bins to represent exploration.\n    # The probability of choosing an exploratory bin is epsilon.\n    # If we explore, we pick one of the fitting bins uniformly.\n    # So, each fitting bin gets an additional 'exploration boost'.\n    exploration_boost = epsilon / len(fitting_bins_indices)\n\n    # --- Combine Exploitation and Exploration ---\n    # The final priority for fitting bins is a weighted sum:\n    # (1 - epsilon) * exploitation_score + epsilon * uniform_exploration_score\n    # Here, the 'uniform_exploration_score' is implicitly handled by adding\n    # the exploration boost.\n\n    # Apply the combined strategy:\n    # For fitting bins: priority = (1-epsilon) * normalized_exploitation_score + epsilon * (uniform score)\n    # A simpler way to think is that the final score is a mix.\n    # Let's consider the scores as probabilities of selection for a simplified view.\n    # We want to assign scores reflecting preference.\n\n    # Let's use the exploitation scores directly, but add an exploration bonus.\n    # The exploration bonus makes less-preferred bins (by exploitation score) more competitive.\n    # We add a constant exploration value to all fitting bins to ensure some randomness.\n    # The value of exploration_boost is small, relative to the peak exploitation score (0.5).\n    # We can add a scaled exploration value.\n    exploration_value = epsilon * 0.5 # A smaller constant exploration value\n\n    # The final priorities are a mix. We can think of it as:\n    # A base score derived from exploitation, with a small random jitter or uniform boost for exploration.\n    priorities[fitting_bins_indices] = exploitation_scores + exploration_value\n\n    # Ensure scores are non-negative.\n    priorities = np.maximum(priorities, 0)\n\n    # Optional: Normalize priorities to sum to 1 if they represent probabilities of selection,\n    # or just return them as preference scores. For selection, normalization is common.\n    # Let's return them as preference scores, allowing the caller to normalize if needed.\n    # A common strategy is to use these scores with a softmax-like selection mechanism.\n\n    # For simplicity and direct preference, we can scale the exploitation scores\n    # and add a smaller exploration component.\n    # Let's re-scale exploitation_scores to have a max value higher than 0.5, e.g., 1.\n    # Max exploitation score is 1 (when sigmoid_argument is large positive).\n    # Min exploitation score is 0 (when sigmoid_argument is large negative).\n    # Peak is 0.5.\n\n    # Let's try a different combination:\n    # Prioritize bins based on exploitation score, but ensure some chance for others.\n    # If random draw < epsilon, pick a random fitting bin. Otherwise, pick based on exploitation.\n    # This is more of a selection logic. For generating priority scores:\n    # We want to combine the 'good fit' score with an exploration factor.\n\n    # A common way to represent this combination is:\n    # priority = (1-epsilon) * exploitation_score + epsilon * uniform_score\n    # Where uniform_score is 1/num_fitting_bins.\n    # Let's re-normalize exploitation scores first to sum to 1 for clarity in combination.\n    if np.sum(exploitation_scores) > 0:\n        normalized_exploitation_scores = exploitation_scores / np.sum(exploitation_scores)\n    else:\n        normalized_exploitation_scores = np.zeros_like(exploitation_scores) # Should not happen if fitting_bins exist\n\n    # Uniform score for exploration among fitting bins\n    uniform_exploration_score = 1.0 / len(fitting_bins_indices) if len(fitting_bins_indices) > 0 else 0.0\n\n    # Combine them:\n    combined_priorities = (1 - epsilon) * normalized_exploitation_scores + epsilon * uniform_exploration_score\n\n    # Place these combined priorities back into the main priorities array\n    priorities[fitting_bins_indices] = combined_priorities\n\n    # Ensure all priorities are non-negative (should already be true)\n    priorities = np.maximum(priorities, 0)\n\n    return priorities\n\n[Reflection]\nBalance exploitation (good fits) with exploration (randomness) for better performance.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}