{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a tunable sigmoid and softmax.\n\n    This heuristic aims to prioritize bins that offer the \"best fit\" for the item,\n    defined as bins where the remaining capacity is only slightly larger than the item's size.\n    It uses a sigmoid function to assign higher scores to these \"tight fits\".\n    The sigmoid's steepness and ideal gap are tunable.\n\n    To encourage exploration among equally good or near-equally good bins,\n    a softmax function is applied to the sigmoid scores. This normalizes scores\n    into probabilities, allowing for probabilistic selection and exploration.\n    Bins that cannot fit the item are assigned a priority of 0.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element is the remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as `bins_remain_cap`, containing the priority\n        score for each bin. Higher scores indicate a more desirable bin for the item.\n    \"\"\"\n\n    def sigmoid(x, steepness=15.0, ideal_gap=0.02):\n        \"\"\"A sigmoid function that peaks at x=0, and can be scaled and shifted.\n        Here, x is effectively (bin_capacity - item_size - ideal_gap).\n        A smaller positive `ideal_gap` means tighter fits are preferred.\n        A larger `steepness` makes the preference for `ideal_gap` more pronounced.\n        \"\"\"\n        # We want the sigmoid to peak when (bin_cap - item) is close to ideal_gap.\n        # So, we map (bin_cap - item) to the sigmoid's input.\n        # Let sigmoid_input = steepness * (ideal_gap - (bin_cap - item))\n        # This means when bin_cap - item = ideal_gap, sigmoid_input = 0, and sigmoid output = 0.5.\n        # We want higher scores for smaller positive gaps.\n        # If bin_cap - item = 0 (perfect fit), sigmoid_input = steepness * ideal_gap > 0, sigmoid output > 0.5.\n        # If bin_cap - item = 0.1, sigmoid_input = steepness * (ideal_gap - 0.1). If ideal_gap is small, this is negative.\n        return 1 / (1 + np.exp(-x))\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit.\n    fits_mask = bins_remain_cap >= item\n\n    if np.any(fits_mask):\n        # Calculate the excess capacity for fitting bins.\n        excess_capacities = bins_remain_cap[fits_mask] - item\n\n        # Tunable parameters for the sigmoid function.\n        # steepness: controls how quickly the priority drops as excess capacity deviates from ideal_gap.\n        # ideal_gap: the preferred small positive residual capacity after packing the item.\n        steepness = 15.0\n        ideal_gap = 0.02\n\n        # Calculate the argument for the sigmoid.\n        # We want the sigmoid to output higher values for smaller, non-negative `excess_capacities`.\n        # The sigmoid `1 / (1 + exp(-x))` has its midpoint at x=0.\n        # To map `excess_capacities` such that `ideal_gap` gives a good score, we use:\n        # `sigmoid_arg = steepness * (ideal_gap - excess_capacities)`\n        # If `excess_capacities` is slightly less than `ideal_gap` (a good fit), `sigmoid_arg` is positive, sigmoid > 0.5.\n        # If `excess_capacities` is exactly `ideal_gap`, `sigmoid_arg` is 0, sigmoid = 0.5.\n        # If `excess_capacities` is larger than `ideal_gap`, `sigmoid_arg` is negative, sigmoid < 0.5.\n        sigmoid_arg = steepness * (ideal_gap - excess_capacities)\n\n        # Calculate raw sigmoid scores for fitting bins.\n        raw_scores = sigmoid(sigmoid_arg, steepness=steepness, ideal_gap=ideal_gap)\n\n        # Apply softmax to the scores. This normalizes scores into a probability distribution,\n        # allowing for probabilistic exploration. Bins with similar high scores will have\n        # non-zero probabilities assigned, encouraging trying different \"good\" bins.\n        # Add a small epsilon to avoid issues with exp(very large negative numbers) if all are bad fits.\n        # However, since we only calculate for fitting bins, this is less of a concern.\n        # We are using the raw scores as inputs to softmax, not probabilities directly.\n        # The 'temperature' parameter in softmax can be adjusted to control exploration.\n        # A higher temperature leads to more uniform probabilities. A lower temperature\n        # leads to probabilities concentrated on the highest score.\n        temperature = 1.0 # Tunable exploration parameter\n\n        # Avoid numerical instability with softmax if all `sigmoid_arg` are very large negative (unlikely here)\n        # or very large positive.\n        # For this application, `sigmoid_arg` will be mostly negative or slightly positive.\n        # A simple softmax on the `raw_scores` is usually sufficient.\n        exp_scores = np.exp(raw_scores / temperature)\n        sum_exp_scores = np.sum(exp_scores)\n\n        if sum_exp_scores > 0:\n            priorities[fits_mask] = exp_scores / sum_exp_scores\n        else:\n            # Fallback: if all exp_scores are zero or NaN (highly unlikely for valid inputs)\n            # distribute probability uniformly among fitting bins.\n            priorities[fits_mask] = 1.0 / np.sum(fits_mask) if np.sum(fits_mask) > 0 else 0\n\n    # Bins that do not fit have a priority of 0.\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit.\n\n    The Best Fit strategy aims to place the item into the bin that has the\n    least remaining capacity after the item is placed, such that the item fits.\n    This minimizes wasted space in the bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins that cannot accommodate the item will have a priority of 0.\n        Among bins that can accommodate the item, higher priority is given to\n        bins that result in less remaining capacity after placing the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in a bin\n    # This is the 'fitness' or 'wasted space' after placement\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # We want to minimize the remaining capacity after fit (Best Fit).\n    # To translate minimization into a maximization priority score, we can\n    # use the negative of the remaining capacity, or a score that is inversely\n    # proportional to it. A common approach is to use something like:\n    # priority = C - (remaining_capacity_after_fit) where C is a large constant.\n    # A simpler approach that achieves the same ordering is to use the negative\n    # of the remaining capacity if we want to *minimize* it.\n    # Alternatively, we can assign a higher priority to smaller remaining capacities.\n    # Let's use the negative of the remaining capacity as the priority score,\n    # so the smallest positive remaining capacity (least waste) gets the highest score.\n\n    # For bins that can fit the item, the priority is the negative of the\n    # remaining capacity after the item is placed. A smaller positive\n    # remaining capacity means a larger negative priority, which is good.\n    # For example, if remaining capacities after fit are [1, 5, 2],\n    # the negative values are [-1, -5, -2]. The highest priority would be -1.\n    # This correctly prioritizes the bin with remaining capacity 1.\n\n    priorities[can_fit_mask] = -remaining_capacities_after_fit\n\n    return priorities\n\n[Reflection]\nFocus on directly optimizing for \"best fit\" rather than complex probabilistic shaping.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}