{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a tunable sigmoid and varied exploration.\n\n    This heuristic aims to prioritize bins that offer the \"best fit\" for the item.\n    A \"best fit\" is defined as a bin where the remaining capacity is only slightly\n    larger than the item's size. This strategy tries to fill bins as much as possible\n    without leaving excessive empty space, thereby minimizing fragmentation.\n\n    The priority is calculated using a sigmoid function. The function is designed\n    to peak when the remaining capacity (`bins_remain_cap`) is precisely equal to\n    the item's size, and the priority decreases as the remaining capacity deviates\n    (either smaller or larger). However, bins where the item doesn't fit at all\n    are assigned a zero priority.\n\n    Tie-breaking is handled using a softmax-like approach on top of the sigmoid scores.\n    This introduces a probabilistic element, favoring bins with higher scores more\n    often but not exclusively, allowing for exploration of less ideal fits.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array where each element is the remaining capacity of a bin.\n\n    Returns:\n        A numpy array of the same size as `bins_remain_cap`, containing the priority\n        score for each bin. Higher scores indicate a more desirable bin for the item.\n    \"\"\"\n\n    def sigmoid(x, steepness=10.0, center=0.0):\n        \"\"\"A custom sigmoid function that can be shifted and scaled.\"\"\"\n        # Ensure numerical stability for large negative exponents\n        exponent = -steepness * (x - center)\n        # Clip exponent to avoid overflow in exp, then compute sigmoid\n        # A large negative exponent approaches 0, large positive approaches 1.\n        # Clipping at -700 is a common practice for exp(-700) ~ 1e-304\n        clipped_exponent = np.clip(exponent, -700, 700)\n        return 1 / (1 + np.exp(clipped_exponent))\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit.\n    fits_mask = bins_remain_cap >= item\n\n    if np.any(fits_mask):\n        # Calculate the excess capacity for fitting bins.\n        excess_capacities = bins_remain_cap[fits_mask] - item\n\n        # Tunable parameters for the sigmoid function\n        # `ideal_gap` defines the target excess capacity for the best fit.\n        # A smaller `ideal_gap` means we prefer bins that leave very little space.\n        # `steepness` controls how quickly the priority drops as excess capacity deviates from `ideal_gap`.\n        ideal_gap = 0.05  # Target for minimal positive residual space\n        steepness = 15.0  # Increased steepness for sharper preference\n\n        # Calculate the argument for the sigmoid function.\n        # We want the peak of the sigmoid (where the argument is 0) to align with our 'ideal_gap'.\n        # The argument is `steepness * (ideal_gap - excess_capacities)`.\n        # This means when `excess_capacities` is close to `ideal_gap`, the argument is close to 0,\n        # resulting in a sigmoid output close to 0.5 (midpoint).\n        # Scores > 0.5 for `excess_capacities` < `ideal_gap`\n        # Scores < 0.5 for `excess_capacities` > `ideal_gap`\n        argument_values = steepness * (ideal_gap - excess_capacities)\n\n        # Apply the sigmoid function to get raw scores for fitting bins.\n        raw_scores = sigmoid(argument_values, steepness=steepness, center=0.0)\n\n        # Normalize scores using a softmax-like approach for exploration.\n        # This converts scores into probabilities, allowing for probabilistic selection\n        # and thus exploration of bins that are not strictly the \"best\" fit.\n        # A small epsilon is added to prevent issues with all scores being identical.\n        # A temperature parameter could be introduced here for more control over exploration.\n        # For simplicity, we'll use the direct softmax on the scaled sigmoid outputs.\n        \n        # We want higher sigmoid scores to translate to higher probabilities.\n        # A simple softmax transformation: exp(score) / sum(exp(scores))\n        # However, direct softmax on scores that might be close to 0 or 1 can lead to extreme probabilities.\n        # A common approach in exploration is to add noise or use a temperature parameter.\n        # Let's scale the sigmoid output to a range that is more suitable for softmax, e.g., [0, 10]\n        # or simply use the sigmoid output directly if it's already in a reasonable range.\n        \n        # For this implementation, let's directly use the sigmoid output as \"desirability\".\n        # Higher desirability means a higher chance of selection.\n        # A simple way to implement \"varied exploration\" without explicit softmax is to\n        # slightly perturb the scores or use a mechanism like epsilon-greedy on these scores.\n        # However, the prompt implies a more direct score-based exploration.\n        # The \"softmax-like\" part can be interpreted as ensuring relative ordering is maintained\n        # and higher scores are disproportionately favored.\n        #\n        # Let's refine the \"softmax-like\" to mean we are generating relative weights.\n        # The sigmoid already provides a relative measure of \"goodness of fit\".\n        # The primary refinement for \"varied exploration\" beyond standard greedy would be:\n        # 1. Add small random noise to the scores.\n        # 2. Use the scores as weights in a weighted random choice.\n        #\n        # The reflection mentioned \"softmax for score normalization\".\n        # If we consider the raw sigmoid scores (0 to 1), softmax on these would yield\n        # probabilities summing to 1 across the *fitting* bins.\n        \n        # Option: Softmax on raw_scores\n        # exp_scores = np.exp(raw_scores)\n        # probabilities = exp_scores / np.sum(exp_scores)\n        # priorities[fits_mask] = probabilities\n\n        # Option: Scaled scores for softmax (e.g., if sigmoid scores are too clustered)\n        # scaled_scores = raw_scores * 5.0 # Scale to a range like [0, 5]\n        # exp_scaled_scores = np.exp(scaled_scores)\n        # probabilities = exp_scaled_scores / np.sum(exp_scaled_scores)\n        # priorities[fits_mask] = probabilities\n\n        # The current sigmoid output is already designed to be a priority score.\n        # The \"varied exploration\" might simply mean that the sigmoid output itself\n        # provides a graded preference, allowing a weighted selection mechanism\n        # (not implemented here but implied by \"priority score\") to explore.\n        # If we interpret \"softmax-like\" as creating relative probabilities, we can do that.\n        # However, a simpler interpretation for \"priority score\" is to just return\n        # the modulated sigmoid scores, and let the selection algorithm handle the exploration.\n\n        # Let's stick to the interpretation that the `priority_v2` function *outputs*\n        # scores that can be used for exploration. The sigmoid already provides a nuanced score.\n        # For tie-breaking and varied exploration, we can enhance the score or rely on the selection mechanism.\n        #\n        # A simple way to introduce variation without full softmax: add a small, scaled random component.\n        # This is akin to adding noise for exploration.\n        #\n        # Let's ensure the scores are in a somewhat predictable range and then use them.\n        # The sigmoid output is [0, 1].\n        \n        # For \"varied exploration\", we can make the scores slightly more distinct or add noise.\n        # Adding a small random noise:\n        # noise = np.random.normal(0, 0.05, raw_scores.shape) # Mean 0, std dev 0.05\n        # noisy_scores = raw_scores + noise\n        # Ensure scores remain within a valid range (e.g., > 0) for weighted selection.\n        # We can clamp or re-normalize.\n\n        # Let's interpret \"varied exploration\" as generating scores that are\n        # not purely greedy, but represent a soft preference. The sigmoid itself does this.\n        # The \"softmax for score normalization\" could mean scaling these priorities\n        # so they sum to a constant (e.g., 1 if using weighted random choice).\n        #\n        # The most direct interpretation is to simply return the refined sigmoid scores.\n        # The \"varied exploration\" aspect is then handled by how these scores are *used* by the calling algorithm\n        # (e.g., weighted random choice vs. simple argmax).\n        #\n        # If the intent is for this function itself to produce probabilities for a direct selection,\n        # then softmax is appropriate. Given the wording \"returns a priority score for each bin\",\n        # it suggests the output is a score, not necessarily a final probability.\n        #\n        # Let's refine the sigmoid output to ensure higher scores are more distinct,\n        # making the preference clearer for exploration.\n        # We can amplify the difference between scores.\n        \n        # A simple amplification of the sigmoid output might be:\n        # amplified_scores = raw_scores ** power_factor  (where power_factor > 1)\n        # Or a linear scaling and shifting that maintains order but increases separation.\n        \n        # Let's use the original sigmoid scores, as they are already graded.\n        # If \"varied exploration\" means probabilistic selection based on scores,\n        # the scores themselves are the input to that mechanism.\n        priorities[fits_mask] = raw_scores\n\n    # For bins where the item does not fit, the priority remains 0.\n    # This correctly implies they have the lowest priority.\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First.\n\n    Exact Fit First strategy prioritizes bins that have a remaining capacity\n    exactly equal to the item's size. Among bins with exact fits, it\n    further prioritizes bins that are \"tighter\" (i.e., have less remaining\n    capacity after the item is placed). If no exact fit is found, it\n    falls back to selecting a bin that can accommodate the item and\n    minimizes the remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Find bins that have an exact fit\n    exact_fit_mask = bins_remain_cap == item\n    if np.any(exact_fit_mask):\n        # Among exact fits, prefer the one with least remaining capacity (which is 0 after fit)\n        # So we can give a high positive score, higher for those that would become exactly full.\n        # Since all exact fits will have 0 remaining capacity after the item,\n        # we can assign a high, uniform score to them to prioritize them.\n        # We add a small penalty to break ties in a deterministic way, although for exact fit,\n        # any exact fit is generally considered equal.\n        priorities[exact_fit_mask] = 1.0\n\n        # To further differentiate among exact fits and prioritize the \"tightest\"\n        # (which in this case, after placing the item, all exact fits leave 0 space),\n        # we can assign a small negative bonus based on their original remaining capacity.\n        # This might seem counterintuitive for \"exact fit\", but if we interpret\n        # \"exact fit\" more broadly as \"closest to item size\", this would matter.\n        # For strict \"exact fit = item size\", all exact fits are equally good.\n        # For this implementation, let's prioritize exact fits and then by how\n        # little extra space is left. For exact fits, this extra space is 0.\n        # So, let's assign a higher priority to exact fits by simply making them positive.\n        # To make them *more* priority, we can give them a higher score.\n        # Let's assign a score that reflects \"best fit\" if it's an exact fit.\n        # We can think of this as `(bin_capacity - item) + penalty_for_exact_fit`.\n        # For exact fits, `bin_capacity - item` is 0.\n\n        # A more sophisticated approach for \"tightest\" exact fit would involve\n        # looking at bins that are *almost* exact fits if we allowed a small epsilon,\n        # but for strict exact fit, we assign a high priority.\n        # Let's assign a score that is higher than any non-exact fit score.\n        priorities[exact_fit_mask] = 1000.0  # High priority for exact fits\n    else:\n        # If no exact fit, find bins that can fit the item\n        can_fit_mask = bins_remain_cap >= item\n        if np.any(can_fit_mask):\n            # For bins that can fit, prioritize those with the smallest remaining capacity\n            # after placing the item (i.e., the \"tightest\" fit).\n            # The score is inversely related to the remaining capacity after placement.\n            # A bin with remaining capacity `c` for item `i` will have `c - i` remaining.\n            # We want to minimize `c - i`.\n            # So, higher priority for smaller `c - i`.\n            # Let's use `-(bins_remain_cap[can_fit_mask] - item)` as a priority score.\n            # Higher values of this (less negative) are better.\n            priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    # For any bins that cannot fit the item, their priority remains 0.\n    return priorities\n\n[Reflection]\nPrioritize exact fits. For others, minimize remaining space after packing.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}