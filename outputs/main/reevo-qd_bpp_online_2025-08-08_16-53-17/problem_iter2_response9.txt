```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority score for each bin using a hybrid approach prioritizing good fits and balancing exploration.

    This heuristic prioritizes bins that offer a "good fit" for the item, meaning
    their remaining capacity is slightly larger than the item size. It also
    incorporates an exploration component to occasionally consider less-full bins,
    balancing the "best fit" tendency with exploration of potential future packing
    opportunities.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A numpy array containing the remaining capacity of each bin.

    Returns:
        A numpy array of priority scores for each bin. Higher scores indicate a
        higher preference for placing the item in that bin.
    """
    epsilon = 0.1  # Probability of exploration (choosing a bin less greedily)
    k_steepness = 5.0  # Steepness parameter for the sigmoid function
    ideal_gap = 0.05  # The preferred remaining capacity beyond the item size

    num_bins = len(bins_remain_cap)
    priorities = np.zeros(num_bins)

    # Identify bins where the item can fit
    fits_mask = bins_remain_cap >= item
    fitting_bins_indices = np.where(fits_mask)[0]

    # If no bins can fit the item, return all zeros.
    if len(fitting_bins_indices) == 0:
        return priorities

    # --- Exploitation Component: Prioritize Good Fits ---
    # Calculate the "excess capacity" for bins where the item fits.
    # A good fit has a small, positive excess capacity.
    excess_capacities = bins_remain_cap[fitting_bins_indices] - item

    # Use a sigmoid function to score the "goodness" of the fit.
    # We want the score to peak when `excess_capacities` is close to `ideal_gap`.
    # The argument for the sigmoid is designed so that:
    # - When `excess_capacities == ideal_gap`, the argument is 0, sigmoid(0) = 0.5 (peak of the "good fit" score).
    # - When `excess_capacities` deviates from `ideal_gap` (either smaller or larger), the score decreases.
    # This formulation penalizes bins that are too empty or too full relative to the ideal gap.
    sigmoid_argument = k_steepness * (ideal_gap - excess_capacities)
    exploitation_scores = 1 / (1 + np.exp(-sigmoid_argument))

    # Normalize exploitation scores so they sum to 1 among fitting bins.
    # This helps in combining with exploration probabilities later if needed, or for clearer interpretation.
    # However, for direct preference scores, normalization might not be strictly required if scaled appropriately.
    # Let's scale them to be within a reasonable range for prioritization.
    # We can scale the 0.5 peak to a higher value for better differentiation if needed.
    # For now, let's use the raw sigmoid output (0 to 1).

    # --- Exploration Component ---
    # With probability epsilon, we want to explore other options.
    # We can assign a uniform, lower priority to all fitting bins to represent exploration.
    # The probability of choosing an exploratory bin is epsilon.
    # If we explore, we pick one of the fitting bins uniformly.
    # So, each fitting bin gets an additional 'exploration boost'.
    exploration_boost = epsilon / len(fitting_bins_indices)

    # --- Combine Exploitation and Exploration ---
    # The final priority for fitting bins is a weighted sum:
    # (1 - epsilon) * exploitation_score + epsilon * uniform_exploration_score
    # Here, the 'uniform_exploration_score' is implicitly handled by adding
    # the exploration boost.

    # Apply the combined strategy:
    # For fitting bins: priority = (1-epsilon) * normalized_exploitation_score + epsilon * (uniform score)
    # A simpler way to think is that the final score is a mix.
    # Let's consider the scores as probabilities of selection for a simplified view.
    # We want to assign scores reflecting preference.

    # Let's use the exploitation scores directly, but add an exploration bonus.
    # The exploration bonus makes less-preferred bins (by exploitation score) more competitive.
    # We add a constant exploration value to all fitting bins to ensure some randomness.
    # The value of exploration_boost is small, relative to the peak exploitation score (0.5).
    # We can add a scaled exploration value.
    exploration_value = epsilon * 0.5 # A smaller constant exploration value

    # The final priorities are a mix. We can think of it as:
    # A base score derived from exploitation, with a small random jitter or uniform boost for exploration.
    priorities[fitting_bins_indices] = exploitation_scores + exploration_value

    # Ensure scores are non-negative.
    priorities = np.maximum(priorities, 0)

    # Optional: Normalize priorities to sum to 1 if they represent probabilities of selection,
    # or just return them as preference scores. For selection, normalization is common.
    # Let's return them as preference scores, allowing the caller to normalize if needed.
    # A common strategy is to use these scores with a softmax-like selection mechanism.

    # For simplicity and direct preference, we can scale the exploitation scores
    # and add a smaller exploration component.
    # Let's re-scale exploitation_scores to have a max value higher than 0.5, e.g., 1.
    # Max exploitation score is 1 (when sigmoid_argument is large positive).
    # Min exploitation score is 0 (when sigmoid_argument is large negative).
    # Peak is 0.5.

    # Let's try a different combination:
    # Prioritize bins based on exploitation score, but ensure some chance for others.
    # If random draw < epsilon, pick a random fitting bin. Otherwise, pick based on exploitation.
    # This is more of a selection logic. For generating priority scores:
    # We want to combine the 'good fit' score with an exploration factor.

    # A common way to represent this combination is:
    # priority = (1-epsilon) * exploitation_score + epsilon * uniform_score
    # Where uniform_score is 1/num_fitting_bins.
    # Let's re-normalize exploitation scores first to sum to 1 for clarity in combination.
    if np.sum(exploitation_scores) > 0:
        normalized_exploitation_scores = exploitation_scores / np.sum(exploitation_scores)
    else:
        normalized_exploitation_scores = np.zeros_like(exploitation_scores) # Should not happen if fitting_bins exist

    # Uniform score for exploration among fitting bins
    uniform_exploration_score = 1.0 / len(fitting_bins_indices) if len(fitting_bins_indices) > 0 else 0.0

    # Combine them:
    combined_priorities = (1 - epsilon) * normalized_exploitation_scores + epsilon * uniform_exploration_score

    # Place these combined priorities back into the main priorities array
    priorities[fitting_bins_indices] = combined_priorities

    # Ensure all priorities are non-negative (should already be true)
    priorities = np.maximum(priorities, 0)

    return priorities
```
