{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, near-full bonuses, and adaptive weighting.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority, use reciprocal of waste\n        waste = np.abs(remaining_after_add[valid_mask])\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, give bonus to near full bins\n        near_full_bonus = np.where((bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item), item / bins_remain_cap[valid_mask] * 10, 0)\n\n        # Adaptive weighting based on remaining capacity distribution\n        capacity_mean = np.mean(bins_remain_cap[valid_mask]) if np.any(valid_mask) else np.mean(bins_remain_cap)\n        capacity_std = np.std(bins_remain_cap[valid_mask]) if np.any(valid_mask) and len(bins_remain_cap[valid_mask]) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 1.0\n        capacity_weight = 1.0\n\n        if capacity_std > 0.0:\n            capacity_normalized = (bins_remain_cap[valid_mask] - capacity_mean) / capacity_std\n            capacity_weight = 1.0 + np.tanh(capacity_normalized)\n\n        priorities[valid_mask] = waste_weight * waste_priority + near_full_weight * near_full_bonus + capacity_weight\n\n        # Fill percentage score from v1\n        fill_percentage = item / bins_remain_cap[valid_mask]\n        fill_score = np.exp(-np.abs(fill_percentage - 0.8))\n        priorities[valid_mask] += 0.5 * fill_score #balance between waste and fill\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, near-full bonuses, and adaptive weighting.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority, use reciprocal of waste\n        waste = np.abs(remaining_after_add[valid_mask])\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, give bonus to near full bins\n        near_full_bonus = np.where((bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item), item / bins_remain_cap[valid_mask] * 10, 0)\n\n        # Adaptive weighting based on remaining capacity distribution\n        capacity_mean = np.mean(bins_remain_cap[valid_mask]) if np.any(valid_mask) else np.mean(bins_remain_cap)\n        capacity_std = np.std(bins_remain_cap[valid_mask]) if np.any(valid_mask) and len(bins_remain_cap[valid_mask]) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 1.0\n        capacity_weight = 1.0\n\n        if capacity_std > 0.0:\n            capacity_normalized = (bins_remain_cap[valid_mask] - capacity_mean) / capacity_std\n            capacity_weight = 1.0 + np.tanh(capacity_normalized)\n\n        priorities[valid_mask] = waste_weight * waste_priority + near_full_weight * near_full_bonus + capacity_weight\n\n        # Fill percentage score from v1\n        fill_percentage = item / bins_remain_cap[valid_mask]\n        fill_score = np.exp(-np.abs(fill_percentage - 0.8))\n        priorities[valid_mask] += 0.5 * fill_score #balance between waste and fill\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, near-full bonuses, and adaptive weighting.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority, use reciprocal of waste\n        waste = np.abs(remaining_after_add[valid_mask])\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, give bonus to near full bins\n        near_full_bonus = np.where((bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item), item / bins_remain_cap[valid_mask] * 10, 0)\n\n        # Adaptive weighting based on remaining capacity distribution\n        capacity_mean = np.mean(bins_remain_cap[valid_mask]) if np.any(valid_mask) else np.mean(bins_remain_cap)\n        capacity_std = np.std(bins_remain_cap[valid_mask]) if np.any(valid_mask) and len(bins_remain_cap[valid_mask]) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 1.0\n        capacity_weight = 1.0\n\n        if capacity_std > 0.0:\n            capacity_normalized = (bins_remain_cap[valid_mask] - capacity_mean) / capacity_std\n            capacity_weight = 1.0 + np.tanh(capacity_normalized)\n\n        priorities[valid_mask] = waste_weight * waste_priority + near_full_weight * near_full_bonus + capacity_weight\n\n        # Fill percentage score from v1\n        fill_percentage = item / bins_remain_cap[valid_mask]\n        fill_score = np.exp(-np.abs(fill_percentage - 0.8))\n        priorities[valid_mask] += 0.5 * fill_score #balance between waste and fill\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, near-full bonuses, and adaptive weighting with numerical stability and a larger infeasibility penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get a very strong negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # A large negative value\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority, use reciprocal of waste\n        waste = remaining_after_add[valid_mask]\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, give bonus to near full bins but adjusted\n        near_full_bonus = np.where(\n            (bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item),\n            (item / bins_remain_cap[valid_mask]) ** 2 * 5, # Increase bonus effect with power\n            0\n        )\n\n        # Adaptive weighting based on remaining capacity distribution\n        capacity_mean = np.mean(bins_remain_cap[valid_mask]) if np.any(valid_mask) else np.mean(bins_remain_cap)\n        capacity_std = np.std(bins_remain_cap[valid_mask]) if np.any(valid_mask) and len(bins_remain_cap[valid_mask]) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 1.0\n        capacity_weight = 0.5  # Reduce capacity weight to avoid over-influence\n\n        if capacity_std > 0.0:\n            capacity_normalized = (bins_remain_cap[valid_mask] - capacity_mean) / capacity_std\n            capacity_weight = 0.5 + 0.5 * np.tanh(capacity_normalized)  # Scale between 0 and 1\n\n        priorities[valid_mask] = waste_weight * waste_priority + near_full_weight * near_full_bonus + capacity_weight\n\n        # Fill percentage score, adjusted for better weighting\n        fill_percentage = item / bins_remain_cap[valid_mask]\n        fill_score = np.exp(-5 * np.abs(fill_percentage - 0.8)) # Sharper peak\n        priorities[valid_mask] += 0.7 * fill_score # Increased influence, 0.7 ensures fill isn't overshadowed\n\n        # Introduce a penalty for bins with very little remaining capacity AFTER adding the item. This encourages filling bins more completely.\n        very_small_remaining_mask = remaining_after_add[valid_mask] < 0.1\n        priorities[valid_mask][very_small_remaining_mask] -= 1.5 # Penalty for almost full, but not full.\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, near-full bonuses, and adaptive weighting with numerical stability and a larger infeasibility penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get a very strong negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # A large negative value\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority, use reciprocal of waste\n        waste = remaining_after_add[valid_mask]\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, give bonus to near full bins but adjusted\n        near_full_bonus = np.where(\n            (bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item),\n            (item / bins_remain_cap[valid_mask]) ** 2 * 5, # Increase bonus effect with power\n            0\n        )\n\n        # Adaptive weighting based on remaining capacity distribution\n        capacity_mean = np.mean(bins_remain_cap[valid_mask]) if np.any(valid_mask) else np.mean(bins_remain_cap)\n        capacity_std = np.std(bins_remain_cap[valid_mask]) if np.any(valid_mask) and len(bins_remain_cap[valid_mask]) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 1.0\n        capacity_weight = 0.5  # Reduce capacity weight to avoid over-influence\n\n        if capacity_std > 0.0:\n            capacity_normalized = (bins_remain_cap[valid_mask] - capacity_mean) / capacity_std\n            capacity_weight = 0.5 + 0.5 * np.tanh(capacity_normalized)  # Scale between 0 and 1\n\n        priorities[valid_mask] = waste_weight * waste_priority + near_full_weight * near_full_bonus + capacity_weight\n\n        # Fill percentage score, adjusted for better weighting\n        fill_percentage = item / bins_remain_cap[valid_mask]\n        fill_score = np.exp(-5 * np.abs(fill_percentage - 0.8)) # Sharper peak\n        priorities[valid_mask] += 0.7 * fill_score # Increased influence, 0.7 ensures fill isn't overshadowed\n\n        # Introduce a penalty for bins with very little remaining capacity AFTER adding the item. This encourages filling bins more completely.\n        very_small_remaining_mask = remaining_after_add[valid_mask] < 0.1\n        priorities[valid_mask][very_small_remaining_mask] -= 1.5 # Penalty for almost full, but not full.\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights based on item size and capacity distribution.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n\n    # Waste priority, use reciprocal of waste\n    waste = np.abs(remaining_after_add)\n    waste_priority = 1.0 / (waste + epsilon)\n\n    # Near-full bonus, give bonus to near full bins\n    near_full_bonus = np.where((bins_remain_cap > item) & (bins_remain_cap <= 2 * item), item / bins_remain_cap * 10, 0)\n    \n    # Capacity based priority, favor larger remaining capacity\n    capacity_priority = np.sqrt(bins_remain_cap) / (item + epsilon)\n\n    # Adaptive weighting based on remaining capacity distribution\n    capacity_mean = np.mean(bins_remain_cap[bins_remain_cap >= item]) if np.any(bins_remain_cap >= item) else np.mean(bins_remain_cap) #Avoid empty array\n    capacity_std = np.std(bins_remain_cap[bins_remain_cap >= item]) if np.any(bins_remain_cap >= item) and len(bins_remain_cap[bins_remain_cap >= item]) > 1 else 0.1 # Avoid empty array and zero std\n    \n    #weights\n    waste_weight = 1.0\n    near_full_weight = 1.0\n    capacity_weight = 1.0\n    \n    if capacity_std > 0.0:\n        capacity_normalized = (bins_remain_cap - capacity_mean) / capacity_std #standardize remaining capacity\n        capacity_weight = 1.0 + np.tanh(capacity_normalized) #adaptive: favors bins more above the mean\n\n    # Adaptive weighting based on item size\n    if item > 0.5: # Large items, prioritize waste minimization and near-full\n        waste_weight = 0.6\n        near_full_weight = 0.3\n        capacity_weight = 0.1\n    else: # Small items, prioritize capacity and near-full\n        waste_weight = 0.2\n        near_full_weight = 0.4\n        capacity_weight = 0.4\n\n    # Combine all priorities with adaptive weights\n    valid_mask = remaining_after_add >= 0\n    priorities[valid_mask] = waste_weight * waste_priority[valid_mask] + near_full_weight * near_full_bonus[valid_mask] + capacity_weight * capacity_priority[valid_mask]\n\n    # Experiment with a different bonus structure for very small remaining capacity\n    very_small_bonus = np.where((remaining_after_add > 0) & (remaining_after_add < 0.1), 100/(remaining_after_add + epsilon), 0)\n\n    priorities[valid_mask] = priorities[valid_mask] + very_small_bonus[valid_mask]\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, near-full bonus, and capacity using adaptive weights.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Waste priority, use exponential decay\n    waste = bins_remain_cap - item\n    feasible_mask = bins_remain_cap >= item\n    priorities[feasible_mask] = np.exp(-waste[feasible_mask] / (item + epsilon))\n\n    # Near-full bonus, give bonus to near full bins, scaled by item size\n    near_full_mask = (bins_remain_cap >= item) & (waste < 0.1)\n    priorities[near_full_mask] += 2\n\n    # Capacity based priority, favor larger remaining capacity.\n    capacity_priority = np.sqrt(bins_remain_cap) / (item + epsilon)\n    priorities[feasible_mask] += 0.5 * capacity_priority[feasible_mask]\n\n    # Adaptive Weighting based on remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n\n    if total_capacity > 0:\n        waste_weight = min(1.0, item / total_capacity * 5)\n        near_full_weight = min(1.0, total_capacity / (np.sum(item)+epsilon) * 0.1)\n        capacity_weight = 1.0 - waste_weight - near_full_weight\n    else:\n        waste_weight = 0.33\n        near_full_weight = 0.33\n        capacity_weight = 0.34\n\n    # Combine all priorities with adaptive weights\n    priorities[~infeasible_mask] = (waste_weight * priorities[~infeasible_mask] +\n                                     near_full_weight * near_full_mask[~infeasible_mask]*2 +\n                                     capacity_weight * capacity_priority[~infeasible_mask])\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, fill ratio, and adaptive weighting.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Waste priority: use reciprocal of waste, scaled by item size.\n    remaining_after_add = bins_remain_cap - item\n    waste = np.abs(remaining_after_add)\n    waste_priority = item / (waste + epsilon)\n\n    # Fill ratio score\n    ratios = item / (bins_remain_cap + epsilon)\n    fill_score = np.exp(-np.abs(ratios - 1) * 5)  # Keep same as v1\n\n    # Adaptive Weighting\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity > 0:\n        waste_weight = min(1.0, item / total_capacity * 5) # Scale based on the item size compared to total cap\n        fill_weight = 1.0 - waste_weight\n    else:\n        waste_weight = 0.5\n        fill_weight = 0.5\n\n    # Combine priorities with adaptive weights\n    priorities[~infeasible_mask] = (waste_weight * waste_priority[~infeasible_mask] +\n                                     fill_weight * fill_score[~infeasible_mask])\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, near-full bonuses, adaptive weighting,\n    and explicit penalties for creating small remaining gaps.\n\n    Prioritizes bins that:\n    1. Fit the item (strongly penalizes infeasible bins)\n    2. Minimize waste after packing\n    3. Avoid creating very small gaps which are hard to fill later\n    4. Adapts to capacity distribution.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # --- Infeasibility Penalty ---\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # Very strong penalty\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # --- Waste Minimization ---\n        waste = remaining_after_add[valid_mask]\n        waste_priority = -waste  # Lower waste is better (negative waste)\n\n        # --- Small Gap Penalty ---\n        small_gap_threshold = 0.1  #tunable, prevents creating small gaps\n        small_gap_penalty = np.where((remaining_after_add[valid_mask] > 0) & (remaining_after_add[valid_mask] < small_gap_threshold), -100, 0)  # Penalty for creating tiny gaps. tunable scalar\n       \n\n        # --- Adaptive Weighting based on Capacity Distribution ---\n        capacity_mean = np.mean(bins_remain_cap[valid_mask]) if np.any(valid_mask) else np.mean(bins_remain_cap)\n        capacity_std = np.std(bins_remain_cap[valid_mask]) if np.any(valid_mask) and len(bins_remain_cap[valid_mask]) > 1 else 0.1\n\n        capacity_normalized = (bins_remain_cap[valid_mask] - capacity_mean) / (capacity_std + epsilon)\n        capacity_priority = np.tanh(capacity_normalized) # Prioritize bins further from the mean, normalized\n        \n        # --- Near-Full Bonus (weaker)---\n        near_full_bonus = np.where((bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item), item / bins_remain_cap[valid_mask] * 10, 0)\n\n        # --- Combine Priorities ---\n        waste_weight = 1.0\n        small_gap_weight = 1.0\n        capacity_weight = 0.5 # Lower importance\n        near_full_weight = 0.1\n\n        priorities[valid_mask] = (\n            waste_weight * waste_priority +\n            small_gap_weight * small_gap_penalty +\n            capacity_weight * capacity_priority +\n            near_full_weight * near_full_bonus\n        )\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights: remaining capacity distribution & item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n    \n    # Waste priority, use reciprocal of waste\n    waste = np.abs(remaining_after_add)\n    waste_priority = 1.0 / (waste + epsilon)\n\n    # Near-full bonus, give bonus to near full bins\n    near_full_bonus = np.where((bins_remain_cap > item) & (bins_remain_cap <= 2 * item), item / bins_remain_cap * 10, 0)\n    \n    # Capacity based priority, favor larger remaining capacity\n    capacity_priority = np.sqrt(bins_remain_cap) / (item + epsilon)\n\n    # Adaptive weighting based on remaining capacity distribution\n    capacity_mean = np.mean(bins_remain_cap[bins_remain_cap >= item]) if np.any(bins_remain_cap >= item) else np.mean(bins_remain_cap) #Avoid empty array\n    capacity_std = np.std(bins_remain_cap[bins_remain_cap >= item]) if np.any(bins_remain_cap >= item) and len(bins_remain_cap[bins_remain_cap >= item]) > 1 else 0.1 # Avoid empty array and zero std\n    \n    #weights - Item-size adaptive\n    if item < 0.2:  # Small items, prioritize waste minimization and capacity\n        waste_weight = 0.6\n        near_full_weight = 0.1\n        capacity_weight = 0.3\n    elif item > 0.8:  # Large items, prioritize near-full and avoid fragmentation\n        waste_weight = 0.1\n        near_full_weight = 0.6\n        capacity_weight = 0.3\n    else:  # Medium items, balance all factors\n        waste_weight = 0.3\n        near_full_weight = 0.4\n        capacity_weight = 0.3\n\n    #capacity_normalized = (bins_remain_cap - capacity_mean) / capacity_std\n    #capacity_weight2 = 1.0 + np.tanh(capacity_normalized) if capacity_std > 0 else 1.0\n\n    # Combine all priorities\n    valid_mask = remaining_after_add >= 0\n    priorities[valid_mask] = waste_weight * waste_priority[valid_mask] + near_full_weight * near_full_bonus[valid_mask] + capacity_weight * capacity_priority[valid_mask]\n\n    # Introduce a penalty for bins that become too empty after adding the item\n    empty_penalty = np.where(remaining_after_add > 0.7, -0.5 * (remaining_after_add - 0.7), 0)  #if remaining cap > 0.7, penalize\n    priorities = np.where(remaining_after_add >= 0, priorities + empty_penalty, priorities)\n\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights based on capacity distribution.\n    Combines waste, fill percentage, and near-full penalties.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    epsilon = 1e-9\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = 1 / (waste + epsilon)\n\n        new_capacities = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.zeros_like(new_capacities)\n\n        near_full_mask = new_capacities < 0.1\n        near_full_penalty[near_full_mask] = -100\n\n        near_full_mask2 = (new_capacities >= 0.1) & (new_capacities < 0.3)\n        near_full_penalty[near_full_mask2] = -2 * (0.3 - new_capacities[near_full_mask2])**2\n        \n        priorities[valid_bins] += near_full_penalty\n        \n        fill_percentage = item / bins_remain_cap[valid_bins]\n        fill_score = np.exp(-np.abs(fill_percentage - 0.8))\n        \n        # Adaptive Weighting\n        total_capacity = np.sum(bins_remain_cap)\n        if total_capacity < 5 * item:\n            fill_weight = 0.3\n            waste_weight = 0.7\n        elif total_capacity > 20 * item:\n            fill_weight = 0.7\n            waste_weight = 0.3\n        else:\n            fill_weight = 0.5\n            waste_weight = 0.5\n\n        priorities[valid_bins] = waste_weight * (1 / (waste + epsilon)) + fill_weight * fill_score #balance between waste and fill\n\n    else:\n        priorities = np.full_like(bins_remain_cap, -1000.0)\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights based on capacity distribution.\n    Combines waste, fill percentage, and near-full penalties.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    epsilon = 1e-9\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = 1 / (waste + epsilon)\n\n        new_capacities = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.zeros_like(new_capacities)\n\n        near_full_mask = new_capacities < 0.1\n        near_full_penalty[near_full_mask] = -100\n\n        near_full_mask2 = (new_capacities >= 0.1) & (new_capacities < 0.3)\n        near_full_penalty[near_full_mask2] = -2 * (0.3 - new_capacities[near_full_mask2])**2\n        \n        priorities[valid_bins] += near_full_penalty\n        \n        fill_percentage = item / bins_remain_cap[valid_bins]\n        fill_score = np.exp(-np.abs(fill_percentage - 0.8))\n        \n        # Adaptive Weighting\n        total_capacity = np.sum(bins_remain_cap)\n        if total_capacity < 5 * item:\n            fill_weight = 0.3\n            waste_weight = 0.7\n        elif total_capacity > 20 * item:\n            fill_weight = 0.7\n            waste_weight = 0.3\n        else:\n            fill_weight = 0.5\n            waste_weight = 0.5\n\n        priorities[valid_bins] = waste_weight * (1 / (waste + epsilon)) + fill_weight * fill_score #balance between waste and fill\n\n    else:\n        priorities = np.full_like(bins_remain_cap, -1000.0)\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, near-full bonuses, adaptive weighting,\n    and fill percentage, with robust infeasibility handling and calibrated weights.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Strong infeasibility penalty\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # Significantly larger penalty\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority (reciprocal, stabilized)\n        waste = remaining_after_add[valid_mask]\n        waste_priority = 1.0 / (waste + 0.1 * item + epsilon)  # Stabilized by item size\n\n        # Near-full bonus (only when item fits reasonably well)\n        near_full_bonus = np.where(\n            (bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item),\n            (item / bins_remain_cap[valid_mask])**2 * 5,  # Reduced magnitude, polynomial\n            0\n        )\n\n        # Fill percentage score\n        fill_percentage = item / bins_remain_cap[valid_mask]\n        fill_score = np.exp(-10 * np.abs(fill_percentage - 0.8)) #Stronger penalty\n\n        # Adaptive weighting based on remaining capacity distribution (dampened)\n        capacity_mean = np.mean(bins_remain_cap[valid_mask]) if np.any(valid_mask) else np.mean(bins_remain_cap)\n        capacity_std = np.std(bins_remain_cap[valid_mask]) if np.any(valid_mask) and len(bins_remain_cap[valid_mask]) > 1 else 0.1\n        capacity_normalized = (bins_remain_cap[valid_mask] - capacity_mean) / (capacity_std + epsilon)\n        capacity_weight = 0.5 + 0.5 * np.tanh(capacity_normalized)  # Scaled tanh for stability\n\n\n        # Calibrated weights (data-driven tuning is essential)\n        waste_weight = 1.0\n        near_full_weight = 0.75 # Reduced near-full weight\n        fill_weight = 0.6 # Reduced fill weight\n        capacity_weight_final = 0.25\n\n\n        priorities[valid_mask] = (\n            waste_weight * waste_priority\n            + near_full_weight * near_full_bonus\n            + fill_weight * fill_score\n            + capacity_weight_final*capacity_weight\n        )\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, near-full bonuses, adaptive weighting based on bin utilization,\n    and penalty for bins that will be overfilled. Aims for a more balanced and robust approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Strong penalty for infeasible bins\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # Significantly stronger penalty than before\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority (reciprocal of waste, as before)\n        waste = np.abs(remaining_after_add[valid_mask])\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, but more conservative and adaptive\n        near_full_bonus = np.where(\n            (bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item),\n            item / bins_remain_cap[valid_mask] * 5,  # Reduced magnitude of bonus\n            0\n        )\n\n        # Adaptive weighting based on bin utilization\n        bin_utilization = (bins_remain_cap - remaining_after_add) / bins_remain_cap # calculate how much space we will be using in the bin\n        bin_utilization = bin_utilization[valid_mask]\n\n        # Scale the values for better control over the weights\n        utilization_mean = np.mean(bin_utilization) if np.any(valid_mask) else 0.5\n        utilization_std = np.std(bin_utilization) if np.any(valid_mask) and len(bin_utilization) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 0.75  # Slightly reduce the importance of near-full bonus\n        utilization_weight = 0.5 # Weight for utilization factor\n\n        # Prioritize bins with lower utilization if item is small\n        if item < np.mean(bins_remain_cap):\n            utilization_priority = 1 - bin_utilization\n        else: # Prioritize bins with higher utilization if item is large\n            utilization_priority = bin_utilization\n\n        # Combine priorities with adaptive weights\n        priorities[valid_mask] = (\n            waste_weight * waste_priority +\n            near_full_weight * near_full_bonus +\n            utilization_weight * utilization_priority\n        )\n\n        # Reduce priority if the item will make the bin nearly full (risk of fragmentation)\n        nearly_full_penalty = np.where(remaining_after_add[valid_mask] < 0.1 * bins_remain_cap[valid_mask], -10, 0)\n        priorities[valid_mask] += nearly_full_penalty\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, near-full bonuses, adaptive weighting based on bin utilization,\n    and penalty for bins that will be overfilled. Aims for a more balanced and robust approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Strong penalty for infeasible bins\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # Significantly stronger penalty than before\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority (reciprocal of waste, as before)\n        waste = np.abs(remaining_after_add[valid_mask])\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, but more conservative and adaptive\n        near_full_bonus = np.where(\n            (bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item),\n            item / bins_remain_cap[valid_mask] * 5,  # Reduced magnitude of bonus\n            0\n        )\n\n        # Adaptive weighting based on bin utilization\n        bin_utilization = (bins_remain_cap - remaining_after_add) / bins_remain_cap # calculate how much space we will be using in the bin\n        bin_utilization = bin_utilization[valid_mask]\n\n        # Scale the values for better control over the weights\n        utilization_mean = np.mean(bin_utilization) if np.any(valid_mask) else 0.5\n        utilization_std = np.std(bin_utilization) if np.any(valid_mask) and len(bin_utilization) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 0.75  # Slightly reduce the importance of near-full bonus\n        utilization_weight = 0.5 # Weight for utilization factor\n\n        # Prioritize bins with lower utilization if item is small\n        if item < np.mean(bins_remain_cap):\n            utilization_priority = 1 - bin_utilization\n        else: # Prioritize bins with higher utilization if item is large\n            utilization_priority = bin_utilization\n\n        # Combine priorities with adaptive weights\n        priorities[valid_mask] = (\n            waste_weight * waste_priority +\n            near_full_weight * near_full_bonus +\n            utilization_weight * utilization_priority\n        )\n\n        # Reduce priority if the item will make the bin nearly full (risk of fragmentation)\n        nearly_full_penalty = np.where(remaining_after_add[valid_mask] < 0.1 * bins_remain_cap[valid_mask], -10, 0)\n        priorities[valid_mask] += nearly_full_penalty\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, near-full bonuses, adaptive weighting based on bin utilization,\n    and penalty for bins that will be overfilled. Aims for a more balanced and robust approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Strong penalty for infeasible bins\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # Significantly stronger penalty than before\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority (reciprocal of waste, as before)\n        waste = np.abs(remaining_after_add[valid_mask])\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, but more conservative and adaptive\n        near_full_bonus = np.where(\n            (bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item),\n            item / bins_remain_cap[valid_mask] * 5,  # Reduced magnitude of bonus\n            0\n        )\n\n        # Adaptive weighting based on bin utilization\n        bin_utilization = (bins_remain_cap - remaining_after_add) / bins_remain_cap # calculate how much space we will be using in the bin\n        bin_utilization = bin_utilization[valid_mask]\n\n        # Scale the values for better control over the weights\n        utilization_mean = np.mean(bin_utilization) if np.any(valid_mask) else 0.5\n        utilization_std = np.std(bin_utilization) if np.any(valid_mask) and len(bin_utilization) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 0.75  # Slightly reduce the importance of near-full bonus\n        utilization_weight = 0.5 # Weight for utilization factor\n\n        # Prioritize bins with lower utilization if item is small\n        if item < np.mean(bins_remain_cap):\n            utilization_priority = 1 - bin_utilization\n        else: # Prioritize bins with higher utilization if item is large\n            utilization_priority = bin_utilization\n\n        # Combine priorities with adaptive weights\n        priorities[valid_mask] = (\n            waste_weight * waste_priority +\n            near_full_weight * near_full_bonus +\n            utilization_weight * utilization_priority\n        )\n\n        # Reduce priority if the item will make the bin nearly full (risk of fragmentation)\n        nearly_full_penalty = np.where(remaining_after_add[valid_mask] < 0.1 * bins_remain_cap[valid_mask], -10, 0)\n        priorities[valid_mask] += nearly_full_penalty\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, near-full bonuses, adaptive weighting based on bin utilization,\n    and penalty for bins that will be overfilled. Aims for a more balanced and robust approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Strong penalty for infeasible bins\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -1e9  # Significantly stronger penalty than before\n\n    valid_mask = remaining_after_add >= 0\n\n    if np.any(valid_mask):\n        # Waste priority (reciprocal of waste, as before)\n        waste = np.abs(remaining_after_add[valid_mask])\n        waste_priority = 1.0 / (waste + epsilon)\n\n        # Near-full bonus, but more conservative and adaptive\n        near_full_bonus = np.where(\n            (bins_remain_cap[valid_mask] > item) & (bins_remain_cap[valid_mask] <= 2 * item),\n            item / bins_remain_cap[valid_mask] * 5,  # Reduced magnitude of bonus\n            0\n        )\n\n        # Adaptive weighting based on bin utilization\n        bin_utilization = (bins_remain_cap - remaining_after_add) / bins_remain_cap # calculate how much space we will be using in the bin\n        bin_utilization = bin_utilization[valid_mask]\n\n        # Scale the values for better control over the weights\n        utilization_mean = np.mean(bin_utilization) if np.any(valid_mask) else 0.5\n        utilization_std = np.std(bin_utilization) if np.any(valid_mask) and len(bin_utilization) > 1 else 0.1\n\n        waste_weight = 1.0\n        near_full_weight = 0.75  # Slightly reduce the importance of near-full bonus\n        utilization_weight = 0.5 # Weight for utilization factor\n\n        # Prioritize bins with lower utilization if item is small\n        if item < np.mean(bins_remain_cap):\n            utilization_priority = 1 - bin_utilization\n        else: # Prioritize bins with higher utilization if item is large\n            utilization_priority = bin_utilization\n\n        # Combine priorities with adaptive weights\n        priorities[valid_mask] = (\n            waste_weight * waste_priority +\n            near_full_weight * near_full_bonus +\n            utilization_weight * utilization_priority\n        )\n\n        # Reduce priority if the item will make the bin nearly full (risk of fragmentation)\n        nearly_full_penalty = np.where(remaining_after_add[valid_mask] < 0.1 * bins_remain_cap[valid_mask], -10, 0)\n        priorities[valid_mask] += nearly_full_penalty\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting based on capacity and waste minimization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n\n    # Waste priority, use reciprocal of waste\n    waste = np.abs(remaining_after_add)\n    waste_priority = 1.0 / (waste + epsilon)\n\n    # Near-full penalty, give penalty to near full bins\n    near_full_penalty = np.where((bins_remain_cap > item) & (bins_remain_cap <= 2 * item), -item / bins_remain_cap * 10, 0)\n    \n    # Capacity based priority, favor larger remaining capacity\n    capacity_priority = np.sqrt(bins_remain_cap) / (item + epsilon)\n\n    # Adaptive weighting based on total capacity\n    total_capacity = np.sum(bins_remain_cap)\n    waste_weight = 0.4\n    near_full_weight = 0.3\n    capacity_weight = 0.3\n    \n    if total_capacity < 5 * item:\n        waste_weight = 0.2\n        near_full_weight = 0.5\n        capacity_weight = 0.3\n    elif total_capacity > 20 * item:\n        waste_weight = 0.5\n        near_full_weight = 0.2\n        capacity_weight = 0.3\n\n    # Combine all priorities with adaptive weights\n    priorities = np.where(~infeasible_mask, waste_weight * waste_priority + near_full_weight * near_full_penalty + capacity_weight * capacity_priority, priorities)\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting based on capacity and waste minimization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n\n    # Waste priority, use reciprocal of waste\n    waste = np.abs(remaining_after_add)\n    waste_priority = 1.0 / (waste + epsilon)\n\n    # Near-full penalty, give penalty to near full bins\n    near_full_penalty = np.where((bins_remain_cap > item) & (bins_remain_cap <= 2 * item), -item / bins_remain_cap * 10, 0)\n    \n    # Capacity based priority, favor larger remaining capacity\n    capacity_priority = np.sqrt(bins_remain_cap) / (item + epsilon)\n\n    # Adaptive weighting based on total capacity\n    total_capacity = np.sum(bins_remain_cap)\n    waste_weight = 0.4\n    near_full_weight = 0.3\n    capacity_weight = 0.3\n    \n    if total_capacity < 5 * item:\n        waste_weight = 0.2\n        near_full_weight = 0.5\n        capacity_weight = 0.3\n    elif total_capacity > 20 * item:\n        waste_weight = 0.5\n        near_full_weight = 0.2\n        capacity_weight = 0.3\n\n    # Combine all priorities with adaptive weights\n    priorities = np.where(~infeasible_mask, waste_weight * waste_priority + near_full_weight * near_full_penalty + capacity_weight * capacity_priority, priorities)\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting based on capacity and waste minimization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    remaining_after_add = bins_remain_cap - item\n    epsilon = 1e-9\n\n    # Infeasible bins get strongly negative priority\n    infeasible_mask = remaining_after_add < 0\n    priorities[infeasible_mask] = -np.inf\n\n    # Waste priority, use reciprocal of waste\n    waste = np.abs(remaining_after_add)\n    waste_priority = 1.0 / (waste + epsilon)\n\n    # Near-full penalty, give penalty to near full bins\n    near_full_penalty = np.where((bins_remain_cap > item) & (bins_remain_cap <= 2 * item), -item / bins_remain_cap * 10, 0)\n    \n    # Capacity based priority, favor larger remaining capacity\n    capacity_priority = np.sqrt(bins_remain_cap) / (item + epsilon)\n\n    # Adaptive weighting based on total capacity\n    total_capacity = np.sum(bins_remain_cap)\n    waste_weight = 0.4\n    near_full_weight = 0.3\n    capacity_weight = 0.3\n    \n    if total_capacity < 5 * item:\n        waste_weight = 0.2\n        near_full_weight = 0.5\n        capacity_weight = 0.3\n    elif total_capacity > 20 * item:\n        waste_weight = 0.5\n        near_full_weight = 0.2\n        capacity_weight = 0.3\n\n    # Combine all priorities with adaptive weights\n    priorities = np.where(~infeasible_mask, waste_weight * waste_priority + near_full_weight * near_full_penalty + capacity_weight * capacity_priority, priorities)\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}