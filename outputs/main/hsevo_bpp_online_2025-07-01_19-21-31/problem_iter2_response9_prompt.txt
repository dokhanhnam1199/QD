{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the celestial dance, where larger bodies exert greater influence.\n    A bin with capacity closest to the item size receives higher priority,\n    but also considering a penalty for near-overflow.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between the remaining capacity and the item size\n    diffs = bins_remain_cap - item\n\n    # Initialize priorities with a base score (e.g., inverse of absolute difference).\n    # We want bins where the remaining capacity is close to the item size.\n    priorities = 1.0 / (np.abs(diffs) + 0.000001) # Add small constant to prevent division by zero\n\n    # Apply a significant penalty for bins where adding the item would overflow.\n    overflow_penalty = 1000.0  # A high value to strongly discourage overflows.\n    priorities[diffs < 0] = -overflow_penalty\n\n    # Bins that fit perfectly are ideal, reward them.\n    perfect_fit_bonus = 10.0 # Give a sizable bonus for perfect fit\n    priorities[diffs == 0] += perfect_fit_bonus\n\n    # Slightly favor fuller bins to consolidate existing packing.\n    # This term is relatively small to not dominate the previous calculations.\n    capacity_utilization = (1 - bins_remain_cap / np.max(bins_remain_cap)) if np.max(bins_remain_cap) > 0 else np.zeros_like(bins_remain_cap)\n    priorities += 0.1 * capacity_utilization\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Uses a combination of remaining capacity and waste minimization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate remaining capacity *after* adding the item to each bin.\n    remaining_after_add = bins_remain_cap - item\n\n    # Assign a low priority to bins that cannot fit the item.\n    priorities = np.where(remaining_after_add >= 0, 0.0, -np.inf)\n\n    # For bins that can fit the item, prioritize bins with\n    # small remaining capacity (minimize waste), but also with\n    # enough capacity left to potentially accommodate future larger items.\n    # A sweet spot is targeted. This is done through a weighted combination:\n    # waste_penalty favors less waste (lower remaining_after_add)\n    # future_potential_reward favors bins with more capacity to handle future jobs\n    waste_penalty = -np.abs(remaining_after_add)  # Prefer smaller remaining space.\n\n    #Calculate standard deviation for all items added so far\n    std_dev_estimated_item_size = 0.2  # Estimate based on previous runs\n\n    future_potential_reward = remaining_after_add/(np.sqrt(std_dev_estimated_item_size**2+0.001)) #avoid division by zero error\n\n    # Combine the waste penalty and future potential reward\n    priorities = np.where(remaining_after_add >= 0, waste_penalty + 0.5 *future_potential_reward, priorities)\n\n    # Give a slight bump to bins that are already somewhat full to avoid very sparse bins.\n    # full_bonus = np.where(bins_remain_cap < 0.8,0,1) #only applies when capacity less than .8\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st heuristic avoids division by zero errors and has a mechanism to discourage filling bins completely. The 20th heuristic, while considering waste minimization and future potential reward, lacks explicit handling of edge cases and complete filling.\n\nComparing (2nd) vs (19th), 2nd heuristic boosts priority when near full and adds ratio of item size, while 19th heuristic calculates waste penalty.\n\nComparing (3rd) vs (4th), the 3rd heuristic uses a Newtonian \"gravitational attraction\" analogy, penalizing bins that are too full with negative infinity. The 4th heuristic gives a negative priority to almost full bins.\n\nComparing (second worst) vs (worst), the 17th heuristic considers a balance between minimizing waste and future potential reward, incorporating an estimate of item size standard deviation, while 20th heuristic do the same as 17th heuristic.\n\nComparing (1st) vs (2nd), the 1st heuristic avoid division by zero by adding a small value while 2nd heuristic avoid division by zero in another way by adding small value to denominator.\n\nComparing (3rd) vs (4th), heuristic 3 uses -np.inf to penalize, while heuristic 4 uses -1000 value.\n\nOverall: The better heuristics appear to prioritize avoiding edge cases (division by zero), encourage fuller bins without completely filling them, consider waste minimization, and some mechanism to avoid extreme fragmentation. Simpler heuristics focusing on the core logic of fitting and waste performed better than complex analogies. Penalties for infeasible bins vary in magnitude, but large negative values are common. The better heuristics combined multiple factors, such as remaining capacity and waste, using weighted sums or other combination methods.\n- \nOkay, let's refine \"Current Self-Reflection\" to make it more effective for designing heuristics, steering clear of pitfalls.\n\nHere's a revised approach, focusing on a proactive and analytical mindset:\n\n*   **Keywords:** Robustness, Simplicity, Penalties, Critical Analysis, Iterative Refinement.\n*   **Advice:** Systematically test heuristic performance on diverse datasets, including edge cases. Analyze *why* failures occur. Prioritize ease of understanding and modification.\n*   **Avoid:** Solely focusing on initial success. Blindly applying penalties without understanding their impact on overall solution quality. Premature optimization.\n*   **Explanation:** Heuristics should be tested rigorously. Penalties help in exploration, but require careful calibration. Simple heuristics allow easier analysis. Iterative refinement is key to improvement.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}