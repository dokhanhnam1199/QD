```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines inverse slack, fill bias, UCB, learning, and exploration to score bins for online BPP.
    """
    global _selection_counts, _total_rewards, _total_calls, _bin_capacity
    caps = np.asarray(bins_remain_cap, dtype=float)
    n = caps.size
    if n == 0:
        return np.array([], dtype=float)
    if '_selection_counts' not in globals() or _selection_counts.shape[0] != n:
        _selection_counts = np.zeros(n, dtype=int)
        _total_rewards = np.zeros(n, dtype=float)
        _total_calls = 0
        _bin_capacity = caps.max() if n > 0 else 1.0
    elif caps.max() > _bin_capacity:
        _bin_capacity = caps.max()
    feasible = caps >= item
    if not np.any(feasible):
        return np.full_like(caps, -np.inf)
    slack = caps - item
    inv_slack = 1.0 / (slack + 1e-9)
    fill = 1.0 - slack / _bin_capacity
    median_slack = np.median(slack[feasible]) if np.any(feasible) else 0.0
    diversity = median_slack - slack
    ucb = np.zeros(n, dtype=float)
    mask_ucb = _selection_counts > 0
    if _total_calls > 0 and np.any(mask_ucb):
        ucb[mask_ucb] = np.sqrt(2 * np.log(_total_calls) / _selection_counts[mask_ucb])
    avg_reward = np.zeros(n, dtype=float)
    mask_reward = _selection_counts > 0
    if np.any(mask_reward):
        avg_reward[mask_reward] = _total_rewards[mask_reward] / _selection_counts[mask_reward]
    combined = (
        1.0 * inv_slack
        + 0.3 * fill
        + 0.1 * diversity
        + 0.1 * avg_reward
        + 0.2 * ucb
    )
    epsilon = 0.15
    rand = np.random.rand(n)
    scores = np.full_like(caps, -np.inf, dtype=float)
    scores[feasible] = (1 - epsilon) * combined[feasible] + epsilon * rand[feasible]
    best_idx = int(np.argmax(scores))
    if feasible[best_idx]:
        reward = -(caps[best_idx] - item)
        _selection_counts[best_idx] += 1
        _total_rewards[best_idx] += reward
    _total_calls += 1
    return scores
```
