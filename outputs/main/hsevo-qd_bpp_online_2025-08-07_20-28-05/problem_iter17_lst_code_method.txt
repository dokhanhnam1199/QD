{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = 1.0 / (leftovers + 1.0)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = 1.0 / (leftovers + 1.0)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = 1.0 / (leftovers + 1.0)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 4th]\nimport numpy as np\n\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Inverse slack + epsilon random + avg reward for online bin packing.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = bins_remain_cap >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - epsilon) * deterministic + epsilon * random_part\n    avg_reward = np.zeros_like(base_score)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    reward_weight = 0.3\n    combined = base_score + reward_weight * avg_reward\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    _total_calls += 1\n    reward = - (bins_remain_cap[best] - item)\n    _selection_counts[best] += 1\n    _total_rewards[best] += reward\n    return scores\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * deterministic + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * deterministic + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.3272578070972282,\n                offset: float = 3.6930496425184325,\n                score_scale: float = 1.8547777441606528) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins given an item size.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of bins.\n    epsilon : float, optional\n        Weight for the random exploration term (default 0.2).\n    offset : float, optional\n        Small constant added to leftover capacity to avoid division by zero\n        (default 1.0).\n    score_scale : float, optional\n        Scaling factor for the deterministic part of the score\n        (default 1.0).\n\n    Returns\n    -------\n    np.ndarray\n        Score for each bin; -inf for infeasible bins.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = score_scale / (leftovers + offset)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.3272578070972282,\n                offset: float = 3.6930496425184325,\n                score_scale: float = 1.8547777441606528) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins given an item size.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of bins.\n    epsilon : float, optional\n        Weight for the random exploration term (default 0.2).\n    offset : float, optional\n        Small constant added to leftover capacity to avoid division by zero\n        (default 1.0).\n    score_scale : float, optional\n        Scaling factor for the deterministic part of the score\n        (default 1.0).\n\n    Returns\n    -------\n    np.ndarray\n        Score for each bin; -inf for infeasible bins.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = score_scale / (leftovers + offset)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 9th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.3272578070972282,\n                offset: float = 3.6930496425184325,\n                score_scale: float = 1.8547777441606528) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins given an item size.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of bins.\n    epsilon : float, optional\n        Weight for the random exploration term (default 0.2).\n    offset : float, optional\n        Small constant added to leftover capacity to avoid division by zero\n        (default 1.0).\n    score_scale : float, optional\n        Scaling factor for the deterministic part of the score\n        (default 1.0).\n\n    Returns\n    -------\n    np.ndarray\n        Score for each bin; -inf for infeasible bins.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = score_scale / (leftovers + offset)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 10th]\nimport numpy as np\n\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\n# Priority combines inverse slack, best\u2011fit, first\u2011fit, fill\u2011balance and simple reward learning.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using slack, fit, index and reward heuristics for online bin packing.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = caps >= item\n    if not np.any(feasible):\n        return np.full(n, -np.inf, dtype=float)\n    leftovers_all = caps - item\n    leftovers = leftovers_all[feasible]\n    inv_slack = 1.0 / (leftovers + 1.0)\n    best_fit = -leftovers\n    first_fit = -np.arange(n)[feasible]\n    target = caps.mean()\n    fill_bal = -np.abs(leftovers - target)\n    avg_reward = np.zeros_like(leftovers)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    w_inv, w_best, w_first, w_bal, w_rew = 0.4, 0.3, 0.1, 0.1, 0.1\n    combined = (w_inv * inv_slack + w_best * best_fit + w_first * first_fit +\n                w_bal * fill_bal + w_rew * avg_reward)\n    scores = np.full(n, -np.inf, dtype=float)\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    reward = -(caps[best] - item)\n    _selection_counts[best] += 1\n    _total_rewards[best] += reward\n    _total_calls += 1\n    return scores\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    slack = bins_remain_cap - item\n    fits = slack >= 0\n    eps = np.finfo(slack.dtype).eps\n    return np.where(fits, -slack + eps, -np.inf)\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.15\n    w_inv = 0.5\n    w_lin = 0.3\n    w_sq = 0.2\n    temperature = 1.0\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    core = w_inv / (slack + 1.0) - w_lin * slack - w_sq * slack**2\n    rand = np.random.rand(feasible.sum())\n    scores_feasible = (1 - epsilon) * core + epsilon * rand\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores[feasible] = scores_feasible\n    max_score = np.max(scores_feasible)\n    exp_scores = np.exp((scores_feasible - max_score) / temperature)\n    probs_feasible = exp_scores / exp_scores.sum()\n    probs = np.zeros_like(bins_remain_cap, dtype=float)\n    probs[feasible] = probs_feasible\n    return probs\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                epsilon: float = 0.2, beta: float = 0.02) -> np.ndarray:\n    \"\"\"Epsilon\u2011greedy tight\u2011fit with squared\u2011slack penalty for waste reduction.\"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    det = 1.0/(leftovers + 1.0) - beta * leftovers**2\n    rand_part = np.random.rand(bins_remain_cap.size)\n    scores[feasible] = (1 - epsilon) * det + epsilon * rand_part[feasible]\n    return scores\n\n[Heuristics 14th]\nimport numpy as np\n\n# Combine inverse\u2011slack and linear\u2011slack with \u03b5\u2011greedy randomness.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    \u03b5\u2011greedy scoring: weighted sum of inverse slack and negative slack, with random tie\u2011breaker.\n    \"\"\"\n    epsilon = 0.15          # exploration factor\n    w_inv = 0.6             # weight for reciprocal slack\n    w_lin = 0.4             # weight for linear slack penalty\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    base = w_inv * (1.0 / (slack + 1.0)) + w_lin * (-slack)\n    scores[feasible] = base\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    # softmax scaling for probability\u2011like priorities\n    finite_mask = np.isfinite(scores)\n    if not np.any(finite_mask):\n        return scores\n    max_score = np.max(scores[finite_mask])\n    exp_scores = np.exp(scores - max_score)\n    exp_scores[~finite_mask] = 0.0\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                beta: float = 0.01, temperature: float = 1.0,\n                total_threshold: float = 1e-6) -> np.ndarray:\n    \"\"\"Score bins by inverse slack minus slack\u00b2, softened with temperature.\"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if not feasible.any():\n        return priorities\n    slack = bins_remain_cap[feasible] - item\n    eps = 1e-9\n    raw = 1.0 / (slack + eps) - beta * slack**2\n    exp_scores = np.exp(raw / temperature)\n    if exp_scores.sum() < total_threshold:\n        return priorities\n    priorities[feasible] = exp_scores\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.15\n    w_inv = 0.5\n    w_lin = 0.3\n    w_sq = 0.2\n    temperature = 1.0\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    core = w_inv / (slack + 1.0) - w_lin * slack - w_sq * slack**2\n    rand = np.random.rand(feasible.sum())\n    scores_feasible = (1 - epsilon) * core + epsilon * rand\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores[feasible] = scores_feasible\n    max_score = np.max(scores_feasible)\n    exp_scores = np.exp((scores_feasible - max_score) / temperature)\n    probs_feasible = exp_scores / exp_scores.sum()\n    probs = np.zeros_like(bins_remain_cap, dtype=float)\n    probs[feasible] = probs_feasible\n    return probs\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if not hasattr(priority_v2, \"initialized\"):\n        priority_v2.num_rules = 4\n        priority_v2.sum_waste = np.zeros(priority_v2.num_rules, dtype=float)\n        priority_v2.count = np.zeros(priority_v2.num_rules, dtype=int)\n        priority_v2.step = 0\n        priority_v2.epsilon = 1e-9\n        priority_v2.initialized = True\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap - item\n    best_fit_score = np.where(feasible, -leftovers, -np.inf)\n    worst_fit_score = np.where(feasible, leftovers, -np.inf)\n    indices = np.arange(bins_remain_cap.shape[0] if hasattr(bins_remain_cap, \"shape\") else len(bins_remain_cap))\n    first_fit_score = np.where(feasible, -indices, -np.inf)\n    target = bins_remain_cap.mean()\n    fill_bal_score = np.where(feasible, -np.abs(leftovers - target), -np.inf)\n    rule_scores = [best_fit_score, worst_fit_score, first_fit_score, fill_bal_score]\n    waste_per_rule = np.empty(priority_v2.num_rules, dtype=float)\n    for i, scores in enumerate(rule_scores):\n        if not np.isfinite(scores).any():\n            waste_per_rule[i] = np.inf\n        else:\n            idx = np.argmax(scores)\n            waste_per_rule[i] = bins_remain_cap[idx] - item\n    for i in range(priority_v2.num_rules):\n        w = waste_per_rule[i]\n        if np.isfinite(w):\n            priority_v2.sum_waste[i] += w\n            priority_v2.count[i] += 1\n    avg_waste = np.where(priority_v2.count > 0, priority_v2.sum_waste / priority_v2.count, np.inf)\n    inv = 1.0 / (avg_waste + priority_v2.epsilon)\n    boost = np.zeros(priority_v2.num_rules, dtype=float)\n    boost_idx = priority_v2.step % priority_v2.num_rules\n    boost[boost_idx] = 1.0 / (priority_v2.step + 1)\n    raw_weights = inv + boost\n    total = raw_weights.sum()\n    if total > 0:\n        weights = raw_weights / total\n    else:\n        weights = np.full(priority_v2.num_rules, 1.0 / priority_v2.num_rules)\n    combined_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    for w, scores in zip(weights, rule_scores):\n        combined_scores += w * scores\n    combined_scores[~feasible] = -np.inf\n    priority_v2.step += 1\n    return combined_scores\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item, bins_remain_cap):\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                temperature: float = 8.21777003404979,\n                total_threshold: float = 0.7518899527010219) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        temperature: Temperature controlling the softness of the exponential weighting.\n        total_threshold: Minimum sum of exponential values required to assign non\u2011zero priorities.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    if not np.any(feasible):\n        return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\n# Global state for the heuristic\n_pv2_selection_counts = None\n_pv2_total_rewards = None\n_pv2_total_calls = None\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines epsilon\u2011greedy inverse slack scoring with UCB exploration and median\u2011based diversity to balance fit and exploration in online BPP.\"\"\"\n    global _pv2_selection_counts, _pv2_total_rewards, _pv2_total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    if _pv2_selection_counts is None or _pv2_selection_counts.shape[0] != n:\n        _pv2_selection_counts = np.zeros(n, dtype=float)\n        _pv2_total_rewards = np.zeros(n, dtype=float)\n        _pv2_total_calls = 0\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full(n, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    det_score = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    rand_part = np.random.rand(leftovers.size)\n    base_score = (1 - epsilon) * det_score + epsilon * rand_part\n    selection_counts_feasible = _pv2_selection_counts[feasible]\n    avg_reward_feasible = np.where(selection_counts_feasible > 0,\n                                   _pv2_total_rewards[feasible] / selection_counts_feasible,\n                                   0.0)\n    c = 0.5\n    exploration_bonus_feasible = c * np.sqrt(np.log(_pv2_total_calls + 1) / (selection_counts_feasible + 1))\n    ucb_score = avg_reward_feasible + exploration_bonus_feasible\n    median_leftover = np.median(leftovers) if leftovers.size > 0 else 0.0\n    diversity_score = 1.0 / (np.abs(leftovers - median_leftover) + 1.0)\n    ucb_weight = 0.3\n    diversity_weight = 0.2\n    combined_score_feasible = base_score + ucb_weight * ucb_score + diversity_weight * diversity_score\n    scores = np.full(n, -np.inf, dtype=float)\n    scores[feasible] = combined_score_feasible\n    best = np.argmax(scores)\n    chosen_leftover = bins_remain_cap[best] - item\n    reward = -chosen_leftover\n    _pv2_selection_counts[best] += 1\n    _pv2_total_rewards[best] += reward\n    _pv2_total_calls += 1\n    return scores\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}