```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines inverse slack priority with lightweight learned rule weighting.
    """
    if not hasattr(priority_v2, "_initialized"):
        priority_v2.num_rules = 3
        priority_v2.sum_waste = np.zeros(priority_v2.num_rules, dtype=float)
        priority_v2.count = np.zeros(priority_v2.num_rules, dtype=int)
        priority_v2.step = 0
        priority_v2.epsilon = 1e-9
        priority_v2._initialized = True

    slack = bins_remain_cap - item
    fits = slack >= 0
    if not fits.any():
        return np.full_like(bins_remain_cap, -np.inf, dtype=float)

    base_priority = np.where(fits, -slack + np.finfo(slack.dtype).eps, -np.inf)

    worst_fit_score = np.where(fits, slack, -np.inf)
    first_fit_score = np.where(fits, -np.arange(bins_remain_cap.shape[0]), -np.inf)
    target = bins_remain_cap.mean()
    fill_bal_score = np.where(fits, -np.abs(slack - target), -np.inf)

    rule_scores = np.stack([worst_fit_score, first_fit_score, fill_bal_score], axis=0)

    for i, scores in enumerate(rule_scores):
        idx = np.argmax(scores)
        if np.isfinite(scores[idx]):
            priority_v2.sum_waste[i] += slack[idx]
            priority_v2.count[i] += 1

    avg_waste = np.where(priority_v2.count > 0, priority_v2.sum_waste / priority_v2.count, np.inf)
    inv = 1.0 / (avg_waste + priority_v2.epsilon)
    weights = inv / inv.sum()

    combined_bonus = np.sum(weights[:, None] * rule_scores, axis=0)
    combined_bonus[~fits] = -np.inf

    priority_v2.step += 1

    return base_priority + 0.1 * combined_bonus
```
