{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = 1.0 / (leftovers + 1.0)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 2nd]\nimport numpy as np\n\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Inverse slack + epsilon random + avg reward for online bin packing.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = bins_remain_cap >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - epsilon) * deterministic + epsilon * random_part\n    avg_reward = np.zeros_like(base_score)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    reward_weight = 0.3\n    combined = base_score + reward_weight * avg_reward\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    _total_calls += 1\n    reward = - (bins_remain_cap[best] - item)\n    _selection_counts[best] += 1\n    _total_rewards[best] += reward\n    return scores\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * deterministic + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 4th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.3272578070972282,\n                offset: float = 3.6930496425184325,\n                score_scale: float = 1.8547777441606528) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins given an item size.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of bins.\n    epsilon : float, optional\n        Weight for the random exploration term (default 0.2).\n    offset : float, optional\n        Small constant added to leftover capacity to avoid division by zero\n        (default 1.0).\n    score_scale : float, optional\n        Scaling factor for the deterministic part of the score\n        (default 1.0).\n\n    Returns\n    -------\n    np.ndarray\n        Score for each bin; -inf for infeasible bins.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = score_scale / (leftovers + offset)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item, bins_remain_cap):\n    if not hasattr(priority_v2, \"_init\"):\n        priority_v2._selection_counts = None\n        priority_v2._total_rewards = None\n        priority_v2._total_calls = 0\n        priority_v2._epsilon = 0.15\n        priority_v2._reward_weight = 0.3\n        priority_v2._ucb_weight = 0.05\n        priority_v2._init = True\n    bins_remain_cap = np.asarray(bins_v2, dtype=float) if False else np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if priority_v2._selection_counts is None or priority_v2._selection_counts.shape[0] != n:\n        priority_v2._selection_counts = np.zeros(n, dtype=float)\n        priority_v2._total_rewards = np.zeros(n, dtype=float)\n    feasible = bins_remain_cap >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        priority_v2._total_calls += 1\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - priority_v2._epsilon) * deterministic + priority_v2._epsilon * random_part\n    avg_reward = np.zeros_like(base_score)\n    mask = priority_v2._selection_counts[feasible] > 0\n    avg_reward[mask] = priority_v2._total_rewards[feasible][mask] / priority_v2._selection_counts[feasible][mask]\n    total = priority_v2._total_calls + 1\n    ucb = np.sqrt(2.0 * np.log(total) / (priority_v2._selection_counts + 1e-6))\n    ucb_feas = ucb[feasible]\n    combined = base_score + priority_v2._reward_weight * avg_reward + priority_v2._ucb_weight * ucb_feas\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    priority_v2._total_calls += 1\n    reward = - (bins_remain_cap[best] - item)\n    priority_v2._selection_counts[best] += 1\n    priority_v2._total_rewards[best] += reward\n    return scores\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item, bins_remain_cap):\n    if not hasattr(priority_v2, \"_init\"):\n        priority_v2._selection_counts = None\n        priority_v2._total_rewards = None\n        priority_v2._total_calls = 0\n        priority_v2._epsilon = 0.15\n        priority_v2._reward_weight = 0.3\n        priority_v2._ucb_weight = 0.05\n        priority_v2._init = True\n    bins_remain_cap = np.asarray(bins_v2, dtype=float) if False else np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if priority_v2._selection_counts is None or priority_v2._selection_counts.shape[0] != n:\n        priority_v2._selection_counts = np.zeros(n, dtype=float)\n        priority_v2._total_rewards = np.zeros(n, dtype=float)\n    feasible = bins_remain_cap >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        priority_v2._total_calls += 1\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - priority_v2._epsilon) * deterministic + priority_v2._epsilon * random_part\n    avg_reward = np.zeros_like(base_score)\n    mask = priority_v2._selection_counts[feasible] > 0\n    avg_reward[mask] = priority_v2._total_rewards[feasible][mask] / priority_v2._selection_counts[feasible][mask]\n    total = priority_v2._total_calls + 1\n    ucb = np.sqrt(2.0 * np.log(total) / (priority_v2._selection_counts + 1e-6))\n    ucb_feas = ucb[feasible]\n    combined = base_score + priority_v2._reward_weight * avg_reward + priority_v2._ucb_weight * ucb_feas\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    priority_v2._total_calls += 1\n    reward = - (bins_remain_cap[best] - item)\n    priority_v2._selection_counts[best] += 1\n    priority_v2._total_rewards[best] += reward\n    return scores\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines inverse\u2011slack, \u03b5\u2011greedy exploration, and reward weighting for online bin packing.\"\"\"\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    max_cap = bins_remain_cap.max()\n    reward = 1.0 - leftovers / max_cap\n    reward = np.clip(reward, 0.0, 1.0)\n    weighted = deterministic * (1.0 + reward)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * weighted + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines inverse\u2011slack, \u03b5\u2011greedy exploration, and reward weighting for online bin packing.\"\"\"\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    max_cap = bins_remain_cap.max()\n    reward = 1.0 - leftovers / max_cap\n    reward = np.clip(reward, 0.0, 1.0)\n    weighted = deterministic * (1.0 + reward)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * weighted + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Inverse\u2011slack scoring with epsilon exploration and per\u2011bin learning.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.size\n    if n == 0:\n        return np.array([], dtype=float)\n    if '_selection_counts' not in globals() or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=int)\n        _total_rewards = np.zeros(n, dtype=float)\n        _total_calls = 0\n    feasible = caps >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    slack = caps - item\n    det = 1.0 / (slack + 1.0)\n    avg_reward = np.zeros(n, dtype=float)\n    mask = _selection_counts > 0\n    avg_reward[mask] = _total_rewards[mask] / _selection_counts[mask]\n    reward_weight = 0.1\n    if _total_calls > 0:\n        ucb = np.zeros(n, dtype=float)\n        ucb[mask] = np.sqrt(2 * np.log(_total_calls) / _selection_counts[mask])\n        ucb_weight = 0.3\n    else:\n        ucb = np.zeros(n, dtype=float)\n        ucb_weight = 0.0\n    median_slack = np.median(slack[feasible]) if np.any(feasible) else 0.0\n    diversity = np.zeros(n, dtype=float)\n    diversity[feasible] = median_slack - slack[feasible]\n    diversity_weight = 0.1\n    combined = det + reward_weight * avg_reward + ucb_weight * ucb + diversity_weight * diversity\n    epsilon = 0.15\n    rand = np.random.rand(n)\n    scores[feasible] = (1 - epsilon) * combined[feasible] + epsilon * rand[feasible]\n    best = int(np.argmax(scores))\n    if feasible[best]:\n        reward = -(caps[best] - item)\n        _selection_counts[best] += 1\n        _total_rewards[best] += reward\n    _total_calls += 1\n    return scores\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Inverse\u2011slack scoring with epsilon exploration and per\u2011bin learning.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.size\n    if n == 0:\n        return np.array([], dtype=float)\n    if '_selection_counts' not in globals() or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=int)\n        _total_rewards = np.zeros(n, dtype=float)\n        _total_calls = 0\n    feasible = caps >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    slack = caps - item\n    det = 1.0 / (slack + 1.0)\n    avg_reward = np.zeros(n, dtype=float)\n    mask = _selection_counts > 0\n    avg_reward[mask] = _total_rewards[mask] / _selection_counts[mask]\n    reward_weight = 0.1\n    if _total_calls > 0:\n        ucb = np.zeros(n, dtype=float)\n        ucb[mask] = np.sqrt(2 * np.log(_total_calls) / _selection_counts[mask])\n        ucb_weight = 0.3\n    else:\n        ucb = np.zeros(n, dtype=float)\n        ucb_weight = 0.0\n    median_slack = np.median(slack[feasible]) if np.any(feasible) else 0.0\n    diversity = np.zeros(n, dtype=float)\n    diversity[feasible] = median_slack - slack[feasible]\n    diversity_weight = 0.1\n    combined = det + reward_weight * avg_reward + ucb_weight * ucb + diversity_weight * diversity\n    epsilon = 0.15\n    rand = np.random.rand(n)\n    scores[feasible] = (1 - epsilon) * combined[feasible] + epsilon * rand[feasible]\n    best = int(np.argmax(scores))\n    if feasible[best]:\n        reward = -(caps[best] - item)\n        _selection_counts[best] += 1\n        _total_rewards[best] += reward\n    _total_calls += 1\n    return scores\n\n[Heuristics 11th]\nimport numpy as np\n\n_initialized = False\n_model_mu = None\n_model_cov = None\n_model_precision = None\n_bin_capacity = 1.0\n_noise_var = 0.5\n_prior_var = 10.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    global _initialized, _model_mu, _model_cov, _model_precision, _bin_capacity, _noise_var, _prior_var\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if not _initialized:\n        _bin_capacity = np.max(caps) if caps.size > 0 else 1.0\n        d = 3\n        _model_mu = np.zeros(d)\n        _model_cov = np.eye(d) * _prior_var\n        _model_precision = np.linalg.inv(_model_cov)\n        _initialized = True\n    else:\n        max_cap = np.max(caps)\n        if max_cap > _bin_capacity:\n            _bin_capacity = max_cap\n    feasible = caps >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    slack = caps[feasible] - item\n    fill = 1.0 - slack / _bin_capacity\n    X = np.column_stack((np.ones_like(slack), slack, fill))\n    w = np.random.multivariate_normal(_model_mu, _model_cov)\n    scores[feasible] = X @ w\n    best = int(np.argmax(scores))\n    if feasible[best]:\n        slack_selected = caps[best] - item\n        reward = -slack_selected\n        x = np.array([1.0, slack_selected, 1.0 - slack_selected / _bin_capacity])\n        precision_update = _model_precision + np.outer(x, x) / _noise_var\n        cov_new = np.linalg.inv(precision_update)\n        mu_new = cov_new @ (_model_precision @ _model_mu + x * reward / _noise_var)\n        _model_cov = cov_new\n        _model_precision = precision_update\n        _model_mu = mu_new\n    return scores\n\n[Heuristics 12th]\nimport numpy as np\n\ndef _extract_features(item: float, bins_remain_cap: np.ndarray, capacity: float):\n    slack = bins_remain_cap - item\n    slack_norm = slack / capacity\n    used_ratio = (capacity - bins_remain_cap) / capacity\n    return slack_norm, used_ratio\n\ndef _combine_features(slack_norm: np.ndarray, used_ratio: np.ndarray):\n    return used_ratio - slack_norm\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    capacity = np.max(bins_remain_cap) if bins_remain_cap.size else 0.0\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    if capacity > 0 and np.any(feasible):\n        slack_norm, used_ratio = _extract_features(item, bins_remain_cap, capacity)\n        combined = _combine_features(slack_norm, used_ratio)\n        scores[feasible] = combined[feasible]\n    return scores\n\n[Heuristics 13th]\nimport numpy as np\n\n_epsilon = 0.2\n_beta = 0.01\n_gamma = 0.5\n_delta = 0.1\n_bin_capacity = None\n_avg_slack = None\n_slack_counts = None\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using inverse slack, fill bias, avg slack, and \u03b5\u2011exploration.\"\"\"\n    global _bin_capacity, _avg_slack, _slack_counts\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _bin_capacity is None:\n        _bin_capacity = caps.max() if caps.size > 0 else 1.0\n    elif caps.max() > _bin_capacity:\n        _bin_capacity = caps.max()\n    if _avg_slack is None or _avg_slack.shape[0] != n:\n        _avg_slack = np.zeros(n, dtype=float)\n        _slack_counts = np.zeros(n, dtype=int)\n    feasible = caps >= item\n    if not feasible.any():\n        return np.full_like(caps, -np.inf)\n    slack = caps[feasible] - item\n    inv_slack = 1.0 / (slack + 1e-9)\n    fill = 1.0 - slack / _bin_capacity\n    avg_slack = _avg_slack[feasible]\n    deterministic = inv_slack - _beta * slack**2 + _gamma * fill - _delta * avg_slack\n    random_part = np.random.rand(slack.size)\n    scores = (1 - _epsilon) * deterministic + _epsilon * random_part\n    priorities = np.full_like(caps, -np.inf)\n    priorities[feasible] = scores\n    idx = np.where(feasible)[0]\n    _avg_slack[idx] = (_avg_slack[idx] * _slack_counts[idx] + slack) / (_slack_counts[idx] + 1)\n    _slack_counts[idx] += 1\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.15\n    w_inv = 0.5\n    w_lin = 0.3\n    w_sq = 0.2\n    temperature = 1.0\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    core = w_inv / (slack + 1.0) - w_lin * slack - w_sq * slack**2\n    rand = np.random.rand(feasible.sum())\n    scores_feasible = (1 - epsilon) * core + epsilon * rand\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores[feasible] = scores_feasible\n    max_score = np.max(scores_feasible)\n    exp_scores = np.exp((scores_feasible - max_score) / temperature)\n    probs_feasible = exp_scores / exp_scores.sum()\n    probs = np.zeros_like(bins_remain_cap, dtype=float)\n    probs[feasible] = probs_feasible\n    return probs\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    slack = bins_remain_cap - item\n    fits = slack >= 0\n    eps = np.finfo(slack.dtype).eps\n    return np.where(fits, -slack + eps, -np.inf)\n\n[Heuristics 16th]\nimport numpy as np\n\n# Hyperparameters\n_EPSILON = 0.2\n_BETA = 0.01\n_GAMMA = 0.5\n_DELTA = 0.1\n_UCB_WEIGHT = 0.05\n\n# State\n_bin_capacity = None\n_avg_slack = None\n_slack_counts = None\n_total_calls = 0\n\n# Hybrid inverse\u2011slack + UCB with \u03b5\u2011greedy exploration.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic using inverse slack, UCB bonus, and \u03b5\u2011greedy noise to rank bins.\"\"\"\n    global _bin_capacity, _avg_slack, _slack_counts, _total_calls\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.size\n    if n == 0:\n        return np.array([], dtype=float)\n    if _bin_capacity is None:\n        _bin_capacity = caps.max() if caps.size > 0 else 1.0\n    else:\n        if caps.max() > _bin_capacity:\n            _bin_capacity = caps.max()\n    if _avg_slack is None or _avg_slack.shape[0] != n:\n        _avg_slack = np.zeros(n, dtype=float)\n        _slack_counts = np.zeros(n, dtype=int)\n    _total_calls += 1\n\n    feasible = caps >= item\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf)\n    slack = caps[feasible] - item\n    inv_slack = 1.0 / (slack + 1e-9)\n    fill = 1.0 - slack / _bin_capacity\n    avg_slack = _avg_slack[feasible]\n    counts = _slack_counts[feasible]\n    ucb_bonus = np.sqrt(2 * np.log(_total_calls) / (counts + 1e-9))\n    deterministic = inv_slack - _BETA * slack**2 + _GAMMA * fill - _DELTA * avg_slack + _UCB_WEIGHT * ucb_bonus\n    random_part = np.random.rand(slack.size)\n    scores = (1 - _EPSILON) * deterministic + _EPSILON * random_part\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n    priorities[feasible] = scores\n    idx = np.where(feasible)[0]\n    _avg_slack[idx] = (_avg_slack[idx] * _slack_counts[idx] + slack) / (_slack_counts[idx] + 1)\n    _slack_counts[idx] += 1\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\n# Global per\u2011bin statistics for lightweight online learning.\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid scoring: inverse slack, penalty, \u03b5\u2011noise, avg reward, UCB, softmax.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n        _total_calls = 0\n    feasible = caps >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    slack = caps[feasible] - item\n    inv_slack = 1.0 / (slack + 1.0)\n    beta = 0.1\n    penalty = -beta * (slack ** 2)\n    deterministic = inv_slack + penalty\n    avg_reward = np.zeros_like(deterministic)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    reward_weight = 0.2\n    total_calls = _total_calls + 1e-6\n    ucb = np.sqrt(2 * np.log(total_calls) / (_selection_counts[feasible] + 1e-6))\n    ucb_weight = 0.05\n    combined = deterministic + reward_weight * avg_reward + ucb_weight * ucb\n    epsilon = 0.05\n    noise = epsilon * np.random.rand(combined.shape[0])\n    raw = combined + noise\n    temperature = 0.5\n    exp_vals = np.exp(raw / temperature)\n    total_exp = exp_vals.sum()\n    if total_exp > 0:\n        scores[feasible] = exp_vals / total_exp\n    best_idx = int(np.argmax(scores))\n    if feasible[best_idx]:\n        chosen_slack = caps[best_idx] - item\n        reward = -chosen_slack\n        _selection_counts[best_idx] += 1\n        _total_rewards[best_idx] += reward\n        _total_calls += 1\n    return scores\n\n[Heuristics 18th]\nimport numpy as np\n\n# Global per\u2011bin statistics for lightweight online learning.\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid scoring: inverse slack, penalty, \u03b5\u2011noise, avg reward, UCB, softmax.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n        _total_calls = 0\n    feasible = caps >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    slack = caps[feasible] - item\n    inv_slack = 1.0 / (slack + 1.0)\n    beta = 0.1\n    penalty = -beta * (slack ** 2)\n    deterministic = inv_slack + penalty\n    avg_reward = np.zeros_like(deterministic)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    reward_weight = 0.2\n    total_calls = _total_calls + 1e-6\n    ucb = np.sqrt(2 * np.log(total_calls) / (_selection_counts[feasible] + 1e-6))\n    ucb_weight = 0.05\n    combined = deterministic + reward_weight * avg_reward + ucb_weight * ucb\n    epsilon = 0.05\n    noise = epsilon * np.random.rand(combined.shape[0])\n    raw = combined + noise\n    temperature = 0.5\n    exp_vals = np.exp(raw / temperature)\n    total_exp = exp_vals.sum()\n    if total_exp > 0:\n        scores[feasible] = exp_vals / total_exp\n    best_idx = int(np.argmax(scores))\n    if feasible[best_idx]:\n        chosen_slack = caps[best_idx] - item\n        reward = -chosen_slack\n        _selection_counts[best_idx] += 1\n        _total_rewards[best_idx] += reward\n        _total_calls += 1\n    return scores\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item, bins_remain_cap):\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n\n[Heuristics 20th]\nimport numpy as np\n\n_pv2_counts = None\n_pv2_rewards = None\n_pv2_total_calls = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    global _pv2_counts, _pv2_rewards, _pv2_total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    if _pv2_counts is None or _pv2_counts.shape[0] != n:\n        _pv2_counts = np.zeros(n, dtype=float)\n        _pv2_rewards = np.zeros(n, dtype=float)\n    feasible = bins_remain_cap >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    epsilon = 0.2\n    inv_slack = 1.0 / (leftovers + 1.0)\n    rand_part = np.random.rand(leftovers.shape[0])\n    base_score = (1 - epsilon) * inv_slack + epsilon * rand_part\n    median_leftover = np.median(leftovers) if leftovers.size > 0 else 0.0\n    diversity = 1.0 / (np.abs(leftovers - median_leftover) + 1.0)\n    diversity_weight = 0.1\n    counts_feasible = _pv2_counts[feasible]\n    rewards_feasible = _pv2_rewards[feasible]\n    avg_reward = np.where(counts_feasible > 0, rewards_feasible / counts_feasible, 0.0)\n    c = 0.5\n    exploration_bonus = c * np.sqrt(np.log(_pv2_total_calls + 1) / (counts_feasible + 1))\n    ucb_score = avg_reward + exploration_bonus\n    ucb_weight = 0.3\n    final_score = base_score + ucb_weight * ucb_score + diversity_weight * diversity\n    scores[feasible] = final_score\n    best_idx = int(0) if n == 0 else int(np.argmax(scores))\n    if scores[best_idx] != -np.inf:\n        chosen_leftover = bins_remain_cap[best_idx] - item\n        reward = -chosen_leftover\n        _pv2_counts[best_idx] += 1\n        _pv2_rewards[best_idx] += reward\n        _pv2_total_calls += 1\n    return scores\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}