```python
import numpy as np

_selection_counts = None
_total_rewards = None

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Score bins by weighted slack features and learned reward, returning scores."""
    global _selection_counts, _total_rewards
    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)
    n = bins_remain_cap.shape[0]
    if n == 0:
        return np.array([], dtype=float)
    if _selection_counts is None or _selection_counts.shape[0] != n:
        _selection_counts = np.zeros(n, dtype=float)
        _total_rewards = np.zeros(n, dtype=float)
    feasible = bins_remain_cap >= item
    scores = np.full(n, -np.inf, dtype=float)
    if not feasible.any():
        return scores
    slack = bins_remain_cap[feasible] - item
    w_inv, w_lin, w_sq = 0.6, 0.3, 0.1
    base = w_inv / (slack + 1.0) - w_lin * slack - w_sq * slack**2
    epsilon = 0.05
    base += epsilon * np.random.rand(slack.size)
    avg_reward = np.zeros_like(base)
    mask = _selection_counts[feasible] > 0
    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]
    reward_weight = 0.2
    final = base + reward_weight * avg_reward
    scores[feasible] = final
    best = np.argmax(scores)
    leftover = bins_remain_cap[best] - item
    reward = -leftover
    _selection_counts[best] += 1
    _total_rewards[best] += reward
    return scores
```
