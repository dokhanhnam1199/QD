{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\n_selection_counts = None\n_total_rewards = None\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    global _selection_counts, _total_rewards\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = caps >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = caps[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - epsilon) * deterministic + epsilon * random_part\n    avg_reward = np.zeros_like(base_score)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    reward_weight = 0.1\n    combined = base_score + reward_weight * avg_reward\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    if feasible[best]:\n        reward = - (caps[best] - item)\n        _selection_counts[best] += 1\n        _total_rewards[best] += reward\n    return scores\n\n[Heuristics 2nd]\nimport numpy as np\n\n_selection_counts = None\n_total_rewards = None\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    global _selection_counts, _total_rewards\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = caps >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = caps[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - epsilon) * deterministic + epsilon * random_part\n    avg_reward = np.zeros_like(base_score)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    reward_weight = 0.1\n    combined = base_score + reward_weight * avg_reward\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    if feasible[best]:\n        reward = - (caps[best] - item)\n        _selection_counts[best] += 1\n        _total_rewards[best] += reward\n    return scores\n\n[Heuristics 3rd]\nimport numpy as np\n\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Inverse slack + epsilon random + avg reward for online bin packing.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = bins_remain_cap >= item\n    scores = np.full(n, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - epsilon) * deterministic + epsilon * random_part\n    avg_reward = np.zeros_like(base_score)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    reward_weight = 0.3\n    combined = base_score + reward_weight * avg_reward\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    _total_calls += 1\n    reward = - (bins_remain_cap[best] - item)\n    _selection_counts[best] += 1\n    _total_rewards[best] += reward\n    return scores\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * deterministic + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * deterministic + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.3272578070972282,\n                offset: float = 3.6930496425184325,\n                score_scale: float = 1.8547777441606528) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins given an item size.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of bins.\n    epsilon : float, optional\n        Weight for the random exploration term (default 0.2).\n    offset : float, optional\n        Small constant added to leftover capacity to avoid division by zero\n        (default 1.0).\n    score_scale : float, optional\n        Scaling factor for the deterministic part of the score\n        (default 1.0).\n\n    Returns\n    -------\n    np.ndarray\n        Score for each bin; -inf for infeasible bins.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = score_scale / (leftovers + offset)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine inverse slack and negative squared slack with epsilon\u2011greedy randomness for balanced tight\u2011fit and exploration.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftover = bins_remain_cap[feasible] - item\n    epsilon = 0.2\n    beta = 0.01\n    deterministic = 1.0 / (leftover + 1e-9) - beta * (leftover ** 2)\n    random_part = np.random.rand(feasible.sum())\n    scores = (1 - epsilon) * deterministic + epsilon * random_part\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    priorities[feasible] = scores\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine inverse slack and negative squared slack with epsilon\u2011greedy randomness for balanced tight\u2011fit and exploration.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftover = bins_remain_cap[feasible] - item\n    epsilon = 0.2\n    beta = 0.01\n    deterministic = 1.0 / (leftover + 1e-9) - beta * (leftover ** 2)\n    random_part = np.random.rand(feasible.sum())\n    scores = (1 - epsilon) * deterministic + epsilon * random_part\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    priorities[feasible] = scores\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\n# Priority combines inverse slack, best\u2011fit, first\u2011fit, fill\u2011balance and simple reward learning.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins using slack, fit, index and reward heuristics for online bin packing.\"\"\"\n    global _selection_counts, _total_rewards, _total_calls\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n = caps.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = caps >= item\n    if not np.any(feasible):\n        return np.full(n, -np.inf, dtype=float)\n    leftovers_all = caps - item\n    leftovers = leftovers_all[feasible]\n    inv_slack = 1.0 / (leftovers + 1.0)\n    best_fit = -leftovers\n    first_fit = -np.arange(n)[feasible]\n    target = caps.mean()\n    fill_bal = -np.abs(leftovers - target)\n    avg_reward = np.zeros_like(leftovers)\n    mask = _selection_counts[feasible] > 0\n    avg_reward[mask] = _total_rewards[feasible][mask] / _selection_counts[feasible][mask]\n    w_inv, w_best, w_first, w_bal, w_rew = 0.4, 0.3, 0.1, 0.1, 0.1\n    combined = (w_inv * inv_slack + w_best * best_fit + w_first * first_fit +\n                w_bal * fill_bal + w_rew * avg_reward)\n    scores = np.full(n, -np.inf, dtype=float)\n    scores[feasible] = combined\n    best = int(np.argmax(scores))\n    reward = -(caps[best] - item)\n    _selection_counts[best] += 1\n    _total_rewards[best] += reward\n    _total_calls += 1\n    return scores\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    slack = bins_remain_cap - item\n    fits = slack >= 0\n    eps = np.finfo(slack.dtype).eps\n    return np.where(fits, -slack + eps, -np.inf)\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    slack = bins_remain_cap - item\n    fits = slack >= 0\n    eps = np.finfo(slack.dtype).eps\n    return np.where(fits, -slack + eps, -np.inf)\n\n[Heuristics 12th]\nimport numpy as np\n\n# Combine inverse\u2011slack and linear\u2011slack with \u03b5\u2011greedy randomness.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    \u03b5\u2011greedy scoring: weighted sum of inverse slack and negative slack, with random tie\u2011breaker.\n    \"\"\"\n    epsilon = 0.15          # exploration factor\n    w_inv = 0.6             # weight for reciprocal slack\n    w_lin = 0.4             # weight for linear slack penalty\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    base = w_inv * (1.0 / (slack + 1.0)) + w_lin * (-slack)\n    scores[feasible] = base\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    # softmax scaling for probability\u2011like priorities\n    finite_mask = np.isfinite(scores)\n    if not np.any(finite_mask):\n        return scores\n    max_score = np.max(scores[finite_mask])\n    exp_scores = np.exp(scores - max_score)\n    exp_scores[~finite_mask] = 0.0\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 13th]\nimport numpy as np\n\n# Combine inverse\u2011slack and linear\u2011slack with \u03b5\u2011greedy randomness.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    \u03b5\u2011greedy scoring: weighted sum of inverse slack and negative slack, with random tie\u2011breaker.\n    \"\"\"\n    epsilon = 0.15          # exploration factor\n    w_inv = 0.6             # weight for reciprocal slack\n    w_lin = 0.4             # weight for linear slack penalty\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    base = w_inv * (1.0 / (slack + 1.0)) + w_lin * (-slack)\n    scores[feasible] = base\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    # softmax scaling for probability\u2011like priorities\n    finite_mask = np.isfinite(scores)\n    if not np.any(finite_mask):\n        return scores\n    max_score = np.max(scores[finite_mask])\n    exp_scores = np.exp(scores - max_score)\n    exp_scores[~finite_mask] = 0.0\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef _extract_features(item: float, bins_remain_cap: np.ndarray, capacity: float):\n    slack = bins_remain_cap - item\n    slack_norm = slack / capacity\n    used_ratio = (capacity - bins_remain_cap) / capacity\n    return slack_norm, used_ratio\n\ndef _combine_features(slack_norm: np.ndarray, used_ratio: np.ndarray):\n    return used_ratio - slack_norm\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    capacity = np.max(bins_remain_cap) if bins_remain_cap.size else 0.0\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    if capacity > 0 and np.any(feasible):\n        slack_norm, used_ratio = _extract_features(item, bins_remain_cap, capacity)\n        combined = _combine_features(slack_norm, used_ratio)\n        scores[feasible] = combined[feasible]\n    return scores\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if not hasattr(priority_v2, \"initialized\"):\n        priority_v2.num_rules = 4\n        priority_v2.sum_waste = np.zeros(priority_v2.num_rules, dtype=float)\n        priority_v2.count = np.zeros(priority_v2.num_rules, dtype=int)\n        priority_v2.step = 0\n        priority_v2.epsilon = 1e-9\n        priority_v2.initialized = True\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap - item\n    best_fit_score = np.where(feasible, -leftovers, -np.inf)\n    worst_fit_score = np.where(feasible, leftovers, -np.inf)\n    indices = np.arange(bins_remain_cap.shape[0] if hasattr(bins_remain_cap, \"shape\") else len(bins_remain_cap))\n    first_fit_score = np.where(feasible, -indices, -np.inf)\n    target = bins_remain_cap.mean()\n    fill_bal_score = np.where(feasible, -np.abs(leftovers - target), -np.inf)\n    rule_scores = [best_fit_score, worst_fit_score, first_fit_score, fill_bal_score]\n    waste_per_rule = np.empty(priority_v2.num_rules, dtype=float)\n    for i, scores in enumerate(rule_scores):\n        if not np.isfinite(scores).any():\n            waste_per_rule[i] = np.inf\n        else:\n            idx = np.argmax(scores)\n            waste_per_rule[i] = bins_remain_cap[idx] - item\n    for i in range(priority_v2.num_rules):\n        w = waste_per_rule[i]\n        if np.isfinite(w):\n            priority_v2.sum_waste[i] += w\n            priority_v2.count[i] += 1\n    avg_waste = np.where(priority_v2.count > 0, priority_v2.sum_waste / priority_v2.count, np.inf)\n    inv = 1.0 / (avg_waste + priority_v2.epsilon)\n    boost = np.zeros(priority_v2.num_rules, dtype=float)\n    boost_idx = priority_v2.step % priority_v2.num_rules\n    boost[boost_idx] = 1.0 / (priority_v2.step + 1)\n    raw_weights = inv + boost\n    total = raw_weights.sum()\n    if total > 0:\n        weights = raw_weights / total\n    else:\n        weights = np.full(priority_v2.num_rules, 1.0 / priority_v2.num_rules)\n    combined_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    for w, scores in zip(weights, rule_scores):\n        combined_scores += w * scores\n    combined_scores[~feasible] = -np.inf\n    priority_v2.step += 1\n    return combined_scores\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if not hasattr(priority_v2, \"initialized\"):\n        priority_v2.num_rules = 4\n        priority_v2.sum_waste = np.zeros(priority_v2.num_rules, dtype=float)\n        priority_v2.count = np.zeros(priority_v2.num_rules, dtype=int)\n        priority_v2.step = 0\n        priority_v2.epsilon = 1e-9\n        priority_v2.initialized = True\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap - item\n    best_fit_score = np.where(feasible, -leftovers, -np.inf)\n    worst_fit_score = np.where(feasible, leftovers, -np.inf)\n    indices = np.arange(bins_remain_cap.shape[0] if hasattr(bins_remain_cap, \"shape\") else len(bins_remain_cap))\n    first_fit_score = np.where(feasible, -indices, -np.inf)\n    target = bins_remain_cap.mean()\n    fill_bal_score = np.where(feasible, -np.abs(leftovers - target), -np.inf)\n    rule_scores = [best_fit_score, worst_fit_score, first_fit_score, fill_bal_score]\n    waste_per_rule = np.empty(priority_v2.num_rules, dtype=float)\n    for i, scores in enumerate(rule_scores):\n        if not np.isfinite(scores).any():\n            waste_per_rule[i] = np.inf\n        else:\n            idx = np.argmax(scores)\n            waste_per_rule[i] = bins_remain_cap[idx] - item\n    for i in range(priority_v2.num_rules):\n        w = waste_per_rule[i]\n        if np.isfinite(w):\n            priority_v2.sum_waste[i] += w\n            priority_v2.count[i] += 1\n    avg_waste = np.where(priority_v2.count > 0, priority_v2.sum_waste / priority_v2.count, np.inf)\n    inv = 1.0 / (avg_waste + priority_v2.epsilon)\n    boost = np.zeros(priority_v2.num_rules, dtype=float)\n    boost_idx = priority_v2.step % priority_v2.num_rules\n    boost[boost_idx] = 1.0 / (priority_v2.step + 1)\n    raw_weights = inv + boost\n    total = raw_weights.sum()\n    if total > 0:\n        weights = raw_weights / total\n    else:\n        weights = np.full(priority_v2.num_rules, 1.0 / priority_v2.num_rules)\n    combined_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    for w, scores in zip(weights, rule_scores):\n        combined_scores += w * scores\n    combined_scores[~feasible] = -np.inf\n    priority_v2.step += 1\n    return combined_scores\n\n[Heuristics 17th]\nimport numpy as np\n\nclass PriorityV2:\n    def __init__(self):\n        self.total_calls = 0\n        self.selection_counts = None\n        self.total_rewards = None\n        self.temperature = 1.0\n        self.decay = 0.995\n\n    def priority(self, item, bins_remain_cap):\n        n = bins_remain_cap.shape[0]\n        if self.selection_counts is None or self.selection_counts.shape[0] != n:\n            self.selection_counts = np.zeros(n, dtype=float)\n            self.total_rewards = np.zeros(n, dtype=float)\n        feasible = bins_remain_cap >= item\n        leftovers = np.where(feasible, bins_remain_cap - item, np.inf)\n        base_score = np.where(feasible, 1.0 / (leftovers + 1.0), 0.0)\n        median_leftover = np.median(leftovers[feasible]) if np.any(feasible) else 0.0\n        diversity = np.where(feasible, 1.0 / (np.abs(leftovers - median_leftover) + 1.0), 0.0)\n        avg_reward = np.where(self.selection_counts > 0, self.total_rewards / self.selection_counts, 0.0)\n        c = 1.0\n        ucb = avg_reward + c * np.sqrt(np.log(self.total_calls + 1) / (self.selection_counts + 1))\n        combined_feas = 0.5 * base_score + 0.3 * diversity + 0.2 * ucb\n        combined = np.full(n, -np.inf, dtype=float)\n        combined[feasible] = combined_feas[feasible]\n        noise = np.random.rand(n)\n        combined[feasible] = (1 - self.temperature) * combined[feasible] + self.temperature * noise[feasible]\n        self.total_calls += 1\n        self.temperature *= self.decay\n        if np.any(feasible):\n            chosen = np.argmax(combined)\n            reward = - (bins_remain_cap[chosen] - item)\n            self.selection_counts[chosen] += 1\n            self.total_rewards[chosen] += reward\n        return combined\n\n_priority_v2_instance = PriorityV2()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    return _priority_v2_instance.priority(item, bins_remain_cap)\n\n[Heuristics 18th]\nimport numpy as np\n\n# Global state for the heuristic\n_pv2_selection_counts = None\n_pv2_total_rewards = None\n_pv2_total_calls = None\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines epsilon\u2011greedy inverse slack scoring with UCB exploration and median\u2011based diversity to balance fit and exploration in online BPP.\"\"\"\n    global _pv2_selection_counts, _pv2_total_rewards, _pv2_total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    if _pv2_selection_counts is None or _pv2_selection_counts.shape[0] != n:\n        _pv2_selection_counts = np.zeros(n, dtype=float)\n        _pv2_total_rewards = np.zeros(n, dtype=float)\n        _pv2_total_calls = 0\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full(n, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    det_score = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    rand_part = np.random.rand(leftovers.size)\n    base_score = (1 - epsilon) * det_score + epsilon * rand_part\n    selection_counts_feasible = _pv2_selection_counts[feasible]\n    avg_reward_feasible = np.where(selection_counts_feasible > 0,\n                                   _pv2_total_rewards[feasible] / selection_counts_feasible,\n                                   0.0)\n    c = 0.5\n    exploration_bonus_feasible = c * np.sqrt(np.log(_pv2_total_calls + 1) / (selection_counts_feasible + 1))\n    ucb_score = avg_reward_feasible + exploration_bonus_feasible\n    median_leftover = np.median(leftovers) if leftovers.size > 0 else 0.0\n    diversity_score = 1.0 / (np.abs(leftovers - median_leftover) + 1.0)\n    ucb_weight = 0.3\n    diversity_weight = 0.2\n    combined_score_feasible = base_score + ucb_weight * ucb_score + diversity_weight * diversity_score\n    scores = np.full(n, -np.inf, dtype=float)\n    scores[feasible] = combined_score_feasible\n    best = np.argmax(scores)\n    chosen_leftover = bins_remain_cap[best] - item\n    reward = -chosen_leftover\n    _pv2_selection_counts[best] += 1\n    _pv2_total_rewards[best] += reward\n    _pv2_total_calls += 1\n    return scores\n\n[Heuristics 19th]\nimport numpy as np\n\n# Global state for the heuristic\n_pv2_selection_counts = None\n_pv2_total_rewards = None\n_pv2_total_calls = None\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines epsilon\u2011greedy inverse slack scoring with UCB exploration and median\u2011based diversity to balance fit and exploration in online BPP.\"\"\"\n    global _pv2_selection_counts, _pv2_total_rewards, _pv2_total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.size\n    if n == 0:\n        return np.empty(0, dtype=float)\n    if _pv2_selection_counts is None or _pv2_selection_counts.shape[0] != n:\n        _pv2_selection_counts = np.zeros(n, dtype=float)\n        _pv2_total_rewards = np.zeros(n, dtype=float)\n        _pv2_total_calls = 0\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full(n, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    det_score = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    rand_part = np.random.rand(leftovers.size)\n    base_score = (1 - epsilon) * det_score + epsilon * rand_part\n    selection_counts_feasible = _pv2_selection_counts[feasible]\n    avg_reward_feasible = np.where(selection_counts_feasible > 0,\n                                   _pv2_total_rewards[feasible] / selection_counts_feasible,\n                                   0.0)\n    c = 0.5\n    exploration_bonus_feasible = c * np.sqrt(np.log(_pv2_total_calls + 1) / (selection_counts_feasible + 1))\n    ucb_score = avg_reward_feasible + exploration_bonus_feasible\n    median_leftover = np.median(leftovers) if leftovers.size > 0 else 0.0\n    diversity_score = 1.0 / (np.abs(leftovers - median_leftover) + 1.0)\n    ucb_weight = 0.3\n    diversity_weight = 0.2\n    combined_score_feasible = base_score + ucb_weight * ucb_score + diversity_weight * diversity_score\n    scores = np.full(n, -np.inf, dtype=float)\n    scores[feasible] = combined_score_feasible\n    best = np.argmax(scores)\n    chosen_leftover = bins_remain_cap[best] - item\n    reward = -chosen_leftover\n    _pv2_selection_counts[best] += 1\n    _pv2_total_rewards[best] += reward\n    _pv2_total_calls += 1\n    return scores\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                epsilon: float = 0.2,\n                temperature: float = 1.0,\n                total_threshold: float = 0.0) -> np.ndarray:\n    \"\"\"Inverse slack scored, temperature\u2011scaled softmax, then blended with \u03b5\u2011noise for tie\u2011breaking.\"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    base = 1.0 / (leftovers + 1.0)\n    exp_input = base / temperature\n    exp_input = np.clip(exp_input, a_min=None, a_max=50.0)\n    exp_scores = np.exp(exp_input)\n    total = exp_scores.sum()\n    if total >= total_threshold:\n        scores[feasible] = exp_scores / total\n    else:\n        scores[feasible] = 0.0\n    rand = np.random.rand(bins_remain_cap.shape[0])\n    rand[~feasible] = 0.0\n    return (1.0 - epsilon) * scores + epsilon * rand\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}