```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Hybrid slack and reward scoring with ε‑greedy exploration."""
    w_inv = 0.6
    w_lin = 0.4
    w_reward = 0.2
    epsilon = 0.15
    if not hasattr(priority_v2, "selection_counts") or priority_v2.selection_counts.shape != bins_remain_cap.shape:
        priority_v2.selection_counts = np.zeros(bins_remain_cap.shape, dtype=float)
        priority_v2.total_rewards = np.zeros(bins_remain_cap.shape, dtype=float)
        priority_v2.total_calls = 0
    feasible = bins_remain_cap >= item
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    if np.any(feasible):
        slack = bins_remain_cap[feasible] - item
        base = w_inv * (1.0 / (slack + 1.0)) + w_lin * (-slack)
        sel_counts_feas = priority_v2.selection_counts[feasible]
        tot_rewards_feas = priority_v2.total_rewards[feasible]
        avg_reward_feas = np.where(sel_counts_feas > 0, tot_rewards_feas / sel_counts_feas, 0.0)
        base = base + w_reward * avg_reward_feas
        rand = np.random.rand(feasible.sum())
        scores[feasible] = 0.0
        scores[feasible] = (1 - epsilon) * base + epsilon * rand
        chosen = np.argmax(scores)
        chosen_slack = bins_remain_cap[chosen] - item
        priority_v2.selection_counts[chosen] += 1
        priority_v2.total_rewards[chosen] += -chosen_slack
        priority_v2.total_calls += 1
    return scores
```
