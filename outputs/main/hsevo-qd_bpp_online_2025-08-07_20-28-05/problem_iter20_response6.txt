```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive hybrid scoring: combine inverse slack, learned waste, UCB exploration, and diversity with epsilon noise."""
    if not hasattr(priority_v2, "initialized"):
        priority_v2.num_rules = 4
        priority_v2.sum_waste = np.zeros(priority_v2.num_rules, dtype=float)
        priority_v2.count = np.zeros(priority_v2.num_rules, dtype=int)
        priority_v2.step = 0
        priority_v2.epsilon = 1e-9
        priority_v2.initialized = True
    feasible = bins_remain_cap >= item
    if not np.any(feasible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=float)
    leftovers = bins_remain_cap - item
    indices = np.arange(bins_remain_cap.shape[0])
    target = bins_remain_cap.mean()
    best_fit_score = np.where(feasible, -leftovers, -np.inf)
    worst_fit_score = np.where(feasible, leftovers, -np.inf)
    first_fit_score = np.where(feasible, -indices, -np.inf)
    fill_bal_score = np.where(feasible, -np.abs(leftovers - target), -np.inf)
    rule_scores = [best_fit_score, worst_fit_score, first_fit_score, fill_bal_score]
    waste_per_rule = np.empty(priority_v2.num_rules, dtype=float)
    for i, scores in enumerate(rule_scores):
        if not np.isfinite(scores).any():
            waste_per_rule[i] = np.inf
        else:
            idx = np.argmax(scores)
            waste_per_rule[i] = bins_remain_cap[idx] - item
    for i in range(priority_v2.num_rules):
        w = waste_per_rule[i]
        if np.isfinite(w):
            priority_v2.sum_waste[i] += w
            priority_v2.count[i] += 1
    avg_waste = np.where(priority_v2.count > 0, priority_v2.sum_waste / priority_v2.count, np.inf)
    inv = 1.0 / (avg_waste + priority_v2.epsilon)
    boost = np.zeros(priority_v2.num_rules, dtype=float)
    boost_idx = priority_v2.step % priority_v2.num_rules
    boost[boost_idx] = 1.0 / (priority_v2.step + 1)
    raw_weights = inv + boost
    total = raw_weights.sum()
    if total > 0:
        weights = raw_weights / total
    else:
        weights = np.full(priority_v2.num_rules, 1.0 / priority_v2.num_rules)
    total_calls = priority_v2.step + 1
    ucb_bonus = np.empty(priority_v2.num_rules, dtype=float)
    for r in range(priority_v2.num_rules):
        if priority_v2.count[r] > 0:
            ucb_bonus[r] = np.sqrt(2 * np.log(total_calls) / priority_v2.count[r])
        else:
            ucb_bonus[r] = np.sqrt(2 * np.log(total_calls))
    median_slack = np.median(leftovers[feasible])
    diversity_bonus = np.empty(priority_v2.num_rules, dtype=float)
    for r, scores in enumerate(rule_scores):
        if not np.isfinite(scores).any():
            diversity_bonus[r] = 0.0
        else:
            idx = np.argmax(scores)
            diversity_bonus[r] = np.abs(leftovers[idx] - median_slack)
    combined_scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    for w, scores, ub, db in zip(weights, rule_scores, ucb_bonus, diversity_bonus):
        temp = np.where(feasible, scores, -np.inf)
        temp += ub
        temp += db
        combined_scores += w * temp
    rand_noise = np.random.rand(bins_remain_cap.shape[0])
    rand_noise[~feasible] = 0.0
    combined_scores += 0.05 * rand_noise
    priority_v2.step += 1
    return combined_scores
```
