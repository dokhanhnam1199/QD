```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Score bins by inverse slack, a simple Bayesian linear model, and ε‑greedy exploration."""
    # Initialize static state on first call
    if not hasattr(priority_v2, "_init"):
        priority_v2._selection_counts = None
        priority_v2._total_rewards = None
        priority_v2._total_calls = 0
        priority_v2._epsilon = 0.1          # exploration probability
        priority_v2._det_weight = 0.7    # weight for deterministic inverse‑slack term
        priority_v2._noise_var = 0.5
        priority_v2._prior_var = 10.0
        priority_v2._bin_capacity = 1.0
        priority_v2._model_mu = None
        priority_v2._model_cov = None
        priority_v2._model_precision = None
        priority_v2._init = True

    caps = np.asarray(bins_remain_cap, dtype=float).ravel()
    n = caps.shape[0]
    if n == 0:
        return np.array([], dtype=float)

    # Resize per‑bin statistics if number of bins changed
    if priority_v2._selection_counts is None or priority_v2._selection_counts.shape[0] != n:
        priority_v2._selection_counts = np.zeros(n, dtype=float)
        priority_v2._total_rewards = np.zeros(n, dtype=float)

    # Initialise Bayesian linear model if needed
    if priority_v2._model_mu is None:
        d = 3
        priority_v2._model_mu = np.zeros(d)
        priority_v2._model_mu = priority_v2._model_mu
        priority_v2._model_cov = np.eye(d) * priority_v2._prior_var
        priority_v2._model_precision = np.linalg.inv(priority_v2._model_cov)

    # Update known bin capacity (assumes uniform capacity across bins)
    max_cap = caps.max()
    if max_cap > priority_v2._bin_capacity:
        priority_v2._bin_capacity = max_cap

    feasible = caps >= item
    scores = np.full(n, -np.inf, dtype=float)
    if not np.any(feasible):
        priority_v2._total_calls += 1
        return scores

    # Deterministic inverse‑slack term
    leftover = caps[feasible] - item
    det_score = 1.0 / (leftover + 1.0)

    # Features for Bayesian model: [1, slack, fill]
    slack = leftover
    fill = 1.0 - slack / priority_v2._bin_capacity
    X = np.column_stack((np.ones_like(slack), slack, fill))
    model_score = X @ priority_v2._model_mu

    # Blend deterministic and model scores
    combined = priority_v2._selection_counts
    combined = priority_v2._det_weight * det_score + (1.0 - priority_v2._det_weight) * model_score

    # ε‑greedy random component
    rand_part = np.random.rand(feasible.sum())
    final = (1.0 - priority_v2._epsilon) * combined + priority_v2._epsilon * rand_part
    scores[feasible] = final

    # Choose best bin and update learning state
    best = int(np.argmax(scores))
    priority_v2._total_calls += 1
    if feasible[best]:
        reward = - (caps[best] - item)          # negative leftover (higher is better)
        priority_v2._selection_counts[best] += 1
        priority_v2._total_rewards[best] += reward

        # Bayesian update with selected bin's feature vector
        slack_best = caps[best] - item
        fill_best = 1.0 - slack_best / priority_v2._bin_capacity
        x = np.array([1.0, slack_best, fill_best])
        precision_new = priority_v2._model_precision + np.outer(x, x) / priority_v2._noise_var
        cov_new = priority_v2._model_cov
        cov_new = np.linalg.inv(precision_new)
        mu_new = cov_new @ (priority_v2._model_precision @ priority_v2._model_mu + x * reward / priority_v2._noise_var)
        priority_v2._model_precision = precision_new
        priority_v2._model_cov = cov_new
        priority_v2._model_mu = mu_new

    return scores
```
