import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                epsilon: float = 0.13593895306863657,
                w_inv: float = 0.3693166297861673,
                w_lin: float = 0.9392327112846909,
                w_sq: float = 0.20958327674192154,
                temperature: float = 0.8215469888601971,
                slack_offset: float = 2.06267289533554) -> np.ndarray:
    """
    Compute a probability distribution over bins based on remaining capacity.

    The function now exposes previously hardâ€‘coded thresholds and weights as
    parameters with sensible defaults.
    """
    feasible = bins_remain_cap >= item
    if not np.any(feasible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=float)

    slack = bins_remain_cap[feasible] - item

    # Core scoring function using configurable weights and slack offset
    core = w_inv / (slack + slack_offset) - w_lin * slack - w_sq * slack**2

    # Add a small random perturbation controlled by epsilon
    rand = np.random.rand(feasible.sum())
    scores_feasible = (1 - epsilon) * core + epsilon * rand

    # Assemble full scores array (infeasible bins get -inf)
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    scores[feasible] = scores_feasible

    # Softmax with temperature scaling
    max_score = np.max(scores_feasible)
    exp_scores = np.exp((scores_feasible - max_score) / temperature)
    probs_feasible = exp_scores / exp_scores.sum()

    # Build final probability vector (infeasible bins get 0)
    0
    probs = np.zeros_like(bins_remain_cap, dtype=float)
    probs[feasible] = probs_feasible
    return probs
