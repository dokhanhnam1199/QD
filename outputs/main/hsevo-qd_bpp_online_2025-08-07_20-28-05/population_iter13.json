[
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    slack = bins_remain_cap - item\n    fits = slack >= 0\n    eps = np.finfo(slack.dtype).eps\n    return np.where(fits, -slack + eps, -np.inf)",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = 1.0 / (leftovers + 1.0)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores",
    "response_id": 18,
    "tryHS": true,
    "obj": 3.370562425209409,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                epsilon: float = 0.2, beta: float = 0.02) -> np.ndarray:\n    \"\"\"Epsilon\u2011greedy tight\u2011fit with squared\u2011slack penalty for waste reduction.\"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    leftovers = bins_remain_cap[feasible] - item\n    det = 1.0/(leftovers + 1.0) - beta * leftovers**2\n    rand_part = np.random.rand(bins_remain_cap.size)\n    scores[feasible] = (1 - epsilon) * det + epsilon * rand_part[feasible]\n    return scores",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.3272578070972282,\n                offset: float = 3.6930496425184325,\n                score_scale: float = 1.8547777441606528) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins given an item size.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of bins.\n    epsilon : float, optional\n        Weight for the random exploration term (default 0.2).\n    offset : float, optional\n        Small constant added to leftover capacity to avoid division by zero\n        (default 1.0).\n    score_scale : float, optional\n        Scaling factor for the deterministic part of the score\n        (default 1.0).\n\n    Returns\n    -------\n    np.ndarray\n        Score for each bin; -inf for infeasible bins.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    scores[feasible] = score_scale / (leftovers + offset)\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    return scores",
    "response_id": 2,
    "tryHS": true,
    "obj": 3.5500598324691004,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\nclass PriorityV2:\n    def __init__(self):\n        self.total_calls = 0\n        self.selection_counts = None\n        self.total_rewards = None\n        self.temperature = 1.0\n        self.decay = 0.995\n\n    def priority(self, item, bins_remain_cap):\n        n = bins_remain_cap.shape[0]\n        if self.selection_counts is None or self.selection_counts.shape[0] != n:\n            self.selection_counts = np.zeros(n, dtype=float)\n            self.total_rewards = np.zeros(n, dtype=float)\n        feasible = bins_remain_cap >= item\n        leftovers = np.where(feasible, bins_remain_cap - item, np.inf)\n        base_score = np.where(feasible, 1.0 / (leftovers + 1.0), 0.0)\n        median_leftover = np.median(leftovers[feasible]) if np.any(feasible) else 0.0\n        diversity = np.where(feasible, 1.0 / (np.abs(leftovers - median_leftover) + 1.0), 0.0)\n        avg_reward = np.where(self.selection_counts > 0, self.total_rewards / self.selection_counts, 0.0)\n        c = 1.0\n        ucb = avg_reward + c * np.sqrt(np.log(self.total_calls + 1) / (self.selection_counts + 1))\n        combined_feas = 0.5 * base_score + 0.3 * diversity + 0.2 * ucb\n        combined = np.full(n, -np.inf, dtype=float)\n        combined[feasible] = combined_feas[feasible]\n        noise = np.random.rand(n)\n        combined[feasible] = (1 - self.temperature) * combined[feasible] + self.temperature * noise[feasible]\n        self.total_calls += 1\n        self.temperature *= self.decay\n        if np.any(feasible):\n            chosen = np.argmax(combined)\n            reward = - (bins_remain_cap[chosen] - item)\n            self.selection_counts[chosen] += 1\n            self.total_rewards[chosen] += reward\n        return combined\n\n_priority_v2_instance = PriorityV2()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    return _priority_v2_instance.priority(item, bins_remain_cap)",
    "response_id": 0,
    "tryHS": false,
    "obj": 59.57319505384924,
    "SLOC": 2.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    if not np.any(feasible):\n        return priorities\n    slack = bins_remain_cap[feasible] - item\n    temperature = 1.0\n    exp_vals = np.exp(-slack / temperature)\n    total = exp_vals.sum()\n    if total > 0:\n        priorities[feasible] = exp_vals / total\n    return priorities",
    "response_id": 19,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\n# Combine inverse\u2011slack and linear\u2011slack with \u03b5\u2011greedy randomness.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    \u03b5\u2011greedy scoring: weighted sum of inverse slack and negative slack, with random tie\u2011breaker.\n    \"\"\"\n    epsilon = 0.15          # exploration factor\n    w_inv = 0.6             # weight for reciprocal slack\n    w_lin = 0.4             # weight for linear slack penalty\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    base = w_inv * (1.0 / (slack + 1.0)) + w_lin * (-slack)\n    scores[feasible] = base\n    scores = (1 - epsilon) * scores + epsilon * np.random.rand(bins_remain_cap.shape[0])\n    # softmax scaling for probability\u2011like priorities\n    finite_mask = np.isfinite(scores)\n    if not np.any(finite_mask):\n        return scores\n    max_score = np.max(scores[finite_mask])\n    exp_scores = np.exp(scores - max_score)\n    exp_scores[~finite_mask] = 0.0\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.2\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    random_part = np.random.rand(feasible.sum())\n    combined = (1 - epsilon) * deterministic + epsilon * random_part\n    scores[feasible] = combined\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    probabilities = exp_scores / exp_scores.sum()\n    return probabilities",
    "response_id": 5,
    "tryHS": false,
    "obj": 3.4004786597527064,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combine inverse slack and negative squared slack with epsilon\u2011greedy randomness for balanced tight\u2011fit and exploration.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftover = bins_remain_cap[feasible] - item\n    epsilon = 0.2\n    beta = 0.01\n    deterministic = 1.0 / (leftover + 1e-9) - beta * (leftover ** 2)\n    random_part = np.random.rand(feasible.sum())\n    scores = (1 - epsilon) * deterministic + epsilon * random_part\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    priorities[feasible] = scores\n    return priorities",
    "response_id": 7,
    "tryHS": true,
    "obj": 4.028719585161557,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\n# Combine tight\u2011fit incentive, slack penalty, random exploration, and softmax scaling.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Score bins by inverse slack, squared\u2011slack penalty, \u03b5\u2011greedy noise, and softmax.\"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    if not np.any(feasible):\n        return priorities\n    slack = bins_remain_cap[feasible] - item\n    inv_slack = 1.0 / (slack + 1.0)\n    beta = 0.1\n    penalty = -beta * (slack ** 2)\n    deterministic = inv_slack + penalty\n    epsilon = 0.05\n    random_noise = epsilon * np.random.rand(deterministic.shape[0])\n    raw = deterministic + random_noise\n    temperature = 0.5\n    exp_vals = np.exp(raw / temperature)\n    total = exp_vals.sum()\n    if total > 0:\n        priorities[feasible] = exp_vals / total\n    return priorities",
    "response_id": 1,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\n# Combines multiple slack components with epsilon\u2011greedy exploration and softmax scaling.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                epsilon: float = 0.1, w_inv: float = 0.5,\n                w_lin: float = 0.3, w_sq: float = 0.2,\n                temperature: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Epsilon\u2011greedy softmax priority blending inverse slack, linear slack penalty,\n    and squared slack penalty for balanced tight fits and exploration.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if np.any(feasible):\n        slack = bins_remain_cap[feasible] - item\n        base = w_inv * (1.0 / (slack + 1.0)) - w_lin * slack - w_sq * slack**2\n        scores[feasible] = base\n    if epsilon > 0:\n        scores += epsilon * np.random.rand(bins_remain_cap.size)\n    finite_mask = np.isfinite(scores)\n    if not np.any(finite_mask):\n        return scores\n    exp_scores = np.exp((scores[finite_mask] / temperature) -\n                        np.max(scores[finite_mask] / temperature))\n    probs = np.zeros_like(scores)\n    probs[finite_mask] = exp_scores / exp_scores.sum()\n    return probs",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                temperature: float = 8.21777003404979,\n                total_threshold: float = 0.7518899527010219) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        temperature: Temperature controlling the softness of the exponential weighting.\n        total_threshold: Minimum sum of exponential values required to assign non\u2011zero priorities.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    if not np.any(feasible):\n        return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 0.15\n    w_inv = 0.5\n    w_lin = 0.3\n    w_sq = 0.2\n    temperature = 1.0\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    slack = bins_remain_cap[feasible] - item\n    core = w_inv / (slack + 1.0) - w_lin * slack - w_sq * slack**2\n    rand = np.random.rand(feasible.sum())\n    scores_feasible = (1 - epsilon) * core + epsilon * rand\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    scores[feasible] = scores_feasible\n    max_score = np.max(scores_feasible)\n    exp_scores = np.exp((scores_feasible - max_score) / temperature)\n    probs_feasible = exp_scores / exp_scores.sum()\n    probs = np.zeros_like(bins_remain_cap, dtype=float)\n    probs[feasible] = probs_feasible\n    return probs",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 21.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\n_selection_counts = None\n_total_rewards = None\n_total_calls = 0\n\ndef priority_v2(item, bins_remain_cap):\n    global _selection_counts, _total_rewards, _total_calls\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n = bins_remain_cap.shape[0]\n    if n == 0:\n        return np.array([], dtype=float)\n    if _selection_counts is None or _selection_counts.shape[0] != n:\n        _selection_counts = np.zeros(n, dtype=float)\n        _total_rewards = np.zeros(n, dtype=float)\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full(n, -np.inf, dtype=float)\n    scores = np.full(n, -np.inf, dtype=float)\n    leftovers = bins_remain_cap[feasible] - item\n    deterministic = 1.0 / (leftovers + 1.0)\n    epsilon = 0.2\n    random_part = np.random.rand(feasible.sum())\n    base_score = (1 - epsilon) * deterministic + epsilon * random_part\n    avg_reward_feas = np.zeros_like(base_score)\n    mask_counts_feas = _selection_counts[feasible] > 0\n    avg_reward_feas[mask_counts_feas] = _total_rewards[feasible][mask_counts_feas] / _selection_counts[feasible][mask_counts_feas]\n    reward_weight = 0.3\n    combined_feas = base_score + reward_weight * avg_reward_feas\n    scores[feasible] = combined_feas\n    best = np.argmax(scores)\n    _total_calls += 1\n    leftover = bins_remain_cap[best] - item\n    reward = -leftover\n    _selection_counts[best] += 1\n    _total_rewards[best] += reward\n    return scores",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.3905065815716,
    "SLOC": 31.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if not hasattr(priority_v2, \"initialized\"):\n        priority_v2.num_rules = 4\n        priority_v2.sum_waste = np.zeros(priority_v2.num_rules, dtype=float)\n        priority_v2.count = np.zeros(priority_v2.num_rules, dtype=int)\n        priority_v2.step = 0\n        priority_v2.epsilon = 1e-9\n        priority_v2.initialized = True\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftovers = bins_remain_cap - item\n    best_fit_score = np.where(feasible, -leftovers, -np.inf)\n    worst_fit_score = np.where(feasible, leftovers, -np.inf)\n    indices = np.arange(bins_remain_cap.shape[0] if hasattr(bins_remain_cap, \"shape\") else len(bins_remain_cap))\n    first_fit_score = np.where(feasible, -indices, -np.inf)\n    target = bins_remain_cap.mean()\n    fill_bal_score = np.where(feasible, -np.abs(leftovers - target), -np.inf)\n    rule_scores = [best_fit_score, worst_fit_score, first_fit_score, fill_bal_score]\n    waste_per_rule = np.empty(priority_v2.num_rules, dtype=float)\n    for i, scores in enumerate(rule_scores):\n        if not np.isfinite(scores).any():\n            waste_per_rule[i] = np.inf\n        else:\n            idx = np.argmax(scores)\n            waste_per_rule[i] = bins_remain_cap[idx] - item\n    for i in range(priority_v2.num_rules):\n        w = waste_per_rule[i]\n        if np.isfinite(w):\n            priority_v2.sum_waste[i] += w\n            priority_v2.count[i] += 1\n    avg_waste = np.where(priority_v2.count > 0, priority_v2.sum_waste / priority_v2.count, np.inf)\n    inv = 1.0 / (avg_waste + priority_v2.epsilon)\n    boost = np.zeros(priority_v2.num_rules, dtype=float)\n    boost_idx = priority_v2.step % priority_v2.num_rules\n    boost[boost_idx] = 1.0 / (priority_v2.step + 1)\n    raw_weights = inv + boost\n    total = raw_weights.sum()\n    if total > 0:\n        weights = raw_weights / total\n    else:\n        weights = np.full(priority_v2.num_rules, 1.0 / priority_v2.num_rules)\n    combined_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    for w, scores in zip(weights, rule_scores):\n        combined_scores += w * scores\n    combined_scores[~feasible] = -np.inf\n    priority_v2.step += 1\n    return combined_scores",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.3777423214998095,
    "SLOC": 48.0,
    "cyclomatic_complexity": 10.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item, bins_remain_cap):\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 5.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                beta: float = 0.01, temperature: float = 1.0,\n                total_threshold: float = 1e-6) -> np.ndarray:\n    \"\"\"Score bins by inverse slack minus slack\u00b2, softened with temperature.\"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if not feasible.any():\n        return priorities\n    slack = bins_remain_cap[feasible] - item\n    eps = 1e-9\n    raw = 1.0 / (slack + eps) - beta * slack**2\n    exp_scores = np.exp(raw / temperature)\n    if exp_scores.sum() < total_threshold:\n        return priorities\n    priorities[feasible] = exp_scores\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef _extract_features(item: float, bins_remain_cap: np.ndarray, capacity: float):\n    slack = bins_remain_cap - item\n    slack_norm = slack / capacity\n    used_ratio = (capacity - bins_remain_cap) / capacity\n    return slack_norm, used_ratio\n\ndef _combine_features(slack_norm: np.ndarray, used_ratio: np.ndarray):\n    return used_ratio - slack_norm\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    capacity = np.max(bins_remain_cap) if bins_remain_cap.size else 0.0\n    feasible = bins_remain_cap >= item\n    scores = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    if capacity > 0 and np.any(feasible):\n        slack_norm, used_ratio = _extract_features(item, bins_remain_cap, capacity)\n        combined = _combine_features(slack_norm, used_ratio)\n        scores[feasible] = combined[feasible]\n    return scores",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  }
]