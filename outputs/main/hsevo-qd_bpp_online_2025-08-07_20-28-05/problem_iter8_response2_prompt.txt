{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combine inverse slack and negative squared slack with epsilon\u2011greedy randomness for balanced tight\u2011fit and exploration.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    leftover = bins_remain_cap[feasible] - item\n    epsilon = 0.2\n    beta = 0.01\n    deterministic = 1.0 / (leftover + 1e-9) - beta * (leftover ** 2)\n    random_part = np.random.rand(feasible.sum())\n    scores = (1 - epsilon) * deterministic + epsilon * random_part\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    priorities[feasible] = scores\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    if not np.any(feasible):\n        return priorities\n    slack = bins_remain_cap[feasible] - item\n    temperature = 1.0\n    exp_vals = np.exp(-slack / temperature)\n    total = exp_vals.sum()\n    if total > 0:\n        priorities[feasible] = exp_vals / total\n    return priorities\n\n### Analyze & experience\n- Comparing **(best) vs (worst)**, we see that the best heuristic is a terse, stateless function that imports only *numpy*, computes a feasible mask, uses a simple inverse\u2011slack score, blends a modest \u03b5\u2011greedy random term, and returns raw scores (\u2011inf for infeasible). The worst heuristic is a heavyweight class with many unused imports, stateful counters, UCB\u2011style confidence bounds, diversity terms, temperature decay, and reward updates\u2014far more parameters and logic than needed, with no clear documentation of why each term helps.  \n\n**(second best) vs (second worst)** shows a similar gap: the second\u2011best function adds an early\u2011exit for infeasibility and a numerically\u2011stable softmax conversion, still staying stateless and lightweight. The second\u2011worst (identical to the worst) repeats the complex UCB machinery, bringing the same overhead and opaque hyper\u2011parameters.  \n\n**Comparing (1st) vs (2nd)**, both share the same deterministic core (inverse slack + \u03b5\u2011greedy), but the 2nd adds a softmax layer and an explicit infeasibility guard. The 1st is marginally faster and returns scores directly; the 2nd is better suited for stochastic selection at the cost of extra exponentials.  \n\n**(3rd) vs (4th)** are exact duplicates of the 2nd version\u2014no code or comment differences, highlighting redundancy in the list.  \n\n**Comparing (second worst) vs (worst)** reveals no distinction: both are identical stateful UCB implementations, offering no incremental benefit despite being labeled separately.  \n\n**Overall:** Simplicity, a clear deterministic metric, and a tiny \u03b5\u2011greedy term dominate performance. Over\u2011parameterization, deep statefulness, and excessive randomness consistently degrade heuristic quality.\n- \n- **Keywords:** adaptive, modular, constraint\u2011driven, exploration\u2011exploitation  \n- **Advice:** Build a deterministic core that exploits structural properties (e.g., priority queues, incremental updates) and pair it with a lightweight meta\u2011selector that chooses among several simple rules based on recent success, updating its preferences online.  \n- **Avoid:** Fixed numeric thresholds, static random mixing, and manual parameter tweaks.  \n- **Explanation:** The deterministic core ensures fast feasible decisions, while the online meta\u2011selector adds diverse behavior without heavy hyper\u2011parameters, yielding robust performance across varied problem instances.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}