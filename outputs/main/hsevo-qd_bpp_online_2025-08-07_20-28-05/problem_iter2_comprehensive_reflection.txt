
- **Keywords:** slack minimization, ε‑greedy, softmax scaling, infeasibility penalty, diversity.  
- **Advice:** Score each bin by a normalized negative slack, add a small ε random perturbation, and apply a softmax to convert scores to selection probabilities.  
- **Avoid:** Fixed deterministic ordering, overly large ε that drowns the signal, reward functions that reward waste or ignore infeasibility.  
- **Explanation:** This mix preserves exploitation of tight fits while retaining exploration, stabilizes learning via bounded probabilities, and quickly rejects impossible placements.