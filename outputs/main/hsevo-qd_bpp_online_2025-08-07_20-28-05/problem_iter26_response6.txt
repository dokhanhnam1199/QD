```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Priority scoring for online BPP: inverse slack, epsilonâ€‘greedy, lightweight learning via avg reward and UCB, updates after each placement.
    """
    if not hasattr(priority_v2, 'counts'):
        priority_v2.counts = np.zeros_like(bins_remain_cap, dtype=int)
        priority_v2.reward_sum = np.zeros_like(bins_remain_cap, dtype=float)
        priority_v2.total_calls = 0
    if priority_v2.counts.shape != bins_remain_cap.shape:
        priority_v2.counts = np.zeros_like(bins_remain_cap, dtype=int)
        priority_v2.reward_sum = np.zeros_like(bins_remain_cap, dtype=float)
        priority_v2.total_calls = 0
    feasible = bins_remain_cap >= item
    if not np.any(feasible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=float)
    leftover = bins_remain_cap[feasible] - item
    eps = 1e-9
    beta = 0.01
    base = 1.0/(leftover + eps) - beta * (leftover ** 2)
    counts_feasible = priority_v2.counts[feasible]
    reward_sum_feasible = priority_v2.reward_sum[feasible]
    avg_reward = np.where(counts_feasible > 0, reward_sum_feasible / counts_feasible, 0.0)
    gamma = 0.05
    reward_bonus = gamma * avg_reward
    total_calls = priority_v2.total_calls
    ucb_bonus = np.sqrt(np.log(total_calls + 1) / (counts_feasible + 1))
    deterministic = base + reward_bonus + ucb_bonus
    epsilon = 0.2
    random_part = np.random.rand(feasible.sum())
    scores_feasible = (1 - epsilon) * deterministic + epsilon * random_part
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    scores[feasible] = scores_feasible
    chosen_idx = np.argmax(scores)
    if feasible[chosen_idx]:
        priority_v2.counts[chosen_idx] += 1
        priority_v2.reward_sum[chosen_idx] += bins_remain_cap[chosen_idx] - item
    priority_v2.total_calls += 1
    return scores
```
