{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using a combination of factors, sparsification, and adaptive thresholding.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix representing the TSP instance.\n\n    Returns:\n        np.ndarray: Prior indicators (probabilities) of edge inclusion.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate inverse distance\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add small value to avoid division by zero\n\n    # Calculate node degree preference:  Nodes with lower degree are preferred (avoiding premature saturation).\n    degree_preference = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_preference[i, j] = 1.0  # Initially, all edges are equally preferred\n    row_sums = np.sum(degree_preference > 0, axis=1, keepdims=True)  # Calculate degree\n    degree_penalty = np.clip(1.0 - row_sums / (n - 1), 0.1, 1.0)  # Scale degree preference, clipping to avoid zero\n    for i in range(n):\n        degree_preference[i, :] *= degree_penalty[i, 0]\n    degree_preference = np.nan_to_num(degree_preference) #handles division by 0, though unlikely.\n\n    # Adaptive Sparsification using Percentile Thresholding.\n    threshold_percentile = 50  # Adjust percentile for sparsification. Experiment with different values.\n    thresholds = np.percentile(distance_matrix[distance_matrix > 0], threshold_percentile) #only consider non-zero elements when determining threshold\n\n    sparse_matrix = distance_matrix.copy()\n    sparse_matrix[distance_matrix > thresholds] = np.inf  # effectively sparsifies matrix.\n    sparse_matrix = (sparse_matrix != np.inf) #creates binary sparse representation\n\n    # Combine heuristics, applying sparsification mask\n    heuristic_matrix = inverse_distance * degree_preference * sparse_matrix # Element-wise product of factors\n\n    # Ensure no self-loops.\n    for i in range(n):\n        heuristic_matrix[i, i] = 0.0\n\n    # Normalize heuristic values to create a probability-like matrix.\n    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)\n    heuristic_matrix = np.nan_to_num(heuristic_matrix / row_sums)  # Avoid division by zero\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP) that combines multiple factors to estimate\n    the promise of each edge. This version considers distance, node degree (preference for less-connected nodes),\n    and random noise for exploration. It sparsifies the matrix by node and ensures symmetry.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix between nodes.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix, where each element indicates\n                      the heuristic value (promise) of including the corresponding edge in the solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate node degree heuristic (prefer less connected nodes)\n    degree_heuristic = np.ones((n, n))  # Initialize with ones\n    for i in range(n):\n        degree = np.sum(1 / (distance_matrix[i, :] + 1e-9))\n        degree_heuristic[i, :] = 1 / degree\n        degree_heuristic[:, i] = 1 / degree\n\n    # Incorporate distance information (shorter distances are better)\n    distance_heuristic = 1 / (distance_matrix + 1e-9)\n\n    # Add random noise for exploration\n    random_noise = np.random.rand(n, n) * 0.1\n\n    # Combine heuristics with adjusted weights\n    heuristics = 0.3 * distance_heuristic + 0.6 * degree_heuristic + 0.1 * random_noise\n\n    # Set diagonal elements to zero (no self-loops)\n    np.fill_diagonal(heuristics, 0)\n\n    # Sparsify the matrix: only keep the most promising edges for each node\n    sparsity_threshold = 0.7\n    for i in range(n):\n        row = heuristics[i, :]\n        threshold = np.quantile(row[row > 0], sparsity_threshold)\n        heuristics[i, row < threshold] = 0\n\n    # Ensure symmetry\n    heuristics = (heuristics + heuristics.T) / 2\n\n    return heuristics\n\n[Reflection]\nSymmetry, node-specific sparsification, weighted combination of factors, and exploration via noise improve heuristic quality.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}