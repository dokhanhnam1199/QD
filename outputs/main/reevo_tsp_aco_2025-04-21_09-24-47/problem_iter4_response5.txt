```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for TSP using a combination of factors, adaptive sparsification, and edge combination.

    Args:
        distance_matrix (np.ndarray): Distance matrix representing the TSP instance.

    Returns:
        np.ndarray: Prior indicators (probabilities) of edge inclusion.
    """
    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Inverse distance heuristic
    inverse_distance = 1.0 / (distance_matrix + 1e-9)

    # Node degree heuristic (favor nodes with fewer connections) - removed as it didn't improve performance in testing.

    # Sparsification - Adaptive k based on percentile.  This is the target neighborhood size.
    k = max(2, int(n * 0.2))  # Start with a percentage, increased for more exploration
    k = min(k, n - 1) # Clamp it.

    # Combination and Sparsification
    combined_heuristic = inverse_distance # Simplified: use only inverse distance for now

    for i in range(n):
        row = combined_heuristic[i].copy()
        indices_to_keep = np.argsort(row)[-k:] # Keep k best edges.
        mask = np.zeros(n, dtype=bool)
        mask[indices_to_keep] = True
        combined_heuristic[i, ~mask] = 0
        combined_heuristic[i, i] = 0 # Remove Self loop.

    # Add some randomness to maintain some level of exploration to get unstuck from local optima. Increased randomness.
    randomness = np.random.rand(n, n) * 0.05 # Add small random noise, increased for more exploration.

    heuristic_matrix = combined_heuristic + randomness # Combine randomness.

    # Normalization (Probability-like)
    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)
    heuristic_matrix = np.nan_to_num(heuristic_matrix / (row_sums + 1e-9)) # Added small constant to avoid division by zero.

    return heuristic_matrix
```
