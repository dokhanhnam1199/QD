{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP) that combines multiple factors to estimate\n    the promise of each edge. This version considers distance, node degree (preference for less-connected nodes),\n    and random noise for exploration. It sparsifies the matrix by node and ensures symmetry. It also refines\n    the degree heuristic and incorporates an edge reciprocity factor.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix between nodes.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix, where each element indicates\n                      the heuristic value (promise) of including the corresponding edge in the solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate node degree heuristic (prefer less connected nodes)\n    degree_heuristic = np.zeros((n, n))\n    for i in range(n):\n        # Refined degree calculation: considers the inverse of the distances to other nodes\n        degree = np.sum(1 / (distance_matrix[i, :] + 1e-9)) - (1 / (distance_matrix[i,i]+1e-9)) #subtract self-loop\n        degree_heuristic[i, :] = 1 / (degree + 1e-9)  # Avoid division by zero and give low score to high degree\n        degree_heuristic[:, i] = 1 / (degree + 1e-9)\n\n\n    # Incorporate distance information (shorter distances are better)\n    distance_heuristic = 1 / (distance_matrix + 1e-9)\n\n    # Edge Reciprocity: Encourage edges that are mutually close.\n    reciprocity_heuristic = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            reciprocity_heuristic[i,j] = 1 / (distance_matrix[i,j] + distance_matrix[j,i] + 1e-9)\n\n    # Add random noise for exploration\n    random_noise = np.random.rand(n, n) * 0.01\n\n    # Combine heuristics with adjusted weights\n    heuristics = 0.4 * distance_heuristic + 0.4 * degree_heuristic + 0.1 * random_noise + 0.1* reciprocity_heuristic\n\n    # Set diagonal elements to zero (no self-loops)\n    np.fill_diagonal(heuristics, 0)\n\n    # Sparsify the matrix: only keep the most promising edges for each node\n    sparsity_threshold = 0.7\n    for i in range(n):\n        row = heuristics[i, :]\n        threshold = np.quantile(row[row > 0], sparsity_threshold) if np.any(row > 0) else -1 #handle edge case\n        heuristics[i, row < threshold] = 0\n\n    # Ensure symmetry\n    heuristics = (heuristics + heuristics.T) / 2\n\n    return heuristics\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using a combination of factors, adaptive sparsification, and edge combination.\n    Includes normalization and slight randomness.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix representing the TSP instance.\n\n    Returns:\n        np.ndarray: Prior indicators (probabilities) of edge inclusion.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance heuristic\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)\n\n    # Node degree heuristic (favor nodes with shorter total distance)\n    node_degree_heuristic = np.zeros_like(distance_matrix, dtype=float)\n    node_distances = np.sum(distance_matrix, axis=1)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                node_degree_heuristic[i, j] = 1.0 / (node_distances[i] + 1e-9) # Bias towards nodes with small distances\n\n    # Sparsification - Adaptive k based on percentile.  This is the target neighborhood size.\n    k = max(2, int(n * 0.1))  # Start with a small percentage\n    k = min(k, n - 1) # Clamp it.\n    # Combination and Sparsification\n    combined_heuristic = inverse_distance * node_degree_heuristic\n    for i in range(n):\n        row = combined_heuristic[i].copy()\n        indices_to_keep = np.argsort(row)[-k:] # Keep k best edges.\n        mask = np.zeros(n, dtype=bool)\n        mask[indices_to_keep] = True\n        combined_heuristic[i, ~mask] = 0\n        combined_heuristic[i, i] = 0 # Remove Self loop.\n\n    # Add some randomness to maintain some level of exploration to get unstuck from local optima\n    randomness = np.random.rand(n, n) * 0.01 # Add small random noise.\n\n    heuristic_matrix = combined_heuristic + randomness # Combine randomness.\n\n    # Normalization (Probability-like)\n    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)\n    heuristic_matrix = np.nan_to_num(heuristic_matrix / (row_sums + 1e-9)) # Adding small constant to avoid division by zero\n\n    return heuristic_matrix\n\n[Reflection]\nAdaptive sparsification, normalization, and combining relevant heuristics factors focusing on node properties improves performance.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}