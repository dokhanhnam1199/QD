```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for TSP using a combination of diverse factors, adaptive weighting,
    and dynamic sparsification. This version incorporates inverse distance, Clarke-Wright savings,
    nearest neighbors, and a novel cycle-breaking mechanism, adjusting weights dynamically
    based on problem characteristics.

    Args:
        distance_matrix (np.ndarray): Distance matrix representing the TSP instance.

    Returns:
        np.ndarray: Prior indicators (probabilities) of edge inclusion.
    """
    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # 1. Inverse Distance Heuristic
    inverse_distance = 1.0 / (distance_matrix + 1e-9)
    inverse_distance = (inverse_distance - np.min(inverse_distance)) / (np.max(inverse_distance) - np.min(inverse_distance) + 1e-9)


    # 2. Clarke-Wright Savings Heuristic
    savings_heuristic = np.zeros((n, n), dtype=float)
    for i in range(n):
        for j in range(i + 1, n):
            savings = distance_matrix[0, i] + distance_matrix[0, j] - distance_matrix[i, j]
            savings_heuristic[i, j] = savings
            savings_heuristic[j, i] = savings
    savings_heuristic = (savings_heuristic - np.min(savings_heuristic)) / (np.max(savings_heuristic) - np.min(savings_heuristic) + 1e-9)


    # 3. Nearest Neighbor Heuristic
    nearest_neighbors = np.zeros((n, n), dtype=float)
    for i in range(n):
        distances = distance_matrix[i].copy()
        distances[i] = np.inf
        num_neighbors = min(max(2, int(np.log(n))), n - 1)  # Logarithmic scaling
        nearest_neighbor_indices = np.argsort(distances)[:num_neighbors]
        for neighbor_index in nearest_neighbor_indices:
            nearest_neighbors[i, neighbor_index] = 1.0

    # 4. Cycle Breaking heuristic. Penalize edges that are likely to form short cycles.
    cycle_breaker = np.zeros((n, n), dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                # Check if adding edge (i, j) would create a cycle of length 3 with node 0
                if distance_matrix[0, i] + distance_matrix[i, j] + distance_matrix[j, 0] < 1.5*(distance_matrix[0, i] + distance_matrix[0, j]):
                     cycle_breaker[i,j] = -0.5 # Penalize this edge
    cycle_breaker = (cycle_breaker - np.min(cycle_breaker)) / (np.max(cycle_breaker) - np.min(cycle_breaker) + 1e-9)

    # Dynamic Weighting (example: adapt based on graph density)
    density = np.sum(distance_matrix < np.mean(distance_matrix)) / (n * n)  # Crude density measure
    weight_inverse_distance = 0.3 if density > 0.5 else 0.4
    weight_savings = 0.3 if density > 0.5 else 0.2
    weight_nearest_neighbors = 0.2
    weight_cycle_breaker = 0.2

    # Combine Heuristics
    heuristic_matrix = (weight_inverse_distance * inverse_distance +
                        weight_savings * savings_heuristic +
                        weight_nearest_neighbors * nearest_neighbors +
                        weight_cycle_breaker * cycle_breaker
                        )

    # Dynamic Sparsification
    k = min(max(3, int(np.sqrt(n))), n - 1)  # Adjust k based on sqrt(n) and problem size
    for i in range(n):
        row = heuristic_matrix[i].copy()
        indices_to_keep = np.argsort(row)[-k:]
        mask = np.zeros(n, dtype=bool)
        mask[indices_to_keep] = True
        heuristic_matrix[i, ~mask] = 0
        heuristic_matrix[i, i] = 0  # Remove self loops

    # Normalize Heuristic Matrix - crucial for stochastic sampling
    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)
    heuristic_matrix = np.nan_to_num(heuristic_matrix / (row_sums + 1e-9))

    return heuristic_matrix
```
