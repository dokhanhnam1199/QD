{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using a combination of factors, adaptive sparsification,\n    edge combination strategies, and cycle prevention, with improved techniques.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix representing the TSP instance.\n\n    Returns:\n        np.ndarray: Prior indicators (probabilities) of edge inclusion.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse Distance Heuristic\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)\n\n    # Nearest Neighbor Heuristic with decay\n    nearest_neighbors = np.zeros((n, n), dtype=float)\n    for i in range(n):\n        distances = distance_matrix[i].copy()\n        distances[i] = np.inf\n        num_neighbors = min(max(2, int(np.log(n))), n - 1)  # Logarithmic scaling\n        nearest_neighbor_indices = np.argsort(distances)[:num_neighbors]\n        for rank, neighbor_index in enumerate(nearest_neighbor_indices):\n            nearest_neighbors[i, neighbor_index] = 1.0 / (rank + 1)  # Decay with rank\n    nearest_neighbors = nearest_neighbors / (np.sum(nearest_neighbors) + 1e-9)\n\n\n    # Savings Heuristic (Clarke-Wright Savings Algorithm idea)\n    savings_matrix = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                savings = distance_matrix[0, i] + distance_matrix[0, j] - distance_matrix[i, j]  # Assuming node 0 is the depot\n                savings_matrix[i, j] = savings\n\n    # Minimum Spanning Tree (MST) heuristic (approximation using distances) - Prim's Algorithm\n    mst_heuristic = np.zeros((n, n), dtype=float)\n    start_node = 0\n    visited = {start_node}\n    possible_edges = []\n    for i in range(n):\n        if i != start_node:\n            possible_edges.append((start_node, i, distance_matrix[start_node, i]))\n\n    mst_edges = []\n    while len(visited) < n:\n        min_edge = None\n        min_dist = np.inf\n        for u, v, dist in possible_edges:\n            if (u in visited and v not in visited) or (v in visited and u not in visited):\n                if dist < min_dist:\n                    min_dist = dist\n                    min_edge = (u, v, dist)\n        if min_edge:\n            u, v, _ = min_edge\n            mst_edges.append((u, v))\n            visited.add(u)\n            visited.add(v)\n            new_possible_edges = []\n            for i in range(n):\n                for j in range(n):\n                    if i != j:\n                        if (i, j, distance_matrix[i, j]) not in possible_edges:\n                            new_possible_edges.append((i, j, distance_matrix[i, j]))\n\n            possible_edges = new_possible_edges\n            for i in range(n):\n                if i not in visited:\n                    for v_node in visited:\n                        possible_edges.append((i, v_node, distance_matrix[i, v_node]))\n            possible_edges = list(set(possible_edges))  # Remove duplicates\n    for u, v in mst_edges:\n        mst_heuristic[u, v] = 1.0\n        mst_heuristic[v, u] = 1.0\n\n\n\n    # Combine Heuristics with dynamic weighting\n    weights = {\n        \"inverse_distance\": 0.4,\n        \"nearest_neighbors\": 0.2,\n        \"savings\": 0.2,\n        \"mst\": 0.2,\n    }\n\n    heuristic_matrix = (weights[\"inverse_distance\"] * inverse_distance +\n                        weights[\"nearest_neighbors\"] * nearest_neighbors +\n                        weights[\"savings\"] * savings_matrix +\n                        weights[\"mst\"] * mst_heuristic)\n\n    # Adaptive Sparsification (adjust based on n, node-specific)\n    for i in range(n):\n        k = min(max(3, int(np.sqrt(n))), n - 1)  # Adjust k based on sqrt(n)\n        row = heuristic_matrix[i].copy()\n        indices_to_keep = np.argsort(row)[-k:]\n        mask = np.zeros(n, dtype=bool)\n        mask[indices_to_keep] = True\n        heuristic_matrix[i, ~mask] = 0\n        heuristic_matrix[i, i] = 0  # Remove self loops\n\n    # Add small noise for exploration\n    noise = np.random.rand(n, n) * 0.01\n    heuristic_matrix = (heuristic_matrix + noise)\n\n    heuristic_matrix = (heuristic_matrix + heuristic_matrix.T) / 2  # ensure Symmetry\n\n    # Cycle Prevention Heuristic (more aggressive)\n    cycle_heuristic = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Penalize edges that are likely to create short cycles\n                cycle_length = 3  # Consider cycles of length 3 (can be adjusted)\n                for k in range(n):\n                    if k != i and k != j:\n                        cycle_penalty = (heuristic_matrix[i, k] * heuristic_matrix[k, j]) # Product of probabilities\n                        cycle_heuristic[i, j] += cycle_penalty\n    cycle_heuristic = cycle_heuristic / (np.max(cycle_heuristic) + 1e-9)  # Normalize\n    heuristic_matrix = heuristic_matrix - 0.2 * cycle_heuristic #reduce cycles (increased penalty)\n\n    heuristic_matrix = np.clip(heuristic_matrix, 0, 1)\n\n    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)\n    heuristic_matrix = np.nan_to_num(heuristic_matrix / (row_sums + 1e-9))\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP based on distance, node degree, and global connectivity,\n    with adaptive sparsification and normalization.\n\n    Args:\n        distance_matrix: A numpy array representing the distance matrix.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix,\n        representing the heuristic values for each edge.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance Heuristic\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)\n    inverse_distance = inverse_distance / np.max(inverse_distance) if np.max(inverse_distance) != 0 else inverse_distance\n\n    # 2. Node Degree Heuristic (Penalize High Degree - Less Aggressively)\n    degree_penalty = np.zeros((n, n), dtype=float)\n    avg_degree = 2\n    for i in range(n):\n        for j in range(n):\n            degree_penalty[i, j] = max(0, 1 - (np.argsort(distance_matrix[i, :]).tolist().index(j) / avg_degree))\n    degree_penalty = degree_penalty / np.max(degree_penalty) if np.max(degree_penalty) != 0 else degree_penalty\n\n    # 3. Global Connectivity Heuristic (MST-like approximation)\n    mst_heuristic = np.zeros((n, n), dtype=float)\n    mst = minimum_spanning_tree(csr_matrix(distance_matrix))\n    for i in range(n):\n        for j in range(n):\n            if mst[i, j] > 0:\n                mst_heuristic[i, j] = 1.0\n    mst_heuristic = mst_heuristic / np.max(mst_heuristic) if np.max(mst_heuristic) != 0 else mst_heuristic\n\n    # 4. Combination with Adaptive Weights\n    alpha, beta, gamma = 0.4, 0.3, 0.3  # Weights for inverse distance, degree penalty, and MST\n    heuristic_matrix = (alpha * inverse_distance +\n                        beta * degree_penalty +\n                        gamma * mst_heuristic)\n\n    # 5. Adaptive Sparsification (Node-Specific k) and Randomness\n    for i in range(n):\n        k = min(max(2, int(np.sqrt(n))), n - 1)\n        row = heuristic_matrix[i].copy()\n        indices_to_keep = np.argsort(row)[-k:]\n        mask = np.zeros(n, dtype=bool)\n        mask[indices_to_keep] = True\n        heuristic_matrix[i, ~mask] = 0  # Sparsify\n        # Add small randomness to the k nearest neighbors\n        randomness = np.random.rand(k) * 0.01  # scaled randomness\n        heuristic_matrix[i, indices_to_keep] += randomness\n        heuristic_matrix[i, indices_to_keep] = np.clip(heuristic_matrix[i, indices_to_keep], 0, 1)\n\n\n    # 6. Normalize Rows\n    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)\n    heuristic_matrix = np.nan_to_num(heuristic_matrix / row_sums)\n\n    heuristic_matrix[np.diag_indices_from(heuristic_matrix)] = 0\n\n    return heuristic_matrix\n\n[Reflection]\nPrioritize core components (distance, degree, connectivity), adaptive sparsification, and row normalization for probabilities.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}