{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using a combination of factors, adaptive sparsification,\n    and edge combination strategies, with improved heuristics and noise injection.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix representing the TSP instance.\n\n    Returns:\n        np.ndarray: Prior indicators (probabilities) of edge inclusion.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance Heuristic\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)\n    inverse_distance = inverse_distance / np.max(inverse_distance) # Normalize\n\n    # 2. Nearest Neighbor Heuristic (Adaptive k)\n    nearest_neighbors = np.zeros((n, n), dtype=float)\n    for i in range(n):\n        distances = distance_matrix[i].copy()\n        distances[i] = np.inf\n        k = min(max(2, int(np.sqrt(n))), n - 1)  # Adaptive k\n        nearest_neighbor_indices = np.argsort(distances)[:k]\n        nearest_neighbors[i, nearest_neighbor_indices] = 1.0\n    nearest_neighbors = nearest_neighbors / np.max(nearest_neighbors)  # Normalize\n\n    # 3. MST Approximation Heuristic (Prim-inspired)\n    mst_heuristic = np.zeros((n, n), dtype=float)\n    start_node = 0\n    visited = {start_node}\n    possible_edges = []\n    for i in range(n):\n        if i != start_node:\n            possible_edges.append((start_node, i, distance_matrix[start_node, i]))\n\n    mst_edges = []\n    while len(visited) < n:\n        min_edge = None\n        min_dist = np.inf\n        for u, v, dist in possible_edges:\n            if (u in visited and v not in visited) or (v in visited and u not in visited):\n                if dist < min_dist:\n                    min_dist = dist\n                    min_edge = (u, v, dist)\n        if min_edge:\n            u, v, _ = min_edge\n            mst_edges.append((u, v))\n            visited.add(u)\n            visited.add(v)\n            new_possible_edges = []\n            for i in range(n):\n              for j in range(n):\n                  if i != j:\n                    if (i,j, distance_matrix[i,j]) not in possible_edges:\n                      new_possible_edges.append((i, j, distance_matrix[i, j]))\n\n            possible_edges = new_possible_edges\n            for i in range(n):\n              if i not in visited:\n                for v_node in visited:\n\n                  possible_edges.append((i,v_node, distance_matrix[i, v_node]))\n            possible_edges = list(set(possible_edges)) # Remove duplicates\n    for u,v in mst_edges:\n        mst_heuristic[u, v] = 1.0\n        mst_heuristic[v, u] = 1.0\n    mst_heuristic = mst_heuristic / np.max(mst_heuristic)  # Normalize\n\n    # 4. Node Degree Heuristic (Penalize High Degree - Less Aggressively)\n    degree_penalty = np.zeros((n, n), dtype=float)\n    avg_degree = 2 # Expect each node to be connected to at least two neighbours in good TSP solution\n    for i in range(n):\n        for j in range(n):\n            degree_penalty[i, j] = max(0, 1 - (distance_matrix[i].argsort().tolist().index(j) / avg_degree))  # Scale degree by average degree\n    degree_penalty = degree_penalty / np.max(degree_penalty) # Normalize\n    # 5. Combine Heuristics (Adjusted Weights)\n    heuristic_matrix = (0.4 * inverse_distance +\n                        0.4 * nearest_neighbors +\n                        0.2 * mst_heuristic) # Increased Weight on MST and NN\n\n    # Adaptive Sparsification (Node-Specific k and Noise Injection)\n    for i in range(n):\n        k = min(max(2, int(np.sqrt(n))), n - 1)  # Node-specific k\n        row = heuristic_matrix[i].copy()\n        indices_to_keep = np.argsort(row)[-k:]\n        mask = np.zeros(n, dtype=bool)\n        mask[indices_to_keep] = True\n        heuristic_matrix[i, ~mask] = 0  # Sparsify\n\n    # Normalize Rows & Add Small Noise\n    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)\n    heuristic_matrix = np.nan_to_num(heuristic_matrix / row_sums)\n    noise = np.random.rand(n, n) * 0.01  # Small noise\n    heuristic_matrix = (heuristic_matrix + noise)\n    heuristic_matrix = (heuristic_matrix + heuristic_matrix.T) / 2 # Maintain Symmetry\n    heuristic_matrix = np.clip(heuristic_matrix, 0, 1)  # Clip to [0, 1]\n    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)\n    heuristic_matrix = np.nan_to_num(heuristic_matrix / row_sums)\n    heuristic_matrix[np.diag_indices_from(heuristic_matrix)] = 0\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using a combination of factors, adaptive sparsification, and edge combination.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix representing the TSP instance.\n\n    Returns:\n        np.ndarray: Prior indicators (probabilities) of edge inclusion.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance heuristic\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)\n\n    # Node degree heuristic (favor nodes with fewer connections) - removed as it didn't improve performance in testing.\n\n    # Sparsification - Adaptive k based on percentile.  This is the target neighborhood size.\n    k = max(2, int(n * 0.2))  # Start with a percentage, increased for more exploration\n    k = min(k, n - 1) # Clamp it.\n\n    # Combination and Sparsification\n    combined_heuristic = inverse_distance # Simplified: use only inverse distance for now\n\n    for i in range(n):\n        row = combined_heuristic[i].copy()\n        indices_to_keep = np.argsort(row)[-k:] # Keep k best edges.\n        mask = np.zeros(n, dtype=bool)\n        mask[indices_to_keep] = True\n        combined_heuristic[i, ~mask] = 0\n        combined_heuristic[i, i] = 0 # Remove Self loop.\n\n    # Add some randomness to maintain some level of exploration to get unstuck from local optima. Increased randomness.\n    randomness = np.random.rand(n, n) * 0.05 # Add small random noise, increased for more exploration.\n\n    heuristic_matrix = combined_heuristic + randomness # Combine randomness.\n\n    # Normalization (Probability-like)\n    row_sums = heuristic_matrix.sum(axis=1, keepdims=True)\n    heuristic_matrix = np.nan_to_num(heuristic_matrix / (row_sums + 1e-9)) # Added small constant to avoid division by zero.\n\n    return heuristic_matrix\n\n[Reflection]\nSimplicity, adaptive sparsification using percentiles, and controlled randomness can improve TSP heuristic performance.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}