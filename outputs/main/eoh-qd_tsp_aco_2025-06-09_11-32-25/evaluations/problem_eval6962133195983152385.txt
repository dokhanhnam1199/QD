import numpy as np

def heuristics_v2(distance_matrix):
  """{This algorithm iteratively refines edge probabilities by sampling tours based on current probabilities, updating probabilities to favor edges in shorter tours, and repeating until convergence.}"""
  n = distance_matrix.shape[0]
  num_iterations = 10
  num_samples = 100
  alpha = 0.1 

  # Initialize edge probabilities uniformly
  heuristics_matrix = np.ones_like(distance_matrix, dtype=float) / n

  for _ in range(num_iterations):
    # Sample tours based on current edge probabilities
    tours = []
    tour_lengths = []
    for _ in range(num_samples):
      tour = [np.random.randint(n)]  # Start with a random city
      unvisited = set(range(n))
      unvisited.remove(tour[0])

      while unvisited:
        current_city = tour[-1]
        probabilities = heuristics_matrix[current_city, list(unvisited)]
        probabilities /= np.sum(probabilities)
        next_city = np.random.choice(list(unvisited), p=probabilities)
        tour.append(next_city)
        unvisited.remove(next_city)

      tour = np.array(tour)
      tours.append(tour)

      # Calculate tour length
      tour_length = 0
      for i in range(n - 1):
        tour_length += distance_matrix[tour[i], tour[i+1]]
      tour_length += distance_matrix[tour[n-1], tour[0]]
      tour_lengths.append(tour_length)
    
    # Update edge probabilities based on tour lengths
    min_tour_length = min(tour_lengths)
    for tour, tour_length in zip(tours, tour_lengths):
        reward = np.exp(-alpha * (tour_length - min_tour_length))  # Exponential reward for shorter tours

        for i in range(n - 1):
            u = tour[i]
            v = tour[i+1]
            heuristics_matrix[u, v] += reward
            heuristics_matrix[v, u] += reward
        u = tour[n-1]
        v = tour[0]
        heuristics_matrix[u, v] += reward
        heuristics_matrix[v, u] += reward

    # Normalize the heuristics matrix
    heuristics_matrix /= np.sum(heuristics_matrix)

  return heuristics_matrix
