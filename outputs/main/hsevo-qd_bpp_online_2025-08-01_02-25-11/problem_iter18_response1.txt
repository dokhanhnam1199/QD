```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns a priority score for each bin, incorporating advanced heuristics
    for online Bin Packing.

    This heuristic combines "Best Fit" with an aggressively incentivized
    "Bin Completion" strategy, a sophisticated "Fragmentation Avoidance"
    (targeting a "Valley of Despair"), and a "Quality of Large Space" bonus.
    It adapts non-linearly to the current item's size to optimize space utilization.

    The priority calculation is composed of:
    1.  **Core Best Fit Principle:** Bins with smaller remaining capacity after
        placement get a base higher priority.
    2.  **Exact Fit / Bin Completion Bonus (Aggressive Non-linear):**
        Applies a very high and sharply decaying exponential bonus for bins
        where the item fits perfectly or near-perfectly (remaining capacity
        is very close to zero). This strongly encourages closing bins efficiently.
    3.  **Fragmentation Penalty ("Valley of Despair" - Non-linear & Adaptive):**
        Introduces a significant penalty for bins that, after placing the item,
        would be left with a non-zero, "awkward" amount of remaining capacity.
        This penalty is shaped like an inverted Gaussian curve, being harshest
        for mid-range remainders (e.g., 30-50% of the item's size) and tapering
        off for very small (near zero) or larger remainders. This discourages
        creating fragmented spaces that are neither useful for larger items
        nor small enough to be easily ignored or filled by tiny items.
    4.  **Quality of Large Remaining Space Bonus (Logarithmic & Adaptive):**
        Provides a moderate, logarithmically increasing bonus for bins that are
        left with a substantial amount of free capacity (e.g., more than double
        the current item's size). This incentivizes keeping bins with genuinely
        useful large spaces available for future large items, promoting overall
        bin utility rather than just minimal remaining space.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        Bins where the item cannot fit will have a priority of -np.inf.
    """
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Tolerance for floating point comparisons to avoid issues with near-zero values
    TOLERANCE_EPS = 1e-9

    # Mask for bins where the item can fit (capacity >= item size, with a small tolerance)
    can_fit_mask = bins_remain_cap >= item - TOLERANCE_EPS

    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]

    # If no bin can fit the item, return priorities initialized to -inf
    if fitting_bins_remain_cap.size == 0:
        return priorities

    # Calculate potential remaining capacity if the item were placed
    potential_remaining_cap = fitting_bins_remain_cap - item
    # Ensure no negative remainders due to floating point inaccuracies when item == capacity
    potential_remaining_cap[potential_remaining_cap < 0] = 0.0

    # --- Core Priority Calculation (Enhanced Best Fit / Space Quality) ---
    # Base: The Best Fit principle inherently prefers smaller remaining capacities.
    # We use a negative linear relationship initially.
    calculated_priorities = -potential_remaining_cap

    # --- Non-linear & Adaptive Components ---

    # 1. Exact Fit / Bin Completion Bonus:
    # A very strong, rapidly decaying exponential bonus for near-perfect fits.
    # This ensures that bins resulting in almost zero remaining capacity are highly prioritized.
    EXACT_FIT_BONUS_MAGNITUDE = 5000.0  # High magnitude to make exact fits dominant
    EXACT_FIT_DECAY_RATE = 50.0         # High decay rate for a very sharp peak at 0
    
    exact_fit_bonus = EXACT_FIT_BONUS_MAGNITUDE * np.exp(-EXACT_FIT_DECAY_RATE * potential_remaining_cap)
    calculated_priorities += exact_fit_bonus

    # 2. Fragmentation Penalty ("Valley of Despair"):
    # Penalizes bins that would be left with an "awkward" non-zero remaining capacity.
    # This penalty uses a negative Gaussian (bell curve) shape, peaking for remainders
    # that are a problematic fraction of the item's size (e.g., 30-50%).
    
    if item > TOLERANCE_EPS: # Only apply if item size is meaningful for relative calculations
        # Define the range of remaining capacities to consider for fragmentation penalties.
        # This covers non-zero remainders up to 1.5 times the item's size.
        fragment_consideration_mask = (potential_remaining_cap > TOLERANCE_EPS) & \
                                      (potential_remaining_cap <= 1.5 * item)

        if np.any(fragment_consideration_mask):
            # Normalize the remaining capacity by the item's size for adaptive scaling.
            normalized_fragment_rem = potential_remaining_cap[fragment_consideration_mask] / item

            # Parameters for the Gaussian penalty curve. These are tunable.
            FRAGMENT_PENALTY_PEAK_RATIO = 0.4 # Peak penalty when remaining capacity is 40% of item size
            FRAGMENT_PENALTY_STD_DEV = 0.2    # Standard deviation: controls the width of the penalty zone
            PENALTY_MAGNITUDE = 100.0         # Maximum strength of the fragmentation penalty

            # Calculate the Gaussian penalty. It's negative, so it subtracts from priority.
            # `exp(-(x-mu)^2 / (2*sigma^2))`
            penalty = -PENALTY_MAGNITUDE * np.exp(
                -((normalized_fragment_rem - FRAGMENT_PENALTY_PEAK_RATIO)**2) / (2 * FRAGMENT_PENALTY_STD_DEV**2)
            )
            calculated_priorities[fragment_consideration_mask] += penalty

    # 3. Quality of Large Remaining Space Bonus:
    # Provides a bonus for bins that maintain a substantial amount of useful free capacity
    # after the item is placed (e.g., more than double the current item's size).
    # This encourages keeping bins with significant "potential" for future large items.
    
    if item > TOLERANCE_EPS:
        # Define "large enough" remaining capacity relative to the item size.
        LARGE_REM_THRESHOLD_MULTIPLE = 2.0
        
        large_rem_mask = potential_remaining_cap > (LARGE_REM_THRESHOLD_MULTIPLE * item)

        if np.any(large_rem_mask):
            # The bonus increases logarithmically with the ratio of remaining capacity
            # to the threshold. Logarithmic growth provides diminishing returns for
            # extremely large remaining spaces, preventing them from dominating excessively.
            LARGE_REM_BONUS_FACTOR = 20.0 # Moderate bonus strength

            # Scale the argument for log1p to ensure positive values and manage sensitivity.
            # Cap the argument to avoid excessively large bonus if item is tiny and remaining is huge.
            scaled_log_arg = potential_remaining_cap[large_rem_mask] / (item * LARGE_REM_THRESHOLD_MULTIPLE)
            log_bonus_amount = LARGE_REM_BONUS_FACTOR * np.log1p(np.minimum(scaled_log_arg, 100.0)) # Cap scaled_arg at 100

            calculated_priorities[large_rem_mask] += log_bonus_amount

    # Assign the calculated priorities back to the original array for fitting bins
    priorities[can_fit_mask] = calculated_priorities

    return priorities
```
