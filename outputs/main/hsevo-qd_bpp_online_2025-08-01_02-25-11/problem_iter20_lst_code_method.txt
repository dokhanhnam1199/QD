{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns a priority score for each bin, incorporating advanced heuristics\n    for online Bin Packing.\n\n    This heuristic combines \"Best Fit\" with an aggressively incentivized\n    \"Bin Completion\" strategy, a sophisticated \"Fragmentation Avoidance\"\n    (targeting a \"Valley of Despair\"), and a \"Quality of Large Space\" bonus.\n    It adapts non-linearly to the current item's size to optimize space utilization.\n\n    The priority calculation is composed of:\n    1.  **Core Best Fit Principle:** Bins with smaller remaining capacity after\n        placement get a base higher priority.\n    2.  **Exact Fit / Bin Completion Bonus (Aggressive Non-linear):**\n        Applies a very high and sharply decaying exponential bonus for bins\n        where the item fits perfectly or near-perfectly (remaining capacity\n        is very close to zero). This strongly encourages closing bins efficiently.\n    3.  **Fragmentation Penalty (\"Valley of Despair\" - Non-linear & Adaptive):**\n        Introduces a significant penalty for bins that, after placing the item,\n        would be left with a non-zero, \"awkward\" amount of remaining capacity.\n        This penalty is shaped like an inverted Gaussian curve, being harshest\n        for mid-range remainders (e.g., 30-50% of the item's size) and tapering\n        off for very small (near zero) or larger remainders. This discourages\n        creating fragmented spaces that are neither useful for larger items\n        nor small enough to be easily ignored or filled by tiny items.\n    4.  **Quality of Large Remaining Space Bonus (Logarithmic & Adaptive):**\n        Provides a moderate, logarithmically increasing bonus for bins that are\n        left with a substantial amount of free capacity (e.g., more than double\n        the current item's size). This incentivizes keeping bins with genuinely\n        useful large spaces available for future large items, promoting overall\n        bin utility rather than just minimal remaining space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins where the item cannot fit will have a priority of -np.inf.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Tolerance for floating point comparisons to avoid issues with near-zero values\n    TOLERANCE_EPS = 1e-9\n\n    # Mask for bins where the item can fit (capacity >= item size, with a small tolerance)\n    can_fit_mask = bins_remain_cap >= item - TOLERANCE_EPS\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n    # Ensure no negative remainders due to floating point inaccuracies when item == capacity\n    potential_remaining_cap[potential_remaining_cap < 0] = 0.0\n\n    # --- Core Priority Calculation (Enhanced Best Fit / Space Quality) ---\n    # Base: The Best Fit principle inherently prefers smaller remaining capacities.\n    # We use a negative linear relationship initially.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Non-linear & Adaptive Components ---\n\n    # 1. Exact Fit / Bin Completion Bonus:\n    # A very strong, rapidly decaying exponential bonus for near-perfect fits.\n    # This ensures that bins resulting in almost zero remaining capacity are highly prioritized.\n    EXACT_FIT_BONUS_MAGNITUDE = 5000.0  # High magnitude to make exact fits dominant\n    EXACT_FIT_DECAY_RATE = 50.0         # High decay rate for a very sharp peak at 0\n    \n    exact_fit_bonus = EXACT_FIT_BONUS_MAGNITUDE * np.exp(-EXACT_FIT_DECAY_RATE * potential_remaining_cap)\n    calculated_priorities += exact_fit_bonus\n\n    # 2. Fragmentation Penalty (\"Valley of Despair\"):\n    # Penalizes bins that would be left with an \"awkward\" non-zero remaining capacity.\n    # This penalty uses a negative Gaussian (bell curve) shape, peaking for remainders\n    # that are a problematic fraction of the item's size (e.g., 30-50%).\n    \n    if item > TOLERANCE_EPS: # Only apply if item size is meaningful for relative calculations\n        # Define the range of remaining capacities to consider for fragmentation penalties.\n        # This covers non-zero remainders up to 1.5 times the item's size.\n        fragment_consideration_mask = (potential_remaining_cap > TOLERANCE_EPS) & \\\n                                      (potential_remaining_cap <= 1.5 * item)\n\n        if np.any(fragment_consideration_mask):\n            # Normalize the remaining capacity by the item's size for adaptive scaling.\n            normalized_fragment_rem = potential_remaining_cap[fragment_consideration_mask] / item\n\n            # Parameters for the Gaussian penalty curve. These are tunable.\n            FRAGMENT_PENALTY_PEAK_RATIO = 0.4 # Peak penalty when remaining capacity is 40% of item size\n            FRAGMENT_PENALTY_STD_DEV = 0.2    # Standard deviation: controls the width of the penalty zone\n            PENALTY_MAGNITUDE = 100.0         # Maximum strength of the fragmentation penalty\n\n            # Calculate the Gaussian penalty. It's negative, so it subtracts from priority.\n            # `exp(-(x-mu)^2 / (2*sigma^2))`\n            penalty = -PENALTY_MAGNITUDE * np.exp(\n                -((normalized_fragment_rem - FRAGMENT_PENALTY_PEAK_RATIO)**2) / (2 * FRAGMENT_PENALTY_STD_DEV**2)\n            )\n            calculated_priorities[fragment_consideration_mask] += penalty\n\n    # 3. Quality of Large Remaining Space Bonus:\n    # Provides a bonus for bins that maintain a substantial amount of useful free capacity\n    # after the item is placed (e.g., more than double the current item's size).\n    # This encourages keeping bins with significant \"potential\" for future large items.\n    \n    if item > TOLERANCE_EPS:\n        # Define \"large enough\" remaining capacity relative to the item size.\n        LARGE_REM_THRESHOLD_MULTIPLE = 2.0\n        \n        large_rem_mask = potential_remaining_cap > (LARGE_REM_THRESHOLD_MULTIPLE * item)\n\n        if np.any(large_rem_mask):\n            # The bonus increases logarithmically with the ratio of remaining capacity\n            # to the threshold. Logarithmic growth provides diminishing returns for\n            # extremely large remaining spaces, preventing them from dominating excessively.\n            LARGE_REM_BONUS_FACTOR = 20.0 # Moderate bonus strength\n\n            # Scale the argument for log1p to ensure positive values and manage sensitivity.\n            # Cap the argument to avoid excessively large bonus if item is tiny and remaining is huge.\n            scaled_log_arg = potential_remaining_cap[large_rem_mask] / (item * LARGE_REM_THRESHOLD_MULTIPLE)\n            log_bonus_amount = LARGE_REM_BONUS_FACTOR * np.log1p(np.minimum(scaled_log_arg, 100.0)) # Cap scaled_arg at 100\n\n            calculated_priorities[large_rem_mask] += log_bonus_amount\n\n    # Assign the calculated priorities back to the original array for fitting bins\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns a priority score for each bin, incorporating advanced heuristics\n    for online Bin Packing.\n\n    This heuristic combines \"Best Fit\" with an aggressively incentivized\n    \"Bin Completion\" strategy, a sophisticated \"Fragmentation Avoidance\"\n    (targeting a \"Valley of Despair\"), and a \"Quality of Large Space\" bonus.\n    It adapts non-linearly to the current item's size to optimize space utilization.\n\n    The priority calculation is composed of:\n    1.  **Core Best Fit Principle:** Bins with smaller remaining capacity after\n        placement get a base higher priority.\n    2.  **Exact Fit / Bin Completion Bonus (Aggressive Non-linear):**\n        Applies a very high and sharply decaying exponential bonus for bins\n        where the item fits perfectly or near-perfectly (remaining capacity\n        is very close to zero). This strongly encourages closing bins efficiently.\n    3.  **Fragmentation Penalty (\"Valley of Despair\" - Non-linear & Adaptive):**\n        Introduces a significant penalty for bins that, after placing the item,\n        would be left with a non-zero, \"awkward\" amount of remaining capacity.\n        This penalty is shaped like an inverted Gaussian curve, being harshest\n        for mid-range remainders (e.g., 30-50% of the item's size) and tapering\n        off for very small (near zero) or larger remainders. This discourages\n        creating fragmented spaces that are neither useful for larger items\n        nor small enough to be easily ignored or filled by tiny items.\n    4.  **Quality of Large Remaining Space Bonus (Logarithmic & Adaptive):**\n        Provides a moderate, logarithmically increasing bonus for bins that are\n        left with a substantial amount of free capacity (e.g., more than double\n        the current item's size). This incentivizes keeping bins with genuinely\n        useful large spaces available for future large items, promoting overall\n        bin utility rather than just minimal remaining space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins where the item cannot fit will have a priority of -np.inf.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Tolerance for floating point comparisons to avoid issues with near-zero values\n    TOLERANCE_EPS = 1e-9\n\n    # Mask for bins where the item can fit (capacity >= item size, with a small tolerance)\n    can_fit_mask = bins_remain_cap >= item - TOLERANCE_EPS\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n    # Ensure no negative remainders due to floating point inaccuracies when item == capacity\n    potential_remaining_cap[potential_remaining_cap < 0] = 0.0\n\n    # --- Core Priority Calculation (Enhanced Best Fit / Space Quality) ---\n    # Base: The Best Fit principle inherently prefers smaller remaining capacities.\n    # We use a negative linear relationship initially.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Non-linear & Adaptive Components ---\n\n    # 1. Exact Fit / Bin Completion Bonus:\n    # A very strong, rapidly decaying exponential bonus for near-perfect fits.\n    # This ensures that bins resulting in almost zero remaining capacity are highly prioritized.\n    EXACT_FIT_BONUS_MAGNITUDE = 5000.0  # High magnitude to make exact fits dominant\n    EXACT_FIT_DECAY_RATE = 50.0         # High decay rate for a very sharp peak at 0\n    \n    exact_fit_bonus = EXACT_FIT_BONUS_MAGNITUDE * np.exp(-EXACT_FIT_DECAY_RATE * potential_remaining_cap)\n    calculated_priorities += exact_fit_bonus\n\n    # 2. Fragmentation Penalty (\"Valley of Despair\"):\n    # Penalizes bins that would be left with an \"awkward\" non-zero remaining capacity.\n    # This penalty uses a negative Gaussian (bell curve) shape, peaking for remainders\n    # that are a problematic fraction of the item's size (e.g., 30-50%).\n    \n    if item > TOLERANCE_EPS: # Only apply if item size is meaningful for relative calculations\n        # Define the range of remaining capacities to consider for fragmentation penalties.\n        # This covers non-zero remainders up to 1.5 times the item's size.\n        fragment_consideration_mask = (potential_remaining_cap > TOLERANCE_EPS) & \\\n                                      (potential_remaining_cap <= 1.5 * item)\n\n        if np.any(fragment_consideration_mask):\n            # Normalize the remaining capacity by the item's size for adaptive scaling.\n            normalized_fragment_rem = potential_remaining_cap[fragment_consideration_mask] / item\n\n            # Parameters for the Gaussian penalty curve. These are tunable.\n            FRAGMENT_PENALTY_PEAK_RATIO = 0.4 # Peak penalty when remaining capacity is 40% of item size\n            FRAGMENT_PENALTY_STD_DEV = 0.2    # Standard deviation: controls the width of the penalty zone\n            PENALTY_MAGNITUDE = 100.0         # Maximum strength of the fragmentation penalty\n\n            # Calculate the Gaussian penalty. It's negative, so it subtracts from priority.\n            # `exp(-(x-mu)^2 / (2*sigma^2))`\n            penalty = -PENALTY_MAGNITUDE * np.exp(\n                -((normalized_fragment_rem - FRAGMENT_PENALTY_PEAK_RATIO)**2) / (2 * FRAGMENT_PENALTY_STD_DEV**2)\n            )\n            calculated_priorities[fragment_consideration_mask] += penalty\n\n    # 3. Quality of Large Remaining Space Bonus:\n    # Provides a bonus for bins that maintain a substantial amount of useful free capacity\n    # after the item is placed (e.g., more than double the current item's size).\n    # This encourages keeping bins with significant \"potential\" for future large items.\n    \n    if item > TOLERANCE_EPS:\n        # Define \"large enough\" remaining capacity relative to the item size.\n        LARGE_REM_THRESHOLD_MULTIPLE = 2.0\n        \n        large_rem_mask = potential_remaining_cap > (LARGE_REM_THRESHOLD_MULTIPLE * item)\n\n        if np.any(large_rem_mask):\n            # The bonus increases logarithmically with the ratio of remaining capacity\n            # to the threshold. Logarithmic growth provides diminishing returns for\n            # extremely large remaining spaces, preventing them from dominating excessively.\n            LARGE_REM_BONUS_FACTOR = 20.0 # Moderate bonus strength\n\n            # Scale the argument for log1p to ensure positive values and manage sensitivity.\n            # Cap the argument to avoid excessively large bonus if item is tiny and remaining is huge.\n            scaled_log_arg = potential_remaining_cap[large_rem_mask] / (item * LARGE_REM_THRESHOLD_MULTIPLE)\n            log_bonus_amount = LARGE_REM_BONUS_FACTOR * np.log1p(np.minimum(scaled_log_arg, 100.0)) # Cap scaled_arg at 100\n\n            calculated_priorities[large_rem_mask] += log_bonus_amount\n\n    # Assign the calculated priorities back to the original array for fitting bins\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns a priority score for each bin, incorporating advanced heuristics\n    for online Bin Packing.\n\n    This heuristic combines \"Best Fit\" with an aggressively incentivized\n    \"Bin Completion\" strategy, a sophisticated \"Fragmentation Avoidance\"\n    (targeting a \"Valley of Despair\"), and a \"Quality of Large Space\" bonus.\n    It adapts non-linearly to the current item's size to optimize space utilization.\n\n    The priority calculation is composed of:\n    1.  **Core Best Fit Principle:** Bins with smaller remaining capacity after\n        placement get a base higher priority.\n    2.  **Exact Fit / Bin Completion Bonus (Aggressive Non-linear):**\n        Applies a very high and sharply decaying exponential bonus for bins\n        where the item fits perfectly or near-perfectly (remaining capacity\n        is very close to zero). This strongly encourages closing bins efficiently.\n    3.  **Fragmentation Penalty (\"Valley of Despair\" - Non-linear & Adaptive):**\n        Introduces a significant penalty for bins that, after placing the item,\n        would be left with a non-zero, \"awkward\" amount of remaining capacity.\n        This penalty is shaped like an inverted Gaussian curve, being harshest\n        for mid-range remainders (e.g., 30-50% of the item's size) and tapering\n        off for very small (near zero) or larger remainders. This discourages\n        creating fragmented spaces that are neither useful for larger items\n        nor small enough to be easily ignored or filled by tiny items.\n    4.  **Quality of Large Remaining Space Bonus (Logarithmic & Adaptive):**\n        Provides a moderate, logarithmically increasing bonus for bins that are\n        left with a substantial amount of free capacity (e.g., more than double\n        the current item's size). This incentivizes keeping bins with genuinely\n        useful large spaces available for future large items, promoting overall\n        bin utility rather than just minimal remaining space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins where the item cannot fit will have a priority of -np.inf.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Tolerance for floating point comparisons to avoid issues with near-zero values\n    TOLERANCE_EPS = 1e-9\n\n    # Mask for bins where the item can fit (capacity >= item size, with a small tolerance)\n    can_fit_mask = bins_remain_cap >= item - TOLERANCE_EPS\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n    # Ensure no negative remainders due to floating point inaccuracies when item == capacity\n    potential_remaining_cap[potential_remaining_cap < 0] = 0.0\n\n    # --- Core Priority Calculation (Enhanced Best Fit / Space Quality) ---\n    # Base: The Best Fit principle inherently prefers smaller remaining capacities.\n    # We use a negative linear relationship initially.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Non-linear & Adaptive Components ---\n\n    # 1. Exact Fit / Bin Completion Bonus:\n    # A very strong, rapidly decaying exponential bonus for near-perfect fits.\n    # This ensures that bins resulting in almost zero remaining capacity are highly prioritized.\n    EXACT_FIT_BONUS_MAGNITUDE = 5000.0  # High magnitude to make exact fits dominant\n    EXACT_FIT_DECAY_RATE = 50.0         # High decay rate for a very sharp peak at 0\n    \n    exact_fit_bonus = EXACT_FIT_BONUS_MAGNITUDE * np.exp(-EXACT_FIT_DECAY_RATE * potential_remaining_cap)\n    calculated_priorities += exact_fit_bonus\n\n    # 2. Fragmentation Penalty (\"Valley of Despair\"):\n    # Penalizes bins that would be left with an \"awkward\" non-zero remaining capacity.\n    # This penalty uses a negative Gaussian (bell curve) shape, peaking for remainders\n    # that are a problematic fraction of the item's size (e.g., 30-50%).\n    \n    if item > TOLERANCE_EPS: # Only apply if item size is meaningful for relative calculations\n        # Define the range of remaining capacities to consider for fragmentation penalties.\n        # This covers non-zero remainders up to 1.5 times the item's size.\n        fragment_consideration_mask = (potential_remaining_cap > TOLERANCE_EPS) & \\\n                                      (potential_remaining_cap <= 1.5 * item)\n\n        if np.any(fragment_consideration_mask):\n            # Normalize the remaining capacity by the item's size for adaptive scaling.\n            normalized_fragment_rem = potential_remaining_cap[fragment_consideration_mask] / item\n\n            # Parameters for the Gaussian penalty curve. These are tunable.\n            FRAGMENT_PENALTY_PEAK_RATIO = 0.4 # Peak penalty when remaining capacity is 40% of item size\n            FRAGMENT_PENALTY_STD_DEV = 0.2    # Standard deviation: controls the width of the penalty zone\n            PENALTY_MAGNITUDE = 100.0         # Maximum strength of the fragmentation penalty\n\n            # Calculate the Gaussian penalty. It's negative, so it subtracts from priority.\n            # `exp(-(x-mu)^2 / (2*sigma^2))`\n            penalty = -PENALTY_MAGNITUDE * np.exp(\n                -((normalized_fragment_rem - FRAGMENT_PENALTY_PEAK_RATIO)**2) / (2 * FRAGMENT_PENALTY_STD_DEV**2)\n            )\n            calculated_priorities[fragment_consideration_mask] += penalty\n\n    # 3. Quality of Large Remaining Space Bonus:\n    # Provides a bonus for bins that maintain a substantial amount of useful free capacity\n    # after the item is placed (e.g., more than double the current item's size).\n    # This encourages keeping bins with significant \"potential\" for future large items.\n    \n    if item > TOLERANCE_EPS:\n        # Define \"large enough\" remaining capacity relative to the item size.\n        LARGE_REM_THRESHOLD_MULTIPLE = 2.0\n        \n        large_rem_mask = potential_remaining_cap > (LARGE_REM_THRESHOLD_MULTIPLE * item)\n\n        if np.any(large_rem_mask):\n            # The bonus increases logarithmically with the ratio of remaining capacity\n            # to the threshold. Logarithmic growth provides diminishing returns for\n            # extremely large remaining spaces, preventing them from dominating excessively.\n            LARGE_REM_BONUS_FACTOR = 20.0 # Moderate bonus strength\n\n            # Scale the argument for log1p to ensure positive values and manage sensitivity.\n            # Cap the argument to avoid excessively large bonus if item is tiny and remaining is huge.\n            scaled_log_arg = potential_remaining_cap[large_rem_mask] / (item * LARGE_REM_THRESHOLD_MULTIPLE)\n            log_bonus_amount = LARGE_REM_BONUS_FACTOR * np.log1p(np.minimum(scaled_log_arg, 100.0)) # Cap scaled_arg at 100\n\n            calculated_priorities[large_rem_mask] += log_bonus_amount\n\n    # Assign the calculated priorities back to the original array for fitting bins\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic combines \"Best Fit\" with a \"Bin Consolidation\" and\n    \"Fragmentation Avoidance\" strategy. It aims to achieve global efficacy\n    through local, non-linear interactions, adapting to the current item's size.\n\n    The priority calculation is composed of:\n    1.  **Best Fit Core:** Prioritizes bins that result in the smallest\n        remaining capacity after the item is placed. This is the foundational\n        linear component.\n    2.  **Exact Fit Bonus (Non-linear):** Provides a significant, discrete\n        bonus for bins where the item fits perfectly, leading to zero\n        remaining capacity. This encourages complete bin utilization and closure.\n    3.  **Fragmentation Penalty (Non-linear & Adaptive):** Applies a penalty\n        to bins that, after placing the item, would be left with a small,\n        non-zero remaining capacity. This penalty is particularly harsh if the\n        remaining capacity is less than or equal to the current `item`'s size,\n        discouraging the creation of fragmented space that might be difficult\n        to fill with future items of similar scale. The penalty scales with\n        how close the remainder is to the `item`'s size, pushing towards\n        either very small remainders or sufficiently large (useful) ones.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit (capacity >= item size)\n    can_fit_mask = bins_remain_cap >= item\n\n    # Extract capacities for only the fitting bins\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # --- Core Priority Calculation (Best Fit component) ---\n    # We negate the potential remaining capacity so that a smaller remainder\n    # results in a higher (less negative) priority score.\n    # Example: remaining 0.1 -> score -0.1; remaining 0.5 -> score -0.5.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Hybrid/Non-linear/Adaptive Components ---\n\n    # 1. Exact Fit Bonus: A strong, discrete non-linear bonus for perfect fits.\n    # This highly prioritizes bins that can be perfectly filled.\n    EXACT_FIT_THRESHOLD = 1e-9  # Tolerance for floating point comparisons to zero\n    EXACT_FIT_BONUS = 1000.0    # A large bonus to ensure exact fits are top priority\n\n    exact_fit_mask = np.isclose(potential_remaining_cap, 0.0, atol=EXACT_FIT_THRESHOLD)\n    calculated_priorities[exact_fit_mask] += EXACT_FIT_BONUS\n\n    # 2. Fragmentation Penalty: Penalize creating small, non-zero remnants.\n    # This aims to avoid \"awkward\" remaining capacities that are too small\n    # to be easily useful for typical future items, especially if they are\n    # a significant fraction of the current item's size.\n    \n    # Apply penalty only if the item size is positive to avoid division by zero.\n    # Item sizes in BPP are typically positive.\n    if item > EXACT_FIT_THRESHOLD:\n        # Define the \"fragmentation zone\": remaining capacities that are\n        # non-zero but less than or equal to the current item's size.\n        # This range is problematic as it's not an exact fit, but also not\n        # large enough to easily accommodate another item of the same size.\n        fragment_zone_mask = (potential_remaining_cap > EXACT_FIT_THRESHOLD) & \\\n                             (potential_remaining_cap <= item)\n\n        if np.any(fragment_zone_mask):\n            # Normalize the remaining capacity within this zone by the item's size.\n            # This makes the penalty adaptive to the scale of the current item.\n            normalized_fragment_rem = potential_remaining_cap[fragment_zone_mask] / item\n\n            # Apply a penalty that increases as the normalized remainder\n            # approaches 1 (i.e., remaining capacity is close to item's size).\n            # This strongly discourages leaving a bin with a capacity just\n            # slightly less than the item, effectively making it a \"dead space\".\n            # PENALTY_FACTOR is a tunable parameter controlling the penalty's strength.\n            PENALTY_FACTOR = 5.0 # Example: A factor of 5.0\n\n            penalty = -PENALTY_FACTOR * normalized_fragment_rem\n            calculated_priorities[fragment_zone_mask] += penalty\n\n    # Assign the calculated priorities to the fitting bins in the main array\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic combines \"Best Fit\" with a \"Bin Consolidation\" and\n    \"Fragmentation Avoidance\" strategy. It aims to achieve global efficacy\n    through local, non-linear interactions, adapting to the current item's size.\n\n    The priority calculation is composed of:\n    1.  **Best Fit Core:** Prioritizes bins that result in the smallest\n        remaining capacity after the item is placed. This is the foundational\n        linear component.\n    2.  **Exact Fit Bonus (Non-linear):** Provides a significant, discrete\n        bonus for bins where the item fits perfectly, leading to zero\n        remaining capacity. This encourages complete bin utilization and closure.\n    3.  **Fragmentation Penalty (Non-linear & Adaptive):** Applies a penalty\n        to bins that, after placing the item, would be left with a small,\n        non-zero remaining capacity. This penalty is particularly harsh if the\n        remaining capacity is less than or equal to the current `item`'s size,\n        discouraging the creation of fragmented space that might be difficult\n        to fill with future items of similar scale. The penalty scales with\n        how close the remainder is to the `item`'s size, pushing towards\n        either very small remainders or sufficiently large (useful) ones.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit (capacity >= item size)\n    can_fit_mask = bins_remain_cap >= item\n\n    # Extract capacities for only the fitting bins\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # --- Core Priority Calculation (Best Fit component) ---\n    # We negate the potential remaining capacity so that a smaller remainder\n    # results in a higher (less negative) priority score.\n    # Example: remaining 0.1 -> score -0.1; remaining 0.5 -> score -0.5.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Hybrid/Non-linear/Adaptive Components ---\n\n    # 1. Exact Fit Bonus: A strong, discrete non-linear bonus for perfect fits.\n    # This highly prioritizes bins that can be perfectly filled.\n    EXACT_FIT_THRESHOLD = 1e-9  # Tolerance for floating point comparisons to zero\n    EXACT_FIT_BONUS = 1000.0    # A large bonus to ensure exact fits are top priority\n\n    exact_fit_mask = np.isclose(potential_remaining_cap, 0.0, atol=EXACT_FIT_THRESHOLD)\n    calculated_priorities[exact_fit_mask] += EXACT_FIT_BONUS\n\n    # 2. Fragmentation Penalty: Penalize creating small, non-zero remnants.\n    # This aims to avoid \"awkward\" remaining capacities that are too small\n    # to be easily useful for typical future items, especially if they are\n    # a significant fraction of the current item's size.\n    \n    # Apply penalty only if the item size is positive to avoid division by zero.\n    # Item sizes in BPP are typically positive.\n    if item > EXACT_FIT_THRESHOLD:\n        # Define the \"fragmentation zone\": remaining capacities that are\n        # non-zero but less than or equal to the current item's size.\n        # This range is problematic as it's not an exact fit, but also not\n        # large enough to easily accommodate another item of the same size.\n        fragment_zone_mask = (potential_remaining_cap > EXACT_FIT_THRESHOLD) & \\\n                             (potential_remaining_cap <= item)\n\n        if np.any(fragment_zone_mask):\n            # Normalize the remaining capacity within this zone by the item's size.\n            # This makes the penalty adaptive to the scale of the current item.\n            normalized_fragment_rem = potential_remaining_cap[fragment_zone_mask] / item\n\n            # Apply a penalty that increases as the normalized remainder\n            # approaches 1 (i.e., remaining capacity is close to item's size).\n            # This strongly discourages leaving a bin with a capacity just\n            # slightly less than the item, effectively making it a \"dead space\".\n            # PENALTY_FACTOR is a tunable parameter controlling the penalty's strength.\n            PENALTY_FACTOR = 5.0 # Example: A factor of 5.0\n\n            penalty = -PENALTY_FACTOR * normalized_fragment_rem\n            calculated_priorities[fragment_zone_mask] += penalty\n\n    # Assign the calculated priorities to the fitting bins in the main array\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic combines \"Best Fit\" with a \"Bin Consolidation\" and\n    \"Fragmentation Avoidance\" strategy. It aims to achieve global efficacy\n    through local, non-linear interactions, adapting to the current item's size.\n\n    The priority calculation is composed of:\n    1.  **Best Fit Core:** Prioritizes bins that result in the smallest\n        remaining capacity after the item is placed. This is the foundational\n        linear component.\n    2.  **Exact Fit Bonus (Non-linear):** Provides a significant, discrete\n        bonus for bins where the item fits perfectly, leading to zero\n        remaining capacity. This encourages complete bin utilization and closure.\n    3.  **Fragmentation Penalty (Non-linear & Adaptive):** Applies a penalty\n        to bins that, after placing the item, would be left with a small,\n        non-zero remaining capacity. This penalty is particularly harsh if the\n        remaining capacity is less than or equal to the current `item`'s size,\n        discouraging the creation of fragmented space that might be difficult\n        to fill with future items of similar scale. The penalty scales with\n        how close the remainder is to the `item`'s size, pushing towards\n        either very small remainders or sufficiently large (useful) ones.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit (capacity >= item size)\n    can_fit_mask = bins_remain_cap >= item\n\n    # Extract capacities for only the fitting bins\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # --- Core Priority Calculation (Best Fit component) ---\n    # We negate the potential remaining capacity so that a smaller remainder\n    # results in a higher (less negative) priority score.\n    # Example: remaining 0.1 -> score -0.1; remaining 0.5 -> score -0.5.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Hybrid/Non-linear/Adaptive Components ---\n\n    # 1. Exact Fit Bonus: A strong, discrete non-linear bonus for perfect fits.\n    # This highly prioritizes bins that can be perfectly filled.\n    EXACT_FIT_THRESHOLD = 1e-9  # Tolerance for floating point comparisons to zero\n    EXACT_FIT_BONUS = 1000.0    # A large bonus to ensure exact fits are top priority\n\n    exact_fit_mask = np.isclose(potential_remaining_cap, 0.0, atol=EXACT_FIT_THRESHOLD)\n    calculated_priorities[exact_fit_mask] += EXACT_FIT_BONUS\n\n    # 2. Fragmentation Penalty: Penalize creating small, non-zero remnants.\n    # This aims to avoid \"awkward\" remaining capacities that are too small\n    # to be easily useful for typical future items, especially if they are\n    # a significant fraction of the current item's size.\n    \n    # Apply penalty only if the item size is positive to avoid division by zero.\n    # Item sizes in BPP are typically positive.\n    if item > EXACT_FIT_THRESHOLD:\n        # Define the \"fragmentation zone\": remaining capacities that are\n        # non-zero but less than or equal to the current item's size.\n        # This range is problematic as it's not an exact fit, but also not\n        # large enough to easily accommodate another item of the same size.\n        fragment_zone_mask = (potential_remaining_cap > EXACT_FIT_THRESHOLD) & \\\n                             (potential_remaining_cap <= item)\n\n        if np.any(fragment_zone_mask):\n            # Normalize the remaining capacity within this zone by the item's size.\n            # This makes the penalty adaptive to the scale of the current item.\n            normalized_fragment_rem = potential_remaining_cap[fragment_zone_mask] / item\n\n            # Apply a penalty that increases as the normalized remainder\n            # approaches 1 (i.e., remaining capacity is close to item's size).\n            # This strongly discourages leaving a bin with a capacity just\n            # slightly less than the item, effectively making it a \"dead space\".\n            # PENALTY_FACTOR is a tunable parameter controlling the penalty's strength.\n            PENALTY_FACTOR = 5.0 # Example: A factor of 5.0\n\n            penalty = -PENALTY_FACTOR * normalized_fragment_rem\n            calculated_priorities[fragment_zone_mask] += penalty\n\n    # Assign the calculated priorities to the fitting bins in the main array\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority for 'Best Fit' by maximizing the effective filled capacity.\n\n    Prioritizes bins that achieve the highest fill level after placing the item,\n    yielding positive scores for valid fits and penalizing impossible ones.\n    \"\"\"\n    # Initialize all priorities to an extremely low value, ensuring bins that cannot\n    # accommodate the item are never selected.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify which bins possess sufficient remaining capacity for the item.\n    fits_mask = bins_remain_cap >= item\n\n    # For bins where the item demonstrably fits, calculate a priority score.\n    # This score, 2 * item - bins_remain_cap[fits_mask], maximizes the resulting\n    # effective filled capacity relative to the item's size. A perfect fit\n    # (where the bin's remaining capacity becomes zero) yields the highest positive\n    # score (equal to `item`), while less efficient fits yield lower positive scores.\n    # This combines the efficiency of masking first with a positive-scaled Best Fit score.\n    priorities[fits_mask] = 2 * item - bins_remain_cap[fits_mask]\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims for a \"Hybrid Fit\" strategy, building upon Best Fit\n    by incorporating multi-objective considerations and non-linear scoring.\n    It prioritizes:\n    1.  **Perfect or Near-Perfect Fits:** Maximizing the chance of completely filling a bin\n        to reduce the total number of active bins and eliminate fragmentation.\n    2.  **Best Fit:** After perfect fits, it reverts to the standard Best Fit strategy\n        of minimizing the remaining capacity.\n    3.  **Fragment Avoidance:** It penalizes bins that, after placement, would be left\n        with a very small, \"awkward\" amount of space that is unlikely to be useful\n        for subsequent items (e.g., too small for most items, but not zero).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n                         Assumes capacities and item sizes are normalized or\n                         consistent in their units.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Find bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # No bin can fit the item, return -inf for all (or new bin logic handled externally)\n        return priorities\n\n    # Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # --- Tunable Parameters for the Hybrid Fit Heuristic ---\n    # These parameters are crucial for balancing the different objectives.\n    # They might require tuning based on the specific distribution of item sizes\n    # and bin capacity in your problem instance.\n\n    # EPSILON_PERFECT_FIT: A small tolerance for floating point comparisons to\n    # consider a bin \"perfectly\" filled. If remaining capacity is within this,\n    # it's considered a perfect fit.\n    EPSILON_PERFECT_FIT = 1e-9\n\n    # TINY_REMAINDER_THRESHOLD: The upper bound for what is considered a \"tiny\"\n    # or \"awkward\" remaining capacity. If a bin's remaining capacity falls\n    # between EPSILON_PERFECT_FIT and this threshold, it incurs a penalty.\n    # This value typically corresponds to a small fraction of the bin's total capacity.\n    # For example, if bin capacity is 1.0, 0.05 means 5% of capacity.\n    TINY_REMAINDER_THRESHOLD = 0.05\n\n    # PERFECT_FIT_BONUS: A large positive bonus applied to bins that achieve\n    # a perfect or near-perfect fit. This should be high enough to make perfect\n    # fits almost always the top priority.\n    PERFECT_FIT_BONUS = 1000.0\n\n    # TINY_REMAINDER_PENALTY: A significant negative penalty applied to bins\n    # that are left with a tiny, potentially unusable remainder. This pushes\n    # the algorithm away from creating such fragmented bins.\n    TINY_REMAINDER_PENALTY = 500.0\n\n    # --- Apply the scoring logic ---\n    # 1. Base Score: Best Fit (minimize remaining capacity)\n    #    A smaller positive remaining capacity results in a larger (less negative) base score.\n    current_priorities = -potential_remaining_cap\n\n    # 2. Perfect/Near-Perfect Fit Bonus\n    #    Identify bins where remaining capacity is very close to zero.\n    perfect_fit_mask = potential_remaining_cap <= EPSILON_PERFECT_FIT\n    current_priorities[perfect_fit_mask] += PERFECT_FIT_BONUS\n\n    # 3. Tiny Remainder Penalty\n    #    Identify bins where remaining capacity is small but not zero (a \"dead zone\").\n    #    Ensure these are not already marked as perfect fits.\n    tiny_remainder_mask = (potential_remaining_cap > EPSILON_PERFECT_FIT) & \\\n                          (potential_remaining_cap < TINY_REMAINDER_THRESHOLD)\n    current_priorities[tiny_remainder_mask] -= TINY_REMAINDER_PENALTY\n\n    # Assign the calculated priorities back to the main priorities array\n    priorities[can_fit_mask] = current_priorities\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims for a \"Best Fit\" strategy:\n    It prioritizes bins that, after the item is placed, will have the smallest\n    remaining capacity. This helps to 'tightly pack' items into existing bins,\n    leaving larger capacities open for larger items or reducing fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Find bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # For fitting bins, we want to maximize the \"tightness\".\n    # A smaller remaining capacity means a tighter fit.\n    # To achieve this with argmax (which finds the maximum priority score),\n    # we can use the negative of the potential_remaining_cap.\n    # E.g., if remainders are [0.1, 0.5, 0.8], their negatives are [-0.1, -0.5, -0.8].\n    # The max of negatives is -0.1, which corresponds to the smallest positive remainder 0.1.\n    priorities[can_fit_mask] = -potential_remaining_cap\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority for 'Best Fit' by maximizing the effective filled capacity.\n\n    Prioritizes bins that achieve the highest fill level after placing the item,\n    yielding positive scores for valid fits and penalizing impossible ones.\n    \"\"\"\n    # Initialize all priorities to an extremely low value, ensuring bins that cannot\n    # accommodate the item are never selected.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify which bins possess sufficient remaining capacity for the item.\n    fits_mask = bins_remain_cap >= item\n\n    # For bins where the item demonstrably fits, calculate a priority score.\n    # This score, 2 * item - bins_remain_cap[fits_mask], maximizes the resulting\n    # effective filled capacity relative to the item's size. A perfect fit\n    # (where the bin's remaining capacity becomes zero) yields the highest positive\n    # score (equal to `item`), while less efficient fits yield lower positive scores.\n    # This combines the efficiency of masking first with a positive-scaled Best Fit score.\n    priorities[fits_mask] = 2 * item - bins_remain_cap[fits_mask]\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims for a \"Hybrid Fit\" strategy, building upon Best Fit\n    by incorporating multi-objective considerations and non-linear scoring.\n    It prioritizes:\n    1.  **Perfect or Near-Perfect Fits:** Maximizing the chance of completely filling a bin\n        to reduce the total number of active bins and eliminate fragmentation.\n    2.  **Best Fit:** After perfect fits, it reverts to the standard Best Fit strategy\n        of minimizing the remaining capacity.\n    3.  **Fragment Avoidance:** It penalizes bins that, after placement, would be left\n        with a very small, \"awkward\" amount of space that is unlikely to be useful\n        for subsequent items (e.g., too small for most items, but not zero).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n                         Assumes capacities and item sizes are normalized or\n                         consistent in their units.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Find bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # No bin can fit the item, return -inf for all (or new bin logic handled externally)\n        return priorities\n\n    # Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # --- Tunable Parameters for the Hybrid Fit Heuristic ---\n    # These parameters are crucial for balancing the different objectives.\n    # They might require tuning based on the specific distribution of item sizes\n    # and bin capacity in your problem instance.\n\n    # EPSILON_PERFECT_FIT: A small tolerance for floating point comparisons to\n    # consider a bin \"perfectly\" filled. If remaining capacity is within this,\n    # it's considered a perfect fit.\n    EPSILON_PERFECT_FIT = 1e-9\n\n    # TINY_REMAINDER_THRESHOLD: The upper bound for what is considered a \"tiny\"\n    # or \"awkward\" remaining capacity. If a bin's remaining capacity falls\n    # between EPSILON_PERFECT_FIT and this threshold, it incurs a penalty.\n    # This value typically corresponds to a small fraction of the bin's total capacity.\n    # For example, if bin capacity is 1.0, 0.05 means 5% of capacity.\n    TINY_REMAINDER_THRESHOLD = 0.05\n\n    # PERFECT_FIT_BONUS: A large positive bonus applied to bins that achieve\n    # a perfect or near-perfect fit. This should be high enough to make perfect\n    # fits almost always the top priority.\n    PERFECT_FIT_BONUS = 1000.0\n\n    # TINY_REMAINDER_PENALTY: A significant negative penalty applied to bins\n    # that are left with a tiny, potentially unusable remainder. This pushes\n    # the algorithm away from creating such fragmented bins.\n    TINY_REMAINDER_PENALTY = 500.0\n\n    # --- Apply the scoring logic ---\n    # 1. Base Score: Best Fit (minimize remaining capacity)\n    #    A smaller positive remaining capacity results in a larger (less negative) base score.\n    current_priorities = -potential_remaining_cap\n\n    # 2. Perfect/Near-Perfect Fit Bonus\n    #    Identify bins where remaining capacity is very close to zero.\n    perfect_fit_mask = potential_remaining_cap <= EPSILON_PERFECT_FIT\n    current_priorities[perfect_fit_mask] += PERFECT_FIT_BONUS\n\n    # 3. Tiny Remainder Penalty\n    #    Identify bins where remaining capacity is small but not zero (a \"dead zone\").\n    #    Ensure these are not already marked as perfect fits.\n    tiny_remainder_mask = (potential_remaining_cap > EPSILON_PERFECT_FIT) & \\\n                          (potential_remaining_cap < TINY_REMAINDER_THRESHOLD)\n    current_priorities[tiny_remainder_mask] -= TINY_REMAINDER_PENALTY\n\n    # Assign the calculated priorities back to the main priorities array\n    priorities[can_fit_mask] = current_priorities\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims for a \"Best Fit\" strategy:\n    It prioritizes bins that, after the item is placed, will have the smallest\n    remaining capacity. This helps to 'tightly pack' items into existing bins,\n    leaving larger capacities open for larger items or reducing fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Find bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # For fitting bins, we want to maximize the \"tightness\".\n    # A smaller remaining capacity means a tighter fit.\n    # To achieve this with argmax (which finds the maximum priority score),\n    # we can use the negative of the potential_remaining_cap.\n    # E.g., if remainders are [0.1, 0.5, 0.8], their negatives are [-0.1, -0.5, -0.8].\n    # The max of negatives is -0.1, which corresponds to the smallest positive remainder 0.1.\n    priorities[can_fit_mask] = -potential_remaining_cap\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float = 1.0) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation builds on the \"Best Fit\" strategy but introduces a slight\n    preference for existing, partially filled bins over entirely new (empty) bins.\n    The goal is to encourage filling up bins already in use, potentially delaying\n    the opening of new bins, which can lead to fewer total bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The maximum capacity of a single bin. Default to 1.0,\n                      assuming item sizes are normalized relative to this capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 1. Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only consider bins where the item fits\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # 2. Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # 3. Base priority: Best Fit strategy (minimize remaining capacity)\n    # A smaller potential_remaining_cap (closer to 0) means a tighter fit,\n    # which is preferred. By taking the negative, we convert minimization\n    # to maximization for `np.argmax`.\n    # A perfect fit (potential_remaining_cap == 0) will result in a priority of 0,\n    # which is the highest possible score from this component.\n    base_priorities = -potential_remaining_cap\n\n    # 4. Mutation: Add a small bonus for choosing an already used bin over a fresh one.\n    # This slightly biases towards consolidating items into existing bins.\n    # The bonus value (e.g., 1e-6) should be carefully chosen. It must be\n    # small enough not to override a significantly better Best Fit (i.e., a\n    # much smaller potential_remaining_cap difference), but large enough\n    # to break ties or influence decisions when Best Fit scores are very close.\n    # For floating-point comparisons, a tolerance (e.g., np.finfo(float).eps * 10)\n    # is often used, but for simplicity and common BPP scenarios where `bin_capacity`\n    # is exactly 1.0 for fresh bins, direct comparison or `x < capacity` is often sufficient.\n    used_bin_bonus = 1e-6  # A small constant bonus\n\n    # Identify bins that are not \"fresh\" (i.e., not entirely empty/unused).\n    # A bin is considered 'used' if its remaining capacity is strictly less than the full capacity.\n    # Using np.isclose for robustness against floating-point inaccuracies when comparing to bin_capacity.\n    is_used_bin_mask = ~np.isclose(fitting_bins_remain_cap, bin_capacity)\n\n    # Apply the bonus only to bins that can fit the item AND are already used.\n    # This applies the bonus to the elements within the 'can_fit_mask' subset.\n    priorities[can_fit_mask] = base_priorities\n    priorities[can_fit_mask][is_used_bin_mask] += used_bin_bonus\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation extends \"Best Fit\" with a \"Consolidation Bonus\".\n    It prioritizes bins that, after the item is placed, will have the smallest\n    remaining capacity (Best Fit). Additionally, it gives a linear bonus\n    to bins that are already partially filled (i.e., not completely empty),\n    to encourage consolidation and avoid opening new bins prematurely.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n                         This array typically includes capacities of active bins\n                         and potentially one or more 'empty' bins representing\n                         new bins that can be opened.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # A small positive constant bonus to encourage consolidation into existing bins.\n    # This value should be carefully chosen. It should be small enough to\n    # generally not override the primary \"Best Fit\" principle, but large enough\n    # to consistently break ties or influence choices when potential remaining\n    # capacities are very close.\n    CONSOLIDATION_BONUS = 0.01\n\n    # Initialize priorities for all bins to negative infinity.\n    # This ensures that bins where the item cannot fit will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Handle the edge case where there are no bins to consider.\n    if len(bins_remain_cap) == 0:\n        return priorities\n\n    # Infer the maximum capacity of an 'empty' bin from the input array.\n    # This assumes that if a new bin is to be opened, its capacity\n    # (or equivalent to a fresh bin's capacity) is present in `bins_remain_cap`.\n    # If all bins are already partially filled, this will consider the least\n    # filled bin as the 'reference empty' for bonus purposes, promoting consolidation\n    # into the most-filled (least remaining capacity) bins among the current set.\n    BIN_CAPACITY = np.max(bins_remain_cap)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the priorities array with -np.inf.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity if the item were placed in each fitting bin.\n    # This is the core of the \"Best Fit\" strategy.\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # Base score: The goal is to minimize the remaining capacity, which means\n    # maximizing the negative of the remaining capacity. This creates a monotonic\n    # scoring where a smaller positive remainder yields a higher priority score.\n    base_scores = -potential_remaining_cap\n\n    # Determine which of the fitting bins are \"partially filled\" (not completely empty).\n    # A bin is considered partially filled if its current remaining capacity\n    # is less than the inferred full bin capacity (BIN_CAPACITY).\n    is_partially_filled_mask = (bins_remain_cap[can_fit_mask] < BIN_CAPACITY)\n\n    # Initialize bonuses for fitting bins to zero.\n    consolidation_bonuses = np.zeros_like(base_scores)\n\n    # Apply the consolidation bonus only to the fitting bins that are partially filled.\n    # This encourages using existing, non-empty bins before opening new ones.\n    consolidation_bonuses[is_partially_filled_mask] = CONSOLIDATION_BONUS\n\n    # The total priority for fitting bins is the sum of the base Best Fit score\n    # and the consolidation bonus.\n    priorities[can_fit_mask] = base_scores + consolidation_bonuses\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation extends \"Best Fit\" with a \"Consolidation Bonus\".\n    It prioritizes bins that, after the item is placed, will have the smallest\n    remaining capacity (Best Fit). Additionally, it gives a linear bonus\n    to bins that are already partially filled (i.e., not completely empty),\n    to encourage consolidation and avoid opening new bins prematurely.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n                         This array typically includes capacities of active bins\n                         and potentially one or more 'empty' bins representing\n                         new bins that can be opened.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # A small positive constant bonus to encourage consolidation into existing bins.\n    # This value should be carefully chosen. It should be small enough to\n    # generally not override the primary \"Best Fit\" principle, but large enough\n    # to consistently break ties or influence choices when potential remaining\n    # capacities are very close.\n    CONSOLIDATION_BONUS = 0.01\n\n    # Initialize priorities for all bins to negative infinity.\n    # This ensures that bins where the item cannot fit will not be chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Handle the edge case where there are no bins to consider.\n    if len(bins_remain_cap) == 0:\n        return priorities\n\n    # Infer the maximum capacity of an 'empty' bin from the input array.\n    # This assumes that if a new bin is to be opened, its capacity\n    # (or equivalent to a fresh bin's capacity) is present in `bins_remain_cap`.\n    # If all bins are already partially filled, this will consider the least\n    # filled bin as the 'reference empty' for bonus purposes, promoting consolidation\n    # into the most-filled (least remaining capacity) bins among the current set.\n    BIN_CAPACITY = np.max(bins_remain_cap)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return the priorities array with -np.inf.\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate the remaining capacity if the item were placed in each fitting bin.\n    # This is the core of the \"Best Fit\" strategy.\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # Base score: The goal is to minimize the remaining capacity, which means\n    # maximizing the negative of the remaining capacity. This creates a monotonic\n    # scoring where a smaller positive remainder yields a higher priority score.\n    base_scores = -potential_remaining_cap\n\n    # Determine which of the fitting bins are \"partially filled\" (not completely empty).\n    # A bin is considered partially filled if its current remaining capacity\n    # is less than the inferred full bin capacity (BIN_CAPACITY).\n    is_partially_filled_mask = (bins_remain_cap[can_fit_mask] < BIN_CAPACITY)\n\n    # Initialize bonuses for fitting bins to zero.\n    consolidation_bonuses = np.zeros_like(base_scores)\n\n    # Apply the consolidation bonus only to the fitting bins that are partially filled.\n    # This encourages using existing, non-empty bins before opening new ones.\n    consolidation_bonuses[is_partially_filled_mask] = CONSOLIDATION_BONUS\n\n    # The total priority for fitting bins is the sum of the base Best Fit score\n    # and the consolidation bonus.\n    priorities[can_fit_mask] = base_scores + consolidation_bonuses\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, ideal_remainder_ratio: float = 0.31342951204947844) -> np.ndarray:\n    \"\"\"Returns priority with which to add an item to each bin.\n\n    This implementation aims for a \"Target Remainder Fit\" strategy. It seeks to\n    assign an item to a bin such that the bin's remaining capacity after placement\n    is close to a predefined 'ideal' target value. This approach is more adaptive\n    and holistic than a simple Best Fit, as it manages the distribution of\n    remaining bin capacities, potentially leaving more \"useful\" space for\n    future items and promoting a more diverse set of bin states.\n\n    The 'ideal_remainder_ratio' parameter determines the target remaining capacity\n    as a fraction of the total bin capacity. A value of 0.0 would revert to a\n    pure Best Fit (minimizing remaining capacity). A value closer to 1.0 would\n    lean towards Worst Fit (maximizing remaining capacity). A moderate value\n    (e.g., 0.25) attempts to maintain a balanced bin state.\n\n    Assumptions:\n    1. The problem implies a fixed `BIN_CAPACITY` for all bins. Since it's not\n       an explicit argument, we infer it from `bins_remain_cap`. In online BPP,\n       new bins are typically added at full capacity. Therefore, `np.max(bins_remain_cap)`\n       is used as a reasonable proxy for `BIN_CAPACITY`, assuming at least one\n       bin is either empty (full capacity) or has the largest possible remaining capacity.\n       For extreme edge cases (e.g., all bins are almost full and no new empty bin has been opened yet),\n       this inference might be inaccurate, but it's a common practical approach.\n    2. `item` and `bins_remain_cap` values are in consistent units.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        ideal_remainder_ratio: A heuristic parameter (between 0.0 and 1.0)\n                               determining the target remaining capacity as a\n                               fraction of the total bin capacity.\n                               0.0 for Best Fit, ~0.2-0.3 for a more balanced \"middle-fit\".\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Handle case where no bins are available or bins_remain_cap is empty\n    if bins_remain_cap.size == 0:\n        return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, ideal_remainder_ratio: float = 0.31342951204947844) -> np.ndarray:\n    \"\"\"Returns priority with which to add an item to each bin.\n\n    This implementation aims for a \"Target Remainder Fit\" strategy. It seeks to\n    assign an item to a bin such that the bin's remaining capacity after placement\n    is close to a predefined 'ideal' target value. This approach is more adaptive\n    and holistic than a simple Best Fit, as it manages the distribution of\n    remaining bin capacities, potentially leaving more \"useful\" space for\n    future items and promoting a more diverse set of bin states.\n\n    The 'ideal_remainder_ratio' parameter determines the target remaining capacity\n    as a fraction of the total bin capacity. A value of 0.0 would revert to a\n    pure Best Fit (minimizing remaining capacity). A value closer to 1.0 would\n    lean towards Worst Fit (maximizing remaining capacity). A moderate value\n    (e.g., 0.25) attempts to maintain a balanced bin state.\n\n    Assumptions:\n    1. The problem implies a fixed `BIN_CAPACITY` for all bins. Since it's not\n       an explicit argument, we infer it from `bins_remain_cap`. In online BPP,\n       new bins are typically added at full capacity. Therefore, `np.max(bins_remain_cap)`\n       is used as a reasonable proxy for `BIN_CAPACITY`, assuming at least one\n       bin is either empty (full capacity) or has the largest possible remaining capacity.\n       For extreme edge cases (e.g., all bins are almost full and no new empty bin has been opened yet),\n       this inference might be inaccurate, but it's a common practical approach.\n    2. `item` and `bins_remain_cap` values are in consistent units.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        ideal_remainder_ratio: A heuristic parameter (between 0.0 and 1.0)\n                               determining the target remaining capacity as a\n                               fraction of the total bin capacity.\n                               0.0 for Best Fit, ~0.2-0.3 for a more balanced \"middle-fit\".\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Handle case where no bins are available or bins_remain_cap is empty\n    if bins_remain_cap.size == 0:\n        return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which to add an item to each bin.\n\n    This implementation aims for a \"Target Remainder Fit\" strategy. It seeks to\n    assign an item to a bin such that the bin's remaining capacity after placement\n    is close to a predefined 'ideal' target value. This approach is more adaptive\n    and holistic than a simple Best Fit, as it manages the distribution of\n    remaining bin capacities, potentially leaving more \"useful\" space for\n    future items and promoting a more diverse set of bin states.\n\n    The 'ideal_remainder_ratio' parameter determines the target remaining capacity\n    as a fraction of the total bin capacity. A value of 0.0 would revert to a\n    pure Best Fit (minimizing remaining capacity). A value closer to 1.0 would\n    lean towards Worst Fit (maximizing remaining capacity). A moderate value\n    (e.g., 0.25) attempts to maintain a balanced bin state.\n\n    Assumptions:\n    1. The problem implies a fixed `BIN_CAPACITY` for all bins. Since it's not\n       an explicit argument, we infer it from `bins_remain_cap`. In online BPP,\n       new bins are typically added at full capacity. Therefore, `np.max(bins_remain_cap)`\n       is used as a reasonable proxy for `BIN_CAPACITY`, assuming at least one\n       bin is either empty (full capacity) or has the largest possible remaining capacity.\n       For extreme edge cases (e.g., all bins are almost full and no new empty bin has been opened yet),\n       this inference might be inaccurate, but it's a common practical approach.\n    2. `item` and `bins_remain_cap` values are in consistent units.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Handle case where no bins are available or bins_remain_cap is empty\n    if bins_remain_cap.size == 0:\n        return priorities\n\n    # Infer BIN_CAPACITY from the maximum remaining capacity among current bins.\n    # This assumes that at least one \"fresh\" bin (with full capacity) is or was available,\n    # or that the maximum value represents the standard bin capacity.\n    BIN_CAPACITY = np.max(bins_remain_cap)\n    if BIN_CAPACITY == 0: # Avoid division by zero if all bins are exactly 0 capacity\n        return priorities # No item can fit anywhere\n\n    # Define the ideal remaining capacity ratio after placing an item.\n    # This is a key heuristic parameter for tuning:\n    # 0.0 for Best Fit, ~0.2-0.3 for a more balanced \"middle-fit\".\n    ideal_remainder_ratio = 0.25\n    TARGET_REMAINDER = BIN_CAPACITY * ideal_remainder_ratio\n\n    # Find bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate priority based on the absolute difference from the TARGET_REMAINDER.\n    # We want to minimize this absolute difference, so we take its negative.\n    # This means bins whose `potential_remaining_cap` is closest to `TARGET_REMAINDER`\n    # will receive the highest priority.\n    priorities[can_fit_mask] = -np.abs(potential_remaining_cap - TARGET_REMAINDER)\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}