```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive hybrid heuristic combining Best Fit with exponential exact-fit bonus,
    Gaussian fragmentation penalty, and logarithmic large-space bonus to optimize bin
    closure and space utility for online BPP."""

    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Mask for bins where the item can fit (capacity >= item size)
    can_fit_mask = bins_remain_cap >= item

    # Extract capacities for only the fitting bins
    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]

    # If no bin can fit the item, return priorities initialized to -inf
    if fitting_bins_remain_cap.size == 0:
        return priorities

    # Calculate potential remaining capacity if the item were placed
    potential_remaining_cap = fitting_bins_remain_cap - item

    # --- Core Priority Calculation (Best Fit component) ---
    # Negate potential remaining capacity: smaller remainder -> higher (less negative) priority.
    # This component forms the baseline preference for tighter fits.
    calculated_priorities = -potential_remaining_cap

    # --- Non-linear, Adaptive Components for nuanced bin state management ---

    # General tolerance for floating point comparisons to zero
    EXACT_FIT_TOLERANCE = 1e-9 
    
    # Use item size or a default if item is too small, to avoid division by zero or
    # disproportionate scaling with very tiny items in relative calculations.
    effective_item_size = item if item > EXACT_FIT_TOLERANCE else 1.0 

    # 1. Exponential Exact Fit Bonus: Strongly incentivizes near-perfect fits.
    # This bonus provides a massive boost for bins that would be left with minimal
    # remaining capacity, pushing for immediate bin closure.
    EXP_BONUS_MAGNITUDE = 5000.0   # High magnitude ensures dominance for exact fits
    EXP_BONUS_DECAY = 50.0         # Rapid decay means bonus is only for truly near-perfect fits
    
    # Define the zone where exponential bonus applies (very close to zero remaining capacity)
    exp_bonus_zone_mask = np.isclose(potential_remaining_cap, 0.0, atol=EXACT_FIT_TOLERANCE) | \
                          (potential_remaining_cap < (effective_item_size * 0.01)) # Or within 1% of item size

    if np.any(exp_bonus_zone_mask):
        # The bonus decays exponentially as remaining capacity moves away from zero
        bonus_values = EXP_BONUS_MAGNITUDE * np.exp(-EXP_BONUS_DECAY * potential_remaining_cap[exp_bonus_zone_mask])
        calculated_priorities[exp_bonus_zone_mask] += bonus_values

    # 2. Gaussian Fragmentation Penalty: Penalizes creating "awkward" small-to-medium
    # remaining capacities. This avoids the "Valley of Despair" where space is too
    # small to be useful for common items, but not perfectly filled.
    GAUSSIAN_PENALTY_MAGNITUDE = 50.0 # Strength of the penalty
    GAUSSIAN_PEAK_FACTOR = 0.4        # Penalty peaks when remainder is 40% of current item's size
    GAUSSIAN_WIDTH_FACTOR = 0.1       # Controls the spread/sharpness of the penalty curve

    # Calculate Gaussian parameters based on effective item size
    mu_fragment = GAUSSIAN_PEAK_FACTOR * effective_item_size
    sigma_fragment = GAUSSIAN_WIDTH_FACTOR * effective_item_size
    
    # Ensure sigma is not zero for Gaussian calculation stability
    if sigma_fragment < EXACT_FIT_TOLERANCE:
        sigma_fragment = EXACT_FIT_TOLERANCE 

    # Define the fragmentation zone: from just above exact fit to a certain multiple of item size
    # This zone starts after the exponential bonus has lost significant effect.
    fragment_zone_mask = (potential_remaining_cap > (effective_item_size * 0.01 + EXACT_FIT_TOLERANCE)) & \
                         (potential_remaining_cap <= effective_item_size * 1.2) # Penalty applies up to 1.2x item size

    if np.any(fragment_zone_mask):
        # Penalty is negative, its magnitude increases as remainder approaches mu_fragment
        penalty_values = -GAUSSIAN_PENALTY_MAGNITUDE * np.exp(
            -((potential_remaining_cap[fragment_zone_mask] - mu_fragment)**2) / (2 * sigma_fragment**2)
        )
        calculated_priorities[fragment_zone_mask] += penalty_values

    # 3. Logarithmic Large Remaining Space Bonus: Incentivizes leaving substantial, useful capacity.
    # This rewards bins that are not nearly full, preserving larger continuous spaces for future large items.
    LARGE_SPACE_BONUS_MAGNITUDE = 10.0 # Strength of the bonus
    LARGE_SPACE_LOWER_BOUND_FACTOR = 1.2 # Bonus applies if remainder is > 1.2x current item's size

    # Define the large space zone: after the fragmentation zone
    large_space_mask = potential_remaining_cap > effective_item_size * LARGE_SPACE_LOWER_BOUND_FACTOR
    
    if np.any(large_space_mask):
        # Logarithm ensures diminishing returns for excessively large spaces.
        # Normalize by effective_item_size for scale invariance and add 1 to avoid log(0) issues.
        bonus_values = LARGE_SPACE_BONUS_MAGNITUDE * np.log(potential_remaining_cap[large_space_mask] / effective_item_size + 1.0)
        calculated_priorities[large_space_mask] += bonus_values

    # Assign the calculated priorities to the fitting bins in the main array
    priorities[can_fit_mask] = calculated_priorities

    return priorities
```
