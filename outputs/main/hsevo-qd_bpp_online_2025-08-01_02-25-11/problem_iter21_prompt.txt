{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\nCurrent heuristics:\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins combining best fit, aggressive exponential near-fit bonuses,\n    a nuanced Gaussian (valley of despair) fragmentation penalty, and a bonus for\n    leaving large useful space. Aims for global efficacy by intelligently managing bin states.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit (capacity >= item size)\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Extract capacities for only the fitting bins\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # --- Core Priority Calculation (Best Fit component) ---\n    # We negate the potential remaining capacity so that a smaller remainder\n    # results in a higher (less negative) priority score.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Hybrid/Non-linear/Adaptive Components ---\n\n    # Tolerance for floating point comparisons to zero\n    EXACT_FIT_THRESHOLD = 1e-9\n\n    # 1. Aggressive Near-Exact Fit Bonus (Exponential Decay):\n    # This provides a very strong, non-linear incentive for bins that can be\n    # almost perfectly filled, with the bonus decaying rapidly as remainder grows.\n    NEAR_EXACT_FIT_BONUS_MAGNITUDE = 5000.0  # Max bonus for perfect fit\n    NEAR_EXACT_FIT_BONUS_DECAY = 50.0       # Steepness of the exponential decay\n\n    # Apply this bonus for very small non-zero remainders (e.g., less than 10% of item size)\n    near_exact_mask = (potential_remaining_cap > EXACT_FIT_THRESHOLD) & \\\n                      (potential_remaining_cap < 0.1 * item) # Or a fixed small absolute threshold\n\n    if np.any(near_exact_mask):\n        # Bonus: A * exp(-B * remainder)\n        bonus = NEAR_EXACT_FIT_BONUS_MAGNITUDE * np.exp(-NEAR_EXACT_FIT_BONUS_DECAY * potential_remaining_cap[near_exact_mask])\n        calculated_priorities[near_exact_mask] += bonus\n\n    # For perfect fits (zero remainder), assign highest possible priority (infinity).\n    # This ensures exact fits are always chosen first.\n    perfect_fit_mask = np.isclose(potential_remaining_cap, 0.0, atol=EXACT_FIT_THRESHOLD)\n    if np.any(perfect_fit_mask):\n        calculated_priorities[perfect_fit_mask] = np.inf\n\n    # 2. Gaussian Fragmentation Penalty (\"Valley of Despair\"):\n    # Applies a strong, non-linear penalty for leaving \"awkward\" small-to-medium\n    # remnants that are difficult to fill. The penalty peaks around a specific\n    # problematic remainder size, creating a \"valley of despair\".\n    if item > EXACT_FIT_THRESHOLD: # Penalty only relevant for positive item sizes\n        GAUSSIAN_PENALTY_AMPLITUDE = 200.0  # Strength of the penalty\n        # The remainder size (as a ratio of item size) that is most undesirable.\n        GAUSSIAN_PENALTY_CENTER_RATIO = 0.4 # E.g., 40% of item's size\n        # Standard deviation of the Gaussian, controls the \"width\" of the valley.\n        GAUSSIAN_PENALTY_SPREAD = 0.1 * item # Adaptive to item size\n\n        # Define the range where this penalty is relevant (non-zero up to 1.5 * item)\n        penalty_zone_mask = (potential_remaining_cap > EXACT_FIT_THRESHOLD) & \\\n                            (potential_remaining_cap <= 1.5 * item)\n\n        if np.any(penalty_zone_mask):\n            # Calculate the \"target\" (undesirable) remainder size\n            target_fragment_remainder = GAUSSIAN_PENALTY_CENTER_RATIO * item\n\n            # Squared difference from the target fragment remainder\n            diff_sq = (potential_remaining_cap[penalty_zone_mask] - target_fragment_remainder)**2\n\n            # Apply a negative Gaussian penalty: -A * exp(-(x - mu)^2 / (2 * sigma^2))\n            # Add a small epsilon to spread to avoid division by zero for extremely small items.\n            penalty = -GAUSSIAN_PENALTY_AMPLITUDE * np.exp(-diff_sq / (2 * (GAUSSIAN_PENALTY_SPREAD + EXACT_FIT_THRESHOLD)**2))\n            calculated_priorities[penalty_zone_mask] += penalty\n\n    # 3. Useful Large Space Bonus (Logarithmic):\n    # Incentivizes leaving a bin with a significantly large remaining capacity\n    # (e.g., enough for another item of similar size). This encourages maintaining\n    # flexible bins that can accommodate future larger items, with diminishing returns.\n    USEFUL_SPACE_BONUS_FACTOR = 10.0 # Magnitude of this bonus\n    MIN_USEFUL_SPACE_FOR_BONUS_RATIO = 1.0 # Remainder must be at least 'item' size\n\n    # Mask for remaining capacities that are considered \"large and useful\"\n    large_useful_mask = potential_remaining_cap >= MIN_USEFUL_SPACE_FOR_BONUS_RATIO * item\n\n    if np.any(large_useful_mask):\n        # Logarithmic bonus: scales with remaining capacity but with diminishing returns.\n        # Use log1p (log(1+x)) for numerical stability.\n        bonus = USEFUL_SPACE_BONUS_FACTOR * np.log1p(potential_remaining_cap[large_useful_mask])\n        calculated_priorities[large_useful_mask] += bonus\n\n    # Assign the calculated priorities to the fitting bins in the main array\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\nNow, think outside the box write a mutated function `priority_v2` better than current version.\nYou can use some hints below:\n- \n*   **Keywords:** Adaptive, Non-linear, Hybrid, State-aware, Quality-of-space.\n*   **Advice:** Design hybrid heuristics with adaptive, non-linear rules targeting critical bin states (completion, fragmentation). Use functions like exponential/Gaussian/logarithmic for specific incentives. Prioritize remaining space *quality* via tunable parameters.\n*   **Avoid:** Sole reliance on monotonic/linear relationships, simple additive bonuses, or shying away from non-linear complexity. Do not over-emphasize basic greedy without state awareness of bin characteristics.\n*   **Explanation:** Non-linear, state-aware functions capture nuanced problem dynamics, providing precise incentives/penalties (e.g., sharp fragmentation costs, strong completion bonuses) that linear or overly simplistic approaches miss, yielding superior solutions.\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}