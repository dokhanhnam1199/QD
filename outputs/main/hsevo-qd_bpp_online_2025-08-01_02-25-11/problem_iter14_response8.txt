```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines Best Fit with dual consolidation bonuses:
    one for current bin fill (to reuse existing bins)
    and another for maximizing post-placement bin fill (to close bins).
    """
    # Scalers for the consolidation bonuses. These values are small to ensure Best Fit
    # remains the primary decision factor, only influencing selection when Best Fit
    # scores are very close.
    CURRENT_FILL_BONUS_SCALER = 0.01  # Encourages using already partially filled bins (from v0)
    POST_PLACEMENT_FILL_BONUS_SCALER = 0.005 # Rewards bins that become very full after item placement

    # Initialize priorities to negative infinity, meaning bins where the item cannot fit
    # or are invalid will not be chosen.
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Handle edge case: no bins available.
    if len(bins_remain_cap) == 0:
        return priorities

    # Infer the maximum bin capacity, assuming it represents the full capacity of a new bin.
    BIN_CAPACITY = np.max(bins_remain_cap)
    # If BIN_CAPACITY is zero or negative, no valid packing is possible for positive items.
    if BIN_CAPACITY <= 0:
        return priorities

    # Identify bins where the item can physically fit.
    can_fit_mask = bins_remain_cap >= item

    # If no bins can accommodate the item, return the initialized priorities array.
    if not np.any(can_fit_mask):
        return priorities

    # 1. Base Score: Best Fit principle.
    # Prioritizes bins that will have the least remaining capacity after the item is placed.
    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item
    base_scores = -potential_remaining_cap  # Negating makes smaller remainders result in higher scores.

    # 2. Dynamic Consolidation Bonus (from priority_v0):
    # Rewards bins that are already more full, encouraging reuse of open bins.
    current_filled_amount = BIN_CAPACITY - bins_remain_cap[can_fit_mask]
    current_filled_amount = np.clip(current_filled_amount, 0, BIN_CAPACITY) # Ensure values are within valid range.
    current_fill_ratio = current_filled_amount / BIN_CAPACITY
    current_consolidation_bonuses = CURRENT_FILL_BONUS_SCALER * current_fill_ratio

    # 3. Post-Placement Fill Maximization Bonus:
    # Rewards bins that become very full (closer to 100% utilized) after the item is placed.
    # This encourages 'closing' bins by packing them tightly.
    post_placement_filled_amount = BIN_CAPACITY - potential_remaining_cap
    post_placement_filled_amount = np.clip(post_placement_filled_amount, 0, BIN_CAPACITY) # Ensure valid range.
    post_placement_fill_ratio = post_placement_filled_amount / BIN_CAPACITY
    post_placement_bonuses = POST_PLACEMENT_FILL_BONUS_SCALER * post_placement_fill_ratio

    # Combine all components: Best Fit as primary, enhanced by two types of fill-based bonuses.
    priorities[can_fit_mask] = base_scores + current_consolidation_bonuses + post_placement_bonuses

    return priorities
```
