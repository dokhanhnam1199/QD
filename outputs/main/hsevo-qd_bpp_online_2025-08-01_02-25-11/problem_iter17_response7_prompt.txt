{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic combines \"Best Fit\" with a \"Bin Consolidation\" and\n    \"Fragmentation Avoidance\" strategy. It aims to achieve global efficacy\n    through local, non-linear interactions, adapting to the current item's size.\n\n    The priority calculation is composed of:\n    1.  **Best Fit Core:** Prioritizes bins that result in the smallest\n        remaining capacity after the item is placed. This is the foundational\n        linear component.\n    2.  **Exact Fit Bonus (Non-linear):** Provides a significant, discrete\n        bonus for bins where the item fits perfectly, leading to zero\n        remaining capacity. This encourages complete bin utilization and closure.\n    3.  **Fragmentation Penalty (Non-linear & Adaptive):** Applies a penalty\n        to bins that, after placing the item, would be left with a small,\n        non-zero remaining capacity. This penalty is particularly harsh if the\n        remaining capacity is less than or equal to the current `item`'s size,\n        discouraging the creation of fragmented space that might be difficult\n        to fill with future items of similar scale. The penalty scales with\n        how close the remainder is to the `item`'s size, pushing towards\n        either very small remainders or sufficiently large (useful) ones.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit (capacity >= item size)\n    can_fit_mask = bins_remain_cap >= item\n\n    # Extract capacities for only the fitting bins\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If no bin can fit the item, return priorities initialized to -inf\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Calculate potential remaining capacity if the item were placed\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # --- Core Priority Calculation (Best Fit component) ---\n    # We negate the potential remaining capacity so that a smaller remainder\n    # results in a higher (less negative) priority score.\n    # Example: remaining 0.1 -> score -0.1; remaining 0.5 -> score -0.5.\n    calculated_priorities = -potential_remaining_cap\n\n    # --- Hybrid/Non-linear/Adaptive Components ---\n\n    # 1. Exact Fit Bonus: A strong, discrete non-linear bonus for perfect fits.\n    # This highly prioritizes bins that can be perfectly filled.\n    EXACT_FIT_THRESHOLD = 1e-9  # Tolerance for floating point comparisons to zero\n    EXACT_FIT_BONUS = 1000.0    # A large bonus to ensure exact fits are top priority\n\n    exact_fit_mask = np.isclose(potential_remaining_cap, 0.0, atol=EXACT_FIT_THRESHOLD)\n    calculated_priorities[exact_fit_mask] += EXACT_FIT_BONUS\n\n    # 2. Fragmentation Penalty: Penalize creating small, non-zero remnants.\n    # This aims to avoid \"awkward\" remaining capacities that are too small\n    # to be easily useful for typical future items, especially if they are\n    # a significant fraction of the current item's size.\n    \n    # Apply penalty only if the item size is positive to avoid division by zero.\n    # Item sizes in BPP are typically positive.\n    if item > EXACT_FIT_THRESHOLD:\n        # Define the \"fragmentation zone\": remaining capacities that are\n        # non-zero but less than or equal to the current item's size.\n        # This range is problematic as it's not an exact fit, but also not\n        # large enough to easily accommodate another item of the same size.\n        fragment_zone_mask = (potential_remaining_cap > EXACT_FIT_THRESHOLD) & \\\n                             (potential_remaining_cap <= item)\n\n        if np.any(fragment_zone_mask):\n            # Normalize the remaining capacity within this zone by the item's size.\n            # This makes the penalty adaptive to the scale of the current item.\n            normalized_fragment_rem = potential_remaining_cap[fragment_zone_mask] / item\n\n            # Apply a penalty that increases as the normalized remainder\n            # approaches 1 (i.e., remaining capacity is close to item's size).\n            # This strongly discourages leaving a bin with a capacity just\n            # slightly less than the item, effectively making it a \"dead space\".\n            # PENALTY_FACTOR is a tunable parameter controlling the penalty's strength.\n            PENALTY_FACTOR = 5.0 # Example: A factor of 5.0\n\n            penalty = -PENALTY_FACTOR * normalized_fragment_rem\n            calculated_priorities[fragment_zone_mask] += penalty\n\n    # Assign the calculated priorities to the fitting bins in the main array\n    priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation builds on the \"Best Fit\" strategy but introduces a slight\n    preference for existing, partially filled bins over entirely new (empty) bins.\n    The goal is to encourage filling up bins already in use, potentially delaying\n    the opening of new bins, which can lead to fewer total bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The maximum capacity of a single bin. Default to 1.0,\n                      assuming item sizes are normalized relative to this capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 1. Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only consider bins where the item fits\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # 2. Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # 3. Base priority: Best Fit strategy (minimize remaining capacity)\n    # A smaller potential_remaining_cap (closer to 0) means a tighter fit,\n    # which is preferred. By taking the negative, we convert minimization\n    # to maximization for `np.argmax`.\n    # A perfect fit (potential_remaining_cap == 0) will result in a priority of 0,\n    # which is the highest possible score from this component.\n    base_priorities = -potential_remaining_cap\n\n    # 4. Mutation: Add a small bonus for choosing an already used bin over a fresh one.\n    # This slightly biases towards consolidating items into existing bins.\n    # The bonus value (e.g., 1e-6) should be carefully chosen. It must be\n    # small enough not to override a significantly better Best Fit (i.e., a\n    # much smaller potential_remaining_cap difference), but large enough\n    # to break ties or influence decisions when Best Fit scores are very close.\n    # For floating-point comparisons, a tolerance (e.g., np.finfo(float).eps * 10)\n    # is often used, but for simplicity and common BPP scenarios where `bin_capacity`\n    # is exactly 1.0 for fresh bins, direct comparison or `x < capacity` is often sufficient.\n    used_bin_bonus = 1e-6  # A small constant bonus\n\n    # Identify bins that are not \"fresh\" (i.e., not entirely empty/unused).\n    # A bin is considered 'used' if its remaining capacity is strictly less than the full capacity.\n    # Using np.isclose for robustness against floating-point inaccuracies when comparing to bin_capacity.\n    is_used_bin_mask = ~np.isclose(fitting_bins_remain_cap, bin_capacity)\n\n    # Apply the bonus only to bins that can fit the item AND are already used.\n    # This applies the bonus to the elements within the 'can_fit_mask' subset.\n    priorities[can_fit_mask] = base_priorities\n    priorities[can_fit_mask][is_used_bin_mask] += used_bin_bonus\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (6th), the best heuristic significantly improves upon a pure \"Best Fit\" by adding an \"Exact Fit Bonus\" and an \"Adaptive Fragmentation Penalty.\" This indicates that actively managing extreme outcomes (perfectly full bins or awkwardly fragmented ones) is more beneficial than just minimizing remaining capacity. The adaptive penalty, which scales with the current item's size, further refines this by making the penalty relevant to the context.\n\nComparing (1st) vs (4th), the 4th heuristic is a basic Best Fit scaled to produce positive scores. The superior performance of the 1st heuristic emphasizes that sophisticated, non-linear adjustments for specific bin states (like exact fits or near-full states) yield better results than merely transforming the linear Best Fit score.\n\nComparing (1st) vs (5th), both attempt consolidation. However, the 1st heuristic's \"Exact Fit Bonus\" and \"Fragmentation Penalty\" directly address the *outcome* of placing an item (filling exactly, or creating problematic remnants). The 5th's \"Consolidation Bonus\" scales with current fullness, but its small weight suggests it's a minor tie-breaker, less impactful than the targeted strategies in the 1st heuristic. This implies that managing final bin states is more critical than simply preferring already-used bins without considering the resulting space quality.\n\nComparing (6th) vs (7th/8th/10th), the simpler \"Best Fit\" (6th) surprisingly performs better than or equal to variants adding a tiny, fixed \"used bin bonus\" (7th/8th/10th). This suggests that a small, constant bonus for used bins isn't sufficiently impactful to consistently improve results beyond a solid Best Fit, or that the specific scenarios it helps with are less frequent or less critical than those addressed by the 1st heuristic.\n\nComparing (6th) vs (9th/11th), a pure \"Best Fit\" (6th) outperforms its slightly parameterized counterpart (9th/11th) which uses a `weight_remaining_cap` parameter. This indicates that merely parameterizing the linear component of Best Fit, or using a sub-optimal parameter value, does not necessarily improve performance over the standard Best Fit. The fixed `-1.0` implicit in pure Best Fit (6th) might already be near-optimal for this component.\n\nComparing (6th) vs (17th/18th/19th/20th), the basic \"Best Fit\" (6th) is significantly better than the \"Target Remainder Fit\" (17th-20th). This implies that, for general Bin Packing, aggressively minimizing the leftover space (Best Fit) is typically superior to trying to maintain a specific \"ideal\" non-zero remainder. The goal is usually to minimize the *number* of bins, which often means filling them as much as possible.\n\nComparing (12th/16th) vs all others, the worst heuristics assign zero priority to all fitting bins, essentially leading to an arbitrary or First Fit choice. This clearly demonstrates that *any* intelligent strategy for bin selection (even a simple Best Fit) is vastly superior to a non-strategic approach.\n- \n*   **Keywords:** Hybrid, Adaptive, Non-linear, State-aware, Space Quality, Bin Completion.\n*   **Advice:** Design heuristics by integrating robust baselines with **adaptive, non-linear rules** that intelligently respond to critical bin states (e.g., exact fits, problematic fragmentation). Strongly incentivize bin completion and focus on the *quality* of remaining space.\n*   **Avoid:** Limiting design to solely monotonic relationships or simple linear bonuses. Do not avoid non-linear transformations or dynamic weighting; embrace them to handle specific state-based challenges. Avoid static, hard-coded \"negative infinity\" penalties.\n*   **Explanation:** Superior heuristic performance arises from dynamic adaptation to problem states. Non-linear, state-dependent rules can capture complex interactions and objectives (like space quality or bin closure) that are missed by overly simplistic or rigidly linear approaches.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}