{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    \"Gravitational Collapse\" Heuristic for Online Bin Packing.\n\n    Drawing inspiration from the relentless pull of gravity that compacts matter\n    into the densest possible states, this heuristic prioritizes bins that, upon\n    accommodating the given item, would have the smallest remaining capacity.\n\n    This strategy encourages \"tight fits,\" aiming to fill bins as completely as\n    possible before their internal 'volume' reaches a critical point of collapse\n    (i.e., minimal remaining space). A bin achieving a 'perfect fit' (remaining\n    capacity exactly zero) is given the ultimate priority, akin to a final,\n    irreversible gravitational collapse.\n\n    Bins that are too small to contain the item are deemed outside the event\n    horizon and are given the lowest possible priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        Higher scores indicate a stronger gravitational pull towards selection.\n    \"\"\"\n    # Initialize all priorities to a state of infinite repulsion (negative infinity)\n    # for bins that cannot even theoretically contain the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify the 'regions of space-time' (bins) that can physically\n    # accommodate the incoming 'matter' (item).\n    can_fit_mask = bins_remain_cap >= item\n\n    # For those eligible regions, we calculate the remaining 'vacuum' (empty space)\n    # after the item is placed.\n    # A tiny epsilon ensures we don't divide by zero in the case of a 'perfect fit'\n    # where the remaining space is exactly zero, giving it the highest possible density score.\n    epsilon = np.finfo(float).eps\n\n    remaining_space_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # The 'gravitational pull' (priority) is inversely proportional to the\n    # remaining 'vacuum'. A smaller remaining space implies a denser state\n    # and thus a stronger pull for the item.\n    priorities[can_fit_mask] = 1.0 / (remaining_space_after_fit + epsilon)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), both implement the \"Best Fit\" heuristic by prioritizing bins that will have the smallest remaining capacity. The core logic of assigning `-potential_remaining_cap` as priority and `-np.inf` for non-fitting bins is identical. The subtle difference lies in the order of operations: Heuristic 1st calculates `potential_remaining_cap` only for fitting bins after masking, while Heuristic 2nd calculates it for all bins first, then masks for assignment. The higher ranking of 1st suggests that masking *before* subtraction, potentially reducing the size of the temporary array for calculation, might offer a marginal performance or memory advantage in specific scenarios.\n\nComparing (2nd) vs (3rd), both aim for tight fits. Heuristic 2nd uses a direct linear negation (`-remaining_capacity`) for priority, while Heuristic 3rd uses an inverse relationship (`1.0 / (remaining_capacity + epsilon)`). The ranking indicates that the linear negation approach is superior. The non-linear inverse, while aiming to heavily favor tight fits, likely struggles due to the `epsilon` term (which introduces a fixed offset and can blur distinctions between very small non-zero remainders) or simply provides a less effective gradient for decision-making compared to the simple linear mapping.\n\nComparing (3rd) vs (4th), these two heuristics are functionally identical in their source code, docstrings, and comments. Their differing ranks suggest either non-deterministic performance variations in evaluation or an arbitrary distinction within the ranking of similar performing heuristics.\n\nComparing (10th) vs (11th), Heuristic 10th still correctly implements a \"Best Fit\" strategy, differentiating between bins and correctly assigning `-np.inf` for impossible fits. In contrast, Heuristic 11th returns a constant array of zeros, effectively providing no intelligent prioritization and failing to mark impossible fits. This highlights the critical importance of having any intelligent heuristic logic that correctly prioritizes and handles infeasibility, as even a basic \"Best Fit\" performs vastly better than a null operation.\n\nOverall, the list shows a clear hierarchy: sophisticated Best Fit variants (1st-10th) are superior to Best Fit variants with less optimal mathematical transformations (3rd-4th), which are in turn vastly superior to non-functional or non-prioritizing heuristics (11th-20th).\n- \nHere's a redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Transparency, Robustness, Simplicity, Iteration.\n*   **Advice:** Prioritize designs with clear, monotonic objective function relationships. Explicitly handle all feasibility constraints. Favor simpler linear logic over complex non-linearities unless thoroughly validated. Systematically build from robust baselines.\n*   **Avoid:** Obscure, non-interpretable logic; implicit or ignored constraint handling; arbitrary \"magic numbers\" or unverified transformations; and trying to leapfrog foundational improvements.\n*   **Explanation:** Effective self-reflection focuses on creating transparent, robust, and incrementally improvable heuristics by valuing clarity and systematic development over unproven complexity.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}