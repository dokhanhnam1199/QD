{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims for a \"Hybrid Fit\" strategy, building upon Best Fit\n    by incorporating multi-objective considerations and non-linear scoring.\n    It prioritizes:\n    1.  **Perfect or Near-Perfect Fits:** Maximizing the chance of completely filling a bin\n        to reduce the total number of active bins and eliminate fragmentation.\n    2.  **Best Fit:** After perfect fits, it reverts to the standard Best Fit strategy\n        of minimizing the remaining capacity.\n    3.  **Fragment Avoidance:** It penalizes bins that, after placement, would be left\n        with a very small, \"awkward\" amount of space that is unlikely to be useful\n        for subsequent items (e.g., too small for most items, but not zero).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n                         Assumes capacities and item sizes are normalized or\n                         consistent in their units.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Find bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        # No bin can fit the item, return -inf for all (or new bin logic handled externally)\n        return priorities\n\n    # Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # --- Tunable Parameters for the Hybrid Fit Heuristic ---\n    # These parameters are crucial for balancing the different objectives.\n    # They might require tuning based on the specific distribution of item sizes\n    # and bin capacity in your problem instance.\n\n    # EPSILON_PERFECT_FIT: A small tolerance for floating point comparisons to\n    # consider a bin \"perfectly\" filled. If remaining capacity is within this,\n    # it's considered a perfect fit.\n    EPSILON_PERFECT_FIT = 1e-9\n\n    # TINY_REMAINDER_THRESHOLD: The upper bound for what is considered a \"tiny\"\n    # or \"awkward\" remaining capacity. If a bin's remaining capacity falls\n    # between EPSILON_PERFECT_FIT and this threshold, it incurs a penalty.\n    # This value typically corresponds to a small fraction of the bin's total capacity.\n    # For example, if bin capacity is 1.0, 0.05 means 5% of capacity.\n    TINY_REMAINDER_THRESHOLD = 0.05\n\n    # PERFECT_FIT_BONUS: A large positive bonus applied to bins that achieve\n    # a perfect or near-perfect fit. This should be high enough to make perfect\n    # fits almost always the top priority.\n    PERFECT_FIT_BONUS = 1000.0\n\n    # TINY_REMAINDER_PENALTY: A significant negative penalty applied to bins\n    # that are left with a tiny, potentially unusable remainder. This pushes\n    # the algorithm away from creating such fragmented bins.\n    TINY_REMAINDER_PENALTY = 500.0\n\n    # --- Apply the scoring logic ---\n    # 1. Base Score: Best Fit (minimize remaining capacity)\n    #    A smaller positive remaining capacity results in a larger (less negative) base score.\n    current_priorities = -potential_remaining_cap\n\n    # 2. Perfect/Near-Perfect Fit Bonus\n    #    Identify bins where remaining capacity is very close to zero.\n    perfect_fit_mask = potential_remaining_cap <= EPSILON_PERFECT_FIT\n    current_priorities[perfect_fit_mask] += PERFECT_FIT_BONUS\n\n    # 3. Tiny Remainder Penalty\n    #    Identify bins where remaining capacity is small but not zero (a \"dead zone\").\n    #    Ensure these are not already marked as perfect fits.\n    tiny_remainder_mask = (potential_remaining_cap > EPSILON_PERFECT_FIT) & \\\n                          (potential_remaining_cap < TINY_REMAINDER_THRESHOLD)\n    current_priorities[tiny_remainder_mask] -= TINY_REMAINDER_PENALTY\n\n    # Assign the calculated priorities back to the main priorities array\n    priorities[can_fit_mask] = current_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (1st) vs (11th-15th), we observe that the best heuristic (1st) leverages a refined \"Best Fit\" strategy by adding a small, fixed bonus for partially filled bins, aiming to consolidate items and delay opening new bins. In stark contrast, the worst heuristics (11th-15th) return `np.zeros_like`, effectively making a random choice among bins that can fit an item, demonstrating a complete lack of intelligent prioritization.\n\nComparing (2nd/10th) vs (16th-20th), the second-best heuristics (2nd/10th) implement a pure \"Best Fit\" strategy, prioritizing the tightest possible fit to minimize remaining bin capacity. This simple, effective approach often leads to good packing density. The second-worst heuristics (16th-20th), \"Target Remainder Fit,\" aim to leave a predefined target amount of space in bins. While conceptually advanced, this strategy often performs worse than Best Fit for minimizing bin count because it prioritizes leaving \"useful\" space over tight packing, which can lead to more bins being used or less optimal utilization overall.\n\nComparing (1st) vs (2nd/10th), the primary difference is the `used_bin_bonus` in 1st. While 2nd/10th strictly minimize remaining capacity, 1st introduces a tiny preference for existing, partially filled bins. This subtle bias in 1st encourages consolidation, which can lead to fewer total bins compared to pure Best Fit by slightly prioritizing filling an already-opened bin over opening a new one that might offer an almost identical (but infinitesimally better) fit. This minor, well-controlled perturbation seems to yield better results.\n\nComparing (3rd) vs (4th), 4th is functionally identical to 1st (Best Fit with a small consolidation bonus) and is ranked much higher than 3rd. Heuristic 3rd attempts a \"Hybrid Fit\" with large, hard-coded bonuses for perfect fits and penalties for \"tiny remainders.\" This indicates that overly complex heuristics with aggressive, fixed magnitude parameters can perform worse than simpler, more robust Best Fit variants. The large parameter values in 3rd (`PERFECT_FIT_BONUS=1000.0`, `TINY_REMAINDER_PENALTY=500.0`) can drastically distort the priority landscape, leading to non-optimal decisions without careful, instance-specific tuning.\n\nComparing (second worst: 16th-20th) vs (worst: 11th-15th), the \"Target Remainder Fit\" heuristics (16th-20th) at least attempt a coherent (though often suboptimal for bin minimization) strategy. They involve calculations based on potential remaining capacity and a target. In contrast, the `np.zeros_like` heuristics (11th-15th) provide no decision-making logic, leading to random or arbitrary bin assignments, which is demonstrably the least effective approach for an optimization problem. The Target Remainder Fit, while performing poorly here, is still a structured heuristic, unlike the \"no-op\" of returning zeros.\n- \nHere's a redefinition of 'Current self-reflection', explicitly avoiding the points from 'Ineffective self-reflection':\n\n*   **Keywords:** Adaptive, Emergent, Hybrid, Non-linear, Learning, Meta-heuristics.\n*   **Advice:** Design heuristics where global efficacy arises from local, non-linear interactions. Integrate adaptive components that learn from solution progress or problem characteristics. Explore hybrid strategies combining diverse principles.\n*   **Avoid:** Limiting design to strictly monotonic, linear relationships or fixed, small-magnitude bonuses. Over-reliance on single, static baselines. Shying away from complex parameter spaces or non-obvious transformations.\n*   **Explanation:** This approach leverages emergent properties and dynamic adaptation, moving beyond rigid, pre-defined rules. It embraces computational complexity and advanced tuning to uncover superior, context-aware solutions that fixed, simple methods often miss.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}