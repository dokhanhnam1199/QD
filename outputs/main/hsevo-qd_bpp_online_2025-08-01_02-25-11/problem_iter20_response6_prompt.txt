{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation builds on the \"Best Fit\" strategy but introduces a slight\n    preference for existing, partially filled bins over entirely new (empty) bins.\n    The goal is to encourage filling up bins already in use, potentially delaying\n    the opening of new bins, which can lead to fewer total bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The maximum capacity of a single bin. Default to 1.0,\n                      assuming item sizes are normalized relative to this capacity.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 1. Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only consider bins where the item fits\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # 2. Calculate remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # 3. Base priority: Best Fit strategy (minimize remaining capacity)\n    # A smaller potential_remaining_cap (closer to 0) means a tighter fit,\n    # which is preferred. By taking the negative, we convert minimization\n    # to maximization for `np.argmax`.\n    # A perfect fit (potential_remaining_cap == 0) will result in a priority of 0,\n    # which is the highest possible score from this component.\n    base_priorities = -potential_remaining_cap\n\n    # 4. Mutation: Add a small bonus for choosing an already used bin over a fresh one.\n    # This slightly biases towards consolidating items into existing bins.\n    # The bonus value (e.g., 1e-6) should be carefully chosen. It must be\n    # small enough not to override a significantly better Best Fit (i.e., a\n    # much smaller potential_remaining_cap difference), but large enough\n    # to break ties or influence decisions when Best Fit scores are very close.\n    # For floating-point comparisons, a tolerance (e.g., np.finfo(float).eps * 10)\n    # is often used, but for simplicity and common BPP scenarios where `bin_capacity`\n    # is exactly 1.0 for fresh bins, direct comparison or `x < capacity` is often sufficient.\n    used_bin_bonus = 1e-6  # A small constant bonus\n\n    # Identify bins that are not \"fresh\" (i.e., not entirely empty/unused).\n    # A bin is considered 'used' if its remaining capacity is strictly less than the full capacity.\n    # Using np.isclose for robustness against floating-point inaccuracies when comparing to bin_capacity.\n    is_used_bin_mask = ~np.isclose(fitting_bins_remain_cap, bin_capacity)\n\n    # Apply the bonus only to bins that can fit the item AND are already used.\n    # This applies the bonus to the elements within the 'can_fit_mask' subset.\n    priorities[can_fit_mask] = base_priorities\n    priorities[can_fit_mask][is_used_bin_mask] += used_bin_bonus\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which to add an item to each bin.\n\n    This implementation aims for a \"Target Remainder Fit\" strategy. It seeks to\n    assign an item to a bin such that the bin's remaining capacity after placement\n    is close to a predefined 'ideal' target value. This approach is more adaptive\n    and holistic than a simple Best Fit, as it manages the distribution of\n    remaining bin capacities, potentially leaving more \"useful\" space for\n    future items and promoting a more diverse set of bin states.\n\n    The 'ideal_remainder_ratio' parameter determines the target remaining capacity\n    as a fraction of the total bin capacity. A value of 0.0 would revert to a\n    pure Best Fit (minimizing remaining capacity). A value closer to 1.0 would\n    lean towards Worst Fit (maximizing remaining capacity). A moderate value\n    (e.g., 0.25) attempts to maintain a balanced bin state.\n\n    Assumptions:\n    1. The problem implies a fixed `BIN_CAPACITY` for all bins. Since it's not\n       an explicit argument, we infer it from `bins_remain_cap`. In online BPP,\n       new bins are typically added at full capacity. Therefore, `np.max(bins_remain_cap)`\n       is used as a reasonable proxy for `BIN_CAPACITY`, assuming at least one\n       bin is either empty (full capacity) or has the largest possible remaining capacity.\n       For extreme edge cases (e.g., all bins are almost full and no new empty bin has been opened yet),\n       this inference might be inaccurate, but it's a common practical approach.\n    2. `item` and `bins_remain_cap` values are in consistent units.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Handle case where no bins are available or bins_remain_cap is empty\n    if bins_remain_cap.size == 0:\n        return priorities\n\n    # Infer BIN_CAPACITY from the maximum remaining capacity among current bins.\n    # This assumes that at least one \"fresh\" bin (with full capacity) is or was available,\n    # or that the maximum value represents the standard bin capacity.\n    BIN_CAPACITY = np.max(bins_remain_cap)\n    if BIN_CAPACITY == 0: # Avoid division by zero if all bins are exactly 0 capacity\n        return priorities # No item can fit anywhere\n\n    # Define the ideal remaining capacity ratio after placing an item.\n    # This is a key heuristic parameter for tuning:\n    # 0.0 for Best Fit, ~0.2-0.3 for a more balanced \"middle-fit\".\n    ideal_remainder_ratio = 0.25\n    TARGET_REMAINDER = BIN_CAPACITY * ideal_remainder_ratio\n\n    # Find bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item were placed in fitting bins\n    potential_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate priority based on the absolute difference from the TARGET_REMAINDER.\n    # We want to minimize this absolute difference, so we take its negative.\n    # This means bins whose `potential_remaining_cap` is closest to `TARGET_REMAINDER`\n    # will receive the highest priority.\n    priorities[can_fit_mask] = -np.abs(potential_remaining_cap - TARGET_REMAINDER)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (4th), we see a significant jump in heuristic sophistication. The top-ranked (1st) introduces an \"aggressively incentivized\" exponential exact-fit bonus (magnitude 5000.0, decay 50.0), a \"Valley of Despair\" fragmentation penalty shaped like a negative Gaussian curve (peaking at 40% of item size), and a \"Quality of Large Remaining Space Bonus\" (logarithmic). In contrast, (4th) uses a discrete exact fit bonus (1000.0) and a simpler linear fragmentation penalty (proportional to normalized remainder, up to item size). The non-linear, adaptive components in (1st) provide far more nuanced control over bin states, encouraging aggressive bin closure and intelligent space management beyond simple minimization.\n\nComparing (4th) vs (8th), the fragmentation penalty shifts from a linearly scaled penalty based on `normalized_fragment_rem` (in 4th) to a fixed `TINY_REMAINDER_PENALTY` applied if the remainder is below `TINY_REMAINDER_THRESHOLD` (in 8th). The exact fit bonus is discrete and high in both (1000.0). The explicit threshold-based penalty in (8th) is simpler but less adaptive than the item-size-normalized linear penalty in (4th), which is itself less sophisticated than the Gaussian penalty in (1st). The higher performance of (4th) suggests its fragmentation handling, though linear, is more effective than a simple \"tiny remainder\" threshold.\n\nComparing (8th) vs (9th), (8th) employs a \"Hybrid Fit\" with a \"Perfect/Near-Perfect Fit Bonus\" and a \"Tiny Remainder Penalty\", while (9th) is a pure \"Best Fit\" strategy, prioritizing only the smallest remaining capacity. The clear improvement from (9th) to (8th) highlights the critical importance of explicitly incentivizing bin completion and penalizing awkward fragment creation.\n\nComparing (9th) vs (13th), both start with a \"Best Fit\" core. (13th) adds a small `used_bin_bonus` (1e-6) to prefer existing, partially filled bins over new ones. This subtle consolidation preference in (13th) leads to better performance than plain Best Fit (9th), indicating that even a minor bias towards existing bins can be beneficial for reducing the total bin count.\n\nComparing (13th) vs (14th), both aim for \"Best Fit\" plus a \"Consolidation Bonus\". (13th) explicitly takes `bin_capacity` as an argument and uses a very small `used_bin_bonus` of 1e-6. (14th) infers `BIN_CAPACITY` from `np.max(bins_remain_cap)` and uses a larger `CONSOLIDATION_BONUS` of 0.01. The stronger consolidation bias and adaptive `BIN_CAPACITY` inference in (14th) likely contribute to its better performance.\n\nComparing (14th) vs (20th), (14th) utilizes Best Fit plus a consolidation bonus, whereas (20th) implements a \"Target Remainder Fit\", aiming to leave a specific `ideal_remainder_ratio` (hardcoded 0.25) of the bin capacity. The higher ranking of (14th) suggests that a combination of Best Fit and consolidation is generally more robust and effective than solely targeting an ideal remainder, which might lead to suboptimal packing if the chosen target isn't universally beneficial across different item sizes.\n\nComparing (20th) vs (16th), (20th) attempts a \"Target Remainder Fit\" by minimizing the absolute difference from a target remaining capacity. In stark contrast, (16th) simply returns `np.zeros_like`, assigning equal priority to all fitting bins, which is equivalent to an arbitrary selection (e.g., First Fit). The functional strategy in (20th), despite its specific approach, vastly outperforms the null strategy of (16th).\n\nComparing (1st/2nd/3rd) with each other, they are identical code snippets. The same applies to (4th/5th/6th), (7th/10th), (8th/11th), (9th/12th), (14th/15th), (16th/17th), and (18th/19th). This suggests that the ranking differences within these identical groups are negligible or due to external factors not present in the code.\n\nOverall: The best heuristics employ a multi-faceted approach, balancing immediate best fit with future bin state management. This includes strong incentives for bin completion, nuanced penalties for fragmentation, and strategies for maintaining useful large spaces. Non-linear, adaptive functions are crucial for expressing these complex preferences. Simple Best Fit is a good baseline, but more sophisticated additions consistently improve performance. Purely arbitrary choices are the worst.\n- \n*   **Keywords:** Adaptive, Non-linear, Hybrid, State-aware, Quality-of-space.\n*   **Advice:** Design hybrid heuristics with adaptive, non-linear rules targeting critical bin states (completion, fragmentation). Use functions like exponential/Gaussian/logarithmic for specific incentives. Prioritize remaining space *quality* via tunable parameters.\n*   **Avoid:** Sole reliance on monotonic/linear relationships, simple additive bonuses, or shying away from non-linear complexity. Do not over-emphasize basic greedy without state awareness of bin characteristics.\n*   **Explanation:** Non-linear, state-aware functions capture nuanced problem dynamics, providing precise incentives/penalties (e.g., sharp fragmentation costs, strong completion bonuses) that linear or overly simplistic approaches miss, yielding superior solutions.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}