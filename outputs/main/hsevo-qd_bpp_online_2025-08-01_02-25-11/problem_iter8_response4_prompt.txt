{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority for 'Best Fit' by maximizing the effective filled capacity.\n\n    Prioritizes bins that achieve the highest fill level after placing the item,\n    yielding positive scores for valid fits and penalizing impossible ones.\n    \"\"\"\n    # Initialize all priorities to an extremely low value, ensuring bins that cannot\n    # accommodate the item are never selected.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify which bins possess sufficient remaining capacity for the item.\n    fits_mask = bins_remain_cap >= item\n\n    # For bins where the item demonstrably fits, calculate a priority score.\n    # This score, 2 * item - bins_remain_cap[fits_mask], maximizes the resulting\n    # effective filled capacity relative to the item's size. A perfect fit\n    # (where the bin's remaining capacity becomes zero) yields the highest positive\n    # score (equal to `item`), while less efficient fits yield lower positive scores.\n    # This combines the efficiency of masking first with a positive-scaled Best Fit score.\n    priorities[fits_mask] = 2 * item - bins_remain_cap[fits_mask]\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- *   **Comparing (1st/2nd) vs (3rd/9th):** Both employ a \"Best Fit\" strategy augmented with a \"Consolidation Bonus\" to favor partially filled bins. The primary difference lies in the `CONSOLIDATION_BONUS` magnitude (0.01 in 1st/2nd vs. 1e-6 in 3rd/9th) and the method of determining `BIN_CAPACITY` (inferred from `np.max` in 1st/2nd vs. explicit argument with `np.isclose` for robustness in 3rd/9th). The higher ranking of 1st/2nd suggests that a more substantial bonus (0.01) is more effective than a very small one (1e-6) at encouraging beneficial consolidation without unduly disrupting the Best Fit principle.\n*   **Comparing (3rd/9th) vs (4th):** Heuristics 3rd and 9th are identical, adding a `1e-6` consolidation bonus to a Best Fit strategy. Heuristic 4th is a pure Best Fit implementation, maximizing the negative of the potential remaining capacity (`-potential_remaining_cap`). The higher ranking of 3rd/9th over 4th indicates that even a small consolidation bonus is generally beneficial compared to a strict Best Fit, as it helps reduce the total number of bins by prioritizing existing ones.\n*   **Comparing (4th) vs (5th/6th/8th):** Heuristic 4th calculates Best Fit using `-potential_remaining_cap`. Heuristics 5th, 6th, and 8th are identical, also implementing Best Fit but via `2 * item - bins_remain_cap`. Both methods correctly rank bins by tightness of fit. The higher ranking of 4th suggests that its specific scoring range (0 for perfect fit, decreasing for worse fits) or numerical behavior is marginally more effective or stable than the alternative scoring, which uses `item` for perfect fit and decreases from there.\n*   **Comparing (5th/6th/8th) vs (7th/10th):** Heuristics 5th, 6th, and 8th represent a standard Best Fit approach. Heuristics 7th and 10th are identical and represent a parameterized Best Fit strategy, where the weighting of `potential_remaining_cap` and the `priority_no_fit` constant are explicitly passed with seemingly \"tuned\" floating-point values (e.g., `weight_remaining_cap = -0.493...`). The lower ranking of 7th/10th indicates that these specific tuned parameters perform worse than the simpler, standard Best Fit approaches. This suggests either the tuning process was suboptimal, or the specific values don't generalize well, or that deviating from a simple `-1.0` weight for `potential_remaining_cap` is detrimental.\n*   **Comparing (7th/10th) vs (11th-20th):** Heuristics 7th and 10th represent a sub-optimal but still functional Best Fit variant. Heuristics 11th through 20th are all identical, returning a zero-filled array, meaning all bins are considered equally preferable (or effectively random selection among fitting bins). This demonstrates that any form of intelligent packing, even if sub-optimally tuned, is significantly better than a completely unprioritized or arbitrary selection of bins.\n*   **Overall:** The best heuristics strategically combine Best Fit with a consolidation bonus, with the magnitude of the bonus being crucial for performance. Pure Best Fit strategies are strong baselines, and their precise scoring formula can have subtle impacts. Parameterized heuristics, while theoretically flexible, can perform poorly if the parameters are not optimally chosen or if the tuning objective doesn't perfectly align with the problem's goal. Completely unprioritized bin selection is the worst approach.\n- \nHere's a redefinition of self-reflection, focusing on principles for better heuristics:\n\n*   **Keywords:** Adaptive Priorities, Non-linear Functions, Exploration, Multi-objective.\n*   **Advice:** Prioritize dynamic, non-linear scoring systems that adapt to solution progression. Integrate controlled exploration, even if it means temporary non-greedy choices. Embrace complex numerical transformations and intricate parameter tuning. Consider multi-objective optimization beyond immediate \"waste\" minimization.\n*   **Avoid:** Static or strictly monotonic priority relationships. Sole reliance on simple greedy strategies. Ignoring the potential of non-linear \"tricks\" or complex interactions. A singular, myopic objective like minimal remaining space.\n*   **Explanation:** Sophisticated, adaptive decision models, coupled with strategic exploration and nuanced objective functions, can reveal richer solution landscapes and overcome limitations of simpler, fixed heuristics.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}