{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority for bin selection, combining Best Fit with a consolidation bonus.\n\n    Prioritizes bins that offer the tightest fit, adding a small bonus for\n    partially-filled bins to encourage consolidation and reduce new bin openings.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 1. Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Get remaining capacities for only the bins that can fit the item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    if fitting_bins_remain_cap.size == 0:\n        return priorities # No bin can fit the item, return all -inf priorities\n\n    # 2. Calculate potential remaining capacity if item were placed in fitting bins\n    potential_remaining_cap = fitting_bins_remain_cap - item\n\n    # 3. Base priority: Best Fit strategy (minimize remaining capacity)\n    # A smaller potential_remaining_cap (closer to 0) means a tighter fit,\n    # which is preferred. By taking the negative, we convert minimization\n    # to maximization for `np.argmax`. A perfect fit (0 remaining) gets a 0 score here.\n    base_priorities_for_fitting_bins = -potential_remaining_cap\n\n    # 4. Consolidation Bonus: Add a small bonus for choosing an already used bin.\n    # This encourages filling existing bins before opening new ones, potentially saving bins.\n    # The value (e.g., 1e-6) should be small enough not to override a significantly\n    # better \"Best Fit\" (i.e., a much smaller potential_remaining_cap difference),\n    # but large enough to break ties or influence decisions when Best Fit scores are very close.\n    used_bin_bonus = 1e-6\n\n    # Identify bins that are 'used' (i.e., not entirely empty/fresh).\n    # A bin is considered 'used' if its remaining capacity is strictly less than the full bin_capacity.\n    # Using np.isclose for robustness against floating-point inaccuracies when comparing to bin_capacity.\n    is_used_bin_mask = ~np.isclose(fitting_bins_remain_cap, bin_capacity)\n\n    # Apply the bonus only to bins that can fit the item AND are already used.\n    # This modifies the base priorities for the subset of fitting bins.\n    base_priorities_for_fitting_bins[is_used_bin_mask] += used_bin_bonus\n\n    # Assign the calculated priorities back to the main priorities array for the fitting bins\n    priorities[can_fit_mask] = base_priorities_for_fitting_bins\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- *   **Comparing (1st/2nd) vs (3rd/9th):** Both employ a \"Best Fit\" strategy augmented with a \"Consolidation Bonus\" to favor partially filled bins. The primary difference lies in the `CONSOLIDATION_BONUS` magnitude (0.01 in 1st/2nd vs. 1e-6 in 3rd/9th) and the method of determining `BIN_CAPACITY` (inferred from `np.max` in 1st/2nd vs. explicit argument with `np.isclose` for robustness in 3rd/9th). The higher ranking of 1st/2nd suggests that a more substantial bonus (0.01) is more effective than a very small one (1e-6) at encouraging beneficial consolidation without unduly disrupting the Best Fit principle.\n*   **Comparing (3rd/9th) vs (4th):** Heuristics 3rd and 9th are identical, adding a `1e-6` consolidation bonus to a Best Fit strategy. Heuristic 4th is a pure Best Fit implementation, maximizing the negative of the potential remaining capacity (`-potential_remaining_cap`). The higher ranking of 3rd/9th over 4th indicates that even a small consolidation bonus is generally beneficial compared to a strict Best Fit, as it helps reduce the total number of bins by prioritizing existing ones.\n*   **Comparing (4th) vs (5th/6th/8th):** Heuristic 4th calculates Best Fit using `-potential_remaining_cap`. Heuristics 5th, 6th, and 8th are identical, also implementing Best Fit but via `2 * item - bins_remain_cap`. Both methods correctly rank bins by tightness of fit. The higher ranking of 4th suggests that its specific scoring range (0 for perfect fit, decreasing for worse fits) or numerical behavior is marginally more effective or stable than the alternative scoring, which uses `item` for perfect fit and decreases from there.\n*   **Comparing (5th/6th/8th) vs (7th/10th):** Heuristics 5th, 6th, and 8th represent a standard Best Fit approach. Heuristics 7th and 10th are identical and represent a parameterized Best Fit strategy, where the weighting of `potential_remaining_cap` and the `priority_no_fit` constant are explicitly passed with seemingly \"tuned\" floating-point values (e.g., `weight_remaining_cap = -0.493...`). The lower ranking of 7th/10th indicates that these specific tuned parameters perform worse than the simpler, standard Best Fit approaches. This suggests either the tuning process was suboptimal, or the specific values don't generalize well, or that deviating from a simple `-1.0` weight for `potential_remaining_cap` is detrimental.\n*   **Comparing (7th/10th) vs (11th-20th):** Heuristics 7th and 10th represent a sub-optimal but still functional Best Fit variant. Heuristics 11th through 20th are all identical, returning a zero-filled array, meaning all bins are considered equally preferable (or effectively random selection among fitting bins). This demonstrates that any form of intelligent packing, even if sub-optimally tuned, is significantly better than a completely unprioritized or arbitrary selection of bins.\n*   **Overall:** The best heuristics strategically combine Best Fit with a consolidation bonus, with the magnitude of the bonus being crucial for performance. Pure Best Fit strategies are strong baselines, and their precise scoring formula can have subtle impacts. Parameterized heuristics, while theoretically flexible, can perform poorly if the parameters are not optimally chosen or if the tuning objective doesn't perfectly align with the problem's goal. Completely unprioritized bin selection is the worst approach.\n- \nHere's a redefinition of self-reflection, focusing on principles for better heuristics:\n\n*   **Keywords:** Adaptive Priorities, Non-linear Functions, Exploration, Multi-objective.\n*   **Advice:** Prioritize dynamic, non-linear scoring systems that adapt to solution progression. Integrate controlled exploration, even if it means temporary non-greedy choices. Embrace complex numerical transformations and intricate parameter tuning. Consider multi-objective optimization beyond immediate \"waste\" minimization.\n*   **Avoid:** Static or strictly monotonic priority relationships. Sole reliance on simple greedy strategies. Ignoring the potential of non-linear \"tricks\" or complex interactions. A singular, myopic objective like minimal remaining space.\n*   **Explanation:** Sophisticated, adaptive decision models, coupled with strategic exploration and nuanced objective functions, can reveal richer solution landscapes and overcome limitations of simpler, fixed heuristics.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}