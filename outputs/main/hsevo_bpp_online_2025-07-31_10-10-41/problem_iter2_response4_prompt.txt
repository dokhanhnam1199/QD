{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add an item to each bin,\n    inspired by a Best-Fit decreasing-gap strategy for optimal packing.\n\n    As a scientist, I sought to organize and utilize every resource with utmost efficiency.\n    This heuristic embodies that principle by prioritizing the bins that, after accommodating\n    the current item, will have the least remaining \"empty\" space. This minimizes the\n    \"radioactive waste\" of unused capacity in bins, leading to a tighter overall packing\n    and fewer bins utilized, much like carefully isolating a new element into the smallest\n    effective container. Bins unable to contain the item are, of course, discarded from\n    consideration.\n\n    Args:\n        item: Size of item to be added to the bin. This is the \"activity\" of our element.\n        bins_remain_cap: Array of capacities for each bin. These are our \"containers\".\n\n    Return:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        A higher score indicates a more desirable bin.\n    \"\"\"\n    # Initialize all priorities to a very low value (effectively ruling out non-viable bins).\n    # Just as an empty flask cannot contain a sample.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Create a mask for bins that can physically accommodate the item.\n    # We must only consider containers that are large enough.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, calculate their score.\n    # The goal is to minimize the remaining capacity (bins_remain_cap - item) after placement.\n    # To achieve this with a \"highest score wins\" selection, we maximize the negative of\n    # the remaining capacity: -(bins_remain_cap - item), which simplifies to (item - bins_remain_cap).\n    # A perfect fit (bins_remain_cap == item) results in a score of 0.0, which is the highest\n    # possible score, signifying the most efficient use of space. All other valid fits\n    # will result in negative scores, with smaller absolute values indicating tighter fits.\n    priorities[can_fit_mask] = item - bins_remain_cap[can_fit_mask]\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    \n    Inspired by quantum phenomena, this heuristic views the packing problem \n    as an optimization of \"potential energy.\" Bins that offer a \"snug fit\" \n    for the item, leaving minimal wasted space, are highly preferred. \n    A perfect fit represents the lowest potential energy state and thus \n    the highest probability (priority) for the item to settle there.\n\n    Specifically, the priority is calculated using an exponential decay function:\n    Priority = exp(-(remaining_capacity - item_size)) for bins where the item fits.\n    This means:\n    - A perfect fit (remaining_capacity - item_size = 0) results in a priority of 1.0 (e^0).\n    - As the \"wasted space\" (remaining_capacity - item_size) increases, the priority \n      decreases exponentially towards zero.\n    - Bins where the item does not fit receive a priority of negative infinity.\n\n    This \"fuzzy Best Fit\" approach smoothly quantifies the desirability of each bin, \n    preferring efficiency while still distinguishing between different levels of \"goodness.\"\n\n    Args:\n        item: Size of item to be added to the bin. Assumed to be a positive float.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    \n    # Items in Bin Packing are typically positive. If a non-positive item were given,\n    # it defies the problem context. Assign lowest priority to all bins.\n    if item <= 0:\n        return np.full_like(bins_remain_cap, -np.inf)\n\n    # Initialize priorities to a very low value, representing \"cannot fit\" or \"undesirable\".\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins where the item *can* fit\n    fits_mask = bins_remain_cap >= item\n\n    # Calculate the 'wasted space' if the item were placed in each fitting bin.\n    # This is the difference: (bin_remaining_capacity - item_size).\n    # We want to minimize this difference for higher priority.\n    wasted_space_for_fits = bins_remain_cap[fits_mask] - item\n\n    # Apply the exponential priority function.\n    # We use -wasted_space to ensure smaller wasted space leads to higher exp value (closer to 1.0).\n    # exp(0) = 1.0 (perfect fit), exp(-small_positive) < 1.0 (snug fit), exp(-large_positive) ~ 0 (loose fit).\n    priorities[fits_mask] = np.exp(-wasted_space_for_fits)\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1st, 2nd, 3rd, 5th, 6th, 7th, 8th, 9th, 10th: These heuristics are functionally identical, all implementing the classic \"Best Fit\" strategy. They assign a priority as the negative of the remaining capacity after placing the item (`-(bins_remain_cap - item)`). A perfect fit results in a priority of 0, while larger remaining capacities yield increasingly negative priorities. The differences among them are purely cosmetic (docstrings, comments, variable names) or minor syntactic variations (e.g., using `np.where` vs. direct boolean masking), which do not alter the core logic. Their consistent high ranking indicates the strong efficacy and robustness of this specific linear priority function.\n\nComparing 1st (Best Fit) vs 4th (Feynman): The 1st heuristic uses a linear negative relationship to remaining space, while the 4th heuristic uses an inverse relationship: `1.0 / (remaining_space + 1e-9)`. This inverse function creates a significantly non-linear priority scaling. A perfect fit receives an extremely high priority, and priorities drop off very steeply even for slightly larger remaining capacities. The fact that the 4th heuristic is ranked lower suggests that this aggressive, non-linear amplification of \"best fits\" might be detrimental. It could lead to a greedy approach that is too focused on immediate, near-perfect fits, potentially preventing better overall packing by leaving less optimal but still viable options for subsequent items.\n\nComparing 1st (Best Fit) vs 11th-20th (Quantum): While the 1st heuristic maintains a linear negative priority, the 11th-20th heuristics employ an exponential decay function: `np.exp(-(remaining_capacity - item))`. This also introduces a non-linear weighting, where a perfect fit yields a priority of 1.0, and values decay exponentially towards zero for looser fits. The consistently lower ranking of this exponential approach compared to the linear Best Fit suggests that this smoother, non-linear decay also performs worse. It might not differentiate sufficiently among various levels of \"goodness\" for non-perfect fits, or its curve might not align optimally with the problem's combinatorial nature, leading to suboptimal overall solutions.\n\nOverall: The results strongly demonstrate that the classic Best Fit heuristic, which uses a simple linear inverse relationship between priority and remaining capacity, is empirically superior for this bin packing scenario. Non-linear transformations of the priority function (like inverse or exponential scaling) appear to degrade performance, likely by distorting the relative desirability of bins in a way that doesn't lead to optimal global packing.\n- \nHere's a redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Directness, Robustness, Interpretability, Proportionality.\n*   **Advice:** Design heuristics with simple, direct functions linearly proportional to key problem objectives. Prioritize interpretability and robustness; add complexity incrementally only if clear performance gains are proven.\n*   **Avoid:** Arbitrary non-linear weighting or excessive parameterization without strong theoretical justification. Such approaches often introduce fragility, obscure decision logic, and hinder generalizability.\n*   **Explanation:** Best Fit's robustness underscores that transparent, proportional relationships to problem state (e.g., remaining capacity) yield superior performance across diverse instances. Non-linearities can often distort this, leading to brittle or sub-optimal decision-making.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}