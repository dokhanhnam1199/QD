{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    As Isaac Newton, I view the Universe, and indeed problems such as Bin Packing,\n    as systems that strive towards an optimal state of arrangement and efficiency.\n    My heuristic for prioritizing bins is inspired by the principle of 'Best Fit',\n    which in my physical understanding, aligns with minimizing potential energy\n    or waste within a system.\n\n    Imagine each bin as a potential well, and the item as a body seeking to fall\n    into the shallowest suitable well. The most 'attractive' bin is not merely\n    one that can contain the item, but one that snugly contains it, leaving the\n    least 'void' or 'unused potential'. This tight packing minimizes the\n    'gravitational pull' for future items to gravitate towards newly opened bins,\n    thus conserving the total number of containers required.\n\n    The priority for a suitable bin is calculated as the negative of the\n    remaining capacity after the item is placed. This converts the pursuit of\n    the *minimum* wasted space into a *maximization* problem, where the bin with\n    the highest priority (i.e., the least negative remaining space) is chosen.\n    Bins that are too small to accommodate the item are given an infinitely\n    low priority, rendering them impenetrable barriers.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities for all bins. Bins that cannot fit the item\n    # are assigned a negative infinity priority, making them effectively\n    # impossible choices, akin to insurmountable obstacles.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify the bins where the item can physically fit.\n    # These are the 'accessible' regions in our potential landscape.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the 'residual capacity' or 'potential void' that would remain\n    # in each fitting bin after the item is placed. Our aim is to minimize this value.\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # To convert the goal of 'minimizing residual capacity' into a 'maximization\n    # of priority', we take the negative of the residual capacity.\n    # A smaller positive residual capacity results in a priority score closer to zero\n    # (i.e., less negative), thus becoming a higher priority choice.\n    priorities[can_fit_mask] = -remaining_after_fit\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    \n    Inspired by quantum phenomena, this heuristic views the packing problem \n    as an optimization of \"potential energy.\" Bins that offer a \"snug fit\" \n    for the item, leaving minimal wasted space, are highly preferred. \n    A perfect fit represents the lowest potential energy state and thus \n    the highest probability (priority) for the item to settle there.\n\n    Specifically, the priority is calculated using an exponential decay function:\n    Priority = exp(-(remaining_capacity - item_size)) for bins where the item fits.\n    This means:\n    - A perfect fit (remaining_capacity - item_size = 0) results in a priority of 1.0 (e^0).\n    - As the \"wasted space\" (remaining_capacity - item_size) increases, the priority \n      decreases exponentially towards zero.\n    - Bins where the item does not fit receive a priority of negative infinity.\n\n    This \"fuzzy Best Fit\" approach smoothly quantifies the desirability of each bin, \n    preferring efficiency while still distinguishing between different levels of \"goodness.\"\n\n    Args:\n        item: Size of item to be added to the bin. Assumed to be a positive float.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    \n    # Items in Bin Packing are typically positive. If a non-positive item were given,\n    # it defies the problem context. Assign lowest priority to all bins.\n    if item <= 0:\n        return np.full_like(bins_remain_cap, -np.inf)\n\n    # Initialize priorities to a very low value, representing \"cannot fit\" or \"undesirable\".\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins where the item *can* fit\n    fits_mask = bins_remain_cap >= item\n\n    # Calculate the 'wasted space' if the item were placed in each fitting bin.\n    # This is the difference: (bin_remaining_capacity - item_size).\n    # We want to minimize this difference for higher priority.\n    wasted_space_for_fits = bins_remain_cap[fits_mask] - item\n\n    # Apply the exponential priority function.\n    # We use -wasted_space to ensure smaller wasted space leads to higher exp value (closer to 1.0).\n    # exp(0) = 1.0 (perfect fit), exp(-small_positive) < 1.0 (snug fit), exp(-large_positive) ~ 0 (loose fit).\n    priorities[fits_mask] = np.exp(-wasted_space_for_fits)\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1st, 2nd, 3rd, 5th, 6th, 7th, 8th, 9th, 10th: These heuristics are functionally identical, all implementing the classic \"Best Fit\" strategy. They assign a priority as the negative of the remaining capacity after placing the item (`-(bins_remain_cap - item)`). A perfect fit results in a priority of 0, while larger remaining capacities yield increasingly negative priorities. The differences among them are purely cosmetic (docstrings, comments, variable names) or minor syntactic variations (e.g., using `np.where` vs. direct boolean masking), which do not alter the core logic. Their consistent high ranking indicates the strong efficacy and robustness of this specific linear priority function.\n\nComparing 1st (Best Fit) vs 4th (Feynman): The 1st heuristic uses a linear negative relationship to remaining space, while the 4th heuristic uses an inverse relationship: `1.0 / (remaining_space + 1e-9)`. This inverse function creates a significantly non-linear priority scaling. A perfect fit receives an extremely high priority, and priorities drop off very steeply even for slightly larger remaining capacities. The fact that the 4th heuristic is ranked lower suggests that this aggressive, non-linear amplification of \"best fits\" might be detrimental. It could lead to a greedy approach that is too focused on immediate, near-perfect fits, potentially preventing better overall packing by leaving less optimal but still viable options for subsequent items.\n\nComparing 1st (Best Fit) vs 11th-20th (Quantum): While the 1st heuristic maintains a linear negative priority, the 11th-20th heuristics employ an exponential decay function: `np.exp(-(remaining_capacity - item))`. This also introduces a non-linear weighting, where a perfect fit yields a priority of 1.0, and values decay exponentially towards zero for looser fits. The consistently lower ranking of this exponential approach compared to the linear Best Fit suggests that this smoother, non-linear decay also performs worse. It might not differentiate sufficiently among various levels of \"goodness\" for non-perfect fits, or its curve might not align optimally with the problem's combinatorial nature, leading to suboptimal overall solutions.\n\nOverall: The results strongly demonstrate that the classic Best Fit heuristic, which uses a simple linear inverse relationship between priority and remaining capacity, is empirically superior for this bin packing scenario. Non-linear transformations of the priority function (like inverse or exponential scaling) appear to degrade performance, likely by distorting the relative desirability of bins in a way that doesn't lead to optimal global packing.\n- \nHere's a redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Directness, Robustness, Interpretability, Proportionality.\n*   **Advice:** Design heuristics with simple, direct functions linearly proportional to key problem objectives. Prioritize interpretability and robustness; add complexity incrementally only if clear performance gains are proven.\n*   **Avoid:** Arbitrary non-linear weighting or excessive parameterization without strong theoretical justification. Such approaches often introduce fragility, obscure decision logic, and hinder generalizability.\n*   **Explanation:** Best Fit's robustness underscores that transparent, proportional relationships to problem state (e.g., remaining capacity) yield superior performance across diverse instances. Non-linearities can often distort this, leading to brittle or sub-optimal decision-making.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}