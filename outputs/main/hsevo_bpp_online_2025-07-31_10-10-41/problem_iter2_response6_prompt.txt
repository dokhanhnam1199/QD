{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This function implements a \"Best Fit\" heuristic for the online bin packing problem.\n    It prioritizes bins that, upon receiving the item, would leave the smallest\n    amount of remaining capacity (i.e., achieving the \"snuggest\" fit).\n    Bins where the item cannot fit are assigned an extremely low priority.\n\n    The logic is as follows:\n    1. For each bin, determine if the item can fit within its remaining capacity.\n    2. If the item fits, calculate the remaining capacity after placing the item\n       (current_bin_capacity - item_size).\n    3. The priority score for a fitting bin is the negative of this remaining capacity.\n       This ensures that a smaller positive remaining capacity (a snugger fit, or\n       even a perfect fit resulting in 0 remaining capacity) yields a higher\n       (less negative or zero) priority score.\n    4. If the item does not fit, the bin receives a priority of negative infinity,\n       ensuring it is never chosen.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities to a very low value (negative infinity).\n    # This ensures that bins where the item does not fit are never selected,\n    # as their priority will be lower than any valid fitting bin.\n    priorities = -np.ones_like(bins_remain_cap, dtype=float) * np.inf\n\n    # Find the indices of all bins where the current item can physically fit.\n    fitting_bin_indices = np.where(item <= bins_remain_cap)[0]\n\n    if fitting_bin_indices.size > 0:\n        # Calculate the remaining capacity in these fitting bins if the item were placed.\n        remaining_after_fit = bins_remain_cap[fitting_bin_indices] - item\n\n        # Assign priority scores to the fitting bins.\n        # By taking the negative of the remaining capacity, a smaller positive\n        # remaining capacity (closer to a perfect fit) results in a larger\n        # (less negative, or zero for a perfect fit) priority score.\n        priorities[fitting_bin_indices] = -remaining_after_fit\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    \n    Inspired by quantum phenomena, this heuristic views the packing problem \n    as an optimization of \"potential energy.\" Bins that offer a \"snug fit\" \n    for the item, leaving minimal wasted space, are highly preferred. \n    A perfect fit represents the lowest potential energy state and thus \n    the highest probability (priority) for the item to settle there.\n\n    Specifically, the priority is calculated using an exponential decay function:\n    Priority = exp(-(remaining_capacity - item_size)) for bins where the item fits.\n    This means:\n    - A perfect fit (remaining_capacity - item_size = 0) results in a priority of 1.0 (e^0).\n    - As the \"wasted space\" (remaining_capacity - item_size) increases, the priority \n      decreases exponentially towards zero.\n    - Bins where the item does not fit receive a priority of negative infinity.\n\n    This \"fuzzy Best Fit\" approach smoothly quantifies the desirability of each bin, \n    preferring efficiency while still distinguishing between different levels of \"goodness.\"\n\n    Args:\n        item: Size of item to be added to the bin. Assumed to be a positive float.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    \n    # Items in Bin Packing are typically positive. If a non-positive item were given,\n    # it defies the problem context. Assign lowest priority to all bins.\n    if item <= 0:\n        return np.full_like(bins_remain_cap, -np.inf)\n\n    # Initialize priorities to a very low value, representing \"cannot fit\" or \"undesirable\".\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins where the item *can* fit\n    fits_mask = bins_remain_cap >= item\n\n    # Calculate the 'wasted space' if the item were placed in each fitting bin.\n    # This is the difference: (bin_remaining_capacity - item_size).\n    # We want to minimize this difference for higher priority.\n    wasted_space_for_fits = bins_remain_cap[fits_mask] - item\n\n    # Apply the exponential priority function.\n    # We use -wasted_space to ensure smaller wasted space leads to higher exp value (closer to 1.0).\n    # exp(0) = 1.0 (perfect fit), exp(-small_positive) < 1.0 (snug fit), exp(-large_positive) ~ 0 (loose fit).\n    priorities[fits_mask] = np.exp(-wasted_space_for_fits)\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1st, 2nd, 3rd, 5th, 6th, 7th, 8th, 9th, 10th: These heuristics are functionally identical, all implementing the classic \"Best Fit\" strategy. They assign a priority as the negative of the remaining capacity after placing the item (`-(bins_remain_cap - item)`). A perfect fit results in a priority of 0, while larger remaining capacities yield increasingly negative priorities. The differences among them are purely cosmetic (docstrings, comments, variable names) or minor syntactic variations (e.g., using `np.where` vs. direct boolean masking), which do not alter the core logic. Their consistent high ranking indicates the strong efficacy and robustness of this specific linear priority function.\n\nComparing 1st (Best Fit) vs 4th (Feynman): The 1st heuristic uses a linear negative relationship to remaining space, while the 4th heuristic uses an inverse relationship: `1.0 / (remaining_space + 1e-9)`. This inverse function creates a significantly non-linear priority scaling. A perfect fit receives an extremely high priority, and priorities drop off very steeply even for slightly larger remaining capacities. The fact that the 4th heuristic is ranked lower suggests that this aggressive, non-linear amplification of \"best fits\" might be detrimental. It could lead to a greedy approach that is too focused on immediate, near-perfect fits, potentially preventing better overall packing by leaving less optimal but still viable options for subsequent items.\n\nComparing 1st (Best Fit) vs 11th-20th (Quantum): While the 1st heuristic maintains a linear negative priority, the 11th-20th heuristics employ an exponential decay function: `np.exp(-(remaining_capacity - item))`. This also introduces a non-linear weighting, where a perfect fit yields a priority of 1.0, and values decay exponentially towards zero for looser fits. The consistently lower ranking of this exponential approach compared to the linear Best Fit suggests that this smoother, non-linear decay also performs worse. It might not differentiate sufficiently among various levels of \"goodness\" for non-perfect fits, or its curve might not align optimally with the problem's combinatorial nature, leading to suboptimal overall solutions.\n\nOverall: The results strongly demonstrate that the classic Best Fit heuristic, which uses a simple linear inverse relationship between priority and remaining capacity, is empirically superior for this bin packing scenario. Non-linear transformations of the priority function (like inverse or exponential scaling) appear to degrade performance, likely by distorting the relative desirability of bins in a way that doesn't lead to optimal global packing.\n- \nHere's a redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Directness, Robustness, Interpretability, Proportionality.\n*   **Advice:** Design heuristics with simple, direct functions linearly proportional to key problem objectives. Prioritize interpretability and robustness; add complexity incrementally only if clear performance gains are proven.\n*   **Avoid:** Arbitrary non-linear weighting or excessive parameterization without strong theoretical justification. Such approaches often introduce fragility, obscure decision logic, and hinder generalizability.\n*   **Explanation:** Best Fit's robustness underscores that transparent, proportional relationships to problem state (e.g., remaining capacity) yield superior performance across diverse instances. Non-linearities can often distort this, leading to brittle or sub-optimal decision-making.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}