{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns a priority score for each bin, combining Best Fit with a \"Bin Completion\" bias.\n\n    This heuristic aims to select a bin that:\n    1.  Fits the item (essential, bins where the item does not fit are assigned the lowest possible priority).\n    2.  Among valid fits, prioritizes Best Fit (leaving the least remaining capacity).\n    3.  Additionally, applies a \"Bin Completion\" bias. It gives a bonus to bins that are\n        already significantly full (i.e., have little remaining capacity before the item is placed).\n        This encourages \"finishing off\" bins that are closer to being full, leading to fewer\n        partially filled bins overall and potentially consolidating items more efficiently.\n        This represents an adaptive strategy, prioritizing a global state objective (bin consolidation)\n        alongside the immediate fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        bin_capacity: The maximum capacity of a single bin. Default to 1.0, assuming\n                      items and bin capacities are normalized.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item in each bin\n    remaining_after_placement = bins_remain_cap - item\n\n    # Base Best Fit priority:\n    # A perfect fit (remaining_after_placement = 0) gets the highest BF score (0).\n    # Less remaining capacity results in a higher score (closer to 0).\n    bf_priorities = -remaining_after_placement\n\n    # Calculate current occupancy ratio for each bin (before placing the item)\n    # This ratio ranges from 0 (empty bin) to 1 (full bin).\n    # We clip it to ensure values are within [0, 1] for robustness against potential\n    # floating point inaccuracies or unusual initial states (though usually not expected).\n    current_occupancy_ratio = (bin_capacity - bins_remain_cap) / bin_capacity\n    current_occupancy_ratio = np.clip(current_occupancy_ratio, 0, 1)\n\n    # Bin Completion Bias:\n    # A bonus is applied based on how full the bin currently is.\n    # The fuller the bin (higher current_occupancy_ratio), the higher the bonus.\n    # This encourages packing items into bins that are already close to being completely filled.\n    # The weight 'beta' controls the influence of this bias. A higher beta means this bias\n    # has a stronger effect on the final priority, potentially shifting choices away from\n    # pure Best Fit if a less tight fit in an already full bin is available.\n    beta = 0.5  # Tunable parameter. A value of 0 effectively reverts to Best Fit.\n\n    completion_bonus = beta * current_occupancy_ratio\n\n    # Combine Best Fit priority with the completion bonus.\n    # The primary BF priority ensures valid fits are preferred and tighter fits are generally\n    # chosen. The completion bonus then adds a strategic layer to favor consolidating items\n    # into bins that are already well-utilized, aiming to reduce the total number of open bins.\n    priorities = bf_priorities + completion_bonus\n\n    # Finally, set priority to negative infinity for bins where the item does not fit.\n    # This ensures these bins are never selected, overriding any potential positive bonuses\n    # that might have been calculated for them (e.g., if a bin was already very full\n    # but the item still didn't fit).\n    priorities[remaining_after_placement < 0] = -np.inf\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                default_priority: float = -137.50755434220446,\n                weight_proportional_fit: float = 6.429049372442565,\n                weight_smallest_fit: float = 4.499361878629241) -> np.ndarray:\n    \"\"\"Combines Best Fit (proportional utilization) with Smallest Fit (current bin capacity).\n    Prioritizes bins yielding a high fill ratio while also preferring bins with smaller current remaining capacities to close them faster.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): A NumPy array of remaining capacities for each bin.\n        default_priority (float, optional): The priority assigned to bins where the item cannot fit\n                                            or for invalid item sizes. Defaults to -np.inf.\n        weight_proportional_fit (float, optional): The weight given to the proportional fit component\n                                                  (item / bin_capacity). Defaults to 1.0.\n        weight_smallest_fit (float, optional): The weight given to the smallest fit component\n                                               (-bin_capacity). Defaults to 1.0.\n\n    Returns:\n        np.ndarray: An array of priority scores for each bin. Higher scores indicate higher priority.\n    \"\"\"\n    # Initialize priority scores to default_priority for non-fitting or invalid cases.\n    priorities = np.full_like(bins_remain_cap, default_priority, dtype=float)\n\n    # Handle invalid item size: If item is non-positive, it cannot be packed.\n    if item <= 0:\n        return priorities\n\n### Analyze & experience\n- Comparing (Heuristics 1st) vs (Heuristics 20th), we see that the simplest Best Fit (H1), which minimizes absolute remaining capacity, significantly outperforms a more complex \"Adaptive Best Fit\" (H20). H20 attempts to dynamically bias item placement for smaller items into fuller bins, but its elaborate formula with parameters like `K` and reliance on `BIN_CAPACITY` appears to lead to worse performance. This suggests that over-engineering or adding complex adaptive factors without precise tuning can be detrimental.\n\nComparing (Heuristics 2nd) vs (Heuristics 17th), both aim for bin consolidation but with different mechanisms. Heuristic 2 adds an explicit \"Bin Completion Bonus\" to already full bins, while Heuristic 17 (identical to H20) applies a dynamic penalty based on current bin capacity and item size. Heuristic 2's bonus-based approach is ranked higher, indicating that encouraging desired states through positive reinforcement (a bonus for being full) may be more effective than complex, dynamically scaled penalties.\n\nComparing (Heuristics 1st) vs (Heuristics 2nd), pure Best Fit (H1) is slightly superior to Best Fit with an added Bin Completion Bonus (H2). This suggests that for this problem, the direct greedy objective of minimizing the immediate remaining space (Best Fit) might be more robust and effective than trying to enforce a global \"bin completion\" strategy with a fixed `beta` parameter. Simplicity often provides a robust baseline.\n\nComparing (Heuristics 3rd) vs (Heuristics 4th), Heuristic 3 attempts to refine Best Fit by penalizing small remnants and strongly prioritizing perfect fits (assigning `np.inf`). Heuristic 4 is functionally almost identical to Heuristic 1 (pure Best Fit). The ranking indicates that Heuristic 3's aggressive perfect fit prioritization and small remnant penalty, while intuitive, is slightly less effective than pure Best Fit, perhaps due to unintended side effects of diverting items from locally optimal (but not perfectly fitting) bins.\n\nComparing (Heuristics 6th) vs (Heuristics 17th), \"Proportional Best Fit\" (H6, 7, 9, 10, 11) is ranked notably higher than the \"Adaptive Best Fit\" (H17-20). This implies that maximizing the proportion of remaining capacity filled is a better strategy than the dynamic adaptive approach of H17-20, even if it's still inferior to standard Best Fit.\n\nComparing (Heuristics 16th) vs (Heuristics 20th), the absolute lowest-ranked heuristics (H12-16) are incomplete, lacking the core logic for placing items beyond a basic invalid item check. This fundamental flaw explains their worst-in-class performance. Heuristics 17-20 are fully implemented but still perform poorly, highlighting that a complete implementation of a suboptimal heuristic is still worse than an incomplete one (if no items can be placed).\n\nOverall: Simple Best Fit (minimizing absolute remaining capacity) appears to be the most robust and effective. Attempts to add complexity, such as dynamic penalties or less direct proportional fits, often lead to worse performance unless extremely well-tuned. Aggressive prioritization of perfect fits is somewhat beneficial but not consistently better than pure Best Fit. Finally, correctly implementing the core logic is paramount.\n- \n*   **Keywords:** Heuristic Baseline, Additive Incentives, Perfect Fits, Logic Validation, Parameter Tuning.\n*   **Advice:** Use Best Fit as an analytical starting concept. Implement additive bonuses for desirable outcomes like bin completion. Strongly prioritize perfect item-bin fits. Verify all core placement logic for completeness. Rigorously tune heuristic parameters.\n*   **Avoid:** Stating Best Fit's general performance, prescribing specific linear/non-linear penalties, or vague calls for calculation simplicity or robustness for invalid inputs.\n*   **Explanation:** This approach emphasizes building from a conceptual baseline with positive, targeted mechanisms, ensuring foundational correctness, and optimizing through calibration, rather than focusing on specific penalty forms or broad performance comparisons.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}