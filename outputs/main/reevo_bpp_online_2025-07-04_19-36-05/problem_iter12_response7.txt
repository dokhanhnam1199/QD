```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:

    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    num_bins = len(bins_remain_cap)
    bin_size = np.max(bins_remain_cap) # Assuming all bins have same capacity initially

    # 1. Feasibility Mask
    feasible_bins = bins_remain_cap >= item

    # 2. Best Fit: Reward bins where item fits best
    residual_capacity = bins_remain_cap - item
    best_fit = np.where(feasible_bins, np.exp(-2 * np.abs(residual_capacity / bin_size)), 0)  # Exponential score based on residual, scaled by bin_size

    # 3. Near-Full Reward: Encourage filling bins that are close to full after placement
    near_full_reward = np.where(feasible_bins, np.exp(-2 * np.abs(residual_capacity) / bin_size), 0)

    # 4. Cubic Fragmentation Penalty: Heavily penalize leaving too much space
    fragmentation_penalty = np.where(feasible_bins, np.exp(-0.5 * (residual_capacity / bin_size)**3), 1e-6)  # Cubic penalty scaled by bin size

    # 5. Item Size Scaling: Scale the priority based on item size. Normalize by bin size.
    item_size_factor = item / bin_size

    # 6. Combine Heuristics Multiplicatively with Learned Weights (Example weights)
    w_best_fit = 0.4
    w_near_full = 0.3
    w_fragmentation = 0.3

    priorities = (w_best_fit * best_fit + 1e-9) * (w_near_full * near_full_reward + 1e-9) * (w_fragmentation * fragmentation_penalty + 1e-9) * (0.1 + item_size_factor)

    # 7. Strong Penalty for Infeasibility
    priorities = np.where(feasible_bins, priorities, -1e9) #Very small value for infeasible bins

    return priorities
```
