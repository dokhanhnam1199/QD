```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    bin_size = np.max(bins_remain_cap)

    # 1. Feasibility: Only consider bins that can fit the item.
    feasible_bins = bins_remain_cap >= item

    # If no bin is feasible, consider relative capacity. Open a new bin.
    if not np.any(feasible_bins):
         return bins_remain_cap / bin_size # Return ratio of remaining capacity to bin size

    # 2. Normalize remaining capacity.
    normalized_cap = bins_remain_cap / bin_size

    # 3. Best Fit Criterion: Prioritize bins with the smallest remaining capacity after placing the item.
    residual_capacity = bins_remain_cap - item
    best_fit_priority = np.where(feasible_bins, bin_size / (residual_capacity + 1e-9), 0) # Use bin size to scale priority.

    # 4. Fragmentation Penalty: Heavily penalize small gaps after placement.
    fragmentation_penalty = np.where(feasible_bins, np.exp(-5 * residual_capacity / bin_size), 0)

    # 5. Near-Full Reward: Encourage filling bins close to full with a stronger non-linear scaling.
    almost_full_bonus = np.where(feasible_bins, np.exp(-10 * (residual_capacity / bin_size)**2), 0)

    # 6. Explicit Small Gap Penalty: Penalize remaining capacity below a certain threshold.
    small_gap_penalty = np.where(feasible_bins & (residual_capacity < 0.1 * bin_size), -1, 0)

    # 7. Introduce a capacity utilization reward. Higher utilization is better.
    capacity_utilization = np.where(feasible_bins, (bin_size - residual_capacity) / bin_size, 0)
    capacity_reward = capacity_utilization * 2 #scale to amplify its effect

    priorities = best_fit_priority + almost_full_bonus + fragmentation_penalty + small_gap_penalty + capacity_reward
    
    #Ensure no negative priorities.
    priorities = np.maximum(priorities, 0)

    return priorities
```
