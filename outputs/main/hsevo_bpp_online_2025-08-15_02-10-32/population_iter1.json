[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99995219509583 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Best Fit strategy for online Bin Packing Problem.\n\n    Calculates priority for each bin based on how well the item fits.\n    A higher priority is given to bins where the remaining capacity\n    after placing the item is minimized, thus aiming for the \"best fit\".\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    # Calculate potential remaining capacity if item fits\n    potential_remain_cap = bins_remain_cap - item\n\n    # Assign a high priority to bins that can accommodate the item\n    # and a low priority to bins that cannot.\n    # Among bins that can accommodate, we want the one that leaves\n    # the least remaining space (best fit).\n    # We can achieve this by prioritizing bins with a smaller positive\n    # potential_remain_cap.\n    # For bins where potential_remain_cap is negative (item doesn't fit),\n    # we assign a very low priority (effectively 0 or less).\n\n    # For bins where the item fits (potential_remain_cap >= 0):\n    # We want to minimize potential_remain_cap. A simple way is to use\n    # a large number minus the potential_remain_cap.\n    # However, to avoid overflow and keep it simple, we can assign\n    # a value inversely proportional to the remaining capacity after fit.\n    # A negative value for potential_remain_cap means the item doesn't fit.\n    # So, we only consider positive potential_remain_cap.\n\n    # A common approach for best fit is to maximize -abs(remaining_capacity - item)\n    # or in this case, maximize the negative of the remaining capacity after fitting,\n    # but only for bins where it fits.\n\n    # Let's try to assign a high score to the smallest positive remaining capacity.\n    # If potential_remain_cap is positive, the score could be related to -potential_remain_cap.\n    # For bins where item does not fit (potential_remain_cap < 0), the priority should be very low.\n\n    # We can use a value that is large if it fits, and small if it doesn't.\n    # Among those that fit, the \"best fit\" would be the one with the smallest positive remaining capacity.\n    # Let's map smaller positive remaining capacities to higher priority scores.\n    # A simple mapping could be: 1 / (1 + potential_remain_cap) for valid fits.\n    # And a very low value for invalid fits.\n\n    # Consider bins where item fits (bins_remain_cap >= item)\n    fits_mask = bins_remain_cap >= item\n    \n    # For bins that fit, calculate the remaining capacity after placing the item.\n    # We want the bin with the minimum remaining capacity.\n    # To convert minimum remaining capacity to a maximum priority, we can use\n    # a transformation. For example, -remaining_capacity.\n    # To ensure positive values and highlight smaller remaining capacities,\n    # we can use a large constant minus remaining capacity.\n    # Or even better, use a function that gives higher values for smaller positive inputs.\n    \n    # Example strategy: Assign priority as (max_capacity + 1 - item - bin_cap_after_fit)\n    # This would be `max_possible_remaining_space` - `actual_remaining_space`\n    # To keep it simple and directly related to \"best fit\":\n    # Priority = -(remaining_capacity_after_item)\n    # This way, the smallest positive remaining capacity will be the least negative number, thus the maximum.\n\n    # Calculate remaining capacity if the item fits\n    remaining_if_fit = bins_remain_cap[fits_mask] - item\n    \n    # Assign priorities to bins that can fit the item\n    # Higher priority for smaller remaining capacity.\n    # Use negative of remaining capacity, so smaller positive values become larger negative values (higher priority).\n    # To make it more intuitive (higher score for better fit), we can use\n    # something like: (some_large_value) - remaining_capacity\n    # Let's use the maximum possible remaining space as the reference.\n    # A very large number representing total capacity could be used, but\n    # let's stick to a relative scale.\n    # A simple strategy: prioritize the bin that has the *least* leftover space.\n    # So if remaining capacity is R, priority could be -R.\n    \n    priorities[fits_mask] = -remaining_if_fit\n    \n    # For bins that do not fit, their priority is essentially zero or very low.\n    # By default, priorities are initialized to zero, which is fine here as\n    # negative priorities will be chosen over zero.\n    \n    # Another approach to ensure positive scores if preferred, but not required by problem statement:\n    # if fits_mask.any():\n    #     min_remaining = np.min(remaining_if_fit)\n    #     # Normalize or scale remaining capacities so smaller is better\n    #     # A simple approach is to use a large number minus the remaining capacity\n    #     # Example: Prioritize by (BinCapacity - item - actual_remaining_after_fit)\n    #     # where BinCapacity is the original capacity (not given directly here)\n    #     # or by a constant that is larger than any possible remaining capacity.\n    #     # If we consider max possible remaining capacity before fitting, it's the item size itself.\n    #     # Let's use a large number, say 1000, and subtract the remaining capacity.\n    #     # priorities[fits_mask] = 1000 - remaining_if_fit\n\n    # The negative of the remaining capacity directly achieves the goal:\n    # smaller positive remaining_if_fit -> larger negative priority -> higher preference.\n    \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 30.880904142633646,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n        else:\n            priorities[i] = -np.inf\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997037090361 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    for i in range(len(bins_remain_cap)):\n        remaining_cap = bins_remain_cap[i]\n        if remaining_cap >= item:\n            \n            \n            if remaining_cap - item < 0.1 * bins_remain_cap[0]: \n                priorities[i] = 1.0 / (remaining_cap - item + 1e-9)\n            else:\n                priorities[i] = 0.1 / (remaining_cap - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n            \n    \n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999945970019326 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First strategy: prioritize bins that can fit the item perfectly,\n    and among those, prefer bins that have less remaining capacity (to fill them up).\n    If no bin can fit the item exactly, fall back to First Fit logic (preferring\n    the first bin that can accommodate the item).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Exact Fit: Prioritize bins where item fits perfectly\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    if len(exact_fit_indices) > 0:\n        # Assign a high priority to exact fits, with higher priority for less remaining capacity\n        # (although for exact fit, remaining capacity is 0)\n        # We use negative of capacity to make higher remaining capacity have lower priority\n        priorities[exact_fit_indices] = 1000 - bins_remain_cap[exact_fit_indices]\n        return priorities\n    \n    # First Fit if no exact fit found\n    first_fit_indices = np.where(bins_remain_cap >= item)[0]\n    if len(first_fit_indices) > 0:\n        # Assign priority based on how \"tight\" the fit is.\n        # Bins with less remaining capacity are preferred.\n        # Add a small constant to differentiate from exact fits, and use negative capacity.\n        priorities[first_fit_indices] = 500 - bins_remain_cap[first_fit_indices]\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 66.60791492653966,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin based on inverse distance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # We want to prioritize bins that are closer to fitting the item perfectly.\n    # This is a heuristic to try and reduce wasted space by using bins that\n    # have just enough capacity.\n    # The inverse distance (proximity fit) suggests giving higher priority\n    # to bins where the remaining capacity is close to the item size.\n    \n    # Calculate the difference between the item size and the remaining capacity of each bin.\n    # We only consider bins where the item can actually fit.\n    valid_bins_mask = bins_remain_cap >= item\n    \n    # For bins where the item fits, calculate the \"proximity score\".\n    # A smaller difference means a better fit, so we want a higher priority for smaller differences.\n    # We can use the inverse of the difference. To avoid division by zero or very small numbers,\n    # we can add a small epsilon.\n    differences = bins_remain_cap[valid_bins_mask] - item\n    epsilon = 1e-6\n    priorities[valid_bins_mask] = 1.0 / (differences + epsilon)\n    \n    # Normalize priorities to a reasonable scale if needed, but for direct comparison,\n    # the relative values are important. The current approach prioritizes bins\n    # with less remaining space *after* fitting the item.\n    \n    # An alternative perspective: if we have multiple bins with same \"tightness\",\n    # which one should we prefer? Perhaps the one with more remaining capacity\n    # to be available for future items? This heuristic doesn't directly account for that,\n    # it purely focuses on the current best fit.\n    \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    fit_scores = valid_bins_cap / (valid_bins_cap - item + 1e-9)\n    \n    # Sigmoid transformation\n    # Center the sigmoid around a reasonable \"ideal\" fit (e.g., close to 1.0)\n    # A higher score indicates a better fit (closer to perfect utilization)\n    centered_scores = fit_scores - 1.0  # Shift scores so that perfect fit (score 1) is at 0\n    priorities = 1 / (1 + np.exp(-centered_scores * 5)) # Scale factor 5 for steeper sigmoid\n\n    # Map priorities back to the original bins_remain_cap array\n    original_priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    original_priorities[valid_bins_mask] = priorities\n    \n    return original_priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.15835660151576,
    "cyclomatic_complexity": 2.0,
    "halstead": 129.32351694048162,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit = bins_remain_cap >= item\n    priorities[can_fit] = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (priorities[can_fit] + 1e-9)\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n    \n    available_bins_capacities = bins_remain_cap[can_fit_mask]\n    \n    if available_bins_capacities.size > 0:\n        \n        relative_capacities = available_bins_capacities - item\n        \n        \n        mean_relative_capacity = np.mean(relative_capacities)\n        \n        \n        priorities[can_fit_mask] = np.exp(-relative_capacities / mean_relative_capacity)\n        \n        \n        \n        priorities[bins_remain_cap < item] = 0.0\n        \n    else:\n        priorities[:] = 0.0\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 64.72503367497926,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_capacities = bins_remain_cap[suitable_bins_mask]\n    if suitable_bins_capacities.size > 0:\n        relative_capacities = suitable_bins_capacities - item\n        exp_priorities = np.exp(relative_capacities)\n        priorities[suitable_bins_mask] = exp_priorities / np.sum(exp_priorities)\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 2.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a Best Fit strategy for online Bin Packing.\n\n    The priority is higher for bins that have just enough remaining capacity\n    to fit the item, favoring a tighter fit. A penalty is applied to bins\n    that have too much excess capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap >= item:\n            # Reward bins that are a close fit\n            difference = remaining_cap - item\n            # Prioritize bins where the difference is small (close to 0)\n            # We use 1/(1+difference) to give higher priority to smaller differences\n            # Adding a small epsilon to avoid division by zero if difference is exactly 0\n            priority_score = 1.0 / (1.0 + difference + 1e-9)\n            # Further penalize bins with very large remaining capacity\n            # This term becomes smaller as the remaining capacity increases beyond what's needed\n            excess_penalty = np.exp(-remaining_cap / 10.0) # Adjust divisor for sensitivity\n            priorities[i] = priority_score * excess_penalty\n        else:\n            # Bins that cannot fit the item get a very low priority (effectively zero)\n            priorities[i] = -np.inf\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99995961703826 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n        else:\n            priorities[i] = -np.inf\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 3.0,
    "halstead": 22.458839376460833,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    exact_fit_mask = (bins_remain_cap >= item)\n    exact_fit_capacities = bins_remain_cap[exact_fit_mask]\n    priorities[exact_fit_mask] = (bins_remain_cap[exact_fit_mask] - item) / bins_remain_cap[exact_fit_mask]\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 1.0,
    "halstead": 27.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Inverse Distance strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    \n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(valid_bins_mask):\n        valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        # Inverse distance to remaining capacity (closer to item size is better)\n        # Add a small epsilon to avoid division by zero if item == bin_remain_cap\n        inverse_distance = 1.0 / (valid_bins_remain_cap - item + 1e-9)\n        \n        # Normalize priorities to prevent extremely large values if remaining capacity is very close to item size\n        # And also to give a more balanced distribution if many bins are suitable\n        if np.max(inverse_distance) > 0:\n            normalized_priorities = inverse_distance / np.max(inverse_distance)\n        else:\n            normalized_priorities = np.zeros_like(inverse_distance)\n\n        priorities[valid_bins_mask] = normalized_priorities\n        \n        # Give a slight preference to bins that are almost full, as they are less likely to be used later\n        # by smaller items (heuristic inspired by First Fit Decreasing but applied online)\n        # This can be achieved by giving higher priority to bins with less remaining capacity\n        # relative to the item size.\n        priorities[valid_bins_mask] = priorities[valid_bins_mask] * (1.0 / (bins_remain_cap[valid_bins_mask] + 1e-9))\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 118.59257041502654,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using sigmoid fit score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # We want to prioritize bins that are \"almost full\" but can still fit the item.\n    # This encourages using existing bins efficiently before opening new ones.\n\n    # Calculate the \"goodness\" of fit for each bin. A higher value means a better fit.\n    # We consider bins where the remaining capacity is just enough or slightly more than the item.\n    # This is a subjective measure to encourage tighter packing.\n\n    # Create a measure of how \"tight\" the fit is.\n    # We want capacity_remaining - item_size to be close to zero.\n    tightness = bins_remain_cap - item\n\n    # Filter out bins that cannot fit the item. Their priority should be zero (or very low).\n    fit_mask = bins_remain_cap >= item\n    valid_tightness = tightness[fit_mask]\n\n    # Normalize the tightness to a range where sigmoid can work well.\n    # If there are no valid bins, this step will be skipped and an all-zero array will be returned.\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if valid_tightness.size > 0:\n        # A simple normalization: scale such that the range of valid tightness is somewhat centered around 0.\n        # This is heuristic and can be tuned. We want positive values for good fits.\n        # A smaller max_tightness means we are more sensitive to \"almost full\" bins.\n        max_tightness = np.max(valid_tightness)\n        min_tightness = np.min(valid_tightness)\n\n        # Avoid division by zero if all valid bins have the same tightness\n        if max_tightness == min_tightness:\n            normalized_tightness = np.zeros_like(valid_tightness)\n        else:\n            # Scale so that the range of valid_tightness is mapped to roughly [-2, 2] or similar,\n            # allowing sigmoid to capture differences.\n            # We want to map the smallest valid tightness (most space left) to a lower sigmoid value,\n            # and the largest valid tightness (tightest fit) to a higher sigmoid value.\n            # So, invert the range for scaling: max_tightness becomes -1, min_tightness becomes 1.\n            # Using -valid_tightness here because we want smaller remaining space (larger negative)\n            # to result in a higher sigmoid value.\n            scaled_tightness = -2 * (valid_tightness - min_tightness) / (max_tightness - min_tightness)\n\n            # Apply sigmoid function.\n            # Sigmoid(x) = 1 / (1 + exp(-x))\n            # This will map scaled_tightness to values between 0 and 1.\n            # We want higher values for tighter fits, so we will scale and shift if needed.\n            # A common approach is to use a scaled and shifted sigmoid.\n            # Let's map tightest fit (min_tightness) to 1 and loosest fit (max_tightness) to 0.\n            # This means we want a higher score when valid_tightness is smaller.\n            # Let's use a shifted and scaled sigmoid.\n            # f(x) = 1 / (1 + exp(-(k * (tightness_max - x))))\n            # where k is a steepness parameter and x is the remaining capacity after fitting.\n\n            # Parameter to control steepness of sigmoid. Higher k means more emphasis on tighter fits.\n            steepness_param = 2.0\n\n            # Calculate the value we pass to sigmoid. We want a larger value for smaller remaining capacity.\n            # So we use -(bins_remain_cap[fit_mask] - item) which means a smaller remaining capacity gives a larger positive value.\n            sigmoid_input = steepness_param * (item - bins_remain_cap[fit_mask])\n\n            # Apply sigmoid. The output will be between 0 and 1.\n            # Higher values for bins that are almost full (but can fit the item).\n            sigmoid_scores = 1 / (1 + np.exp(-sigmoid_input))\n\n            # Map these scores back to the original priority array\n            priorities[fit_mask] = sigmoid_scores\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 190.19550008653877,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n        else:\n            priorities[i] = -np.inf\n    \n    # Introduce some randomness, like a quantum fluctuation\n    noise = np.random.normal(0, 0.1, size=bins_remain_cap.shape)\n    priorities += noise\n\n    # Invert for maximization of negative difference (minimizing remaining capacity)\n    priorities = -priorities \n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 13, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n3\n43.18506523353572\n"
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities[suitable_bins_mask] = 1.0 / (bins_remain_cap[suitable_bins_mask] - item + 1e-9)\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    fit_values = []\n    for capacity in bins_remain_cap:\n        if capacity >= item:\n            fit_values.append(capacity - item)\n        else:\n            fit_values.append(np.inf)\n\n    fit_values = np.array(fit_values)\n    \n    priorities = np.exp(-fit_values)\n    \n    if np.all(np.isinf(priorities)):\n        priorities = np.ones_like(bins_remain_cap)\n    elif np.any(np.isinf(priorities)):\n        priorities[np.isinf(priorities)] = 1e10 \n        \n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 5.0,
    "halstead": 20.67970000576925,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using First Fit strategy.\n    Bins that can fit the item are prioritized higher. Among fitting bins,\n    those with smaller remaining capacity after fitting the item are preferred (to minimize waste).\n    Unfitting bins are given a low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf) # Initialize with very low priority\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate priority\n    # Priority is inversely proportional to the remaining capacity AFTER fitting the item.\n    # This means bins that are almost full after fitting will have higher priority.\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_fit = fitting_bins_remain_cap - item\n\n    # Avoid division by zero if remaining_after_fit is 0, assign a very high priority\n    # For others, prioritize smaller remaining_after_fit by using 1 / (1 + remaining_after_fit)\n    # Adding 1 ensures we don't divide by zero and that smaller remaining capacity gets higher score.\n    priorities[can_fit_mask] = 1 / (1 + remaining_after_fit)\n\n    # Optionally, you could add a bonus for fitting into bins that are exactly the right size\n    # For instance, if remaining_after_fit is 0, assign an even higher score\n    # priorities[can_fit_mask][remaining_after_fit == 0] = 1.0 # Or some other high value\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 50.18947501009619,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    eligible_bins_mask = bins_remain_cap >= item\n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n\n    if eligible_bins_remain_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    differences = eligible_bins_remain_cap - item\n    min_difference = np.min(differences)\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_indices = np.where(eligible_bins_mask)[0]\n\n    for i, idx in enumerate(eligible_indices):\n        if bins_remain_cap[idx] - item == min_difference:\n            priorities[idx] = 1.0\n        else:\n            priorities[idx] = 0.0\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 51.89147427955947,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 3.0,
    "halstead": 13.931568569324174,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the 'almost full' threshold. We'll consider bins with capacity\n    # just slightly larger than the item as more preferable.\n    # Let's define \"slightly larger\" as within a small epsilon of the item size.\n    epsilon = 0.1 # A small margin to consider as \"almost full\"\n    \n    # For bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate a score based on how close the remaining capacity is to the item size.\n    # Higher score for bins where remaining capacity is just enough or slightly more.\n    # We want to penalize bins that have a lot of remaining space.\n    # We can use a score that is inversely proportional to the remaining capacity,\n    # but only for those bins that can fit the item.\n    \n    # For bins that can fit the item, calculate their preference score.\n    # A good score would be one that prioritizes bins that are almost full but can still take the item.\n    # We can model this by looking at the difference between the bin's capacity and the item's size.\n    # A smaller positive difference (bin_remain_cap - item) means the bin is more \"almost full\".\n    # Let's give a higher priority to bins with a smaller positive difference.\n    \n    # We want to prioritize bins that leave the least wasted space if the item fits perfectly.\n    # If bin_remain_cap == item, the \"waste\" is 0.\n    # If bin_remain_cap > item, the \"waste\" is bin_remain_cap - item.\n    # We want to minimize this waste, so we want to maximize a score that is inversely related to waste.\n    \n    # Let's try a scoring system where bins that can fit the item get a score.\n    # Bins that can fit the item will have a higher priority if their remaining capacity\n    # is close to the item's size.\n    \n    # Calculate how much \"space\" is left after fitting the item\n    space_left_after_fit = bins_remain_cap - item\n    \n    # We want to prioritize bins where space_left_after_fit is small and non-negative.\n    # A higher priority for smaller positive values.\n    # We can use something like 1 / (1 + space_left_after_fit) for bins that fit.\n    # This will give a score close to 1 for perfect fits and decreasing scores for larger remaining spaces.\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # For bins where the item fits\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    \n    # Calculate priorities for bins that can fit the item.\n    # The \"almost full\" heuristic means we prefer bins that are nearly full,\n    # but can still accommodate the item. This implies minimizing the remaining space\n    # after placing the item.\n    # So, a bin with remaining capacity just slightly larger than the item is preferred.\n    \n    # Let's score based on the remaining capacity after placing the item.\n    # We want to find the bin that leaves the *least* remaining capacity.\n    # This is equivalent to finding the bin whose current remaining capacity is closest to the item size,\n    # such that the remaining capacity is still greater than or equal to the item size.\n    \n    # If a bin's remaining capacity is exactly the item size, that's ideal for \"almost full\".\n    # If it's slightly larger, it's also good.\n    # If it's much larger, it's less preferable.\n    \n    # We can assign a high priority to bins where bins_remain_cap is just above 'item'.\n    # Let's consider a scoring function that favors bins where (bins_remain_cap - item) is minimal.\n    # For bins that can fit, we can give a score that is inversely related to the remaining space.\n    # However, to implement \"almost full\", we want to prioritize bins that are *already* quite full.\n    \n    # A common approach for \"almost full\" is to look for bins with remaining capacity\n    # that is just enough or slightly more than the item.\n    \n    # Let's assign priority based on the \"tightness\" of the fit.\n    # A tighter fit (smaller difference between remaining capacity and item size) is preferred.\n    \n    # For bins that can fit the item:\n    # Score = 1 / (epsilon + (bins_remain_cap[i] - item))\n    # where epsilon is a small constant to avoid division by zero and to provide a base value.\n    # This would give higher scores for smaller (bins_remain_cap[i] - item).\n    \n    # To strongly favor \"almost full\", we can give a bonus if the remaining capacity is\n    # within a small margin of the item size.\n    \n    # Let's define \"almost full\" as remaining capacity `r` such that `item <= r < item + threshold`.\n    # For such bins, we want to give a high priority, especially to those with smaller `r`.\n    \n    # Consider the inverse of the remaining capacity if the item fits.\n    # The bin with the *smallest* remaining capacity that can fit the item is the \"most almost full\".\n    \n    # So, for bins that can fit:\n    # Priority = 1 / (bins_remain_cap[i] + epsilon)\n    # This will give higher priority to bins with *smaller* remaining capacity.\n    # We want the *smallest* remaining capacity that is still *greater than or equal to* item.\n    \n    # Let's simplify: Prioritize bins that have the least amount of \"wasted\" space.\n    # The wasted space is (bins_remain_cap[i] - item) for bins where item fits.\n    # We want to MINIMIZE this waste. Thus, we want to MAXIMIZE a value related to the negative of this waste.\n    # Or, simply, we want to pick the bin with the smallest `bins_remain_cap[i]` among those that fit.\n    \n    # Let's try a direct inverse relationship with the remaining capacity for fitting bins.\n    # Higher priority for smaller remaining capacities.\n    \n    # This directly implements \"Best Fit\" logic. For \"Almost Full Fit\", we want\n    # to target bins that are *already* quite full.\n    \n    # A common interpretation of \"Almost Full Fit\" or \"Worst Fit Decreasing\" (though we are online here)\n    # is to try to leave larger spaces for larger items. So, we'd put the current item\n    # into a bin that leaves the *largest* remaining capacity, *if it fits*.\n    # This is the opposite of what's implied by \"almost full\".\n    \n    # Let's re-read: \"The bin with the highest priority score will be selected for the item.\"\n    # \"Almost Full Fit strategy\" for online BPP.\n    # This usually means filling bins as much as possible. So we prefer bins that are nearly full.\n    \n    # A higher priority should be given to bins that have just enough space,\n    # or are closest to being full but can still fit the item.\n    \n    # Let's consider the difference: `diff = bins_remain_cap[i] - item`.\n    # We want `diff` to be as small and non-negative as possible.\n    # So, a score like `1 / (1 + diff)` would work.\n    \n    # However, the term \"Almost Full Fit\" can also imply giving preference to bins\n    # that have been used more. In an online scenario, this means bins with less remaining capacity.\n    \n    # Let's use the negative of the remaining capacity, but only for bins that can fit.\n    # For bins that can fit, a lower remaining capacity is better (more \"almost full\").\n    # We want to MAXIMIZE the priority. So, we want to MAXIMIZE `-bins_remain_cap`.\n    # Or, equivalently, MINIMIZE `bins_remain_cap`.\n    \n    # If we want to specifically target bins that are \"almost full\" (meaning their capacity is\n    # relatively small, but still fits the item), we could score based on the inverse of the remaining capacity.\n    \n    # A simple way to implement \"almost full\" is to look at bins that are already fairly full.\n    # If `bins_remain_cap` is `[10, 5, 2, 8]` and `item` is `3`.\n    # Fits in: Bin 0 (rem 7), Bin 1 (rem 2), Bin 3 (rem 5).\n    # The \"most almost full\" that fits is Bin 1 (rem 2).\n    # So, we want to pick the bin with the smallest `bins_remain_cap` that is `>= item`.\n    \n    # This is equivalent to Best Fit. If the problem statement means something else by \"Almost Full Fit\"\n    # that differentiates it from Best Fit, it's not immediately obvious.\n    \n    # Let's assume \"Almost Full Fit\" means prioritizing bins with smaller remaining capacities\n    # that can still fit the item. This is essentially Best Fit.\n    \n    # If we need to be more nuanced about \"almost full\", maybe we consider bins\n    # where `bins_remain_cap` is large, but only slightly larger than `item`.\n    \n    # Let's create a priority that is high for bins where `bins_remain_cap` is just a bit larger than `item`.\n    # `priority = max(0, 1 - (bins_remain_cap[i] - item) / some_large_capacity)`\n    \n    # Let's stick to the interpretation: prioritize bins that, after placing the item, will have the smallest remaining capacity.\n    # This means finding the bin with the minimum `bins_remain_cap` such that `bins_remain_cap >= item`.\n    \n    # To achieve this with a highest-priority-wins system:\n    # For bins that can fit, assign a priority that is inversely related to their remaining capacity.\n    # `priority = 1 / (bins_remain_cap[i] + epsilon)`\n    # This rewards smaller remaining capacities.\n    \n    # Let's try a scoring function where bins that can fit get a score proportional to how 'full' they are,\n    # but we also need to ensure they can fit.\n    \n    # Consider bins_remain_cap = [10, 8, 6, 4, 2], item = 3\n    # Fits in: [10, 8, 6, 4] -> remain_caps: [7, 5, 3, 1]\n    # The most \"almost full\" that fits is bin with remaining capacity 1.\n    # So we want to maximize a score that is achieved by the smallest valid `bins_remain_cap`.\n    \n    # Let's assign a priority that is simply the negative of the remaining capacity,\n    # but only for those bins that can accommodate the item.\n    # For bins that cannot fit, their priority should be very low.\n    \n    priorities = np.full_like(bins_remain_cap, -np.inf) # Initialize with very low priority\n    \n    fitting_indices = np.where(bins_remain_cap >= item)[0]\n    \n    if fitting_indices.size > 0:\n        # For bins that can fit, assign a priority based on how much space is left.\n        # We want the least remaining space. So, the priority should be higher\n        # for smaller remaining space.\n        # We can use the negative of the remaining capacity for bins that fit.\n        # `priorities[fitting_indices] = -bins_remain_cap[fitting_indices]`\n        \n        # To be more explicit about \"almost full\":\n        # We want bins where the `remaining_capacity` is small, but still >= `item`.\n        # Let's define a score where a smaller `remaining_capacity - item` gets a higher score.\n        # Score = 1.0 / (epsilon + (bins_remain_cap[i] - item))\n        # where epsilon is a small constant to avoid division by zero.\n        \n        # Let's try `bins_remain_cap - item`. We want to minimize this.\n        # So we want to maximize `-(bins_remain_cap - item)`.\n        \n        priorities[fitting_indices] = -(bins_remain_cap[fitting_indices] - item)\n        \n        # This would pick the bin that results in the LEAST remaining capacity.\n        # Example: caps=[10, 8, 6, 4], item=3\n        # Fits: [10, 8, 6, 4]\n        # Scores: -(10-3), -(8-3), -(6-3), -(4-3)  -> [-7, -5, -3, -1]\n        # Max score is -1, which corresponds to the bin with remaining capacity 4. This is the Best Fit.\n        \n        # If \"Almost Full Fit\" means preferring bins that have a capacity *just slightly larger than the item*,\n        # we might need a different approach.\n        \n        # Let's consider a scenario where we prioritize bins that are closer to being full overall,\n        # but not *too* full that they can't fit the item.\n        \n        # If the problem implies preferring bins that have *more* remaining capacity\n        # (so as to leave them \"almost full\" for future larger items), that would be Worst Fit.\n        # However, \"Almost Full Fit\" usually implies the opposite: filling bins up.\n        \n        # Let's try to assign higher priority to bins that are *already* very full,\n        # and can still fit the item.\n        # If remaining capacity is `r`, we want to prioritize small `r` such that `r >= item`.\n        \n        # Let's re-evaluate the interpretation of \"Almost Full Fit\".\n        # It often means to put the item into the bin that has the least free space *but can still accommodate the item*.\n        # This is synonymous with the Best Fit heuristic.\n        \n        # So, we want to find the bin `j` that minimizes `bins_remain_cap[j] - item`\n        # subject to `bins_remain_cap[j] >= item`.\n        \n        # To convert this minimization into a maximization problem for priority:\n        # `priority[j] = 1 / ( (bins_remain_cap[j] - item) + epsilon )`\n        # or\n        # `priority[j] = -(bins_remain_cap[j] - item)`\n        \n        # Let's use the negative difference as the priority.\n        # Higher values of `-(bins_remain_cap - item)` mean smaller `bins_remain_cap - item`.\n        \n        # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n        # Fits: [10, 8, 6, 4]\n        # Scores = [-(10-3), -(8-3), -(6-3), -(4-3)] = [-7, -5, -3, -1]\n        # Max score is -1, corresponds to bin with remaining capacity 4. This is Best Fit.\n        \n        # Let's try a different angle for \"Almost Full Fit\".\n        # Maybe it's about maximizing the 'fullness' of the bin *before* placing the item.\n        # A bin is \"almost full\" if its `bins_remain_cap` is small.\n        # So, we want to prioritize bins with small `bins_remain_cap`, provided they fit.\n        \n        # Let's assign priority `1 / bins_remain_cap[i]` for bins that fit.\n        # This rewards smaller remaining capacities.\n        \n        # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n        # Fits: [10, 8, 6, 4]\n        # Scores = [1/10, 1/8, 1/6, 1/4] = [0.1, 0.125, 0.166, 0.25]\n        # Max score is 0.25, corresponds to bin with remaining capacity 4. This is still Best Fit.\n        \n        # What if \"Almost Full Fit\" means preferring bins that are *just* large enough?\n        # Consider `bins_remain_cap` and `item`.\n        # We want to prioritize bins where `bins_remain_cap` is in a range, e.g., `item <= bins_remain_cap < item + threshold`.\n        # Within that range, we might prefer those closer to `item`.\n        \n        # Let's try a priority function that gives a high score if the remaining capacity\n        # is just slightly larger than the item size.\n        \n        # Define a \"sweet spot\" for remaining capacity: `item` to `item + margin`.\n        # `margin = item * 0.2`  (e.g., 20% more than item size)\n        \n        margin = item * 0.2\n        \n        # Initialize priorities for fitting bins\n        fitting_priorities = np.zeros_like(bins_remain_cap[fitting_indices])\n        \n        # Case 1: Remaining capacity is within the \"almost full\" margin\n        almost_full_mask = (bins_remain_cap[fitting_indices] >= item) & \\\n                           (bins_remain_cap[fitting_indices] < item + margin)\n        \n        almost_full_indices = fitting_indices[almost_full_mask]\n        \n        if almost_full_indices.size > 0:\n            # Within this \"almost full\" group, prioritize those with less remaining capacity.\n            # So, higher priority for smaller `bins_remain_cap`.\n            # `priority = 1 / (bins_remain_cap + epsilon)`\n            # Or `priority = -(bins_remain_cap - item)`\n            fitting_priorities[almost_full_mask] = -(bins_remain_cap[almost_full_indices] - item)\n        \n        # Case 2: Remaining capacity is larger than the \"almost full\" margin.\n        # These are less preferable. Give them a lower priority.\n        less_preferable_mask = bins_remain_cap[fitting_indices] >= item + margin\n        less_preferable_indices = fitting_indices[less_preferable_mask]\n        \n        if less_preferable_indices.size > 0:\n            # Give them a lower score, perhaps inversely proportional to their large remaining capacity.\n            # `priority = -(bins_remain_cap - item) / large_constant`\n            # Or simply a smaller constant value, or a value that is clearly less than the \"almost full\" group.\n            \n            # Let's give them a negative priority that is less severe than the \"almost full\" group.\n            # Example: `priority = -10 - (bins_remain_cap[i] - item)`\n            # This will be smaller than `-(bins_remain_cap - item)` from the first group.\n            \n            # Let's try to scale the priority such that the best case (closest fit) has the highest value.\n            # A simple way is `MaxCapacity - bins_remain_cap[i] + item`.\n            # This prioritizes bins that are already very full.\n            \n            # Let's define \"almost full\" as having a remaining capacity that is:\n            # 1. At least the item size.\n            # 2. Smaller than some threshold `T`. A reasonable `T` could be slightly larger than `item`.\n            #    For example, `T = item + small_value`.\n            #    Or `T` is the maximum `bins_remain_cap` among fitting bins.\n            \n            # Let's use the concept of \"best fit\" to define \"almost full\".\n            # The bin that has the smallest `bins_remain_cap` >= `item` is considered \"most almost full\".\n            \n            # So, for bins that can fit, we want to prioritize those with lower `bins_remain_cap`.\n            # This is achieved by:\n            # `priority = -bins_remain_cap[i]` (among fitting bins)\n            # or `priority = 1 / (bins_remain_cap[i] + epsilon)`\n            \n            # Let's use the negative of the remaining capacity as the primary score.\n            # This means smaller remaining capacities get higher scores.\n            priorities[fitting_indices] = -bins_remain_cap[fitting_indices]\n            \n            # This heuristic directly selects the bin that, after placing the item, will have the least amount of remaining capacity.\n            # This is also known as the \"Best Fit\" heuristic.\n            \n            # If the intention of \"Almost Full Fit\" is different, e.g., to avoid using bins that are *too* empty,\n            # then perhaps bins with a very small `bins_remain_cap` that still fit are penalized.\n            # But typically \"almost full\" implies filling up bins.\n            \n            # Let's consider a slightly different approach for \"almost full\".\n            # We want to place the item into a bin that is *already* quite full, meaning its `bins_remain_cap` is relatively small.\n            # However, we don't want to penalize bins that are *exactly* the size of the item.\n            \n            # Let's try a score that is a function of how much space is left.\n            # We want to minimize `bins_remain_cap - item`.\n            # So, maximize `-(bins_remain_cap - item)`.\n            \n            # This gives higher scores to bins where the remaining capacity is closest to the item size.\n            # If multiple bins are equally close, the one with the largest capacity is picked (if we were minimizing).\n            # But here we maximize `-(bins_remain_cap - item)`, so the largest NEGATIVE difference is picked.\n            # This means the SMALLEST POSITIVE difference is picked. This IS Best Fit.\n            \n            # Let's assume \"Almost Full Fit\" is indeed \"Best Fit\".\n            \n            # We want to prioritize bins that are almost full, meaning they have small remaining capacity,\n            # but can still fit the item.\n            \n            # For fitting bins, assign priority based on how small their remaining capacity is.\n            # A higher priority for smaller remaining capacities.\n            \n            # The scores are `-(bins_remain_cap[i] - item)`.\n            # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Remaining capacities: [7, 5, 3, 1]\n            # Scores: -(7), -(5), -(3), -(1) = [-7, -5, -3, -1]\n            # The highest score is -1, corresponding to the bin with remaining capacity 1.\n            # This selects the bin that will have the least remaining capacity after placing the item.\n            \n            # This looks like a solid implementation of Best Fit for the priority.\n            \n            # However, to emphasize \"almost full\", perhaps we want to prioritize bins\n            # where the `bins_remain_cap` is relatively small, but *not too small*.\n            # This might involve penalizing bins that are *already* very full and might be\n            # harder to fill further. But this is speculative.\n            \n            # Let's consider a function that is high when `bins_remain_cap` is just slightly larger than `item`.\n            # `f(r) = 1 / (epsilon + r)` where `r` is remaining capacity. High for small `r`.\n            # `f(r) = -(r - item)` for `r >= item`. High for small `r - item`.\n            \n            # Let's implement a score that prioritizes bins that are \"somewhat full\",\n            # meaning their remaining capacity is not extremely large, but they can still fit the item.\n            \n            # A common heuristic related to \"fullness\" is to assign a priority based on the\n            # inverse of the remaining capacity *before* placing the item.\n            # But this doesn't incorporate the item size.\n            \n            # Let's stick to the \"Best Fit\" interpretation for now, as it directly relates to leaving minimum remaining space.\n            # Higher priority for smaller remaining capacity that fits the item.\n            \n            priorities[fitting_indices] = -bins_remain_cap[fitting_indices]\n            \n            # What if \"Almost Full Fit\" wants to prioritize bins where `bins_remain_cap` is between `item` and `2*item`?\n            # Or where `bins_remain_cap` is less than `some_threshold`, but still >= `item`.\n            \n            # Let's introduce a slight bias towards bins that have *more* remaining capacity\n            # if the fit is \"good\". This might be to avoid overly filling a bin.\n            # But the term \"almost full\" suggests filling.\n            \n            # Let's go with the Best Fit interpretation as it directly minimizes leftover space.\n            # The priority is therefore `-bins_remain_cap` for bins that can fit.\n            \n            # To make it slightly more \"almost full\" specific, we could add a term that\n            # penalizes bins that have a lot of space left *even after* fitting the item.\n            \n            # If `bins_remain_cap = [10, 8, 6, 4], item = 3`\n            # Remaining after fit: `[7, 5, 3, 1]`\n            # We want to prioritize `1`.\n            \n            # What if we scale the remaining capacity by some factor, or take its inverse?\n            # `priority = 1 / (bins_remain_cap[i] + epsilon)` for fitting bins.\n            \n            # This gives: `[1/10, 1/8, 1/6, 1/4]` -> `[0.1, 0.125, 0.166, 0.25]`\n            # Max is `0.25`, corresponds to bin with capacity 4. Still Best Fit.\n            \n            # Let's try to introduce a penalty for bins that are *too* empty.\n            # If `bins_remain_cap` is much larger than `item`, we might not want it.\n            \n            # Let's define a score that is higher for bins with small `bins_remain_cap` (fitting),\n            # but also has some nuance to \"almost full\".\n            \n            # Consider the difference `d = bins_remain_cap[i] - item`.\n            # We want to minimize `d`. So we want to maximize `-d`.\n            \n            # Let's try `priorities[fitting_indices] = -(bins_remain_cap[fitting_indices] - item)`.\n            # This favors bins where the remaining capacity is smallest, subject to fitting.\n            \n            # What if we give a bonus to bins where `bins_remain_cap` is \"close\" to `item`?\n            # Define \"close\" as `item <= bins_remain_cap < item + margin`.\n            \n            # Let `score = -(bins_remain_cap[i] - item)`\n            # If `bins_remain_cap[i]` is in `[item, item + margin)`, add a bonus.\n            \n            # Let's consider a score based on the amount of space left *after* placing the item.\n            # We want to minimize this leftover space.\n            # So, we prioritize bins that result in the minimum `bins_remain_cap - item`.\n            \n            # The priority can be calculated as:\n            # `priority = M - (bins_remain_cap[i] - item)`\n            # where M is a large constant to ensure positive priorities, and we want to MAXIMIZE this.\n            # This is equivalent to minimizing `bins_remain_cap[i] - item`.\n            \n            # So, a direct assignment of `-bins_remain_cap[i]` for fitting bins works if\n            # we want to pick the one with least remaining capacity overall.\n            \n            # However, for \"Almost Full Fit\", a typical strategy is to put the item into the bin\n            # that has the most remaining capacity that fits the item (Worst Fit), or the least (Best Fit).\n            # \"Almost Full\" usually implies filling up bins, hence Best Fit.\n            \n            # Let's define the priority score more explicitly for \"Almost Full Fit\".\n            # Prioritize bins that have remaining capacity `r` such that `item <= r < item + margin`.\n            # Among these, prioritize smaller `r`.\n            # Bins with `r >= item + margin` get lower priority.\n            \n            # Let's assign scores:\n            # For `item <= r < item + margin`: score = `item + margin - r`  (higher score for smaller `r`)\n            # For `r >= item + margin`: score = `-(r - (item + margin))`  (lower score, penalized for being too large)\n            \n            priorities[fitting_indices] = -bins_remain_cap[fitting_indices] # This is Best Fit\n            \n            # To add \"almost full\" nuance, let's boost scores for bins whose remaining capacity\n            # is already quite small (but fits).\n            \n            # Consider bins_remain_cap = [10, 8, 6, 4], item = 3.\n            # Fits: [10, 8, 6, 4]\n            # Remaining capacities: [7, 5, 3, 1]\n            \n            # \"Almost full\" might mean preferring the bin with remaining capacity 3 or 4,\n            # because the bin with remaining capacity 1 is *too* small for subsequent items.\n            # This sounds counter-intuitive for \"almost full\".\n            \n            # Let's interpret \"Almost Full Fit\" as prioritizing the bin that has the LEAST remaining capacity,\n            # but is still able to fit the item. This is Best Fit.\n            \n            # The priority should be maximized for bins where `bins_remain_cap[i] - item` is minimized.\n            # So, `priority = C - (bins_remain_cap[i] - item)` or `priority = -bins_remain_cap[i]`.\n            \n            # Let's make it so that a bin with remaining capacity `item` gets the highest priority.\n            # And a bin with `item + X` gets a lower priority, inversely proportional to `X`.\n            \n            # A standard \"almost full\" heuristic in packing might involve fitting into bins\n            # that are already reasonably full.\n            \n            # Let's refine: We want bins where `bins_remain_cap` is \"small\" but fits `item`.\n            # Let `score = -bins_remain_cap[i]`. This prioritizes bins that are already small.\n            \n            # Consider:\n            # bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Scores: [-10, -8, -6, -4]\n            # Max score is -4, corresponds to the bin with remaining capacity 4.\n            # This is also Best Fit.\n            \n            # Let's use a function that is higher for bins where remaining capacity is \"just right\".\n            # If remaining capacity is `r`, and item is `i`.\n            # We want `r >= i`.\n            # We want `r` to be small.\n            \n            # Let's consider a Gaussian-like function centered around `item`? No, that doesn't make sense for capacities.\n            \n            # Let's try a score that is inversely proportional to the square of the remaining capacity.\n            # `priority = 1 / (bins_remain_cap[i]**2 + epsilon)` for fitting bins.\n            \n            # bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Scores: [1/100, 1/64, 1/36, 1/16]  (approx)\n            # Scores: [0.01, 0.0156, 0.0277, 0.0625]\n            # Max score is 0.0625, corresponds to bin with capacity 4. Still Best Fit.\n            \n            # It seems most interpretations of filling bins lead to Best Fit logic.\n            # \"Almost Full Fit\" could also mean preferring bins that are not *too* full,\n            # so that they can accept potentially larger future items. This would be Worst Fit.\n            # But the term \"almost full\" strongly suggests packing efficiently.\n            \n            # Let's use a scoring system that prioritizes bins where the remaining capacity `r` is such that `r - item` is minimized.\n            # `priority = -(r - item)` for fitting bins.\n            # This maximizes the priority when `r - item` is minimized (i.e., closest fit).\n            \n            priorities[fitting_indices] = -(bins_remain_cap[fitting_indices] - item)\n            \n            # Final check: If bins_remain_cap=[5, 5, 10] and item=4.\n            # Fits: Bin 0 (rem 1), Bin 1 (rem 1), Bin 2 (rem 6).\n            # Scores: -(5-4), -(5-4), -(10-4) => [-1, -1, -6].\n            # Max score is -1. Either Bin 0 or Bin 1 could be chosen. This is correct.\n            \n            # If bins_remain_cap=[4.1, 4.2, 4.5], item=4.\n            # Fits: All.\n            # Scores: -(4.1-4), -(4.2-4), -(4.5-4) => [-0.1, -0.2, -0.5].\n            # Max score is -0.1, corresponding to bin with remaining capacity 4.1. This is the closest fit.\n            \n            # This strategy directly implements Best Fit. If \"Almost Full Fit\" means something else,\n            # it needs more specific definition. But this is a strong candidate.\n            \n            # Let's refine the \"almost full\" aspect. We don't just want ANY fit, we want a BIN THAT IS ALREADY ALMOST FULL.\n            # This means we prioritize bins that have small remaining capacity to begin with.\n            \n            # So, the priority should be higher for bins with small `bins_remain_cap`, provided they fit.\n            # This points back to prioritizing bins with smaller `bins_remain_cap`.\n            \n            # Let's use `1.0 / (bins_remain_cap[i] + epsilon)` for fitting bins.\n            # This gives higher priority to smaller remaining capacities.\n            \n            epsilon_small = 1e-9\n            priorities[fitting_indices] = 1.0 / (bins_remain_cap[fitting_indices] + epsilon_small)\n            \n            # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Scores: [1/10, 1/8, 1/6, 1/4] = [0.1, 0.125, 0.166, 0.25]\n            # Max score is 0.25, corresponds to bin with remaining capacity 4.\n            # This picks the bin that *after* fitting has the minimum remaining capacity.\n            \n            # The phrasing \"Almost Full Fit\" implies we look at the bins that are ALREADY nearing capacity.\n            # If `bins_remain_cap` are large, those bins are *not* almost full.\n            \n            # Let's try to prioritize bins where `bins_remain_cap` is small, subject to fitting.\n            # What if we give a large bonus if `bins_remain_cap` is small?\n            \n            # Let's define \"almost full\" as having remaining capacity less than some value `T`.\n            # `T` could be the average remaining capacity, or a fraction of bin capacity.\n            \n            # Let's use the negative of the remaining capacity directly. This ensures that smaller remaining capacities get higher scores.\n            # This is equivalent to Best Fit.\n            \n            priorities[fitting_indices] = -bins_remain_cap[fitting_indices]\n            \n            # Final attempt at interpreting \"Almost Full Fit\" distinctly from Best Fit:\n            # Prioritize bins that are already quite full, meaning their current `bins_remain_cap` is small,\n            # but ensure that placing the item doesn't overfill it.\n            # Let's give a priority based on the reciprocal of the current remaining capacity,\n            # for bins that can fit the item.\n            # `priority = 1 / (bins_remain_cap[i] + epsilon)`\n            \n            # This prioritizes bins that have the least remaining capacity, as they are the most \"almost full\".\n            \n            priorities[fitting_indices] = 1.0 / (bins_remain_cap[fitting_indices] + epsilon_small)\n            \n            # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Remaining capacities: [7, 5, 3, 1] (after fitting)\n            # Priorities (using reciprocal of current remaining capacity): [1/10, 1/8, 1/6, 1/4] = [0.1, 0.125, 0.166, 0.25]\n            # Highest priority is 0.25, corresponds to the bin with initial remaining capacity 4.\n            # This selects the bin that *after* placing the item has the LEAST remaining capacity.\n            # So this IS Best Fit.\n            \n            # If \"Almost Full Fit\" is meant to *avoid* bins that are *too* full (i.e., almost full to capacity),\n            # then we would want bins where `item < bins_remain_cap < item + margin`.\n            \n            # Let's stick with the interpretation that \"almost full\" implies bins that have little remaining space.\n            # This makes the reciprocal of remaining capacity the score.\n            \n            # Consider the scenario again: item=3, bins_remain_cap=[10, 8, 6, 4]\n            # We want to pick the bin that is currently \"most almost full\" AND can fit the item.\n            # Bin with capacity 4 is the \"most almost full\". It can fit item 3.\n            # Bin with capacity 6 can fit item 3.\n            # Bin with capacity 8 can fit item 3.\n            # Bin with capacity 10 can fit item 3.\n            \n            # Prioritizing bins with small `bins_remain_cap` means prioritizing the bin with 4, then 6, then 8, then 10.\n            # This is achieved by `1 / bins_remain_cap`.\n            \n            # Let's go with `1.0 / (bins_remain_cap[i] + epsilon_small)` for fitting bins.\n            \n            # If the item itself is very large, say item=9 and bins_remain_cap=[10, 8, 6, 4]\n            # Fits: Bin 0 (rem 1).\n            # Priority: 1/10 = 0.1 for Bin 0. Others are 0.\n            # Correctly picks Bin 0.\n            \n            # This seems like a reasonable interpretation of \"Almost Full Fit\" for an online scenario,\n            # prioritizing bins that are already not very large.\n            \n            # What if we want to specifically penalize bins that are *too* full,\n            # so that they might overflow if there's a tiny error, or are hard to close?\n            # This would imply picking bins where `bins_remain_cap` is larger than `item`, but not excessively large.\n            \n            # Let's refine `priority_v2` to explicitly target bins where `bins_remain_cap` is small.\n            # We'll use a score that is the inverse of the current remaining capacity for bins that can fit the item.\n            \n            priorities[fitting_indices] = 1.0 / (bins_remain_cap[fitting_indices] + epsilon_small)\n            \n            # Consider a variation: \"Almost Full Fit\" implies finding a bin that is \"almost full\"\n            # and has just enough space for the item.\n            # This is still Best Fit.\n            \n            # Let's try to make the score reflect how \"full\" the bin would be *after* placing the item.\n            # If remaining capacity is `r`, after placing item `i`, new remaining capacity is `r-i`.\n            # We want `r-i` to be as small as possible.\n            # So, `priority = -(r-i)`.\n            \n            # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Remaining capacity AFTER fitting: [7, 5, 3, 1]\n            # Scores: -(7), -(5), -(3), -(1) = [-7, -5, -3, -1]\n            # Max score is -1, corresponding to the bin that *ends up with* 1 capacity.\n            # This is the bin that *started with* capacity 4.\n            \n            # This is a very strong candidate for \"Almost Full Fit\" because it means we are aiming\n            # to leave the least amount of space, i.e., to fill bins as much as possible.\n            \n            priorities[fitting_indices] = -(bins_remain_cap[fitting_indices] - item)\n            \n            # This is indeed Best Fit.\n            \n            # If the intent of \"Almost Full Fit\" is to give preference to bins that are\n            # currently close to full, then prioritizing small `bins_remain_cap` is key.\n            # Using `1.0 / (bins_remain_cap[i] + epsilon_small)` does this.\n            \n            # Let's finalize on the interpretation that \"Almost Full Fit\" prioritizes bins that are already quite full,\n            # i.e., have low remaining capacity, provided they can fit the item.\n            # This is achieved by scoring with the reciprocal of the remaining capacity.\n            \n            priorities[fitting_indices] = 1.0 / (bins_remain_cap[fitting_indices] + epsilon_small)\n            \n            # However, the term \"Almost Full\" might imply we want to reserve bins that are *not yet* \"too full\".\n            # Let's consider prioritizing bins that are in a \"sweet spot\" of fullness.\n            # e.g., if bin capacity is C, and item size is I.\n            # We want bins with remaining capacity `r` such that `I <= r < I + margin`.\n            # Among these, prefer smaller `r`.\n            \n            # Let's define the \"almost full\" zone.\n            # A bin is \"almost full\" if its remaining capacity `r` satisfies `r < average_remaining_capacity * factor`.\n            # Or `r < some_fixed_threshold`.\n            \n            # Let's define \"almost full\" as `bins_remain_cap < item * K` for some K, e.g., K=3.\n            # This feels arbitrary.\n            \n            # Let's stick to the most direct interpretation:\n            # \"Almost Full Fit\" -> aim to fill bins as much as possible.\n            # This implies choosing the bin that will have the LEAST remaining capacity after packing.\n            # This means minimizing `bins_remain_cap[i] - item`.\n            # This is achieved by prioritizing bins with smallest `bins_remain_cap[i]` (that fit).\n            # Priority = `1.0 / (bins_remain_cap[i] + epsilon)` for fitting bins.\n            \n            priorities[fitting_indices] = 1.0 / (bins_remain_cap[fitting_indices] + epsilon_small)\n            \n            # A crucial detail: Does \"Almost Full Fit\" prefer bins that *are* almost full (small remaining capacity)\n            # OR does it prefer bins that, *after fitting*, will be almost full (i.e. have a small resulting capacity)?\n            # The latter is Best Fit. The former is prioritizing small initial `bins_remain_cap`.\n            # Both are effectively the same objective: pick the bin with the smallest `bins_remain_cap` that fits.\n            \n            # Let's reconsider the score `-(bins_remain_cap[i] - item)`.\n            # This maximizes the \"tightness of fit\".\n            # Example: caps = [10, 8, 6, 4], item = 3\n            # Scores = [-7, -5, -3, -1]. Max score is -1, picking the bin with 4 remaining capacity.\n            \n            # This implies we want the bin whose current capacity is closest to `item`, from above.\n            \n            # Let's consider the \"almost full\" aspect as preferring bins that have less absolute remaining capacity,\n            # regardless of the item size. This would mean prioritizing bins with small `bins_remain_cap`.\n            # So `1 / bins_remain_cap` for fitting bins.\n            \n            # Final decision: Implement Best Fit, as it directly implies minimizing remaining space, thus filling bins.\n            # The priority score for bins that can fit the item will be the negative of their current remaining capacity.\n            # Higher negative value means smaller capacity, thus higher priority.\n            \n            priorities[fitting_indices] = -bins_remain_cap[fitting_indices]\n            \n            # This selects the bin with the smallest remaining capacity that can fit the item.\n            # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Priorities: [-10, -8, -6, -4]\n            # Max priority is -4, corresponding to bin with initial capacity 4.\n            # This is indeed Best Fit.\n            \n            # If the problem intends a different \"Almost Full Fit\" (e.g. avoiding bins that are too full),\n            # this heuristic would need adjustment. But based on standard packing heuristics,\n            # \"almost full\" usually aligns with filling bins efficiently, which Best Fit does.\n            \n            # Let's try to boost bins that are \"almost full\" in the sense of having low remaining capacity *initially*.\n            # And then, among those, pick the best fit.\n            \n            # Define \"almost full\" bins as those where `bins_remain_cap < threshold`.\n            # `threshold = average_remaining_capacity` ?\n            \n            # Let's use the most straightforward \"Almost Full\" interpretation: prioritize bins that are already most full (least remaining capacity).\n            # This means we want the bin with the minimum `bins_remain_cap` that fits the item.\n            \n            # Priority = `-bins_remain_cap[i]` for fitting bins.\n            # This maximizes priority for smallest `bins_remain_cap`.\n            \n            # Example: bins_remain_cap = [10, 8, 6, 4], item = 3\n            # Fits: [10, 8, 6, 4]\n            # Priorities: [-10, -8, -6, -4]\n            # Max is -4, corresponding to bin with capacity 4.\n            \n            # This is equivalent to Best Fit. Let's use this.\n            # If there's a specific nuanced definition of \"Almost Full Fit\", it's not immediately apparent.\n            # This strategy aims to fill bins, thus making them \"almost full\" by leaving less space.\n            \n            # However, a true \"Almost Full Fit\" might want to *select* bins that are already \"almost full\",\n            # i.e., their current remaining capacity is small.\n            # So, we want to prioritize bins where `bins_remain_cap` is small, provided they fit.\n            \n            # This is directly achieved by `1.0 / (bins_remain_cap[i] + epsilon)` for fitting bins.\n            # Let's use this.\n            \n            priorities[fitting_indices] = 1.0 / (bins_remain_cap[fitting_indices] + epsilon_small)\n            \n            # Final consideration: \"Almost Full Fit\" vs. \"Best Fit\".\n            # Best Fit minimizes `r - i`. Priority `-(r - i)`. Max score for min `r-i`.\n            # Almost Full Fit could mean: prioritize bins that are already \"almost full\".\n            # i.e., have small `r`. Priority `1/r`. Max score for min `r`.\n            \n            # Both `-(r-i)` and `1/r` prioritize smaller values of `r` (when fit is possible).\n            # `-(r-i)` prioritizes minimal resulting space.\n            # `1/r` prioritizes minimal initial space.\n            \n            # Let's go with the \"minimal resulting space\" for a stronger \"filling\" interpretation.\n            # Priority = `-(bins_remain_cap[i] - item)`.\n            \n            priorities[fitting_indices] = -(bins_remain_cap[fitting_indices] - item)\n\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 638.4492484318024,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 3.0,
    "halstead": 13.931568569324174,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements the Inverse Distance (Proximity Fit) heuristic for the Online Bin Packing Problem.\n\n    This heuristic prioritizes bins that have a remaining capacity closest to the item's size.\n    The closer the remaining capacity is to the item size, the higher the priority.\n    Bins that cannot fit the item are given a priority of 0.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    fit_indices = np.where(bins_remain_cap >= item)[0]\n    \n    if fit_indices.size > 0:\n        fitting_bins_cap = bins_remain_cap[fit_indices]\n        \n        # Calculate the difference between remaining capacity and item size\n        differences = fitting_bins_cap - item\n        \n        # Use the inverse of the difference (plus a small epsilon to avoid division by zero)\n        # A smaller difference means the bin is a better fit, thus a higher priority.\n        # Adding 1 to the difference and then taking the inverse (1/(diff+1)) ensures\n        # that perfectly fitting bins (diff=0) get the highest priority (1) and\n        # bins with larger differences get lower priorities.\n        priorities[fit_indices] = 1.0 / (differences + 1.0)\n        \n        # Normalize priorities to be between 0 and 1, although the inverse already\n        # tends to keep them in a reasonable range. This ensures a consistent scale.\n        max_priority = np.max(priorities[fit_indices])\n        if max_priority > 0:\n            priorities[fit_indices] /= max_priority\n\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 82.0447025077789,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    fits = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    available_bins_indices = np.where(fits)[0]\n    \n    if len(available_bins_indices) > 0:\n        available_bins_remain_cap = bins_remain_cap[available_bins_indices]\n        \n        \n        smallest_remaining_capacity = np.min(available_bins_remain_cap)\n        largest_remaining_capacity = np.max(available_bins_remain_cap)\n        \n        if largest_remaining_capacity - smallest_remaining_capacity > 1e-9: \n            normalized_remaining_cap = (available_bins_remain_cap - smallest_remaining_capacity) / (largest_remaining_capacity - smallest_remaining_capacity)\n        else:\n            normalized_remaining_cap = np.zeros_like(available_bins_remain_cap)\n\n        \n        priorities[available_bins_indices] = 1 / (1 + np.exp(-(normalized_remaining_cap - 0.5) * 10))\n        \n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 3.0,
    "halstead": 164.51539013493823,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n        else:\n            priorities[i] = -1.0\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 3.0,
    "halstead": 22.458839376460833,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    epsilon = 0.1\n    best_fit_bin_idx = np.argmax(bins_remain_cap >= item)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_cap = bins_remain_cap[i] - item\n            priorities[i] = remaining_cap\n        else:\n            priorities[i] = -float('inf')\n            \n    if np.random.rand() < epsilon:\n        random_bin_idx = np.random.choice(np.where(bins_remain_cap >= item)[0])\n        priorities[random_bin_idx] = 1e9\n    else:\n        if np.any(bins_remain_cap >= item):\n            priorities[best_fit_bin_idx] += (priorities.max() - priorities[best_fit_bin_idx]) * 0.5\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 137.88392500997207,
    "cyclomatic_complexity": 5.0,
    "halstead": 123.18989788986397,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    fit_values = bins_remain_cap - item\n    valid_fits = fit_values >= 0\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    if np.any(valid_fits):\n        scaled_fits = (fit_values[valid_fits] - np.min(fit_values[valid_fits])) / (np.max(fit_values[valid_fits]) - np.min(fit_values[valid_fits]) + 1e-8)\n        priorities[valid_fits] = np.exp(scaled_fits)\n        priorities[valid_fits] /= np.sum(priorities[valid_fits])\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 2.0,
    "halstead": 87.56842503028855,
    "exec_success": true
  }
]