{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a dynamic penalty based on the item size relative to bin capacity.\n    Prioritizes bins that offer a \"near-perfect\" fit without excessive leftover space,\n    dynamically adjusting the penalty based on how \"tight\" the fit is.\n    This aims for better space utilization by being more sensitive to the actual item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # \"Best Fit\" component: Prioritize bins with minimum remaining capacity after packing.\n    # We use the negative of the remaining capacity to transform minimization into maximization.\n    # Add a small epsilon to ensure no division by zero or log(0) if remaining_cap == item.\n    # Using log to compress the range and emphasize smaller differences.\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)\n    \n    # Dynamic Penalty component: Penalize bins with significantly more capacity than needed.\n    # The penalty is higher when the \"excess capacity\" (remaining_cap - item) is large\n    # relative to the item's size. This makes the penalty scale with the item's magnitude.\n    \n    # Calculate the \"tightness ratio\": (item_size) / (remaining_capacity_after_packing)\n    # A higher ratio means a tighter fit.\n    tightness_ratio = item / (suitable_bins_remain_cap - item + 1e-9)\n    \n    # Calculate a penalty that is higher for bins with a lower tightness ratio (more excess capacity relative to item size)\n    # We want to penalize bins where (suitable_bins_remain_cap - item) is large compared to 'item'.\n    # Using a sigmoid-like function (inverse of a scaled ratio) to dampen extreme values and provide a smoother penalty.\n    # The scaling factor (e.g., 1.0) can be tuned.\n    \n    # Higher penalty for lower tightness_ratio. Invert and add 1 to avoid division by zero and ensure positive penalty.\n    # A larger suitable_bins_remain_cap relative to 'item' leads to a smaller tightness_ratio,\n    # which after inversion and addition, results in a larger penalty.\n    # We want to *subtract* this penalty from the best_fit_score, so a higher penalty means a lower final score.\n    penalty_component = 1.0 / (tightness_ratio + 0.5) # Add 0.5 to avoid issues with very tight fits.\n    \n    # Combine the scores. We want to maximize `best_fit_score` and minimize `penalty_component`.\n    # A simple subtraction works if interpreted as score = bf_score - penalty.\n    # Alternatively, we can multiply if penalties were designed as multipliers.\n    # Here, we aim for a higher combined score. Since `best_fit_score` is already a maximization proxy,\n    # and `penalty_component` is something we want to minimize (i.e., a higher penalty is bad),\n    # we subtract the penalty.\n    \n    # To make it a maximization problem directly, we can express it as:\n    # Score = best_fit_score - penalty_component\n    # or, if we want to penalize the penalty:\n    # Score = best_fit_score * (1 / (penalty_component + epsilon)) which is equivalent to\n    # Score = best_fit_score * tightness_ratio (approximately)\n    # Let's use a multiplicative approach where a higher `penalty_component` reduces the score.\n    # A simple way to combine: maximize `best_fit_score` and maximize `1 / (penalty_component + epsilon)`\n    # This means maximizing `best_fit_score * (tightness_ratio)`.\n    \n    # Let's refine the penalty: Penalize bins where `remaining_cap - item` is large relative to `item`.\n    # Consider `excess_ratio = (remaining_cap - item) / item`. We want to penalize high `excess_ratio`.\n    # Penalty_score = 1 / (excess_ratio + 1).\n    # This is similar to the tightness ratio logic but framed differently.\n    \n    excess_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)\n    # A bin with exact fit has excess_ratio = 0. A bin with large excess has large excess_ratio.\n    # We want to penalize large excess_ratio. So, a good penalty multiplier would be 1 / (excess_ratio + C).\n    # The smaller the `1 / (excess_ratio + C)`, the worse the bin.\n    # So, we want to maximize `best_fit_score` and maximize `1 / (excess_ratio + C)`.\n    # Thus, we can multiply them.\n    \n    penalty_multiplier = 1.0 / (excess_ratio + 0.2) # Add 0.2 to ensure it's not too aggressive.\n    \n    # Final priority is the product of the best-fit score proxy and the penalty multiplier.\n    # Higher best_fit_score is good. Higher penalty_multiplier is good (means low excess ratio).\n    priorities[suitable_bins_mask] = best_fit_score * penalty_multiplier\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Adaptive \"Best Fit with Dynamic Ratio\" heuristic.\n    This version dynamically adjusts the influence of the \"tightness\" or \"excess\" component\n    based on the item's size relative to the overall capacity distribution. It also\n    introduces a small preference for bins that are not \"too empty\".\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Base score: Primarily aims for Best Fit.\n    # Using log to compress the range and emphasize smaller differences.\n    # Add a small epsilon to avoid log(0).\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)\n\n    # Dynamic weighting factor: Adjust the importance of the \"tightness\" component.\n    # If the item is small relative to typical bin capacities, we might be more\n    # forgiving of slightly larger remaining capacities. If the item is large,\n    # we want tighter fits.\n    # Consider the average remaining capacity of *all* bins (even unsuitable ones)\n    # as a proxy for the general state of the packing.\n    # Alternatively, use the average remaining capacity of *suitable* bins.\n    avg_suitable_remain_cap = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0\n    \n    # If item is large relative to the average suitable remaining capacity,\n    # we want to heavily favor tight fits. If item is small, the penalty for\n    # excess capacity is less critical.\n    # Ratio: item_size / avg_suitable_remain_cap\n    # We want to increase the weight of the tightness component when this ratio is high.\n    \n    # Let's define a \"tightness preference\" score.\n    # We want to reward bins where `remaining_cap - item` is small relative to `item`.\n    # `excess_ratio = (remaining_cap - item) / item`\n    # We prefer lower `excess_ratio`.\n    excess_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)\n    \n    # A score that is high when excess_ratio is low.\n    # Use a sigmoid-like function to bound and smooth the effect.\n    # `tightness_score = 1 / (1 + exp(k * excess_ratio))`\n    # A simpler approach: `tightness_score = 1 / (excess_ratio + C)`\n    # Let's use a scaled inverse of excess_ratio.\n    # The scaling factor `item / avg_suitable_remain_cap` will modify the impact.\n    \n    # We want the `tightness_score` component to be more influential for larger items.\n    # Let's consider `weight_for_tightness = min(1.0, item / avg_suitable_remain_cap)`\n    # This weight is between 0 and 1.\n    weight_for_tightness = np.clip(item / (avg_suitable_remain_cap + 1e-9), 0.1, 2.0) # Clip to avoid extreme values\n\n    # Refined tightness score: higher for bins with less excess capacity relative to item size,\n    # scaled by how important tightness is.\n    # `tightness_factor = 1.0 / (1 + excess_ratio)` gives higher values for tighter fits.\n    # Multiply by `weight_for_tightness` to make it adaptive.\n    # We want to ADD this adaptive tightness score to the best_fit_score (which is already a maximization score).\n    # The original `best_fit_score` rewards tighter fits. We want to ADD a component that\n    # also rewards tighter fits, but with an adaptive weight.\n    \n    # Combine: Score = best_fit_score + adaptive_tightness_bonus\n    # `adaptive_tightness_bonus = weight_for_tightness * (1.0 / (1.0 + excess_ratio))`\n    # This encourages tight fits, with the encouragement amplified for larger items.\n\n    adaptive_tightness_bonus = weight_for_tightness * (1.0 / (1.0 + excess_ratio))\n    \n    # Small preference for not being \"too empty\" for the item.\n    # If remaining capacity is much larger than the item, it's less preferred.\n    # `emptiness_penalty = (suitable_bins_remain_cap - item) / suitable_bins_remain_cap`\n    # We want to penalize high `emptiness_penalty`. So we want to ADD something that\n    # is small when `emptiness_penalty` is large.\n    # `emptiness_score = 1.0 / (1.0 + emptiness_penalty)`\n    # This is essentially `item / suitable_bins_remain_cap`.\n    \n    # Let's use the negative of remaining capacity as a simple penalty for being too empty.\n    # The original best_fit_score already prioritizes minimal remaining capacity.\n    # Adding a component that penalizes large remaining capacity *even more*:\n    # `excess_capacity_penalty = -(suitable_bins_remain_cap - item)`\n    # But we want this penalty to be LESS impactful if `item` is small.\n    # `scaled_excess_capacity_penalty = - (suitable_bins_remain_cap - item) / (item + 1e-9)`\n    # This is negative of the `excess_ratio`.\n    # So, we can add `weight_for_tightness * (excess_ratio)` to the score.\n    # This means we are rewarding smaller excess ratios more when `weight_for_tightness` is high.\n    \n    # Final score: Maximize the log-based best fit score, and add an adaptive bonus\n    # for tightness, where the bonus is stronger for larger items or items that\n    # create tighter fits.\n    \n    # Let's adjust the `best_fit_score` calculation slightly.\n    # Instead of log, let's use a linear inverse of remaining capacity, then scale it.\n    # `bf_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)`\n    # This already favors minimal remaining capacity.\n    \n    # Now, add the adaptive tightness bonus.\n    # We want to favor smaller `excess_ratio = (suitable_bins_remain_cap - item) / item`.\n    # Let's use `1.0 / (excess_ratio + 1.0)` as a tightness indicator.\n    # We scale this by `weight_for_tightness`.\n    \n    tightness_indicator = 1.0 / (excess_ratio + 1.0) # Higher is better, up to 1.0\n    \n    # The combined score will be:\n    # `score = (1.0 / (suitable_bins_remain_cap - item + 1e-9)) * (1.0 + weight_for_tightness * tightness_indicator)`\n    # This combines the best fit (inverse remaining capacity) with an adaptive bonus for tightness.\n    # The `+ 1.0` in the multiplier ensures that the best-fit part is always dominant,\n    # and the tightness bonus modifies it.\n    \n    # Let's simplify the base score to avoid potential issues with very small differences in remaining capacity.\n    # Instead of `log`, let's use a simple inverse.\n    # Consider the \"waste\" `suitable_bins_remain_cap - item`. We want to minimize this.\n    # Base score: `- (suitable_bins_remain_cap - item)` - Higher is better.\n    # This directly rewards the smallest remaining capacity.\n    \n    # Now, apply the adaptive tightness bonus.\n    # Bonus should be higher when `excess_ratio` is lower AND `weight_for_tightness` is higher.\n    # `tightness_bonus = weight_for_tightness * (1.0 / (excess_ratio + 1.0))`\n    \n    # Combine them additively.\n    # `final_score = -(suitable_bins_remain_cap - item) + weight_for_tightness * (1.0 / (excess_ratio + 1.0))`\n    # This is essentially maximizing `(item - suitable_bins_remain_cap) + adaptive_bonus`.\n    \n    # Let's try a multiplicative approach again but with refined components.\n    # Score = (BestFitComponent) * (TightnessComponent)\n    # BestFitComponent: `-np.log(suitable_bins_remain_cap - item + 1e-9)` (already good for BF)\n    # TightnessComponent: Needs to be high when `excess_ratio` is low.\n    # `tightness_factor = 1.0 / (excess_ratio + 1.0)` (0 to 1)\n    # Adaptive scaling for tightness: `adaptive_tightness = 1.0 + weight_for_tightness * (tightness_factor - 0.5)`\n    # The `-0.5` shifts the range of `tightness_factor` so that the bonus is centered around typical values.\n    # `weight_for_tightness` is `item / avg_suitable_remain_cap`.\n    \n    # Let's consider a direct combination:\n    # Maximize `f(item, remaining_cap)`\n    # We want `remaining_cap` to be close to `item`.\n    # And we want `item / remaining_cap` to be high.\n    \n    # Revised Strategy:\n    # 1. Start with a Best Fit metric: `1.0 / (remaining_cap - item + eps)`\n    # 2. Add an adaptive \"closeness\" metric: penalize bins where `remaining_cap` is much larger than `item`.\n    #    The penalty should increase with `(remaining_cap - item) / item`.\n    #    The sensitivity to this penalty should be modulated by `item / avg_suitable_remain_cap`.\n    \n    # Base Best Fit Score: Maximize `-(remaining_cap - item)`\n    base_bf_score = -(suitable_bins_remain_cap - item)\n    \n    # Adaptive Closeness Score:\n    # We want to ADD a score that is higher for smaller `excess_ratio`.\n    # The magnitude of this addition is scaled by `weight_for_tightness`.\n    # `closeness_score = weight_for_tightness * (1.0 / (excess_ratio + 1.0))`\n    # This is the same as `adaptive_tightness_bonus` from before.\n    \n    # Combine additively:\n    # `final_priorities = base_bf_score + closeness_score`\n    # This combines the direct \"minimize waste\" with an adaptive \"maximize tight fit\" bonus.\n    \n    final_priorities = base_bf_score + adaptive_tightness_bonus\n    \n    # Apply the calculated priorities back to the original array.\n    priorities[suitable_bins_mask] = final_priorities\n    \n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), the code is identical. The ranking suggests a subtle difference in conceptualization, not implementation.\n\nComparing (2nd) vs (3rd), the code is identical. The ranking is arbitrary or based on external factors not evident from the code.\n\nComparing (3rd) vs (4th): Heuristic 3 attempts to combine \"Best Fit\" with a penalty for large excess capacity relative to item size using a `tightness_ratio` and `penalty_component`. Heuristic 4 introduces \"Worst Fit\" concepts and a \"dynamic gap penalty,\" but its implementation primarily focuses on `best_fit_score * gap_management_score`, where `gap_management_score` is `1.0 / (1.0 + (gap / item))`. Heuristic 3's penalty is more directly tied to the `remaining_cap - item` ratio, whereas Heuristic 4 uses `item / (remaining_cap)`. The core idea of penalizing large gaps is similar, but Heuristic 4's `gap_management_score` might be more stable for very small items.\n\nComparing (4th) vs (5th): Heuristic 4 uses a multiplicative combination of Best Fit and a gap management score. Heuristic 5 introduces a sigmoid for tight fits and a penalty for large initial capacities, combining them multiplicatively. Heuristic 5's sigmoid introduces non-linearity, potentially offering smoother preferences for tight fits. Heuristic 4's approach is more directly interpretable as Best Fit scaled by a tightness factor.\n\nComparing (5th) vs (6th): Heuristic 5 uses a sigmoid and a simple inverse capacity penalty. Heuristic 6 prioritizes exact fits with a very high score and then uses exponential decay based on normalized slack for non-exact fits. Heuristic 6's explicit handling of exact fits is a strong point, but its normalization of slack might be sensitive to extreme values.\n\nComparing (6th) vs (7th): Heuristic 6 has explicit exact fit handling and exponential decay. Heuristic 7 also prioritizes exact fits (with a slightly lower score) and then combines Best Fit (`1.0 / (remaining_capacities_after_fit)`) with a preference for \"almost full\" bins (using `1.0 / (suitable_capacities)`). Heuristic 7's additive combination of these two preferences, weighted, offers a different balance.\n\nComparing (7th) vs (8th): Heuristics 7 and 8 are identical.\n\nComparing (8th) vs (9th): Heuristic 8 uses a sigmoid for tight fits and an inverse capacity penalty. Heuristic 9 combines a tightness score (`1.0 / slack`) with a fill ratio (`item / remaining_cap`), using multiplication. Heuristic 9's multiplicative approach is more direct in rewarding both tight fits and good item utilization within the bin.\n\nComparing (9th) vs (10th): Heuristic 9 multiplies tightness and fill ratio. Heuristic 10 does the same but adds an \"almost full\" bonus, which is essentially another term favoring bins with low initial remaining capacity. The additive bonus provides an additional layer of preference.\n\nComparing (10th) vs (11th): Heuristic 10 combines efficiency (tightness * fill ratio) with an \"almost full\" bonus additively. Heuristic 11 uses a weighted additive combination of \"almost full\" preference and \"tightest fit\" preference. Heuristic 11's explicit weighting of preferences is more structured than Heuristic 10's additive bonus.\n\nComparing (11th) vs (12th): Heuristics 11 and 12 are identical.\n\nComparing (12th) vs (13th): Heuristics 12 and 13 are identical.\n\nComparing (13th) vs (14th): Heuristic 13 is identical to 11 and 12. Heuristic 14 introduces an \"adaptive Best Fit\" by dynamically weighting a tightness component based on the item's size relative to average remaining capacity. It also uses a log-based best-fit score. This adaptivity is a novel aspect.\n\nComparing (14th) vs (15th): Heuristics 14 and 15 are identical.\n\nComparing (15th) vs (16th): Heuristic 15 is identical to 14. Heuristic 16 combines Best Fit (log scale) with a refined slack minimization and a fill ratio component, using multiplication. It also introduces a `slack_decay_factor` (`exp(-relative_slack)`). This multiplicative approach with an exponential decay is a strong combination.\n\nComparing (16th) vs (17th): Heuristics 16 and 17 are identical.\n\nComparing (17th) vs (18th): Heuristics 17 and 18 are identical.\n\nComparing (18th) vs (19th): Heuristic 18 is identical to 16 and 17. Heuristic 19 attempts to combine Best Fit, an adaptive slack penalty (normalized by average excess capacity), and a uniformity score (penalizing deviation from average remaining capacity). This multi-faceted approach aims for more balanced packing.\n\nComparing (19th) vs (20th): Heuristic 19 combines Best Fit (log), adaptive slack penalty, and uniformity. Heuristic 20 combines Best Fit (log), fullness score (inverse capacity), multiplicatively. Heuristic 19's attempt at adaptivity and uniformity suggests a more sophisticated strategy than Heuristic 20's simpler multiplicative combination.\n\nOverall, heuristics that explicitly handle exact fits (6, 7), use adaptive weights or penalties based on item size or system state (14, 15, 19), or combine multiple strong metrics multiplicatively with decay functions (16, 17, 18) appear to be conceptually superior. The ranking seems to generally increase in complexity and adaptivity up to a point, then potentially plateau or slightly decline in perceived quality.\n- \nHere's a redefined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Robustness, adaptability, clarity, parsimony, performance, objective function.\n*   **Advice:** Focus on designing heuristics with clear, interpretable objective functions that can adapt to varying problem states (e.g., item sizes, bin utilization). Prioritize vectorized implementations for efficiency.\n*   **Avoid:** Redundant or overly complex metric combinations, arbitrary thresholds, and heuristics that don't demonstrably improve performance across a range of scenarios.\n*   **Explanation:** True self-reflection means identifying core principles of good heuristic design (like clarity and adaptability) and ruthlessly eliminating elements that introduce complexity without clear benefit, ensuring robustness and efficient execution.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}