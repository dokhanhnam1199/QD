[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines 'Best Fit' with an adaptive penalty for large slack, scaled by item size.\n\n    This heuristic prioritizes bins that result in the smallest remaining capacity after packing\n    (Best Fit), while also penalizing bins where the slack (remaining capacity - item) is large\n    relative to the item's size. The penalty's impact is amplified for larger items.\n    \"\"\"\n    epsilon_small = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    fitting_indices = np.where(bins_remain_cap >= item)[0]\n\n    if fitting_indices.size > 0:\n        suitable_bins_remain_cap = bins_remain_cap[fitting_indices]\n        \n        # Component 1: Best Fit score (higher is better)\n        # Maximizes -(remaining_capacity - item), which is equivalent to minimizing (remaining_capacity - item)\n        best_fit_score = -(suitable_bins_remain_cap - item)\n\n        # Component 2: Adaptive Slack Penalty score (higher is better for smaller slack)\n        # Calculates slack relative to item size: (remaining_cap - item) / item\n        # We want to reward smaller relative slack. So, we use 1.0 / (relative_slack + 1.0).\n        # The weight `item / (np.mean(bins_remain_cap[bins_remain_cap > 0]) + epsilon_small)`\n        # makes the penalty more influential for larger items.\n        avg_positive_cap = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0\n        weight_for_slack = item / (avg_positive_cap + epsilon_small)\n        \n        relative_slack = (suitable_bins_remain_cap - item) / (item + epsilon_small)\n        \n        # The score component is higher when relative_slack is low.\n        adaptive_slack_score = weight_for_slack * (1.0 / (relative_slack + 1.0))\n\n        # Combine scores additively. Best fit is the base, adaptive slack provides refinement.\n        combined_priority = best_fit_score + adaptive_slack_score\n        \n        priorities[fitting_indices] = combined_priority\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.11846828879138,
    "cyclomatic_complexity": 3.0,
    "halstead": 216.22022703449025,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits, then uses a weighted sum of 'most full' and 'tightest fit'.\n\n    This heuristic aims for efficient packing by strongly favoring exact fits,\n    and otherwise balancing the preference for bins that are already nearly full\n    with the preference for minimizing leftover space after packing.\n    \"\"\"\n    epsilon = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item\n    fitting_indices = np.where(bins_remain_cap >= item - epsilon)[0]\n\n    if fitting_indices.size == 0:\n        return priorities # No bin can fit the item\n\n    suitable_bins_remain_cap = bins_remain_cap[fitting_indices]\n\n    # --- Heuristic Design Principles ---\n    # 1. Exact Fit: Give a very high priority to bins that fit the item perfectly\n    #    to avoid any waste in that specific bin. This is crucial for overall efficiency.\n    # 2. Most Full (Preference for less empty bins): Favor bins that are already\n    #    closer to capacity. This can help consolidate items and potentially open\n    #    fewer new bins. Modeled as 1 / (initial remaining capacity + epsilon).\n    # 3. Tightest Fit (Best Fit): After considering fullness, prioritize bins that\n    #    leave minimal remaining capacity after the item is packed. This minimizes\n    #    immediate waste. Modeled as - (remaining capacity - item).\n    # 4. Weighted Combination: Combine 'Most Full' and 'Tightest Fit' preferences\n    #    using weights to balance their contributions. A slightly higher weight\n    #    for 'Most Full' encourages denser packing across bins, while 'Tightest Fit'\n    #    ensures efficient use of the chosen bin.\n\n    # Calculate priorities for fitting bins\n    remaining_after_fit = suitable_bins_remain_cap - item\n\n    # Score for exact fits (very high positive value)\n    exact_fit_mask = np.abs(remaining_after_fit) < epsilon\n    exact_fit_priorities = np.full(fitting_indices.size, 1e9, dtype=float) # High score for exact fits\n\n    # Scores for non-exact fits\n    non_exact_indices_in_subset = np.where(~exact_fit_mask)[0]\n    if non_exact_indices_in_subset.size > 0:\n        non_exact_suitable_bins_remain_cap = suitable_bins_remain_cap[non_exact_indices_in_subset]\n        non_exact_remaining_after_fit = remaining_after_fit[non_exact_indices_in_subset]\n\n        # Preference for bins that are already \"most full\" (lower initial remaining capacity)\n        # Higher score for bins with less remaining capacity. Add epsilon for stability.\n        most_full_score = 1.0 / (non_exact_suitable_bins_remain_cap + epsilon)\n\n        # Preference for \"tightest fit\" (minimal remaining capacity after packing)\n        # Higher score for smaller remaining capacity after item is placed.\n        tightest_fit_score = -non_exact_remaining_after_fit\n\n        # Combine preferences: A weighted sum.\n        # Weight for 'most_full' (e.g., 0.7) encourages using bins that are already somewhat full.\n        # Weight for 'tightest_fit' (e.g., 0.3) refines the choice among those.\n        # These weights can be tuned. A higher weight on 'most_full' leans towards filling up bins.\n        weight_most_full = 0.7\n        weight_tightest_fit = 0.3\n\n        combined_non_exact_priorities = (weight_most_full * most_full_score) + \\\n                                        (weight_tightest_fit * tightest_fit_score)\n\n        # Assign priorities to the fitting bins\n        priorities[fitting_indices[exact_fit_mask]] = exact_fit_priorities[exact_fit_mask]\n        priorities[fitting_indices[non_exact_indices_in_subset]] = combined_non_exact_priorities\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 191.36873322873222,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic 'fill ratio' consideration.\n    Prioritizes bins that offer a tight fit and maximize item utilization,\n    while remaining robust to extreme capacities.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mask for bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities  # No bin can fit the item\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    # Component 1: Best Fit (Minimize slack)\n    # We want to minimize (remaining_capacity - item).\n    # Using -log(slack + epsilon) makes smaller slacks yield higher scores.\n    # This strongly prefers bins that leave minimal space after packing.\n    slack = suitable_bins_remain_cap - item\n    best_fit_score = -np.log(slack + 1e-9)\n\n    # Component 2: Fill Ratio (Maximize item utilization within the bin's current capacity)\n    # This score represents how much of the *current* remaining capacity the item would occupy.\n    # Maximizing item / suitable_bins_remain_cap is good, as it means the item fills\n    # a larger portion of the available space in that bin.\n    # This helps in scenarios where the absolute slack might be similar, but one bin\n    # is generally less full, thus offering more room for future items.\n    fill_ratio_score = item / (suitable_bins_remain_cap + 1e-9)\n\n    # Combine scores:\n    # A multiplicative combination of best_fit_score and fill_ratio_score.\n    # This encourages bins that are both a tight fit (high best_fit_score)\n    # AND where the item significantly contributes to filling the bin (high fill_ratio_score).\n    # It balances minimizing waste in the chosen bin with efficiently packing the current item.\n    # The log in best_fit_score helps to compress the range of slack, making the multiplicative\n    # effect more balanced.\n    combined_score = best_fit_score * fill_ratio_score\n\n    priorities[suitable_bins_mask] = combined_score\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 67.92979656960512,
    "cyclomatic_complexity": 2.0,
    "halstead": 89.92418250750748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive slack penalty, prioritizing tight fits and\n    dynamically adjusting penalty based on item size relative to bin state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Best Fit component: Maximize -(remaining_capacity - item)\n    # This directly rewards the smallest remaining capacity after packing.\n    best_fit_score = -(suitable_bins_remain_cap - item)\n\n    # Adaptive Slack Penalty component: Penalize bins where slack (remaining_cap - item) is large relative to item size.\n    # The penalty is scaled by how important tightness is (item size relative to average bin state).\n    # Calculate slack ratio: (remaining_cap - item) / item\n    slack_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)\n\n    # Calculate an adaptive weight for the slack penalty.\n    # If the item is large relative to the average remaining capacity of suitable bins,\n    # we increase the penalty's influence.\n    avg_suitable_remain_cap = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0\n    weight_for_tightness = np.clip(item / (avg_suitable_remain_cap + 1e-9), 0.1, 2.0) # Clip to avoid extreme values\n\n    # The adaptive slack score is higher for smaller slack ratios, scaled by weight.\n    # We want to ADD this to the best_fit_score.\n    adaptive_slack_score = weight_for_tightness * (1.0 / (slack_ratio + 1.0))\n    \n    # Combine the scores additively. This prioritizes minimizing waste (best_fit_score)\n    # and further rewards tight fits adaptively.\n    final_priorities = best_fit_score + adaptive_slack_score\n    \n    priorities[suitable_bins_mask] = final_priorities\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.11846828879138,
    "cyclomatic_complexity": 3.0,
    "halstead": 202.11890788006698,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with exponential decay on slack and a fullness bonus.\n    Prioritizes tight fits and bins that are already well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Component 1: Best Fit score (log scale for better discrimination of small slacks)\n    # Smaller remaining capacity after fit (slack) is better.\n    # Using -log(slack + epsilon) to maximize this.\n    slack = suitable_bins_remain_cap - item\n    best_fit_score = -np.log(slack + 1e-9)\n    \n    # Component 2: Tightness score with exponential decay\n    # Penalize bins that have large slack relative to their capacity.\n    # A bin with small slack relative to the item size is preferred.\n    # We want to reward small slack. Using exp(-k * slack) or similar.\n    # Let's use a normalized slack and apply exponential decay.\n    # Normalize slack by the item size to make it relative.\n    # relative_slack = slack / (item + 1e-9)\n    # Using a simpler slack_decay: exp(-slack / avg_capacity_of_suitable_bins)\n    \n    # Calculate a factor that decreases exponentially with slack.\n    # Higher values for smaller slack.\n    if slack.size > 0:\n        # Normalize slack by the maximum possible slack among suitable bins for better scaling.\n        # Or, simply use a heuristic decay factor.\n        # Let's use a factor that is high for small slack and decays.\n        # A simple approach: 1.0 / (1.0 + slack) or exp(-slack) or exp(-slack/C)\n        # A good decay: exp(-slack / average_slack_or_item_size)\n        avg_suitable_cap = np.mean(suitable_bins_remain_cap)\n        decay_factor = np.exp(-slack / (avg_suitable_cap + 1e-9))\n    else:\n        decay_factor = np.zeros_like(slack)\n\n    # Component 3: Fullness bonus (inverse of remaining capacity before packing)\n    # Prefer bins that are already more full (less remaining capacity).\n    # This is 1 / (initial_remaining_cap + epsilon).\n    fullness_score = 1.0 / (suitable_bins_remain_cap + 1e-9)\n    \n    # Combine scores multiplicatively:\n    # Maximize best_fit_score, maximize decay_factor (prefer small slack), maximize fullness_score.\n    # The product naturally encourages bins that satisfy all conditions.\n    combined_scores = best_fit_score * decay_factor * fullness_score\n    \n    priorities[suitable_bins_mask] = combined_scores\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 81.80095731950539,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit prioritization with a weighted score favoring tight fits\n    and bins that are already relatively full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_indices = np.where(can_fit_mask)[0]\n    \n    if not np.any(fitting_indices):\n        return priorities\n\n    fitting_bins_caps = bins_remain_cap[fitting_indices]\n    \n    # --- Component 1: Exact Fit Priority ---\n    # Assign a very high score to bins that provide an exact fit.\n    exact_fit_mask = fitting_bins_caps == item\n    priorities[fitting_indices[exact_fit_mask]] = 1e10\n    \n    # --- Component 2: Tight Fit (Best Fit) for Non-Exact Fits ---\n    # Calculate remaining capacity after placing the item in non-exact fitting bins.\n    non_exact_fitting_indices_in_fitting = np.where(~exact_fit_mask)[0]\n    non_exact_fitting_bins_caps = fitting_bins_caps[~exact_fit_mask]\n    \n    if non_exact_fitting_bins_caps.size > 0:\n        remaining_after_fit = non_exact_fitting_bins_caps - item\n        \n        # Score based on how little is left over. Higher score for smaller remaining capacity.\n        # Adding epsilon to avoid division by zero if remaining_after_fit is 0 (though handled by exact_fit).\n        # Using 1 / (1 + remaining_after_fit) to map smaller remaining capacity to higher scores.\n        tight_fit_scores = 1.0 / (1.0 + remaining_after_fit)\n        \n        # --- Component 3: Preference for \"Almost Full\" Bins ---\n        # Favor bins that have less remaining capacity initially among the suitable ones.\n        # This encourages filling up bins more.\n        # Using inverse of initial remaining capacity, scaled.\n        almost_full_scores = 0.5 * (1.0 / (bins_remain_cap[fitting_indices[~exact_fit_mask]] + 1e-9))\n\n        # Combine scores for non-exact fits: weighted sum\n        # Weighting tight_fit_scores more heavily (e.g., 0.8) than almost_full_scores (e.g., 0.2).\n        combined_non_exact_score = 0.8 * tight_fit_scores + 0.2 * almost_full_scores\n        \n        # Scale these combined scores to be less than the exact fit priority.\n        # Normalize combined_non_exact_score to [0, 1] and scale down.\n        if np.max(combined_non_exact_score) > 0:\n            scaled_combined_scores = (combined_non_exact_score / np.max(combined_non_exact_score)) * 1e9\n        else:\n            scaled_combined_scores = np.zeros_like(combined_non_exact_score)\n            \n        priorities[fitting_indices[~exact_fit_mask]] = scaled_combined_scores\n        \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 284.3458750793272,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit (log-scaled) with a dynamic penalty for large excess capacity,\n    prioritizing near-perfect fits and efficient bin utilization.\n    \"\"\"\n    epsilon = 1e-9\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Component 1: Best Fit (log-scaled)\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    # Using log to compress the range and emphasize smaller differences.\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + epsilon)\n    \n    # Component 2: Dynamic Penalty (Excess Capacity Ratio)\n    # Penalize bins where the excess capacity (remaining_cap - item) is large\n    # relative to the item's size. This encourages using bins that are already\n    # somewhat filled rather than very empty ones for smaller items.\n    # We want to maximize this component, so we use its inverse.\n    excess_capacity_ratio = (suitable_bins_remain_cap - item) / (item + epsilon)\n    # A higher ratio (more excess) means a lower score here.\n    # Adding 0.2 to the denominator to prevent overly aggressive penalties for small excesses.\n    fill_efficiency_score = 1.0 / (excess_capacity_ratio + 0.2) \n    \n    # Combine scores multiplicatively: Maximize both Best Fit and Fill Efficiency.\n    # A bin is preferred if it offers a good fit AND if the remaining space\n    # isn't excessively large compared to the item.\n    combined_score = best_fit_score * fill_efficiency_score\n    \n    priorities[suitable_bins_mask] = combined_score\n    \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 83.58595931392104,
    "cyclomatic_complexity": 2.0,
    "halstead": 138.24238017775622,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic penalty for large relative slack,\n    prioritizing bins that are tightly fitting and not excessively empty.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # --- Component 1: Best Fit Score (logarithmic) ---\n    # Encourages bins with minimal remaining capacity after packing.\n    # Add epsilon for numerical stability when remaining_cap == item.\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)\n    \n    # --- Component 2: Dynamic Gap (Slack) Management Score ---\n    # Penalizes bins where the difference (slack) between bin's remaining capacity \n    # and item size is large, relative to the item size itself.\n    # Score is 1 for perfect fit (slack=0) and decreases as relative slack increases.\n    slack = suitable_bins_remain_cap - item\n    gap_management_score = 1.0 / (1.0 + (slack / (item + 1e-9)))\n    \n    # Combine scores multiplicatively: prioritize bins that are both tightly fitting \n    # and do not have an excessively large relative slack.\n    priorities[suitable_bins_mask] = best_fit_score * gap_management_score\n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 67.92979656960512,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.16184010614157,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a penalty for large remaining capacity.\n    Prioritizes bins where the item fits snugly and penalizes bins with\n    significant excess capacity, promoting efficient bin usage.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    # Metric 1: Tightness of fit (similar to Best Fit)\n    # High score for small `remaining_capacity - item`.\n    # Uses `1.0 / (slack + epsilon)`\n    slack = suitable_bins_remain_cap - item\n    tightness_score = 1.0 / (slack + 1e-9)\n\n    # Metric 2: Fill ratio of remaining space\n    # High score for `item / suitable_bins_remain_cap`.\n    # This implicitly penalizes bins with large `suitable_bins_remain_cap`.\n    fill_ratio = item / (suitable_bins_remain_cap + 1e-9)\n    \n    # Combine metrics multiplicatively: Prioritize bins that are both a tight fit\n    # AND where the item occupies a significant portion of the remaining capacity.\n    # This combination naturally penalizes bins with large `suitable_bins_remain_cap`\n    # because `fill_ratio` will be small. The `tightness_score` ensures that among\n    # bins with similar fill ratios, the one with less slack is preferred.\n    combined_score = tightness_score * fill_ratio\n\n    priorities[suitable_bin_indices] = combined_score\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 94.01164534875782,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive fill ratio, favoring tight fits and\n    bins where the item significantly utilizes remaining capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    # Best Fit Score: Prioritize bins that leave the smallest remaining capacity.\n    # Inverse of remaining capacity after fitting the item. Higher is better.\n    best_fit_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Adaptive Fill Ratio: Rewards bins where the item fills a larger portion of *available* space.\n    # This is dynamic, influenced by the capacity of the suitable bin.\n    # Higher score for item / suitable_bins_remain_cap.\n    fill_ratio = item / (suitable_bins_remain_cap + 1e-9)\n\n    # Combined Score: Multiplies Best Fit and Fill Ratio.\n    # This prioritizes bins that are a tight fit AND where the item represents a\n    # significant portion of the bin's available capacity, implicitly penalizing\n    # bins with large absolute remaining capacity that are still \"tight\" relative to the item.\n    combined_score = best_fit_score * fill_ratio\n\n    # Applying a small constant to ensure scores are positive, as `combined_score` could be very small.\n    # This also helps in cases where one component might approach zero.\n    final_priorities = combined_score + 1e-6\n\n    priorities[suitable_bin_indices] = final_priorities\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 110.44611534953322,
    "exec_success": true
  }
]