[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines 'Best Fit' with an adaptive penalty for large slack, scaled by item size.\n\n    This heuristic prioritizes bins that result in the smallest remaining capacity after packing\n    (Best Fit), while also penalizing bins where the slack (remaining capacity - item) is large\n    relative to the item's size. The penalty's impact is amplified for larger items.\n    \"\"\"\n    epsilon_small = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    fitting_indices = np.where(bins_remain_cap >= item)[0]\n\n    if fitting_indices.size > 0:\n        suitable_bins_remain_cap = bins_remain_cap[fitting_indices]\n        \n        # Component 1: Best Fit score (higher is better)\n        # Maximizes -(remaining_capacity - item), which is equivalent to minimizing (remaining_capacity - item)\n        best_fit_score = -(suitable_bins_remain_cap - item)\n\n        # Component 2: Adaptive Slack Penalty score (higher is better for smaller slack)\n        # Calculates slack relative to item size: (remaining_cap - item) / item\n        # We want to reward smaller relative slack. So, we use 1.0 / (relative_slack + 1.0).\n        # The weight `item / (np.mean(bins_remain_cap[bins_remain_cap > 0]) + epsilon_small)`\n        # makes the penalty more influential for larger items.\n        avg_positive_cap = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0\n        weight_for_slack = item / (avg_positive_cap + epsilon_small)\n        \n        relative_slack = (suitable_bins_remain_cap - item) / (item + epsilon_small)\n        \n        # The score component is higher when relative_slack is low.\n        adaptive_slack_score = weight_for_slack * (1.0 / (relative_slack + 1.0))\n\n        # Combine scores additively. Best fit is the base, adaptive slack provides refinement.\n        combined_priority = best_fit_score + adaptive_slack_score\n        \n        priorities[fitting_indices] = combined_priority\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.11846828879138,
    "cyclomatic_complexity": 3.0,
    "halstead": 216.22022703449025,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits, then uses a weighted sum of 'most full' and 'tightest fit'.\n\n    This heuristic aims for efficient packing by strongly favoring exact fits,\n    and otherwise balancing the preference for bins that are already nearly full\n    with the preference for minimizing leftover space after packing.\n    \"\"\"\n    epsilon = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item\n    fitting_indices = np.where(bins_remain_cap >= item - epsilon)[0]\n\n    if fitting_indices.size == 0:\n        return priorities # No bin can fit the item\n\n    suitable_bins_remain_cap = bins_remain_cap[fitting_indices]\n\n    # --- Heuristic Design Principles ---\n    # 1. Exact Fit: Give a very high priority to bins that fit the item perfectly\n    #    to avoid any waste in that specific bin. This is crucial for overall efficiency.\n    # 2. Most Full (Preference for less empty bins): Favor bins that are already\n    #    closer to capacity. This can help consolidate items and potentially open\n    #    fewer new bins. Modeled as 1 / (initial remaining capacity + epsilon).\n    # 3. Tightest Fit (Best Fit): After considering fullness, prioritize bins that\n    #    leave minimal remaining capacity after the item is packed. This minimizes\n    #    immediate waste. Modeled as - (remaining capacity - item).\n    # 4. Weighted Combination: Combine 'Most Full' and 'Tightest Fit' preferences\n    #    using weights to balance their contributions. A slightly higher weight\n    #    for 'Most Full' encourages denser packing across bins, while 'Tightest Fit'\n    #    ensures efficient use of the chosen bin.\n\n    # Calculate priorities for fitting bins\n    remaining_after_fit = suitable_bins_remain_cap - item\n\n    # Score for exact fits (very high positive value)\n    exact_fit_mask = np.abs(remaining_after_fit) < epsilon\n    exact_fit_priorities = np.full(fitting_indices.size, 1e9, dtype=float) # High score for exact fits\n\n    # Scores for non-exact fits\n    non_exact_indices_in_subset = np.where(~exact_fit_mask)[0]\n    if non_exact_indices_in_subset.size > 0:\n        non_exact_suitable_bins_remain_cap = suitable_bins_remain_cap[non_exact_indices_in_subset]\n        non_exact_remaining_after_fit = remaining_after_fit[non_exact_indices_in_subset]\n\n        # Preference for bins that are already \"most full\" (lower initial remaining capacity)\n        # Higher score for bins with less remaining capacity. Add epsilon for stability.\n        most_full_score = 1.0 / (non_exact_suitable_bins_remain_cap + epsilon)\n\n        # Preference for \"tightest fit\" (minimal remaining capacity after packing)\n        # Higher score for smaller remaining capacity after item is placed.\n        tightest_fit_score = -non_exact_remaining_after_fit\n\n        # Combine preferences: A weighted sum.\n        # Weight for 'most_full' (e.g., 0.7) encourages using bins that are already somewhat full.\n        # Weight for 'tightest_fit' (e.g., 0.3) refines the choice among those.\n        # These weights can be tuned. A higher weight on 'most_full' leans towards filling up bins.\n        weight_most_full = 0.7\n        weight_tightest_fit = 0.3\n\n        combined_non_exact_priorities = (weight_most_full * most_full_score) + \\\n                                        (weight_tightest_fit * tightest_fit_score)\n\n        # Assign priorities to the fitting bins\n        priorities[fitting_indices[exact_fit_mask]] = exact_fit_priorities[exact_fit_mask]\n        priorities[fitting_indices[non_exact_indices_in_subset]] = combined_non_exact_priorities\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 191.36873322873222,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic 'fill ratio' consideration.\n    Prioritizes bins that offer a tight fit and maximize item utilization,\n    while remaining robust to extreme capacities.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mask for bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities  # No bin can fit the item\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    # Component 1: Best Fit (Minimize slack)\n    # We want to minimize (remaining_capacity - item).\n    # Using -log(slack + epsilon) makes smaller slacks yield higher scores.\n    # This strongly prefers bins that leave minimal space after packing.\n    slack = suitable_bins_remain_cap - item\n    best_fit_score = -np.log(slack + 1e-9)\n\n    # Component 2: Fill Ratio (Maximize item utilization within the bin's current capacity)\n    # This score represents how much of the *current* remaining capacity the item would occupy.\n    # Maximizing item / suitable_bins_remain_cap is good, as it means the item fills\n    # a larger portion of the available space in that bin.\n    # This helps in scenarios where the absolute slack might be similar, but one bin\n    # is generally less full, thus offering more room for future items.\n    fill_ratio_score = item / (suitable_bins_remain_cap + 1e-9)\n\n    # Combine scores:\n    # A multiplicative combination of best_fit_score and fill_ratio_score.\n    # This encourages bins that are both a tight fit (high best_fit_score)\n    # AND where the item significantly contributes to filling the bin (high fill_ratio_score).\n    # It balances minimizing waste in the chosen bin with efficiently packing the current item.\n    # The log in best_fit_score helps to compress the range of slack, making the multiplicative\n    # effect more balanced.\n    combined_score = best_fit_score * fill_ratio_score\n\n    priorities[suitable_bins_mask] = combined_score\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 67.92979656960512,
    "cyclomatic_complexity": 2.0,
    "halstead": 89.92418250750748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive slack penalty, prioritizing tight fits and\n    dynamically adjusting penalty based on item size relative to bin state.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Best Fit component: Maximize -(remaining_capacity - item)\n    # This directly rewards the smallest remaining capacity after packing.\n    best_fit_score = -(suitable_bins_remain_cap - item)\n\n    # Adaptive Slack Penalty component: Penalize bins where slack (remaining_cap - item) is large relative to item size.\n    # The penalty is scaled by how important tightness is (item size relative to average bin state).\n    # Calculate slack ratio: (remaining_cap - item) / item\n    slack_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)\n\n    # Calculate an adaptive weight for the slack penalty.\n    # If the item is large relative to the average remaining capacity of suitable bins,\n    # we increase the penalty's influence.\n    avg_suitable_remain_cap = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1.0\n    weight_for_tightness = np.clip(item / (avg_suitable_remain_cap + 1e-9), 0.1, 2.0) # Clip to avoid extreme values\n\n    # The adaptive slack score is higher for smaller slack ratios, scaled by weight.\n    # We want to ADD this to the best_fit_score.\n    adaptive_slack_score = weight_for_tightness * (1.0 / (slack_ratio + 1.0))\n    \n    # Combine the scores additively. This prioritizes minimizing waste (best_fit_score)\n    # and further rewards tight fits adaptively.\n    final_priorities = best_fit_score + adaptive_slack_score\n    \n    priorities[suitable_bins_mask] = final_priorities\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.11846828879138,
    "cyclomatic_complexity": 3.0,
    "halstead": 202.11890788006698,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with exponential decay on slack and a fullness bonus.\n    Prioritizes tight fits and bins that are already well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Component 1: Best Fit score (log scale for better discrimination of small slacks)\n    # Smaller remaining capacity after fit (slack) is better.\n    # Using -log(slack + epsilon) to maximize this.\n    slack = suitable_bins_remain_cap - item\n    best_fit_score = -np.log(slack + 1e-9)\n    \n    # Component 2: Tightness score with exponential decay\n    # Penalize bins that have large slack relative to their capacity.\n    # A bin with small slack relative to the item size is preferred.\n    # We want to reward small slack. Using exp(-k * slack) or similar.\n    # Let's use a normalized slack and apply exponential decay.\n    # Normalize slack by the item size to make it relative.\n    # relative_slack = slack / (item + 1e-9)\n    # Using a simpler slack_decay: exp(-slack / avg_capacity_of_suitable_bins)\n    \n    # Calculate a factor that decreases exponentially with slack.\n    # Higher values for smaller slack.\n    if slack.size > 0:\n        # Normalize slack by the maximum possible slack among suitable bins for better scaling.\n        # Or, simply use a heuristic decay factor.\n        # Let's use a factor that is high for small slack and decays.\n        # A simple approach: 1.0 / (1.0 + slack) or exp(-slack) or exp(-slack/C)\n        # A good decay: exp(-slack / average_slack_or_item_size)\n        avg_suitable_cap = np.mean(suitable_bins_remain_cap)\n        decay_factor = np.exp(-slack / (avg_suitable_cap + 1e-9))\n    else:\n        decay_factor = np.zeros_like(slack)\n\n    # Component 3: Fullness bonus (inverse of remaining capacity before packing)\n    # Prefer bins that are already more full (less remaining capacity).\n    # This is 1 / (initial_remaining_cap + epsilon).\n    fullness_score = 1.0 / (suitable_bins_remain_cap + 1e-9)\n    \n    # Combine scores multiplicatively:\n    # Maximize best_fit_score, maximize decay_factor (prefer small slack), maximize fullness_score.\n    # The product naturally encourages bins that satisfy all conditions.\n    combined_scores = best_fit_score * decay_factor * fullness_score\n    \n    priorities[suitable_bins_mask] = combined_scores\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 81.80095731950539,
    "cyclomatic_complexity": 3.0,
    "halstead": 169.21582985307933,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit prioritization with a weighted score favoring tight fits\n    and bins that are already relatively full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_indices = np.where(can_fit_mask)[0]\n    \n    if not np.any(fitting_indices):\n        return priorities\n\n    fitting_bins_caps = bins_remain_cap[fitting_indices]\n    \n    # --- Component 1: Exact Fit Priority ---\n    # Assign a very high score to bins that provide an exact fit.\n    exact_fit_mask = fitting_bins_caps == item\n    priorities[fitting_indices[exact_fit_mask]] = 1e10\n    \n    # --- Component 2: Tight Fit (Best Fit) for Non-Exact Fits ---\n    # Calculate remaining capacity after placing the item in non-exact fitting bins.\n    non_exact_fitting_indices_in_fitting = np.where(~exact_fit_mask)[0]\n    non_exact_fitting_bins_caps = fitting_bins_caps[~exact_fit_mask]\n    \n    if non_exact_fitting_bins_caps.size > 0:\n        remaining_after_fit = non_exact_fitting_bins_caps - item\n        \n        # Score based on how little is left over. Higher score for smaller remaining capacity.\n        # Adding epsilon to avoid division by zero if remaining_after_fit is 0 (though handled by exact_fit).\n        # Using 1 / (1 + remaining_after_fit) to map smaller remaining capacity to higher scores.\n        tight_fit_scores = 1.0 / (1.0 + remaining_after_fit)\n        \n        # --- Component 3: Preference for \"Almost Full\" Bins ---\n        # Favor bins that have less remaining capacity initially among the suitable ones.\n        # This encourages filling up bins more.\n        # Using inverse of initial remaining capacity, scaled.\n        almost_full_scores = 0.5 * (1.0 / (bins_remain_cap[fitting_indices[~exact_fit_mask]] + 1e-9))\n\n        # Combine scores for non-exact fits: weighted sum\n        # Weighting tight_fit_scores more heavily (e.g., 0.8) than almost_full_scores (e.g., 0.2).\n        combined_non_exact_score = 0.8 * tight_fit_scores + 0.2 * almost_full_scores\n        \n        # Scale these combined scores to be less than the exact fit priority.\n        # Normalize combined_non_exact_score to [0, 1] and scale down.\n        if np.max(combined_non_exact_score) > 0:\n            scaled_combined_scores = (combined_non_exact_score / np.max(combined_non_exact_score)) * 1e9\n        else:\n            scaled_combined_scores = np.zeros_like(combined_non_exact_score)\n            \n        priorities[fitting_indices[~exact_fit_mask]] = scaled_combined_scores\n        \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 284.3458750793272,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit (log-scaled) with a dynamic penalty for large excess capacity,\n    prioritizing near-perfect fits and efficient bin utilization.\n    \"\"\"\n    epsilon = 1e-9\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Component 1: Best Fit (log-scaled)\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    # Using log to compress the range and emphasize smaller differences.\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + epsilon)\n    \n    # Component 2: Dynamic Penalty (Excess Capacity Ratio)\n    # Penalize bins where the excess capacity (remaining_cap - item) is large\n    # relative to the item's size. This encourages using bins that are already\n    # somewhat filled rather than very empty ones for smaller items.\n    # We want to maximize this component, so we use its inverse.\n    excess_capacity_ratio = (suitable_bins_remain_cap - item) / (item + epsilon)\n    # A higher ratio (more excess) means a lower score here.\n    # Adding 0.2 to the denominator to prevent overly aggressive penalties for small excesses.\n    fill_efficiency_score = 1.0 / (excess_capacity_ratio + 0.2) \n    \n    # Combine scores multiplicatively: Maximize both Best Fit and Fill Efficiency.\n    # A bin is preferred if it offers a good fit AND if the remaining space\n    # isn't excessively large compared to the item.\n    combined_score = best_fit_score * fill_efficiency_score\n    \n    priorities[suitable_bins_mask] = combined_score\n    \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 83.58595931392104,
    "cyclomatic_complexity": 2.0,
    "halstead": 138.24238017775622,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic penalty for large relative slack,\n    prioritizing bins that are tightly fitting and not excessively empty.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # --- Component 1: Best Fit Score (logarithmic) ---\n    # Encourages bins with minimal remaining capacity after packing.\n    # Add epsilon for numerical stability when remaining_cap == item.\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)\n    \n    # --- Component 2: Dynamic Gap (Slack) Management Score ---\n    # Penalizes bins where the difference (slack) between bin's remaining capacity \n    # and item size is large, relative to the item size itself.\n    # Score is 1 for perfect fit (slack=0) and decreases as relative slack increases.\n    slack = suitable_bins_remain_cap - item\n    gap_management_score = 1.0 / (1.0 + (slack / (item + 1e-9)))\n    \n    # Combine scores multiplicatively: prioritize bins that are both tightly fitting \n    # and do not have an excessively large relative slack.\n    priorities[suitable_bins_mask] = best_fit_score * gap_management_score\n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 67.92979656960512,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.16184010614157,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a penalty for large remaining capacity.\n    Prioritizes bins where the item fits snugly and penalizes bins with\n    significant excess capacity, promoting efficient bin usage.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    # Metric 1: Tightness of fit (similar to Best Fit)\n    # High score for small `remaining_capacity - item`.\n    # Uses `1.0 / (slack + epsilon)`\n    slack = suitable_bins_remain_cap - item\n    tightness_score = 1.0 / (slack + 1e-9)\n\n    # Metric 2: Fill ratio of remaining space\n    # High score for `item / suitable_bins_remain_cap`.\n    # This implicitly penalizes bins with large `suitable_bins_remain_cap`.\n    fill_ratio = item / (suitable_bins_remain_cap + 1e-9)\n    \n    # Combine metrics multiplicatively: Prioritize bins that are both a tight fit\n    # AND where the item occupies a significant portion of the remaining capacity.\n    # This combination naturally penalizes bins with large `suitable_bins_remain_cap`\n    # because `fill_ratio` will be small. The `tightness_score` ensures that among\n    # bins with similar fill ratios, the one with less slack is preferred.\n    combined_score = tightness_score * fill_ratio\n\n    priorities[suitable_bin_indices] = combined_score\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 94.01164534875782,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive fill ratio, favoring tight fits and\n    bins where the item significantly utilizes remaining capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    # Best Fit Score: Prioritize bins that leave the smallest remaining capacity.\n    # Inverse of remaining capacity after fitting the item. Higher is better.\n    best_fit_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Adaptive Fill Ratio: Rewards bins where the item fills a larger portion of *available* space.\n    # This is dynamic, influenced by the capacity of the suitable bin.\n    # Higher score for item / suitable_bins_remain_cap.\n    fill_ratio = item / (suitable_bins_remain_cap + 1e-9)\n\n    # Combined Score: Multiplies Best Fit and Fill Ratio.\n    # This prioritizes bins that are a tight fit AND where the item represents a\n    # significant portion of the bin's available capacity, implicitly penalizing\n    # bins with large absolute remaining capacity that are still \"tight\" relative to the item.\n    combined_score = best_fit_score * fill_ratio\n\n    # Applying a small constant to ensure scores are positive, as `combined_score` could be very small.\n    # This also helps in cases where one component might approach zero.\n    final_priorities = combined_score + 1e-6\n\n    priorities[suitable_bin_indices] = final_priorities\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 110.44611534953322,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit: Prioritizes bins that are a \"good fit\" based on the item size,\n    and then uses a penalty for bins that are \"too large\" to encourage denser packing.\n    This aims for a balance between fitting the current item well and leaving space\n    for future items without excessive wasted capacity in any single bin.\n\n    The core idea is to favor bins where the remaining capacity after packing is\n    close to the item size, but also penalize bins that have a much larger remaining\n    capacity than the item, as these are less efficient for the current item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    # Score 1: \"Near Fit\" score.\n    # This score rewards bins where the remaining capacity *after* packing is small,\n    # meaning the fit is close to perfect. We use a negative log to map smaller\n    # remaining capacities (better fits) to higher scores.\n    # Adding 1e-9 for numerical stability.\n    near_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)\n\n    # Score 2: \"Waste Penalty\" score.\n    # This score penalizes bins where the remaining capacity *before* packing is\n    # significantly larger than the item. This encourages using bins that are\n    # \"just enough\" rather than overly large ones, which might lead to fragmentation.\n    # We want to *decrease* the priority of bins with high \"excess capacity\".\n    # `excess_capacity_ratio` = (bin_capacity - item) / bin_capacity\n    # A higher ratio means more wasted space relative to the bin's total size.\n    # We want to penalize high `excess_capacity_ratio`.\n    # A simple penalty: `1 / (excess_capacity_ratio + epsilon)`.\n    # Or, consider `item_fraction_in_bin = item / bin_capacity`.\n    # We want to prioritize bins where `item_fraction_in_bin` is high.\n    # A sigmoid-like function can map `item_fraction_in_bin` to a score between 0 and 1,\n    # where higher values mean better fit for utilization.\n    # Let's use the ratio of item size to bin's remaining capacity to encourage fuller bins.\n    # `fill_ratio = item / suitable_bins_remain_cap` (this is BEFORE packing)\n    # This doesn't reflect the state AFTER packing.\n    # Let's use `item / bin_capacity` to represent how much of a bin is occupied if we use it.\n    # This is `item / (suitable_bins_remain_cap + item)`.\n    # We want to maximize this ratio.\n    # A sigmoid-like function: `tanh(k * (item / (suitable_bins_remain_cap + item)))`\n    # where `k` is a scaling factor. A simpler version is just the ratio itself, scaled.\n\n    # A score based on how much of the bin's *original* capacity is used by the item.\n    # This encourages using bins that are better utilized by the current item.\n    # Original capacity of suitable bins is `suitable_bins_remain_cap + item`.\n    utilization_score = item / (suitable_bins_remain_cap + item + 1e-9) # Ratio of item size to total capacity of the bin if used\n\n    # Combining scores:\n    # We want to maximize `near_fit_score` (good fit after packing)\n    # and maximize `utilization_score` (bin is well-utilized by this item).\n    # A multiplicative combination often works well:\n    # priority = near_fit_score * utilization_score\n    # This ensures that both conditions must be met to some degree for a high priority.\n    # A bin with a perfect fit (high `near_fit_score`) but low `utilization_score` (bin is very large)\n    # will be penalized. Similarly, a bin with high `utilization_score` but not a great fit\n    # (large `suitable_bins_remain_cap - item`) will also be penalized.\n\n    priorities[suitable_bins_mask] = near_fit_score * utilization_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.148384523334677,
    "cyclomatic_complexity": 2.0,
    "halstead": 104.2481250360578,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Aims to balance the \"tightness\" of a fit with the \"bin fullness\",\n    prioritizing bins that have just enough space for the item (tight fit)\n    but are not overly empty themselves. This promotes fuller bins overall.\n    It also incorporates a penalty for bins that are too full to accept the item,\n    ensuring only valid placements are considered.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf) # Initialize with negative infinity for invalid bins\n\n    # Mask for bins that can fit the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return np.zeros_like(bins_remain_cap) # Return zeros if no bin can fit\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    # Component 1: \"Tight Fit\" Score (Maximizes tightness)\n    # Prioritize bins where remaining capacity is closest to the item size.\n    # This is the inverse of the remaining capacity after packing.\n    # Adding a small epsilon to avoid division by zero.\n    tightness_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Component 2: \"Bin Fullness\" Score (Maximizes bin fullness)\n    # Prioritize bins that are already quite full (low remaining capacity before packing).\n    # This encourages using partially filled bins.\n    # Using the inverse of the remaining capacity.\n    bin_fullness_score = 1.0 / (bins_remain_cap[suitable_bins_mask] + 1e-9)\n\n    # Component 3: \"Proximity Penalty\" (Penalizes bins that are *almost* full but don't fit)\n    # While not directly used for selection of suitable bins, we can implicitly consider\n    # bins that are very close to fitting as less desirable than truly \"tight\" fits.\n    # However, for clarity and directness, we focus on the positive aspects of suitable bins.\n\n    # Combine scores: Weighted sum or product. A product can emphasize bins that excel in both.\n    # Let's use a multiplicative approach: a bin is good if it's tight AND the bin is generally full.\n    # We want to maximize both tightness_score and bin_fullness_score.\n    # To make it a single maximization objective, we multiply them.\n    combined_score = tightness_score * bin_fullness_score\n\n    # Assign the calculated priorities to the suitable bins\n    priorities[suitable_bins_mask] = combined_score\n\n    # Ensure that bins that cannot fit the item have a very low priority (handled by initialization with -inf)\n    # For selection purposes, it's often better to return zero for non-suitable bins if the selection logic\n    # is `np.argmax` and we want to avoid picking them if possible.\n    # If no bin is suitable, we already return zeros. If some are suitable, we want to pick the max among them.\n    # If `priorities` contains only -inf and zeros, `argmax` will pick a zero if available.\n    # If all are -inf, argmax might pick an arbitrary one.\n\n    # A robust way: If any suitable bins exist, return the computed priorities.\n    # Otherwise, return zeros.\n    if np.any(suitable_bins_mask):\n        # Replace -inf with 0 for bins that couldn't fit, so argmax doesn't pick them\n        # if all suitable bins have a score of 0 (e.g., item size is exactly 0).\n        priorities[~suitable_bins_mask] = 0\n        return priorities\n    else:\n        return np.zeros_like(bins_remain_cap)",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 120.40465370320703,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response2.txt_stdout.txt",
    "code_path": "problem_iter9_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins based on a combination of First Fit Decreasing (FFD) like preference\n    (favoring bins that are nearly full, but can still fit the item) and a penalty\n    for bins that would leave excessive \"dead space\" after packing.\n    This aims for a balance between fitting items tightly and avoiding fragmentation.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Mask for bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Score component 1: Proximity to a perfect fit (similar to Best Fit)\n    # We want to minimize (remaining_capacity - item).\n    # A smaller value is better. Using negative value to maximize.\n    # Adding a small constant to avoid log(0) or division by zero if remaining_cap == item.\n    fit_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n    \n    # Score component 2: Penalty for large leftover capacity relative to the item size.\n    # This discourages putting a small item into a very large bin if other options exist.\n    # Calculate the \"waste ratio\" if the item is placed in the bin: (remaining_capacity - item) / item\n    # A higher waste ratio is bad. We want to penalize this.\n    # Using `item + epsilon` to avoid division by zero if item is zero.\n    waste_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)\n    \n    # We want to penalize bins with high waste_ratio.\n    # A simple penalty function could be 1 / (waste_ratio + C) where C is a constant.\n    # This means as waste_ratio increases, the penalty multiplier decreases.\n    # We want to favor bins with low waste_ratio.\n    # A small constant (e.g., 0.5) makes the penalty more sensitive to small waste.\n    penalty_multiplier = 1.0 / (waste_ratio + 0.5)\n    \n    # Combine scores: Multiply the fit_score by the penalty_multiplier.\n    # This means bins that have a good fit AND a low waste ratio (high penalty_multiplier) will have a higher priority.\n    # The intuition is to maximize both fitting tightly and minimizing relative waste.\n    \n    combined_score = fit_score * penalty_multiplier\n    \n    priorities[suitable_bins_mask] = combined_score\n    \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 140.55415752892034,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response3.txt_stdout.txt",
    "code_path": "problem_iter9_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a \"Tightest Fit with Capacity Bias\" heuristic.\n    Prioritizes bins that minimize leftover capacity after packing (tightest fit),\n    but adds a bias towards bins that have more remaining capacity overall,\n    to prevent prematurely filling up potentially useful larger bins.\n    This aims for a balance between immediate tightness and future flexibility.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    # 1. Tightest Fit Component (minimizing leftover space)\n    # We want to maximize the negative of the leftover space.\n    # Higher values are better (less leftover).\n    leftover_space = suitable_bins_remain_cap - item\n    # Using a small epsilon to avoid log(0) if leftover_space is 0.\n    # The log compresses the range, making differences more granular.\n    tightest_fit_score = -np.log(leftover_space + 1e-9)\n\n    # 2. Capacity Bias Component (preferring bins with more capacity)\n    # We want to give a boost to bins that have significantly more capacity,\n    # even if they aren't the absolute tightest fit. This prevents scenarios\n    # where we fill up slightly larger bins first, leaving only very small\n    # bins for larger items later.\n    # This score should be higher for bins with larger remaining capacity.\n    # Using a scaled inverse of remaining capacity to create a \"bias bonus\".\n    # A linear scaling is simpler and less prone to issues than logarithmic.\n    # We want to boost larger capacities. A simple linear increase is good.\n    # However, to avoid large absolute values dominating, we can scale it.\n    # A simple approach is to add a fraction of the bin's remaining capacity.\n    # The \"+1\" is to ensure non-zero values and prevent issues when remaining capacity is small.\n    capacity_bias_score = suitable_bins_remain_cap\n\n    # Combine the scores:\n    # We want to maximize both tightest_fit_score and capacity_bias_score.\n    # A simple additive combination can work.\n    # To balance them, we can scale the capacity bias.\n    # Let's assume a reasonable scaling factor for the bias, e.g., 0.1.\n    # This means a unit of leftover capacity reduction is 10x more important than a unit of bin capacity.\n    # The exact scaling factor can be a hyperparameter.\n    scaling_factor = 0.1\n    combined_score = tightest_fit_score + scaling_factor * capacity_bias_score\n\n    priorities[suitable_bins_mask] = combined_score\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 78.5301156761069,
    "cyclomatic_complexity": 2.0,
    "halstead": 77.66179398375645,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response4.txt_stdout.txt",
    "code_path": "problem_iter9_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Component 1: Best Fit (minimizing waste)\n    # Prioritize bins where remaining capacity after packing is minimized.\n    # This directly targets reducing wasted space in the chosen bin.\n    # Using negative to convert minimization to maximization.\n    # Adding a small epsilon to prevent log(0) for perfect fits.\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)\n    \n    # Component 2: Adaptability to Item Size (Dynamic Prioritization)\n    # If the item is very large, we might be more forgiving of slightly larger remaining capacity\n    # if it means fitting the item at all. Conversely, for small items, we want a very tight fit.\n    # This component aims to adjust priority based on the \"difficulty\" of fitting the current item.\n    # A simple way to capture this is to consider the ratio of item size to bin capacity.\n    # However, we are already considering the remaining capacity.\n    # A better approach: penalize bins that have *excessively* more capacity than the item,\n    # especially when the item itself is small.\n    \n    # Calculate the ratio of available capacity to item size.\n    # Higher ratio means more \"slack\" or less \"tightness\".\n    # We want to penalize bins with high slack, especially for smaller items.\n    # We want to favor bins where suitable_bins_remain_cap is close to item.\n    \n    # Let's use a penalty based on the remaining capacity *relative to the item size*.\n    # If `remaining_cap - item` is large compared to `item`, it's a bad fit.\n    # We want to maximize `1 / ( (remaining_cap - item) / item + C )`\n    # Where C is a small constant to avoid division by zero and control sensitivity.\n    \n    # Calculate the \"slack ratio\": (remaining_cap_after_packing) / item_size\n    # We want to penalize high slack ratios.\n    slack_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)\n    \n    # A penalty that decreases as slack_ratio increases.\n    # `1 / (slack_ratio + C)` ensures that bins with low slack (good fits) get higher multipliers.\n    # Adding a base value to `slack_ratio` ensures that even perfect fits (slack_ratio=0) don't yield infinity.\n    # A small constant `C` (e.g., 0.1) provides a baseline level of preference for tighter fits.\n    adaptability_multiplier = 1.0 / (slack_ratio + 0.1)\n    \n    # Component 3: Robustness against \"almost full\" bins\n    # Sometimes, a bin that is almost full but can still fit the item is preferable\n    # to a bin that has a lot of space but is also a \"best fit\" in terms of minimal waste.\n    # This can help consolidate items more effectively, preventing a situation where\n    # many bins are left with small residual capacities.\n    # We can add a bonus to bins that are closer to being full (but can still fit the item).\n    # This can be represented by the ratio of item size to the bin's remaining capacity *before* packing.\n    # Higher ratio means the item takes up a larger proportion of the bin's current available space.\n    \n    # Ratio of item size to bin's remaining capacity (before packing)\n    # Higher value means item is a \"significant\" portion of what's left.\n    # We want to boost scores for bins where this ratio is high.\n    fill_ratio_bonus_factor = item / (bins_remain_cap[suitable_bins_mask] + 1e-9)\n    \n    # Apply a transformation to make this a bonus (e.g., add directly, or use as multiplier).\n    # Adding a scaled version seems more robust than multiplying, as it complements the best-fit score.\n    # The scaling factor (e.g., 0.5) can be tuned.\n    fill_bonus = 0.5 * fill_ratio_bonus_factor\n\n    # Combine the scores:\n    # We want to maximize `best_fit_score`.\n    # We want to maximize `adaptability_multiplier` (which favors tighter fits).\n    # We want to add `fill_bonus` to encourage using bins that are already somewhat full.\n    # A simple additive combination with appropriate scaling is often effective.\n    # Alternatively, a multiplicative approach can balance the factors.\n    # Let's try a combined approach:\n    # Base score is best_fit_score.\n    # Adjust it with adaptability_multiplier.\n    # Add fill_bonus.\n\n    # The `best_fit_score` is already a log. The `adaptability_multiplier` is a ratio.\n    # Multiplying them might scale too aggressively.\n    # Let's try a weighted sum or a combination where the adaptability is a multiplier\n    # on the best-fit and the fill_bonus is an additive boost.\n    \n    # Prioritize bins that are close to the item size, and add a bonus if they are\n    # already somewhat utilized.\n    \n    # Revisit: the goal is to select *one* bin. The priority score should reflect\n    # the desirability of that bin.\n    # 1. Best Fit: Minimize `remaining_cap - item`.\n    # 2. Adaptability: Favor tighter fits, penalize large gaps relative to item size.\n    # 3. Fill Ratio Bonus: Favor bins that are already somewhat full.\n\n    # Let's combine Best Fit and Adaptability using multiplication as before,\n    # but refine the adaptability component.\n    # The `adaptability_multiplier` `1.0 / (slack_ratio + 0.1)` is good.\n    \n    # Let's integrate the \"fill ratio bonus\" more directly into the main score.\n    # Consider the remaining capacity *after* packing `R = suitable_bins_remain_cap - item`.\n    # We want to minimize `R`.\n    # We also want to minimize `R / item`.\n    # And we want to maximize `item / suitable_bins_remain_cap` (if `suitable_bins_remain_cap` is the capacity before packing).\n\n    # Let's use a combined score that aims to maximize:\n    # `(-log(R + eps)) * (1 / (R / item + eps)) + C * (item / suitable_bins_remain_cap)`\n    # This is becoming complex. Let's aim for clarity and robustness.\n\n    # Simplified approach:\n    # Score = (Best Fit component) * (Adaptability component) + (Fill Bonus component)\n\n    # Best Fit component: `1 / (remaining_cap_after_packing + epsilon)`\n    # This is an inverse relationship, higher value for smaller waste.\n    # Using inverse instead of log for simpler combination.\n    best_fit_component = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Adaptability component: `item / (remaining_cap_after_packing + epsilon)`\n    # This rewards fits where the item takes up a larger fraction of the *remaining* space.\n    # Essentially, how \"full\" the bin gets *after* packing.\n    adaptability_component = item / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Fill Bonus component: `item / (original_bin_capacity + epsilon)`\n    # This rewards bins that were already more full before this item.\n    # We need original capacities, which are not directly passed. We can use the `bins_remain_cap`\n    # before filtering suitable bins, but this requires re-indexing.\n    # A proxy could be the `suitable_bins_remain_cap` themselves (representing their state *before* packing this item).\n    # So, `fill_bonus_component` ~ `item / suitable_bins_remain_cap`.\n    # However, `suitable_bins_remain_cap` are already filtered.\n    # Let's focus on making `priority_v1` better.\n\n    # Re-evaluating `priority_v1`:\n    # `best_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)`: Good, favors minimal waste.\n    # `excess_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)`: Measures excess capacity relative to item size.\n    # `penalty_multiplier = 1.0 / (excess_ratio + 0.2)`: Higher multiplier for lower excess ratio (tighter fit).\n    # `priorities[suitable_bins_mask] = best_fit_score * penalty_multiplier`: Combines minimal waste with tight fit preference.\n\n    # Improvement idea: Make the `penalty_multiplier` more sensitive to the *absolute* amount of waste,\n    # not just relative to the item size. A large absolute waste is bad regardless of item size.\n    # Also, consider the \"quality\" of the best fit itself. A bin with very little waste might be prioritized higher.\n\n    # New components for v2:\n    # 1. Fit Quality (similar to Best Fit): Emphasize bins with minimal `waste = remaining_cap - item`.\n    #    Use `1 / (waste + epsilon)` for direct maximization of quality.\n    # 2. Fit Tightness (Adaptability): Emphasize bins where the item fills a larger proportion of the *remaining* space.\n    #    Use `item / (remaining_cap + epsilon)` where `remaining_cap` is `suitable_bins_remain_cap`.\n    # 3. Global Bin Utilization (Fill Bonus): Prefer bins that are already more full. This is tricky without original capacity.\n    #    We can proxy this by looking at `suitable_bins_remain_cap`. A smaller `suitable_bins_remain_cap`\n    #    (before packing) means the bin was more utilized.\n    #    So, we want to boost bins with smaller `suitable_bins_remain_cap`.\n    #    Let's use `1 / suitable_bins_remain_cap` as a bonus, but scaled.\n\n    # Component 1: Fit Quality\n    # Higher value for smaller waste.\n    waste = suitable_bins_remain_cap - item\n    fit_quality = 1.0 / (waste + 1e-9)\n\n    # Component 2: Fit Tightness (relative to remaining space)\n    # Higher value if item occupies a larger fraction of the available space.\n    fit_tightness = item / (suitable_bins_remain_cap + 1e-9)\n\n    # Component 3: Bin Utilization Bonus (proxy: smaller remaining capacity before packing)\n    # Higher value for bins that were more utilized (smaller `suitable_bins_remain_cap`).\n    # Add a small constant to the denominator to avoid division by zero and control sensitivity.\n    # Let's scale this bonus to avoid dominating other components.\n    utilization_bonus = 0.5 * (1.0 / (suitable_bins_remain_cap + 1e-9)) # Scaled bonus\n\n    # Combine components:\n    # A common heuristic combination is multiplicative for related scores and additive for bonuses.\n    # Let's multiply Fit Quality and Fit Tightness, then add the Utilization Bonus.\n    # This means we want bins that are both good fits (low waste) AND tight fits (item fills space well).\n    # The bonus then adds a preference for bins that were generally more full.\n\n    combined_score = (fit_quality * fit_tightness) + utilization_bonus\n\n    # Assign scores to the original priority array\n    priorities[suitable_bins_mask] = combined_score\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 442.80353607846075,
    "exec_success": true
  }
]