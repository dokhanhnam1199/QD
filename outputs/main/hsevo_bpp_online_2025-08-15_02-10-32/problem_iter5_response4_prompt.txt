{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins that are an exact fit, then uses an inverse remaining capacity\n    approach for other suitable bins, balancing precision and general effectiveness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    # Exact fit priority (highest)\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1e9 # Assign a very high priority for exact fits\n    \n    # Best fit for non-exact fits\n    non_exact_suitable_mask = suitable_bins_mask & ~exact_fit_mask\n    \n    if np.any(non_exact_suitable_mask):\n        remaining_capacities_for_non_exact = bins_remain_cap[non_exact_suitable_mask] - item\n        # Using inverse remaining capacity as a measure of \"best fit\"\n        priorities[non_exact_suitable_mask] = 1.0 / (remaining_capacities_for_non_exact + 1e-9)\n        \n    # Normalize priorities for non-exact fits to avoid overpowering exact fits\n    # and to make the best-fit values relative among themselves.\n    # We don't normalize the exact fit priorities as they are intended to be dominant.\n    if np.any(non_exact_suitable_mask):\n        non_exact_priorities = priorities[non_exact_suitable_mask]\n        if np.sum(non_exact_priorities) > 0:\n            priorities[non_exact_suitable_mask] = non_exact_priorities / np.sum(non_exact_priorities)\n\n    # If no bins are suitable, all priorities remain 0.\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins by giving a higher score to bins that fit the item\n    tightly, using an exponential decay based on relative capacity,\n    but also strongly favoring exact fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    \n    if fitting_bins_capacities.size > 0:\n        \n        exact_fit_mask = fitting_bins_capacities == item\n        \n        \n        relative_capacities = fitting_bins_capacities - item\n        \n        \n        non_exact_fit_mask = ~exact_fit_mask\n        \n        \n        non_exact_fitting_capacities = relative_capacities[non_exact_fit_mask]\n        \n        if non_exact_fitting_capacities.size > 0:\n            \n            mean_relative_capacity = np.mean(non_exact_fitting_capacities)\n            \n            \n            if mean_relative_capacity > 0:\n                \n                priorities[can_fit_mask][non_exact_fit_mask] = np.exp(-non_exact_fitting_capacities / mean_relative_capacity)\n            else:\n                \n                priorities[can_fit_mask][non_exact_fit_mask] = 0.0\n        \n        \n        priorities[can_fit_mask][exact_fit_mask] = 1.0 \n        \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 vs Heuristic 2: Heuristic 1 uses a log transform and a `tightness_ratio` for its score, while Heuristic 2 uses an inverse remaining capacity and a normalized excess capacity penalty. Heuristic 1's score `best_fit_score * penalty_multiplier` (where `penalty_multiplier = 1.0 / (excess_ratio + 0.2)`) appears more direct in penalizing bins with large excess capacity relative to item size.\n\nComparing Heuristic 3 vs Heuristic 7 (which are identical): Both use `fill_ratio * tightness` as their score, which is `item / (suitable_bins_remain_cap * (suitable_bins_remain_cap - item) + 1e-9)`. This score effectively balances the tightness of the fit with how much of the remaining space the item occupies, and it implicitly penalizes bins with large `suitable_bins_remain_cap`.\n\nComparing Heuristic 4 vs Heuristic 9 (which are identical): Both use a sigmoid function based on normalized slack. Heuristic 4 maps `max_slack - slack` to the sigmoid, aiming for higher scores for smaller slack. Heuristic 9 directly uses `differences * scale_factor` as the sigmoid input, achieving a similar goal.\n\nComparing Heuristic 5 vs Heuristic 6 (which are identical): Both prioritize exact fits with a high score, then use inverse remaining capacity for non-exact fits, normalizing these scores. This is a robust approach for prioritizing exact fits.\n\nComparing Heuristic 10 vs Heuristic 11/12: Heuristic 10 uses a product of Best Fit, Excess Capacity Penalty, and Distributional Balancing. Heuristics 11/12 combine Best Fit with a preference for \"almost full\" bins using a weighted sum. Heuristic 11/12's direct combination of `1.0 / (bins_remain_cap + epsilon_small)` and `0.5 * (-remaining_after_fit)` seems more straightforward than Heuristic 10's multiplicative approach with potentially complex interactions.\n\nComparing Heuristic 13/14/15 vs Heuristic 16: Heuristics 13/14/15 prioritize exact fits (score 1.0) and then use an exponential decay `exp(-relative_capacities / mean_relative_capacity)` for non-exact fits. Heuristic 16 prioritizes exact fits with a high score and uses `exp(-scaled_relative_capacities)` for non-exact fits, where `scaled_relative_capacities` is normalized between 0 and 1. Heuristic 16's normalization and conditional scaling might lead to more stable and comparable scores.\n\nComparing Heuristic 17/18 vs Heuristic 19/20: Heuristics 17/18 use a sigmoid `1 / (1 + exp(-scaled_differences))` based on the negative difference for tight fits. Heuristics 19/20 use `exp(remaining_capacities)` scaled and normalized, which seems to amplify the preference for tighter fits directly. The sigmoid in 17/18 might offer smoother control.\n\nOverall: Heuristics focusing on multiplicative combinations of \"tightness\" (like `1/(rem-item)`) and \"fill ratio\" (like `item/rem`), or those that directly penalize large initial remaining capacities, seem most promising for balancing fit quality and overall bin utilization. Exact fit prioritization is also a strong strategy. The complexity of penalties and normalizations can sometimes obscure the intended behavior.\n- \nHere's a redefined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Iterative refinement, empirical validation, component interaction, adaptability.\n*   **Advice:** Focus on how heuristic components *interact* and *evolve* during search. Design for *adaptability* based on problem instance characteristics.\n*   **Avoid:** Over-reliance on fixed mathematical combinations or static penalties.\n*   **Explanation:** Instead of solely prioritizing fixed metrics like \"tightness\" or \"fill ratio,\" continuously evaluate their effectiveness *in conjunction* throughout the heuristic's execution. Tune component weights or logic dynamically, rather than with static formulas.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}