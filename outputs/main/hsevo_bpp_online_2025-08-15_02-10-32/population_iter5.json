[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic penalty for large remaining capacity,\n    prioritizing tight fits and penalizing bins with excessive unused space.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    # If no bins can fit the item, return zero priorities\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Component 1: Best Fit (minimize remaining capacity after packing)\n    # We want to maximize -log(remaining_capacity_after_packing).\n    # Adding a small epsilon to prevent log(0) or division by zero issues.\n    remaining_after_fit = suitable_bins_remain_cap - item\n    best_fit_score = -np.log(remaining_after_fit + 1e-9)\n    \n    # Component 2: Dynamic Penalty for Excess Capacity\n    # Penalize bins where the *initial* remaining capacity is much larger than the item.\n    # We want to penalize bins with a high ratio of (bin_capacity / item_size)\n    # or equivalently, a low ratio of (item_size / bin_capacity).\n    # A simple penalty can be based on (item / bin_capacity).\n    # A high item/bin_capacity ratio is good.\n    # Let's use 1 - (item / bin_capacity) as a penalty: higher value means more excess.\n    # We want to *minimize* this penalty. So, use -(1 - item / bin_capacity) or (item / bin_capacity - 1).\n    # A different approach: penalize large initial remaining capacity relative to the item.\n    # Consider 'excess_ratio_initial' = (suitable_bins_remain_cap - item) / item\n    # A high excess_ratio_initial is bad. We want to penalize it.\n    # Penalty multiplier = 1 / (excess_ratio_initial + C)\n    # This is similar to the logic in priority_v0 for penalty_multiplier.\n    \n    # Let's use the concept of \"slack\" (initial remaining capacity) and \"tightness\" (remaining after fit)\n    # We want to prioritize bins with low slack AND low remaining_after_fit.\n    \n    # Using a multiplicative approach combining Best Fit and a penalty for initial large capacity.\n    # The penalty term should be higher for bins with larger initial capacity compared to the item.\n    # Consider the inverse of the remaining capacity as a score for \"fullness\".\n    # Add epsilon to avoid division by zero.\n    fullness_score = 1.0 / (suitable_bins_remain_cap + 1e-9)\n    \n    # Combine Best Fit score with the fullness score.\n    # A high best_fit_score (tight fit after packing) is good.\n    # A high fullness_score (bin is initially quite full) is also good.\n    # Multiplying them seems reasonable: a bin is good if it's a tight fit AND was already quite full.\n    combined_score = best_fit_score * fullness_score\n    \n    # Assign the calculated scores to the priority array\n    priorities[suitable_bins_mask] = combined_score\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 67.92979656960512,
    "cyclomatic_complexity": 2.0,
    "halstead": 91.73835003173087,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a penalty for large remaining capacity.\n    Prioritizes bins where the item fits snugly and penalizes bins with\n    significant excess capacity, promoting efficient bin usage.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    # Metric 1: Tightness of fit (similar to Best Fit)\n    # High score for small `remaining_capacity - item`.\n    # Uses `1.0 / (slack + epsilon)`\n    tightness_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Metric 2: Fill ratio of remaining space\n    # High score for `item / suitable_bins_remain_cap` when `suitable_bins_remain_cap` is small.\n    # This implicitly penalizes bins with large `suitable_bins_remain_cap`.\n    fill_ratio = item / (suitable_bins_remain_cap + 1e-9)\n    \n    # Combine metrics multiplicatively: Prioritize bins that are both a tight fit\n    # AND where the item occupies a significant portion of the remaining capacity.\n    # This combination naturally penalizes bins with large `suitable_bins_remain_cap`\n    # because `fill_ratio` will be small, and `tightness_score`'s denominator\n    # will also be larger (though less impactful).\n    combined_score = tightness_score * fill_ratio\n\n    priorities[suitable_bin_indices] = combined_score\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 94.01164534875782,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit with a sigmoid for prioritizing tight fits and relative fill ratio.\n\n    Prioritizes bins that are a tight fit using a sigmoid on slack, and boosts\n    priority for bins with a higher fill ratio.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities\n\n    valid_bins_remain_cap = bins_remain_cap[fit_mask]\n    \n    # Component 1: Best Fit tightness using sigmoid\n    # Prioritize bins where the remaining capacity after placing the item is minimal.\n    slack = valid_bins_remain_cap - item\n    \n    # Normalize slack to a range suitable for sigmoid, focusing on smaller slack\n    # which indicates a tighter fit. We want smaller slack to yield a higher score.\n    min_slack = np.min(slack)\n    max_slack = np.max(slack)\n    \n    if max_slack == min_slack:\n        normalized_slack_for_sigmoid = np.zeros_like(slack)\n    else:\n        # Map slack to a range that gives higher sigmoid input for smaller slack.\n        # (max_slack - slack) makes smaller slack values larger.\n        transformed_slack = max_slack - slack\n        normalized_transformed_slack = transformed_slack / (max_slack - min_slack)\n        \n    # Apply sigmoid to the normalized transformed slack. Steepness controls sensitivity.\n    steepness = 5.0\n    sigmoid_input = steepness * (normalized_transformed_slack - 0.5)\n    best_fit_score = 1 / (1 + np.exp(-sigmoid_input))\n\n    # Component 2: Relative Fill Ratio (incorporating item size and bin capacity)\n    # Prioritize bins that are relatively full with respect to their current remaining capacity.\n    # This encourages using bins that already have a significant portion of their capacity used.\n    # We use `item / valid_bins_remain_cap` as a proxy for fill ratio.\n    # Add a small epsilon to avoid division by zero if remaining capacity is zero (though filtered by fit_mask).\n    fill_ratio_score = item / (valid_bins_remain_cap + 1e-9)\n    \n    # Combine scores: Multiply for synergy. Higher values from both components are preferred.\n    # This combines the tightness of the fit (sigmoid) with the relative fullness of the bin.\n    priorities[fit_mask] = best_fit_score * fill_ratio_score\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 36, in priority_v2\n    penalty = np.zeros_like(suitable_capacities, dtype=float)\nUnboundLocalError: local variable 'normalized_transformed_slack' referenced before assignment\n3\n208.89318279048564\n"
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit prioritization with a refined best-fit strategy that\n    penalizes overly large remaining capacities, encouraging fuller bins.\n    \"\"\"\n    epsilon_small = 1e-9\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mask for bins that can fit the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    # Assign very high priority to exact fits\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1e9\n\n    # For bins that are not an exact fit but can accommodate the item\n    non_exact_suitable_mask = suitable_bins_mask & ~exact_fit_mask\n\n    if np.any(non_exact_suitable_mask):\n        suitable_capacities = bins_remain_cap[non_exact_suitable_mask]\n        remaining_capacities_after_fit = suitable_capacities - item\n\n        # Base priority: inverse of remaining capacity after fit (Best Fit)\n        # Higher score for smaller remaining capacity\n        best_fit_scores = 1.0 / (remaining_capacities_after_fit + epsilon_small)\n\n        # Penalty for bins that are initially \"too empty\"\n        # We want to favor bins that are already somewhat filled.\n        # Penalize bins where initial `bins_remain_cap` is significantly larger than the item.\n        # A threshold of `item * 3.0` for initial capacity is used.\n        # The penalty is scaled inversely by the initial capacity itself to avoid\n        # overly aggressive penalties for moderately large capacities.\n        large_capacity_threshold = item * 3.0\n        penalty = np.zeros_like(suitable_capacities, dtype=float)\n        \n        large_capacity_mask = suitable_capacities > large_capacity_threshold\n        \n        # Calculate penalty: Lower score for larger initial capacities.\n        # Use a scaled inverse of the initial remaining capacity.\n        # Adding a small constant `epsilon_small` to the denominator to prevent division by zero.\n        # Subtracting this scaled inverse from the best_fit_scores.\n        penalty[large_capacity_mask] = 1.0 / (suitable_capacities[large_capacity_mask] + epsilon_small)\n        \n        # Combine scores: Prioritize tight fits, then penalize very empty bins.\n        # We add the penalty (which is negative in effect due to `1/cap` nature) to the best fit score.\n        # A smaller initial capacity (leading to a larger `1/cap`) is less penalized.\n        # A larger initial capacity (leading to a smaller `1/cap`) is more penalized.\n        \n        # Let's refine this. We want:\n        # 1. High score for small `remaining_capacities_after_fit`\n        # 2. High score for small `suitable_capacities` (initial)\n        \n        # Score = `(1.0 / (remaining_capacities_after_fit + epsilon_small))`  # Best Fit\n        #       `+ W * (1.0 / (suitable_capacities + epsilon_small))`      # Prefer \"almost full\" bins\n\n        # Let's use a weight `W=0.5` for the \"almost full\" preference.\n        weight_almost_full = 0.5\n        combined_priority = best_fit_scores + weight_almost_full * (1.0 / (suitable_capacities + epsilon_small))\n        \n        priorities[non_exact_suitable_mask] = combined_priority\n\n    # Normalize priorities for non-exact fits to ensure they don't overshadow exact fits\n    # and to make the best-fit scores relative among themselves.\n    if np.any(non_exact_suitable_mask):\n        non_exact_priorities = priorities[non_exact_suitable_mask]\n        sum_non_exact_priorities = np.sum(non_exact_priorities)\n        if sum_non_exact_priorities > 0:\n            priorities[non_exact_suitable_mask] = non_exact_priorities / sum_non_exact_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 230.62385799360038,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit preference with a score inversely proportional to\n    remaining capacity for non-exact fits, prioritizing bins that leave\n    minimal waste after placement.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    # Assign very high priority to bins that provide an exact fit\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1e9  # High score for exact fits\n    \n    # For bins that are not an exact fit but can still accommodate the item\n    non_exact_suitable_mask = suitable_bins_mask & ~exact_fit_mask\n    \n    if np.any(non_exact_suitable_mask):\n        # Calculate the remaining capacity *after* placing the item\n        remaining_after_fit = bins_remain_cap[non_exact_suitable_mask] - item\n        \n        # Prioritize bins with less remaining capacity (i.e., tighter fits)\n        # Add a small epsilon to avoid division by zero\n        priorities[non_exact_suitable_mask] = 1.0 / (remaining_after_fit + 1e-9)\n        \n        # Normalize the priorities of non-exact fits to ensure they don't\n        # unfairly dominate due to large inverse values. This makes the\n        # \"best fit\" scores relative among themselves.\n        non_exact_priorities = priorities[non_exact_suitable_mask]\n        if np.sum(non_exact_priorities) > 0:\n            priorities[non_exact_suitable_mask] = non_exact_priorities / np.sum(non_exact_priorities)\n            \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 101.02330072391149,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a penalty for excessive remaining capacity and\n    rewards for bins that are already substantially filled.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    # Best Fit Score: Prioritize bins that leave the smallest remaining capacity after fitting the item.\n    # Higher score for smaller (remaining_capacity - item).\n    best_fit_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Fill Ratio: Reward bins where the item occupies a larger portion of the *available* space.\n    # Higher score for larger item / suitable_bins_remain_cap.\n    fill_ratio = item / (suitable_bins_remain_cap + 1e-9)\n\n    # Combined Score: Multiply best_fit_score and fill_ratio. This favors bins that are\n    # both a tight fit and where the item significantly utilizes the remaining capacity.\n    # This implicitly penalizes bins with large absolute remaining capacity.\n    combined_score = best_fit_score * fill_ratio\n\n    # Additional Bonus for \"Almost Full\" bins:\n    # Explicitly reward bins that are already substantially filled (small remaining capacity).\n    # This uses a penalty inversely proportional to the remaining capacity.\n    # A small `suitable_bins_remain_cap` (but still >= item) gets a higher bonus.\n    # We add a small constant to the denominator to avoid division by zero for full bins.\n    # We use `item + epsilon` as a reference to avoid issues if a bin is exactly filled by the item.\n    almost_full_bonus = 1.0 / (suitable_bins_remain_cap + 1e-9)\n\n    # Final Priority: Combine the efficiency score with the almost-full bonus.\n    # The `combined_score` (efficiency) already captures tightness and fill ratio.\n    # The `almost_full_bonus` further boosts bins that are simply close to being full.\n    # A simple sum gives a weighted effect, where `combined_score` is the primary driver\n    # and `almost_full_bonus` acts as a secondary preference for already-full bins.\n    # We can tune the weight of the bonus if needed, but a simple sum is a good starting point.\n    final_priorities = combined_score + 0.5 * almost_full_bonus # Tunable weight for bonus\n\n    priorities[suitable_bin_indices] = final_priorities\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 156.0801066523054,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines tightest fit with preference for less empty bins.\n\n    Prioritizes bins that leave minimal remaining capacity after packing (Best Fit),\n    while also favoring bins that are already closer to being full (smaller initial remaining capacity).\n    \"\"\"\n    epsilon_small = 1e-9\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can fit the item\n    fitting_indices = np.where(bins_remain_cap >= item)[0]\n\n    if fitting_indices.size > 0:\n        # Calculate remaining capacity after fitting the item\n        remaining_after_fit = bins_remain_cap[fitting_indices] - item\n\n        # Strategy:\n        # 1. Prioritize bins that are already \"almost full\" (low initial `bins_remain_cap`).\n        #    This is captured by `1.0 / (bins_remain_cap[fitting_indices] + epsilon_small)`.\n        #    Bins with smaller remaining capacity get a higher score here.\n        # 2. Among those, pick the one that results in the tightest fit (Best Fit).\n        #    This is captured by `(-remaining_after_fit)`. Smaller remaining space gets a higher score.\n\n        # Combine these two preferences. A weighted sum is a common approach.\n        # Let's use a weight of 1.0 for the \"almost full\" preference and 0.7 for the \"tightest fit\" preference.\n        # This means we slightly favor bins that are already less empty, and then refine with best fit.\n        weight_almost_full = 1.0\n        weight_tight_fit = 0.7\n\n        score_almost_full = weight_almost_full * (1.0 / (bins_remain_cap[fitting_indices] + epsilon_small))\n        score_tight_fit = weight_tight_fit * (-remaining_after_fit)\n\n        combined_priority = score_almost_full + score_tight_fit\n        priorities[fitting_indices] = combined_priority\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.0885520542481055,
    "cyclomatic_complexity": 2.0,
    "halstead": 128.3789500201924,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit prioritization with a scaled preference for tighter fits\n    using an exponential decay based on normalized slack, similar to v0 but\n    with a more robust normalization for non-exact fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    \n    exact_fit_mask = fitting_bins_caps == item\n    \n    # High priority for exact fits\n    priorities[fitting_bins_indices[exact_fit_mask]] = 1e10\n    \n    non_exact_fitting_indices = fitting_bins_indices[~exact_fit_mask]\n    non_exact_fitting_bins_caps = fitting_bins_caps[~exact_fit_mask]\n    \n    if non_exact_fitting_bins_caps.size > 0:\n        # Calculate slack for non-exact fits\n        slack = non_exact_fitting_bins_caps - item\n        \n        # Normalize slack to a [0, 1] range for exponential scaling\n        min_slack = np.min(slack)\n        max_slack = np.max(slack)\n\n        if max_slack == min_slack:\n            # If all slacks are the same, give them a uniform score (lower than exact fit)\n            normalized_slack = np.zeros_like(slack)\n        else:\n            normalized_slack = (slack - min_slack) / (max_slack - min_slack)\n        \n        # Exponential decay: smaller normalized slack (tighter fit) gets higher score\n        # Use exp(-x) so smaller x (tighter fit) gives larger score\n        scores = np.exp(-normalized_slack)\n        \n        # Scale scores to be less than the exact fit priority, but still prioritize tighter non-exact fits\n        # Find max score among non-exact fits and scale it slightly below exact fit priority\n        max_non_exact_score = np.max(scores)\n        if max_non_exact_score > 0:\n            scaled_scores = (scores / max_non_exact_score) * 1e9 # Scale to be just below 1e10\n        else:\n            scaled_scores = np.zeros_like(scores) # Should not happen if slack > 0\n\n        priorities[non_exact_fitting_indices] = scaled_scores\n        \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 5.0,
    "halstead": 194.95038758870223,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a preference for bins that utilize remaining capacity well.\n    Penalizes bins with excessive remaining capacity after fitting.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    # Metric 1: Tightness of fit (Best Fit heuristic component)\n    # Prioritizes bins where remaining capacity is closest to item size.\n    # Add epsilon to avoid division by zero for exact fits.\n    tightness_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Metric 2: Fill Ratio of remaining capacity\n    # Prioritizes bins where the item occupies a larger portion of the current remaining space.\n    # This helps in packing more densely.\n    fill_ratio_score = item / (suitable_bins_remain_cap + 1e-9)\n\n    # Combine metrics multiplicatively:\n    # We want both a tight fit AND a good fill ratio of the current remaining capacity.\n    # This multiplicative approach naturally penalizes bins with very large remaining capacities\n    # because the fill_ratio_score will be small for them, even if the tightness_score is high.\n    # It also favors bins where the item itself is large relative to the remaining space.\n    combined_score = tightness_score * fill_ratio_score\n\n    # Assign the calculated scores to the appropriate bins\n    priorities[suitable_bin_indices] = combined_score\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 94.01164534875782,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes tight fits using a sigmoid, with a penalty for large initial capacities.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities\n\n    valid_bins_remain_cap = bins_remain_cap[fit_mask]\n\n    # Component 1: Sigmoid for tight fits (inspired by priority_v0)\n    # Prioritize bins where the remaining capacity after placing the item is small.\n    slack = valid_bins_remain_cap - item\n    \n    # Normalize slack to be in a range suitable for sigmoid, focusing on small slack.\n    # We map smaller slack to larger input for sigmoid, thus higher output.\n    min_slack = np.min(slack)\n    max_slack = np.max(slack)\n    \n    sigmoid_scores = np.zeros_like(slack, dtype=float)\n    if max_slack > min_slack:\n        # Transform slack: smaller slack -> larger transformed value\n        transformed_slack = max_slack - slack\n        normalized_transformed_slack = transformed_slack / (max_slack - min_slack)\n        # Apply sigmoid centered around 0.5 for smooth preference\n        steepness = 5.0 \n        sigmoid_input = steepness * (normalized_transformed_slack - 0.5)\n        sigmoid_scores = 1 / (1 + np.exp(-sigmoid_input))\n    elif slack.size > 0: # All slacks are the same\n        sigmoid_scores = np.full_like(slack, 0.5) # Neutral score if all fits are identical\n\n\n    # Component 2: Penalty for large initial capacities (inspired by the idea of penalizing large bins)\n    # Reduce priority for bins that have significantly more capacity than needed initially.\n    # This is a simple inverse capacity scaling. Add epsilon to avoid division by zero.\n    epsilon_large_cap = 1e-6\n    large_capacity_penalty = epsilon_large_cap / (valid_bins_remain_cap + epsilon_large_cap)\n\n\n    # Combine scores: Multiply sigmoid scores by penalty.\n    # A high sigmoid score (tight fit) AND a low penalty (not excessively large bin) is preferred.\n    combined_scores = sigmoid_scores * large_capacity_penalty\n\n    # Normalize combined scores for the fitting bins\n    sum_combined_scores = np.sum(combined_scores)\n    if sum_combined_scores > 0:\n        normalized_combined_scores = combined_scores / sum_combined_scores\n    else: # If all scores are zero (e.g., if penalty made them zero)\n        # Fallback: give equal priority to all fitting bins\n        normalized_combined_scores = np.ones_like(valid_bins_remain_cap) / len(valid_bins_remain_cap)\n\n    priorities[fit_mask] = normalized_combined_scores\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 5.0,
    "halstead": 282.11056593197316,
    "exec_success": true
  }
]