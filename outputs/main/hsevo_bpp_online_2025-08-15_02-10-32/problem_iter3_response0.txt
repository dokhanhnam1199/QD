```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with a dynamic penalty based on the item's size relative
    to the bin's remaining capacity, and considers the overall distribution of
    remaining capacities.

    Prioritizes bins that are a tight fit, but also dynamically penalizes bins
    with excess capacity that is disproportionately large compared to the item size.
    It also incorporates a factor that encourages using bins that are closer to
    the average remaining capacity among suitable bins, promoting a more balanced
    usage of bins.
    """
    priorities = np.zeros_like(bins_remain_cap)
    suitable_bins_mask = bins_remain_cap >= item

    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]
    
    # --- Component 1: Best Fit (Tightness) ---
    # Prioritize bins with less remaining capacity after placing the item.
    # Add a small epsilon to avoid division by zero if remaining_cap == item.
    best_fit_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)

    # --- Component 2: Dynamic Excess Capacity Penalty ---
    # Penalize bins where the remaining capacity (after placing the item) is
    # significantly larger than the item itself.
    # We want to penalize `suitable_bins_remain_cap - item` when it's large relative to `item`.
    # Using a log-based penalty can be more robust than a simple inverse
    # and less sensitive to extreme outliers in excess capacity.
    excess_capacity_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)
    # Penalize more if the excess ratio is high. A higher penalty value means lower priority.
    # We use 1 + log(1 + ratio) to ensure positive values and a gradual penalty.
    # Adding 1 to log argument to handle cases where ratio is 0.
    excess_penalty = 1.0 / (1.0 + np.log(1.0 + excess_capacity_ratio)) # Lower value for higher penalty

    # --- Component 3: Distributional Balancing ---
    # Consider how "central" a bin's remaining capacity is within the set of suitable bins.
    # Bins that are closer to the mean remaining capacity of suitable bins might be
    # preferred to avoid creating too many bins with very large remaining spaces,
    # or conversely, using up all the slightly-larger-but-still-suitable bins too quickly.
    if len(suitable_bins_remain_cap) > 1:
        avg_suitable_cap = np.mean(suitable_bins_remain_cap)
        # Score based on proximity to the average: higher score for being closer.
        # Using inverse of absolute difference from average.
        proximity_to_avg_score = 1.0 / (np.abs(suitable_bins_remain_cap - avg_suitable_cap) + 1e-9)
    else:
        # If only one suitable bin, this component has no effect.
        proximity_to_avg_score = np.ones_like(suitable_bins_remain_cap)

    # --- Combination Strategy ---
    # We want to maximize best_fit_score and proximity_to_avg_score,
    # and maximize excess_penalty (which means minimizing the penalty term).
    # Multiply scores together.
    # Using weights to balance the contributions of each component. These weights
    # can be tuned based on empirical performance. For now, we give equal weight conceptually.
    
    # The effective priority for suitable bins is the product of their scores.
    # Higher scores are better.
    priorities[suitable_bins_mask] = (best_fit_score * excess_penalty * proximity_to_avg_score)

    return priorities
```
