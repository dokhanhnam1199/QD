{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a dynamic penalty based on the item size relative to bin capacity.\n    Prioritizes bins that offer a \"near-perfect\" fit without excessive leftover space,\n    dynamically adjusting the penalty based on how \"tight\" the fit is.\n    This aims for better space utilization by being more sensitive to the actual item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # \"Best Fit\" component: Prioritize bins with minimum remaining capacity after packing.\n    # We use the negative of the remaining capacity to transform minimization into maximization.\n    # Add a small epsilon to ensure no division by zero or log(0) if remaining_cap == item.\n    # Using log to compress the range and emphasize smaller differences.\n    best_fit_score = -np.log(suitable_bins_remain_cap - item + 1e-9)\n    \n    # Dynamic Penalty component: Penalize bins with significantly more capacity than needed.\n    # The penalty is higher when the \"excess capacity\" (remaining_cap - item) is large\n    # relative to the item's size. This makes the penalty scale with the item's magnitude.\n    \n    # Calculate the \"tightness ratio\": (item_size) / (remaining_capacity_after_packing)\n    # A higher ratio means a tighter fit.\n    tightness_ratio = item / (suitable_bins_remain_cap - item + 1e-9)\n    \n    # Calculate a penalty that is higher for bins with a lower tightness ratio (more excess capacity relative to item size)\n    # We want to penalize bins where (suitable_bins_remain_cap - item) is large compared to 'item'.\n    # Using a sigmoid-like function (inverse of a scaled ratio) to dampen extreme values and provide a smoother penalty.\n    # The scaling factor (e.g., 1.0) can be tuned.\n    \n    # Higher penalty for lower tightness_ratio. Invert and add 1 to avoid division by zero and ensure positive penalty.\n    # A larger suitable_bins_remain_cap relative to 'item' leads to a smaller tightness_ratio,\n    # which after inversion and addition, results in a larger penalty.\n    # We want to *subtract* this penalty from the best_fit_score, so a higher penalty means a lower final score.\n    penalty_component = 1.0 / (tightness_ratio + 0.5) # Add 0.5 to avoid issues with very tight fits.\n    \n    # Combine the scores. We want to maximize `best_fit_score` and minimize `penalty_component`.\n    # A simple subtraction works if interpreted as score = bf_score - penalty.\n    # Alternatively, we can multiply if penalties were designed as multipliers.\n    # Here, we aim for a higher combined score. Since `best_fit_score` is already a maximization proxy,\n    # and `penalty_component` is something we want to minimize (i.e., a higher penalty is bad),\n    # we subtract the penalty.\n    \n    # To make it a maximization problem directly, we can express it as:\n    # Score = best_fit_score - penalty_component\n    # or, if we want to penalize the penalty:\n    # Score = best_fit_score * (1 / (penalty_component + epsilon)) which is equivalent to\n    # Score = best_fit_score * tightness_ratio (approximately)\n    # Let's use a multiplicative approach where a higher `penalty_component` reduces the score.\n    # A simple way to combine: maximize `best_fit_score` and maximize `1 / (penalty_component + epsilon)`\n    # This means maximizing `best_fit_score * (tightness_ratio)`.\n    \n    # Let's refine the penalty: Penalize bins where `remaining_cap - item` is large relative to `item`.\n    # Consider `excess_ratio = (remaining_cap - item) / item`. We want to penalize high `excess_ratio`.\n    # Penalty_score = 1 / (excess_ratio + 1).\n    # This is similar to the tightness ratio logic but framed differently.\n    \n    excess_ratio = (suitable_bins_remain_cap - item) / (item + 1e-9)\n    # A bin with exact fit has excess_ratio = 0. A bin with large excess has large excess_ratio.\n    # We want to penalize large excess_ratio. So, a good penalty multiplier would be 1 / (excess_ratio + C).\n    # The smaller the `1 / (excess_ratio + C)`, the worse the bin.\n    # So, we want to maximize `best_fit_score` and maximize `1 / (excess_ratio + C)`.\n    # Thus, we can multiply them.\n    \n    penalty_multiplier = 1.0 / (excess_ratio + 0.2) # Add 0.2 to ensure it's not too aggressive.\n    \n    # Final priority is the product of the best-fit score proxy and the penalty multiplier.\n    # Higher best_fit_score is good. Higher penalty_multiplier is good (means low excess ratio).\n    priorities[suitable_bins_mask] = best_fit_score * penalty_multiplier\n    \n    return priorities\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}