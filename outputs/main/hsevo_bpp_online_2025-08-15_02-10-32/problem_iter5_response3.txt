```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines exact fit prioritization with a refined best-fit strategy that
    penalizes overly large remaining capacities, encouraging fuller bins.
    """
    epsilon_small = 1e-9
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Mask for bins that can fit the item
    suitable_bins_mask = bins_remain_cap >= item

    # Assign very high priority to exact fits
    exact_fit_mask = np.isclose(bins_remain_cap, item)
    priorities[exact_fit_mask] = 1e9

    # For bins that are not an exact fit but can accommodate the item
    non_exact_suitable_mask = suitable_bins_mask & ~exact_fit_mask

    if np.any(non_exact_suitable_mask):
        suitable_capacities = bins_remain_cap[non_exact_suitable_mask]
        remaining_capacities_after_fit = suitable_capacities - item

        # Base priority: inverse of remaining capacity after fit (Best Fit)
        # Higher score for smaller remaining capacity
        best_fit_scores = 1.0 / (remaining_capacities_after_fit + epsilon_small)

        # Penalty for bins that are initially "too empty"
        # We want to favor bins that are already somewhat filled.
        # Penalize bins where initial `bins_remain_cap` is significantly larger than the item.
        # A threshold of `item * 3.0` for initial capacity is used.
        # The penalty is scaled inversely by the initial capacity itself to avoid
        # overly aggressive penalties for moderately large capacities.
        large_capacity_threshold = item * 3.0
        penalty = np.zeros_like(suitable_capacities, dtype=float)
        
        large_capacity_mask = suitable_capacities > large_capacity_threshold
        
        # Calculate penalty: Lower score for larger initial capacities.
        # Use a scaled inverse of the initial remaining capacity.
        # Adding a small constant `epsilon_small` to the denominator to prevent division by zero.
        # Subtracting this scaled inverse from the best_fit_scores.
        penalty[large_capacity_mask] = 1.0 / (suitable_capacities[large_capacity_mask] + epsilon_small)
        
        # Combine scores: Prioritize tight fits, then penalize very empty bins.
        # We add the penalty (which is negative in effect due to `1/cap` nature) to the best fit score.
        # A smaller initial capacity (leading to a larger `1/cap`) is less penalized.
        # A larger initial capacity (leading to a smaller `1/cap`) is more penalized.
        
        # Let's refine this. We want:
        # 1. High score for small `remaining_capacities_after_fit`
        # 2. High score for small `suitable_capacities` (initial)
        
        # Score = `(1.0 / (remaining_capacities_after_fit + epsilon_small))`  # Best Fit
        #       `+ W * (1.0 / (suitable_capacities + epsilon_small))`      # Prefer "almost full" bins

        # Let's use a weight `W=0.5` for the "almost full" preference.
        weight_almost_full = 0.5
        combined_priority = best_fit_scores + weight_almost_full * (1.0 / (suitable_capacities + epsilon_small))
        
        priorities[non_exact_suitable_mask] = combined_priority

    # Normalize priorities for non-exact fits to ensure they don't overshadow exact fits
    # and to make the best-fit scores relative among themselves.
    if np.any(non_exact_suitable_mask):
        non_exact_priorities = priorities[non_exact_suitable_mask]
        sum_non_exact_priorities = np.sum(non_exact_priorities)
        if sum_non_exact_priorities > 0:
            priorities[non_exact_suitable_mask] = non_exact_priorities / sum_non_exact_priorities

    return priorities
```
