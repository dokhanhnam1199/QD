{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Assigns bin priorities considering utilization, fragmentation, and remaining capacity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    # 2. Existing Fill Bonus\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (item / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.01\n\n    # 5. Remaining Capacity Consideration\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap))\n\n    # 6. Penalize Nearly Full Bins\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    priorities = np.clip(priorities, -1, 1)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Improved priority function with adaptive parameters and combined strategies.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    max_cap = np.max(bins_remain_cap)\n\n    # 1. Feasibility Check (Essential - High Priority)\n    priorities[~eligible_bins] = -np.inf\n\n    # 2. Fill Ratio (Primary Optimization Goal)\n    fill_ratio = item / bins_remain_cap\n    priorities[eligible_bins] += fill_ratio[eligible_bins]\n\n    # 3. Encourage Existing Fill (But Moderately)\n    existing_fill_bonus = 0.15 * (1 - (bins_remain_cap / max_cap))\n    priorities[eligible_bins] += existing_fill_bonus[eligible_bins]\n\n    # 4. Fragmentation Penalty (Adaptive)\n    gap_size = bins_remain_cap - item\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n\n    # Dynamic penalty based on gap size relative to average item size and max bin size.\n    frag_threshold = 0.2 * max_cap #If gap is less than 20% of max capacity\n    fragmentation_penalty = 0.1 * (avg_item_size / max_cap) # penalty relative to item size\n\n    small_gap = (gap_size > 0) & (gap_size < frag_threshold)\n    priorities[small_gap & eligible_bins] -= fragmentation_penalty\n\n    # 5. Near-Perfect Fit Reward (Small but consistent)\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.05\n\n    # 6. Remaining Capacity Preference (Slight bias towards larger remaining capacity)\n    priorities[eligible_bins] += 0.03 * (bins_remain_cap[eligible_bins] / max_cap)\n\n    # 7. Minimum Useful Capacity Penalty (Aggressive to avoid useless small gaps)\n    min_useful_capacity = 0.15 * max_cap\n    nearly_full = (gap_size >0 ) & (gap_size < min_useful_capacity)\n    priorities[nearly_full & eligible_bins] -= 0.2\n\n    # 8. Item Size Consideration: Slightly prefer bins that fit the item well relative to *average* fill level\n    average_fill = np.mean(1 - (bins_remain_cap / max_cap))\n    item_fit_score = item / max_cap\n\n    # If the item size is close to the average fill level, give a small bonus.\n    if 0.05 < abs(item_fit_score - average_fill) < 0.25:\n        priorities[eligible_bins] += 0.02\n\n\n    # 9. Scale and Clip (Important for stability)\n    priorities = np.clip(priorities, -1, 1)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first heuristic incorporates a much more complex, multi-faceted approach, considering fill ratio, existing fill, fragmentation penalty, near-perfect fit reward, remaining capacity, nearly full bin penalty, look-ahead fragmentation penalty, and half-full bin reward, bin utilization variance penalty, dynamic gap penalty scaling, reward for creating bins with specific common size, and a final scaling/clipping step. The last heuristic uses a simple log ratio calculation.\nComparing (2nd) vs (19th), the second heuristic uses a weighted combination of fill ratio, existing fill bonus, and fragmentation penalty. The 19th heuristic uses a simple log ratio calculation.\nComparing (1st) vs (2nd), we see that the first heuristic has new heuristics like 9. Bin Utilization Variance Penalty, 10. Dynamic Gap Penalty Scaling, 11. Reward for creating bins that can fit a specific \"common size\", and 12. Scale and Clip and uses more aggressive weights than the second.\nComparing (3rd) vs (4th), we see the 3rd and 4th are nearly identical; they differ only in comments.\nComparing (second worst) vs (worst), we see 19th and 20th are nearly identical; both are the same function. Overall: Better heuristics employ multiple factors including fill ratio, fragmentation, remaining capacity, and look-ahead considerations, combining them with carefully tuned weights and adaptive penalties/rewards. They often incorporate scaling/clipping to maintain stability and prevent extreme priority values. Simpler heuristics rely on one or two factors.\n- \nOkay, I'll help you redefine \"Current self-reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective self-reflection.\" Here's a refined approach:\n\n*   **Keywords:** Iterative refinement, problem constraints, performance-driven, simplification.\n\n*   **Advice:** Begin with a simple heuristic that directly addresses core constraints. Iteratively improve by incorporating relevant factors guided by performance analysis.\n\n*   **Avoid:** Premature complexity, over-parameterization without justification, neglecting core problem constraints.\n\n*   **Explanation:** Prioritize a functional baseline and build upon it using data-driven insights. Focus on addressing the core problem before adding complexity, and only add complexity where there is a demonstrated performance improvement.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}