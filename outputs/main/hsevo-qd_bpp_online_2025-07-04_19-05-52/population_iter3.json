[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n      # No bin can fit the item, prioritize creating a new bin. Since we cannot create bins in this problem. We'll assign lowest priority possible\n      return np.zeros_like(bins_remain_cap) - np.inf # Give a large negative number to effectively say these are impossible.\n\n    # First priority: Bins that can fit the item with minimal waste (highest fill ratio). Avoid fragmentation!\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf # Disqualify bins that can't fit.\n    priorities = fill_ratio\n\n\n    # Add a small bonus for bins that are already relatively full. This promotes utilizing bins further before opening new ones.\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Assuming bins all have same max capacity, normalize\n    priorities[eligible_bins] += 0.1 * existing_fill[eligible_bins] #Adjustable weighting factor to existing_fill bonus.\n\n\n    # Penalty for bins that have *just enough* space; Encourages more even filling\n    # Avoiding situations where next few items can *only* go in that single bin creating bottlenecks.\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap)) #Bins with nearly perfect fits\n    priorities[small_gap & eligible_bins] -= 0.05 #Adjustable penalty factor\n\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 74.23092131656186,
    "mi": 78.66680715880324,
    "token_count": 146.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, existing fullness, and gap penalty for bin selection.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.1 * existing_fill[eligible_bins]\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= 0.05\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 206.0894050155578,
    "mi": 58.52635020262376,
    "token_count": 147.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # Primary Priority: Maximize bin utilization while minimizing fragmentation.\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf  # Disqualify bins that can't fit.\n    priorities = fill_ratio\n\n    # Bonus for bins that are already well-utilized (avoid opening new bins unnecessarily).\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.15 * existing_fill[eligible_bins]  # Increased weight\n\n    # Fragmentation Penalty: Heavily penalize bins that would leave small gaps.  Make this adaptive to item size.\n    #  The smaller the average item size is, the more important it becomes to avoid small gaps.\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item #Average item size to decide penalty scaling\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.10 + 0.05*(avg_item_size / np.max(bins_remain_cap)) #Dynamic penalty; adjustable base\n    priorities[small_gap & eligible_bins] -= penalty_factor #Increased base penalty\n\n\n\n    # Reward near-perfect fits, but less so than perfect fills\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.02 # Small bonus for perfect fit\n\n    # Scale priorities to ensure a reasonable range\n    priorities = np.clip(priorities, -1, 1)  # Prevent extreme values\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 3.9688871160749857,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 311.8387309128727,
    "mi": 76.22242281742339,
    "token_count": 258.0,
    "exec_success": true
  }
]