[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n      # No bin can fit the item, prioritize creating a new bin. Since we cannot create bins in this problem. We'll assign lowest priority possible\n      return np.zeros_like(bins_remain_cap) - np.inf # Give a large negative number to effectively say these are impossible.\n\n    # First priority: Bins that can fit the item with minimal waste (highest fill ratio). Avoid fragmentation!\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf # Disqualify bins that can't fit.\n    priorities = fill_ratio\n\n\n    # Add a small bonus for bins that are already relatively full. This promotes utilizing bins further before opening new ones.\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Assuming bins all have same max capacity, normalize\n    priorities[eligible_bins] += 0.1 * existing_fill[eligible_bins] #Adjustable weighting factor to existing_fill bonus.\n\n\n    # Penalty for bins that have *just enough* space; Encourages more even filling\n    # Avoiding situations where next few items can *only* go in that single bin creating bottlenecks.\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap)) #Bins with nearly perfect fits\n    priorities[small_gap & eligible_bins] -= 0.05 #Adjustable penalty factor\n\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 74.23092131656186,
    "mi": 78.66680715880324,
    "token_count": 146.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, existing fullness, and gap penalty for bin selection.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.1 * existing_fill[eligible_bins]\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= 0.05\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 206.0894050155578,
    "mi": 58.52635020262376,
    "token_count": 147.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # Primary Priority: Maximize bin utilization while minimizing fragmentation.\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf  # Disqualify bins that can't fit.\n    priorities = fill_ratio\n\n    # Bonus for bins that are already well-utilized (avoid opening new bins unnecessarily).\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.15 * existing_fill[eligible_bins]  # Increased weight\n\n    # Fragmentation Penalty: Heavily penalize bins that would leave small gaps.  Make this adaptive to item size.\n    #  The smaller the average item size is, the more important it becomes to avoid small gaps.\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item #Average item size to decide penalty scaling\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.10 + 0.05*(avg_item_size / np.max(bins_remain_cap)) #Dynamic penalty; adjustable base\n    priorities[small_gap & eligible_bins] -= penalty_factor #Increased base penalty\n\n\n\n    # Reward near-perfect fits, but less so than perfect fills\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.02 # Small bonus for perfect fit\n\n    # Scale priorities to ensure a reasonable range\n    priorities = np.clip(priorities, -1, 1)  # Prevent extreme values\n    return priorities",
    "response_id": 4,
    "tryHS": true,
    "obj": 3.9688871160749857,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 311.8387309128727,
    "mi": 76.22242281742339,
    "token_count": 258.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                well_utilized_weight: float = 0.5620779929510653,\n                small_gap_threshold: float = 0.5469013482151883,\n                penalty_base: float = 0.32547627501697496,\n                penalty_scaling: float = 0.20719000925734765,\n                near_perfect_fit_bonus: float = 0.006120595101508675,\n                clip_lower: float = -1.5955296147342695,\n                clip_upper: float = 1.0099227962254071,\n                rtol: float = 9.375468344349782e-06,\n                atol: float = 8.098184462613543e-07,\n                min_remain_cap_priority: float = -1.6144647234512934) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        well_utilized_weight: Weight for bins that are already well-utilized.\n        small_gap_threshold: Threshold for considering a gap as small (fraction of max bin cap).\n        penalty_base: Base penalty for small gaps.\n        penalty_scaling: Scaling factor for the small gap penalty based on item size.\n        near_perfect_fit_bonus: Bonus for near-perfect fits.\n        clip_lower: Lower bound for clipping priority values.\n        clip_upper: Upper bound for clipping priority values.\n        rtol: Relative tolerance for near-perfect fit comparison.\n        atol: Absolute tolerance for near-perfect fit comparison.\n        min_remain_cap_priority: priority value when no bin can fit the item\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.full_like(bins_remain_cap, min_remain_cap_priority)",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 11.60964047443681,
    "mi": 97.90365228622603,
    "token_count": 144.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Assigns bin priorities considering utilization, fragmentation, and remaining capacity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization (fill ratio)\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    # 2. Existing Fill Bonus\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (item / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.01\n\n    # 5. Remaining Capacity Consideration - scaled\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap))\n\n    # 6. Penalize Nearly Full Bins\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    # 7. Adjusted Fragmentation Penalty based on Item Size\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    fragmentation_threshold = 0.5 * np.max(bins_remain_cap)  # Example dynamic threshold\n    high_fragmentation = gap_size > fragmentation_threshold\n    if high_fragmentation.any():\n        priorities[high_fragmentation & eligible_bins] -= 0.05 * (item / np.max(bins_remain_cap))\n\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 3.5700039888312682,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 311.8387309128727,
    "mi": 54.23927513093755,
    "token_count": 231.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Enhanced priority function considering utilization, fragmentation, and future packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization (Fill Ratio)\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    # 2. Existing Fill Bonus (Encourage using partially filled bins) - Adjusted weight.\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.20 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive based on remaining capacity and item size)\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (avg_item_size / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward (Encourage near-optimal packing) - Reduced magnitude\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.01  # Smaller reward\n\n    # 5. Remaining Capacity Consideration (Prioritize bins with larger *remaining* capacity among eligible bins)\n    # This helps to keep options open for potentially larger future items.  Important!\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap))\n\n    # 6. Penalize bins that will be left with capacities that are smaller than a certain threshold (Dynamic threshold)\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)  # Bin must have at least 15% useful capacity\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    # 7. Scale and Clip\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.5700039888312682,
    "SLOC": 25.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 531.8850936442687,
    "mi": 76.24764014804039,
    "token_count": 337.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                well_utilized_weight: float = 0.9767042431939332,\n                small_gap_threshold: float = 0.7661779765338794,\n                penalty_base: float = 0.822658676260284,\n                penalty_scaling: float = 0.5774246707396835,\n                near_perfect_fit_bonus: float = 0.05102813276505112,\n                clip_lower: float = -1.6149819187450574,\n                clip_upper: float = 0.14715493303357707,\n                rtol: float = 9.771420380638054e-05,\n                atol: float = 8.874997683098374e-06,\n                min_item_size_cap_ratio: float = 1.2934804877229156) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        well_utilized_weight: Weight for bins that are already well-utilized.\n        small_gap_threshold: Threshold for considering a gap as small (fraction of max bin cap).\n        penalty_base: Base penalty for small gaps.\n        penalty_scaling: Scaling factor for the small gap penalty based on item size.\n        near_perfect_fit_bonus: Bonus for near-perfect fits.\n        clip_lower: Lower bound for clipping priority values.\n        clip_upper: Upper bound for clipping priority values.\n        rtol: Relative tolerance for near-perfect fit comparison.\n        atol: Absolute tolerance for near-perfect fit comparison.\n        min_item_size_cap_ratio:  A bin must have at least item size cap * this ratio\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item * min_item_size_cap_ratio\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 38.053747805010275,
    "mi": 94.29356369593572,
    "token_count": 147.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Assigns bin priorities considering utilization, fragmentation, and remaining capacity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    # 2. Existing Fill Bonus\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (item / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.01\n\n    # 5. Remaining Capacity Consideration\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap))\n\n    # 6. Penalize Nearly Full Bins\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 3.5700039888312682,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 299.13186826628436,
    "mi": 82.58039517444328,
    "token_count": 216.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response3.txt_stdout.txt",
    "code_path": "problem_iter9_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Improved priority function with adaptive parameters and combined strategies.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    max_cap = np.max(bins_remain_cap)\n\n    # 1. Feasibility Check (Essential - High Priority)\n    priorities[~eligible_bins] = -np.inf\n\n    # 2. Fill Ratio (Primary Optimization Goal)\n    fill_ratio = item / bins_remain_cap\n    priorities[eligible_bins] += fill_ratio[eligible_bins]\n\n    # 3. Encourage Existing Fill (But Moderately)\n    existing_fill_bonus = 0.15 * (1 - (bins_remain_cap / max_cap))\n    priorities[eligible_bins] += existing_fill_bonus[eligible_bins]\n\n    # 4. Fragmentation Penalty (Adaptive)\n    gap_size = bins_remain_cap - item\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n\n    # Dynamic penalty based on gap size relative to average item size and max bin size.\n    frag_threshold = 0.2 * max_cap #If gap is less than 20% of max capacity\n    fragmentation_penalty = 0.1 * (avg_item_size / max_cap) # penalty relative to item size\n\n    small_gap = (gap_size > 0) & (gap_size < frag_threshold)\n    priorities[small_gap & eligible_bins] -= fragmentation_penalty\n\n    # 5. Near-Perfect Fit Reward (Small but consistent)\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.05\n\n    # 6. Remaining Capacity Preference (Slight bias towards larger remaining capacity)\n    priorities[eligible_bins] += 0.03 * (bins_remain_cap[eligible_bins] / max_cap)\n\n    # 7. Minimum Useful Capacity Penalty (Aggressive to avoid useless small gaps)\n    min_useful_capacity = 0.15 * max_cap\n    nearly_full = (gap_size >0 ) & (gap_size < min_useful_capacity)\n    priorities[nearly_full & eligible_bins] -= 0.2\n\n    # 8. Item Size Consideration: Slightly prefer bins that fit the item well relative to *average* fill level\n    average_fill = np.mean(1 - (bins_remain_cap / max_cap))\n    item_fit_score = item / max_cap\n\n    # If the item size is close to the average fill level, give a small bonus.\n    if 0.05 < abs(item_fit_score - average_fill) < 0.25:\n        priorities[eligible_bins] += 0.02\n\n\n    # 9. Scale and Clip (Important for stability)\n    priorities = np.clip(priorities, -1, 1)\n\n    return priorities",
    "response_id": 3,
    "tryHS": true,
    "obj": 3.9389708815317115,
    "SLOC": 31.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 618.6154090928255,
    "mi": 74.16663938381369,
    "token_count": 330.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Enhanced priority function considering utilization, fragmentation, and future packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization (Fill Ratio) - Increased Weight\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = 1.2 * fill_ratio  # Increased weight for fill ratio\n\n    # 2. Existing Fill Bonus (Encourage using partially filled bins) - Adjusted weight.\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.25 * existing_fill[eligible_bins]  # Slightly increased weight\n\n    # 3. Fragmentation Penalty (Adaptive based on remaining capacity and item size)\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (avg_item_size / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward (Encourage near-optimal packing) - Increased magnitude\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.02  # Increased reward\n\n    # 5. Remaining Capacity Consideration (Prioritize bins with larger *remaining* capacity among eligible bins)\n    # This helps to keep options open for potentially larger future items.  Important!  Adjusted Weight\n    priorities[eligible_bins] += 0.06 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap)) # Slightly increased\n\n    # 6. Penalize bins that will be left with capacities that are smaller than a certain threshold (Dynamic threshold)\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)  # Bin must have at least 15% useful capacity\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    # 7.  Look-Ahead Fragmentation Penalty (New Heuristic)\n    # Penalize bins that, after placing the item, would leave a remaining space\n    # that's smaller than a fraction of the *smallest* item size seen so far.\n    # This encourages consolidating smaller items.\n\n    min_item_size = np.min(item) if isinstance(item, np.ndarray) else item\n    if min_item_size > 0: # Check for zero item sizes to avoid division by zero\n        very_small_gap = gap_size < (0.5 * min_item_size)\n        priorities[very_small_gap & eligible_bins] -= 0.12 # Higher penalty\n\n    # 8. Scale and Clip\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 3.5101715197447194,
    "SLOC": 29.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 544.1524431835039,
    "mi": 73.8613814613603,
    "token_count": 334.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response0.txt_stdout.txt",
    "code_path": "problem_iter13_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                well_utilized_weight: float = 0.24728286901450924,\n                small_gap_threshold: float = 0.4985336729381905,\n                penalty_base: float = 0.49469717920928247,\n                penalty_scaling: float = 0.7052548426334041,\n                near_perfect_fit_bonus: float = 0.031543737126602966,\n                clip_lower: float = -1.1063978813760091,\n                clip_upper: float = 0.35396569928206845,\n                rtol: float = 0.0008781615481267307,\n                atol: float = 6.625360861980192e-06,\n                min_item_size_cap_ratio: float = 1.4312050738011082,\n                eligible_bins_multiplier: float = 0.43177516546408823) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        well_utilized_weight: Weight for bins that are already well-utilized.\n        small_gap_threshold: Threshold for considering a gap as small (fraction of max bin cap).\n        penalty_base: Base penalty for small gaps.\n        penalty_scaling: Scaling factor for the small gap penalty based on item size.\n        near_perfect_fit_bonus: Bonus for near-perfect fits.\n        clip_lower: Lower bound for clipping priority values.\n        clip_upper: Upper bound for clipping priority values.\n        rtol: Relative tolerance for near-perfect fit comparison.\n        atol: Absolute tolerance for near-perfect fit comparison.\n        min_item_size_cap_ratio:  A bin must have at least item size cap * this ratio\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item * min_item_size_cap_ratio\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 38.053747805010275,
    "mi": 95.49180387389299,
    "token_count": 154.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, existing fill, and fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # Fill Ratio\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = 0.6 * fill_ratio\n\n    # Existing Fill Bonus\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # Fragmentation Penalty\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= 0.15\n    \n    # Scale and Clip\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.7395293179098523,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 307.35774857210805,
    "mi": 54.41779192573494,
    "token_count": 189.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response3.txt_stdout.txt",
    "code_path": "problem_iter15_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Improved priority function focusing on reducing fragmentation and maximizing bin utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    bin_capacity = np.max(bins_remain_cap)\n\n    # 1. Fill Ratio Maximization (Aggressive)\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = 1.5 * fill_ratio  # Increased fill ratio importance.\n\n    # 2. Encourage existing fill (but less aggressively than fill ratio).\n    existing_fill = 1 - (bins_remain_cap / bin_capacity)\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive and more sensitive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * bin_capacity)\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    penalty_factor = 0.2 + 0.1 * (avg_item_size / bin_capacity)  # Increased base penalty.\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward (More significant reward)\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.05\n\n    # 5. Prioritize larger remaining capacity (slightly adjusted weight)\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / bin_capacity)\n\n    # 6. Significant penalty for bins that become nearly full, with dynamic threshold\n    min_useful_capacity = 0.15 * bin_capacity\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.15  # Increased penalty\n\n    # 7. Look-Ahead Fragmentation Penalty (Relative to smallest item) - Enhanced penalty.\n    min_item_size = np.min(item) if isinstance(item, np.ndarray) else item\n    if min_item_size > 0:\n        very_small_gap = gap_size < (0.4 * min_item_size)  # Reduced threshold\n        priorities[very_small_gap & eligible_bins] -= 0.2  # Increased penalty\n\n    # 8. Reward bins close to half-full (Balance utilization with future flexibility)\n    half_full_range_lower = 0.4 * bin_capacity\n    half_full_range_upper = 0.6 * bin_capacity\n\n    close_to_half = (bins_remain_cap >= (item + half_full_range_lower)) & (bins_remain_cap <= (item + half_full_range_upper))\n    priorities[close_to_half & eligible_bins] += 0.08  # Moderate reward\n\n    # 9. Scale and Clip\n    priorities = np.clip(priorities, -1, 1)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 2.5029916234543417,
    "SLOC": 21.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 342.88332829555736,
    "mi": 73.24054956707269,
    "token_count": 274.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response0.txt_stdout.txt",
    "code_path": "problem_iter16_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, existing_fill_weight: float = 0.20603594174665274,\n                frag_threshold_coeff: float = 0.4741767435098202, fragmentation_penalty_coeff: float = 0.1369505266898457,\n                near_perfect_fit_rtol: float = 1.673171340186565e-05, near_perfect_fit_atol: float = 4.018047020847416e-06,\n                remaining_capacity_weight: float = 0.09238865018818894, min_useful_capacity_coeff: float = 0.19589275047108662,\n                min_useful_capacity_penalty: float = 0.4317189226251604, item_fit_score_threshold_lower: float = 0.18349601040557917,\n                item_fit_score_threshold_upper: float = 0.45507864051512825, item_fit_score_bonus: float = 0.06802531697785033,\n                clip_lower: float = -3.6528031163498027, clip_upper: float = 2.1112751497191247) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Improved priority function with adaptive parameters and combined strategies.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        existing_fill_weight: Weight for encouraging existing fill.\n        frag_threshold_coeff: Coefficient for fragmentation threshold calculation.\n        fragmentation_penalty_coeff: Coefficient for fragmentation penalty calculation.\n        near_perfect_fit_rtol: Relative tolerance for near-perfect fit check.\n        near_perfect_fit_atol: Absolute tolerance for near-perfect fit check.\n        remaining_capacity_weight: Weight for remaining capacity preference.\n        min_useful_capacity_coeff: Coefficient for minimum useful capacity calculation.\n        min_useful_capacity_penalty: Penalty for nearly full bins.\n        item_fit_score_threshold_lower: Lower threshold for item fit score difference.\n        item_fit_score_threshold_upper: Upper threshold for item fit score difference.\n        item_fit_score_bonus: Bonus for item fit score within the thresholds.\n        clip_lower: Lower bound for clipping the priorities.\n        clip_upper: Upper bound for clipping the priorities.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 24.0,
    "mi": 81.13352681041704,
    "token_count": 153.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Assigns bin priorities considering utilization, fragmentation.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization (fill ratio) - increased weight\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = 1.1 * fill_ratio # Increased weight\n\n    # 2. Existing Fill Bonus - adjusted weight\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.22 * existing_fill[eligible_bins] # Slightly Increased weight\n\n    # 3. Fragmentation Penalty (Adaptive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (item / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward - keep consistent\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.015\n\n    # 5. Remaining Capacity Consideration - scaled, keep consistent\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap))\n\n    # 6. Penalize Nearly Full Bins - adjusted weight\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    # 7.  Look-Ahead Fragmentation Penalty\n    min_item_size = np.min(item) if isinstance(item, np.ndarray) else item\n    if min_item_size > 0:\n        very_small_gap = gap_size < (0.5 * min_item_size)\n        priorities[very_small_gap & eligible_bins] -= 0.12\n\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 3.3107299561228607,
    "SLOC": 26.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 576.4990188374604,
    "mi": 76.35715583926348,
    "token_count": 329.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Improved priority function focusing on reducing fragmentation and maximizing bin utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    bin_capacity = np.max(bins_remain_cap)\n\n    # 1. Fill Ratio Maximization (Aggressive)\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = 1.5 * fill_ratio  # Increased fill ratio importance.\n\n    # 2. Encourage existing fill (but less aggressively than fill ratio).\n    existing_fill = 1 - (bins_remain_cap / bin_capacity)\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive and more sensitive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * bin_capacity)\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    penalty_factor = 0.2 + 0.1 * (avg_item_size / bin_capacity)  # Increased base penalty.\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward (More significant reward)\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.05\n\n    # 5. Prioritize larger remaining capacity (slightly adjusted weight)\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / bin_capacity)\n\n    # 6. Significant penalty for bins that become nearly full, with dynamic threshold\n    min_useful_capacity = 0.15 * bin_capacity\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.15  # Increased penalty\n\n    # 7. Look-Ahead Fragmentation Penalty (Relative to smallest item) - Enhanced penalty.\n    min_item_size = np.min(item) if isinstance(item, np.ndarray) else item\n    if min_item_size > 0:\n        very_small_gap = gap_size < (0.4 * min_item_size)  # Reduced threshold\n        priorities[very_small_gap & eligible_bins] -= 0.2  # Increased penalty\n\n    # 8. Reward bins close to half-full (Balance utilization with future flexibility)\n    half_full_range_lower = 0.4 * bin_capacity\n    half_full_range_upper = 0.6 * bin_capacity\n\n    close_to_half = (bins_remain_cap >= (item + half_full_range_lower)) & (bins_remain_cap <= (item + half_full_range_upper))\n    priorities[close_to_half & eligible_bins] += 0.08  # Moderate reward\n\n    # New Heuristics\n\n    # 9. Bin Utilization Variance Penalty\n    bin_utilization = 1 - (bins_remain_cap / bin_capacity)\n    mean_utilization = np.mean(bin_utilization)\n    utilization_variance = np.abs(bin_utilization - mean_utilization)\n    priorities[eligible_bins] -= 0.03 * utilization_variance[eligible_bins]  # Penalize bins that deviate from average utilization\n\n    # 10. Dynamic Gap Penalty Scaling\n    gap_ratio = gap_size / bin_capacity\n    dynamic_gap_penalty = np.where(gap_ratio < 0.2, 0.15 * (0.2 - gap_ratio), 0)\n    priorities[eligible_bins] -= dynamic_gap_penalty[eligible_bins]\n\n    # 11. Reward for creating bins that can fit a specific \"common size\".\n    common_size = 0.25 * bin_capacity  # Example common size\n    room_for_common = gap_size >= common_size\n    priorities[room_for_common & eligible_bins] += 0.06\n\n    # 12. Scale and Clip\n    priorities = np.clip(priorities, -1, 1)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 2.5029916234543417,
    "SLOC": 42.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 1052.731384945576,
    "mi": 71.43982757852501,
    "token_count": 501.0,
    "exec_success": true
  }
]