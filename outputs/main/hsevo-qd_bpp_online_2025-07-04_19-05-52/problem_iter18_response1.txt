```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Enhanced priority function balancing bin utilization, fragmentation avoidance,
    and future accommodation of items, with dynamic adjustments based on item size.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    eligible_bins = bins_remain_cap >= item
    bin_capacity = np.max(bins_remain_cap)

    if not np.any(eligible_bins):
        return np.zeros_like(bins_remain_cap) - np.inf

    # 1. Fill Ratio Maximization (Adjusted weight)
    fill_ratio = item / bins_remain_cap
    fill_ratio[~eligible_bins] = -np.inf
    priorities = 1.6 * fill_ratio  # Slightly increased importance

    # 2. Existing Fill Encouragement (Adaptive)
    existing_fill = 1 - (bins_remain_cap / bin_capacity)
    priorities[eligible_bins] += 0.25 * existing_fill[eligible_bins] #Increased importance

    # 3. Fragmentation Penalty (Item-Size Aware)
    gap_size = bins_remain_cap - item
    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item
    small_gap_threshold = 0.3 * avg_item_size
    small_gap = gap_size < small_gap_threshold
    penalty_factor = 0.25  #Adjusted baseline penalty
    priorities[small_gap & eligible_bins] -= penalty_factor

    # 4. Near-Perfect Fit Reward (Increased Significance)
    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)
    priorities[near_perfect_fit & eligible_bins] += 0.1 # More significant reward

    # 5. Prioritize Larger Remaining Capacity (Diminishing Returns)
    capacity_priority = bins_remain_cap / bin_capacity
    priorities[eligible_bins] += 0.07 * capacity_priority[eligible_bins]  #Adjusted weight

    # 6. Penalty for Nearing Fullness (Adaptive Threshold)
    min_useful_capacity = 0.1 * bin_capacity  # Smaller Threshold
    nearly_full = gap_size < min_useful_capacity
    priorities[nearly_full & eligible_bins] -= 0.2 # Higher Penalty

    # 7. Look-Ahead Fragmentation (Enhanced, size-relative)
    min_item_size = np.min(item) if isinstance(item, np.ndarray) else item
    very_small_gap_threshold = 0.3 * min_item_size  # More restrictive gap
    very_small_gap = gap_size < very_small_gap_threshold
    priorities[very_small_gap & eligible_bins] -= 0.3 # Stronger Penalty

    # 8. Reward Bins Around Half-Full (Tuned Range, Adaptive Reward)
    half_full_range_lower = 0.35 * bin_capacity
    half_full_range_upper = 0.65 * bin_capacity
    close_to_half = (bins_remain_cap >= (item + half_full_range_lower)) & (bins_remain_cap <= (item + half_full_range_upper))
    priorities[close_to_half & eligible_bins] += 0.12 # Enhanced Reward

    # 9. Encourage packing in bins with similar remaining capacity
    capacity_std = np.std(bins_remain_cap)
    similar_capacity = np.abs(bins_remain_cap - np.mean(bins_remain_cap)) <= capacity_std
    priorities[similar_capacity & eligible_bins] += 0.06

    # 10. Global balancing bonus: penalize bins if the average remaining capacity in all bins is too high
    average_remaining_capacity = np.mean(bins_remain_cap)
    if average_remaining_capacity > 0.7 * bin_capacity:
        priorities[eligible_bins] -= 0.05

    # 11. Dynamic adjustment of fill ratio based on item size
    if item > 0.5 * bin_capacity:
        priorities = priorities - 0.1 * fill_ratio
    elif item < 0.1 * bin_capacity:
        priorities = priorities + 0.05 * fill_ratio

    # 12. Scale and Clip
    priorities = np.clip(priorities, -1, 1)

    return priorities
```
