```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Improved priority function focusing on reducing fragmentation and maximizing bin utilization.
    Version 2: Adapts penalty and reward dynamically based on item size and bin capacities.
    Also includes bin diversity to encourage even distribution of items.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    eligible_bins = bins_remain_cap >= item

    if not np.any(eligible_bins):
        return np.zeros_like(bins_remain_cap) - np.inf

    bin_capacity = np.max(bins_remain_cap)

    # 1. Fill Ratio Maximization (Aggressive, item-size aware)
    fill_ratio = item / bins_remain_cap
    fill_ratio[~eligible_bins] = -np.inf
    priority_fill_weight = 1.5 + 0.5 * (item / bin_capacity)  # Larger items get more fill priority
    priorities = priority_fill_weight * fill_ratio

    # 2. Encourage existing fill (but less aggressively than fill ratio).
    existing_fill = 1 - (bins_remain_cap / bin_capacity)
    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]

    # 3. Fragmentation Penalty (Adaptive and more sensitive, relative to item size)
    gap_size = bins_remain_cap - item
    small_gap_threshold = 0.2 * item  # Dynamic threshold relative to item size
    small_gap = gap_size < small_gap_threshold
    penalty_factor = 0.2 + 0.2 * (item / bin_capacity)  # Increased penalty for small gaps
    priorities[small_gap & eligible_bins] -= penalty_factor

    # 4. Near-Perfect Fit Reward (More significant reward)
    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)
    priorities[near_perfect_fit & eligible_bins] += 0.1  #Increased reward

    # 5. Prioritize larger remaining capacity (slightly adjusted weight)
    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / bin_capacity)

    # 6. Significant penalty for bins that become nearly full, with dynamic threshold
    min_useful_capacity = 0.15 * bin_capacity
    nearly_full = gap_size < min_useful_capacity
    nearly_full_penalty = 0.15 + 0.05 * (item / bin_capacity)  #Increased penalty if item is large
    priorities[nearly_full & eligible_bins] -= nearly_full_penalty

    # 7. Look-Ahead Fragmentation Penalty (Relative to item size) - Enhanced penalty.
    very_small_gap_threshold = 0.1 * item
    very_small_gap = gap_size < very_small_gap_threshold
    very_small_gap_penalty = 0.3 + 0.1 * (item/bin_capacity)
    priorities[very_small_gap & eligible_bins] -= very_small_gap_penalty

    # 8. Reward bins close to half-full (Balance utilization with future flexibility)
    half_full_range_lower = 0.4 * bin_capacity
    half_full_range_upper = 0.6 * bin_capacity

    close_to_half = (bins_remain_cap >= (item + half_full_range_lower)) & (bins_remain_cap <= (item + half_full_range_upper))
    priorities[close_to_half & eligible_bins] += 0.08  # Moderate reward

    # 9. Bin Diversity Reward: encourage use of bins with different fill levels
    bin_fill_levels = 1 - (bins_remain_cap / bin_capacity)
    bin_diversity_reward = 0.02 * (1 - np.std(bin_fill_levels)) # Higher std means more diversity, penalize it
    priorities[eligible_bins] += bin_diversity_reward

    # 10. Adjust priority if placing item makes this the fullest bin so far
    current_max_fill = np.max(1 - (bins_remain_cap / bin_capacity))
    future_fill_levels = 1 - ((bins_remain_cap - item)/bin_capacity)
    new_max_bin = future_fill_levels >= np.max(current_max_fill)

    priorities[new_max_bin & eligible_bins] += 0.03 # Small reward for creating max fill bin

    # 11. Scale and Clip
    priorities = np.clip(priorities, -1, 1)

    return priorities
```
