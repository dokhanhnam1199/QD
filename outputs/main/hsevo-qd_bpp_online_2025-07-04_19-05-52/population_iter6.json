[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n      # No bin can fit the item, prioritize creating a new bin. Since we cannot create bins in this problem. We'll assign lowest priority possible\n      return np.zeros_like(bins_remain_cap) - np.inf # Give a large negative number to effectively say these are impossible.\n\n    # First priority: Bins that can fit the item with minimal waste (highest fill ratio). Avoid fragmentation!\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf # Disqualify bins that can't fit.\n    priorities = fill_ratio\n\n\n    # Add a small bonus for bins that are already relatively full. This promotes utilizing bins further before opening new ones.\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Assuming bins all have same max capacity, normalize\n    priorities[eligible_bins] += 0.1 * existing_fill[eligible_bins] #Adjustable weighting factor to existing_fill bonus.\n\n\n    # Penalty for bins that have *just enough* space; Encourages more even filling\n    # Avoiding situations where next few items can *only* go in that single bin creating bottlenecks.\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap)) #Bins with nearly perfect fits\n    priorities[small_gap & eligible_bins] -= 0.05 #Adjustable penalty factor\n\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 74.23092131656186,
    "mi": 78.66680715880324,
    "token_count": 146.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, existing fullness, and gap penalty for bin selection.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.1 * existing_fill[eligible_bins]\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= 0.05\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.01874750698045,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 206.0894050155578,
    "mi": 58.52635020262376,
    "token_count": 147.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # Primary Priority: Maximize bin utilization while minimizing fragmentation.\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf  # Disqualify bins that can't fit.\n    priorities = fill_ratio\n\n    # Bonus for bins that are already well-utilized (avoid opening new bins unnecessarily).\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.15 * existing_fill[eligible_bins]  # Increased weight\n\n    # Fragmentation Penalty: Heavily penalize bins that would leave small gaps.  Make this adaptive to item size.\n    #  The smaller the average item size is, the more important it becomes to avoid small gaps.\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item #Average item size to decide penalty scaling\n\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.10 + 0.05*(avg_item_size / np.max(bins_remain_cap)) #Dynamic penalty; adjustable base\n    priorities[small_gap & eligible_bins] -= penalty_factor #Increased base penalty\n\n\n\n    # Reward near-perfect fits, but less so than perfect fills\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.02 # Small bonus for perfect fit\n\n    # Scale priorities to ensure a reasonable range\n    priorities = np.clip(priorities, -1, 1)  # Prevent extreme values\n    return priorities",
    "response_id": 4,
    "tryHS": true,
    "obj": 3.9688871160749857,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 311.8387309128727,
    "mi": 76.22242281742339,
    "token_count": 258.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                well_utilized_weight: float = 0.35062835173089724,\n                small_gap_threshold: float = 0.2843404739363855,\n                penalty_base: float = 0.06433963514511276,\n                penalty_scaling: float = 0.25541437954022345,\n                near_perfect_fit_bonus: float = 0.002922134236358265,\n                clip_lower: float = -1.6092107662972261,\n                clip_upper: float = 0.9282869875935645,\n                rtol: float = 1.4782407673254387e-05,\n                atol: float = 9.868264437581935e-06) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        well_utilized_weight: Weight for bins that are already well-utilized.\n        small_gap_threshold: Threshold for considering a gap as small (fraction of max bin cap).\n        penalty_base: Base penalty for small gaps.\n        penalty_scaling: Scaling factor for the small gap penalty based on item size.\n        near_perfect_fit_bonus: Bonus for near-perfect fits.\n        clip_lower: Lower bound for clipping priority values.\n        clip_upper: Upper bound for clipping priority values.\n        rtol: Relative tolerance for near-perfect fit comparison.\n        atol: Absolute tolerance for near-perfect fit comparison.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 24.0,
    "mi": 95.47382517661812,
    "token_count": 138.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculates priority for adding item to each bin.\n    Combines fill ratio, existing fill, gap penalty, near-perfect fit.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.15 * existing_fill[eligible_bins]\n\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    small_gap = (bins_remain_cap - item) < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.10 + 0.05 * (avg_item_size / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.02\n\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 3.9688871160749857,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 311.8387309128727,
    "mi": 54.23927513093755,
    "token_count": 232.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Enhanced priority function considering utilization, fragmentation, and future packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization (Fill Ratio)\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    # 2. Existing Fill Bonus (Encourage using partially filled bins) - Adjusted weight.\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.20 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive based on remaining capacity and item size)\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (avg_item_size / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward (Encourage near-optimal packing) - Reduced magnitude\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.01  # Smaller reward\n\n    # 5. Remaining Capacity Consideration (Prioritize bins with larger *remaining* capacity among eligible bins)\n    # This helps to keep options open for potentially larger future items.  Important!\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap))\n\n    # 6. Penalize bins that will be left with capacities that are smaller than a certain threshold (Dynamic threshold)\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)  # Bin must have at least 15% useful capacity\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    # 7. Scale and Clip\n    priorities = np.clip(priorities, -1, 1)\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.5700039888312682,
    "SLOC": 25.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 531.8850936442687,
    "mi": 76.24764014804039,
    "token_count": 337.0,
    "exec_success": true
  }
]