{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Assigns bin priorities considering utilization, fragmentation, and remaining capacity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    # 1. Utilization Maximization (fill ratio)\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = fill_ratio\n\n    # 2. Existing Fill Bonus\n    existing_fill = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * np.max(bins_remain_cap))\n    penalty_factor = 0.15 + 0.07 * (item / np.max(bins_remain_cap))\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.01\n\n    # 5. Remaining Capacity Consideration - scaled\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / np.max(bins_remain_cap))\n\n    # 6. Penalize Nearly Full Bins\n    min_useful_capacity = 0.15 * np.max(bins_remain_cap)\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.1\n\n    # 7. Adjusted Fragmentation Penalty based on Item Size\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    fragmentation_threshold = 0.5 * np.max(bins_remain_cap)  # Example dynamic threshold\n    high_fragmentation = gap_size > fragmentation_threshold\n    if high_fragmentation.any():\n        priorities[high_fragmentation & eligible_bins] -= 0.05 * (item / np.max(bins_remain_cap))\n\n    priorities = np.clip(priorities, -1, 1)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                well_utilized_weight: float = 0.9767042431939332,\n                small_gap_threshold: float = 0.7661779765338794,\n                penalty_base: float = 0.822658676260284,\n                penalty_scaling: float = 0.5774246707396835,\n                near_perfect_fit_bonus: float = 0.05102813276505112,\n                clip_lower: float = -1.6149819187450574,\n                clip_upper: float = 0.14715493303357707,\n                rtol: float = 9.771420380638054e-05,\n                atol: float = 8.874997683098374e-06,\n                min_item_size_cap_ratio: float = 1.2934804877229156) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        well_utilized_weight: Weight for bins that are already well-utilized.\n        small_gap_threshold: Threshold for considering a gap as small (fraction of max bin cap).\n        penalty_base: Base penalty for small gaps.\n        penalty_scaling: Scaling factor for the small gap penalty based on item size.\n        near_perfect_fit_bonus: Bonus for near-perfect fits.\n        clip_lower: Lower bound for clipping priority values.\n        clip_upper: Upper bound for clipping priority values.\n        rtol: Relative tolerance for near-perfect fit comparison.\n        atol: Absolute tolerance for near-perfect fit comparison.\n        min_item_size_cap_ratio:  A bin must have at least item size cap * this ratio\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item * min_item_size_cap_ratio\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first heuristic uses a multi-faceted approach considering utilization, fragmentation, and future packing, while the last one only considers the log of the fill ratio. (2nd) vs (19th) is similar. Comparing (1st) vs (2nd), we see the 1st has increased weights on utilization maximization and near-perfect fit reward and a look-ahead fragmentation penalty; Comparing (3rd) vs (4th), we see (3rd) has the same logic, just a smaller reward for near-perfect fit. Comparing (2nd) vs (3rd), we observe the existing fill bonus weight and near-perfect fit reward are higher in (2nd). (14th) vs (13th), we see that (14th) adds a whole host of parameters and constraints, but doesn't actually implement the core logic, making it less effective. (17th) vs (16th) is similar. Comparing (second worst) vs (worst), we see second worst one lacks necessary logic. Overall: The better heuristics incorporate a combination of factors, use adaptive parameters, and scale and clip the final priorities. Simpler heuristics focusing solely on fill ratio tend to perform poorly. Over-parameterization without core logic is also ineffective.\n- \nOkay, I'm ready to refine \"Current Self-Reflection\" to design better heuristics, keeping in mind the pitfalls of \"Ineffective Self-Reflection\". Let's aim for actionable advice, focusing on structured improvement and avoiding premature complexity.\n\nHere's a redefined approach to self-reflection:\n\n*   **Keywords:** Incremental, Empirical, Contextual, Validation.\n*   **Advice:** Build heuristics iteratively, validating each addition empirically. Consider the problem's context to guide feature selection.\n*   **Avoid:** Over-parameterization early on. Blindly adding features without understanding their impact.\n*   **Explanation:** Prioritize a clear understanding of the heuristic's behavior at each step. Start with a basic solution and only add complexity if proven necessary through careful testing and observation. Focus on data-driven decisions for feature engineering and parameter tuning.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}