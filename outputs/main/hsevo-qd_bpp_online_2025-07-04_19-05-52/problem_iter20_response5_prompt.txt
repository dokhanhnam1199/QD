{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Improved priority function focusing on reducing fragmentation and maximizing bin utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n    bin_capacity = np.max(bins_remain_cap)\n\n    # 1. Fill Ratio Maximization (Aggressive)\n    fill_ratio = item / bins_remain_cap\n    fill_ratio[~eligible_bins] = -np.inf\n    priorities = 1.5 * fill_ratio  # Increased fill ratio importance.\n\n    # 2. Encourage existing fill (but less aggressively than fill ratio).\n    existing_fill = 1 - (bins_remain_cap / bin_capacity)\n    priorities[eligible_bins] += 0.2 * existing_fill[eligible_bins]\n\n    # 3. Fragmentation Penalty (Adaptive and more sensitive)\n    gap_size = bins_remain_cap - item\n    small_gap = gap_size < (0.2 * bin_capacity)\n    avg_item_size = np.mean(item) if isinstance(item, np.ndarray) else item\n    penalty_factor = 0.2 + 0.1 * (avg_item_size / bin_capacity)  # Increased base penalty.\n    priorities[small_gap & eligible_bins] -= penalty_factor\n\n    # 4. Near-Perfect Fit Reward (More significant reward)\n    near_perfect_fit = np.isclose(bins_remain_cap, item, rtol=1e-05, atol=1e-06)\n    priorities[near_perfect_fit & eligible_bins] += 0.05\n\n    # 5. Prioritize larger remaining capacity (slightly adjusted weight)\n    priorities[eligible_bins] += 0.05 * (bins_remain_cap[eligible_bins] / bin_capacity)\n\n    # 6. Significant penalty for bins that become nearly full, with dynamic threshold\n    min_useful_capacity = 0.15 * bin_capacity\n    nearly_full = gap_size < min_useful_capacity\n    priorities[nearly_full & eligible_bins] -= 0.15  # Increased penalty\n\n    # 7. Look-Ahead Fragmentation Penalty (Relative to smallest item) - Enhanced penalty.\n    min_item_size = np.min(item) if isinstance(item, np.ndarray) else item\n    if min_item_size > 0:\n        very_small_gap = gap_size < (0.4 * min_item_size)  # Reduced threshold\n        priorities[very_small_gap & eligible_bins] -= 0.2  # Increased penalty\n\n    # 8. Reward bins close to half-full (Balance utilization with future flexibility)\n    half_full_range_lower = 0.4 * bin_capacity\n    half_full_range_upper = 0.6 * bin_capacity\n\n    close_to_half = (bins_remain_cap >= (item + half_full_range_lower)) & (bins_remain_cap <= (item + half_full_range_upper))\n    priorities[close_to_half & eligible_bins] += 0.08  # Moderate reward\n\n    # New Heuristics\n\n    # 9. Bin Utilization Variance Penalty\n    bin_utilization = 1 - (bins_remain_cap / bin_capacity)\n    mean_utilization = np.mean(bin_utilization)\n    utilization_variance = np.abs(bin_utilization - mean_utilization)\n    priorities[eligible_bins] -= 0.03 * utilization_variance[eligible_bins]  # Penalize bins that deviate from average utilization\n\n    # 10. Dynamic Gap Penalty Scaling\n    gap_ratio = gap_size / bin_capacity\n    dynamic_gap_penalty = np.where(gap_ratio < 0.2, 0.15 * (0.2 - gap_ratio), 0)\n    priorities[eligible_bins] -= dynamic_gap_penalty[eligible_bins]\n\n    # 11. Reward for creating bins that can fit a specific \"common size\".\n    common_size = 0.25 * bin_capacity  # Example common size\n    room_for_common = gap_size >= common_size\n    priorities[room_for_common & eligible_bins] += 0.06\n\n    # 12. Scale and Clip\n    priorities = np.clip(priorities, -1, 1)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                well_utilized_weight: float = 0.9767042431939332,\n                small_gap_threshold: float = 0.7661779765338794,\n                penalty_base: float = 0.822658676260284,\n                penalty_scaling: float = 0.5774246707396835,\n                near_perfect_fit_bonus: float = 0.05102813276505112,\n                clip_lower: float = -1.6149819187450574,\n                clip_upper: float = 0.14715493303357707,\n                rtol: float = 9.771420380638054e-05,\n                atol: float = 8.874997683098374e-06,\n                min_item_size_cap_ratio: float = 1.2934804877229156) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        well_utilized_weight: Weight for bins that are already well-utilized.\n        small_gap_threshold: Threshold for considering a gap as small (fraction of max bin cap).\n        penalty_base: Base penalty for small gaps.\n        penalty_scaling: Scaling factor for the small gap penalty based on item size.\n        near_perfect_fit_bonus: Bonus for near-perfect fits.\n        clip_lower: Lower bound for clipping priority values.\n        clip_upper: Upper bound for clipping priority values.\n        rtol: Relative tolerance for near-perfect fit comparison.\n        atol: Absolute tolerance for near-perfect fit comparison.\n        min_item_size_cap_ratio:  A bin must have at least item size cap * this ratio\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin must have at least item size capacity\n    eligible_bins = bins_remain_cap >= item * min_item_size_cap_ratio\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item, prioritize creating a new bin if possible.  Since not possible assign lowest priority.\n        return np.zeros_like(bins_remain_cap) - np.inf\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first heuristic incorporates a much more complex, multi-faceted approach, considering fill ratio, existing fill, fragmentation penalty, near-perfect fit reward, remaining capacity, nearly full bin penalty, look-ahead fragmentation penalty, and half-full bin reward, bin utilization variance penalty, dynamic gap penalty scaling, reward for creating bins with specific common size, and a final scaling/clipping step. The last heuristic uses a simple log ratio calculation.\nComparing (2nd) vs (19th), the second heuristic uses a weighted combination of fill ratio, existing fill bonus, and fragmentation penalty. The 19th heuristic uses a simple log ratio calculation.\nComparing (1st) vs (2nd), we see that the first heuristic has new heuristics like 9. Bin Utilization Variance Penalty, 10. Dynamic Gap Penalty Scaling, 11. Reward for creating bins that can fit a specific \"common size\", and 12. Scale and Clip and uses more aggressive weights than the second.\nComparing (3rd) vs (4th), we see the 3rd and 4th are nearly identical; they differ only in comments.\nComparing (second worst) vs (worst), we see 19th and 20th are nearly identical; both are the same function. Overall: Better heuristics employ multiple factors including fill ratio, fragmentation, remaining capacity, and look-ahead considerations, combining them with carefully tuned weights and adaptive penalties/rewards. They often incorporate scaling/clipping to maintain stability and prevent extreme priority values. Simpler heuristics rely on one or two factors.\n- \nOkay, I'll help you redefine \"Current self-reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective self-reflection.\" Here's a refined approach:\n\n*   **Keywords:** Iterative refinement, problem constraints, performance-driven, simplification.\n\n*   **Advice:** Begin with a simple heuristic that directly addresses core constraints. Iteratively improve by incorporating relevant factors guided by performance analysis.\n\n*   **Avoid:** Premature complexity, over-parameterization without justification, neglecting core problem constraints.\n\n*   **Explanation:** Prioritize a functional baseline and build upon it using data-driven insights. Focus on addressing the core problem before adding complexity, and only add complexity where there is a demonstrated performance improvement.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}