{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines a refined best-fit metric that penalizes both extreme remaining capacities\n    with a dynamic weighting strategy that adapts to item size relative to bin availability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    \n    # Metric 1: Refined Best Fit (using log of inverse residual)\n    # Penalizes bins that are too full (small residual) or too empty (large residual) after placement.\n    remaining_after_placement = suitable_bins_caps - item\n    # Use log1p of the inverse of remaining capacity + epsilon. Higher score for residuals closer to 0.\n    # Adding 1 to the denominator ensures that even for perfect fits (residual=0), we don't get division by zero.\n    # A small epsilon is added to the denominator to prevent division by zero if remaining_after_placement is 0.\n    best_fit_scores = np.log1p(1.0 / (remaining_after_placement + 1e-6))\n\n    # Metric 2: Exploration/Spread (using log of current remaining capacity)\n    # Favors bins with larger initial remaining capacities, promoting spreading items.\n    # Use log1p of remaining capacity. Higher score for larger remaining capacities.\n    exploration_scores = np.log1p(suitable_bins_caps)\n\n    # Normalize scores to be in a comparable range [0, 1] for combining.\n    # Avoid division by zero if all scores for a metric are zero.\n    max_best_fit = np.max(best_fit_scores)\n    normalized_best_fit = best_fit_scores / max_best_fit if max_best_fit > 1e-6 else np.zeros_like(best_fit_scores)\n\n    max_exploration = np.max(exploration_scores)\n    normalized_exploration = exploration_scores / max_exploration if max_exploration > 1e-6 else np.zeros_like(exploration_scores)\n\n    # Dynamic Weighting: Adjust weights based on item size relative to the maximum remaining capacity of suitable bins.\n    # This aims to balance \"best fit\" for larger items with \"exploration\" for smaller items.\n    max_suitable_cap = np.max(suitable_bins_caps)\n    relative_item_size = item / (max_suitable_cap + 1e-6)\n\n    # Weight for Best Fit: Higher for larger items, lower for smaller items.\n    # This ensures that for large items, we prioritize a tight fit.\n    weight_best_fit = 0.5 + 0.4 * relative_item_size\n    weight_best_fit = np.clip(weight_best_fit, 0.5, 0.9)\n\n    # Weight for Exploration: Lower for larger items, higher for smaller items.\n    # This encourages spreading smaller items into less utilized bins.\n    weight_exploration = 0.5 - 0.4 * relative_item_size\n    weight_exploration = np.clip(weight_exploration, 0.1, 0.5)\n\n    # Ensure weights sum to 1\n    total_weight = weight_best_fit + weight_exploration\n    if total_weight < 1e-6:\n        total_weight = 1.0\n    \n    weight_best_fit /= total_weight\n    weight_exploration /= total_weight\n\n    combined_scores = (weight_best_fit * normalized_best_fit +\n                       weight_exploration * normalized_exploration)\n\n    priorities[suitable_bins_mask] = combined_scores\n\n    return priorities\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}