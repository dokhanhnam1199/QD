{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins using a combination of inverse difference and remaining capacity.\n\n    This heuristic combines the \"best fit\" aspect of inverse difference with a\n    penalty for bins with excessively large remaining capacity, promoting tighter fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins_mask = bins_remain_cap >= item\n    \n    if np.any(valid_bins_mask):\n        valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        differences = valid_bins_remain_cap - item\n        \n        # Inverse difference for best fit, scaled by inverse of remaining capacity to penalize large gaps\n        # Adding a small epsilon to the denominator to prevent division by zero\n        scaled_inverse_differences = 1.0 / (differences + 1e-9) / (valid_bins_remain_cap + 1e-9)\n        \n        priorities[valid_bins_mask] = scaled_inverse_differences\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the 'tight fit' prioritization of inverse difference with a sigmoid\n    function to normalize priorities, favoring bins that are a near-perfect fit\n    while maintaining a reasonable range.\n\n    Args:\n        item (float): The item size to fit.\n        bins_remain_cap (np.ndarray): A numpy array representing the remaining capacity of each bin.\n        epsilon (float): A small value added to the denominator to prevent division by zero.\n        sigmoid_k (float): The steepness parameter for the sigmoid function.\n        sigmoid_center_offset (float): The offset to center the sigmoid curve.\n\n    Returns:\n        np.ndarray: An array of priorities for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(valid_bins_mask):\n        return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1 and 6 (identical): Heuristic 1 uses a combination of inverse difference and inverse remaining capacity, aiming for tight fits and penalizing large gaps. Heuristic 6 is identical.\n\nComparing Heuristics 2 and 10: Heuristic 2 scales the inverse difference by the inverse of remaining capacity, penalizing large gaps. Heuristic 10 uses a sigmoid on the fit ratio and normalizes the inverse remaining capacity, then combines them. Heuristic 2 is simpler and likely less prone to issues with parameter tuning that affect Heuristic 10's performance.\n\nComparing Heuristics 3 and 17/18 (identical): Heuristic 3 uses an inverse difference and then normalizes it with a sigmoid, aiming for a normalized priority range. Heuristics 17 and 18 are identical to Heuristic 3 but include additional parameters for sigmoid control, potentially offering more fine-tuning but increasing complexity.\n\nComparing Heuristics 4 and 5: Heuristic 4 combines Best Fit with a sigmoid penalty for large remaining capacities, using multiplication for combination. Heuristic 5 uses a composite score involving inverse remaining capacity and a fill ratio, aiming for tighter fits and better utilization. Heuristic 5's approach of combining metrics in a weighted manner seems more robust than Heuristic 4's multiplication which can lead to zero scores.\n\nComparing Heuristics 7, 8 (identical) and 11, 12, 15, 16 (identical): These heuristics combine \"Best Fit\" with an exploration bonus for less full bins using an epsilon-greedy approach. They prioritize tight fits but also explore less full bins. The difference lies in how the exploration bonus is calculated: Heuristics 7/8 use a raw difference from the average, while 11/12/15/16 use min-max scaling for normalization, potentially offering better control.\n\nComparing Heuristics 9 and 13 (identical): Identical to 7/8, using an epsilon-greedy approach with mean-based exploration bonus.\n\nComparing Heuristics 14 and 15/16: These are similar to 7/8 but use min-max scaling for the exploration bonus, which is generally more robust than using the mean.\n\nComparing Heuristics 19 and 20 (identical): These heuristics combine Best Fit with scores for original capacity and a fullness penalty, then normalize. This multi-component approach aims for a balanced solution.\n\nOverall: Heuristics that combine multiple criteria (like Best Fit with utilization or exploration) tend to be more sophisticated. Simple inverse relationships are a good baseline. Methods involving sigmoid normalization offer controlled ranges but introduce complexity. Exploration strategies (epsilon-greedy) add robustness. Heuristics 19/20 offer a well-rounded approach by combining several factors and normalizing.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Performance, Robustness, Exploration, Nuance.\n*   **Advice:** Focus on how current metrics reflect problem dynamics and adapt exploration based on observed search progress.\n*   **Avoid:** Over-reliance on static metrics or single-purpose exploration without considering their interaction.\n*   **Explanation:** True self-reflection involves understanding *why* a metric or exploration strategy works (or doesn't) in relation to the problem's inherent complexity, leading to more sophisticated, adaptive heuristic design.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}