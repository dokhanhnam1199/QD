{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Sigmoid Fit Score strategy.\n\n    The priority is higher for bins that have just enough remaining capacity to fit the item.\n    This encourages fuller bins and potentially fewer overall bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    available_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(available_bins_mask):\n        valid_capacities = bins_remain_cap[available_bins_mask]\n        \n        # Calculate the \"fit score\" - how close the remaining capacity is to the item size.\n        # We want a high score when remaining_capacity is just slightly larger than item.\n        # A good proxy is item / remaining_capacity for available bins.\n        # If remaining_capacity is exactly item, this is 1. If much larger, it's close to 0.\n        fit_scores = item / valid_capacities\n\n        # Apply sigmoid to compress the fit scores into a [0, 1] range.\n        # We can use a scaling factor to tune the steepness of the sigmoid.\n        # A higher scaling factor makes the sigmoid steeper, more sensitive to small differences.\n        # We can also add an offset to shift the sigmoid, but for this problem, a simple sigmoid is sufficient.\n        scaling_factor = 5.0  # Tunable parameter\n        sigmoided_scores = 1 / (1 + np.exp(-scaling_factor * (fit_scores - 0.8))) # Centered around a fit score of 0.8\n\n        priorities[available_bins_mask] = sigmoided_scores\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    available_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(available_bins):\n        available_caps = bins_remain_cap[available_bins]\n        diff = available_caps - item\n        \n        # Sigmoid function to map differences to priorities\n        # We want smaller differences to have higher priority\n        # A larger negative number results in a sigmoid closer to 1\n        # Adding a small constant to avoid division by zero or very large negative numbers\n        adjusted_diff = - (diff + 1e-9) / (np.max(diff) - np.min(diff) + 1e-9)\n        \n        # Using a scaled sigmoid where the steepness is controlled\n        steepness = 5.0 # Controls how sharply the priority drops as difference increases\n        scaled_sigmoid_input = steepness * adjusted_diff\n        \n        # Apply sigmoid\n        priorities[available_bins] = 1 / (1 + np.exp(-scaled_sigmoid_input))\n        \n        # Normalize priorities to be between 0 and 1 (though sigmoid already does this)\n        # This step is more for conceptual clarity or if other scaling were involved\n        if np.max(priorities[available_bins]) > 0:\n            priorities[available_bins] /= np.max(priorities[available_bins])\n        \n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Sigmoid Fit Score strategy.\n\n    The priority is higher for bins that have just enough remaining capacity to fit the item.\n    This encourages fuller bins and potentially fewer overall bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    available_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(available_bins_mask):\n        valid_capacities = bins_remain_cap[available_bins_mask]\n        \n        # Calculate the \"fit score\" - how close the remaining capacity is to the item size.\n        # We want a high score when remaining_capacity is just slightly larger than item.\n        # A good proxy is item / remaining_capacity for available bins.\n        # If remaining_capacity is exactly item, this is 1. If much larger, it's close to 0.\n        fit_scores = item / valid_capacities\n\n        # Apply sigmoid to compress the fit scores into a [0, 1] range.\n        # We can use a scaling factor to tune the steepness of the sigmoid.\n        # A higher scaling factor makes the sigmoid steeper, more sensitive to small differences.\n        # We can also add an offset to shift the sigmoid, but for this problem, a simple sigmoid is sufficient.\n        scaling_factor = 5.0  # Tunable parameter\n        sigmoided_scores = 1 / (1 + np.exp(-scaling_factor * (fit_scores - 0.8))) # Centered around a fit score of 0.8\n\n        priorities[available_bins_mask] = sigmoided_scores\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Inverse Distance (Proximity Fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins_mask = bins_remain_cap >= item\n    \n    if np.any(valid_bins_mask):\n        valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        differences = valid_bins_remain_cap - item\n        \n        inverse_distances = 1.0 / (differences + 1e-9)\n        \n        priorities[valid_bins_mask] = inverse_distances\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Epsilon-Greedy priority for online Bin Packing Problem.\n\n    This priority function aims to balance exploration (trying less full bins)\n    and exploitation (using bins that are a good fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    suitable_bins = bins_remain_cap >= item\n    \n    if np.any(suitable_bins):\n        \n        best_fit_score = 1 / (bins_remain_cap[suitable_bins] - item + 1e-9) \n        \n        \n        avg_remaining_capacity = np.mean(bins_remain_cap[suitable_bins])\n        exploration_bonus = np.zeros_like(bins_remain_cap)\n        exploration_bonus[suitable_bins] = np.maximum(0, avg_remaining_capacity - bins_remain_cap[suitable_bins]) * epsilon\n\n        \n        priorities[suitable_bins] = best_fit_score + exploration_bonus[suitable_bins]\n    else:\n        \n        priorities = np.ones_like(bins_remain_cap) * -np.inf \n        \n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Epsilon-Greedy priority for online Bin Packing Problem.\n\n    This priority function aims to balance exploration (trying less full bins)\n    and exploitation (using bins that are a good fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    suitable_bins = bins_remain_cap >= item\n    \n    if np.any(suitable_bins):\n        \n        best_fit_score = 1 / (bins_remain_cap[suitable_bins] - item + 1e-9) \n        \n        \n        avg_remaining_capacity = np.mean(bins_remain_cap[suitable_bins])\n        exploration_bonus = np.zeros_like(bins_remain_cap)\n        exploration_bonus[suitable_bins] = np.maximum(0, avg_remaining_capacity - bins_remain_cap[suitable_bins]) * epsilon\n\n        \n        priorities[suitable_bins] = best_fit_score + exploration_bonus[suitable_bins]\n    else:\n        \n        priorities = np.ones_like(bins_remain_cap) * -np.inf \n        \n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Epsilon-Greedy priority for online Bin Packing Problem.\n\n    This priority function aims to balance exploration (trying less full bins)\n    and exploitation (using bins that are a good fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    suitable_bins = bins_remain_cap >= item\n    \n    if np.any(suitable_bins):\n        \n        best_fit_score = 1 / (bins_remain_cap[suitable_bins] - item + 1e-9) \n        \n        \n        avg_remaining_capacity = np.mean(bins_remain_cap[suitable_bins])\n        exploration_bonus = np.zeros_like(bins_remain_cap)\n        exploration_bonus[suitable_bins] = np.maximum(0, avg_remaining_capacity - bins_remain_cap[suitable_bins]) * epsilon\n\n        \n        priorities[suitable_bins] = best_fit_score + exploration_bonus[suitable_bins]\n    else:\n        \n        priorities = np.ones_like(bins_remain_cap) * -np.inf \n        \n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap >= item:\n            priorities[i] = 1.0 / (remaining_cap - item + 1e-9)\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Prioritize bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Heuristic: Prioritize bins with least remaining capacity that can still fit the item\n    # This is a \"best fit\" approach.\n    fitting_bins_capacity = bins_remain_cap[can_fit_mask]\n    if fitting_bins_capacity.size > 0:\n        # Calculate the \"waste\" if the item is placed in these bins\n        waste = fitting_bins_capacity - item\n        # Higher priority for bins with less waste (i.e., tighter fit)\n        # We invert the waste because we want the smallest waste to have the highest priority\n        # Add a small epsilon to avoid division by zero or very large negative numbers if waste is 0\n        priorities[can_fit_mask] = 1.0 / (waste + 1e-9)\n    \n    # A small random component can be added for exploration (epsilon-greedy like behavior)\n    # For simplicity in this priority function, we are directly implementing the greedy part.\n    # The epsilon-greedy strategy would then decide whether to pick the best fit (greedy)\n    # or a random bin. This priority function is solely for the greedy selection.\n    \n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Prioritize bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Heuristic: Prioritize bins with least remaining capacity that can still fit the item\n    # This is a \"best fit\" approach.\n    fitting_bins_capacity = bins_remain_cap[can_fit_mask]\n    if fitting_bins_capacity.size > 0:\n        # Calculate the \"waste\" if the item is placed in these bins\n        waste = fitting_bins_capacity - item\n        # Higher priority for bins with less waste (i.e., tighter fit)\n        # We invert the waste because we want the smallest waste to have the highest priority\n        # Add a small epsilon to avoid division by zero or very large negative numbers if waste is 0\n        priorities[can_fit_mask] = 1.0 / (waste + 1e-9)\n    \n    # A small random component can be added for exploration (epsilon-greedy like behavior)\n    # For simplicity in this priority function, we are directly implementing the greedy part.\n    # The epsilon-greedy strategy would then decide whether to pick the best fit (greedy)\n    # or a random bin. This priority function is solely for the greedy selection.\n    \n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    if not np.any(valid_bins_mask):\n        return priorities\n        \n    available_capacities = bins_remain_cap[valid_bins_mask]\n    \n    gaps = available_capacities - item\n    \n    priorities[valid_bins_mask] = -gaps / available_capacities\n    \n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item\n    potential_remaining_cap = bins_remain_cap - item\n\n    # Filter out bins where the item cannot fit\n    valid_bins_mask = potential_remaining_cap >= 0\n    valid_potential_remaining_cap = potential_remaining_cap[valid_bins_mask]\n\n    # If no bins can accommodate the item, return zeros\n    if valid_potential_remaining_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate the 'goodness' of fit. We want to minimize remaining capacity.\n    # A smaller remaining capacity is better, hence we use -valid_potential_remaining_cap.\n    # The sigmoid function squashes the values between 0 and 1.\n    # A higher value means a better fit (less remaining capacity).\n    # We'll use a scaling factor to control the steepness of the sigmoid.\n    # A larger scaling factor means the sigmoid is steeper, making the \"best fit\" more pronounced.\n    # Let's choose a scaling factor that encourages placing items in bins that are nearly full.\n    scaling_factor = 2.0\n    fit_scores = 1 / (1 + np.exp(-scaling_factor * (-valid_potential_remaining_cap)))\n\n    # Initialize priorities with zeros for all bins\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Assign the calculated fit scores to the valid bins\n    priorities[valid_bins_mask] = fit_scores\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = cap - item\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n        else:\n            priorities[i] = -1\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = capacity - item\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    fit_ratios = np.clip(bins_remain_cap - item, 0, None)\n    soft_max_priorities = np.exp(fit_ratios)\n    return soft_max_priorities / np.sum(soft_max_priorities)\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}