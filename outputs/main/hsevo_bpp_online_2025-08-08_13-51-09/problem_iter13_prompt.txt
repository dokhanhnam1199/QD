{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a normalized bonus for larger remaining capacity,\n    using a weighted sum for balanced decision-making. Favors bins that are\n    almost full but can still accommodate the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    \n    # Metric 1: Best Fit - prioritize bins with minimal remaining capacity after placement.\n    # Higher score for smaller residual space.\n    remaining_after_placement = suitable_bins_caps - item\n    # Inverse relationship: smaller residual -> higher score. Add epsilon for stability.\n    best_fit_scores = 1.0 / (remaining_after_placement + 1e-9)\n    \n    # Metric 2: Exploration/Larger Bin Preference - favor bins with more capacity initially.\n    # This encourages not always picking the absolute tightest, promoting diversification.\n    # We'll use a logarithmic scale for remaining capacity to de-emphasize very large bins\n    # and focus on bins that are \"reasonably\" large but not excessively so.\n    # log1p is used to handle cases where remaining capacity is 0 after placement,\n    # and to provide a smoother scaling than a simple linear approach.\n    exploration_scores = np.log1p(suitable_bins_caps)\n    \n    # Normalize Best Fit scores (min-max scaling)\n    if suitable_bins_caps.size > 1:\n        min_bf = np.min(best_fit_scores)\n        max_bf = np.max(best_fit_scores)\n        range_bf = max_bf - min_bf\n        if range_bf > 1e-9:\n            normalized_best_fit = (best_fit_scores - min_bf) / range_bf\n        else:\n            normalized_best_fit = np.ones_like(best_fit_scores) # All suitable bins offer same tightness score\n    elif suitable_bins_caps.size == 1:\n        normalized_best_fit = np.array([1.0])\n    else:\n        normalized_best_fit = np.zeros_like(best_fit_scores)\n\n    # Normalize Exploration scores (min-max scaling)\n    if suitable_bins_caps.size > 1:\n        min_exp = np.min(exploration_scores)\n        max_exp = np.max(exploration_scores)\n        range_exp = max_exp - min_exp\n        if range_exp > 1e-9:\n            normalized_exploration = (exploration_scores - min_exp) / range_exp\n        else:\n            normalized_exploration = np.zeros_like(exploration_scores) # All suitable bins have same initial capacity\n    elif suitable_bins_caps.size == 1:\n        normalized_exploration = np.array([1.0]) # If only one bin, it's maximally \"exploratory\" in this context\n    else:\n        normalized_exploration = np.zeros_like(exploration_scores)\n\n    # Combine normalized scores using a weighted sum.\n    # We give a slightly higher weight to Best Fit, as tight packing is crucial for BPP.\n    # The exploration bonus helps to prevent premature fragmentation.\n    combined_scores = 0.7 * normalized_best_fit + 0.3 * normalized_exploration\n    \n    priorities[suitable_bins_mask] = combined_scores\n    \n    return priorities\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}