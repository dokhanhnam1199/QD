{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n\n    # Metric 1: Best Fit - score based on how tightly the item fits\n    # Using log to compress larger gaps, making smaller gaps relatively more important\n    remaining_after_placement = suitable_bins_caps - item\n    # Add a small epsilon to avoid log(0) and to differentiate very tight fits\n    best_fit_scores = np.log1p(1.0 / (remaining_after_placement + 1e-6))\n\n    # Metric 2: Exploration Bonus - score based on the \"openness\" of the bin\n    # Favor bins that have a significant amount of remaining capacity, but not excessively so.\n    # This is a sigmoid-like approach to reward moderately open bins.\n    # Normalize capacity to a 0-1 range based on the maximum possible capacity (assumed to be large, e.g., 100 for typical bin packing)\n    # or based on the max capacity among suitable bins if that's more contextually relevant.\n    # Let's use max of suitable bins as it's adaptive.\n    max_suitable_cap = np.max(suitable_bins_caps)\n    if max_suitable_cap > 1e-6:\n        normalized_suitable_caps = suitable_bins_caps / max_suitable_cap\n        # Sigmoid-like function to reward bins that are not too empty, not too full.\n        # Parameters can be tuned. Here, we aim to reward bins with roughly 50-75% remaining capacity.\n        # Example: exp(-(x-0.6)^2) where x is normalized_suitable_caps\n        exploration_scores = np.exp(-((normalized_suitable_caps - 0.6)**2) / 0.2)\n    else:\n        exploration_scores = np.zeros_like(suitable_bins_caps)\n\n    # Metric 3: Uniformity Bonus - Reward bins that are already partially filled,\n    # aiming to create more uniformly filled bins overall.\n    # This is inversely related to how \"empty\" the bin is.\n    # We can score based on how much has *already* been placed in the bin.\n    # Let's estimate initial fill based on remaining capacity relative to a hypothetical 'full' capacity.\n    # For simplicity, assume max bin capacity is 1.0, or use a value derived from data.\n    # Here, we'll use remaining capacity relative to the *item's* size to penalize bins that are *almost* empty\n    # and would be significantly \"wasted\" by a small item.\n    # More generally, consider the ratio of remaining capacity to the item size.\n    # A higher ratio means the item is small relative to the bin's open space.\n    # We want to prioritize bins where the item represents a larger fraction of the remaining space,\n    # which is counter to simple exploration.\n    # Let's reframe: reward bins that have *some* capacity already used.\n    # We can proxy this by 1 - normalized_suitable_caps, then apply a similar sigmoid.\n    # However, a simpler approach is to reward bins that are not \"too empty\".\n    # Let's use the inverse of normalized_suitable_caps, scaled to avoid large values.\n    # Consider `1 - normalized_suitable_caps` as a measure of \"fill level\".\n    # We want to slightly penalize very low fill levels.\n    fill_level = 1.0 - normalized_suitable_caps\n    # Add a small penalty for bins that are very empty (i.e., fill_level is close to 0)\n    # Using a power function to make the penalty more pronounced for emptier bins.\n    uniformity_scores = np.where(fill_level < 0.3, fill_level * 5, fill_level) # Penalize very empty bins more\n    uniformity_scores = np.clip(uniformity_scores, 0, 1) # Clip to 0-1 range\n\n\n    # Normalize scores to be in a comparable range [0, 1]\n    if np.max(best_fit_scores) > 1e-6:\n        normalized_best_fit = best_fit_scores / np.max(best_fit_scores)\n    else:\n        normalized_best_fit = np.zeros_like(best_fit_scores)\n\n    if np.max(exploration_scores) > 1e-6:\n        normalized_exploration = exploration_scores / np.max(exploration_scores)\n    else:\n        normalized_exploration = np.zeros_like(exploration_scores)\n\n    if np.max(uniformity_scores) > 1e-6:\n        normalized_uniformity = uniformity_scores / np.max(uniformity_scores)\n    else:\n        normalized_uniformity = np.zeros_like(uniformity_scores)\n\n\n    # Combine scores with dynamic weights.\n    # The weights can be adjusted based on the item size relative to the bin capacity.\n    # If the item is large, prioritize \"best fit\". If the item is small, prioritize \"exploration\" and \"uniformity\".\n\n    # Example dynamic weighting:\n    # For smaller items, give more weight to exploration and uniformity.\n    # For larger items, give more weight to best fit.\n    # Let's define a threshold for \"small\" item, e.g., item size < 0.5 * max_bin_capacity. Assume max_bin_capacity = 1.0 for normalization.\n    item_size_normalized = item # assuming item is already normalized or scaled appropriately\n\n    weight_best_fit = 0.5 + 0.4 * item_size_normalized # weight increases with item size\n    weight_exploration = 0.3 - 0.2 * item_size_normalized # weight decreases with item size\n    weight_uniformity = 0.2 - 0.1 * item_size_normalized # weight decreases with item size\n\n    # Ensure weights sum to 1 (or handle normalization if not exactly 1)\n    total_weight = weight_best_fit + weight_exploration + weight_uniformity\n    weight_best_fit /= total_weight\n    weight_exploration /= total_weight\n    weight_uniformity /= total_weight\n\n\n    combined_scores = (weight_best_fit * normalized_best_fit +\n                       weight_exploration * normalized_exploration +\n                       weight_uniformity * normalized_uniformity)\n\n    priorities[suitable_bins_mask] = combined_scores\n\n    return priorities\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}