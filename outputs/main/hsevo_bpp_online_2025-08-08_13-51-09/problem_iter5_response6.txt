```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with a scaled exploration bonus for less utilized bins,
    promoting both tight fits and exploring under-filled bins.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    valid_bins_mask = bins_remain_cap >= item

    if not np.any(valid_bins_mask):
        return priorities

    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]
    
    # Best Fit component: Inverse difference
    differences = valid_bins_remain_cap - item
    best_fit_scores = 1.0 / (differences + 1e-9)

    # Exploration component: Reward less utilized bins (higher original capacity)
    # We'll use min-max scaling on the *original* capacities of valid bins
    # to create an exploration bonus. Assuming bins_remain_cap is derived from
    # an initial bin capacity, we need to infer or have access to original capacities.
    # For this example, let's assume initial capacity is related to remaining capacity
    # before any items were placed, or we can infer it. A simple proxy is to assume
    # bins with larger remaining capacity *might* have had larger original capacity.
    # A more robust implementation would pass initial bin capacities.
    # Let's simulate inferring original capacity by assuming a maximum possible capacity
    # or a distribution if not provided. For simplicity, we'll use a proxy for
    # original capacity: if we don't have it, we can use remaining capacity as a weak proxy
    # or assume a default large capacity for all bins initially.
    # A better approach: assume bins_remain_cap is from a fixed initial capacity C.
    # Then original_capacity = C - (total_item_size_in_bin). This is complex for online.
    # Let's simplify: Prioritize bins that are NOT too full.
    # Higher remaining capacity means less utilized. Let's reward that.

    # Using remaining capacity itself as a proxy for "less utilized"
    # Scale remaining capacity to give a bonus. Min-max scale it.
    min_rem_cap = np.min(valid_bins_remain_cap)
    max_rem_cap = np.max(valid_bins_remain_cap)
    
    if max_rem_cap - min_rem_cap > 1e-9:
        exploration_bonus = (valid_bins_remain_cap - min_rem_cap) / (max_rem_cap - min_rem_cap)
    else:
        exploration_bonus = np.zeros_like(valid_bins_remain_cap)


    # Combine Best Fit and Exploration: weighted sum
    # Weights can be tuned. Let's give slightly more weight to Best Fit.
    w_best_fit = 0.7
    w_exploration = 0.3

    combined_scores = w_best_fit * best_fit_scores + w_exploration * exploration_bonus
    
    priorities[valid_bins_mask] = combined_scores

    return priorities
```
