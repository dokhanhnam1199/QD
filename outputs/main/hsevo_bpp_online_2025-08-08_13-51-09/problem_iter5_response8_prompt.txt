{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with an exploration bonus for less full bins.\n\n    Prioritizes bins that offer a tight fit (small remaining capacity) but\n    also encourages exploring bins with more empty space to avoid premature\n    bin exhaustion.\n    \"\"\"\n    epsilon = 0.1\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if np.any(suitable_bins_mask):\n        suitable_bins_cap = bins_remain_cap[suitable_bins_mask]\n\n        # Best Fit component: prioritize bins with minimal remaining capacity after fit\n        # Add a small constant to avoid division by zero.\n        best_fit_score = 1.0 / (suitable_bins_cap - item + 1e-9)\n\n        # Exploration component: bonus for bins with larger remaining capacity\n        # Normalize the bonus to prevent it from dominating the best fit score.\n        # Using min-max scaling on the remaining capacities of suitable bins.\n        if suitable_bins_cap.size > 1:\n            min_cap = np.min(suitable_bins_cap)\n            max_cap = np.max(suitable_bins_cap)\n            normalized_remaining_cap = (suitable_bins_cap - min_cap) / (max_cap - min_cap + 1e-9)\n            exploration_bonus = epsilon * normalized_remaining_cap\n        else:\n            # If only one suitable bin, no exploration bonus needed relative to others\n            exploration_bonus = np.zeros_like(suitable_bins_cap)\n\n        # Combine scores\n        priorities[suitable_bins_mask] = best_fit_score + exploration_bonus\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Filter bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    # Calculate potential remaining capacity if item is placed\n    potential_remaining_cap = bins_remain_cap[suitable_bins_mask] - item\n    \n    # Heuristic 1: Prioritize bins with the smallest remaining capacity after placement (Best Fit)\n    # Lower remaining capacity means a tighter fit. We want to prioritize these.\n    # We invert the remaining capacity to get a higher score for smaller remaining capacity.\n    # Add a small epsilon to avoid division by zero if remaining capacity is 0.\n    best_fit_score = 1.0 / (potential_remaining_cap + 1e-9)\n    \n    # Heuristic 2: Consider the original remaining capacity for diversification.\n    # Bins with larger original remaining capacity might offer more flexibility for future items.\n    # We use a logarithmic scale to dampen the effect of very large capacities.\n    original_capacity_score = np.log1p(bins_remain_cap[suitable_bins_mask])\n    \n    # Heuristic 3: Introduce a slight penalty for bins that are already very full.\n    # This encourages using slightly less full bins to leave more room for future items.\n    # The penalty is higher for bins that are closer to being full.\n    fullness_penalty = 1.0 / (bins_remain_cap[suitable_bins_mask] + 1e-9)\n    \n    # Combine heuristics: A weighted sum of the scores.\n    # The weights can be tuned. Here, we give a slightly higher weight to Best Fit.\n    combined_score = (0.5 * best_fit_score + 0.3 * original_capacity_score - 0.2 * fullness_penalty)\n    \n    # Normalize scores to be between 0 and 1 for better stability and comparability\n    if combined_score.size > 0:\n        min_score = np.min(combined_score)\n        max_score = np.max(combined_score)\n        if max_score - min_score > 1e-9:\n            normalized_scores = (combined_score - min_score) / (max_score - min_score)\n        else:\n            normalized_scores = np.ones_like(combined_score) * 0.5 # If all scores are the same, assign a neutral score\n    else:\n        normalized_scores = np.array([])\n\n    # Assign the calculated priorities to the suitable bins\n    priorities[suitable_bins_mask] = normalized_scores\n    \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1 and 6 (identical): Heuristic 1 uses a combination of inverse difference and inverse remaining capacity, aiming for tight fits and penalizing large gaps. Heuristic 6 is identical.\n\nComparing Heuristics 2 and 10: Heuristic 2 scales the inverse difference by the inverse of remaining capacity, penalizing large gaps. Heuristic 10 uses a sigmoid on the fit ratio and normalizes the inverse remaining capacity, then combines them. Heuristic 2 is simpler and likely less prone to issues with parameter tuning that affect Heuristic 10's performance.\n\nComparing Heuristics 3 and 17/18 (identical): Heuristic 3 uses an inverse difference and then normalizes it with a sigmoid, aiming for a normalized priority range. Heuristics 17 and 18 are identical to Heuristic 3 but include additional parameters for sigmoid control, potentially offering more fine-tuning but increasing complexity.\n\nComparing Heuristics 4 and 5: Heuristic 4 combines Best Fit with a sigmoid penalty for large remaining capacities, using multiplication for combination. Heuristic 5 uses a composite score involving inverse remaining capacity and a fill ratio, aiming for tighter fits and better utilization. Heuristic 5's approach of combining metrics in a weighted manner seems more robust than Heuristic 4's multiplication which can lead to zero scores.\n\nComparing Heuristics 7, 8 (identical) and 11, 12, 15, 16 (identical): These heuristics combine \"Best Fit\" with an exploration bonus for less full bins using an epsilon-greedy approach. They prioritize tight fits but also explore less full bins. The difference lies in how the exploration bonus is calculated: Heuristics 7/8 use a raw difference from the average, while 11/12/15/16 use min-max scaling for normalization, potentially offering better control.\n\nComparing Heuristics 9 and 13 (identical): Identical to 7/8, using an epsilon-greedy approach with mean-based exploration bonus.\n\nComparing Heuristics 14 and 15/16: These are similar to 7/8 but use min-max scaling for the exploration bonus, which is generally more robust than using the mean.\n\nComparing Heuristics 19 and 20 (identical): These heuristics combine Best Fit with scores for original capacity and a fullness penalty, then normalize. This multi-component approach aims for a balanced solution.\n\nOverall: Heuristics that combine multiple criteria (like Best Fit with utilization or exploration) tend to be more sophisticated. Simple inverse relationships are a good baseline. Methods involving sigmoid normalization offer controlled ranges but introduce complexity. Exploration strategies (epsilon-greedy) add robustness. Heuristics 19/20 offer a well-rounded approach by combining several factors and normalizing.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Performance, Robustness, Exploration, Nuance.\n*   **Advice:** Focus on how current metrics reflect problem dynamics and adapt exploration based on observed search progress.\n*   **Avoid:** Over-reliance on static metrics or single-purpose exploration without considering their interaction.\n*   **Explanation:** True self-reflection involves understanding *why* a metric or exploration strategy works (or doesn't) in relation to the problem's inherent complexity, leading to more sophisticated, adaptive heuristic design.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}