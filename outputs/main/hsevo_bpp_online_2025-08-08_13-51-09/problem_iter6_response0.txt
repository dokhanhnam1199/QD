```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin, favoring bins
    that leave minimal remaining space, but also considering bins that are
    nearly full to encourage consolidation.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    suitable_bins_mask = bins_remain_cap >= item

    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]

    # Calculate "tightness" score: how much space is left after packing
    # We want to minimize remaining space, so higher score for smaller remaining space
    tightness_scores = - (suitable_bins_remain_cap - item)

    # Calculate "consolidation" score: favor bins that are already quite full
    # This encourages using up existing bins before opening new ones.
    # A bin is considered "nearly full" if its remaining capacity is small relative to the bin size.
    # We'll assume a standard bin size for this example, say 1.0. If bin size varies,
    # this would need to be adjusted or passed as an argument.
    bin_capacity = 1.0 # Assuming a standard bin capacity of 1.0
    consolidation_scores = (bin_capacity - suitable_bins_remain_cap) / bin_capacity

    # Combine scores. We want bins that are both tight (minimize remaining space)
    # and encourage consolidation (bins that are already full).
    # A simple approach is to sum them. We can use weights to tune their importance.
    # Let's give slightly more weight to tightness as it's the primary goal of BPP.
    combined_scores = 0.7 * tightness_scores + 0.3 * consolidation_scores

    # Normalize combined_scores to be between 0 and 1 for better comparison across items/bin states
    if np.ptp(combined_scores) > 0: # Avoid division by zero if all scores are the same
        normalized_scores = (combined_scores - np.min(combined_scores)) / np.ptp(combined_scores)
    else:
        normalized_scores = np.zeros_like(combined_scores)


    # Assign the normalized scores to the original priority array for suitable bins
    priorities[suitable_bins_mask] = normalized_scores

    # To ensure we pick the *best* bin according to these priorities, we want to
    # maximize the priority score.
    # For the First Fit Decreasing logic (which the original v1 hinted at),
    # the *best* bin is the one that minimizes remaining capacity.
    # Our `priority_v2` is designed to assign higher scores to such bins.
    # So, the bin with the highest priority score is the one we select.

    return priorities
```
