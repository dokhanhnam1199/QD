{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines the 'tight fit' prioritization of inverse difference with a sigmoid\n    function to normalize priorities, favoring bins that are a near-perfect fit\n    while maintaining a reasonable range.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(valid_bins_mask):\n        return priorities\n\n    valid_bins_cap = bins_remain_cap[valid_bins_mask]\n    \n    # Calculate inverse difference for valid bins: smaller difference is better\n    # Adding a small epsilon to avoid division by zero and extreme values\n    inverse_diff = 1.0 / (valid_bins_cap - item + 1e-9)\n    \n    # Use sigmoid to normalize and shape the priorities.\n    # The sigmoid will map the inverse differences to a [0, 1] range.\n    # We can center the sigmoid around a typical \"good fit\" or use the min/max\n    # of the calculated inverse differences to create a more adaptive scaling.\n    \n    min_inv_diff = np.min(inverse_diff)\n    max_inv_diff = np.max(inverse_diff)\n    \n    # Normalize inverse_diff to [0, 1] before applying sigmoid for more stable results\n    if max_inv_diff - min_inv_diff > 1e-9:\n        normalized_inv_diff = (inverse_diff - min_inv_diff) / (max_inv_diff - min_inv_diff)\n    else:\n        normalized_inv_diff = np.zeros_like(inverse_diff)\n\n    # Apply sigmoid. A sigmoid centered around 0.5 (e.g., 2 * x - 1 for normalized input)\n    # will map [0, 1] to roughly [0, 1], with a steep rise in the middle.\n    # Here, we use a simple sigmoid form that maps values to [0, 1].\n    # A common sigmoid form: 1 / (1 + exp(-k * (x - x0)))\n    # Let's use a simpler form for demonstration, similar to a normalized inverse:\n    # We want smaller differences (larger inverse_diff) to have higher priority.\n    # A high inverse_diff should map to a high sigmoid output.\n    # Using normalized_inv_diff, a higher value means a tighter fit.\n    # Let's use a sigmoid that emphasizes the middle range.\n    \n    # Option 1: Simple sigmoid on normalized inverse difference\n    # This will give higher priority to bins that are \"moderately\" good fits\n    # relative to the best fits.\n    scaled_priorities = 1 / (1 + np.exp(-10 * (normalized_inv_diff - 0.5))) # steep sigmoid\n\n    # Option 2: Direct sigmoid on inverse difference, scaled and shifted.\n    # This approach might be more sensitive to extreme inverse_diff values.\n    # We can scale inverse_diff to a reasonable range for sigmoid.\n    # Let's use the inverse difference directly, but clip extreme values or scale carefully.\n    # For simplicity and robustness, sticking with normalized inverse difference.\n\n    priorities[valid_bins_mask] = scaled_priorities\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with an exploration bonus for less full bins.\n\n    Prioritizes bins that are a tight fit (best fit) but also explores\n    less full bins to potentially improve overall packing.\n    \"\"\"\n    epsilon = 0.1\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if np.any(suitable_bins_mask):\n        suitable_bins_cap = bins_remain_cap[suitable_bins_mask]\n\n        # Best Fit component: inverse of remaining capacity after fitting\n        best_fit_scores = 1.0 / (suitable_bins_cap - item + 1e-9)\n\n        # Exploration component: bonus for bins with more remaining capacity (less full)\n        avg_remaining_capacity = np.mean(suitable_bins_cap)\n        exploration_bonus = np.maximum(0, avg_remaining_capacity - suitable_bins_cap) * epsilon\n\n        priorities[suitable_bins_mask] = best_fit_scores + exploration_bonus\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1 and 6 (identical): Heuristic 1 uses a combination of inverse difference and inverse remaining capacity, aiming for tight fits and penalizing large gaps. Heuristic 6 is identical.\n\nComparing Heuristics 2 and 10: Heuristic 2 scales the inverse difference by the inverse of remaining capacity, penalizing large gaps. Heuristic 10 uses a sigmoid on the fit ratio and normalizes the inverse remaining capacity, then combines them. Heuristic 2 is simpler and likely less prone to issues with parameter tuning that affect Heuristic 10's performance.\n\nComparing Heuristics 3 and 17/18 (identical): Heuristic 3 uses an inverse difference and then normalizes it with a sigmoid, aiming for a normalized priority range. Heuristics 17 and 18 are identical to Heuristic 3 but include additional parameters for sigmoid control, potentially offering more fine-tuning but increasing complexity.\n\nComparing Heuristics 4 and 5: Heuristic 4 combines Best Fit with a sigmoid penalty for large remaining capacities, using multiplication for combination. Heuristic 5 uses a composite score involving inverse remaining capacity and a fill ratio, aiming for tighter fits and better utilization. Heuristic 5's approach of combining metrics in a weighted manner seems more robust than Heuristic 4's multiplication which can lead to zero scores.\n\nComparing Heuristics 7, 8 (identical) and 11, 12, 15, 16 (identical): These heuristics combine \"Best Fit\" with an exploration bonus for less full bins using an epsilon-greedy approach. They prioritize tight fits but also explore less full bins. The difference lies in how the exploration bonus is calculated: Heuristics 7/8 use a raw difference from the average, while 11/12/15/16 use min-max scaling for normalization, potentially offering better control.\n\nComparing Heuristics 9 and 13 (identical): Identical to 7/8, using an epsilon-greedy approach with mean-based exploration bonus.\n\nComparing Heuristics 14 and 15/16: These are similar to 7/8 but use min-max scaling for the exploration bonus, which is generally more robust than using the mean.\n\nComparing Heuristics 19 and 20 (identical): These heuristics combine Best Fit with scores for original capacity and a fullness penalty, then normalize. This multi-component approach aims for a balanced solution.\n\nOverall: Heuristics that combine multiple criteria (like Best Fit with utilization or exploration) tend to be more sophisticated. Simple inverse relationships are a good baseline. Methods involving sigmoid normalization offer controlled ranges but introduce complexity. Exploration strategies (epsilon-greedy) add robustness. Heuristics 19/20 offer a well-rounded approach by combining several factors and normalizing.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Performance, Robustness, Exploration, Nuance.\n*   **Advice:** Focus on how current metrics reflect problem dynamics and adapt exploration based on observed search progress.\n*   **Avoid:** Over-reliance on static metrics or single-purpose exploration without considering their interaction.\n*   **Explanation:** True self-reflection involves understanding *why* a metric or exploration strategy works (or doesn't) in relation to the problem's inherent complexity, leading to more sophisticated, adaptive heuristic design.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}