{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap >= item:\n            priorities[i] = 1.0 / (remaining_cap - item + 1e-9)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = cap - item\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Sigmoid Fit Score) with Heuristic 8 (simple inverse distance loop): Heuristic 1 uses a sigmoid function to map the \"fit score\" (item/remaining_capacity) to a priority between 0 and 1, with a tunable scaling factor. This provides a more nuanced prioritization, favoring bins that are *just right* for the item. Heuristic 8 simply calculates the inverse of the difference, which can lead to extremely high priorities for bins with very little remaining capacity, potentially causing instability or suboptimal packing.\n\nComparing Heuristic 1 (Sigmoid Fit Score) with Heuristic 4 (Inverse Distance): Both aim to prioritize bins with a tighter fit. Heuristic 1 uses a sigmoid to normalize and shape the priority, making it less sensitive to extreme differences than Heuristic 4's direct inverse distance. The sigmoid in Heuristic 1 can also be centered, as seen in the implementation (e.g., `fit_scores - 0.8`), allowing for more control over what constitutes a \"good fit.\" Heuristic 4's `1.0 / (differences + 1e-9)` can still produce very large values.\n\nComparing Heuristic 2 (Sigmoid on Differences) with Heuristic 1: Heuristic 2 applies a sigmoid to the *difference* between available capacity and item size. It normalizes these differences before applying the sigmoid, aiming for higher priority with smaller differences. While conceptually similar in using a sigmoid, Heuristic 1's approach of using `item / valid_capacities` as the base score is more directly tied to the concept of \"how full\" the bin would be, which is a common objective in bin packing. Heuristic 2's normalization `(np.max(diff) - np.min(diff) + 1e-9)` can be sensitive to outliers in the available capacities.\n\nComparing Heuristic 5/6/7 (Epsilon-Greedy) with Heuristic 9/10 (Best Fit with potential exploration): These heuristics introduce an element of exploration by considering bins that are not necessarily the best fit. Heuristic 5/6/7 add an \"exploration bonus\" based on the average remaining capacity, aiming to balance using nearly full bins with exploring less full ones. Heuristic 9/10 directly implement a \"best fit\" priority, with comments suggesting an epsilon-greedy *strategy* that would use this priority. The explicit integration of exploration within the priority calculation (as in 5/6/7) is a more direct approach to balancing exploration and exploitation within the priority scoring itself.\n\nComparing Heuristic 11/12/13/14 (Simple Inverse Distance Loops) with Heuristic 9/10 (Vectorized Inverse Distance): The vectorized versions (9/10) are generally preferred for performance in Python with NumPy due to avoiding explicit Python loops. The logic is identical.\n\nComparing Heuristic 16 (Sigmoid on Remaining Capacity) with Heuristic 1 (Sigmoid on Fit Ratio): Heuristic 16 uses the sigmoid on the *remaining capacity* after fitting, effectively minimizing it. This is similar to Heuristic 1 but uses `-valid_potential_remaining_cap` as input to the sigmoid, pushing values towards 1 for smaller remaining capacities. Heuristic 1's approach of `item / valid_capacities` is perhaps a more direct representation of \"how full\" the bin will be relative to its capacity.\n\nComparing Heuristic 20 (Softmax on Differences) with Heuristic 4 (Inverse Distance): Heuristic 20 uses `exp(fit_ratios)` and normalizes via softmax. This can lead to very large priorities if any bin has a large remaining capacity, potentially dominating the selection. Heuristic 4's inverse distance is also prone to large values, but the sigmoid approach of Heuristic 1 offers better control.\n\nComparing Heuristic 17/18/19 (Remaining Difference) with Heuristic 8/11/12/13/14 (Inverse Difference): The simple difference (`cap - item`) as a priority (Heuristics 17, 19) means that *larger* remaining differences are prioritized, which is the opposite of what's usually desired for minimizing bins. Heuristic 18 adds a -1 for invalid bins, which is a reasonable way to disqualify them. Heuristics 8, 11, 12, 13, 14 prioritize bins with *smaller* differences (inverse relationship), which is more aligned with the \"best fit\" principle.\n\nOverall: Heuristics using sigmoid functions (1, 2, 16) offer controlled and nuanced prioritization, mapping different \"fit\" metrics to a predictable range. Heuristics incorporating exploration (5, 6, 7) add a valuable dimension for improving overall packing. Simple inverse distance (4, 8, 9, 10, 11, 12, 13, 14) is a good baseline but can be sensitive to extreme values. Prioritizing by simply the remaining difference (17, 18, 19) is generally counterproductive. Softmax (20) can be unstable.\n- \n*   **Keywords:** Bin packing, heuristic design, local search, neighborhood exploration, diversification.\n*   **Advice:** Focus on refining the *quality* of \"tight fit\" assessment by exploring diverse metrics beyond simple inverse relationships. Consider how different neighborhood structures in local search can expose novel packing solutions.\n*   **Avoid:** Over-reliance on fixed scaling functions. Avoid neglecting the impact of initial solutions; consider a diversification strategy for starting points.\n*   **Explanation:** \"Tight fit\" can be multifaceted. Instead of just inverse relationships, explore metrics that capture volume utilization *and* adjacency benefits. Different local search neighborhoods explore different parts of the solution space, preventing getting stuck in poor local optima. Diverse starting points ensure a broader exploration.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}