{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines a refined Best Fit with a dynamic Exploration bonus.\n    Prioritizes tight fits for larger items and exploration for smaller items,\n    adapting the strategy based on item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    remaining_after_placement = suitable_bins_caps - item\n\n    # Metric 1: Refined Best Fit - favors bins with smallest remaining capacity after placement.\n    # Using log1p to compress larger gaps and emphasize smaller ones. Add epsilon for stability.\n    best_fit_scores = np.log1p(1.0 / (remaining_after_placement + 1e-6))\n\n    # Metric 2: Exploration Bonus - favors bins that have significantly more remaining capacity.\n    # This is achieved by rewarding bins that are further from the minimum possible remaining capacity\n    # (after placing the item). Using min-max scaling on the remaining space after placement.\n    min_rem_after = np.min(remaining_after_placement)\n    max_rem_after = np.max(remaining_after_placement)\n\n    exploration_scores = np.zeros_like(remaining_after_placement)\n    if max_rem_after > min_rem_after:\n        # Normalize remaining capacity after placement to get exploration score (0 to 1)\n        exploration_scores = (remaining_after_placement - min_rem_after) / (max_rem_after - min_rem_after)\n    else:\n        # If all suitable bins leave the same remaining capacity, no exploration bonus from this metric.\n        pass\n\n    # Dynamic Weighting based on item size.\n    # Larger items benefit more from a precise fit (Best Fit).\n    # Smaller items can afford to explore less utilized bins (Exploration Bonus).\n    # Assume bin capacity is normalized to 1.0 for a relative item size assessment.\n    # If bin capacities vary significantly, a different normalization might be needed.\n    # For simplicity, we'll use item size directly, assuming it's scaled appropriately.\n    # Let's assume `item` is on a scale where 0.5 means it's half the typical bin capacity.\n    \n    # A simple heuristic: if item is more than 50% of typical capacity, prioritize best fit.\n    # If item is less than 20%, prioritize exploration. In between, a mix.\n    # Using item size as a proxy for its \"impact\" on bin fullness.\n    \n    # Weights sum to 1.0.\n    # For small items (e.g., item < 0.3): higher exploration, lower best fit.\n    # For large items (e.g., item > 0.7): higher best fit, lower exploration.\n    \n    # Example: Item size normalized to [0, 1] range, representing proportion of bin capacity.\n    # If actual item sizes are larger, they would need to be scaled.\n    # Let's assume `item` is already scaled relative to a standard bin capacity.\n\n    # Define a threshold, e.g., 0.5, for medium-sized items.\n    threshold_medium = 0.5 \n    \n    # Smooth transition for weights\n    weight_best_fit = np.clip(item / threshold_medium, 0.1, 1.0) # Favors best fit for larger items\n    weight_exploration = np.clip((threshold_medium - item) / threshold_medium, 0.1, 1.0) # Favors exploration for smaller items\n\n    # Normalize weights to ensure they sum to 1 if they cross thresholds or are outside bounds.\n    total_weight = weight_best_fit + weight_exploration\n    if total_weight > 1e-6:\n        weight_best_fit /= total_weight\n        weight_exploration /= total_weight\n    else: # Fallback if both are effectively zero\n        weight_best_fit = 0.5\n        weight_exploration = 0.5\n\n    # Combine scores\n    combined_scores = (weight_best_fit * best_fit_scores +\n                       weight_exploration * exploration_scores)\n\n    priorities[suitable_bins_mask] = combined_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines a tight fit metric with an exploration bonus, favoring bins\n    that minimize remaining space while also considering less utilized bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    # Metric 1: Tight Fit (similar to priority_v0)\n    # Prioritize bins that leave minimal remaining space after packing.\n    # Add epsilon for numerical stability. Higher score for smaller remaining space.\n    tightness_score = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n\n    # Metric 2: Exploration Bonus (inspired by priority_v0 and priority_v10/11/12)\n    # Favor bins that are less full (more remaining capacity).\n    # Using log1p for slightly better distribution at lower capacities.\n    # Higher score for bins with more remaining capacity.\n    exploration_score = np.log1p(suitable_bins_remain_cap)\n\n    # Combine scores with weights.\n    # Giving a slight edge to tightness, but exploration is also important.\n    # These weights can be tuned based on empirical performance.\n    combined_scores = 0.55 * tightness_score + 0.45 * exploration_score\n\n    # Normalize combined scores to a [0, 1] range.\n    # This ensures that the relative priorities are maintained even with different\n    # scales of the individual metrics. Handle cases where all scores are equal.\n    min_score = np.min(combined_scores)\n    max_score = np.max(combined_scores)\n    if max_score - min_score > 1e-9:\n        normalized_scores = (combined_scores - min_score) / (max_score - min_score)\n    else:\n        normalized_scores = np.ones_like(combined_scores) * 0.5\n\n    priorities[suitable_bins_mask] = normalized_scores\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1 and 2 (identical): They implement three metrics: Best Fit, Gap Exploitation, and Bin Fill Similarity, with dynamic weighting based on item size relative to max suitable capacity. The weights adapt to prioritize Best Fit for larger items and Gap Exploitation/Fill Similarity for smaller ones. Normalization is applied to each metric before combining.\n\nComparing Heuristics 3 and 4: Heuristic 3 combines Best Fit (tightness) with Exploration (larger initial capacity) using a fixed weighted sum. Heuristic 4 combines Best Fit (negative remaining capacity) with Exploration (normalized remaining capacity) using a weighted sum, favoring Best Fit. Heuristic 3 normalizes component scores via min-max scaling, while Heuristic 4 uses direct combination.\n\nComparing Heuristics 5, 6, 7, 8 (identical): These heuristics also use Best Fit (relative remaining capacity), Bin Fullness (inverse of remaining capacity), and Item Size Ratio. They employ dynamic weighting based on the item's size relative to the average suitable bin capacity. The weights adapt to prioritize Best Fit and Fullness for larger items, and Item Ratio/Fullness for smaller items. Normalization is applied to each metric before weighted combination.\n\nComparing Heuristics 9 and 10, 11, 12 (identical): Heuristic 9 combines Best Fit (tightness) with a fairness penalty (deviation from average remaining capacity). Heuristics 10-12 combine Modified Best Fit (sweet spot residual), Exploration (normalized remaining capacity after placement), and Usage Proxy (normalized current remaining capacity) with fixed weights.\n\nComparing Heuristics 13, 14, 15 (identical): These combine Refined Best Fit (log1p of inverse residual) with Exploration (min-max scaled remaining capacity after placement), using dynamic weights based on item size relative to a threshold.\n\nComparing Heuristics 16, 17, 18, 19, 20 (identical): These combine Best Fit (inverse residual) with Exploration (log1p or log of remaining capacity). They use fixed weights and normalize the combined score. Heuristics 17-18 have slightly different weights (0.55/0.45) than 19-20 (0.55/0.45) and 16 (0.7/0.3) for Best Fit vs. Exploration.\n\nOverall: The best heuristics (1-8) tend to use multiple metrics and adapt their weighting dynamically based on item characteristics or bin states, often involving normalization of individual metrics or the final combined score. Simpler fixed-weight combinations of Best Fit and Exploration (like 16-20) are less sophisticated but might be more robust. The use of logarithmic or Gaussian-like functions for scoring can provide smoother preference curves.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Metric selection, dynamic weighting, normalization, balance, robustness, simplicity.\n*   **Advice:** Focus on a core set of well-defined, interpretable metrics. Systematically explore dynamic weighting and robust normalization techniques. Aim for a balance between primary objectives and secondary goals like diversification or exploration.\n*   **Avoid:** Overly complex or opaque mathematical transformations, unstable calculations, and prioritizing single, overly simplistic metrics.\n*   **Explanation:** Effective self-reflection identifies *how* and *why* certain metric combinations and adjustments lead to improved performance by understanding their impact on the problem's core objectives.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}