{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins by combining a tight fit score (inverse of remaining capacity after fitting)\n    with a diversification bonus for bins with less capacity.\n    This aims to favor bins that are almost full for the current item while also\n    exploring less utilized bins to prevent premature overcrowding.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Filter bins that can accommodate the item\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n    \n    if valid_bins_remain_cap.size > 0:\n        # Calculate \"tight fit\" score: inverse of remaining capacity after fitting\n        # A smaller remaining capacity means a tighter fit, hence higher priority.\n        # Add a small epsilon to avoid division by zero.\n        fit_scores = 1.0 / (valid_bins_remain_cap - item + 1e-9)\n        \n        # Calculate a \"diversification bonus\" based on the inverse of the remaining capacity\n        # This slightly favors bins that are less full, promoting exploration.\n        # We use the original remaining capacity here to gauge overall fullness.\n        diversification_bonus = 1.0 / (bins_remain_cap[valid_bins_mask] + 1e-9)\n        \n        # Combine fit score and diversification bonus.\n        # A simple additive combination, scaled to give reasonable influence to both.\n        # The scaling factor can be tuned. Here, we'll give a slight edge to fit_scores.\n        combined_priorities = fit_scores + 0.5 * diversification_bonus\n        \n        # Assign the calculated priorities back to the original array indices\n        priorities[valid_bins_mask] = combined_priorities\n        \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins based on a combination of 'best fit' and 'least remaining capacity'.\n    It favors bins that closely fit the item while also considering those that will have\n    the least remaining space after packing, encouraging fuller bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    available_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(available_bins_mask):\n        return priorities  # No bins available\n\n    available_caps = bins_remain_cap[available_bins_mask]\n    \n    # --- Heuristic 1: Sigmoid on Fit Ratio (modified) ---\n    # Metric 1: How well the item fits the bin's remaining capacity.\n    # We use item / available_caps to represent how full the bin *will become*.\n    # A smaller ratio means a tighter fit (higher priority).\n    # We invert this for the sigmoid input to favor smaller ratios.\n    fit_ratios = item / available_caps\n    \n    # Sigmoid for fit ratio: -fit_ratios emphasizes smaller ratios.\n    # Scale and shift to center the sigmoid around a 'good fit' point (e.g., ratio close to 0).\n    # Adding a small epsilon to avoid division by zero or log(0) issues if scaling is applied later.\n    sigmoid_fit_input = -fit_ratios * 5.0 # Steepness parameter\n    priorities[available_bins_mask] = 1 / (1 + np.exp(-sigmoid_fit_input))\n\n    # --- Heuristic 11: Inverse Distance (modified for remaining capacity) ---\n    # Metric 2: Prioritize bins with less remaining capacity *after* packing.\n    # This is similar to \"best fit\" by minimizing leftover space.\n    remaining_capacities_after_fit = available_caps - item\n    \n    # Use inverse of remaining capacity, adding a small epsilon to avoid division by zero.\n    # Smaller remaining capacity should lead to higher priority.\n    inverse_remaining_cap = 1.0 / (remaining_capacities_after_fit + 1e-9)\n\n    # Normalize inverse remaining capacities to combine with fit priorities.\n    # This ensures that the remaining capacity metric is on a similar scale.\n    max_inv_rem_cap = np.max(inverse_remaining_cap)\n    if max_inv_rem_cap > 0:\n        normalized_inverse_remaining_cap = inverse_remaining_cap / max_inv_rem_cap\n    else:\n        normalized_inverse_remaining_cap = np.zeros_like(inverse_remaining_cap)\n\n    # --- Combination ---\n    # Combine the two metrics. We can use a weighted sum or a multiplication.\n    # Multiplication can emphasize bins that are good in *both* aspects.\n    # Let's use a weighted sum for more flexibility.\n    \n    # Assign weights to each heuristic. These can be tuned.\n    weight_fit = 0.7\n    weight_remaining = 0.3\n    \n    combined_priorities = (weight_fit * priorities[available_bins_mask] + \n                           weight_remaining * normalized_inverse_remaining_cap)\n\n    # Normalize the final combined priorities to be between 0 and 1,\n    # ensuring the highest priority bin is clearly selected.\n    max_combined_priority = np.max(combined_priorities)\n    if max_combined_priority > 0:\n        priorities[available_bins_mask] = combined_priorities / max_combined_priority\n    else:\n        priorities[available_bins_mask] = np.zeros_like(combined_priorities)\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1 and 6 (identical): Heuristic 1 uses a combination of inverse difference and inverse remaining capacity, aiming for tight fits and penalizing large gaps. Heuristic 6 is identical.\n\nComparing Heuristics 2 and 10: Heuristic 2 scales the inverse difference by the inverse of remaining capacity, penalizing large gaps. Heuristic 10 uses a sigmoid on the fit ratio and normalizes the inverse remaining capacity, then combines them. Heuristic 2 is simpler and likely less prone to issues with parameter tuning that affect Heuristic 10's performance.\n\nComparing Heuristics 3 and 17/18 (identical): Heuristic 3 uses an inverse difference and then normalizes it with a sigmoid, aiming for a normalized priority range. Heuristics 17 and 18 are identical to Heuristic 3 but include additional parameters for sigmoid control, potentially offering more fine-tuning but increasing complexity.\n\nComparing Heuristics 4 and 5: Heuristic 4 combines Best Fit with a sigmoid penalty for large remaining capacities, using multiplication for combination. Heuristic 5 uses a composite score involving inverse remaining capacity and a fill ratio, aiming for tighter fits and better utilization. Heuristic 5's approach of combining metrics in a weighted manner seems more robust than Heuristic 4's multiplication which can lead to zero scores.\n\nComparing Heuristics 7, 8 (identical) and 11, 12, 15, 16 (identical): These heuristics combine \"Best Fit\" with an exploration bonus for less full bins using an epsilon-greedy approach. They prioritize tight fits but also explore less full bins. The difference lies in how the exploration bonus is calculated: Heuristics 7/8 use a raw difference from the average, while 11/12/15/16 use min-max scaling for normalization, potentially offering better control.\n\nComparing Heuristics 9 and 13 (identical): Identical to 7/8, using an epsilon-greedy approach with mean-based exploration bonus.\n\nComparing Heuristics 14 and 15/16: These are similar to 7/8 but use min-max scaling for the exploration bonus, which is generally more robust than using the mean.\n\nComparing Heuristics 19 and 20 (identical): These heuristics combine Best Fit with scores for original capacity and a fullness penalty, then normalize. This multi-component approach aims for a balanced solution.\n\nOverall: Heuristics that combine multiple criteria (like Best Fit with utilization or exploration) tend to be more sophisticated. Simple inverse relationships are a good baseline. Methods involving sigmoid normalization offer controlled ranges but introduce complexity. Exploration strategies (epsilon-greedy) add robustness. Heuristics 19/20 offer a well-rounded approach by combining several factors and normalizing.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Performance, Robustness, Exploration, Nuance.\n*   **Advice:** Focus on how current metrics reflect problem dynamics and adapt exploration based on observed search progress.\n*   **Avoid:** Over-reliance on static metrics or single-purpose exploration without considering their interaction.\n*   **Explanation:** True self-reflection involves understanding *why* a metric or exploration strategy works (or doesn't) in relation to the problem's inherent complexity, leading to more sophisticated, adaptive heuristic design.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}