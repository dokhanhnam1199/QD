```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines best-fit tight packing with an exploration bonus for less utilized bins.
    Prioritizes bins that leave minimal residual space after packing, while also
    offering a slight preference for less full bins to encourage exploration.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    suitable_bins_mask = bins_remain_cap >= item

    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_cap = bins_remain_cap[suitable_bins_mask]
    remaining_after_placement = suitable_bins_cap - item

    # Core "Best Fit" score: Higher score for smaller remaining capacity (tighter fit)
    # Using reciprocal to emphasize very small remaining capacities.
    tight_fit_score = 1.0 / (remaining_after_placement + 1e-9)

    # Exploration/Diversification component: Bonus for bins that are less full.
    # This is inspired by epsilon-greedy strategies where we sometimes explore
    # non-optimal choices to potentially find better overall solutions.
    # We'll scale this bonus by a small factor to ensure "best fit" is primary.
    
    # Calculate a measure of how "full" each suitable bin is.
    fill_ratio = (suitable_bins_cap - remaining_after_placement) / (suitable_bins_cap + 1e-9)
    
    # A simple exploration bonus based on how much space is left relative to initial capacity.
    # We want to favor bins with *more* remaining capacity, as an exploration incentive.
    # The score should be higher for larger remaining capacities.
    exploration_score = remaining_after_placement / (suitable_bins_cap + 1e-9)
    
    # Combine scores: Prioritize tight fits, but add a small bonus for exploration.
    # The tight_fit_score is the primary driver. The exploration_score is a secondary boost.
    # A simple weighted sum:
    # We want to heavily favor tight fits, so the weight for tight_fit_score should be higher.
    # Let's use weights that reflect this. For example, weight = 1 for tight fit, and a smaller weight for exploration.
    
    # The idea from Heuristics 7/8/9/11/12/15/16 which used an epsilon-greedy approach:
    # They assigned a primary score (like best fit) and then added an exploration bonus.
    # Let's adapt that. The `tight_fit_score` is our primary score.
    # For the exploration bonus, we want to favor bins that are NOT the tightest fit.
    # Heuristics 11/12/15/16 used min-max scaling for the exploration bonus, which is robust.
    # Let's use a simplified exploration bonus that is higher for bins with larger remaining capacity.
    
    # Consider the normalized remaining capacity:
    # Min-max scaling for exploration bonus:
    min_rem = np.min(remaining_after_placement)
    max_rem = np.max(remaining_after_placement)
    
    exploration_bonus = np.zeros_like(remaining_after_placement)
    if max_rem > min_rem: # Avoid division by zero if all remaining capacities are the same
        exploration_bonus = (remaining_after_placement - min_rem) / (max_rem - min_rem)
    else:
        # If all remaining capacities are the same, no exploration bonus based on difference.
        # Or assign a small constant bonus if needed, but zero is fine for diversity.
        pass # exploration_bonus remains zeros

    # Combine: Primarily driven by tight fit, with an additive exploration bonus.
    # The exploration bonus is scaled to be less influential than the tight fit.
    # A small multiplier for the exploration bonus ensures it acts as a tie-breaker or diversification element.
    
    final_priorities = tight_fit_score + 0.1 * exploration_bonus # 0.1 is an arbitrary small weight for exploration

    priorities[suitable_bins_mask] = final_priorities

    return priorities
```
