```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    suitable_bins_mask = bins_remain_cap >= item

    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]

    # Metric 1: Best Fit (Tightness)
    # Score based on how tightly the item fits. Prefer bins where remaining capacity is minimal but sufficient.
    # Use inverse of remaining capacity, clamped to avoid division by zero and to cap extreme values.
    remaining_after_placement = suitable_bins_caps - item
    # We want smaller remaining_after_placement to have higher score.
    # Using 1/(x+epsilon) or similar. Let's use a clipped inverse.
    best_fit_scores = 1.0 / (remaining_after_placement + 1e-6)
    # Cap the score to prevent overly large values from very small remaining capacities.
    best_fit_scores = np.clip(best_fit_scores, 0, 10) # Arbitrary cap, can be tuned

    # Metric 2: Fill Ratio (Uniformity/Exploration Balance)
    # Reward bins that are not too empty, encouraging fuller bins first.
    # This balances filling existing bins to some extent before opening new ones.
    # Calculate the fill ratio if the item is placed. Assume max bin capacity is 1.0 for normalization.
    # If bin capacities vary significantly, using a context-aware max capacity could be better,
    # but for simplicity, we'll assume a standard bin capacity (e.g., 1.0 or a known max).
    # Let's assume a theoretical max capacity of 1.0 for normalization of 'emptiness'.
    # A higher fill ratio (closer to 1) is preferred.
    # Consider the capacity *before* placing the item for this metric.
    # We want to prefer bins that are already somewhat filled.
    # Let's use remaining_after_placement as a proxy for emptiness.
    # Normalized "emptiness" would be remaining_after_placement / max_bin_capacity.
    # We want to penalize high emptiness. So, score should be inversely related to emptiness.
    # Let's use 1 - (remaining_after_placement / max_suitable_cap_before_placement) where max_suitable_cap_before_placement is the capacity of the fullest suitable bin.
    # This aims to reward bins that are already somewhat utilized.

    # Let's simplify and focus on the remaining capacity itself.
    # We want bins that are not excessively empty, but also not almost full (to leave space).
    # This suggests a "sweet spot".
    # Let's score based on the remaining capacity *after* placement relative to the item size.
    # A bin that has just enough for the item (small remaining_after_placement) gets a high best_fit score.
    # For fill ratio, let's reward bins that have a moderate amount of remaining capacity.
    # This helps to leave space for future items and avoid packing items too tightly too early.
    # We can use a Gaussian-like function centered around a preferred remaining capacity.
    # Preferred remaining capacity could be item_size * some_factor, or a fixed percentage.
    # Let's try scoring based on how much space is left *relative to the bin's current capacity*.
    # More intuitively, reward bins that are not "too empty".
    # Consider the capacity before placement: suitable_bins_caps.
    # We want to encourage using bins that are not at their absolute minimum, but also not nearly full.
    # Let's use remaining capacity relative to item size: suitable_bins_caps / item
    # Higher ratio means the bin has more extra space compared to the item.
    # We want a moderate amount of extra space.
    # Let's define a "target" remaining capacity: perhaps related to the item size.
    # Target_remaining = item * 0.5 (or some other factor)
    # Score is high if abs(remaining_after_placement - Target_remaining) is small.
    # Or, more simply, reward bins with a good amount of remaining capacity, but not too much.
    # Let's use a "gap fill" metric: remaining_after_placement / suitable_bins_caps.
    # We want this to be small for "best fit", but not too small for "exploration".
    # Let's try a metric that rewards bins that are not too empty, using the *original* remaining capacity.
    # We want to avoid bins that are almost empty.
    # Let's use the inverse of the *original* remaining capacity (as a proxy for "fill level").
    # Higher original remaining capacity (less filled) gets a lower score here.
    # We want to favor bins that are *not* excessively empty.
    # Fill_score = 1 / (suitable_bins_caps + 1e-6) - this rewards fuller bins.
    # Let's focus on the remaining capacity *after* packing, normalized by the *original* capacity of that bin.
    # This tells us how much space is left relative to how much was available.
    # We want this ratio to be small for best fit, and moderate for exploration.

    # Let's try a simpler, more robust approach: prioritize bins that offer a good balance of fitting the item snugly AND leaving reasonable space for future items.
    # Metric 1: Fit Tightness (similar to Best Fit)
    # Score = 1 / (remaining_after_placement + epsilon)
    fit_tightness = 1.0 / (remaining_after_placement + 1e-6)
    fit_tightness = np.clip(fit_tightness, 0, 15) # Cap to avoid extreme values

    # Metric 2: Space Utilization (Balance)
    # Reward bins that leave a "useful" amount of space.
    # This means not too little (handled by fit_tightness) and not too much.
    # Let's score based on the ratio of remaining capacity *after* placement to the *item size*.
    # A ratio of 0 means it fits perfectly. A high ratio means a lot of space is left.
    # We want a moderate ratio.
    # Let's use a Gaussian-like function centered around a preferred remaining space.
    # Preferred remaining space could be item_size * 1.0 (i.e., double the item size left)
    # Or, a fixed percentage of bin capacity.
    # Let's try scoring based on the remaining capacity *relative to the bin's original capacity*.
    # This is (remaining_after_placement / suitable_bins_caps)
    # We want this ratio to be small, but not zero.
    # Let's try a simpler "minimum remaining capacity" concept.
    # Reward bins that have *at least* a certain amount of space left, e.g., 0.2 * bin_capacity.
    # This encourages leaving some buffer.
    # Let's consider the "slack" relative to the item size.
    # Slack = remaining_after_placement
    # We want slack to be positive but not excessively large.
    # Consider the ratio: suitable_bins_caps / item.
    # This ratio indicates how many times the item fits into the current bin capacity.
    # A ratio close to 1 is good for fitting.
    # A ratio much larger than 1 means a lot of space is left.
    # Let's try to reward bins where the *remaining capacity after placement* is a reasonable fraction of the *original capacity*.
    # (remaining_after_placement / suitable_bins_caps)
    # We want this to be in a middle range.
    # Let's use a function that peaks at a certain "excess capacity" relative to the item.
    # Excess capacity = remaining_after_placement
    # We want Excess capacity to be not too small (handled by fit_tightness) and not too large.
    # Let's score based on the remaining capacity *after* placement, normalized by the *item size*.
    # `remaining_after_placement / item`
    # High score for moderate values.
    # Let's try a Gumbel-like distribution for the remaining capacity.
    # Score = exp(-exp(-(remaining_after_placement - mu) / sigma))
    # Let mu be a target remaining capacity. For example, mu = item_size * 0.5
    # This rewards bins that leave roughly half the item's size in remaining space.
    mu = item * 0.5  # Target remaining space
    sigma = item * 0.2 # Spread of the distribution

    # Ensure sigma is not zero
    if sigma < 1e-6:
        sigma = 1e-6
    space_utilization = np.exp(-np.exp(-(remaining_after_placement - mu) / sigma))
    space_utilization = np.clip(space_utilization, 0, 1) # Scale to [0, 1]


    # Metric 3: Bin Age/Usage (Exploration/Diversification)
    # Reward bins that have been used less, to spread items and avoid creating many nearly full bins and one very empty bin.
    # This can be proxied by the *original* remaining capacity. Higher original remaining capacity means less used.
    # We want to avoid bins that are *too* empty, but also encourage using bins that aren't already nearly full.
    # Let's score based on the *original* remaining capacity, normalized by max suitable bin capacity.
    # This rewards bins that have more "room" in an absolute sense, but we need to temper this.
    # A better approach is to reward bins that are not at their absolute maximum capacity, but also not at their minimum.
    # Let's use the *inverse* of the original remaining capacity as a proxy for "fill level".
    # Fill_level_proxy = 1 / (suitable_bins_caps + 1e-6)
    # We want to reward moderately filled bins.
    # Let's use the inverse of the original remaining capacity, but capped.
    # This rewards bins that are less empty.
    less_empty_score = 1.0 / (suitable_bins_caps + 1e-6)
    less_empty_score = np.clip(less_empty_score, 0, 5) # Cap to avoid extreme values

    # Combine scores with dynamic weights.
    # Weights should adapt based on the item size relative to the typical bin capacity.
    # Assume a normalized bin capacity of 1.0.
    # If item size is large (e.g., > 0.5), 'fit_tightness' becomes more important.
    # If item size is small, 'space_utilization' and 'less_empty_score' can be more important.

    # Normalize item size relative to a typical max capacity (e.g., 1.0)
    item_normalized = item # Assuming item is already scaled or typical max capacity is 1.0

    # Dynamic weighting:
    # For smaller items, we might want to ensure they go into bins that are not extremely empty.
    # For larger items, fitting them snugly is crucial.
    
    # Weight for fit_tightness increases with item size
    w_fit = 0.4 + 0.5 * item_normalized
    w_fit = np.clip(w_fit, 0.4, 0.9)

    # Weight for space_utilization (leaving moderate space) can be moderate, perhaps peaking for medium items.
    w_space = 0.3 + 0.4 * (1 - item_normalized) # Higher for smaller items
    w_space = np.clip(w_space, 0.3, 0.7)

    # Weight for less_empty_score (avoiding very empty bins) is important for small items.
    w_less_empty = 0.3 + 0.4 * (1 - item_normalized) # Higher for smaller items
    w_less_empty = np.clip(w_less_empty, 0.3, 0.7)

    # Re-normalize weights to sum to 1
    total_w = w_fit + w_space + w_less_empty
    w_fit /= total_w
    w_space /= total_w
    w_less_empty /= total_w
    

    # Normalize each metric's scores before combining
    # Avoid division by zero if a metric yields all zeros
    if np.max(fit_tightness) > 1e-6:
        norm_fit = fit_tightness / np.max(fit_tightness)
    else:
        norm_fit = np.zeros_like(fit_tightness)

    if np.max(space_utilization) > 1e-6:
        norm_space = space_utilization / np.max(space_utilization)
    else:
        norm_space = np.zeros_like(space_utilization)

    if np.max(less_empty_score) > 1e-6:
        norm_less_empty = less_empty_score / np.max(less_empty_score)
    else:
        norm_less_empty = np.zeros_like(less_empty_score)

    combined_scores = (w_fit * norm_fit +
                       w_space * norm_space +
                       w_less_empty * norm_less_empty)

    priorities[suitable_bins_mask] = combined_scores

    return priorities
```
