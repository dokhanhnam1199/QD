{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a refined strategy.\n\n    This strategy prioritizes bins that offer a \"tight fit\" for the item,\n    meaning the remaining capacity after insertion is minimized. It achieves this\n    by assigning a priority score based on the inverse of (1 + slack), where slack\n    is the difference between the bin's remaining capacity and the item's size.\n\n    To further balance this with the \"fullness\" of bins (prioritizing bins that\n    are already closer to full, i.e., have less remaining capacity overall), a small\n    secondary score is added. This secondary score is proportional to the negative\n    of the bin's remaining capacity, effectively giving a slight preference to\n    smaller bins when tight fits are comparable.\n\n    A small amount of noise is added to the priority scores to introduce a stochastic\n    element, promoting exploration and helping to escape local optima, as suggested\n    by the \"balance with random exploration for robustness\" aspect of the reflection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities\n\n    # Calculate slack for bins that can fit the item\n    # Slack = remaining_capacity - item_size\n    slack = bins_remain_cap[fit_mask] - item\n\n    # Primary scoring: Favor tight fits by using 1 / (1 + slack).\n    # This assigns higher scores to bins with smaller positive slack.\n    tight_fit_scores = 1.0 / (1.0 + slack)\n\n    # Secondary scoring: Favor \"fuller\" bins (those with less initial remaining capacity).\n    # We use a small negative term proportional to the bin's remaining capacity.\n    # Maximizing this term means minimizing bins_remain_cap for fitting bins.\n    # The small multiplier ensures tight fit is primary.\n    fullness_scores = -0.1 * bins_remain_cap[fit_mask]\n\n    # Combine scores\n    combined_scores = tight_fit_scores + fullness_scores\n\n    # Add a small amount of random noise to encourage exploration.\n    # This helps to break ties and explore different packing configurations.\n    noise = np.random.normal(0, 0.01, size=combined_scores.shape)\n    priorities[fit_mask] = combined_scores + noise\n\n    # Normalize priorities so they sum to 1 over the fittable bins.\n    # This converts scores into probabilities if using a probabilistic selection method.\n    # If deterministic selection (e.g., argmax) is used, normalization isn't strictly necessary\n    # but can help in interpreting relative preferences.\n    current_priorities = priorities[fit_mask]\n    if np.any(current_priorities):\n        # Ensure no division by zero if all priorities are zero (though unlikely with noise)\n        sum_priorities = np.sum(current_priorities)\n        if sum_priorities > 0:\n            priorities[fit_mask] = current_priorities / sum_priorities\n        else:\n            # If for some reason all priorities are non-positive, assign equal probability\n            # to all fittable bins.\n            priorities[fit_mask] = 1.0 / len(current_priorities) if len(current_priorities) > 0 else 0\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Almost Full Fit strategy.\n\n    This strategy prioritizes bins that provide the \"tightest fit\" for the item,\n    meaning the remaining capacity after insertion is minimized. This is achieved\n    by maximizing `1.0 / (1.0 + slack)`, where slack is `remaining_capacity - item_size`.\n    Additionally, it introduces a secondary preference for bins that are already\n    \"fuller\" (i.e., have less initial remaining capacity) among those offering similar\n    tight fits, to promote more balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate the slack for bins that can fit the item\n    # Slack = remaining_capacity - item_size\n    slack = bins_remain_cap[fit_mask] - item\n\n    # Primary scoring: Prioritize minimal slack (tightest fits).\n    # Use `1.0 / (1.0 + slack)`: higher score for smaller slack.\n    # A slack of 0 gives priority 1.0.\n    primary_score = 1.0 / (1.0 + slack)\n\n    # Secondary scoring: Among bins with similar slacks, prioritize those that are\n    # \"fuller\" initially. This means preferring bins with smaller original `bins_remain_cap`.\n    # We can add a term proportional to the negative of the initial remaining capacity.\n    # A small coefficient `alpha` ensures the primary criterion (tightness) dominates.\n    alpha = 0.01\n    secondary_score = -alpha * bins_remain_cap[fit_mask]\n\n    # Combine scores: maximize primary score, then secondary score\n    priorities[fit_mask] = primary_score + secondary_score\n\n    return priorities\n\n[Reflection]\nPrioritize tight fits, then fuller bins. Tune secondary score weight for balance.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}