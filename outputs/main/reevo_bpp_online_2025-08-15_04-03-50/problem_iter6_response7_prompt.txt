{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a refined strategy.\n\n    This strategy prioritizes bins that offer a \"tight fit\" for the item,\n    meaning the remaining capacity after insertion is minimized. It achieves this\n    by assigning a priority score based on the inverse of (1 + slack), where slack\n    is the difference between the bin's remaining capacity and the item's size.\n\n    To further balance this with the \"fullness\" of bins (prioritizing bins that\n    are already closer to full, i.e., have less remaining capacity overall), a small\n    secondary score is added. This secondary score is proportional to the negative\n    of the bin's remaining capacity, effectively giving a slight preference to\n    smaller bins when tight fits are comparable.\n\n    A small amount of noise is added to the priority scores to introduce a stochastic\n    element, promoting exploration and helping to escape local optima, as suggested\n    by the \"balance with random exploration for robustness\" aspect of the reflection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities\n\n    # Calculate slack for bins that can fit the item\n    # Slack = remaining_capacity - item_size\n    slack = bins_remain_cap[fit_mask] - item\n\n    # Primary scoring: Favor tight fits by using 1 / (1 + slack).\n    # This assigns higher scores to bins with smaller positive slack.\n    tight_fit_scores = 1.0 / (1.0 + slack)\n\n    # Secondary scoring: Favor \"fuller\" bins (those with less initial remaining capacity).\n    # We use a small negative term proportional to the bin's remaining capacity.\n    # Maximizing this term means minimizing bins_remain_cap for fitting bins.\n    # The small multiplier ensures tight fit is primary.\n    fullness_scores = -0.1 * bins_remain_cap[fit_mask]\n\n    # Combine scores\n    combined_scores = tight_fit_scores + fullness_scores\n\n    # Add a small amount of random noise to encourage exploration.\n    # This helps to break ties and explore different packing configurations.\n    noise = np.random.normal(0, 0.01, size=combined_scores.shape)\n    priorities[fit_mask] = combined_scores + noise\n\n    # Normalize priorities so they sum to 1 over the fittable bins.\n    # This converts scores into probabilities if using a probabilistic selection method.\n    # If deterministic selection (e.g., argmax) is used, normalization isn't strictly necessary\n    # but can help in interpreting relative preferences.\n    current_priorities = priorities[fit_mask]\n    if np.any(current_priorities):\n        # Ensure no division by zero if all priorities are zero (though unlikely with noise)\n        sum_priorities = np.sum(current_priorities)\n        if sum_priorities > 0:\n            priorities[fit_mask] = current_priorities / sum_priorities\n        else:\n            # If for some reason all priorities are non-positive, assign equal probability\n            # to all fittable bins.\n            priorities[fit_mask] = 1.0 / len(current_priorities) if len(current_priorities) > 0 else 0\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, prioritizing fuller bins first, then best fit.\n\n    This heuristic prioritizes bins that are already fuller (have less remaining capacity).\n    If multiple bins have the same minimal remaining capacity, it then applies the Best Fit\n    principle to choose the one that results in the least waste. This aims to pack items\n    more densely by preferring bins that are closer to being full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates higher priority. Bins that cannot fit the item will have a priority of 0.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Create a boolean mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    fittable_bins_capacities = bins_remain_cap[can_fit_mask]\n\n    # Primary goal: Prioritize fuller bins. This means prioritizing bins with smaller remaining capacity.\n    # We can use the inverse of remaining capacity as a score. Higher score for smaller capacity.\n    # `fullness_score = 1.0 / (fittable_bins_capacities + epsilon)`\n\n    # Secondary goal: Among equally full bins, prioritize the best fit (minimize waste).\n    # Waste = `fittable_bins_capacities - item`.\n    # Best fit score = `1.0 / (waste + epsilon)`\n\n    # Combine the two: We want to prioritize bins with smaller `bins_remain_cap` first,\n    # and then smaller `fittable_bins_capacities - item` as a tie-breaker.\n    # A single score that achieves this is to create a composite key:\n    # `composite_key = (fittable_bins_capacities, fittable_bins_capacities - item)`\n    # We want to minimize this composite key lexicographically.\n    # For priority (maximize), we want to maximize the inverse of this key.\n    # A simple way to combine them into a single score for maximization is:\n    # `priority = (1.0 / (fittable_bins_capacities + epsilon)) + (1.0 / (fittable_bins_capacities - item + epsilon))`\n    # This gives a higher score to bins that are both fuller and have less waste.\n    # Let's test this combination:\n    # Bin A: remain_cap=0.6, item=0.5 -> waste=0.1. Score = 1/0.6 + 1/0.1 = 1.667 + 10 = 11.667\n    # Bin B: remain_cap=0.7, item=0.5 -> waste=0.2. Score = 1/0.7 + 1/0.2 = 1.428 + 5 = 6.428\n    # Bin C: remain_cap=0.6, item=0.4 -> waste=0.2. Score = 1/0.6 + 1/0.2 = 1.667 + 5 = 6.667\n    # Bin A (fullest, best fit) gets highest score. Bin C (equally full as A, worse fit) gets second highest. Bin B (less full, worse fit) gets lowest.\n    # This combination seems to correctly prioritize fullness first, then best fit.\n\n    combined_score = (1.0 / (fittable_bins_capacities + epsilon)) + \\\n                     (1.0 / (fittable_bins_capacities - item + epsilon))\n\n    priorities[can_fit_mask] = combined_score\n\n    return priorities\n\n[Reflection]\nPrioritize fullness, then best fit. Avoid noise for deterministic goals.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}