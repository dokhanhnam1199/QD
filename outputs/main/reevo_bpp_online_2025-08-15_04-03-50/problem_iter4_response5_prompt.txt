{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a refined 'Almost Full Fit' strategy.\n\n    This strategy prioritizes bins that can fit the item and, after fitting,\n    will have the least remaining capacity (i.e., the 'tightest' fits).\n    It also introduces a slight bias towards bins that have more overall remaining capacity\n    among those that offer a similarly tight fit, aiming to preserve very tight fits for\n    potentially smaller items later and to explore fuller bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in each fitting bin\n    potential_remaining_cap_fitting = bins_remain_cap[fit_mask] - item\n\n    # The core idea of \"Almost Full Fit\" is to minimize the remaining capacity after insertion.\n    # So, we want to prioritize bins with smaller `potential_remaining_cap_fitting`.\n    # We can use the inverse of (1 + slack) as a score, where slack is `potential_remaining_cap_fitting`.\n    # This gives higher scores to smaller slacks. A slack of 0 gets a priority of 1.0.\n    # A slack of 1 gets 0.5, etc.\n    # This part directly addresses the \"tight fit\" preference.\n\n    # To introduce a preference for fuller bins or to break ties in slack,\n    # we can add a secondary criterion. A common approach is to prefer bins\n    # that are already fuller among those with similar slacks.\n    # This can be approximated by using the original `bins_remain_cap` as a factor.\n    # However, a simpler way to break ties is to add a small, increasing value based\n    # on the original remaining capacity, ensuring that if two bins have the same slack,\n    # the one that was originally fuller (and thus has less capacity now) gets a slightly\n    # higher priority if we were to simply maximize `-potential_remaining_cap`.\n\n    # Let's refine the scoring to prioritize smaller `potential_remaining_cap_fitting`\n    # but also provide a subtle bias towards bins that were not excessively large to begin with,\n    # while still favoring tighter fits.\n\n    # Strategy: Prioritize based on `1.0 / (1.0 + slack)`.\n    # To break ties or encourage slightly less full bins when slacks are equal (to save tighter fits),\n    # we can also consider the original `bins_remain_cap`.\n    # A common heuristic for \"Best Fit\" or variations is to pick the bin with the smallest remaining capacity\n    # *after* insertion. This is `potential_remaining_cap_fitting`.\n    # To maximize this (i.e., get the smallest positive remaining capacity), we can use `-(potential_remaining_cap_fitting)`.\n    # To ensure robustness and avoid extremely large bins being picked if they result in a similar \"tightness\",\n    # we can also add a small factor related to the original capacity.\n\n    # Let's try a scoring function that prioritizes minimum slack, but with a slight\n    # nudge for bins that were not excessively large.\n    # Consider the score as: (priority for slack) + (small bonus for being less full initially, to break ties in favor of tighter bins).\n    # Or, more simply, maximize `-potential_remaining_cap_fitting`.\n\n    # The prompt reflection mentions \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits).\"\n    # This is achieved by `1.0 / (1.0 + slack)`.\n    # It also suggests \"balancing with random exploration for robustness\", but this function\n    # is deterministic. \"Favoring fuller bins using inverted slack\" is captured by `1/(1+slack)` where slack is minimized.\n\n    # Let's re-evaluate based on the reflection: \"Prioritize bins that have just enough capacity to fit the item,\n    # with a preference for bins that will have less remaining capacity after the item is added.\"\n    # This is still `1.0 / (1.0 + slack)`.\n\n    # A common variant to break ties or introduce exploration is to add a random component.\n    # However, for deterministic heuristics, tie-breaking is key.\n    # If multiple bins have the same minimal slack, which one to pick?\n    # Some strategies pick the one with the smallest original capacity (First Fit Decreasing logic),\n    # or the one with the largest original capacity (to consolidate larger bins).\n\n    # Let's use the inverse slack `1.0 / (1.0 + slack)` as the primary score.\n    # For tie-breaking, if slacks are equal, we might prefer the bin that was originally less full\n    # (higher `bins_remain_cap` among those with minimal slack). This helps keep the very tightest\n    # bins available for future very small items.\n    # To implement this, we can add a small value proportional to `bins_remain_cap[fit_mask]`\n    # to the primary score, or use a lexicographical sort implicitly.\n\n    # Score = (1.0 / (1.0 + slack)) + small_epsilon * bins_remain_cap[fit_mask]\n    # This would prioritize smaller slack, and for equal slacks, it would prioritize bins\n    # that originally had more capacity. This seems to align with \"balancing with random exploration\"\n    # by making choices less extreme in favoring already full bins.\n\n    slack = bins_remain_cap[fit_mask] - item\n    # Primary score: higher for smaller slack\n    primary_score = 1.0 / (1.0 + slack)\n\n    # Secondary score for tie-breaking or introducing slight variation:\n    # Adding a small fraction of the original remaining capacity.\n    # This boosts scores for bins that were less full if they have the same slack.\n    # We use a small multiplier (e.g., 1e-3) to ensure slack is the dominant factor.\n    secondary_score = 1e-3 * bins_remain_cap[fit_mask]\n\n    priorities[fit_mask] = primary_score + secondary_score\n\n    # Ensure that bins that don't fit have a priority of 0.\n    # The initialisation to zeros and `fit_mask` already handle this.\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Almost Full Fit strategy.\n\n    This strategy prioritizes bins that have a \"tight fit\" for the item, meaning the\n    remaining capacity after insertion is minimized (but non-negative).\n    It uses the inverse of (1 + slack) to reward smaller slacks.\n    Additionally, it introduces a slight bias towards bins that are *not* excessively large,\n    even if they offer a tight fit for the current item, to promote better overall packing.\n    This is done by penalizing bins with significantly more remaining capacity than needed.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate the slack for bins that can fit the item\n    # Slack is defined as remaining_capacity - item_size\n    slack = bins_remain_cap[fit_mask] - item\n\n    # Strategy: Prioritize bins with minimal non-negative slack (tightest fits).\n    # The core idea is to maximize `1 / (1 + slack)`.\n    # A slack of 0 (perfect fit) gives priority 1.0.\n    # Smaller positive slacks give higher priorities than larger ones.\n    # We add 1 to slack to avoid division by zero and to bound priorities.\n    base_priorities = 1.0 / (1.0 + slack)\n\n    # Refinement: Introduce a penalty for bins that have significantly more capacity\n    # than is currently needed, even if they provide a tight fit for this item.\n    # This discourages using a large, mostly empty bin if a smaller, nearly full bin exists.\n    # We can do this by penalizing `bins_remain_cap` for bins that fit.\n    # A common approach is to divide the base priority by some function of the bin's capacity,\n    # or subtract a value related to the capacity.\n    # Let's use a factor that slightly reduces priority for larger bins.\n    # A simple way is to use the inverse of the original remaining capacity,\n    # effectively favoring smaller bins.\n\n    # However, a simpler approach for \"Almost Full Fit\" is to focus purely on the slack.\n    # The reflection also suggests \"balance with random exploration for robustness\",\n    # but this is a deterministic priority function. For robustness, one might consider\n    # a small random element or using multiple heuristics.\n    # For this specific function, let's refine the slack prioritization.\n\n    # The `1.0 / (1.0 + slack)` formulation already favors tighter fits.\n    # To avoid very large bins being chosen if they have a similar slack to smaller bins,\n    # we can introduce a penalty related to the bin's *original* remaining capacity.\n    # For example, we could multiply by `(1.0 - log(bins_remain_cap[fit_mask] + 1) / max_log_cap)`.\n    # This is becoming complex.\n\n    # Let's simplify based on the reflection: \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits). Experiment with prioritizing fuller bins using inverted slack, but balance with random exploration for robustness.\"\n\n    # The `1.0 / (1.0 + slack)` already favors minimal remaining capacity.\n    # \"Prioritizing fuller bins using inverted slack\" could mean maximizing `-slack`,\n    # but this assumes we want *negative* slack (i.e., item overflows).\n    # For fitting items, we want minimal *positive* slack. `1/(1+slack)` achieves this.\n\n    # Let's add a term that slightly favors bins that are \"closer\" to being full relative to their own size,\n    # or simply prefer smaller bins overall when slack is equal.\n    # A simple way to penalize larger bins without overcomplicating is to subtract a small value proportional to their capacity.\n    # However, this could make priorities negative.\n\n    # A balanced approach could be to ensure that the priority is also influenced by how \"full\" the bin *will become*.\n    # If `potential_remaining_cap` is small, it's good.\n    # We are already maximizing `1/(1+slack)` where `slack = bins_remain_cap - item`.\n    # This is equivalent to minimizing `slack`.\n\n    # Consider the \"slack\" as the primary metric.\n    # For bins that fit, `bins_remain_cap[fit_mask] - item`\n    # We want to prioritize smaller values of this slack.\n    # `1.0 / (1.0 + slack)` achieves this.\n\n    # Alternative interpretation for \"Almost Full Fit\": prioritize bins where `bins_remain_cap` is slightly larger than `item`.\n    # Example:\n    # Bin A: capacity=5, item=3, slack=2, potential_rem=2. Priority = 1/(1+2) = 0.33\n    # Bin B: capacity=4, item=3, slack=1, potential_rem=1. Priority = 1/(1+1) = 0.5\n    # Bin C: capacity=3, item=3, slack=0, potential_rem=0. Priority = 1/(1+0) = 1.0\n\n    # This seems correct for favoring tight fits.\n    # The reflection mentions \"balancing with random exploration\". Since this is deterministic,\n    # we can simulate a *slight* bias by adding a tiny noise or by using a secondary criterion for ties.\n    # For now, let's stick to a refined deterministic priority based on slack.\n\n    # Let's ensure that bins that are *just barely* large enough are prioritized\n    # over bins that are much larger but also fit.\n    # The `1 / (1 + slack)` already does this indirectly: a larger bin will have a larger\n    # slack for the same item, resulting in a lower priority.\n\n    # Example: item=2\n    # Bin A: cap=3, slack=1, priority=1/2=0.5\n    # Bin B: cap=10, slack=8, priority=1/9~0.11\n    # This is working as intended.\n\n    # Final check on the reflection: \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits). Experiment with prioritizing fuller bins using inverted slack, but balance with random exploration for robustness.\"\n    # Minimal remaining capacity after fit => minimal slack => maximize `1/(1+slack)`.\n    # \"Prioritizing fuller bins using inverted slack\" => This might imply `-(bins_remain_cap - item)` or similar.\n    # If we use `-slack`, we want the most negative slack (overflow), which is not for fitting.\n    # If we want the *least positive* slack, `1/(1+slack)` is a good proxy.\n\n    # Let's refine the priority to explicitly prefer bins where `bins_remain_cap` is closer to `item`.\n    # This means minimizing `bins_remain_cap - item`.\n\n    # A potential issue with `1/(1+slack)` is that if `slack` is very large, the priority approaches zero.\n    # We can add a small constant to the slack to push priorities slightly higher for all fitting bins,\n    # or use a different function.\n\n    # Consider `priority = exp(-slack)`\n    # slack=0: exp(0) = 1\n    # slack=1: exp(-1) ~ 0.37\n    # slack=2: exp(-2) ~ 0.13\n    # This also favors smaller slacks and decays faster.\n\n    # Another approach: The \"Best Fit Decreasing\" heuristic for offline BPP often prioritizes\n    # bins that have the smallest capacity *that is greater than or equal to the item size*.\n    # For online, we can adapt this. Find bins that fit, and among those, pick the one\n    # with the smallest `bins_remain_cap`.\n    # This is equivalent to minimizing slack: `bins_remain_cap - item`.\n\n    # Let's use the negative of the slack for fitting bins, as maximizing this will minimize slack.\n    # But we need to ensure non-fitting bins have a very low priority.\n    # If `bins_remain_cap - item` is negative, the item doesn't fit.\n    # We want to prioritize smaller values of `bins_remain_cap` for fitting bins.\n    # So, maximize `-bins_remain_cap` for bins where `bins_remain_cap >= item`.\n\n    # Let's try: priority = bins_remain_cap for fitting bins. This would favor smaller bins directly.\n    # If item=2:\n    # Bin A: cap=3, slack=1. Priority = 3\n    # Bin B: cap=4, slack=2. Priority = 4\n    # Bin C: cap=10, slack=8. Priority = 10\n    # This favors bins that are *just* big enough.\n\n    # Combining \"tight fit\" (minimize slack) and \"favor smaller bins\":\n    # For fitting bins, priority = -(bins_remain_cap - item) + K * (-bins_remain_cap)\n    # This is equivalent to minimizing `slack - K * bins_remain_cap`\n    # Or maximizing `item - bins_remain_cap + K * bins_remain_cap`\n\n    # Let's use the simplest interpretation of \"tight fit\" which is minimizing slack.\n    # The `1.0 / (1.0 + slack)` seems robust and directly rewards smaller slacks.\n    # To address the \"prioritizing fuller bins\" part, consider that a bin that is already very full\n    # (small original `bins_remain_cap`) might be preferred if it has a tight fit.\n    # The `1.0 / (1.0 + slack)` indirectly favors smaller bins because they tend to have smaller slacks.\n\n    # Let's try a simpler approach that directly maximizes the \"fullness\" after packing.\n    # We want to maximize `-(bins_remain_cap - item)` for fitting bins.\n    # This means we want to minimize `bins_remain_cap - item`.\n\n    # `potential_remaining_cap = bins_remain_cap[fit_mask] - item`\n    # We want to maximize `-potential_remaining_cap`.\n    # Let's try setting priority to `-potential_remaining_cap`.\n    # This means smaller remaining capacity gets higher priority.\n\n    # Example: item=2\n    # Bin A: cap=3, item=2 -> potential_rem=1. Priority = -1\n    # Bin B: cap=4, item=2 -> potential_rem=2. Priority = -2\n    # Bin C: cap=10, item=2 -> potential_rem=8. Priority = -8\n    # Bin D: cap=1, item=2 -> doesn't fit. Priority = 0\n\n    # This makes the *least negative* number the highest priority. This means\n    # we want the smallest `potential_remaining_cap`.\n    # This strategy seems to align well with \"Almost Full Fit\".\n\n    # To make it slightly more robust against very large bins:\n    # We can normalize the priority by the bin's original capacity or add a penalty.\n    # Let's try to modify the priority: `-potential_remaining_cap - alpha * bins_remain_cap[fit_mask]`\n    # Where alpha is a small positive constant. This would penalize larger bins.\n    # A simpler modification: Prioritize by `-potential_remaining_cap`, and for ties,\n    # pick the bin with smaller `bins_remain_cap`.\n\n    # Let's use the direct \"minimize remaining capacity after packing\" approach.\n    # This is equivalent to maximizing `-(bins_remain_cap - item)`.\n\n    potential_remaining_cap = bins_remain_cap[fit_mask] - item\n\n    # Maximize the negative of the remaining capacity.\n    # This prioritizes bins that will have the least capacity left.\n    priorities[fit_mask] = -potential_remaining_cap\n\n    # To incorporate the \"favoring fuller bins\" aspect more directly,\n    # we can also consider the initial state of the bin.\n    # A bin that is already \"more full\" might be a better candidate.\n    # This can be done by adding a term that is inversely related to initial capacity.\n    # For example, `-(bins_remain_cap[fit_mask] - item) + C * (1.0 / bins_remain_cap[fit_mask])`\n    # This is complex. Let's stick to the most direct interpretation of \"Almost Full Fit\".\n\n    # The reflection suggests \"prioritizing fuller bins using inverted slack\".\n    # Inverted slack could mean `1 / (slack + epsilon)` if slack is positive, or `1 / (capacity - item)`\n    # for fitting bins, where we want smaller denominators.\n    # The current `-potential_remaining_cap` is a good candidate.\n\n    # Let's consider a slight modification inspired by Best Fit:\n    # Among bins that fit, choose the one with the minimum `bins_remain_cap`.\n    # This is equivalent to minimizing `slack`.\n    # If we want to return higher priority for better choices, we should maximize `-slack`.\n    # So, `-potential_remaining_cap` is a good choice.\n\n    # Consider `bins_remain_cap = [5, 6], item = 3`\n    # Bin 0: cap=5, item=3 -> potential_rem=2. priority = -2\n    # Bin 1: cap=6, item=3 -> potential_rem=3. priority = -3\n    # Bin 0 is chosen. This is correct (tightest fit).\n\n    # Consider `bins_remain_cap = [3, 4], item = 3`\n    # Bin 0: cap=3, item=3 -> potential_rem=0. priority = 0\n    # Bin 1: cap=4, item=3 -> potential_rem=1. priority = -1\n    # Bin 0 is chosen. This is correct (perfect fit, minimal remaining).\n\n    # To add a slight bias towards smaller bins when slack is equal:\n    # If `potential_remaining_cap` is the same for two bins, we'd want to break ties.\n    # For example, if item=3, and bins_remain_cap = [5, 5]:\n    # Both give potential_rem=2, priority=-2.\n    # In this case, we could add a term proportional to `-bins_remain_cap`.\n    # `priority = -potential_remaining_cap - alpha * bins_remain_cap[fit_mask]`\n    # Let alpha = 0.1.\n    # Bin 0: cap=5 -> -2 - 0.1*5 = -2.5\n    # Bin 1: cap=5 -> -2 - 0.1*5 = -2.5\n    # Tie still exists.\n\n    # A more direct way to prioritize smaller bins when slack is equal:\n    # Use the original `bins_remain_cap` as a secondary sorting key or part of the primary.\n    # Let's try: `priority = -bins_remain_cap[fit_mask] + C * (-potential_remaining_cap)`\n    # This prioritizes smaller initial capacity, and then tighter fits.\n    # Let C=1.\n    # Bin 0: cap=3, item=3 -> potential_rem=0. priority = -3 + 1*0 = -3\n    # Bin 1: cap=4, item=3 -> potential_rem=1. priority = -4 + 1*(-1) = -5\n    # Bin 0 is chosen. This favors tighter fits more.\n\n    # Let's try maximizing `-potential_remaining_cap` AND `-bins_remain_cap`.\n    # This means minimizing `potential_remaining_cap` and `bins_remain_cap`.\n    # Prioritize by `-(potential_remaining_cap + bins_remain_cap[fit_mask])`\n    # Bin 0: cap=3, item=3 -> pot_rem=0. priority = -(0 + 3) = -3\n    # Bin 1: cap=4, item=3 -> pot_rem=1. priority = -(1 + 4) = -5\n    # Bin 0 is chosen. This seems to combine both criteria.\n\n    # However, the reflection emphasizes \"minimal remaining capacity (tight fits)\".\n    # So, `-potential_remaining_cap` should be the primary driver.\n    # The \"favoring fuller bins\" could mean prioritizing bins that are already\n    # closer to full *before* insertion, but this contradicts tight-fitting.\n    # It's more likely referring to the state *after* insertion.\n\n    # Let's re-read: \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits).\"\n    # This is addressed by maximizing `-potential_remaining_cap`.\n\n    # \"Experiment with prioritizing fuller bins using inverted slack\"\n    # Inverted slack could mean `1/(slack+eps)` or `-slack`.\n    # If we want to prioritize fuller bins, we want smaller *initial* remaining capacity.\n    # So, let's use a weighted sum:\n    # Priority = `w1 * (-potential_remaining_cap) + w2 * (-bins_remain_cap[fit_mask])`\n    # We want to maximize this.\n    # Let's try `w1 = 1, w2 = 0.5` (slightly favor tight fits over smaller bins).\n    # Bin A: cap=5, item=3 -> pot_rem=2. priority = 1*(-2) + 0.5*(-5) = -2 - 2.5 = -4.5\n    # Bin B: cap=4, item=3 -> pot_rem=1. priority = 1*(-1) + 0.5*(-4) = -1 - 2.0 = -3.0\n    # Bin B is chosen. It has a tighter fit.\n\n    # If `w1 = 0.5, w2 = 1` (slightly favor smaller bins over tight fits).\n    # Bin A: cap=5, item=3 -> pot_rem=2. priority = 0.5*(-2) + 1*(-5) = -1 - 5 = -6.0\n    # Bin B: cap=4, item=3 -> pot_rem=1. priority = 0.5*(-1) + 1*(-4) = -0.5 - 4 = -4.5\n    # Bin B is chosen. It has a tighter fit.\n\n    # It seems `-potential_remaining_cap` is the dominant factor for \"tight fit\".\n    # Let's focus on that and add a small secondary criterion for \"fuller bins\" (smaller initial capacity).\n    # We want to maximize `-potential_remaining_cap`, and secondarily maximize `-bins_remain_cap`.\n    # This is equivalent to maximizing `-potential_remaining_cap - alpha * bins_remain_cap` for a small alpha.\n    # Let's use a small alpha to ensure `-potential_remaining_cap` is primary.\n\n    alpha = 0.01  # A small weight for the secondary criterion\n    priorities[fit_mask] = -potential_remaining_cap - alpha * bins_remain_cap[fit_mask]\n\n    # Testing this:\n    # item=3\n    # bins_remain_cap = [5, 4]\n    # Bin 0: cap=5, item=3 -> pot_rem=2. priority = -2 - 0.01*5 = -2.05\n    # Bin 1: cap=4, item=3 -> pot_rem=1. priority = -1 - 0.01*4 = -1.04\n    # Bin 1 is chosen. This is correct, it has a tighter fit.\n\n    # item=3\n    # bins_remain_cap = [5, 5]\n    # Bin 0: cap=5, item=3 -> pot_rem=2. priority = -2 - 0.01*5 = -2.05\n    # Bin 1: cap=5, item=3 -> pot_rem=2. priority = -2 - 0.01*5 = -2.05\n    # Tie.\n\n    # If we want to prioritize smaller bins *when fits are equal*:\n    # Let's use `-bins_remain_cap[fit_mask]` as the primary, and `-potential_remaining_cap` as secondary.\n    # Priority = `-bins_remain_cap[fit_mask] - alpha * potential_remaining_cap`\n    # Bin A: cap=5, item=3 -> pot_rem=2. priority = -5 - 0.01*2 = -5.02\n    # Bin B: cap=4, item=3 -> pot_rem=1. priority = -4 - 0.01*1 = -4.01\n    # Bin B is chosen. It has a smaller initial capacity and a tighter fit.\n\n    # The reflection emphasizes \"minimal remaining capacity (tight fits)\" first.\n    # So, `-potential_remaining_cap` must be primary.\n    # Let's stick to: `priorities[fit_mask] = -potential_remaining_cap` as the core.\n    # The \"favoring fuller bins\" aspect is implicitly handled by tight fits.\n    # A bin that is already more full will have less remaining capacity, thus a smaller `potential_remaining_cap`.\n\n    # Final formulation based on prioritizing minimal remaining capacity after fit.\n    # Maximize `-potential_remaining_cap` which means minimize `potential_remaining_cap`.\n    # The primary goal is tight fits.\n\n    # A slight adjustment to make it more sensitive to very small positive slacks,\n    # and to align with \"inverted slack\" which might imply higher values for smaller slacks.\n    # `1.0 / (1.0 + slack)` is a good choice for this.\n\n    # Let's go back to the `1.0 / (1.0 + slack)` form, as it directly penalizes larger slacks.\n    # This seems to be the most direct implementation of \"tight fits\".\n    slack = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (1.0 + slack)\n\n    # This prioritizes bins with 0 slack (perfect fit) with priority 1.0,\n    # then bins with slack 1 (priority 0.5), slack 2 (priority 0.33), etc.\n    # This directly favors minimal remaining capacity.\n\n    # To address \"favoring fuller bins\", it's implicitly handled because\n    # bins that are already fuller will tend to have smaller slacks.\n    # For example, if item=10:\n    # Bin A: cap=12, slack=2, priority=1/3\n    # Bin B: cap=20, slack=10, priority=1/11\n    # Bin A is chosen, which is a tighter fit and also started with less capacity.\n\n    return priorities\n\n[Reflection]\nPrioritize minimizing remaining capacity for tight fits, then consider initial bin fullness.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}