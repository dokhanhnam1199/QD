{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploring (choosing a random bin)\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if np.any(fittable_bins_mask):\n        # Greedy part: Calculate priority for fittable bins\n        # Prioritize bins with less remaining capacity that can still fit the item.\n        # This is a \"best fit\" approach for the greedy choice.\n        fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n        \n        # To prioritize bins with less remaining capacity, we want higher scores\n        # for smaller remaining capacities. We can use the inverse of remaining capacity.\n        # To avoid division by zero or very small numbers, we add a small constant.\n        # A higher score means higher priority.\n        priorities[fittable_bins_mask] = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n        \n        # Normalize priorities so they sum to 1 for the fittable bins\n        if np.sum(priorities[fittable_bins_mask]) > 0:\n            priorities[fittable_bins_mask] /= np.sum(priorities[fittable_bins_mask])\n\n        # Epsilon-Greedy: With probability epsilon, choose a random fittable bin\n        if np.random.rand() < epsilon:\n            random_bin_index = np.random.choice(np.where(fittable_bins_mask)[0])\n            # Set the priority of the random bin to 1 and others to 0 for selection\n            priorities = np.zeros_like(bins_remain_cap, dtype=float)\n            priorities[random_bin_index] = 1.0\n    else:\n        # If no bin can fit the item, all priorities remain 0 (or you might want\n        # to signal that a new bin is needed, but for priority scoring, 0 is fine).\n        pass\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    The Sigmoid Fit Score prioritizes bins that are a \"good fit\" for the item.\n    A good fit is defined as a bin where the remaining capacity is slightly larger\n    than the item size. This strategy aims to leave larger gaps in other bins\n    for potentially larger future items, while efficiently using space in the\n    current bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Ensure item size is not larger than any bin's capacity (otherwise it can't fit)\n    # For items that cannot fit, assign a very low priority (-inf)\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # For bins where the item can fit\n    remaining_capacities_for_valid_bins = bins_remain_cap[valid_bins_mask]\n\n    # Calculate the difference between remaining capacity and item size\n    # This represents how much \"extra\" space is left after placing the item.\n    # We want this difference to be small but positive for a good fit.\n    diff = remaining_capacities_for_valid_bins - item\n\n    # Apply a sigmoid-like function to map the differences to priorities.\n    # A steep sigmoid centered around 0 (meaning diff=0) would give the highest score.\n    # We want to penalize bins that are too small (negative diff, item doesn't fit, already handled by -inf)\n    # and bins that are too large (large positive diff, leaving a lot of wasted space).\n    # A common approach is to use a sigmoid scaled and shifted.\n    # Let's center the sigmoid around 0. The logistic function is 1 / (1 + exp(-x)).\n    # To prioritize bins with diff close to 0, we can use exp(-abs(diff)).\n    # Alternatively, we can use a transformed diff in the sigmoid:\n    # sigmoid(k * (target_diff - diff)). We want target_diff to be close to 0.\n    # So, exp(-k * diff) or exp(-k * abs(diff)) might be suitable.\n    # Let's try exp(-k * diff). If diff is small and positive, exp(-k*diff) is close to 1.\n    # If diff is negative (item doesn't fit), exp(-k*diff) would be large, which is good for negative values,\n    # but we've already filtered those.\n    #\n    # A more robust sigmoid fit could be:\n    # priority = 1 / (1 + exp(-k * (remaining_capacity - item - margin)))\n    # where 'margin' is a desired small positive buffer.\n    # For simplicity, let's use a Gaussian-like shape centered around zero difference,\n    # which is achieved by exp(-diff^2) or similar.\n\n    # Let's use exp(-k * diff) where k is a scaling factor. A larger k makes the preference for\n    # a tight fit more pronounced.\n    k = 2.0  # Sensitivity parameter, adjust as needed. Higher k means tighter fit preferred.\n    priorities[valid_bins_mask] = np.exp(-k * diff)\n\n    # To make it more \"priority-like\" where higher means more desirable,\n    # and we want to strongly prefer bins that are just big enough,\n    # we can also consider how much space is left.\n    # A simple logistic function centered around the \"ideal\" remaining capacity might be:\n    # ideal_remaining_capacity = item  (or item + a small buffer)\n    # Let's try a function that is high when remaining_capacity is slightly larger than item, and decreases otherwise.\n    # For example, a Gaussian-like shape: exp(-((remaining_capacity - item - buffer)**2) / sigma**2)\n    # Let's use a simpler approach: 1 / (1 + exp(k * (item - remaining_capacity)))\n    # If remaining_capacity is slightly larger than item, (item - remaining_capacity) is small negative, exp is close to 0, priority is close to 1.\n    # If remaining_capacity is much larger than item, (item - remaining_capacity) is large negative, exp is close to 0, priority is close to 1. This is not ideal.\n    #\n    # Let's re-evaluate the goal: we want to select bins where the remaining capacity is *just* enough.\n    # This means `remaining_capacity - item` should be small and positive.\n    # So, `diff = remaining_capacity - item` should be close to zero.\n    # A function that peaks at diff=0 would be `exp(-c * diff^2)` or `1 / (1 + exp(-c * diff))`.\n    #\n    # Let's refine using the sigmoid idea for \"fit score\":\n    # Consider the \"waste\" ratio: `(remaining_capacity - item) / remaining_capacity` if remaining_capacity > 0.\n    # We want this ratio to be small.\n    # Let's try prioritizing bins where `remaining_capacity` is close to `item`.\n    # This means `remaining_capacity / item` is close to 1.\n\n    # Let's try a sigmoid applied to the difference:\n    # sigmoid(a * (ideal_fit - (remaining_capacity - item)))\n    # ideal_fit = 0 (meaning we want remaining_capacity - item = 0)\n    # So, sigmoid(a * (- (remaining_capacity - item))) = sigmoid(a * (item - remaining_capacity))\n    # If remaining_capacity is just slightly larger than item, `item - remaining_capacity` is small negative, sigmoid output is ~0.5\n    # If remaining_capacity is much larger than item, `item - remaining_capacity` is large negative, sigmoid output is ~0.\n    # If remaining_capacity is less than item, `item - remaining_capacity` is positive, sigmoid output is ~1. This is also not good as it implies larger bins are better when item doesn't fit.\n\n    # Let's use a sigmoid that peaks at `remaining_capacity == item` (i.e., `diff == 0`).\n    # A common choice for this is a scaled Gaussian-like function or a logistic function focused on the difference.\n    # Let's use `1 / (1 + exp(k * abs(diff)))`. This peaks at diff=0 (score=1) and decays as diff increases.\n    # We already filtered for diff >= 0. So, `abs(diff)` is just `diff`.\n    # `1 / (1 + exp(k * diff))`.\n    # If diff = 0, score = 1.\n    # If diff is small positive (e.g., 0.1), score is slightly less than 1.\n    # If diff is large positive, score is close to 0.\n    # This means bins that *exactly* fit the item are prioritized the most, and bins with much larger capacity are de-prioritized.\n\n    k_sigmoid = 5.0 # Controls how sharply the priority drops as the fit becomes less tight.\n    priorities[valid_bins_mask] = 1.0 / (1.0 + np.exp(k_sigmoid * diff))\n\n    # Optional: Normalize priorities or add a small constant to avoid zero priorities if needed,\n    # but for this strategy, zero is a valid low priority if nothing fits.\n    # The current approach ensures items that can fit have priority > 0 and <= 1.\n\n    return priorities\n\n[Reflection]\nPrioritize \"tight fits\" for better space utilization and future item packing.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}