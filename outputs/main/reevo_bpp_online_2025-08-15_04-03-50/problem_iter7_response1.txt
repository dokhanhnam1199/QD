```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a refined Almost Full Fit strategy.

    This strategy prioritizes bins that have just enough capacity to fit the item,
    with a preference for bins that will have less remaining capacity after the item is added.
    It gently penalizes bins with very large remaining capacity. The goal is to fill bins
    more tightly and efficiently, potentially reducing the total number of bins used.

    The priority is calculated based on the "slack" (remaining capacity - item size).
    Bins with smaller non-negative slack get higher priority. A term is added to
    slightly favor bins that are not excessively large even if they fit.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins where the item can fit
    fit_mask = bins_remain_cap >= item

    # Calculate slack for bins that can fit the item
    # Slack is the remaining capacity after placing the item.
    # We want to minimize this slack for bins that fit.
    slack = bins_remain_cap[fit_mask] - item

    # --- Prioritization Strategy ---
    # We want to prioritize bins with smaller slack.
    # A common way to achieve this is using an inverse relationship.
    # Using 1 / (1 + slack) gives higher scores for smaller slack.
    # For example:
    # slack = 0 (perfect fit): priority = 1 / (1 + 0) = 1.0
    # slack = 1 (tight fit): priority = 1 / (1 + 1) = 0.5
    # slack = 5 (moderate fit): priority = 1 / (1 + 5) = 0.167
    # slack = 10 (loose fit): priority = 1 / (1 + 10) = 0.083

    # To prevent very large capacity bins from getting high priority just because
    # they fit, we can also consider a penalty based on the original remaining capacity
    # or the inverse of the remaining capacity. However, a simple "almost full fit"
    # focuses on the slack.

    # Let's refine the slack-based priority. We want to favor smaller slack.
    # The inverse function `1 / (1 + slack)` already does this.
    # To "gently penalize large gaps", we could adjust the slope of this function,
    # or perhaps add a term that reduces priority for bins that were initially very large.

    # A simple refinement to prioritize "almost full" fits is to use a scoring
    # where smaller slack gets higher priority.
    # Let's use a term that is high when slack is small and decreases as slack increases.
    # `1.0 / (1.0 + slack)` is a good start.
    # To slightly penalize very large initial capacities that might not be "tight fits"
    # even if they have a small slack, we can subtract a small penalty proportional
    # to the original capacity (but only for bins that fit).

    # Let's try a weighted sum or a more direct inverse:
    # Priority ~ 1 / (slack + epsilon) for bins that fit.
    # A slightly different approach: prioritize bins that will have minimal remaining capacity.
    # This means maximizing `-(bins_remain_cap[fit_mask] - item)`.
    # So, `item - bins_remain_cap[fit_mask]` is what we want to maximize (become more negative).
    # This is equivalent to minimizing `bins_remain_cap[fit_mask] - item`.

    # Let's stick to the `1 / (1 + slack)` as it directly favors small non-negative slack.
    # To incorporate "gently penalize large gaps", we can consider the original capacity.
    # A bin with `bins_remain_cap = 100` and `item = 3` (slack=97) shouldn't have as high priority
    # as a bin with `bins_remain_cap = 4` and `item = 3` (slack=1), even if we use a formula
    # that tries to invert slack.

    # A different approach for "almost full fit":
    # Prioritize bins where `bins_remain_cap - item` is minimized, subject to being non-negative.
    # This means we want to find the minimum of `bins_remain_cap[fit_mask] - item`.
    # The priority should be inversely related to this minimum.

    # Consider the range of slack. If slack is very small (e.g., 0 to 5), we want high priority.
    # If slack is large (e.g., 50+), we want low priority.
    # The function `1.0 / (1.0 + slack)` achieves this.

    # To refine "gently penalize large gaps", we could make the priority
    # decrease more steeply for larger slacks.
    # For instance, `exp(-slack / scale)` where scale is a tunable parameter.
    # Or, directly use the negative of slack, but clamp it or scale it.

    # Let's try to directly prioritize by the *negative* remaining capacity after placement,
    # but ensure it's relative and favors tighter fits.
    # The core idea of "Almost Full Fit" is to minimize `bins_remain_cap - item`.
    # So, we want to maximize `-(bins_remain_cap - item)`.
    # This is `item - bins_remain_cap`.

    # Let's try prioritizing based on how close `bins_remain_cap` is to `item`.
    # We want `bins_remain_cap` to be just slightly larger than `item`.
    # So, `bins_remain_cap - item` should be small and non-negative.
    # The priority score should be high for small `bins_remain_cap - item`.

    # Using `1.0 / (1.0 + slack)` is a robust way. Let's try to add a small penalty
    # for initially large bins.

    # Penalize bins that are excessively large, even if they fit.
    # We can achieve this by subtracting a small fraction of the original capacity.
    # For example, `priority = (1.0 / (1.0 + slack)) - alpha * bins_remain_cap[fit_mask]`
    # where alpha is a small positive constant (e.g., 0.01).
    # This would reduce the priority of very large bins.

    # Let's use `1.0 / (1.0 + slack)` for the primary "almost full" metric.
    # To incorporate the "gently penalize large gaps" aspect:
    # Perhaps the priority should be related to the *ratio* of item size to remaining capacity?
    # No, that favors filling smaller bins.

    # The core of "Almost Full Fit" is indeed minimizing `remaining_capacity - item`.
    # So, maximizing `item - remaining_capacity` for valid bins.

    # Let's use a score that emphasizes small positive slack.
    # The `1.0 / (1.0 + slack)` works well for this.
    # To "gently penalize large gaps", we can add a term that reduces priority for
    # bins with very large *original* capacities.

    # Option 1: Stick with `1 / (1 + slack)`. This already penalizes large gaps implicitly.
    # Option 2: Introduce a penalty for large original capacity.
    # Example: `priority = (1.0 / (1.0 + slack)) * (1.0 / (1.0 + C * bins_remain_cap[fit_mask]))`
    # where C is a small constant. This would decrease priority for larger original capacities.

    # Let's use a slightly modified version of the inverse slack, but perhaps make it
    # more sensitive to smaller slacks.
    # Consider `1.0 / (slack**p + epsilon)` for small p, or `exp(-slack/scale)`.

    # A common heuristic for "Best Fit" is to find the bin with `min(bins_remain_cap - item)`.
    # For "Almost Full Fit", it's similar but might include a slight preference for
    # bins that aren't *too* full if that leaves no room for future items.

    # Let's refine `1.0 / (1.0 + slack)`.
    # If `bins_remain_cap` is very large, `slack` will be large, and `1/(1+slack)` will be small.
    # This inherently penalizes large gaps.
    # The "gently penalize large gaps" might mean that if two bins have similar small slacks,
    # but one started much larger, the one that started smaller is preferred.

    # A simple, effective way to get "almost full" is to maximize `item - (bins_remain_cap - item)`.
    # This is `2*item - bins_remain_cap`. We want to maximize this, subject to `bins_remain_cap >= item`.
    # So, bins with `bins_remain_cap` closer to `item` (but >= item) get higher priority.

    # Let's use the negative of the slack for prioritization. Higher value means smaller slack.
    # To ensure we penalize larger gaps gently, we can add a term that is less sensitive
    # to the absolute size of the bin, or perhaps favors bins that were not excessively large.
    # A common approach is to normalize or scale slack values.

    # Consider `priority = -slack`. Maximizing this means minimizing slack.
    # To avoid very large bins dominating, maybe scale slack by original capacity or vice versa.
    # Or, use `(item - bins_remain_cap)`.
    # For bins that fit:
    # Priority = `item - bins_remain_cap[fit_mask]`
    # This means a bin with `bins_remain_cap = 4, item = 3` gives `-1`.
    # A bin with `bins_remain_cap = 5, item = 3` gives `-2`.
    # We want to maximize this value, so `-1` is better than `-2`. This favors smaller slacks.

    # Let's introduce a slight bonus for bins that have just enough capacity.
    # A simple approach could be to make the priority inversely proportional to `1 + slack`.

    # Let's refine the `1.0 / (1.0 + slack)` approach.
    # This favors smaller slack values.
    # To "gently penalize large gaps", we could modify the denominator.
    # For example, `1.0 / (1.0 + slack * scaling_factor)` where `scaling_factor`
    # could be adjusted to make the penalty steeper.
    # Or, simply ensure that bins with *very* large slack get significantly lower priority.

    # Let's use a strategy that aims to find bins where `bins_remain_cap` is just slightly larger than `item`.
    # Priority for fitting bins: `1.0 / (1.0 + (bins_remain_cap[fit_mask] - item))`
    # This gives priority 1.0 for perfect fits, and decreasing priority for larger slacks.

    # To address "gently penalize large gaps", we can consider the ratio of slack to total bin capacity
    # or simply the magnitude of the original capacity.
    # A common "Almost Full Fit" heuristic is indeed to minimize slack `bins_remain_cap - item`.

    # Let's try prioritizing based on `bins_remain_cap` relative to `item`.
    # We want `bins_remain_cap` to be as close to `item` as possible, from above.
    # Consider `bins_remain_cap / item`. We want this ratio to be close to 1.
    # If `bins_remain_cap = 5, item = 3`, ratio = 1.67
    # If `bins_remain_cap = 4, item = 3`, ratio = 1.33
    # If `bins_remain_cap = 3, item = 3`, ratio = 1.0
    # We want to prioritize smaller ratios.
    # So, priority can be `1.0 / (bins_remain_cap[fit_mask] / item)`.

    # Let's refine the `1 / (1 + slack)` idea.
    # It directly targets minimizing slack.
    # To incorporate "gently penalize large gaps": The inverse function already does this.
    # Perhaps the "gently" part means not having an extreme penalty.
    # The `1 / (1 + slack)` is a gentle exponential decay.

    # Let's add a small component that favors bins that are not excessively large *initially*.
    # This is tricky because "almost full" inherently means we don't want bins that are too empty.
    # The strategy should prioritize tight fits.

    # A commonly cited "Almost Full Fit" heuristic prioritizes bins with the minimum remaining capacity after packing.
    # This means maximizing `-potential_remaining_cap`.
    # So, `item - bins_remain_cap[fit_mask]` should be maximized.

    # Let's use the negative of the slack as a base priority, and then
    # introduce a term that slightly reduces priority for bins that were initially very large.

    # Base priority: higher for smaller slack (closer to 0)
    # `priority_base = -(bins_remain_cap[fit_mask] - item)` which is `item - bins_remain_cap[fit_mask]`
    # This is maximized when `bins_remain_cap[fit_mask]` is minimized.

    # To gently penalize large original capacities, we can subtract a small fraction of `bins_remain_cap[fit_mask]`.
    # `penalty = alpha * bins_remain_cap[fit_mask]`
    # Final priority = `priority_base - penalty`
    # Final priority = `item - bins_remain_cap[fit_mask] - alpha * bins_remain_cap[fit_mask]`
    # Final priority = `item - (1 + alpha) * bins_remain_cap[fit_mask]`
    # Maximizing this means minimizing `(1 + alpha) * bins_remain_cap[fit_mask]`.
    # This is still primarily minimizing `bins_remain_cap[fit_mask]`, but with a slight bias away from large bins.

    # Let's try a simpler formulation that captures the spirit:
    # Prioritize bins where `bins_remain_cap` is closest to `item`, but >= `item`.
    # This means `bins_remain_cap - item` should be minimized.
    # The `1.0 / (1.0 + slack)` strategy is good for this.

    # A different interpretation of "gently penalize large gaps":
    # Consider the percentage of capacity filled. We want to maximize `item / bins_remain_cap_original`.
    # No, that's for filling smaller bins.

    # Back to the most direct interpretation of "Almost Full Fit":
    # Prioritize bins that, after packing the item, will have the least remaining capacity.
    # This means minimizing `bins_remain_cap[fit_mask] - item`.
    # So, we can set priority as `- (bins_remain_cap[fit_mask] - item)`.
    # Let's add a small constant to avoid negative zero and ensure all valid bins have positive priority.

    # A common heuristic for "Almost Full Fit" is to rank bins by `bins_remain_cap - item`.
    # We select the bin with the minimum non-negative `bins_remain_cap - item`.
    # So, the priority should be higher for smaller non-negative `bins_remain_cap - item`.

    # Let's use a slight modification of `1.0 / (1.0 + slack)` to make it
    # more sensitive to the difference between `bins_remain_cap` and `item`.
    # Consider `priority = (bins_remain_cap[fit_mask] - item)`. We want to MINIMIZE this.
    # So, priority should be inversely proportional to this.

    # Let's consider the original `priority_v1` score: `1.0 / (1.0 + slack)`.
    # This favors bins with small slack.
    # "Gently penalize large gaps": This implies if a very large bin fits the item,
    # its priority should be lower than a smaller bin that fits the item with the same slack.
    # For example, if item=3:
    # Bin A: cap=4, slack=1. priority = 1/(1+1) = 0.5
    # Bin B: cap=103, slack=1. priority = 1/(1+1) = 0.5
    # We want Bin A to have higher priority than Bin B.

    # We can achieve this by subtracting a small fraction of the original capacity.
    # The target is to minimize `bins_remain_cap - item`.
    # Let's prioritize based on `-(bins_remain_cap - item)`, which is `item - bins_remain_cap`.
    # To penalize large original capacities, we subtract a portion of it.
    # Score = `item - bins_remain_cap[fit_mask] - alpha * bins_remain_cap[fit_mask]`
    # Score = `item - (1 + alpha) * bins_remain_cap[fit_mask]`
    # We want to maximize this score.

    # Let's pick a small alpha, e.g., 0.1.
    alpha = 0.1
    priorities[fit_mask] = item - (1 + alpha) * bins_remain_cap[fit_mask]

    # Ensure that bins that are "too full" (i.e., remaining capacity is very small,
    # potentially negative if we didn't have fit_mask) are not highly prioritized.
    # The `fit_mask` already handles non-fitting bins.
    # The goal is to find the tightest fit.

    # A more direct approach to penalizing large gaps:
    # Prioritize bins where `bins_remain_cap` is between `item` and `item + tolerance`.
    # And for those, pick the one with smallest `bins_remain_cap`.

    # Let's use a simple formula that prioritizes small slack but de-prioritizes very large original capacities.
    # The score `item - (1 + alpha) * bins_remain_cap[fit_mask]` achieves this.
    # For example:
    # item = 3
    # Bin A: cap=4. slack=1. score = 3 - (1.1)*4 = 3 - 4.4 = -1.4
    # Bin B: cap=5. slack=2. score = 3 - (1.1)*5 = 3 - 5.5 = -2.5
    # Bin C: cap=103. slack=100. score = 3 - (1.1)*103 = 3 - 113.3 = -110.3
    # Bin D: cap=104. slack=101. score = 3 - (1.1)*104 = 3 - 114.4 = -111.4

    # This prioritizes Bin A (-1.4) over Bin B (-2.5), which is correct (smaller slack).
    # It also drastically de-prioritizes Bin C (-110.3) and Bin D (-111.4), which is the "gently penalize large gaps" part.
    # The "gently" aspect comes from `alpha`. A smaller alpha makes the penalty less severe.

    # Let's try to make priorities positive for better interpretation and potential use in selection.
    # We can shift the scores or use a transform.
    # The relative ordering is what matters.
    # If we want higher priority to mean "more desirable", we need to invert or shift.

    # A common way to handle priorities where you want to minimize a value is to use `1 / (value + epsilon)`.
    # Here, we want to minimize `(1 + alpha) * bins_remain_cap[fit_mask] - item`.
    # Let `effective_remaining_capacity = (1 + alpha) * bins_remain_cap[fit_mask]`.
    # We want to minimize `effective_remaining_capacity - item`.
    # So, priority = `1.0 / (1.0 + (effective_remaining_capacity - item))`
    # priority = `1.0 / (1.0 + (1 + alpha) * bins_remain_cap[fit_mask] - item)`

    # Let's test this revised priority function:
    # item = 3, alpha = 0.1
    # Bin A: cap=4. effective_rem_cap = 1.1 * 4 = 4.4. value = 4.4 - 3 = 1.4. priority = 1 / (1 + 1.4) = 1 / 2.4 = 0.417
    # Bin B: cap=5. slack=2. effective_rem_cap = 1.1 * 5 = 5.5. value = 5.5 - 3 = 2.5. priority = 1 / (1 + 2.5) = 1 / 3.5 = 0.286
    # Bin C: cap=103. slack=100. effective_rem_cap = 1.1 * 103 = 113.3. value = 113.3 - 3 = 110.3. priority = 1 / (1 + 110.3) = 1 / 111.3 = 0.009
    # Bin D: cap=104. slack=101. effective_rem_cap = 1.1 * 104 = 114.4. value = 114.4 - 3 = 111.4. priority = 1 / (1 + 111.4) = 1 / 112.4 = 0.0089

    # This seems to correctly prioritize Bin A (tightest fit, moderate original capacity)
    # over Bin B (looser fit, moderate original capacity), and both over very large bins.
    # The "gently penalize" is achieved by the `alpha` factor which scales the original capacity's influence.

    # The denominator `1.0 + (1 + alpha) * bins_remain_cap[fit_mask] - item` is essentially
    # `1.0 + slack + alpha * bins_remain_cap[fit_mask]`.
    # This penalizes larger original capacities by increasing the denominator, thus decreasing priority.

    effective_slack = (1 + alpha) * bins_remain_cap[fit_mask] - item
    priorities[fit_mask] = 1.0 / (1.0 + effective_slack)

    return priorities
```
