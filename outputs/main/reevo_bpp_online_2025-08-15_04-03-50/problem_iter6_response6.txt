```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a refined Almost Full Fit with a preference for less empty space.

    This strategy prioritizes bins that have just enough capacity to fit the item,
    aiming to minimize the remaining capacity after placing the item (tight fit).
    To promote robustness and prevent packing small items into extremely large,
    mostly empty bins, it also penalizes bins with very large remaining capacities.
    The priority score is a combination that rewards tighter fits and discourages
    placing items into bins that will remain significantly empty.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        Bins that cannot fit the item will have a priority of 0.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins where the item can fit.
    fit_mask = bins_remain_cap >= item

    if not np.any(fit_mask):
        return priorities

    fittable_capacities = bins_remain_cap[fit_mask]

    # Calculate the slack (unused capacity) for bins that can fit the item.
    # This is the primary factor for "almost full fit". Smaller slack is better.
    slack = fittable_capacities - item

    # Score based on minimizing slack: 1 / (1 + slack)
    # A perfect fit (slack=0) gets a score of 1.0.
    # As slack increases, the score decreases.
    tight_fit_score = 1.0 / (1.0 + slack)

    # Penalize excessively large bins. We want to avoid putting a small item
    # into a bin that will still be mostly empty. This promotes more even
    # distribution and leaves larger contiguous spaces in other bins.
    # A simple penalty can be based on the inverse of the remaining capacity.
    # Bins with larger remaining capacity should get a lower penalty factor.
    # Using 1 / (1 + capacity) ensures we don't divide by zero and also
    # that larger capacities yield smaller (less favorable) scores here.
    # This factor is for the *original* remaining capacity of the fittable bins.
    large_bin_penalty_factor = 1.0 / (1.0 + fittable_capacities)

    # Combine the tight fit score with the penalty factor.
    # We multiply them: prioritize tight fits AND penalize large bins.
    # This means bins that are a tight fit AND have smaller remaining capacity
    # will get the highest scores.
    combined_priority = tight_fit_score * large_bin_penalty_factor

    # Assign the calculated priorities to the bins that can fit the item.
    priorities[fit_mask] = combined_priority

    # Normalize priorities among fittable bins so they sum to 1.
    # This ensures that the selection is probabilistic and relative.
    fittable_priorities = priorities[fit_mask]
    if np.sum(fittable_priorities) > 0:
        priorities[fit_mask] /= np.sum(fittable_priorities)
    else:
        # If all fittable priorities are zero (e.g., due to extreme large_bin_penalty_factor),
        # fall back to uniform probability among fittable bins.
        # This ensures we always select a bin if one is available.
        priorities[fit_mask] = 1.0 / len(fittable_priorities)

    return priorities
```
