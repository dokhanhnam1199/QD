```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Implements the Sigmoid Fit Score strategy for online Bin Packing Problem.

    This heuristic prioritizes bins based on how well an item fits, using a sigmoid
    function to smooth the preference. Bins that can accommodate the item with
    a remaining capacity close to the item's size (but not too small) are
    given higher priority.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.

    Returns:
        A NumPy array of the same size as bins_remain_cap, where each element
        represents the priority score for placing the item into the corresponding bin.
        Higher scores indicate a higher priority.
    """
    # We want to prioritize bins where the remaining capacity is just enough for the item.
    # A good candidate for 'just enough' is when remaining_capacity is close to item_size.
    #
    # Let's define a 'target' remaining capacity. If remaining_capacity is much larger
    # than item_size, it's not ideal (waste of space). If remaining_capacity is smaller
    # than item_size, it's not a valid fit.
    #
    # We can model this with a sigmoid function. The sigmoid function is good at
    # mapping values to a range between 0 and 1, and it has an "S" shape.
    #
    # We'll shift and scale the remaining capacities so that the "sweet spot"
    # (where remaining_capacity is closest to item_size) maps to the steepest
    # part of the sigmoid.

    # Ensure we only consider bins that can actually fit the item
    valid_bins_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap)

    # Calculate a "closeness" score for valid bins.
    # We want remaining_cap - item to be close to 0.
    # To use sigmoid effectively, we'll transform this difference.
    # Let's consider the relative difference: (remaining_cap - item) / remaining_cap
    # This score will be close to 0 if remaining_cap >> item, and close to 1 if remaining_cap is just slightly larger than item.
    # Or, even simpler, let's just look at remaining_cap directly.

    # We want remaining_cap to be roughly item + a small gap.
    # Let's try mapping remaining_cap.
    # The center of the sigmoid should be where remaining_cap is "ideal".
    # A good ideal might be slightly larger than 'item', perhaps item + some epsilon.
    # Let's use a characteristic size for scaling. The average remaining capacity
    # could be a good reference point, or maybe just a constant, or even the bin capacity.
    # For simplicity, let's make the sigmoid sensitive around the item size.

    # A common sigmoid form is 1 / (1 + exp(-k * (x - x0)))
    # where x is the input, x0 is the center, and k controls steepness.

    # We want high priority when bins_remain_cap is close to 'item'.
    # Let's set the center (x0) of our sigmoid to be slightly above 'item'.
    # A small offset like 0.1 or a percentage of item could work.
    # Let's try to center it around `item + item * 0.1` (10% buffer).

    center = item * 1.1  # Ideal remaining capacity is 10% larger than item

    # The steepness (k) will determine how sensitive the priority is to deviations
    # from the ideal center. A larger k means a sharper transition.
    # Let's make the steepness dependent on the item size. Larger items might
    # benefit from less steep sigmoid, smaller items from steeper. Or just a constant.
    steepness = 5.0  # A tunable parameter

    # Calculate the sigmoid score for valid bins
    # The input to the sigmoid will be `bins_remain_cap`.
    # The sigmoid function will output a value between 0 and 1.
    # We want higher values when bins_remain_cap is close to `center`.
    # However, a standard sigmoid increases as the input increases.
    # We want priority to be high when `bins_remain_cap` is *around* `center`.
    #
    # A better approach: Use a bell-shaped curve (like Gaussian or a
    # derivative of sigmoid). Or, we can invert the input to the sigmoid.
    # If we use sigmoid(-k * (x - x0)), it peaks at x0.

    # Let's re-think: we want high priority when `remaining_cap` is close to `item`.
    # Let `score = remaining_cap - item`.
    # We want `score` to be close to 0.
    # We want a function that peaks at `score = 0`.
    # Consider a Gaussian: `exp(-a * score^2)`. This is like a squared distance.
    #
    # Let's stick with sigmoid but modify the input.
    # We want to map `bins_remain_cap` to a priority score.
    #
    # Let's aim for higher priority when `bins_remain_cap` is NOT too large and NOT too small.
    # Bins that are very full (small remaining capacity) should have low priority.
    # Bins that are very empty (large remaining capacity) should also have low priority.
    # Bins that are "just right" should have high priority.
    #
    # Consider `(bins_remain_cap - item)`.
    # If this is positive and small, good. If it's negative, invalid. If it's large, bad.
    #
    # Let's try to model a score that is high when `bins_remain_cap` is within a certain range of `item`.
    # We can achieve this by combining two sigmoid functions or by using a transformation.
    #
    # Alternative: Let's focus on the "waste". Waste = `bins_remain_cap - item`.
    # We want minimal waste, but `bins_remain_cap >= item`.
    #
    # Sigmoid Fit Score strategy often refers to prioritizing bins that leave the LEAST remaining capacity
    # AFTER packing the item (i.e., Best Fit). Our current `bins_remain_cap` is BEFORE packing.
    # So, we want to select a bin such that `bins_remain_cap - item` is minimized, but still non-negative.
    # This is Best Fit.
    #
    # The request specifically mentions "Sigmoid Fit Score". This implies using sigmoid for scoring.
    # Let's interpret "Sigmoid Fit Score" as a variation of "First Fit", "Best Fit" or "Worst Fit"
    # that uses a sigmoid to assign probabilities or priorities.
    #
    # If we use the standard "Best Fit" approach (minimize `bins_remain_cap - item`),
    # a simple way to use sigmoid is to transform this difference.
    #
    # Let `diff = bins_remain_cap - item`. We want to prioritize small non-negative `diff`.
    #
    # If `bins_remain_cap < item`, priority is 0.
    # If `bins_remain_cap >= item`, we want to prioritize smaller `bins_remain_cap`.
    #
    # Let's scale `bins_remain_cap` values.
    # A common approach for Sigmoid Fit is to relate it to how full the bin is *after* packing.
    # The "fit" is how well the item fills the bin.
    #
    # Let's consider the *percentage of space utilized* for the item in the bin.
    # This is `item / original_bin_capacity`. This isn't directly available here.
    # We only have `bins_remain_cap`.
    #
    # Let's use the sigmoid to encourage bins that leave a small but positive remaining capacity.
    # The range of `bins_remain_cap` can vary greatly. We need to normalize or scale appropriately.
    #
    # A simple sigmoid mapping of `bins_remain_cap` would give higher scores to larger `bins_remain_cap`
    # (if it's increasing sigmoid) or smaller `bins_remain_cap` (if it's decreasing).
    #
    # Let's consider `x = bins_remain_cap`. We want high priority when `x` is close to `item`.
    # We can define a score function `f(x)` that peaks at `x = item`.
    # A Gaussian `exp(-k * (x - item)**2)` would do this.
    # How to use sigmoid?
    #
    # If we want to maximize the sigmoid output, we need the argument to be large positive.
    # If we want to minimize sigmoid output, we need the argument to be large negative.
    #
    # Let's map `bins_remain_cap` to a score that is high when `bins_remain_cap` is `item`.
    #
    # Consider the transformation: `-(bins_remain_cap - item)**2`. This peaks at `item`.
    # Then apply sigmoid to this: `sigmoid(k * -(bins_remain_cap - item)**2)`
    # `1 / (1 + exp(k * (bins_remain_cap - item)**2))`
    # This function is `1` when `bins_remain_cap = item` and approaches `0` as `bins_remain_cap` moves away from `item`.
    # This is a bell curve shape, often associated with "best fit" properties when smoothed by sigmoid.

    # Apply the valid bins mask
    valid_bins_remain_cap = bins_remain_cap[valid_bins_remain_cap]

    if valid_bins_remain_cap.size == 0:
        return np.zeros_like(bins_remain_cap)

    # Calculate the "squared difference from ideal fit"
    # Ideal remaining capacity is `item` to minimize waste.
    # We are penalizing bins that are too large or too small (if less than item, which we filtered)
    squared_diff = (valid_bins_remain_cap - item)**2

    # Apply sigmoid transformation.
    # We want the highest priority when squared_diff is 0.
    # So, we want the input to sigmoid to be as large and positive as possible.
    # This means `sigmoid(k * (something that is high when squared_diff is low))`.
    # Let's use `sigmoid(-k * squared_diff)`. This peaks at 0 difference.
    # `1 / (1 + exp(k * squared_diff))`
    # This gives a value close to 1 for small `squared_diff` and close to 0 for large `squared_diff`.

    # To make it more like a score that can be used in selection, higher is better.
    # Let's scale `squared_diff` to control the steepness.
    # A common practice is to normalize based on the range of possible differences.
    # The maximum possible difference could be related to the bin capacity.
    # However, we don't have original bin capacity.
    # Let's try scaling `squared_diff` by a factor.

    # Scale the squared differences.
    # If the differences are very large, the sigmoid might quickly become zero.
    # We can scale the squared differences by a factor `scale` such that
    # `scale * squared_diff` maps to the sigmoid's sensitive region.
    # If `squared_diff` is around `item^2`, we want that to be significant.
    # Let's try scaling by `1 / item**2` to make the relative difference matter.
    # Or, let's choose a `scale` parameter that's tunable.
    # A simpler approach is to use a constant scaling factor for `k`.

    k_scaled = 5.0 / (item + 1e-6) # Make steepness somewhat dependent on item size (avoid division by zero)

    # Calculate the transformed scores using the inverted sigmoid logic
    # higher_score_for_closer_fit = 1 / (1 + np.exp(k_scaled * squared_diff))
    # This still peaks at 1 for the best fit.

    # Let's try a different sigmoid interpretation:
    # Prioritize bins that are "not too full" and "not too empty".
    # This implies a peak around the middle of available capacities.
    # The term "Sigmoid Fit Score" is a bit ambiguous without a precise definition provided.
    # A common interpretation for similar heuristics is to use sigmoid to translate
    # the "goodness of fit" into a probability or priority.

    # Let's simplify and try to make it "Best Fit with Sigmoid Shaping".
    # Best Fit aims to minimize `bins_remain_cap - item`.
    # We can transform `bins_remain_cap - item` to a score.
    #
    # Consider the ratio `(bins_remain_cap - item) / bins_remain_cap` for valid bins.
    # This ratio is 0 when `bins_remain_cap = item`.
    # This ratio approaches 1 when `bins_remain_cap` is very large.
    # This ratio is negative if `bins_remain_cap < item` (but we filter these).
    #
    # We want to prioritize smaller positive values of this ratio.
    # `ratio = (valid_bins_remain_cap - item) / valid_bins_remain_cap`
    # A ratio close to 0 is good.
    #
    # To use sigmoid for this, we want a score that increases as the ratio decreases.
    # Let `score_input = -ratio`.
    #
    # Then `priorities_valid = 1 / (1 + np.exp(-k_sigmoid * score_input))`
    # `priorities_valid = 1 / (1 + np.exp(k_sigmoid * ratio))`
    # This will give higher priority when `ratio` is smaller (closer to 0).
    # `k_sigmoid` controls the steepness. Let's set it to a reasonable value.

    k_sigmoid = 10.0 # Tunable parameter for steepness

    # Calculate ratio (percentage of leftover space relative to current remaining capacity)
    # Avoid division by zero for bins that might have zero remaining capacity (though filtered by valid_bins_mask)
    ratios = (valid_bins_remain_cap - item) / (valid_bins_remain_cap + 1e-9)

    # Apply sigmoid: high score for small ratios (good fit)
    # The sigmoid function `1 / (1 + exp(-x))` is monotonically increasing.
    # We want high scores for small `ratios`. So we need an argument `x` that is large negative when `ratios` is small.
    # Let `x = -k_sigmoid * ratios`.
    # Score = `1 / (1 + exp(k_sigmoid * ratios))`
    priorities_valid = 1.0 / (1.0 + np.exp(k_sigmoid * ratios))

    # Distribute the calculated priorities back to the original array shape
    priorities[valid_bins_remain_cap > 0] = priorities_valid # Ensure we only assign to valid bins

    return priorities
```
