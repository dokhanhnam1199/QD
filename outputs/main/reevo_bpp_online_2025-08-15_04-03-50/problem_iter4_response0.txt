```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a refined strategy.

    This strategy prioritizes bins that offer a "tight fit" for the item,
    meaning the remaining capacity after insertion is minimized. It achieves this
    by assigning a priority score based on the inverse of (1 + slack), where slack
    is the difference between the bin's remaining capacity and the item's size.

    To further balance this with the "fullness" of bins (prioritizing bins that
    are already closer to full, i.e., have less remaining capacity overall), a small
    secondary score is added. This secondary score is proportional to the negative
    of the bin's remaining capacity, effectively giving a slight preference to
    smaller bins when tight fits are comparable.

    A small amount of noise is added to the priority scores to introduce a stochastic
    element, promoting exploration and helping to escape local optima, as suggested
    by the "balance with random exploration for robustness" aspect of the reflection.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins where the item can fit
    fit_mask = bins_remain_cap >= item

    if not np.any(fit_mask):
        return priorities

    # Calculate slack for bins that can fit the item
    # Slack = remaining_capacity - item_size
    slack = bins_remain_cap[fit_mask] - item

    # Primary scoring: Favor tight fits by using 1 / (1 + slack).
    # This assigns higher scores to bins with smaller positive slack.
    tight_fit_scores = 1.0 / (1.0 + slack)

    # Secondary scoring: Favor "fuller" bins (those with less initial remaining capacity).
    # We use a small negative term proportional to the bin's remaining capacity.
    # Maximizing this term means minimizing bins_remain_cap for fitting bins.
    # The small multiplier ensures tight fit is primary.
    fullness_scores = -0.1 * bins_remain_cap[fit_mask]

    # Combine scores
    combined_scores = tight_fit_scores + fullness_scores

    # Add a small amount of random noise to encourage exploration.
    # This helps to break ties and explore different packing configurations.
    noise = np.random.normal(0, 0.01, size=combined_scores.shape)
    priorities[fit_mask] = combined_scores + noise

    # Normalize priorities so they sum to 1 over the fittable bins.
    # This converts scores into probabilities if using a probabilistic selection method.
    # If deterministic selection (e.g., argmax) is used, normalization isn't strictly necessary
    # but can help in interpreting relative preferences.
    current_priorities = priorities[fit_mask]
    if np.any(current_priorities):
        # Ensure no division by zero if all priorities are zero (though unlikely with noise)
        sum_priorities = np.sum(current_priorities)
        if sum_priorities > 0:
            priorities[fit_mask] = current_priorities / sum_priorities
        else:
            # If for some reason all priorities are non-positive, assign equal probability
            # to all fittable bins.
            priorities[fit_mask] = 1.0 / len(current_priorities) if len(current_priorities) > 0 else 0

    return priorities
```
