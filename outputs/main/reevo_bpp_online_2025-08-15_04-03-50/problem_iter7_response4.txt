```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using an enhanced 'Almost Full Fit' strategy.

    This strategy prioritizes bins that fit the item tightly, aiming to minimize
    remaining capacity after packing. It slightly penalizes bins with very large
    remaining capacities even if they can fit the item, and gently penalizes
    bins that would become extremely full (very close to zero remaining capacity)
    to encourage slightly more open bins if tightness is otherwise equal.
    The core idea is to favor bins that are neither too empty nor too full,
    but rather "just right" to fit the item.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins where the item can fit
    fit_mask = bins_remain_cap >= item

    # Calculate the remaining capacity if the item is placed in each fitting bin
    potential_remaining_cap = bins_remain_cap[fit_mask] - item
    fitting_bins_indices = np.where(fit_mask)[0]

    # Strategy: Prioritize bins with small non-negative remaining capacity (tight fits).
    # We want to assign higher scores to smaller values of `potential_remaining_cap`.
    # A common approach is to use the inverse.
    # To avoid division by zero and to provide a smooth curve: 1 / (1 + slack)
    # This assigns 1.0 to perfect fits (slack=0), lower values for larger slacks.

    # However, the reflection suggests penalizing large gaps gently and balancing efficiency with robustness.
    # Let's consider the "slack": slack = bins_remain_cap - item.
    # Smaller slack is generally better for "almost full".

    # To prioritize tight fits and fuller bins, we want to maximize the "fullness"
    # after packing. This means minimizing `potential_remaining_cap`.
    # Let's use `-(potential_remaining_cap)` as a base score.
    # A bin that ends up with -0.1 remaining capacity (overfilled) is worse than one that ends up with 0.0.
    # But we only consider bins where `item <= bins_remain_cap`.

    # Refined strategy:
    # 1. Prioritize bins that fit the item.
    # 2. Among fitting bins, prioritize those with smaller slack (`bins_remain_cap - item`).
    #    This means `potential_remaining_cap` should be as close to zero as possible.
    # 3. To avoid very large gaps being penalized too much, and to avoid very tight bins
    #    being overly favored if they are extremely small, we can introduce a gentle penalty
    #    for very large remaining capacities (large slack) and a slight bias for moderate fullness.

    # Let's use a score that peaks for a "just right" slack, but favors smaller slacks overall.
    # Consider a function that is high for slack near 0, and decreases as slack increases.
    # A Gaussian-like or logistic function could work, but for simplicity, let's stick to
    # inverse relationships with adjustments.

    # Primary scoring: Minimize `potential_remaining_cap`.
    # So, maximize `-potential_remaining_cap`.
    # Let's use `-potential_remaining_cap` directly, which favors bins that will be most full.
    # This is a direct "Best Fit" interpretation, which is related to "Almost Full Fit".

    # To "gently penalize large gaps":
    # If slack is very large, the priority should be lower.
    # `1.0 / (1.0 + slack)` does this. A slack of 10 gives ~0.09, slack of 100 gives ~0.01.

    # To ensure the "almost full" aspect, we want smaller slack values to be more preferred.
    # The `1.0 / (1.0 + slack)` function already does this.
    # Slack = 0  => Priority = 1.0
    # Slack = 1  => Priority = 0.5
    # Slack = 2  => Priority = 0.33

    # Reflection point: "Penalize large gaps gently." and "Prioritize tight fits and fuller bins."
    # The `1.0 / (1.0 + slack)` is a good balance. It strongly favors tight fits (slack near 0)
    # and gently reduces priority as slack increases.

    # Let's try a slightly modified score that emphasizes bins that become *very* full,
    # by slightly amplifying the negative remaining capacity.
    # The existing `1.0 / (1.0 + slack)` is a good baseline for favoring smaller slacks.

    # To add a nuance: what if a bin has capacity 100 and item is 10 (slack 90) vs.
    # capacity 12 and item is 10 (slack 2)? Both fit. `1/(1+90)` vs `1/(1+2)`.
    # The second bin is strongly preferred. This seems reasonable.

    # Let's ensure that bins with zero remaining capacity after fitting (perfect fit)
    # get the highest priority.
    # The current `1.0 / (1.0 + slack)` handles slack=0 by giving priority 1.0.

    # To ensure "fuller bins" are prioritized if slacks are comparable,
    # we can add a small bonus for bins that started with more capacity,
    # but this might contradict "tight fits".

    # Let's refine the score slightly: use `1 / (epsilon + slack)` where epsilon is small.
    # This still favors small slack.
    # Perhaps a score that is sensitive to the *absolute* remaining capacity after placement?
    # Maximize `-potential_remaining_cap`.
    # If potential_remaining_cap = 0, score = 0.
    # If potential_remaining_cap = 1, score = -1.
    # If potential_remaining_cap = 5, score = -5.
    # This means we prefer bins that become most full (closest to 0 remaining).

    # Consider `1 - (potential_remaining_cap / BIN_CAPACITY)` or similar normalized approaches.
    # This is getting complex. Let's keep it simple and effective.

    # The `1.0 / (1.0 + slack)` approach seems robust and directly addresses
    # prioritizing tight fits (small slack).

    # Let's consider the reflection again: "Prioritize tight fits and fuller bins."
    # Tight fit = small slack. Fuller bins = smaller `potential_remaining_cap`.
    # These are mostly aligned.
    # "Penalize large gaps gently." `1 / (1 + slack)` does this.
    # "Balance efficiency with robustness through simple, tunable scoring."

    # Let's slightly modify `1.0 / (1.0 + slack)` to give a bit more emphasis to
    # *very* small slacks.
    # We can use a non-linear transformation.
    # For example, `exp(-k * slack)` where k is a tuning parameter.
    # Or, `1.0 / (1.0 + slack**p)` where p > 1.
    # Let's use `p=1.5` to give more weight to smaller slacks.

    slack_values = bins_remain_cap[fit_mask] - item
    priorities[fitting_bins_indices] = 1.0 / (1.0 + slack_values**1.5)

    # This gives:
    # Slack = 0   => Priority = 1.0 / (1.0 + 0^1.5) = 1.0
    # Slack = 1   => Priority = 1.0 / (1.0 + 1^1.5) = 0.5
    # Slack = 2   => Priority = 1.0 / (1.0 + 2^1.5) = 1.0 / (1.0 + 2.828) approx 0.26
    # Slack = 0.5 => Priority = 1.0 / (1.0 + 0.5^1.5) = 1.0 / (1.0 + 0.707) approx 0.58

    # This emphasizes smaller slacks more than `1/(1+slack)`.
    # It still penalizes large gaps gently and prioritizes tight fits.
    # The power `1.5` is tunable.

    # Consider an alternative: maximize `-(potential_remaining_cap)`.
    # This would favor bins that end up with capacity closest to zero.
    # Example:
    # Bin A: capacity 5, item 3 -> potential_remaining_cap = 2, score = -2
    # Bin B: capacity 4, item 3 -> potential_remaining_cap = 1, score = -1
    # Bin C: capacity 3, item 3 -> potential_remaining_cap = 0, score = 0
    # This favors Bin C (perfect fit), then B, then A. This is "Best Fit".

    # The prompt for "Almost Full Fit" usually implies minimizing slack.
    # The `1 / (1 + slack**p)` approach is a good way to do this while being robust.

    # To further align with "fuller bins", let's consider the actual remaining capacity after item placement.
    # Let's try a combined score:
    # Priority = (1 - slack_norm) + (1 - original_capacity_norm)
    # where slack_norm = slack / max_slack, etc. This gets complicated.

    # Let's stick to the `1 / (1 + slack**p)` as it directly addresses the prioritized properties.
    # It's simple, tunable (via `p`), prioritizes small slacks, and penalizes large slacks gently.

    return priorities
```
