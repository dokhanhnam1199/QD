```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a refined First Fit strategy.

    This heuristic prioritizes bins that can accommodate the item and have a remaining capacity
    that is "just enough" or slightly larger than the item. This aims to leave larger gaps in
    other bins for potentially larger future items, a common strategy in First Fit variants.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Only consider bins that can actually fit the item
    suitable_bins_mask = bins_remain_cap >= item

    # For suitable bins, calculate priority.
    # A bin with remaining capacity slightly larger than the item gets a higher priority.
    # We can achieve this by looking at the difference (remaining_capacity - item).
    # A smaller positive difference is preferred.
    # We invert this difference to make smaller positive differences have higher priority.
    # To handle bins that are exactly the right fit (difference = 0), we can add a small epsilon
    # or simply handle the zero case.
    # Let's use a score that rewards fitting the item as snugly as possible.
    # A bin with remaining_capacity = item + delta, where delta is small and positive, is good.
    # We can calculate (remaining_capacity - item). A smaller non-negative value is good.
    # To turn this into a higher priority score, we can do something like 1 / (1 + diff).
    # Or, we can use the negative of the difference, and add a large constant to ensure
    # positive scores for fitting bins.

    suitable_bin_capacities = bins_remain_cap[suitable_bins_mask]
    differences = suitable_bin_capacities - item

    # Priority: higher for smaller non-negative differences
    # We can map differences to priorities. For example, differences of 0 are most preferred.
    # Differences slightly larger than 0 are next most preferred.
    # Using the negative difference, and a large offset to keep priorities positive.
    # A large offset ensures that even if differences are large negative (which won't happen due to mask),
    # the priority is still somewhat meaningful. The key is the relative ordering for suitable bins.

    # Example mapping:
    # diff = 0   -> priority ~ MAX_PRIORITY
    # diff = 0.1 -> priority ~ MAX_PRIORITY - 0.1
    # diff = 1.0 -> priority ~ MAX_PRIORITY - 1.0

    # Let's set a base priority for fitting bins and reduce it based on the "waste" if the item fits.
    # If item fits exactly, remaining_cap - item = 0.
    # If item fits with some room, remaining_cap - item > 0.
    # The goal is to minimize remaining_cap - item for suitable bins.

    # Priority = 1 / (1 + difference) might work, but it gives very low priority to bins with
    # larger remaining capacities, even if they fit. We want to favor those that fit "best".

    # Let's assign a high base priority to any bin that can fit the item, and then
    # give a bonus based on how tightly it fits.
    base_priority_for_fitting_bins = 1000.0
    # A smaller "slack" (remaining_cap - item) should result in a higher bonus.
    # We can use the negative of the slack as a bonus, so smaller slack is a larger negative slack,
    # which when negated becomes a larger positive bonus.
    bonus_for_tight_fit = -differences

    # Assign priorities to suitable bins
    priorities[suitable_bins_mask] = base_priority_for_fitting_bins + bonus_for_tight_fit

    # Note: This heuristic might be overly aggressive in trying to find the "perfect" fit
    # for every item, potentially leading to fragmentation if not carefully tuned or if
    # the definition of "tight fit" is too strict. However, it aims to be more intelligent
    # than a simple "can fit" by considering the degree of fit.
    # An alternative could be: priority = 1 / (item + epsilon) if bin_remain_cap[i] >= item else 0
    # to prioritize bins that have more capacity left *after* placing the item.

    # Let's refine it: prioritize bins where the remaining capacity is closest to the item size.
    # We want `bins_remain_cap[i] - item` to be small and non-negative.
    # The smaller this value, the higher the priority.
    # For bins where `bins_remain_cap[i] < item`, the priority is 0.

    # Calculate the absolute difference from being a perfect fit, for suitable bins.
    # We want to minimize this difference.
    # abs_diff_from_perfect_fit = np.abs(bins_remain_cap[suitable_bins_mask] - item)
    # For bins that can fit, the priority should be inversely proportional to this difference.
    # A small difference means high priority.

    # Let's re-think: First Fit's strength is simplicity and quick decision.
    # A priority function should still reflect that.
    # What if we give a higher priority to bins that are "just large enough" or "slightly too large"?
    # This is what v2 tried to do.

    # Let's try another approach that emphasizes "best fit" within the First Fit paradigm.
    # Prioritize bins that have *just enough* capacity.
    # This means bins where `bins_remain_cap[i]` is between `item` and `item + margin` for some small `margin`.
    # Bins that are much larger might be better saved for larger items.

    # For bins that can fit the item:
    # Priority = 1 if bin_remain_cap[i] == item
    # Priority = 0.9 if item < bin_remain_cap[i] <= item + epsilon
    # Priority = 0.8 if item + epsilon < bin_remain_cap[i] <= item + 2*epsilon
    # ... and so on, decreasing priority as remaining capacity increases.

    # Let's simplify: give highest priority to bins that fit the item exactly.
    # Then, progressively lower priority for bins that fit with more "slack".
    # Let's define "slack" as `bins_remain_cap[i] - item`.
    # We want to minimize slack.

    # Assign a base priority to all bins that can fit.
    # For those that fit, add a penalty based on the slack. The smaller the slack, the less penalty (higher priority).
    base_priority = 1.0  # A default for any bin that *could* fit if we only cared about fitting
    penalty_scale = 0.1 # Controls how quickly priority drops with slack

    for i in range(len(bins_remain_cap)):
        if bins_remain_cap[i] >= item:
            slack = bins_remain_cap[i] - item
            # We want smaller slack to mean higher priority.
            # So, priority is inversely related to slack.
            # A simple way is: base_priority - slack * penalty_scale
            # This gives higher priority to bins with smaller remaining capacity *after* placing the item.
            priorities[i] = base_priority - slack * penalty_scale
            # Ensure priorities are not negative if slack is very large (though unlikely to be chosen anyway)
            priorities[i] = max(priorities[i], 0.0)
        else:
            priorities[i] = 0.0 # Cannot fit, so zero priority

    # This strategy prioritizes bins that leave the least remaining capacity after placing the item.
    # This is a common "best fit" inspired idea adapted to a priority queue context.
    # The "First Fit" aspect is implicit in that we consider *all* bins currently open.

    # Consider the "first fit" intuition more directly: place it in the first bin it fits.
    # The priority here is about *which* of the available bins that fit should be preferred.
    # This v2 attempts to "smartly" pick among the fitting bins.

    # Let's consider a scenario:
    # bins_remain_cap = [10, 5, 8, 2]
    # item = 3
    #
    # Bin 0: fits (10 >= 3). Slack = 10 - 3 = 7. Priority = 1.0 - 7*0.1 = 0.3
    # Bin 1: fits (5 >= 3). Slack = 5 - 3 = 2. Priority = 1.0 - 2*0.1 = 0.8
    # Bin 2: fits (8 >= 3). Slack = 8 - 3 = 5. Priority = 1.0 - 5*0.1 = 0.5
    # Bin 3: cannot fit (2 < 3). Priority = 0.0
    #
    # Priorities: [0.3, 0.8, 0.5, 0.0]
    # Max priority is for Bin 1, which has the smallest remaining capacity that still fits the item.

    # This heuristic implements a "best fit" type of selection among available bins.
    # If the goal is strictly First Fit (pick the first one encountered), then a priority function
    # doesn't make sense unless we're re-ordering the bins *before* processing.
    # Given the prompt asks for a priority function to select a bin, it implies we are choosing
    # among valid bins.

    # Let's add a small epsilon to avoid zero slack getting the same priority as slack close to zero.
    # For better discrimination.
    epsilon_for_slack = 0.01
    priorities_refined = np.zeros_like(bins_remain_cap, dtype=float)
    for i in range(len(bins_remain_cap)):
        if bins_remain_cap[i] >= item:
            slack = bins_remain_cap[i] - item
            # Higher priority for smaller slack.
            # Add 1 to slack to ensure a non-zero denominator and that perfect fit has high priority.
            # The smaller slack, the larger this priority value will be.
            # Add a small value to distinguish between identical slacks if needed, but np.maximum helps.
            priorities_refined[i] = 1.0 / (slack + epsilon_for_slack)
        else:
            priorities_refined[i] = 0.0

    # Example with refined:
    # bins_remain_cap = [10, 5, 8, 2]
    # item = 3
    #
    # Bin 0: slack = 7. Priority = 1.0 / (7 + 0.01) = 1.0 / 7.01 ~ 0.142
    # Bin 1: slack = 2. Priority = 1.0 / (2 + 0.01) = 1.0 / 2.01 ~ 0.497
    # Bin 2: slack = 5. Priority = 1.0 / (5 + 0.01) = 1.0 / 5.01 ~ 0.199
    # Bin 3: Priority = 0.0
    #
    # Priorities: [0.142, 0.497, 0.199, 0.0]
    # This also prioritizes the bin that fits most snugly.

    # This version is a good candidate for `priority_v2` as it refines the strategy.
    return priorities_refined
```
