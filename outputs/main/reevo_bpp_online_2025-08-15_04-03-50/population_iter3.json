[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a strategy that prioritizes bins that have *just enough* space, and among those, favors fuller bins.\n\n    This strategy is a variation of Best Fit, aiming to minimize wasted space.\n    It prioritizes bins where `bins_remain_cap - item` is smallest and non-negative.\n    A secondary preference is given to bins that are fuller (have less remaining capacity)\n    among those that can fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the item\n        will have a priority of 0.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Create a boolean mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the \"slack\" or \"waste\"\n    # This is the remaining capacity after placing the item.\n    slack = bins_remain_cap[can_fit_mask] - item\n\n    # To prioritize bins with the least slack (best fit), we can use the\n    # inverse of slack. A smaller slack should result in a higher priority.\n    # Add a small epsilon to avoid division by zero if slack is 0.\n    # Higher priority for smaller slack values.\n    # We can use `1.0 / (slack + epsilon)` or `-slack`.\n    # Using `-slack` directly favors bins with minimal non-negative slack.\n    # For example, slack of 0 gets priority 0, slack of 1 gets -1, slack of 5 gets -5.\n    # We want to maximize this value, so we use `-slack`.\n\n    # To incorporate the preference for fuller bins (which is implied by smaller\n    # `bins_remain_cap` among fitting bins), we can combine this with the slack.\n    # A simple approach is to subtract the original remaining capacity from the\n    # inverse slack, or simply use a combination.\n\n    # Let's prioritize bins with minimal slack.\n    # If slack is 0, priority should be highest.\n    # If slack is positive, priority should be lower.\n    # We can map slack to priority. A common mapping for \"minimize X\" to \"maximize Y\" is Y = -X or Y = 1/(1+X).\n    # Using `-slack` gives higher values for smaller slacks.\n    # We also want to prefer bins that were initially fuller (smaller bins_remain_cap).\n    # This means that among bins with the same slack, the one with the smaller original\n    # `bins_remain_cap` should be preferred.\n\n    # Let's consider the inverse of the remaining capacity as a secondary sorting key.\n    # A higher inverse remaining capacity (meaning lower original remaining capacity, i.e. fuller bin) is better.\n    # So, for fitting bins, we want to maximize: `priority = -slack + C * (1 / bins_remain_cap[can_fit_mask])`\n    # where C is a weighting factor. A simpler approach is to rank them based on slack first,\n    # and then remaining capacity.\n\n    # A common heuristic for Best Fit is to sort by remaining capacity and pick the first one.\n    # For priority, we want the bin with the smallest `bins_remain_cap - item` to have the highest score.\n    # This means `bins_remain_cap - item` should be minimized.\n    # So, we can use `- (bins_remain_cap - item)` as a primary score.\n    # To break ties, or to add a preference for fuller bins, we can add a term that\n    # is proportional to `1.0 / bins_remain_cap`.\n\n    # Let's try to prioritize based on minimal slack first.\n    # A bin with slack 0 is best.\n    # A bin with slack 1 is second best.\n    # ...\n    # For bins with the same slack, the one with less remaining capacity (fuller) is better.\n    # This implies we want to maximize `-(bins_remain_cap[i] - item)` and secondarily maximize `bins_remain_cap[i]`.\n\n    # A common approach for \"best fit\" is to aim for a score where smaller `bins_remain_cap - item` are better.\n    # So, we can use a score like `1.0 / (1.0 + (bins_remain_cap[can_fit_mask] - item))`.\n    # This gives a value between 0 and 1, with 1 for a perfect fit (slack=0).\n\n    # To add a preference for fuller bins among those with the same slack,\n    # we can add a secondary term that increases with decreasing `bins_remain_cap`.\n    # For example, `1.0 / (1.0 + slack)` could be the primary score.\n    # A secondary score could be `1.0 / bins_remain_cap`.\n    # Combined: `priority = 1.0 / (1.0 + slack) + weight * (1.0 / bins_remain_cap[can_fit_mask])`\n\n    # However, the reflection implies prioritizing fuller bins directly.\n    # A simple way to prioritize fuller bins is to use the inverse of their remaining capacity.\n    # `1.0 / bins_remain_cap[can_fit_mask]` gives higher scores to fuller bins.\n    # But this doesn't directly address the \"just enough space\" aspect of Best Fit.\n\n    # Let's refine the Best Fit idea: we want the smallest *positive* slack.\n    # So, `slack = bins_remain_cap[can_fit_mask] - item`.\n    # We want to minimize `slack`.\n    # For priority, we want to maximize a function of `slack`.\n    # A simple way is `priorities[can_fit_mask] = -slack`.\n    # This means slack 0 -> priority 0, slack 1 -> priority -1, slack 5 -> priority -5.\n    # Higher priority for smaller slack.\n\n    # Now, consider the \"preference for fuller bins\". This means that among bins\n    # with the same slack, we prefer the one that was more full to begin with.\n    # So if `bins_remain_cap[i] - item == bins_remain_cap[j] - item`, and\n    # `bins_remain_cap[i] < bins_remain_cap[j]`, then bin `i` is preferred.\n    # This implies that `bins_remain_cap[i]` itself should contribute to higher priority.\n\n    # We can combine these: maximize `-slack` and maximize `bins_remain_cap[can_fit_mask]`.\n    # A potential priority score could be: `priority = -(bins_remain_cap[can_fit_mask] - item) + alpha * bins_remain_cap[can_fit_mask]`\n    # where `alpha` is a small positive weight to ensure slack is primary.\n\n    # Let's try a simpler, more direct approach that captures both aspects.\n    # Prioritize bins with the smallest positive `slack`.\n    # Among those with the same slack, prioritize bins with the smallest `bins_remain_cap`.\n\n    # One way to achieve this is to use a composite score.\n    # The value `bins_remain_cap[can_fit_mask] - item` should be minimized.\n    # The value `bins_remain_cap[can_fit_mask]` should also be minimized (to favor fuller bins).\n    # We can create a composite key for sorting: `(slack, bins_remain_cap[can_fit_mask])`.\n    # For priority, we want to maximize this composite key, but in reverse.\n    # So, we want to maximize `(-slack, -bins_remain_cap[can_fit_mask])`.\n\n    # A direct mapping to a single priority score:\n    # We want to maximize `1.0 / (1.0 + slack)` for best fit.\n    # To favor fuller bins, we can add a term like `1.0 / bins_remain_cap`.\n    # Let's use a scaling factor to balance these two objectives.\n\n    # A common technique for multiple objectives is to scale and sum.\n    # Objective 1: Minimize slack (maximize 1 / (1 + slack))\n    # Objective 2: Minimize bins_remain_cap (maximize 1 / bins_remain_cap)\n\n    # Let's normalize the slack and remaining capacities first, or use a well-behaved function.\n    # Using `1.0 / (1.0 + slack)` maps slack [0, inf) to priority (1, 0].\n    # Using `1.0 / bins_remain_cap` maps remaining_cap [item, inf) to priority (1/item, 0).\n\n    # Let's combine them directly:\n    # Higher priority for smaller slack AND smaller remaining_capacity.\n    # We can use a lexicographical ordering effect by careful function design.\n    # `priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] - item + 1e-9) * (1.0 / bins_remain_cap[can_fit_mask] + 1e-9)`\n    # This might over-prioritize very small remaining capacities regardless of slack.\n\n    # A more robust approach for \"just enough space\" (Best Fit):\n    # Prioritize bins where `bins_remain_cap - item` is minimized.\n    # Let `score_bf = -(bins_remain_cap[can_fit_mask] - item)`. Maximize this.\n    # For tie-breaking (prefer fuller bins), we want to maximize `bins_remain_cap[can_fit_mask]`.\n    # So, we want to maximize `score_bf` and secondarily `bins_remain_cap`.\n    # This can be achieved by `priority = score_bf + alpha * bins_remain_cap`.\n    # A suitable `alpha` would be small enough that `score_bf` dominates for same slack.\n\n    # Let's use a large multiplier for the secondary criterion to make it effective.\n    # Consider the remaining capacities themselves.\n    # We want to pick the bin with minimum `bins_remain_cap` that fits the item.\n    # If multiple bins have the same minimum `bins_remain_cap` that fits, pick the one with the smallest slack.\n    # This is a subtle ordering.\n\n    # The reflection states: \"prioritize fuller bins by inverting remaining capacity for better fit.\"\n    # This implies that if two bins can fit an item, the one that is *more full* is preferred.\n    # This sounds like a variation of First Fit Decreasing or Best Fit.\n    # \"Better fit\" usually means less waste.\n\n    # Let's reconsider the goal: \"prioritize bins that have *just enough* space, and among those, favors fuller bins.\"\n    # \"Just enough space\" implies minimizing `bins_remain_cap - item`.\n    # \"Favors fuller bins\" implies minimizing `bins_remain_cap`.\n\n    # So we want to minimize two values:\n    # 1. `slack = bins_remain_cap[can_fit_mask] - item`\n    # 2. `bins_remain_cap[can_fit_mask]`\n\n    # To maximize priority, we want to maximize functions of these.\n    # Maximize `-slack` and maximize `-bins_remain_cap`.\n    # A common approach is to combine them, e.g., `priority = -slack - alpha * bins_remain_cap`.\n    # Or, more directly: `priority = -(slack + alpha * bins_remain_cap)`.\n    # Here, `slack` is minimized first, and then `bins_remain_cap` is minimized.\n\n    # Let's assign a score that is inversely proportional to slack, and then inversely proportional to remaining capacity.\n    # `score1 = 1.0 / (slack + epsilon)`\n    # `score2 = 1.0 / bins_remain_cap[can_fit_mask]`\n    # `priorities[can_fit_mask] = score1 + weight * score2`\n\n    # Let's try to make the slack minimization dominant.\n    # If slack is 0, priority should be high.\n    # If slack is 0 and bin_rem_cap is 5, priority is X.\n    # If slack is 0 and bin_rem_cap is 10, priority is Y, where Y < X.\n    # If slack is 1, priority should be lower than X and Y.\n\n    # Let's use a score that heavily penalizes slack, and then uses remaining capacity.\n    # `priorities[can_fit_mask] = 1.0 / (1.0 + slack) - alpha * bins_remain_cap[can_fit_mask]`\n    # This would prioritize smaller slack, but then penalize larger remaining capacities.\n    # This sounds correct for \"just enough space\" and then \"fuller bins\".\n\n    # Let's use a small `alpha` to ensure the slack is the primary driver.\n    # A common strategy is to use `1.0 / (1.0 + slack)` and `1.0 / bins_remain_cap`.\n    # Combining them: `priorities[can_fit_mask] = 1.0 / (1.0 + slack) + 0.1 * (1.0 / bins_remain_cap[can_fit_mask])`\n    # The `0.1` is an arbitrary weight.\n\n    # A simpler interpretation of \"prioritize fuller bins by inverting remaining capacity\" might be:\n    # For best fit, we want `bins_remain_cap - item` to be minimal.\n    # So, prioritize bins with `bins_remain_cap` closest to `item`.\n    # Let `diff = bins_remain_cap[can_fit_mask] - item`. We want to minimize `diff`.\n    # The priority should be high for small `diff`.\n    # So, `priority = 1.0 / (diff + epsilon)`. This is Best Fit.\n\n    # Now, \"favors fuller bins\". This means, if `diff` is the same for two bins,\n    # the one with smaller `bins_remain_cap` is preferred.\n    # This implies that `bins_remain_cap` itself should positively contribute to priority.\n    # So, we want to maximize `1.0 / (diff + epsilon)` AND maximize `bins_remain_cap`.\n    # This is counter-intuitive. If fuller bins are preferred, it means smaller `bins_remain_cap`.\n    # So, we want to maximize `1.0 / (diff + epsilon)` AND maximize `(1.0 / bins_remain_cap)`.\n\n    # Let's try a direct mapping:\n    # We want to minimize `bins_remain_cap - item`. Let this be `waste`.\n    # We want to minimize `bins_remain_cap`.\n    # So, the ideal bin has small `waste` and small `bins_remain_cap`.\n    # For priority, we want to maximize `1.0 / (waste + epsilon)` and `1.0 / bins_remain_cap`.\n\n    # Combining: `priorities[can_fit_mask] = (1.0 / (slack + 1e-9)) * (1.0 / bins_remain_cap[can_fit_mask] + 1e-9)`\n    # This might scale too aggressively.\n\n    # Let's stick to the idea of minimizing `slack` AND `bins_remain_cap`.\n    # Maximize `-slack` and maximize `-bins_remain_cap`.\n    # Priority = `-slack - alpha * bins_remain_cap`\n\n    # Let's assign priorities based on `-(slack)` and then `-bins_remain_cap`.\n    # `priorities[can_fit_mask] = -(slack + bins_remain_cap[can_fit_mask])`\n    # This prioritizes bins with smaller `slack + bins_remain_cap`.\n    # If slack is 0, and remaining_cap is 5, sum is 5. Priority -5.\n    # If slack is 0, and remaining_cap is 10, sum is 10. Priority -10.\n    # This favors fuller bins when slack is the same.\n\n    # However, the prompt for v1 was \"preference for fuller bins\" by inverting remaining capacity.\n    # This usually implies something like `1.0 / bins_remain_cap`.\n    # So, the reflection means the *priority* should be higher for fuller bins.\n\n    # Let's try a composite score that directly favors smaller `slack` AND smaller `bins_remain_cap`.\n    # We can make `slack` the primary factor, and `bins_remain_cap` the secondary.\n    #\n    # For Best Fit, we want to minimize `slack = bins_remain_cap - item`.\n    # So, prioritize by `1.0 / (slack + epsilon)`.\n    #\n    # For preferring fuller bins, we want to minimize `bins_remain_cap`.\n    # So, prioritize by `1.0 / bins_remain_cap`.\n    #\n    # Combining these:\n    # We want to maximize `f(slack, bins_remain_cap)` where `f` increases with `1/slack` and `1/bins_remain_cap`.\n    # A simple additive approach:\n    # `priorities[can_fit_mask] = (1.0 / (slack + 1e-9)) + (1.0 / bins_remain_cap[can_fit_mask] + 1e-9)`\n    # This gives higher priority to bins with small slack AND small remaining capacity.\n    # The `+ 1e-9` in the second term is to avoid division by zero if the bin capacity itself is 0 (though unlikely in BPP).\n    # The first term `1.0 / (slack + 1e-9)` ensures Best Fit logic (smaller slack is better).\n    # The second term `1.0 / bins_remain_cap[can_fit_mask]` adds the preference for fuller bins.\n\n    priorities[can_fit_mask] = (1.0 / (slack + 1e-9)) + (1.0 / (bins_remain_cap[can_fit_mask] + 1e-9))\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 82.0447025077789,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Minimum Remaining Capacity strategy.\n\n    This strategy prioritizes bins that will have the least remaining capacity\n    after the item is placed, aiming to fill bins as tightly as possible.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity *after* placing the item.\n    # We want to prioritize bins with the *minimum* remaining capacity.\n    # To achieve this with a maximization-based priority system (higher score is better),\n    # we can use the negative of the remaining capacity as the score.\n    # E.g., if remaining capacities after placement are [2, 1, 5], we want to pick the one with 1.\n    # Scores would be [-2, -1, -5]. The maximum score is -1.\n    potential_remaining_cap = bins_remain_cap[fit_mask] - item\n\n    # Assign scores: negative of the remaining capacity.\n    # Higher value (less negative) means more remaining capacity, lower value (more negative) means less remaining capacity.\n    # Thus, to pick the bin with the *least* remaining capacity, we want the most negative score.\n    # So, we want to maximize `potential_remaining_cap` directly, if we consider the definition of \"minimum remaining capacity\" as the target.\n    # However, the problem statement asks for \"highest priority score\". If higher score means better,\n    # and we want minimum remaining capacity, we need to map minimum remaining capacity to a maximum score.\n    # This can be done by `1 / (1 + remaining_capacity)` as in v1, or `MAX_CAP - remaining_capacity`.\n    # A simple inversion like `-remaining_capacity` works if remaining capacities are positive.\n    # But if we have capacities [10, 20, 30] and item=5, remaining are [5, 15, 25]. We want 5.\n    # Using `-remaining_capacity`: [-5, -15, -25]. Max score is -5. This selects the bin with 5 remaining.\n    # This seems correct for \"minimum remaining capacity\".\n\n    # Let's refine: The goal is to minimize `bins_remain_cap - item`.\n    # If we use `bins_remain_cap - item` directly as the score, we'd pick the bin with the most remaining capacity.\n    # If we use `-(bins_remain_cap - item)`, we'd pick the bin with the least remaining capacity.\n    # This interpretation aligns with the \"tightest fit\" goal.\n\n    # So, for bins that fit, the priority is the negative of the remaining capacity after placement.\n    priorities[fit_mask] = -potential_remaining_cap\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 22.458839376460833,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using the Almost Full Fit strategy.\n\n    The strategy prioritizes bins that will have the smallest remaining capacity\n    after the item is packed, provided the item fits. This aims to utilize bins\n    more completely, leaving larger, more flexible capacities in other bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    # Initialize priorities to a very low value (-infinity) for bins that cannot accommodate the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity *after* packing.\n    # We want to prioritize bins where this remaining capacity is minimized.\n    # A common way to map minimization to maximization of a score is to use the negative.\n    # So, for a bin `j` where `bins_remain_cap[j] >= item`, the priority score is\n    # `- (bins_remain_cap[j] - item)`.\n    # This means a smaller positive `bins_remain_cap[j] - item` will result in a\n    # less negative (i.e., higher) priority score.\n    # For example, if remaining capacities are [5, 3, 8] and item is 2:\n    # - Bin 0: fits, remaining cap = 5-2=3. Priority = -3.\n    # - Bin 1: fits, remaining cap = 3-2=1. Priority = -1.\n    # - Bin 2: fits, remaining cap = 8-2=6. Priority = -6.\n    # The highest priority is -1, corresponding to the bin with the smallest remaining capacity after packing.\n\n    if np.any(can_fit_mask):\n        remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n        # Assign the negative of the remaining capacity as the priority score.\n        priorities[can_fit_mask] = -remaining_after_fit\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 30.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy.\n\n    The Best Fit strategy aims to place the item in the bin that has the smallest\n    remaining capacity that is still large enough to accommodate the item.\n    This often leads to fuller bins, reducing wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Create a boolean mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit the item, calculate priority.\n    # The priority should be higher for bins with less remaining capacity\n    # (i.e., the 'tightest' fit).\n    # We can assign a priority inversely proportional to the difference\n    # between the bin's remaining capacity and the item's size.\n    # A smaller difference means a tighter fit, thus a higher priority.\n    # Add a small epsilon to avoid division by zero if remaining_capacity == item.\n    \n    # Calculate the difference: remaining_capacity - item_size\n    difference = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign higher priority to smaller differences.\n    # We can use 1 / (difference + epsilon) to achieve this.\n    # A larger difference will result in a smaller priority score.\n    priorities[can_fit_mask] = 1.0 / (difference + 1e-9)\n    \n    # Bins that cannot fit the item receive a priority of 0, as they are not viable options.\n    \n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a modified Best Fit Decreasing heuristic.\n\n    This heuristic prioritizes bins that can fit the item. Among the bins that can fit,\n    it assigns a higher priority to bins where the remaining capacity is closest to the item size\n    (i.e., the \"tightest fit\"). This is achieved by assigning a priority score that is the\n    inverse of the absolute difference between the bin's remaining capacity and the item size.\n    Bins that cannot accommodate the item are assigned a priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Identify bins that have enough remaining capacity for the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Initialize priorities to zero for all bins. Bins that cannot fit will retain a priority of 0.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate priorities only for bins that can fit the item\n    if np.any(can_fit_mask):\n        # Calculate the absolute difference between the remaining capacity and the item size for fitting bins.\n        # We want to prioritize bins where this difference is minimized (tightest fit).\n        diff = bins_remain_cap[can_fit_mask] - item\n\n        # Assign a priority score that is inversely proportional to the absolute difference.\n        # A smaller absolute difference means a tighter fit, hence a higher priority.\n        # We use `1.0 / (1.0 + abs(diff))` to ensure:\n        # 1. Division by zero is avoided (by adding 1.0).\n        # 2. A perfect fit (diff = 0) gets the highest possible priority (1.0).\n        # 3. As the difference increases, the priority decreases.\n        priorities[can_fit_mask] = 1.0 / (1.0 + np.abs(diff))\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 39.863137138648355,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid approach prioritizing fuller bins and then best fit.\n\n    This heuristic tries to pack the item into a bin that has just enough space\n    (Best Fit principle), but if multiple bins offer a similar \"tight fit\",\n    it prefers the one that is already fuller (smaller remaining capacity).\n    This can help in consolidating items and potentially opening up space in less full bins for future larger items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score indicates higher priority. Bins that cannot fit the item will have a priority of 0.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Create a boolean mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate priority\n    # We want to prioritize bins that have minimal remaining capacity after packing.\n    # This is the \"Best Fit\" principle.\n    # So, we want to maximize `-(bins_remain_cap - item)`, which means minimizing `bins_remain_cap - item`.\n    # A common way to map smaller positive values to higher priorities is using `1 / (1 + value)`.\n    # To further encourage fuller bins among those with similar fits, we can add a penalty\n    # proportional to the remaining capacity. A higher remaining capacity should result in a lower priority.\n    # We can achieve this by subtracting the `bins_remain_cap` from a large constant, or by\n    # dividing by `bins_remain_cap` (but carefully to avoid division by zero and to handle\n    # bins that are already very full).\n\n    # Let's combine the Best Fit idea (minimize waste) with a preference for fuller bins.\n    # Priority = (Preference for being full) * (Best Fit factor)\n    # A simple way to encode \"preference for being full\" is to use the inverse of the current remaining capacity.\n    # A higher `1/bins_remain_cap` means the bin is fuller.\n    # However, we need to be careful about bins that are *exactly* fitting or have very little space.\n\n    # Strategy:\n    # 1. Identify bins that can fit the item.\n    # 2. For these bins, calculate a score that is high when `bins_remain_cap - item` is small (Best Fit).\n    # 3. Also, make this score higher for bins that are already fuller (lower `bins_remain_cap`).\n\n    # Let's try a combined approach:\n    # Priority = (1.0 / (bins_remain_cap[can_fit_mask] - item + 1e-9)) * (bins_remain_cap[can_fit_mask])\n    # This would give higher priority to bins that are both a good fit and are already quite full.\n    # However, simply multiplying might not be ideal as it could over-prioritize very full bins that are not the best fit.\n\n    # A more robust approach for Best Fit is `1.0 / (1.0 + waste)`, where `waste = bins_remain_cap - item`.\n    # To incorporate the \"fuller bin\" preference, we can slightly penalize larger remaining capacities.\n    # Let's use `1.0 / (1.0 + waste) + penalty_for_emptiness`.\n    # The `penalty_for_emptiness` should be higher for bins with *more* remaining capacity.\n    # So, `penalty_for_emptiness` could be something like `C / bins_remain_cap`.\n    # The challenge is to balance these.\n\n    # Let's simplify: Prioritize bins that have the smallest remaining capacity after fitting the item.\n    # This is the core of Best Fit.\n    # `best_fit_score = 1.0 / (1.0 + (bins_remain_cap[can_fit_mask] - item))`\n    # To favor fuller bins, we can slightly amplify the priority for bins that are already more full.\n    # For example, we could add a term proportional to `1.0 / bins_remain_cap[can_fit_mask]`.\n\n    # Consider this: we want to minimize `bins_remain_cap - item`.\n    # Let `remaining_after_fit = bins_remain_cap[can_fit_mask] - item`.\n    # We want to pick the smallest `remaining_after_fit`.\n    # To make the fuller bins more appealing among ties, we can use their `bins_remain_cap` as a secondary sorting key.\n    # A direct priority could be a combination.\n    # Let's try prioritizing bins that are fuller. The fuller the bin, the higher the priority.\n    # This is the First Fit Decreasing (FFD) intuition for the *online* version.\n    # The `priority_v1` already does this to some extent by prioritizing bins with smaller remaining capacities.\n\n    # Let's refine `v1` to explicitly favor bins that are fuller, meaning smaller `bins_remain_cap`.\n    # So, if `bin_i` and `bin_j` can fit the item, and `bins_remain_cap[i] < bins_remain_cap[j]`,\n    # then `bin_i` should have higher priority.\n\n    # We can achieve this by multiplying the inverse of remaining capacity by the inverse of the residual capacity after placement.\n    # A bin that is fuller (smaller `bins_remain_cap`) gets a higher score.\n    # A bin that results in less waste (`bins_remain_cap - item` is small) gets a higher score.\n\n    # Let's use the reciprocal of the remaining capacity as a primary factor for \"fullness\".\n    # And the reciprocal of the residual capacity for \"best fit\".\n    # We want to maximize both.\n\n    # Let's prioritize bins that are already fuller.\n    # A simple heuristic for \"fullness\" is `1.0 / bins_remain_cap`.\n    # However, this gives very high priority to bins with very small capacities, which might not be the best fit.\n    # A common heuristic is to use the current remaining capacity to prioritize bins that are \"most full\" or have the least slack.\n    # Let's try to give higher priority to bins with smaller `bins_remain_cap` among those that fit.\n\n    # Simple approach: Directly use the inverse of the remaining capacity of the bin.\n    # This prioritizes bins that are currently fuller.\n    # `priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] + 1e-9)`\n    # This is effectively a \"First Fit\" heuristic if we iterate through bins.\n    # For a priority array, this would mean bins that are already more full (smaller remaining capacity) get higher priority.\n\n    # Let's refine `v1` to emphasize \"fullness\" more directly.\n    # `v1` prioritized `1.0 / (bins_remain_cap - item + 1e-9)`. This favors small waste.\n    # To favor fuller bins, we could also consider `1.0 / (bins_remain_cap + 1e-9)`.\n    # How to combine them? Summing or multiplying?\n\n    # Let's try prioritizing bins that have the smallest `bins_remain_cap` first, and among those with equal `bins_remain_cap`,\n    # pick the one with the smallest `bins_remain_cap - item`.\n    # This suggests a lexicographical sort, which is hard to encode directly in a single priority score unless carefully designed.\n\n    # Alternative: Focus on the \"slack\" or how much space is left.\n    # We want to minimize `bins_remain_cap - item`.\n    # A simple way to assign priority to smaller values is using `1.0 / (1.0 + value)`.\n    # Let's also add a term that favors fuller bins.\n    # `priority = 1.0 / (1.0 + (bins_remain_cap[can_fit_mask] - item)) + alpha * (1.0 / bins_remain_cap[can_fit_mask])`\n    # The `alpha` would control the trade-off. This can become complex.\n\n    # Let's revisit `v1`'s approach: `1.0 / (bins_remain_cap - item + 1e-9)`. This emphasizes minimal waste (Best Fit).\n    # To slightly favor fuller bins *when waste is similar*, we can add a small bonus based on current fullness.\n    # Or, a simpler interpretation of \"preference for fuller bins\" is to sort by `bins_remain_cap` first.\n    # So, among bins that can fit, pick the one with minimum `bins_remain_cap`.\n    # If there's a tie in `bins_remain_cap`, then pick the one with minimum `bins_remain_cap - item`.\n\n    # Let's stick to a single score that tries to capture both:\n    # A bin is good if it's almost full AND leaves little space.\n    # So, prioritize small `bins_remain_cap` AND small `bins_remain_cap - item`.\n    # This means prioritizing small `bins_remain_cap` is the primary goal, and then small `bins_remain_cap - item` as a tie-breaker.\n\n    # A single score that balances this could be:\n    # `priority = 1.0 / (bins_remain_cap[can_fit_mask] + 1e-9)` for fullness\n    # and `1.0 / (bins_remain_cap[can_fit_mask] - item + 1e-9)` for fit.\n    # Let's try to combine them.\n    # If we want to prioritize smaller `bins_remain_cap` and then smaller `bins_remain_cap - item`:\n    # `priority = (bins_remain_cap[can_fit_mask] * CONSTANT_FACTOR) + (bins_remain_cap[can_fit_mask] - item)`\n    # And we want to minimize this value. For a priority score, we want to maximize.\n    # So, `priority = - (bins_remain_cap[can_fit_mask] * CONSTANT_FACTOR + bins_remain_cap[can_fit_mask] - item)`\n    # This is getting complicated.\n\n    # Let's simplify the reflection: \"Prioritize fuller bins for better packing density.\"\n    # This implies that we want to select a bin such that `bins_remain_cap` is minimized.\n    # So, `1.0 / (bins_remain_cap + epsilon)` is a good candidate.\n    # Let's combine this with the best fit idea.\n    # The `v1` function focused on the *waste* (`bins_remain_cap - item`).\n    # The reflection is about prioritizing *fullness* (`bins_remain_cap`).\n\n    # So, let's prioritize bins that have the smallest current remaining capacity.\n    # `priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] + 1e-9)`\n    # This would favor bins that are already fuller.\n\n    # Let's consider what happens with an item of size 0.5 and bins with capacities [1.0, 0.6, 0.9].\n    # `bins_remain_cap` = [1.0, 0.6, 0.9]\n    # `item` = 0.5\n    # `can_fit_mask` = [True, True, True]\n\n    # `v0` (Best Fit):\n    # `potential_remaining_cap` = [0.5, 0.1, 0.4]\n    # `waste` = [0.5, 0.1, 0.4]\n    # `priorities` = [1/(1+0.5), 1/(1+0.1), 1/(1+0.4)] = [0.667, 0.909, 0.714]\n    # Max priority is for bin 1 (0.1 waste).\n\n    # `v1` (First Fit-ish / Prefer less remaining capacity after fit):\n    # `priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] - item + 1e-9)`\n    # `priorities` = [1/(1.0-0.5+1e-9), 1/(0.6-0.5+1e-9), 1/(0.9-0.5+1e-9)]\n    # `priorities` = [1/0.5, 1/0.1, 1/0.4] = [2.0, 10.0, 2.5]\n    # Max priority is for bin 1 (0.1 remaining capacity). This is also Best Fit.\n\n    # Reflection: \"Prioritize fuller bins for better packing density.\"\n    # This suggests that a bin with capacity 0.6 is \"fuller\" than a bin with capacity 1.0.\n    # So, we should prefer the bin with `bins_remain_cap = 0.6`.\n\n    # Let's try a heuristic that favors smaller `bins_remain_cap` directly.\n    # `priority = 1.0 / (bins_remain_cap[can_fit_mask] + 1e-9)`\n    # `priorities` = [1/1.0, 1/0.6, 1/0.9] = [1.0, 1.667, 1.111]\n    # Max priority is for bin 1 (0.6 remaining capacity). This prioritizes the fullest bin.\n\n    # How to combine \"fullest bin\" and \"best fit\"?\n    # If we use `priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] + 1e-9)`\n    # This prioritizes bin 1 (0.6 capacity). Let's see the waste: 0.6 - 0.5 = 0.1.\n    # What if we had another bin with capacity 0.7?\n    # `bins_remain_cap` = [1.0, 0.6, 0.9, 0.7]\n    # `item` = 0.5\n    # `can_fit_mask` = [True, True, True, True]\n    # Priorities for fullness: [1.0, 1.667, 1.111, 1.428] -> Bin 1 (0.6 capacity) is chosen. Waste = 0.1.\n    # Waste for bin 3 (0.7 capacity) = 0.7 - 0.5 = 0.2.\n    # Bin 1 is both the fullest and the best fit.\n\n    # What if we had a bin with capacity 0.55?\n    # `bins_remain_cap` = [1.0, 0.6, 0.9, 0.55]\n    # `item` = 0.5\n    # `can_fit_mask` = [True, True, True, True]\n    # Priorities for fullness: [1.0, 1.667, 1.111, 1.818] -> Bin 3 (0.55 capacity) is chosen. Waste = 0.05.\n    # Waste for bin 1 (0.6 capacity) = 0.1.\n    # Bin 3 is fuller and also the best fit.\n\n    # The reflection \"Prioritize fuller bins for better packing density\" suggests that the *current* remaining capacity\n    # is the primary driver of priority. The best fit is a secondary consideration if we want to be explicit.\n    # The `v1` code implements \"best fit\" by minimizing waste.\n    # The new `v2` should implement \"prioritize fuller bins\".\n\n    # Let's try to combine these:\n    # Prioritize bins with smaller `bins_remain_cap`.\n    # Among those with the same `bins_remain_cap`, prioritize the one with smaller `bins_remain_cap - item`.\n    # A score that combines these: `score = bins_remain_cap + (bins_remain_cap - item)`. We want to minimize this.\n    # For priority (maximize), we want to maximize `- (bins_remain_cap + bins_remain_cap - item)`.\n    # `priority = - (2 * bins_remain_cap - item)`\n\n    # Let's try a simpler combination.\n    # Priority = (1 / (bins_remain_cap + epsilon)) + (1 / (bins_remain_cap - item + epsilon))\n    # This will heavily favor bins that are both full and have small waste.\n    # Consider `bins_remain_cap` = [1.0, 0.6, 0.9], `item` = 0.5\n    # Bin 0: 1/1 + 1/0.5 = 1 + 2 = 3.0\n    # Bin 1: 1/0.6 + 1/0.1 = 1.667 + 10 = 11.667\n    # Bin 2: 1/0.9 + 1/0.4 = 1.111 + 2.5 = 3.611\n    # This strongly favors bin 1, which is both the fullest and best fit.\n\n    # Let's simplify the reflection \"Prioritize fuller bins\" to mean, among bins that can fit,\n    # pick the one with the smallest `bins_remain_cap`.\n    # This is equivalent to `1.0 / (bins_remain_cap[can_fit_mask] + 1e-9)`.\n\n    # So, the improved heuristic will directly prioritize the bins that are currently fullest.\n    priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] + 1e-9)\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 28.529325012980813,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy with a slight random perturbation.\n\n    The Best Fit strategy aims to minimize wasted space by selecting the bin that\n    has the least remaining capacity after the item is placed. To encourage\n    exploration and avoid getting stuck in local optima, a small random value is\n    added to the priority of eligible bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Identify bins that can accommodate the item\n    eligible_bins_mask = bins_remain_cap >= item\n\n    # Initialize priorities to a very low value (or zero) for bins that cannot accommodate the item\n    # This ensures they are never chosen.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if np.any(eligible_bins_mask):\n        # For eligible bins, calculate a priority based on the remaining capacity.\n        # We want to favor bins with less remaining capacity (closer to fitting the item perfectly).\n        # So, we use the negative of the remaining capacity.\n        # A small random value is added to break ties and encourage exploration.\n        priorities[eligible_bins_mask] = -(bins_remain_cap[eligible_bins_mask] - item) + np.random.rand(np.sum(eligible_bins_mask)) * 0.01\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 60.91767875292166,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    The Best Fit strategy aims to place the item into the bin where it leaves the\n    least amount of remaining capacity. This is achieved by prioritizing bins\n    that have just enough space for the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the item\n        will have a priority of 0.\n    \"\"\"\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Initialize priorities to 0\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # For bins that can fit the item, calculate the remaining capacity after placing the item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    waste = fitting_bins_remain_cap - item\n\n    # Best Fit prioritizes bins with the minimum waste (smallest positive difference).\n    # To map smaller waste to higher priorities, we can use the inverse of (1 + waste).\n    # This maps a waste of 0 to a priority of 1, and larger waste to smaller priorities.\n    priorities[can_fit_mask] = 1.0 / (1.0 + waste)\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 39.863137138648355,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Sigmoid Fit Score.\n\n    This version prioritizes bins that have a remaining capacity that is just\n    slightly larger than the item size. This aims to minimize wasted space in\n    the selected bin, leaving larger contiguous free spaces in other bins for\n    potentially larger future items.\n\n    The priority is calculated using a sigmoid function applied to the difference\n    between the bin's remaining capacity and the item's size. A smaller\n    positive difference (a tighter fit) results in a higher priority score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Bins that cannot fit the item will have a priority of 0.\n    \"\"\"\n    # Initialize priorities to 0 for all bins. Bins that cannot fit the item will retain this score.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that have enough capacity to fit the item.\n    fittable_bins_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item:\n    if np.any(fittable_bins_mask):\n        fittable_bins_capacities = bins_remain_cap[fittable_bins_mask]\n\n        # Calculate the \"slack\" or \"wasted space\" if the item is placed in the bin.\n        # slack = remaining_capacity - item_size\n        # We want slack to be as close to zero as possible (but non-negative).\n        slack = fittable_bins_capacities - item\n\n        # Use a sigmoid-like function to map slack to a priority score.\n        # A common form that peaks at slack=0 is `1 / (1 + exp(k * slack))`.\n        # As slack increases (larger gaps), the priority decreases.\n        # A higher `k` makes the preference for tight fits more pronounced.\n        k = 5.0  # Sensitivity parameter: higher k means tighter fits are more strongly preferred.\n        priorities[fittable_bins_mask] = 1.0 / (1.0 + np.exp(k * slack))\n\n        # An alternative could be to use a Gaussian-like function, which would also peak at slack=0:\n        # sigma = 1.0 # Controls the spread of the Gaussian.\n        # priorities[fittable_bins_mask] = np.exp(-(slack**2) / (2 * sigma**2))\n\n        # Ensure that if all fittable bins have infinite slack (e.g., if item is 0 and bins are large),\n        # they still get some non-zero priority. The current sigmoid handles this.\n        # Also, if all fittable bins have exactly zero slack, they all get priority 1.\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 55.506595772116384,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid strategy.\n\n    This strategy combines a \"Best Fit\" approach (prioritizing bins that leave minimal\n    remaining capacity after packing) with a \"Worst Fit\" element (prioritizing bins\n    with more remaining capacity to encourage spreading items). It also incorporates\n    a small probability of choosing a random bin to escape local optima.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    exploration_prob = 0.05  # Probability of exploring (choosing a random fittable bin)\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        # If no bin can fit the item, return all zeros.\n        return priorities\n\n    # Calculate scores for fittable bins\n    fittable_bins_indices = np.where(fittable_bins_mask)[0]\n    fittable_bins_capacities = bins_remain_cap[fittable_bins_mask]\n\n    # Hybrid scoring:\n    # 1. Best Fit component: Prioritize bins where (capacity - item) is minimized.\n    #    We use 1 / (difference + epsilon) for this.\n    epsilon = 1e-9\n    best_fit_scores = 1.0 / (fittable_bins_capacities - item + epsilon)\n\n    # 2. Worst Fit component: Prioritize bins with larger remaining capacity.\n    #    We can use the capacity itself or a scaled version. Here, we'll use\n    #    the capacity directly as a secondary scoring factor.\n    worst_fit_scores = fittable_bins_capacities\n\n    # Combine scores: A simple linear combination. You can tune weights.\n    # Here, we give slightly more weight to the \"best fit\" aspect.\n    combined_scores = 0.7 * best_fit_scores + 0.3 * worst_fit_scores\n\n    # Assign combined scores to priorities for fittable bins\n    priorities[fittable_bins_mask] = combined_scores\n\n    # Apply exploration: With a small probability, pick a random fittable bin.\n    if np.random.rand() < exploration_prob:\n        random_fittable_index_in_fittable_array = np.random.randint(len(fittable_bins_indices))\n        chosen_bin_global_index = fittable_bins_indices[random_fittable_index_in_fittable_array]\n\n        # Reset priorities and set the randomly chosen bin's priority to 1\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        priorities[chosen_bin_global_index] = 1.0\n    else:\n        # Normalize priorities to sum to 1 if we are not exploring randomly\n        if np.sum(priorities[fittable_bins_mask]) > 0:\n            priorities[fittable_bins_mask] /= np.sum(priorities[fittable_bins_mask])\n\n    return priorities",
    "response_id": 9,
    "obj": 81.01316314319905,
    "cyclomatic_complexity": 4.0,
    "halstead": 153.83535750584332,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined 'Almost Full Fit' strategy.\n\n    This strategy prioritizes bins that can fit the item and, after fitting,\n    will have the least remaining capacity (i.e., the 'tightest' fits).\n    It also introduces a slight bias towards bins that have more overall remaining capacity\n    among those that offer a similarly tight fit, aiming to preserve very tight fits for\n    potentially smaller items later and to explore fuller bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity if the item is placed in each fitting bin\n    potential_remaining_cap_fitting = bins_remain_cap[fit_mask] - item\n\n    # The core idea of \"Almost Full Fit\" is to minimize the remaining capacity after insertion.\n    # So, we want to prioritize bins with smaller `potential_remaining_cap_fitting`.\n    # We can use the inverse of (1 + slack) as a score, where slack is `potential_remaining_cap_fitting`.\n    # This gives higher scores to smaller slacks. A slack of 0 gets a priority of 1.0.\n    # A slack of 1 gets 0.5, etc.\n    # This part directly addresses the \"tight fit\" preference.\n\n    # To introduce a preference for fuller bins or to break ties in slack,\n    # we can add a secondary criterion. A common approach is to prefer bins\n    # that are already fuller among those with similar slacks.\n    # This can be approximated by using the original `bins_remain_cap` as a factor.\n    # However, a simpler way to break ties is to add a small, increasing value based\n    # on the original remaining capacity, ensuring that if two bins have the same slack,\n    # the one that was originally fuller (and thus has less capacity now) gets a slightly\n    # higher priority if we were to simply maximize `-potential_remaining_cap`.\n\n    # Let's refine the scoring to prioritize smaller `potential_remaining_cap_fitting`\n    # but also provide a subtle bias towards bins that were not excessively large to begin with,\n    # while still favoring tighter fits.\n\n    # Strategy: Prioritize based on `1.0 / (1.0 + slack)`.\n    # To break ties or encourage slightly less full bins when slacks are equal (to save tighter fits),\n    # we can also consider the original `bins_remain_cap`.\n    # A common heuristic for \"Best Fit\" or variations is to pick the bin with the smallest remaining capacity\n    # *after* insertion. This is `potential_remaining_cap_fitting`.\n    # To maximize this (i.e., get the smallest positive remaining capacity), we can use `-(potential_remaining_cap_fitting)`.\n    # To ensure robustness and avoid extremely large bins being picked if they result in a similar \"tightness\",\n    # we can also add a small factor related to the original capacity.\n\n    # Let's try a scoring function that prioritizes minimum slack, but with a slight\n    # nudge for bins that were not excessively large.\n    # Consider the score as: (priority for slack) + (small bonus for being less full initially, to break ties in favor of tighter bins).\n    # Or, more simply, maximize `-potential_remaining_cap_fitting`.\n\n    # The prompt reflection mentions \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits).\"\n    # This is achieved by `1.0 / (1.0 + slack)`.\n    # It also suggests \"balancing with random exploration for robustness\", but this function\n    # is deterministic. \"Favoring fuller bins using inverted slack\" is captured by `1/(1+slack)` where slack is minimized.\n\n    # Let's re-evaluate based on the reflection: \"Prioritize bins that have just enough capacity to fit the item,\n    # with a preference for bins that will have less remaining capacity after the item is added.\"\n    # This is still `1.0 / (1.0 + slack)`.\n\n    # A common variant to break ties or introduce exploration is to add a random component.\n    # However, for deterministic heuristics, tie-breaking is key.\n    # If multiple bins have the same minimal slack, which one to pick?\n    # Some strategies pick the one with the smallest original capacity (First Fit Decreasing logic),\n    # or the one with the largest original capacity (to consolidate larger bins).\n\n    # Let's use the inverse slack `1.0 / (1.0 + slack)` as the primary score.\n    # For tie-breaking, if slacks are equal, we might prefer the bin that was originally less full\n    # (higher `bins_remain_cap` among those with minimal slack). This helps keep the very tightest\n    # bins available for future very small items.\n    # To implement this, we can add a small value proportional to `bins_remain_cap[fit_mask]`\n    # to the primary score, or use a lexicographical sort implicitly.\n\n    # Score = (1.0 / (1.0 + slack)) + small_epsilon * bins_remain_cap[fit_mask]\n    # This would prioritize smaller slack, and for equal slacks, it would prioritize bins\n    # that originally had more capacity. This seems to align with \"balancing with random exploration\"\n    # by making choices less extreme in favoring already full bins.\n\n    slack = bins_remain_cap[fit_mask] - item\n    # Primary score: higher for smaller slack\n    primary_score = 1.0 / (1.0 + slack)\n\n    # Secondary score for tie-breaking or introducing slight variation:\n    # Adding a small fraction of the original remaining capacity.\n    # This boosts scores for bins that were less full if they have the same slack.\n    # We use a small multiplier (e.g., 1e-3) to ensure slack is the dominant factor.\n    secondary_score = 1e-3 * bins_remain_cap[fit_mask]\n\n    priorities[fit_mask] = primary_score + secondary_score\n\n    # Ensure that bins that don't fit have a priority of 0.\n    # The initialisation to zeros and `fit_mask` already handle this.\n\n    return priorities",
    "response_id": 0,
    "obj": 40.915436777024325,
    "cyclomatic_complexity": 1.0,
    "halstead": 84.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an improved Almost Full Fit strategy.\n\n    The strategy prioritizes bins that have minimal remaining capacity after the item is added.\n    This aims to fill bins more tightly. To ensure robustness and avoid getting stuck in local optima\n    due to overly aggressive \"tight fits\", a small amount of randomness or exploration can be beneficial.\n    This version prioritizes bins with smaller slacks (bins_remain_cap - item) but also adds a small\n    random perturbation to the priority to encourage exploration of slightly less optimal bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the slack (remaining capacity after packing)\n    # Slack = bins_remain_cap - item\n    # We want to prioritize bins with minimal slack.\n    slack = bins_remain_cap[fit_mask] - item\n\n    # Assign priorities: higher priority for smaller slack.\n    # Using 1 / (1 + slack) gives higher values for smaller slack.\n    # A slack of 0 (perfect fit) gives priority 1.0.\n    # A slack of 1 gives priority 0.5.\n    # A slack of 10 gives priority ~0.09.\n    # This naturally favors bins that become \"almost full\".\n    base_priorities = 1.0 / (1.0 + slack)\n\n    # Introduce a small random perturbation to encourage exploration.\n    # This helps to avoid always picking the absolute tightest fit, which might\n    # leave slightly larger bins in a state where they are harder to fill later.\n    # The perturbation should be small enough not to override the primary heuristic.\n    # We generate random numbers between 0 and a small fraction of the range of base_priorities.\n    # For example, a perturbation scaled by 10% of the average priority.\n    if len(base_priorities) > 0:\n        max_priority = np.max(base_priorities)\n        perturbation_scale = max_priority * 0.1  # Scale perturbation by a fraction of the max priority\n        random_perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, size=slack.shape)\n        priorities[fit_mask] = base_priorities + random_perturbation\n        # Ensure priorities don't become negative due to perturbation, and clip if necessary\n        # (though with 1/(1+slack) base, this is unlikely unless slack is very large and perturbation negative)\n        priorities[fit_mask] = np.maximum(priorities[fit_mask], 0.0)\n    else:\n        # If no bins fit, priorities remain 0.\n        pass\n\n    return priorities",
    "response_id": 1,
    "obj": 4.058635819704831,
    "cyclomatic_complexity": 2.0,
    "halstead": 99.40434618240934,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Almost Full Fit strategy.\n\n    This strategy prioritizes bins that have a \"tight fit\" for the item, meaning the\n    remaining capacity after insertion is minimized (but non-negative).\n    It uses the inverse of (1 + slack) to reward smaller slacks.\n    Additionally, it introduces a slight bias towards bins that are *not* excessively large,\n    even if they offer a tight fit for the current item, to promote better overall packing.\n    This is done by penalizing bins with significantly more remaining capacity than needed.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate the slack for bins that can fit the item\n    # Slack is defined as remaining_capacity - item_size\n    slack = bins_remain_cap[fit_mask] - item\n\n    # Strategy: Prioritize bins with minimal non-negative slack (tightest fits).\n    # The core idea is to maximize `1 / (1 + slack)`.\n    # A slack of 0 (perfect fit) gives priority 1.0.\n    # Smaller positive slacks give higher priorities than larger ones.\n    # We add 1 to slack to avoid division by zero and to bound priorities.\n    base_priorities = 1.0 / (1.0 + slack)\n\n    # Refinement: Introduce a penalty for bins that have significantly more capacity\n    # than is currently needed, even if they provide a tight fit for this item.\n    # This discourages using a large, mostly empty bin if a smaller, nearly full bin exists.\n    # We can do this by penalizing `bins_remain_cap` for bins that fit.\n    # A common approach is to divide the base priority by some function of the bin's capacity,\n    # or subtract a value related to the capacity.\n    # Let's use a factor that slightly reduces priority for larger bins.\n    # A simple way is to use the inverse of the original remaining capacity,\n    # effectively favoring smaller bins.\n\n    # However, a simpler approach for \"Almost Full Fit\" is to focus purely on the slack.\n    # The reflection also suggests \"balance with random exploration for robustness\",\n    # but this is a deterministic priority function. For robustness, one might consider\n    # a small random element or using multiple heuristics.\n    # For this specific function, let's refine the slack prioritization.\n\n    # The `1.0 / (1.0 + slack)` formulation already favors tighter fits.\n    # To avoid very large bins being chosen if they have a similar slack to smaller bins,\n    # we can introduce a penalty related to the bin's *original* remaining capacity.\n    # For example, we could multiply by `(1.0 - log(bins_remain_cap[fit_mask] + 1) / max_log_cap)`.\n    # This is becoming complex.\n\n    # Let's simplify based on the reflection: \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits). Experiment with prioritizing fuller bins using inverted slack, but balance with random exploration for robustness.\"\n\n    # The `1.0 / (1.0 + slack)` already favors minimal remaining capacity.\n    # \"Prioritizing fuller bins using inverted slack\" could mean maximizing `-slack`,\n    # but this assumes we want *negative* slack (i.e., item overflows).\n    # For fitting items, we want minimal *positive* slack. `1/(1+slack)` achieves this.\n\n    # Let's add a term that slightly favors bins that are \"closer\" to being full relative to their own size,\n    # or simply prefer smaller bins overall when slack is equal.\n    # A simple way to penalize larger bins without overcomplicating is to subtract a small value proportional to their capacity.\n    # However, this could make priorities negative.\n\n    # A balanced approach could be to ensure that the priority is also influenced by how \"full\" the bin *will become*.\n    # If `potential_remaining_cap` is small, it's good.\n    # We are already maximizing `1/(1+slack)` where `slack = bins_remain_cap - item`.\n    # This is equivalent to minimizing `slack`.\n\n    # Consider the \"slack\" as the primary metric.\n    # For bins that fit, `bins_remain_cap[fit_mask] - item`\n    # We want to prioritize smaller values of this slack.\n    # `1.0 / (1.0 + slack)` achieves this.\n\n    # Alternative interpretation for \"Almost Full Fit\": prioritize bins where `bins_remain_cap` is slightly larger than `item`.\n    # Example:\n    # Bin A: capacity=5, item=3, slack=2, potential_rem=2. Priority = 1/(1+2) = 0.33\n    # Bin B: capacity=4, item=3, slack=1, potential_rem=1. Priority = 1/(1+1) = 0.5\n    # Bin C: capacity=3, item=3, slack=0, potential_rem=0. Priority = 1/(1+0) = 1.0\n\n    # This seems correct for favoring tight fits.\n    # The reflection mentions \"balancing with random exploration\". Since this is deterministic,\n    # we can simulate a *slight* bias by adding a tiny noise or by using a secondary criterion for ties.\n    # For now, let's stick to a refined deterministic priority based on slack.\n\n    # Let's ensure that bins that are *just barely* large enough are prioritized\n    # over bins that are much larger but also fit.\n    # The `1 / (1 + slack)` already does this indirectly: a larger bin will have a larger\n    # slack for the same item, resulting in a lower priority.\n\n    # Example: item=2\n    # Bin A: cap=3, slack=1, priority=1/2=0.5\n    # Bin B: cap=10, slack=8, priority=1/9~0.11\n    # This is working as intended.\n\n    # Final check on the reflection: \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits). Experiment with prioritizing fuller bins using inverted slack, but balance with random exploration for robustness.\"\n    # Minimal remaining capacity after fit => minimal slack => maximize `1/(1+slack)`.\n    # \"Prioritizing fuller bins using inverted slack\" => This might imply `-(bins_remain_cap - item)` or similar.\n    # If we use `-slack`, we want the most negative slack (overflow), which is not for fitting.\n    # If we want the *least positive* slack, `1/(1+slack)` is a good proxy.\n\n    # Let's refine the priority to explicitly prefer bins where `bins_remain_cap` is closer to `item`.\n    # This means minimizing `bins_remain_cap - item`.\n\n    # A potential issue with `1/(1+slack)` is that if `slack` is very large, the priority approaches zero.\n    # We can add a small constant to the slack to push priorities slightly higher for all fitting bins,\n    # or use a different function.\n\n    # Consider `priority = exp(-slack)`\n    # slack=0: exp(0) = 1\n    # slack=1: exp(-1) ~ 0.37\n    # slack=2: exp(-2) ~ 0.13\n    # This also favors smaller slacks and decays faster.\n\n    # Another approach: The \"Best Fit Decreasing\" heuristic for offline BPP often prioritizes\n    # bins that have the smallest capacity *that is greater than or equal to the item size*.\n    # For online, we can adapt this. Find bins that fit, and among those, pick the one\n    # with the smallest `bins_remain_cap`.\n    # This is equivalent to minimizing slack: `bins_remain_cap - item`.\n\n    # Let's use the negative of the slack for fitting bins, as maximizing this will minimize slack.\n    # But we need to ensure non-fitting bins have a very low priority.\n    # If `bins_remain_cap - item` is negative, the item doesn't fit.\n    # We want to prioritize smaller values of `bins_remain_cap` for fitting bins.\n    # So, maximize `-bins_remain_cap` for bins where `bins_remain_cap >= item`.\n\n    # Let's try: priority = bins_remain_cap for fitting bins. This would favor smaller bins directly.\n    # If item=2:\n    # Bin A: cap=3, slack=1. Priority = 3\n    # Bin B: cap=4, slack=2. Priority = 4\n    # Bin C: cap=10, slack=8. Priority = 10\n    # This favors bins that are *just* big enough.\n\n    # Combining \"tight fit\" (minimize slack) and \"favor smaller bins\":\n    # For fitting bins, priority = -(bins_remain_cap - item) + K * (-bins_remain_cap)\n    # This is equivalent to minimizing `slack - K * bins_remain_cap`\n    # Or maximizing `item - bins_remain_cap + K * bins_remain_cap`\n\n    # Let's use the simplest interpretation of \"tight fit\" which is minimizing slack.\n    # The `1.0 / (1.0 + slack)` seems robust and directly rewards smaller slacks.\n    # To address the \"prioritizing fuller bins\" part, consider that a bin that is already very full\n    # (small original `bins_remain_cap`) might be preferred if it has a tight fit.\n    # The `1.0 / (1.0 + slack)` indirectly favors smaller bins because they tend to have smaller slacks.\n\n    # Let's try a simpler approach that directly maximizes the \"fullness\" after packing.\n    # We want to maximize `-(bins_remain_cap - item)` for fitting bins.\n    # This means we want to minimize `bins_remain_cap - item`.\n\n    # `potential_remaining_cap = bins_remain_cap[fit_mask] - item`\n    # We want to maximize `-potential_remaining_cap`.\n    # Let's try setting priority to `-potential_remaining_cap`.\n    # This means smaller remaining capacity gets higher priority.\n\n    # Example: item=2\n    # Bin A: cap=3, item=2 -> potential_rem=1. Priority = -1\n    # Bin B: cap=4, item=2 -> potential_rem=2. Priority = -2\n    # Bin C: cap=10, item=2 -> potential_rem=8. Priority = -8\n    # Bin D: cap=1, item=2 -> doesn't fit. Priority = 0\n\n    # This makes the *least negative* number the highest priority. This means\n    # we want the smallest `potential_remaining_cap`.\n    # This strategy seems to align well with \"Almost Full Fit\".\n\n    # To make it slightly more robust against very large bins:\n    # We can normalize the priority by the bin's original capacity or add a penalty.\n    # Let's try to modify the priority: `-potential_remaining_cap - alpha * bins_remain_cap[fit_mask]`\n    # Where alpha is a small positive constant. This would penalize larger bins.\n    # A simpler modification: Prioritize by `-potential_remaining_cap`, and for ties,\n    # pick the bin with smaller `bins_remain_cap`.\n\n    # Let's use the direct \"minimize remaining capacity after packing\" approach.\n    # This is equivalent to maximizing `-(bins_remain_cap - item)`.\n\n    potential_remaining_cap = bins_remain_cap[fit_mask] - item\n\n    # Maximize the negative of the remaining capacity.\n    # This prioritizes bins that will have the least capacity left.\n    priorities[fit_mask] = -potential_remaining_cap\n\n    # To incorporate the \"favoring fuller bins\" aspect more directly,\n    # we can also consider the initial state of the bin.\n    # A bin that is already \"more full\" might be a better candidate.\n    # This can be done by adding a term that is inversely related to initial capacity.\n    # For example, `-(bins_remain_cap[fit_mask] - item) + C * (1.0 / bins_remain_cap[fit_mask])`\n    # This is complex. Let's stick to the most direct interpretation of \"Almost Full Fit\".\n\n    # The reflection suggests \"prioritizing fuller bins using inverted slack\".\n    # Inverted slack could mean `1 / (slack + epsilon)` if slack is positive, or `1 / (capacity - item)`\n    # for fitting bins, where we want smaller denominators.\n    # The current `-potential_remaining_cap` is a good candidate.\n\n    # Let's consider a slight modification inspired by Best Fit:\n    # Among bins that fit, choose the one with the minimum `bins_remain_cap`.\n    # This is equivalent to minimizing `slack`.\n    # If we want to return higher priority for better choices, we should maximize `-slack`.\n    # So, `-potential_remaining_cap` is a good choice.\n\n    # Consider `bins_remain_cap = [5, 6], item = 3`\n    # Bin 0: cap=5, item=3 -> potential_rem=2. priority = -2\n    # Bin 1: cap=6, item=3 -> potential_rem=3. priority = -3\n    # Bin 0 is chosen. This is correct (tightest fit).\n\n    # Consider `bins_remain_cap = [3, 4], item = 3`\n    # Bin 0: cap=3, item=3 -> potential_rem=0. priority = 0\n    # Bin 1: cap=4, item=3 -> potential_rem=1. priority = -1\n    # Bin 0 is chosen. This is correct (perfect fit, minimal remaining).\n\n    # To add a slight bias towards smaller bins when slack is equal:\n    # If `potential_remaining_cap` is the same for two bins, we'd want to break ties.\n    # For example, if item=3, and bins_remain_cap = [5, 5]:\n    # Both give potential_rem=2, priority=-2.\n    # In this case, we could add a term proportional to `-bins_remain_cap`.\n    # `priority = -potential_remaining_cap - alpha * bins_remain_cap[fit_mask]`\n    # Let alpha = 0.1.\n    # Bin 0: cap=5 -> -2 - 0.1*5 = -2.5\n    # Bin 1: cap=5 -> -2 - 0.1*5 = -2.5\n    # Tie still exists.\n\n    # A more direct way to prioritize smaller bins when slack is equal:\n    # Use the original `bins_remain_cap` as a secondary sorting key or part of the primary.\n    # Let's try: `priority = -bins_remain_cap[fit_mask] + C * (-potential_remaining_cap)`\n    # This prioritizes smaller initial capacity, and then tighter fits.\n    # Let C=1.\n    # Bin 0: cap=3, item=3 -> potential_rem=0. priority = -3 + 1*0 = -3\n    # Bin 1: cap=4, item=3 -> potential_rem=1. priority = -4 + 1*(-1) = -5\n    # Bin 0 is chosen. This favors tighter fits more.\n\n    # Let's try maximizing `-potential_remaining_cap` AND `-bins_remain_cap`.\n    # This means minimizing `potential_remaining_cap` and `bins_remain_cap`.\n    # Prioritize by `-(potential_remaining_cap + bins_remain_cap[fit_mask])`\n    # Bin 0: cap=3, item=3 -> pot_rem=0. priority = -(0 + 3) = -3\n    # Bin 1: cap=4, item=3 -> pot_rem=1. priority = -(1 + 4) = -5\n    # Bin 0 is chosen. This seems to combine both criteria.\n\n    # However, the reflection emphasizes \"minimal remaining capacity (tight fits)\".\n    # So, `-potential_remaining_cap` should be the primary driver.\n    # The \"favoring fuller bins\" could mean prioritizing bins that are already\n    # closer to full *before* insertion, but this contradicts tight-fitting.\n    # It's more likely referring to the state *after* insertion.\n\n    # Let's re-read: \"Prioritize fitting bins, favoring those with minimal remaining capacity (tight fits).\"\n    # This is addressed by maximizing `-potential_remaining_cap`.\n\n    # \"Experiment with prioritizing fuller bins using inverted slack\"\n    # Inverted slack could mean `1/(slack+eps)` or `-slack`.\n    # If we want to prioritize fuller bins, we want smaller *initial* remaining capacity.\n    # So, let's use a weighted sum:\n    # Priority = `w1 * (-potential_remaining_cap) + w2 * (-bins_remain_cap[fit_mask])`\n    # We want to maximize this.\n    # Let's try `w1 = 1, w2 = 0.5` (slightly favor tight fits over smaller bins).\n    # Bin A: cap=5, item=3 -> pot_rem=2. priority = 1*(-2) + 0.5*(-5) = -2 - 2.5 = -4.5\n    # Bin B: cap=4, item=3 -> pot_rem=1. priority = 1*(-1) + 0.5*(-4) = -1 - 2.0 = -3.0\n    # Bin B is chosen. It has a tighter fit.\n\n    # If `w1 = 0.5, w2 = 1` (slightly favor smaller bins over tight fits).\n    # Bin A: cap=5, item=3 -> pot_rem=2. priority = 0.5*(-2) + 1*(-5) = -1 - 5 = -6.0\n    # Bin B: cap=4, item=3 -> pot_rem=1. priority = 0.5*(-1) + 1*(-4) = -0.5 - 4 = -4.5\n    # Bin B is chosen. It has a tighter fit.\n\n    # It seems `-potential_remaining_cap` is the dominant factor for \"tight fit\".\n    # Let's focus on that and add a small secondary criterion for \"fuller bins\" (smaller initial capacity).\n    # We want to maximize `-potential_remaining_cap`, and secondarily maximize `-bins_remain_cap`.\n    # This is equivalent to maximizing `-potential_remaining_cap - alpha * bins_remain_cap` for a small alpha.\n    # Let's use a small alpha to ensure `-potential_remaining_cap` is primary.\n\n    alpha = 0.01  # A small weight for the secondary criterion\n    priorities[fit_mask] = -potential_remaining_cap - alpha * bins_remain_cap[fit_mask]\n\n    # Testing this:\n    # item=3\n    # bins_remain_cap = [5, 4]\n    # Bin 0: cap=5, item=3 -> pot_rem=2. priority = -2 - 0.01*5 = -2.05\n    # Bin 1: cap=4, item=3 -> pot_rem=1. priority = -1 - 0.01*4 = -1.04\n    # Bin 1 is chosen. This is correct, it has a tighter fit.\n\n    # item=3\n    # bins_remain_cap = [5, 5]\n    # Bin 0: cap=5, item=3 -> pot_rem=2. priority = -2 - 0.01*5 = -2.05\n    # Bin 1: cap=5, item=3 -> pot_rem=2. priority = -2 - 0.01*5 = -2.05\n    # Tie.\n\n    # If we want to prioritize smaller bins *when fits are equal*:\n    # Let's use `-bins_remain_cap[fit_mask]` as the primary, and `-potential_remaining_cap` as secondary.\n    # Priority = `-bins_remain_cap[fit_mask] - alpha * potential_remaining_cap`\n    # Bin A: cap=5, item=3 -> pot_rem=2. priority = -5 - 0.01*2 = -5.02\n    # Bin B: cap=4, item=3 -> pot_rem=1. priority = -4 - 0.01*1 = -4.01\n    # Bin B is chosen. It has a smaller initial capacity and a tighter fit.\n\n    # The reflection emphasizes \"minimal remaining capacity (tight fits)\" first.\n    # So, `-potential_remaining_cap` must be primary.\n    # Let's stick to: `priorities[fit_mask] = -potential_remaining_cap` as the core.\n    # The \"favoring fuller bins\" aspect is implicitly handled by tight fits.\n    # A bin that is already more full will have less remaining capacity, thus a smaller `potential_remaining_cap`.\n\n    # Final formulation based on prioritizing minimal remaining capacity after fit.\n    # Maximize `-potential_remaining_cap` which means minimize `potential_remaining_cap`.\n    # The primary goal is tight fits.\n\n    # A slight adjustment to make it more sensitive to very small positive slacks,\n    # and to align with \"inverted slack\" which might imply higher values for smaller slacks.\n    # `1.0 / (1.0 + slack)` is a good choice for this.\n\n    # Let's go back to the `1.0 / (1.0 + slack)` form, as it directly penalizes larger slacks.\n    # This seems to be the most direct implementation of \"tight fits\".\n    slack = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (1.0 + slack)\n\n    # This prioritizes bins with 0 slack (perfect fit) with priority 1.0,\n    # then bins with slack 1 (priority 0.5), slack 2 (priority 0.33), etc.\n    # This directly favors minimal remaining capacity.\n\n    # To address \"favoring fuller bins\", it's implicitly handled because\n    # bins that are already fuller will tend to have smaller slacks.\n    # For example, if item=10:\n    # Bin A: cap=12, slack=2, priority=1/3\n    # Bin B: cap=20, slack=10, priority=1/11\n    # Bin A is chosen, which is a tighter fit and also started with less capacity.\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 146.94555522617034,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an improved Almost Full Fit strategy.\n\n    This strategy prioritizes bins that have minimal remaining capacity after fitting the item,\n    focusing on bins that become \"tight fits\". It also includes a mechanism to avoid\n    over-prioritizing very large bins that happen to have small remaining capacity after insertion\n    if there are genuinely \"almost full\" bins available. A slight bias is added to favor\n    bins that have more capacity to begin with (less slack) when multiple bins offer a very tight fit.\n    This aims to reduce the total number of bins used by filling bins more efficiently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the \"slack\" (remaining capacity after item is placed)\n    # Slack = bins_remain_cap - item. We want to minimize slack.\n    slack = bins_remain_cap[fit_mask] - item\n\n    # The core idea is to prioritize bins with the smallest non-negative slack.\n    # A common way to do this is to use a function that gives higher values for smaller slacks.\n    # We can use an inverse relationship, e.g., 1 / (1 + slack).\n    # This assigns a priority of 1.0 to perfect fits (slack=0), and decreasing priority as slack increases.\n\n    # To encourage \"almost full\" fits, we want to prioritize smaller slacks.\n    # However, we also want to avoid situations where a very large bin that has slightly\n    # more capacity than needed is prioritized over a slightly smaller bin that is a tighter fit.\n    # We can achieve this by penalizing larger original capacities among those with minimal slack.\n\n    # Let's create a score that favors smaller slacks:\n    # score_slack = 1.0 / (1.0 + slack)\n    # A high score_slack means a small slack.\n\n    # Now, to also factor in the original remaining capacity (bins_remain_cap[fit_mask])\n    # and ensure that among bins with similar small slacks, we prefer those that were \"less full\" initially,\n    # we can subtract the original capacity. This is slightly counter-intuitive to \"almost full\" if interpreted as\n    # \"least remaining capacity\", but it can lead to better overall packing by not \"over-filling\" a bin unnecessarily\n    # if a slightly less full bin also provides a tight fit.\n\n    # A common approach for \"Best Fit\" (which is related to \"Almost Full Fit\") is to\n    # choose the bin with the minimum remaining capacity *after* the item is placed.\n    # This means we want to minimize `bins_remain_cap - item`.\n\n    # Let's try to combine these:\n    # We want small slack. `1/(1+slack)` works for this.\n    # However, if we have bins:\n    # Bin A: capacity=5, item=3 -> slack=2, score_slack=0.33\n    # Bin B: capacity=10, item=3 -> slack=7, score_slack=0.125\n    # If we only use `1/(1+slack)`, Bin A is preferred. This is good.\n\n    # What if we have:\n    # Bin A: capacity=5, item=3 -> slack=2, score_slack=0.33\n    # Bin B: capacity=5, item=3 -> slack=2, score_slack=0.33\n    # Bin C: capacity=6, item=3 -> slack=3, score_slack=0.25\n    # In this case, A and B are tied. We might want a tie-breaker.\n\n    # A common heuristic for \"Almost Full Fit\" or \"Best Fit\" is to directly use the\n    # *remaining capacity after insertion* as the priority value, and select the bin\n    # that yields the minimum such value. Since we want the *highest* priority score\n    # to be selected, we can use the negative of this value, or `max_capacity - remaining_capacity`.\n\n    # Let's try a strategy that penalizes larger remaining capacity after fitting.\n    # This means we want to minimize `bins_remain_cap[fit_mask] - item`.\n    # So, the priority should be inversely proportional to `bins_remain_cap[fit_mask] - item`.\n    # We want higher priority for smaller `bins_remain_cap[fit_mask] - item`.\n\n    # Let's use `-(bins_remain_cap[fit_mask] - item)` as a base priority.\n    # This makes perfect fits (-0) have the highest priority among valid bins.\n    # Bins with small positive slack will have small negative priorities,\n    # and bins with larger positive slack will have more negative priorities.\n    # This directly rewards the smallest remaining capacity.\n\n    base_priorities = -(slack) # Higher values for smaller slack\n\n    # To avoid over-prioritizing very large bins when there are tighter fits,\n    # we can introduce a penalty based on the original bin capacity if the slack is \"large\".\n    # Or, conversely, a bonus for smaller original capacity if the slack is small.\n\n    # Let's consider \"inverted slack\" as a priority metric: `1.0 / (1.0 + slack)`.\n    # To add robustness and avoid over-selection of bins that are just \"barely fitting\"\n    # but are very large, we can add a small penalty based on the original capacity\n    # if the slack is positive.\n\n    # A simple heuristic for \"Almost Full Fit\" is to prioritize bins that have the\n    # minimum slack. We can use `1 / (1 + slack)` as a proxy for this.\n    # To break ties and favor bins that are not excessively large, we can\n    # slightly penalize larger original capacities.\n\n    # Let's use `-(bins_remain_cap[fit_mask] - item)` as the primary score.\n    # This makes smaller remaining capacities yield higher scores.\n    # Example:\n    # Bin A: cap=5, item=3 -> slack=2, score = -2\n    # Bin B: cap=4, item=3 -> slack=1, score = -1\n    # Bin C: cap=3, item=3 -> slack=0, score = 0\n    # Bin C will be picked. If C is not available, Bin B.\n\n    # To implement the \"avoiding over-prioritizing very large bins\" from the reflection,\n    # we can add a term that decreases priority with original capacity.\n    # A common pattern is to use something like:\n    # Priority = -(slack) + C * (original_capacity_normalized)\n    # where C is a small positive constant. This way, if slacks are similar,\n    # smaller original capacities are slightly preferred.\n\n    # However, the prompt states \"the bin with the highest priority score will be selected.\"\n    # The simplest interpretation of \"Almost Full Fit\" is to pick the bin that results\n    # in the minimum remaining capacity. This means we want to maximize `-(bins_remain_cap - item)`.\n\n    # Let's refine the simple `-(slack)` idea with a tie-breaker.\n    # If two bins have the same minimal slack, which one to choose?\n    # The reflection suggests \"favoring fuller bins using inverted slack, but balance with random exploration for robustness.\"\n    # The \"inverted slack\" is captured by `1/(1+slack)`.\n    # The \"favoring fuller bins\" implies prioritizing bins that started with less capacity, if slacks are equal.\n\n    # Let's use a score that prioritizes minimum slack, and then minimum original capacity among those.\n    # Score = -(slack) - epsilon * original_capacity\n    # where epsilon is a small positive number.\n\n    # Example:\n    # Bin A: cap=5, item=3 -> slack=2, score = -2 - epsilon * 5\n    # Bin B: cap=4, item=3 -> slack=1, score = -1 - epsilon * 4\n    # Bin C: cap=3, item=3 -> slack=0, score = 0 - epsilon * 3\n\n    # Bin C has the highest score (0), then Bin B (-1 - 4*eps), then Bin A (-2 - 5*eps).\n    # This aligns with minimizing slack first, then minimizing original capacity.\n\n    # Let's make it more robust by using `1 / (1 + slack)` and then penalizing larger original capacity.\n    # For example: `priority = 1.0 / (1.0 + slack) - penalty * bins_remain_cap[fit_mask]`\n    # This would mean smaller slack gives higher priority. If slacks are equal, smaller original capacity is preferred.\n\n    # Let's stick to the principle of minimizing remaining capacity, but add a tie-breaker.\n    # If `bins_remain_cap[fit_mask] - item` is the primary value, we want to pick the minimum.\n    # To get the highest priority, we maximize `-(bins_remain_cap[fit_mask] - item)`.\n\n    # Let's consider the reflection's \"favoring fuller bins using inverted slack\".\n    # \"Fuller bins\" can be interpreted as bins with less remaining capacity *before* insertion.\n    # This is `bins_remain_cap[fit_mask]`.\n    # So, we want to prioritize smaller slack AND smaller original `bins_remain_cap`.\n    # Prioritizing smaller slack can be done by `1/(1+slack)`.\n    # Prioritizing smaller original capacity can be done by `-bins_remain_cap[fit_mask]`.\n\n    # Let's combine: priority = `(1.0 / (1.0 + slack)) + C * (-bins_remain_cap[fit_mask])`\n    # where C is a small positive constant.\n    # This rewards smaller slack, and if slacks are similar, rewards smaller original capacity.\n\n    # Let's try a simpler formulation that captures the spirit:\n    # Prioritize bins that become \"most full\" (smallest remaining capacity).\n    # Among those, if there's a tie, prioritize the one that was \"less full\" initially.\n    # This means, we want to minimize `slack`, and if slacks are equal, minimize `bins_remain_cap[fit_mask]`.\n\n    # We can achieve this by creating a compound score where the first element\n    # is the primary criterion (slack) and the second is the tie-breaker (original capacity).\n    # We want to MINIMIZE `slack`.\n    # We want to MINIMIZE `bins_remain_cap[fit_mask]` if slacks are equal.\n\n    # So, we are looking for the minimum pair `(slack, bins_remain_cap[fit_mask])`.\n    # To convert this to a maximization problem for priority, we can use:\n    # priority = -slack - epsilon * bins_remain_cap[fit_mask]\n    # where epsilon is a small positive value.\n\n    epsilon = 1e-6 # A small value for tie-breaking\n\n    # Calculate priority: Maximize `-slack` (favors smaller slack),\n    # and then maximize `-bins_remain_cap[fit_mask]` (favors smaller original capacity) as a tie-breaker.\n    # The priority score directly represents the desirability.\n    priorities[fit_mask] = -slack - epsilon * bins_remain_cap[fit_mask]\n\n    # This strategy directly implements the \"tight fit\" preference and the tie-breaking mechanism.\n    # Bins that don't fit remain with a priority of 0.\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 57.359400011538504,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin, favoring\n    tighter fits and generally fuller bins.\n\n    The strategy prioritizes bins that result in minimal remaining capacity\n    after the item is placed (tight fit). Among those with similar tightness,\n    it prefers bins that had less capacity to begin with (fuller bins).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float) # Initialize with very low priority\n\n    # Identify bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n\n    # Calculate slack for fitting bins: how much space is left after fitting the item\n    # A smaller slack means a tighter fit.\n    slack = bins_remain_cap[fit_mask] - item\n\n    # Strategy: Maximize -(slack) AND Maximize -(bins_remain_cap)\n    # Combine these: Maximize -(slack) - alpha * bins_remain_cap\n    # alpha is a small positive constant to weigh the preference for fuller bins.\n    # Let's use alpha = 0.1 as a starting point.\n    alpha = 0.1\n\n    # Calculate the primary score component: negative slack (favors tight fits)\n    # Higher value for smaller slack.\n    tight_fit_score = -slack\n\n    # Calculate the secondary score component: negative original remaining capacity (favors fuller bins)\n    # Higher value for smaller original remaining capacity.\n    fuller_bin_score = -bins_remain_cap[fit_mask]\n\n    # Combine the scores\n    # The combined score is: tight_fit_score + alpha * fuller_bin_score\n    # This means we maximize -(slack) - alpha * bins_remain_cap\n    combined_score = tight_fit_score + alpha * fuller_bin_score\n\n    # Assign the calculated priorities to the fitting bins\n    priorities[fit_mask] = combined_score\n\n    # Ensure we don't have -inf if all bins are full, but we do need to differentiate fitting bins.\n    # If all bins can fit the item, and we want the highest priority, we need to make sure\n    # the highest score is indeed positive or represents the best option.\n    # The current score can be negative. The relative order is what matters.\n    # A simple way to ensure scores are \"priority-like\" (higher is better) and non-infinite:\n    # If all bins can fit the item, the highest score among them is the best.\n    # If some bins don't fit, they will have -inf.\n    # The current structure handles this correctly for selection.\n\n    # If we want to avoid negative scores in general and ensure that at least one option\n    # is clearly \"good\", we could add an offset.\n    # However, for a priority score, relative magnitude is key.\n    # If no bins can fit the item, `fit_mask` will be all False, and `priorities` will remain [-inf, -inf, ...].\n    # This is acceptable as no bin can be chosen.\n\n    # Let's refine the score calculation to be explicitly about maximizing values.\n    # We want to maximize: `-(slack) - alpha * bins_remain_cap[fit_mask]`\n    # Example:\n    # item=3, bins_remain_cap=[5, 4, 3, 2]\n    # fit_mask = [True, True, True, False]\n    # slack = [2, 1, 0]\n    # bins_remain_cap[fit_mask] = [5, 4, 3]\n    # alpha = 0.1\n    # tight_fit_score = [-2, -1, 0]\n    # fuller_bin_score = [-5, -4, -3]\n    # combined_score = [-2, -1, 0] + 0.1 * [-5, -4, -3]\n    # combined_score = [-2, -1, 0] + [-0.5, -0.4, -0.3]\n    # combined_score = [-2.5, -1.4, -0.3]\n    #\n    # priorities = [-2.5, -1.4, -0.3, -inf]\n    # The bin with capacity 3 has the highest priority (-0.3).\n    # This means it has the tightest fit (slack 0) and the smallest original capacity (3).\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 70.32403072095333,
    "exec_success": true
  }
]