{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines gravitational effect and fill factor with a capacity scaling.\"\"\"\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    gravitational_effect = item / bins_remain_cap**2\n\n    fill_factor = (1 - (bins_remain_cap - item) / bins_remain_cap)\n    fill_factor = np.where(bins_remain_cap < item, -np.inf, fill_factor)\n\n    capacity_scaling = np.exp(-bins_remain_cap) # scale by remaining capacity\n\n    priorities = gravitational_effect + fill_factor + capacity_scaling\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines gravitational effect, fill ratio, and adaptive capacity scaling.\"\"\"\n    # Avoid division by zero\n    min_capacity = 1e-9\n    bins_remain_cap = np.where(bins_remain_cap <= 0, min_capacity, bins_remain_cap)\n\n    # Gravitational effect\n    gravity_power = 2\n    gravitational_effect = item / (bins_remain_cap**gravity_power)\n\n    # Fill ratio\n    fill_ratio = item / bins_remain_cap\n    fill_ratio = np.where(bins_remain_cap < item, -np.inf, fill_ratio)\n\n    # Adaptive capacity scaling based on item size\n    capacity_scaling_factor = np.exp(-bins_remain_cap / item) if item > 0 else np.exp(-bins_remain_cap)\n\n    # Combine the factors with weights. Weights can be tuned.\n    priorities = gravitational_effect + fill_ratio + capacity_scaling_factor\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, small_cap_threshold: float = 8.987758769187444e-09, gravity_power: float = 1.711145028643874) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by space-time curvature, we prioritize bins where the\n    item \"bends\" the remaining capacity the most significantly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        small_cap_threshold: Threshold below which remaining capacity is considered zero.\n        gravity_power: Exponent for the inverse square relationship in gravitational effect.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero\n    bins_remain_cap = np.where(bins_remain_cap <= 0, small_cap_threshold, bins_remain_cap)\n\n    # Calculate the \"gravitational effect\" based on item size and remaining capacity.\n    # A larger item has a stronger effect; smaller remaining capacity implies higher urgency.\n    gravitational_effect = item / bins_remain_cap**gravity_power # Inverse square relationship, reminiscent of gravity\n\n    # Introduce a term that favors bins that are reasonably full, but can still accomodate the item.\n    # This prevents premature exhaustion of some bins and promotes better overall packing.\n    fill_factor = (1 - (bins_remain_cap - item) / bins_remain_cap)\n    fill_factor = np.where(bins_remain_cap < item, -np.inf, fill_factor) #make inelligible when not fitting\n\n    # Combine gravitational effect and fill factor\n    priorities = gravitational_effect + fill_factor\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version incorporates multiple factors, non-linear relationships,\n    and adaptive scaling to improve bin packing efficiency.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 1e-9  # Small constant to avoid division by zero and numerical instability\n\n    # 1. Basic Feasibility Check: Eliminate bins that cannot fit the item.\n    feasible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf  # Initialize to -inf\n\n    # 2. Capacity Utilization Factor: Favor bins that are already reasonably full.\n    #    This encourages filling bins and reduces fragmentation.\n    utilization = (1 - bins_remain_cap / (np.max(bins_remain_cap) + epsilon))\n    utilization = np.clip(utilization, 0, 1)  # Ensure values are within [0, 1]\n    utilization_factor = utilization**2 # Non-linear, emphasize already full bins\n\n\n    # 3. Item Fit Score: How well the item fits into the remaining space.\n    #    A tighter fit is generally preferred, but not if it leads to excessive fragmentation.\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / (item + epsilon))\n\n    # 4. Balance Factor: Discourage near-empty bins from being used too early.\n    #    This helps to keep options open for larger items later on.\n    balance_factor = np.sqrt(bins_remain_cap / (np.max(bins_remain_cap) + epsilon))\n\n    # 5. Remaining Capacity Penalty: Penalize bins with very little remaining capacity\n    #    after placing the current item.  This avoids creating slivers.\n    remaining_capacity_penalty = np.exp(-10 * np.maximum(0, bins_remain_cap - item) / (np.max(bins_remain_cap)+epsilon))\n\n\n    # Adaptive Scaling: Adjust the weights of the factors based on the item size.\n    #  - For smaller items, prioritize utilization and fit.\n    #  - For larger items, prioritize feasibility and balance.\n    item_scale = np.clip(item / (np.mean(bins_remain_cap) + epsilon), 0, 1)\n    \n    #6. Combine the Factors:  Weighted sum of the individual factors.\n    priority_weights = {\n        'utilization': 0.3 + 0.1*item_scale,\n        'fit': 0.4 - 0.2 * item_scale,\n        'balance': 0.1+ 0.4*item_scale,\n        'penalty': 0.2 - 0.1*item_scale\n    }\n\n    # Assign priorities to feasible bins\n    priorities[feasible_bins] = (\n        priority_weights['utilization'] * utilization_factor[feasible_bins] +\n        priority_weights['fit'] * fit_score[feasible_bins] +\n        priority_weights['balance'] * balance_factor[feasible_bins] +\n        priority_weights['penalty'] * remaining_capacity_penalty[feasible_bins]\n    )\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines gravitational effect, fill ratio, and adaptive capacity scaling.\"\"\"\n    # Avoid division by zero\n    min_capacity = 1e-9\n    bins_remain_cap = np.where(bins_remain_cap <= 0, min_capacity, bins_remain_cap)\n\n    # Gravitational effect\n    gravity_power = 2\n    gravitational_effect = item / (bins_remain_cap**gravity_power)\n\n    # Fill ratio\n    fill_ratio = item / bins_remain_cap\n    fill_ratio = np.where(bins_remain_cap < item, -np.inf, fill_ratio)\n\n    # Adaptive capacity scaling based on item size\n    capacity_scaling_factor = np.exp(-bins_remain_cap / item) if item > 0 else np.exp(-bins_remain_cap)\n\n    # Combine the factors with weights. Weights can be tuned.\n    priorities = gravitational_effect + fill_ratio + capacity_scaling_factor\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by space-time curvature, we prioritize bins where the\n    item \"bends\" the remaining capacity the most significantly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    # Calculate the \"gravitational effect\" based on item size and remaining capacity.\n    # A larger item has a stronger effect; smaller remaining capacity implies higher urgency.\n    gravitational_effect = item / bins_remain_cap**2 # Inverse square relationship, reminiscent of gravity\n\n    # Introduce a term that favors bins that are reasonably full, but can still accomodate the item.\n    # This prevents premature exhaustion of some bins and promotes better overall packing.\n    fill_factor = (1 - (bins_remain_cap - item) / bins_remain_cap)\n    fill_factor = np.where(bins_remain_cap < item, -np.inf, fill_factor) #make inelligible when not fitting\n\n    # Combine gravitational effect and fill factor\n    priorities = gravitational_effect + fill_factor\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                division_safety: float = 4.717408705269109e-09,\n                exponent: float = 1.5832716567146647) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by space-time curvature, we prioritize bins where the\n    item \"bends\" the remaining capacity the most significantly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        division_safety: Small value to avoid division by zero.\n        exponent: determines the rate at which the gravitational effect decreases with distance (remaining capacity)\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero\n    bins_remain_cap = np.where(bins_remain_cap <= 0, division_safety, bins_remain_cap)\n\n    # Calculate the \"gravitational effect\" based on item size and remaining capacity.\n    # A larger item has a stronger effect; smaller remaining capacity implies higher urgency.\n    gravitational_effect = item / bins_remain_cap**exponent # Inverse square relationship, reminiscent of gravity\n\n    # Introduce a term that favors bins that are reasonably full, but can still accomodate the item.\n    # This prevents premature exhaustion of some bins and promotes better overall packing.\n    fill_factor = (1 - (bins_remain_cap - item) / bins_remain_cap)\n    fill_factor = np.where(bins_remain_cap < item, -np.inf, fill_factor) #make inelligible when not fitting\n\n    # Combine gravitational effect and fill factor\n    priorities = gravitational_effect + fill_factor\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, remaining capacity, and feasibility.\"\"\"\n    min_capacity = 1e-9\n    bins_remain_cap = np.where(bins_remain_cap <= 0, min_capacity, bins_remain_cap)\n\n    # Fill ratio, penalize infeasible bins\n    fill_ratio = item / bins_remain_cap\n    fill_ratio = np.where(bins_remain_cap < item, -np.inf, fill_ratio)\n\n    # Remaining capacity utilization\n    capacity_utilization = 1 - (bins_remain_cap - item) / bins_remain_cap\n    capacity_utilization = np.where(bins_remain_cap < item, -np.inf, capacity_utilization)\n\n    priorities = fill_ratio + capacity_utilization\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines gravitational effect and fill factor with a capacity scaling.\"\"\"\n    bins_remain_cap = np.where(bins_remain_cap <= 0, 1e-9, bins_remain_cap)\n\n    gravitational_effect = item / bins_remain_cap**2\n\n    fill_factor = (1 - (bins_remain_cap - item) / bins_remain_cap)\n    fill_factor = np.where(bins_remain_cap < item, -np.inf, fill_factor)\n\n    capacity_scaling = np.exp(-bins_remain_cap) # scale by remaining capacity\n\n    priorities = gravitational_effect + fill_factor + capacity_scaling\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version refines the priority calculation by considering multiple factors\n    in a more nuanced and adaptive manner.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Handle edge cases: bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities = np.full_like(bins_remain_cap, -np.inf)  # Mark infeasible bins with -inf\n    \n    # Avoid division by zero and operate only on feasible bins\n    feasible_bins_remain_cap = bins_remain_cap[~infeasible_mask]\n    if feasible_bins_remain_cap.size == 0:\n        return priorities\n    \n    # Calculate remaining capacities after adding item, cliping negative values to 0\n    remaining_after_add = np.clip(feasible_bins_remain_cap - item, 0, np.inf)\n    \n    # 1. Capacity Utilization Score: favors bins filling up nicely without too much waste.\n    utilization_score = (feasible_bins_remain_cap - remaining_after_add) / feasible_bins_remain_cap # item / feasible_bins_remain_cap\n    \n    # 2. Waste Minimization Score: penalizes bins that would leave too much empty space.\n    waste_penalty = remaining_after_add / np.max(bins_remain_cap)  # Normalized to max bin size\n\n    # 3. Item Size Significance Score: Considers how significant is the item size comparing to available space\n    item_significance = item / np.max(bins_remain_cap)\n\n    #Adaptive Weighting: Dynamically adjust the importance of each factor.\n    alpha = 0.6 # Weight for utilization\n    beta = 0.3 # Weight for waste\n    gamma = 0.1 #Weight for item_significance\n\n    combined_priority = (alpha * utilization_score) - (beta * waste_penalty) + (gamma * item_significance)\n\n    # Assign priority to feasible bins and return\n    priorities[~infeasible_mask] = combined_priority\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version refines the priority calculation by considering multiple factors\n    in a more nuanced and adaptive manner.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Handle edge cases: bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities = np.full_like(bins_remain_cap, -np.inf)  # Mark infeasible bins with -inf\n    \n    # Avoid division by zero and operate only on feasible bins\n    feasible_bins_remain_cap = bins_remain_cap[~infeasible_mask]\n    if feasible_bins_remain_cap.size == 0:\n        return priorities\n    \n    # Calculate remaining capacities after adding item, cliping negative values to 0\n    remaining_after_add = np.clip(feasible_bins_remain_cap - item, 0, np.inf)\n    \n    # 1. Capacity Utilization Score: favors bins filling up nicely without too much waste.\n    utilization_score = (feasible_bins_remain_cap - remaining_after_add) / feasible_bins_remain_cap # item / feasible_bins_remain_cap\n    \n    # 2. Waste Minimization Score: penalizes bins that would leave too much empty space.\n    waste_penalty = remaining_after_add / np.max(bins_remain_cap)  # Normalized to max bin size\n\n    # 3. Item Size Significance Score: Considers how significant is the item size comparing to available space\n    item_significance = item / np.max(bins_remain_cap)\n\n    #Adaptive Weighting: Dynamically adjust the importance of each factor.\n    alpha = 0.6 # Weight for utilization\n    beta = 0.3 # Weight for waste\n    gamma = 0.1 #Weight for item_significance\n\n    combined_priority = (alpha * utilization_score) - (beta * waste_penalty) + (gamma * item_significance)\n\n    # Assign priority to feasible bins and return\n    priorities[~infeasible_mask] = combined_priority\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version refines the priority calculation by considering multiple factors\n    in a more nuanced and adaptive manner.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Handle edge cases: bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities = np.full_like(bins_remain_cap, -np.inf)  # Mark infeasible bins with -inf\n    \n    # Avoid division by zero and operate only on feasible bins\n    feasible_bins_remain_cap = bins_remain_cap[~infeasible_mask]\n    if feasible_bins_remain_cap.size == 0:\n        return priorities\n    \n    # Calculate remaining capacities after adding item, cliping negative values to 0\n    remaining_after_add = np.clip(feasible_bins_remain_cap - item, 0, np.inf)\n    \n    # 1. Capacity Utilization Score: favors bins filling up nicely without too much waste.\n    utilization_score = (feasible_bins_remain_cap - remaining_after_add) / feasible_bins_remain_cap # item / feasible_bins_remain_cap\n    \n    # 2. Waste Minimization Score: penalizes bins that would leave too much empty space.\n    waste_penalty = remaining_after_add / np.max(bins_remain_cap)  # Normalized to max bin size\n\n    # 3. Item Size Significance Score: Considers how significant is the item size comparing to available space\n    item_significance = item / np.max(bins_remain_cap)\n\n    #Adaptive Weighting: Dynamically adjust the importance of each factor.\n    alpha = 0.6 # Weight for utilization\n    beta = 0.3 # Weight for waste\n    gamma = 0.1 #Weight for item_significance\n\n    combined_priority = (alpha * utilization_score) - (beta * waste_penalty) + (gamma * item_significance)\n\n    # Assign priority to feasible bins and return\n    priorities[~infeasible_mask] = combined_priority\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version refines the priority calculation by considering multiple factors\n    in a more nuanced and adaptive manner.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Handle edge cases: bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities = np.full_like(bins_remain_cap, -np.inf)  # Mark infeasible bins with -inf\n    \n    # Avoid division by zero and operate only on feasible bins\n    feasible_bins_remain_cap = bins_remain_cap[~infeasible_mask]\n    if feasible_bins_remain_cap.size == 0:\n        return priorities\n    \n    # Calculate remaining capacities after adding item, cliping negative values to 0\n    remaining_after_add = np.clip(feasible_bins_remain_cap - item, 0, np.inf)\n    \n    # 1. Capacity Utilization Score: favors bins filling up nicely without too much waste.\n    utilization_score = (feasible_bins_remain_cap - remaining_after_add) / feasible_bins_remain_cap # item / feasible_bins_remain_cap\n    \n    # 2. Waste Minimization Score: penalizes bins that would leave too much empty space.\n    waste_penalty = remaining_after_add / np.max(bins_remain_cap)  # Normalized to max bin size\n\n    # 3. Item Size Significance Score: Considers how significant is the item size comparing to available space\n    item_significance = item / np.max(bins_remain_cap)\n\n    #Adaptive Weighting: Dynamically adjust the importance of each factor.\n    alpha = 0.6 # Weight for utilization\n    beta = 0.3 # Weight for waste\n    gamma = 0.1 #Weight for item_significance\n\n    combined_priority = (alpha * utilization_score) - (beta * waste_penalty) + (gamma * item_significance)\n\n    # Assign priority to feasible bins and return\n    priorities[~infeasible_mask] = combined_priority\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}