[
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a multiplicative bonus for fuller bins,\n    using a logarithmic scale to favor bins that are mostly full but can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins with minimal remaining capacity after fitting.\n    # Adding epsilon for numerical stability.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Bonus: A bonus reflecting how full the bin is *before* fitting the item.\n    # We use a logarithmic scale for the remaining capacity to give diminishing returns\n    # as bins get very full, but still reward those that are significantly filled.\n    # The idea is to slightly favor bins that are already quite full (smaller remaining capacity)\n    # to encourage consolidation. Adding 1 to avoid log(0).\n    fullness_bonus = np.log1p(bins_remain_cap[fittable_bins_mask])\n\n    # Combine scores multiplicatively: Prioritize bins that are both a good fit (low residual)\n    # and are already quite full. The fullness bonus acts as a multiplier on the best-fit score.\n    combined_scores = best_fit_scores * (1.0 + fullness_bonus * 0.2) # Add 1 to ensure positive multiplier\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a 'fill ratio' bonus, prioritizing bins that are both a tight fit\n    and already well-utilized, aiming for efficient packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # Best Fit Score: Inversely proportional to the remaining capacity after fitting the item.\n    # Adding a small epsilon to avoid division by zero.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Fill Ratio Score: Proportional to how full the bin is *relative to its capacity after packing*.\n    # This emphasizes bins that will have less remaining space after the item is placed.\n    fill_ratio_scores = (bins_remain_cap[eligible_bins_mask] - item) / (bins_remain_cap[eligible_bins_mask] + 1e-9)\n\n\n    # Combined Score: Multiplicative combination.\n    # Prioritizes bins that are a good fit (high best_fit_scores) AND are already quite full (high fill_ratio_scores).\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison across different item sizes and bin states.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a bonus for bins that are already utilized,\n    prioritizing snug fits in partially filled bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Best Fit score: Inverse of remaining capacity after fitting. High score for tight fits.\n    proximity_score = 1.0 / (fitting_bins_remain_cap - item + 1e-9)\n    \n    # Fill Ratio Score: Bonus for bins that are already mostly full.\n    # We use the inverse of the remaining capacity *before* placing the item as a proxy for fullness.\n    # A higher value means the bin was less full, so we want to penalize that.\n    # The lower the remaining capacity (before fitting), the fuller the bin.\n    fullness_bonus = 1.0 / (fitting_bins_remain_cap + 1e-9)\n    \n    # Combine scores multiplicatively: prioritize tight fits that are also on already utilized bins.\n    combined_score = proximity_score * fullness_bonus\n    \n    # Normalize scores to [0, 1] for better comparability and to avoid extreme values.\n    # Add a small epsilon to avoid division by zero if all scores are zero.\n    max_score = np.max(combined_score)\n    if max_score > 1e-9:\n        priorities[can_fit_mask] = combined_score / max_score\n    else:\n        # If all combined scores are near zero (e.g., only very large gaps available)\n        # fallback to a simple proximity score, normalized.\n        max_proximity = np.max(proximity_score)\n        if max_proximity > 1e-9:\n            priorities[can_fit_mask] = proximity_score / max_proximity\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a Fill Ratio bonus, using a multiplicative approach.\n    This prioritizes bins that fit tightly and are already relatively full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Inverse of remaining capacity after packing. Higher is better.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fill Ratio Score: Inverse of the bin's total capacity (assuming total capacity is 1 for simplicity or can be passed).\n    # Here we use the inverse of the *original* remaining capacity before fitting the item,\n    # to represent how full the bin *was*. A higher fill ratio (lower remaining capacity) is better.\n    # Add 1 to avoid division by zero if a bin was already full (though fittable_bins_mask should prevent this).\n    fill_ratio_score = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine multiplicatively: Prioritize bins that are both a tight fit and were already full.\n    # This balances immediate packing efficiency with the goal of consolidating items.\n    combined_scores = best_fit_score * fill_ratio_score\n\n    # Normalize to [0, 1]\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a Fullness bonus multiplicatively.\n    Prioritizes bins that are a tight fit and are already more utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Score 1: Best Fit - Higher score for smaller remaining capacity after packing.\n    # This encourages minimizing immediate wasted space.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Score 2: Fullness Bonus - Higher score for bins that are already more full.\n    # This is calculated as the inverse of the remaining capacity among fittable bins.\n    # Encourages consolidation into fewer bins.\n    fullness_bonus = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine scores multiplicatively. This ensures that bins must perform well on both\n    # metrics to achieve a high priority. A bin that is a perfect fit but very empty,\n    # or a very full bin that is a poor fit, will receive a lower combined score.\n    combined_scores = best_fit_score * fullness_bonus\n\n    # Normalize priorities to a [0, 1] range for consistent behavior.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are effectively zero (e.g., very large items or very similar capacities),\n        # assign a small uniform priority to fittable bins to ensure selection.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a multiplicative bonus for bins that are already fuller,\n    aiming for efficient packing and reduced bin count.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher score for bins with less remaining capacity after fit.\n    # This strongly favors tight fits. Add epsilon for stability.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Score: Higher score for bins that are already more full.\n    # This encourages consolidating items into fewer bins.\n    # Normalize by the maximum remaining capacity among fittable bins for relative comparison.\n    max_rem_cap_fittable = np.max(fittable_bins_remain_cap)\n    fullness_scores = (max_rem_cap_fittable - fittable_bins_remain_cap) / (max_rem_cap_fittable + 1e-6)\n\n    # Combine scores multiplicatively.\n    # The multiplication ensures that a good fit (high best_fit_scores) is prioritized,\n    # and this priority is boosted if the bin is also already fuller (high fullness_scores).\n    # This heuristic balances the desire for a tight fit with the objective of using fewer bins.\n    combined_scores = best_fit_scores * (1 + 0.5 * fullness_scores)\n\n    # Normalize priorities to a [0, 1] range.\n    max_combined_score = np.max(combined_scores)\n    if max_combined_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_combined_score\n    else:\n        # Fallback: if all combined scores are near zero, assign a small uniform priority.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a fill ratio bonus using a multiplicative approach,\n    prioritizing bins that offer a tight fit and are already well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    \n    if fitting_bins_indices.size > 0:\n        fitting_bins_cap = bins_remain_cap[fitting_bins_indices]\n        \n        # Best Fit component: Smaller difference is better (higher score)\n        differences = fitting_bins_cap - item\n        best_fit_score = 1.0 / (differences + 1e-9)\n        \n        # Fill Ratio component: Higher fill ratio is better (higher score)\n        # Assuming bin capacity is constant (e.g., 1.0 for normalized problems or a known max_capacity)\n        # Here, we use the total capacity before packing as the reference for fill ratio.\n        # A simpler proxy for fullness is (bin_capacity - remaining_capacity).\n        # Let's assume a hypothetical bin capacity of 1.0 for this calculation if not provided.\n        # If bin_capacity is known, replace 1.0 with it.\n        bin_capacity = 1.0 \n        fullness = (bin_capacity - fitting_bins_cap) / bin_capacity\n        fill_ratio_score = fullness \n        \n        # Combine scores multiplicatively: Boosts bins that are both tight fits and fuller.\n        # Adding a small constant to fill_ratio_score to avoid multiplying by zero if a bin is empty.\n        combined_scores = best_fit_score * (fill_ratio_score + 0.1) # Add small bonus to slightly full bins\n        \n        priorities[fitting_bins_indices] = combined_scores\n        \n        # Normalize priorities to be between 0 and 1 for the fitting bins\n        max_priority = np.max(priorities[fitting_bins_indices])\n        if max_priority > 0:\n            priorities[fitting_bins_indices] /= max_priority\n            \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response7.txt_stdout.txt",
    "code_path": "problem_iter11_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive fill ratio bonus, prioritizing tight fits\n    that also contribute to fuller bins, weighted by item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Best Fit Component ---\n    # Score based on how little capacity is left after fitting.\n    # Higher score for smaller remaining capacity.\n    best_fit_score = 1.0 / (fitting_bins_remain_cap - item + 1e-9)\n    \n    # --- Adaptive Fill Ratio Component ---\n    # This component encourages filling bins more, but it's modulated by how large the item is relative to the bin's capacity.\n    # If an item is a large fraction of the bin's total capacity, we slightly de-emphasize the fill ratio contribution\n    # to avoid over-packing small items into partially filled bins at the expense of better fits for larger items.\n    # Assume a nominal bin capacity of 1.0 for fill ratio calculation.\n    bin_capacity = 1.0\n    current_fill_ratio = (bin_capacity - fitting_bins_remain_cap) / bin_capacity\n    \n    # Adaptive weight for fill ratio: Higher weight for smaller items relative to bin capacity.\n    # We want to encourage filling, but more so for smaller items that are less likely to \"ruin\" a bin for future items.\n    # The item_size_ratio helps normalize this. A small item (e.g., 0.1) gets a higher weight (e.g., 1.0 / (0.1+1) = 0.9)\n    # A large item (e.g., 0.8) gets a lower weight (e.g., 1.0 / (0.8+1) = 0.55).\n    # We add 1 to the denominator to ensure the weight is <= 1 and to avoid issues when item_size_ratio is 0.\n    item_size_ratio = item / bin_capacity \n    adaptive_fill_weight = 1.0 / (item_size_ratio + 1.0)\n\n    fill_ratio_score = current_fill_ratio * adaptive_fill_weight\n    \n    # --- Combined Score ---\n    # Multiplicatively combine Best Fit and the weighted Fill Ratio.\n    # This prioritizes bins that are both a tight fit and contribute to overall bin fullness,\n    # with the fill ratio component being more influential for smaller items.\n    combined_score = best_fit_score * (1 + fill_ratio_score) # Add 1 to fill_ratio_score to ensure it boosts, not reduces, the BF score if fill_ratio_score is small.\n    \n    # Normalize scores to [0, 1]\n    max_score = np.max(combined_score)\n    if max_score > 1e-9:\n        priorities[can_fit_mask] = combined_score / max_score\n    else: # Handle cases where all scores are zero or near-zero\n        priorities[can_fit_mask] = 1.0 / (len(fitting_bins_remain_cap) + 1e-9) # Give equal priority if no clear differentiator\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a modified Fill Ratio for denser packing.\n    Prioritizes bins that fit the item snugly and are already substantially full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # Score 1: Best Fit - inverse of remaining capacity after packing.\n    # Higher score for smaller remaining capacity.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Score 2: Fill Ratio - remaining capacity relative to the item size.\n    # Prioritizes bins where the item occupies a larger fraction of the remaining space,\n    # promoting tighter packing. Avoids penalizing bins with very large remaining capacity.\n    fill_ratio_scores = item / (eligible_bins_caps + 1e-9)\n\n    # Combine scores multiplicatively: accentuates bins that excel in both criteria.\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign combined scores to the priorities array for eligible bins.\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a Fill Ratio bonus multiplicatively,\n    prioritizing bins that are both a tight fit and already well-utilized.\n    This aims for efficient packing by favoring dense bins that can snugly fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Best Fit Component ---\n    # Higher score for smaller remaining capacity after fitting.\n    remaining_capacity_after_fit = fitting_bins_remain_cap - item\n    proximity_score = 1.0 / (remaining_capacity_after_fit + 1e-9)\n    \n    # --- Fill Ratio Component ---\n    # Using 1.0 as the assumed bin capacity. Higher fill ratio (less remaining capacity) is better.\n    # This encourages using bins that are already somewhat full.\n    bin_capacity = 1.0 \n    current_fill_ratio = (bin_capacity - fitting_bins_remain_cap) / bin_capacity\n    fill_ratio_score = current_fill_ratio\n    \n    # --- Combined Score ---\n    # Multiplicatively combine Best Fit and Fill Ratio.\n    # This prioritizes bins that are both a good fit (high proximity) AND already well-utilized (high fill ratio).\n    # A bin that is nearly full and can snugly fit the item will get a high score.\n    combined_score = proximity_score * fill_ratio_score\n    \n    # --- Refinement: Ensure proximity is considered for empty bins ---\n    # If a bin was empty (fill_ratio=0), combined_score would be 0.\n    # We want to ensure that even in this case, the proximity score is still considered,\n    # as an empty bin might be the only option or a good first fit.\n    # We take the maximum of the combined score and a modified proximity score\n    # where the fill_ratio_score component is only applied if fill_ratio > 0.\n    # This ensures that even empty bins get a score based on their proximity.\n    priorities[can_fit_mask] = np.maximum(combined_score, proximity_score * (fill_ratio_score > 1e-9))\n    \n    # Add a small constant to all valid priorities to ensure that even if\n    # all scores are very low, they are distinct and positive, aiding tie-breaking.\n    priorities[can_fit_mask] += 1e-6\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]