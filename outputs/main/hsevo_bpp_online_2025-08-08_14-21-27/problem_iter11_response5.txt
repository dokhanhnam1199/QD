```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with a multiplicative bonus for bins that are already fuller,
    aiming for efficient packing and reduced bin count.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    fittable_bins_mask = bins_remain_cap >= item

    if not np.any(fittable_bins_mask):
        return priorities

    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]

    # Best Fit Score: Higher score for bins with less remaining capacity after fit.
    # This strongly favors tight fits. Add epsilon for stability.
    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)

    # Fullness Score: Higher score for bins that are already more full.
    # This encourages consolidating items into fewer bins.
    # Normalize by the maximum remaining capacity among fittable bins for relative comparison.
    max_rem_cap_fittable = np.max(fittable_bins_remain_cap)
    fullness_scores = (max_rem_cap_fittable - fittable_bins_remain_cap) / (max_rem_cap_fittable + 1e-6)

    # Combine scores multiplicatively.
    # The multiplication ensures that a good fit (high best_fit_scores) is prioritized,
    # and this priority is boosted if the bin is also already fuller (high fullness_scores).
    # This heuristic balances the desire for a tight fit with the objective of using fewer bins.
    combined_scores = best_fit_scores * (1 + 0.5 * fullness_scores)

    # Normalize priorities to a [0, 1] range.
    max_combined_score = np.max(combined_scores)
    if max_combined_score > 1e-9:
        priorities[fittable_bins_mask] = combined_scores / max_combined_score
    else:
        # Fallback: if all combined scores are near zero, assign a small uniform priority.
        priorities[fittable_bins_mask] = 0.1

    return priorities
```
