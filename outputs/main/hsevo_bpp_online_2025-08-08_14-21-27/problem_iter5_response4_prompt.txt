{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines the \"Best Fit\" greedy strategy with an exploration component.\n    Prioritizes bins that best fit the item, with a small chance of exploring other options.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    # Calculate greedy scores: inverse of remaining capacity after placement (Best Fit)\n    # Higher score for bins with less remaining capacity after placing the item\n    greedy_scores = 1.0 / (bins_remain_cap[fittable_bins_mask] - item + 1e-9)\n\n    # Introduce a small exploration factor: slightly boost all fittable bins\n    # This encourages trying bins that might not be the absolute best fit but could lead to better overall packing later.\n    exploration_boost = 0.05\n    priorities[fittable_bins_mask] = greedy_scores + exploration_boost\n\n    # Normalize priorities to ensure they are comparable and avoid extreme values\n    if np.max(priorities) > 1e-9: # Avoid division by zero if all priorities are zero\n        priorities /= np.max(priorities)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a balance of minimal wasted space and avoiding fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    valid_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(valid_bins_mask):\n        return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 & 6 vs. Heuristics 2 & 3:** Heuristics 1 and 6 attempt to combine proximity fit with a consideration for the *resulting* remainder, aiming for a balance. They use a multiplicative approach (fill ratio * proximity) or explicitly try to penalize large remainders. Heuristics 2 and 3 focus on a \"Best Fit\" with an \"Almost Full\" bias, but their adaptive component is less sophisticated, relying on an arbitrary small residual or absolute threshold. The core idea of balancing fit with future utility is stronger in 1 & 6.\n\n*   **Heuristics 1 & 6 vs. Heuristics 4 & 7 & 8 & 12:** Heuristics 4, 7, 8, and 12 introduce an \"exploration\" component (adding a small boost or random selection) to the basic \"Best Fit\" (inverse of remaining capacity). While exploration can be beneficial in some search contexts, for a greedy priority heuristic, it often dilutes the core objective of finding the *best* immediate fit. Heuristics 1 and 6's adaptive components are more directly related to packing efficiency.\n\n*   **Heuristics 1 & 6 vs. Heuristics 5:** Heuristic 5 tries to combine proximity, minimal waste bonus, and an exact fit penalty. While it attempts multiple factors, the combination (multiplication with enhancement and penalty) can be complex and harder to tune than the more straightforward multiplicative approach of Heuristic 1 (fill ratio * proximity).\n\n*   **Heuristics 1 & 6 vs. Heuristics 9, 10, 11:** Heuristics 9, 10, and 11 are incomplete and only define the initialization of priorities and a mask. They don't implement any scoring logic, making them inherently the worst.\n\n*   **Heuristics 1 & 6 vs. Heuristics 13 & 14:** Heuristics 13 and 14 combine proximity with an \"adaptive bonus\" that rewards leaving more capacity for non-perfect fits. This is a different strategy than 1 & 6, which aim to reward *tight* fits but consider the resulting remainder. The bonus for leaving *more* capacity seems counter-intuitive for a heuristic focused on minimizing bins unless specifically designed for a scenario where future items are guaranteed to be much larger. Heuristic 1's approach (high fill ratio + proximity) is generally more aligned with dense packing.\n\n*   **Heuristics 1 & 6 vs. Heuristics 15:** Heuristic 15 uses an inverse difference score combined with a sigmoid centered on the median difference. This is a sophisticated adaptive approach aiming to differentiate between bins near the median. However, it might be overly complex compared to Heuristic 1's more direct multiplicative strategy, which achieves a similar goal of favoring tighter fits and penalizing large remainders via the fill ratio.\n\n*   **Heuristics 1 & 6 vs. Heuristics 16 & 17:** Heuristics 16 and 17 combine proximity with a \"fullness bonus,\" weighted differently. They try to balance a preference for tighter fits (proximity) with a preference for bins with more remaining capacity (fullness). This is a reasonable strategy but might be less direct than Heuristic 1's approach of maximizing the \"fill ratio * proximity\" which inherently favors bins that are both close fits and have high initial fill ratios.\n\n*   **Heuristics 1 & 6 vs. Heuristics 18, 19, 20:** Heuristics 18, 19, and 20 implement a \"Best Fit\" (1/residual) multiplied by the residual itself. This heuristic attempts to balance tight fits with future flexibility by favoring bins that leave *some* remaining capacity, but not too much. Heuristic 1's multiplicative approach (fill ratio * proximity) is arguably more direct in achieving dense packing by rewarding bins that are already well-utilized and also represent a close fit. The multiplication by `potential_remaining_cap` in 18-20 might overly favor bins with moderate residuals, potentially at the cost of a truly tight fit.\n\nOverall, Heuristics 1 and 6 stand out for their balanced approach using a multiplicative score that combines high fill ratio with proximity, aiming for dense packing.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Balance, Utility, Efficiency, Simplicity, Exploration Bias.\n*   **Advice:** Focus on simple, quantifiable metrics that capture both immediate fit and long-term potential. Introduce complexity *only* when data clearly indicates current strategies are insufficient.\n*   **Avoid:** Redundant implementations that offer marginal improvements. Over-reliance on arbitrary thresholds or overly complex weighting schemes without empirical justification.\n*   **Explanation:** Ineffective reflection often gets bogged down in minor implementation differences. Effective reflection questions *why* a strategy is chosen, assessing its core principle and its impact on the overall objective (better packing). Strive for elegant solutions, not just variations on a theme.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}