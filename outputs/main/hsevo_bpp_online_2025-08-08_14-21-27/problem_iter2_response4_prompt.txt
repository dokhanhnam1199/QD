{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Richard Feynman's \"Quantum Hop\" Priority for Bin Packing:\n    Let's think about this. We've got these items, right? And we've got these bins.\n    We want to pack 'em up, neat and tidy, with as few bins as possible.\n    It's like trying to fit all your thoughts into your brain, and you want to do it efficiently, so you don't get cluttered.\n\n    Now, with this \"Random Fit\" business, it's not about being perfectly clever every time.\n    It's more like... a hunch. A good guess. Sometimes, you gotta just pick a path and see where it leads.\n    We get an item, a new thought, and we have these bins, these mental compartments, each with some space left.\n    We want to assign a \"priority\" to each bin, saying how good a fit it *might* be.\n\n    My idea? Let's give a higher priority to bins that are *almost* full, but not *too* full.\n    Why? Because if a bin is almost full, putting this item in might just finish it off, or at least make it quite full. That's a good use of space, a satisfying \"closure.\"\n    But if a bin is practically empty, or if the item *barely* fits, well, that doesn't feel as right. It's like trying to cram a tiny pebble into a vast stadium \u2013 it doesn't quite *fill* the purpose.\n\n    So, for each bin, let's calculate this \"priority score.\"\n    It's like a little dance.\n    If the item fits in the bin (capacity >= item), that's a good start. No priority if it doesn't fit \u2013 that's a no-go zone.\n    If it fits, how much space is left *after* we put the item in? That's `bins_remain_cap - item`.\n    We want this remaining space to be small, but not negative (that's why we checked `bins_remain_cap >= item`).\n    Let's say `residual_capacity = bins_remain_cap - item`.\n    Now, we want to maximize the \"goodness\" of this residual capacity.\n    If `residual_capacity` is zero, that's perfect! The bin is full. Max priority.\n    If `residual_capacity` is small and positive, that's also good. High priority.\n    If `residual_capacity` is large, that's not as great. We're not using the bin efficiently. Lower priority.\n\n    So, let's try this:\n    For each bin, if the item fits:\n        Calculate the leftover space: `leftover = bin_capacity - item`\n        The priority is inversely related to `leftover`. More leftover, less priority.\n        A simple way to do this is to make the priority proportional to `1 / (1 + leftover)`.\n        This way, if `leftover` is 0, priority is 1. If `leftover` is large, priority approaches 0.\n\n    What if the item doesn't fit? The priority is 0. A firm no.\n\n    Let's put it all together.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits_mask = bins_remain_cap >= item\n    residual_capacity = bins_remain_cap[fits_mask] - item\n    \n    # We want to give a higher priority to bins with less residual capacity after packing.\n    # A residual capacity of 0 is ideal. Large residual capacity is less ideal.\n    # The formula 1 / (1 + residual_capacity) captures this:\n    # If residual_capacity is 0, priority is 1 / (1 + 0) = 1.\n    # If residual_capacity is large, say 100, priority is 1 / (1 + 100) = 1/101, which is small.\n    # This gives a \"quantum hop\" towards the more filled bins without being too rigid.\n    priorities[fits_mask] = 1.0 / (1.0 + residual_capacity)\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    First Fit strategy with a priority score that favors bins with minimal remaining capacity\n    that can still accommodate the item. This encourages tighter packing and potentially\n    leaving larger bins available for future larger items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Assign priorities only to bins that can fit the item\n    # The priority is inversely proportional to the remaining capacity.\n    # A smaller remaining capacity (but still fitting) gets a higher priority.\n    # Add a small epsilon to avoid division by zero if a bin has exactly item size remaining.\n    priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] - item + 1e-9)\n    \n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (3rd) and (4th), all three implement a similar strategy: assigning priority inversely proportional to the remaining capacity after placing the item, using `1.0 / (bins_remain_cap[eligible_bins_mask] - item + 1e-9)`. The 1st and 4th are nearly identical in their implementation and docstrings, with the 4th having a slightl\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Adaptive Prioritization, Dynamic Evaluation, Predictive Performance, Causal Analysis.\n*   **Advice:** Instead of solely relying on static or post-hoc comparisons, focus on *predicting* the future impact of heuristic choices. Experiment with actively *adapting* the heuristic's logic based on early performance signals during a run.\n*   **Avoid:** Repeating analyses of near-identical implementations. Over-reliance on single-metric comparisons without considering the underlying mechanisms.\n*   **Explanation:** Truly improving heuristics requires understanding *why* certain strategies work or fail, not just observing superficial similarities. Analyze the *causal relationship* between a heuristic's choice and the overall solution quality to drive innovation.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}