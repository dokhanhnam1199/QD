[
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a normalized fill ratio, prioritizing bins\n    that snugly fit the item and are already substantially full, adaptively.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[fittable_bins_mask]\n\n    # Score 1: Best Fit (inverse of remaining capacity after packing).\n    # Smaller remaining capacity after packing yields a higher score.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Score 2: Normalized Fill Ratio.\n    # Aims to prioritize bins that are more full. We use a formula that is\n    # sensitive to how much space is left relative to the total capacity,\n    # but we normalize it against the maximum initial remaining capacity\n    # to provide a more consistent fill measure across different scenarios.\n    # Adding a small epsilon for stability and to avoid zero if all bins are empty.\n    max_initial_remain_cap = np.max(bins_remain_cap) if np.any(bins_remain_cap > 0) else 1.0\n    fill_ratio_scores = 1.0 - (eligible_bins_caps / (max_initial_remain_cap + 1e-9))\n    # Add a small constant to ensure even less full bins have a positive score,\n    # preventing the multiplicative term from becoming zero too easily.\n    fill_ratio_scores = fill_ratio_scores + 0.1\n\n    # Combine scores multiplicatively.\n    # This approach emphasizes bins that are good in both aspects: tight fit (best_fit_scores)\n    # and already substantially full (fill_ratio_scores).\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign combined scores to the priorities array for eligible bins.\n    priorities[fittable_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a balanced preference for bins that are\n    not excessively empty after packing. This aims for efficient packing while\n    keeping options open for future items.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n    residual_capacity = fittable_bins_remain_cap - item\n\n    # Component 1: Best Fit (tightness)\n    # Higher score for smaller residual capacity.\n    # Using inverse with epsilon for numerical stability.\n    best_fit_score = 1.0 / (residual_capacity + 1e-9)\n\n    # Component 2: \"Bin Fullness Preference\"\n    # Favor bins that are already somewhat full, meaning they have less remaining capacity.\n    # This discourages leaving many bins nearly empty.\n    # Higher score for smaller fittable_bins_remain_cap.\n    bin_fullness_score = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine scores using a weighted additive approach.\n    # Weight for Best Fit (tightness) is primary.\n    # Weight for Bin Fullness is secondary, to encourage using less empty bins.\n    w_best_fit = 1.0\n    w_bin_fullness = 0.5\n\n    combined_scores = (w_best_fit * best_fit_score) + (w_bin_fullness * bin_fullness_score)\n\n    # Normalize the combined scores for the fittable bins to be in a comparable range (e.g., 0 to 1).\n    # This prevents one component from dominating solely due to its scale.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        normalized_scores = combined_scores / max_score\n    else:\n        # If all scores are very small (e.g., all residuals are huge), assign a minimal uniform priority.\n        normalized_scores = np.full_like(combined_scores, 0.1)\n\n    # Assign the calculated priorities to the fittable bins.\n    priorities[fittable_bins_mask] = normalized_scores\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines a refined Best Fit approach with a penalty for leaving excessive\n    remaining capacity, using a multiplicative scoring for synergy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Component 1: Best Fit - Prioritize bins that leave minimal remaining space.\n    # This is crucial for immediate packing efficiency.\n    # Using 1/(difference + epsilon) to favor smaller differences.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Component 2: Penalty for Large Leftover Space - Discourage packing into\n    # bins that leave significantly more capacity than needed. This aims to\n    # preserve larger spaces for potentially larger future items.\n    # We use a logarithmic penalty: smaller leftovers are better, but the\n    # penalty grows slower for larger leftovers, avoiding over-penalization.\n    # The +1 in log1p handles cases where remaining capacity after fit is 0.\n    leftover_space_penalty = np.log1p(fittable_bins_remain_cap - item)\n\n    # Combine scores multiplicatively to ensure bins perform well on both criteria.\n    # We want to maximize the best_fit_score and minimize the leftover_space_penalty.\n    # Therefore, we divide by (1 + penalty) to get a score that is higher when\n    # the penalty is lower.\n    combined_scores = best_fit_score / (1.0 + leftover_space_penalty)\n\n    # Normalize priorities to a [0, 1] range for consistent selection.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all calculated scores are negligible, assign a small uniform priority\n        # to all fittable bins to ensure at least one is chosen if available.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a normalized measure of bin fullness,\n    using an additive approach for better control and interpretability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Prioritize bins that leave minimal remaining capacity.\n    # Using inverse of remaining space after fit, with epsilon for stability.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fullness Score: Prioritize bins that are already more full.\n    # Normalized by the *initial* maximum remaining capacity to provide a stable baseline.\n    # This measure is relative to the overall capacity landscape, not just fittable bins.\n    # A higher score means the bin has less *initial* remaining capacity (i.e., is fuller).\n    if bins_remain_cap.size > 0 and np.max(bins_remain_cap) > 1e-9:\n        max_initial_remain_cap = np.max(bins_remain_cap)\n        fullness_scores = (max_initial_remain_cap - fittable_bins_remain_cap) / (max_initial_remain_cap + 1e-9)\n    else:\n        # If no bins or all bins are empty, fullness doesn't differentiate much.\n        fullness_scores = np.zeros_like(fittable_bins_remain_cap)\n\n    # Combine Scores Additively:\n    # Weight Best Fit more heavily, but give a significant boost for fuller bins.\n    # This aims for a balance: prioritize tight fits but also leverage existing bin fullness.\n    # Weights can be tuned for performance.\n    combined_scores = (best_fit_scores * 1.0) + (fullness_scores * 0.75)\n\n    # Normalize combined scores to [0, 1] for consistent priority assignment.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all combined scores are effectively zero, assign a small uniform priority.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a normalized fill ratio, prioritizing bins\n    that fit snugly and are already substantially full, using additive weighting for control.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # Best Fit component: Prioritize bins with least remaining capacity after packing.\n    # A smaller difference (eligible_bins_caps - item) yields a higher score.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Fill Ratio component: Prioritize bins that are already more utilized relative to their total capacity.\n    # Normalize the current remaining capacity by the maximum initial remaining capacity across all bins.\n    # This score is higher for bins that are more full. Using log1p for smoother distribution.\n    max_initial_remain_cap = np.max(bins_remain_cap) # Consider initial state for normalization\n    if max_initial_remain_cap == 0: # Handle case where all bins might be full initially\n        fill_ratio_scores = np.ones_like(eligible_bins_caps) # All eligible bins are equally \"full\"\n    else:\n        fill_ratio_scores = np.log1p(1.0 / (eligible_bins_caps / max_initial_remain_cap + 1e-9))\n\n    # Combine scores additively with weights. This provides more granular control.\n    # Weight for Best Fit: 0.7 (emphasizes immediate packing efficiency)\n    # Weight for Fill Ratio: 0.3 (emphasizes future bin utilization)\n    # The weights are chosen to balance immediate fit with long-term packing density.\n    combined_scores = 0.7 * best_fit_scores + 0.3 * fill_ratio_scores\n\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1].\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response5.txt_stdout.txt",
    "code_path": "problem_iter17_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive fullness bonus. Prioritizes bins that are\n    nearly full and can accommodate the item with minimal remaining space,\n    using a normalized fullness score for better adaptability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit component: Prioritize bins with smallest remaining capacity after fitting.\n    # Adding a small epsilon to avoid division by zero.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Adaptive Fullness component: Prioritize bins that are already more full,\n    # using a normalized measure relative to the maximum initial remaining capacity\n    # among fittable bins to ensure better cross-bin comparison.\n    # This score is higher for bins that are already fuller.\n    # Add a small epsilon to the denominator to avoid division by zero if all fittable bins are empty.\n    max_initial_remain_cap = np.max(fittable_bins_remain_cap)\n    fullness_score = 1.0 - (fittable_bins_remain_cap / (max_initial_remain_cap + 1e-9))\n\n    # Combine scores multiplicatively: Boosts bins that are both tight fits and more full.\n    # Add a small constant to fullness_score to ensure it always contributes positively\n    # and doesn't zero out the overall score if a bin is very empty.\n    combined_scores = best_fit_score * (fullness_score + 0.5)\n\n    priorities[fittable_bins_mask] = combined_scores\n\n    # Normalize priorities for fittable bins to a [0, 1] range.\n    max_priority = np.max(priorities[fittable_bins_mask])\n    if max_priority > 0:\n        priorities[fittable_bins_mask] /= max_priority\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response6.txt_stdout.txt",
    "code_path": "problem_iter17_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness and a normalized fill ratio using additive weights.\n    Balances immediate packing efficiency with future bin utility.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Component 1: Best Fit (inverse of remaining capacity after packing)\n    # Prioritizes bins where the item fits most snugly.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Component 2: Normalized Fill Ratio\n    # Measures how full a bin is relative to its capacity, encouraging use of already utilized bins.\n    # We use (capacity - remaining_capacity) / capacity for the overall bin fill,\n    # but for priority, we consider item/remaining_capacity as a measure of how much\n    # the item \"fills\" the *available* space. A higher ratio is better.\n    fill_ratio_scores = item / (fittable_bins_remain_cap + 1e-9)\n\n    # Weights for combining components. These can be tuned.\n    # Beta emphasizes fitting snugly, Alpha emphasizes already fuller bins.\n    beta = 0.7\n    alpha = 0.3\n\n    # Combined score using weighted additive approach for better control.\n    # We normalize each component before weighting to ensure fair contribution.\n    # Normalize best_fit_scores (higher is better, higher score means smaller leftover)\n    max_bf = np.max(best_fit_scores)\n    normalized_best_fit = best_fit_scores / max_bf if max_bf > 1e-9 else np.ones_like(best_fit_scores)\n\n    # Normalize fill_ratio_scores (higher is better, higher score means item is a larger fraction of available space)\n    max_fr = np.max(fill_ratio_scores)\n    normalized_fill_ratio = fill_ratio_scores / max_fr if max_fr > 1e-9 else np.ones_like(fill_ratio_scores)\n\n    combined_scores = alpha * normalized_fill_ratio + beta * normalized_best_fit\n\n    # Assign calculated scores back and normalize the final priorities.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / np.max(combined_scores)\n    else:\n        # If all scores are zero or near-zero, assign uniform small priority\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response7.txt_stdout.txt",
    "code_path": "problem_iter17_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's preference for tight fits with a normalized Fill Ratio bonus.\n    Prioritizes bins that fit the item snugly and are already substantially full,\n    with adaptive weighting for robustness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[fittable_bins_mask]\n\n    # Component 1: Best Fit (tightness) - Inverse of remaining capacity after packing\n    # Higher score for smaller leftover space.\n    best_fit_score = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Component 2: Fill Ratio (bin fullness) - Normalized inverse of remaining capacity\n    # This component is derived from Heuristic 9's approach to normalize based on\n    # maximum initial capacity if it were known. Here, we use a general\n    # penalty for large remaining capacities by inverting the capacity.\n    # Adding a small constant to avoid zero and ensure all bins have some base priority.\n    fill_ratio_score = 1.0 / (eligible_bins_caps + 1.0) # Penalize large remaining space more\n\n    # Adaptive Weighting: Use item size to adjust the importance of fill ratio.\n    # Larger items might benefit more from prioritizing bins that are already fuller,\n    # while smaller items might be more sensitive to the tightness of the fit.\n    # This is a simple heuristic: a higher weight for fill ratio for larger items.\n    # Let's assume a normalized item size for this scaling (e.g., item / max_possible_item_size).\n    # For simplicity, we'll use a direct relationship with item size, capped.\n    fill_ratio_weight = min(item * 2.0, 1.5) # Weight for fill ratio, capped at 1.5\n\n    # Combine scores: Weighted sum for better control and interpretability.\n    # This offers more granular control than pure multiplicative combinations.\n    combined_scores = best_fit_score + fill_ratio_weight * fill_ratio_score\n\n    # Assign combined scores to the priorities array for eligible bins.\n    priorities[fittable_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response8.txt_stdout.txt",
    "code_path": "problem_iter17_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a normalized fullness score multiplicatively.\n    Prioritizes bins that are a tight fit and also already quite full,\n    with careful normalization to ensure score stability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Inverse of remaining capacity after fitting. Smaller remaining capacity is better.\n    # Add a small epsilon to prevent division by zero if remaining capacity is exactly item size.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fullness Score: Ratio of capacity already used relative to the maximum remaining capacity among fittable bins.\n    # This provides a relative measure of how \"full\" a bin is compared to other potential candidates.\n    max_initial_remain_cap = np.max(fittable_bins_remain_cap)\n    if max_initial_remain_cap < 1e-9:\n        # If all fittable bins have negligible remaining capacity, they are all equally \"full\" in a relative sense.\n        fullness_scores = np.ones_like(fittable_bins_remain_cap)\n    else:\n        # Score is higher for bins with less initial remaining capacity (i.e., they are fuller).\n        fullness_scores = 1.0 - (fittable_bins_remain_cap / max_initial_remain_cap)\n\n    # Combine scores multiplicatively. This rewards bins that are both a good fit and already full.\n    # Adding a small constant to fullness scores ensures that even bins that are not maximally full\n    # still contribute a positive multiplicative factor, preventing the overall score from collapsing to zero.\n    combined_scores = best_fit_scores * (fullness_scores + 0.1)\n\n    # Normalize the combined scores for fittable bins to a [0, 1] range.\n    # This ensures that the priority values are on a consistent scale, regardless of the absolute magnitudes of the scores.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all combined scores are near zero (e.g., all fittable bins are very large and empty),\n        # assign a small uniform priority to fittable bins to allow selection.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit preference with a logarithmic fullness bonus,\n    additively weighted, prioritizing bins that are a tight fit and already full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit component: Inverse of remaining capacity after fitting. Prioritizes tight fits.\n    # Add epsilon for numerical stability.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fullness Bonus: Logarithmic scale of how full the bin is before fitting.\n    # log1p(1/remaining_cap) is used to give higher bonus to fuller bins (smaller remaining_cap).\n    fullness_bonus = np.log1p(1.0 / (fittable_bins_remain_cap + 1e-9))\n\n    # Combine scores additively with weights for balance.\n    # Weighting allows for tunable influence of each component.\n    # Adding 1.0 to fullness_bonus to ensure it contributes positively.\n    # Adjusted weights to balance Best Fit and Fullness.\n    combined_scores = 0.7 * best_fit_score + 0.3 * (1.0 + fullness_bonus * 0.5)\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # Fallback: uniform small priority if all scores are negligible.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]