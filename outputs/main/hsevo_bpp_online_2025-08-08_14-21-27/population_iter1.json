[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = capacity - item\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999526419997 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    priorities[valid_bins] = bins_remain_cap[valid_bins] - item\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_capacity = bins_remain_cap[i] - item\n            \n            if remaining_capacity == 0:\n                priorities[i] = 1e9 \n            else:\n                priorities[i] = remaining_capacity\n                \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99995274399407 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = (cap - item) ** 2\n        else:\n            priorities[i] = -1\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999947868986055 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = 1.0 / (capacity - item + 1e-9)\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for bins using the Inverse Distance (Proximity Fit) strategy.\n    The closer a bin's remaining capacity is to the item size, the higher its priority.\n    Bins that can fit the item will have a non-zero priority, while those that cannot will have zero.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    \n    fitting_bins_cap = bins_remain_cap[can_fit_mask]\n    \n    if fitting_bins_cap.size > 0:\n        differences = fitting_bins_cap - item\n        # Add a small epsilon to avoid division by zero if an item perfectly fits a bin\n        priorities[can_fit_mask] = 1.0 / (differences + 1e-9)\n        \n        # Normalize priorities so that the best fit bin has a score of 1\n        max_priority = np.max(priorities[can_fit_mask])\n        if max_priority > 0:\n            priorities[can_fit_mask] /= max_priority\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    possible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if not np.any(possible_bins):\n        return priorities\n\n    remaining_capacities_for_possible = bins_remain_cap[possible_bins]\n    \n    differences = remaining_capacities_for_possible - item\n    \n    k = 10.0 \n    \n    sigmoid_scores = 1 / (1 + np.exp(-k * (differences - np.median(differences))))\n    \n    priorities[possible_bins] = sigmoid_scores\n    \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 72.82608695652173,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Richard Feynman's \"Quantum Hop\" Priority for Bin Packing:\n    Let's think about this. We've got these items, right? And we've got these bins.\n    We want to pack 'em up, neat and tidy, with as few bins as possible.\n    It's like trying to fit all your thoughts into your brain, and you want to do it efficiently, so you don't get cluttered.\n\n    Now, with this \"Random Fit\" business, it's not about being perfectly clever every time.\n    It's more like... a hunch. A good guess. Sometimes, you gotta just pick a path and see where it leads.\n    We get an item, a new thought, and we have these bins, these mental compartments, each with some space left.\n    We want to assign a \"priority\" to each bin, saying how good a fit it *might* be.\n\n    My idea? Let's give a higher priority to bins that are *almost* full, but not *too* full.\n    Why? Because if a bin is almost full, putting this item in might just finish it off, or at least make it quite full. That's a good use of space, a satisfying \"closure.\"\n    But if a bin is practically empty, or if the item *barely* fits, well, that doesn't feel as right. It's like trying to cram a tiny pebble into a vast stadium \u2013 it doesn't quite *fill* the purpose.\n\n    So, for each bin, let's calculate this \"priority score.\"\n    It's like a little dance.\n    If the item fits in the bin (capacity >= item), that's a good start. No priority if it doesn't fit \u2013 that's a no-go zone.\n    If it fits, how much space is left *after* we put the item in? That's `bins_remain_cap - item`.\n    We want this remaining space to be small, but not negative (that's why we checked `bins_remain_cap >= item`).\n    Let's say `residual_capacity = bins_remain_cap - item`.\n    Now, we want to maximize the \"goodness\" of this residual capacity.\n    If `residual_capacity` is zero, that's perfect! The bin is full. Max priority.\n    If `residual_capacity` is small and positive, that's also good. High priority.\n    If `residual_capacity` is large, that's not as great. We're not using the bin efficiently. Lower priority.\n\n    So, let's try this:\n    For each bin, if the item fits:\n        Calculate the leftover space: `leftover = bin_capacity - item`\n        The priority is inversely related to `leftover`. More leftover, less priority.\n        A simple way to do this is to make the priority proportional to `1 / (1 + leftover)`.\n        This way, if `leftover` is 0, priority is 1. If `leftover` is large, priority approaches 0.\n\n    What if the item doesn't fit? The priority is 0. A firm no.\n\n    Let's put it all together.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits_mask = bins_remain_cap >= item\n    residual_capacity = bins_remain_cap[fits_mask] - item\n    \n    # We want to give a higher priority to bins with less residual capacity after packing.\n    # A residual capacity of 0 is ideal. Large residual capacity is less ideal.\n    # The formula 1 / (1 + residual_capacity) captures this:\n    # If residual_capacity is 0, priority is 1 / (1 + 0) = 1.\n    # If residual_capacity is large, say 100, priority is 1 / (1 + 100) = 1/101, which is small.\n    # This gives a \"quantum hop\" towards the more filled bins without being too rigid.\n    priorities[fits_mask] = 1.0 / (1.0 + residual_capacity)\n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    available_bins = bins_remain_cap[available_bins_mask]\n    if available_bins.size > 0:\n        priorities[available_bins_mask] = (available_bins - item) / available_bins\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 7.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    if suitable_bins_remain_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    residuals = suitable_bins_remain_cap - item\n    \n    e_x = np.exp(residuals)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[suitable_bins_mask] = e_x / np.sum(e_x)\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    First Fit strategy with a priority score that favors bins with minimal remaining capacity\n    that can still accommodate the item. This encourages tighter packing and potentially\n    leaving larger bins available for future larger items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Assign priorities only to bins that can fit the item\n    # The priority is inversely proportional to the remaining capacity.\n    # A smaller remaining capacity (but still fitting) gets a higher priority.\n    # Add a small epsilon to avoid division by zero if a bin has exactly item size remaining.\n    priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] - item + 1e-9)\n    \n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = capacity - item\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n        else:\n            priorities[i] = -1  # Infeasible bin\n    \n    # Invert priorities so that largest difference (worst fit) is highest\n    # and -1 remains the lowest\n    priorities[priorities != -1] = -priorities[priorities != -1]\n    \n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Exact Fit First strategy:\n    # Give higher priority to bins that can perfectly fit the item.\n    # If no perfect fit, prioritize bins that have just enough space (smallest remaining capacity greater than or equal to item).\n    # If multiple perfect fits, or multiple \"just enough\" fits, the order doesn't strictly matter for exact fit, \n    # but we can use the original bin index as a tie-breaker for consistency.\n    \n    perfect_fit_mask = (bins_remain_cap == item)\n    if np.any(perfect_fit_mask):\n        priorities[perfect_fit_mask] = 1.0\n    else:\n        # Find bins where remaining capacity is just enough for the item\n        sufficient_capacity_mask = (bins_remain_cap >= item)\n        if np.any(sufficient_capacity_mask):\n            # Prioritize bins with the least remaining capacity that is still sufficient\n            # This is a secondary heuristic: Best Fit variation when exact fit is not possible.\n            sufficient_capacities = bins_remain_cap[sufficient_capacity_mask]\n            \n            # Calculate a score inversely proportional to remaining capacity for sufficient bins\n            # A smaller remaining capacity (but still >= item) is better.\n            # We want to maximize this score. So, we can use something like 1 / (remaining_capacity - item + 1) \n            # to give higher scores to tighter fits. Adding 1 to avoid division by zero if remaining_capacity == item.\n            \n            # Create temporary indices for sorting\n            temp_indices = np.where(sufficient_capacity_mask)[0]\n            \n            # Sort these bins by their remaining capacity\n            sorted_indices = temp_indices[np.argsort(bins_remain_cap[temp_indices])]\n            \n            # Assign priorities to the sorted bins. Higher priority for smaller remaining capacity.\n            # We can assign decreasing priorities, e.g., N, N-1, ..., 1\n            num_sufficient_bins = len(sorted_indices)\n            for i, original_idx in enumerate(sorted_indices):\n                # Assign a priority that decreases from N to 1 for bins with increasing capacity.\n                # So, the bin with the smallest sufficient capacity gets the highest priority among these.\n                priorities[original_idx] = num_sufficient_bins - i\n        \n    # Normalize priorities for potential future use or comparison, though not strictly necessary for selection here.\n    # If all priorities are zero (no bin can fit the item), the array remains all zeros.\n    if np.sum(priorities) > 0:\n        priorities = priorities / np.sum(priorities)\n    \n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using sigmoid fit score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bin_capacities = bins_remain_cap - item\n    valid_bins_mask = bin_capacities >= 0\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(valid_bins_mask):\n        return priorities\n\n    remaining_capacities_valid = bins_remain_cap[valid_bins_mask]\n    max_capacity = np.max(bins_remain_cap) # Consider the maximum possible capacity to normalize\n\n    if max_capacity == 0: # Avoid division by zero if all bins were full and no items could fit\n        return priorities\n\n    # Sigmoid function to map remaining capacity to a priority score.\n    # We want bins that are nearly full (low remaining capacity) to have higher priority.\n    # A larger negative slope will make the transition sharper.\n    slope = -5.0 # Adjust slope for desired sharpness of the sigmoid\n    # Shift the sigmoid so that remaining capacity of 0 (bin is exactly full) gets a high score\n    # and large remaining capacity gets a low score.\n    # shifted_remaining_capacity = (remaining_capacities_valid / max_capacity) - 1.0\n    shifted_remaining_capacity = remaining_capacities_valid / max_capacity\n\n    priorities[valid_bins_mask] = 1 / (1 + np.exp(slope * shifted_remaining_capacity))\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = cap - item\n        else:\n            priorities[i] = -1\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 8.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Epsilon-Greedy priority for Online Bin Packing Problem.\n\n    This heuristic prioritizes bins that can accommodate the item and\n    favors bins with less remaining capacity (Best Fit approach) to\n    minimize wasted space. A small epsilon is introduced to allow for\n    exploration of less optimal bins occasionally.\n    \"\"\"\n    epsilon = 0.1  # Exploration parameter\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, assign a priority based on remaining capacity\n    # Smaller remaining capacity gets a higher priority (closer to 0)\n    # Add a small epsilon to some bins to encourage exploration\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    if fitting_bins_capacities.size > 0:\n        # Calculate priorities for fitting bins: higher priority for less remaining capacity\n        # We use 1 / (remaining_capacity - item + 1) to ensure a positive value and to favor smaller remaining capacity\n        # Adding item ensures we are comparing to the capacity AFTER placing the item.\n        # Adding 1 prevents division by zero if remaining_capacity - item is 0.\n        priorities[can_fit_mask] = 1.0 / (fitting_bins_capacities - item + 1.0)\n\n        # Introduce epsilon-greedy exploration: randomly pick a subset of fitting bins and slightly alter their priority\n        num_fitting_bins = fitting_bins_capacities.size\n        num_explore = int(np.floor(epsilon * num_fitting_bins))\n        if num_explore > 0:\n            explore_indices_relative = np.random.choice(num_fitting_bins, num_explore, replace=False)\n            explore_indices_absolute = np.where(can_fit_mask)[0][explore_indices_relative]\n            # Slightly increase priority to make them more likely to be chosen if they are not the absolute best\n            priorities[explore_indices_absolute] *= (1 + np.random.uniform(0, 0.2, num_explore)) # slight boost\n\n    # Normalize priorities to be between 0 and 1 for a clear probabilistic interpretation\n    if np.max(priorities) > 0:\n        priorities = priorities / np.max(priorities)\n\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    \n    eligible_bins_mask = bins_remain_cap >= item\n    \n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    if eligible_bins_remain_cap.size > 0:\n        \n        utility = eligible_bins_remain_cap - item\n        \n        exp_utility = np.exp(utility)\n        \n        probabilities = exp_utility / np.sum(exp_utility)\n        \n        priorities[eligible_bins_mask] = probabilities\n        \n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a First Fit approach with a twist.\n\n    The priority is higher for bins that can accommodate the item and for bins that will have\n    minimal remaining capacity after the item is placed, thus trying to fill bins more effectively.\n    A small penalty is applied if the item perfectly fits to encourage using bins that are\n    not completely filled, which can be beneficial for subsequent items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_after_fit = bins_remain_cap[i] - item\n            if remaining_after_fit == 0:\n                priorities[i] = 1.0 / (remaining_after_fit + 1e-6) - 0.1\n            else:\n                priorities[i] = 1.0 / (remaining_after_fit + 1e-6)\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 10.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    available_bins_mask = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    if np.any(available_bins_mask):\n        available_bins_cap = bins_remain_cap[available_bins_mask]\n        \n        differences = available_bins_cap - item\n        \n        max_diff_index = np.argmax(differences)\n        \n        priorities[available_bins_mask][max_diff_index] = 1.0\n        \n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins_mask = bins_remain_cap >= item\n    \n    if np.any(valid_bins_mask):\n        remaining_capacities = bins_remain_cap[valid_bins_mask]\n        \n        smallest_valid_remaining_capacity = np.min(remaining_capacities)\n        \n        closest_fit_mask = (remaining_capacities - item) == 0\n        \n        if np.any(closest_fit_mask):\n            priorities[valid_bins_mask][closest_fit_mask] = 2\n        else:\n            priorities[valid_bins_mask] = 1 - (remaining_capacities / (remaining_capacities + item)) \n            \n            bins_with_smallest_capacity_mask = (remaining_capacities == smallest_valid_remaining_capacity)\n            priorities[valid_bins_mask][bins_with_smallest_capacity_mask] += 0.5 \n    \n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n14\n3\n"
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins_mask = bins_remain_cap >= item\n    remaining_caps_for_valid_bins = bins_remain_cap[valid_bins_mask]\n    diffs = remaining_caps_for_valid_bins - item\n    priorities[valid_bins_mask] = 1.0 / (1.0 + diffs)\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    eligible_bins_mask = bins_remain_cap >= item\n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    if eligible_bins_remain_cap.size > 0:\n        \n        inverse_distance = 1.0 / (bins_remain_cap[eligible_bins_mask] - item + 1e-9)\n        \n        priorities[eligible_bins_mask] = inverse_distance\n        \n        \n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    fits = bins_remain_cap >= item\n    valid_bins_cap = bins_remain_cap[fits]\n    if valid_bins_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    \n    diffs = valid_bins_cap - item\n    \n    \n    scaled_diffs = (diffs - np.min(diffs)) / (np.max(diffs) - np.min(diffs) + 1e-9)\n\n    \n    priorities = 1 / (1 + np.exp(-10 * (scaled_diffs - 0.5)))\n\n    \n    final_priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    final_priorities[fits] = priorities\n    \n    return final_priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 8.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Exploration rate\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    fittable_bins_mask = bins_remain_cap >= item\n\n    # If no bins can fit, return all zeros\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    # Greedy choice: Prioritize bins with the least remaining capacity after placing the item\n    # This encourages filling bins more completely.\n    greedy_scores = 1.0 / (bins_remain_cap[fittable_bins_mask] - item + 1e-9) # Add epsilon for division by zero\n\n    # Epsilon-Greedy strategy:\n    # With probability epsilon, choose a random fittable bin.\n    # With probability 1-epsilon, choose the bin with the highest greedy score.\n\n    num_fittable_bins = np.sum(fittable_bins_mask)\n    random_indices = np.random.choice(num_fittable_bins, size=int(epsilon * num_fittable_bins), replace=True)\n    random_fittable_bins_mask = np.zeros(num_fittable_bins, dtype=bool)\n    random_fittable_bins_mask[random_indices] = True\n\n    # Assign high priority to randomly chosen bins\n    priorities[fittable_bins_mask][random_fittable_bins_mask] = 1.0\n\n    # Assign greedy scores to the remaining fittable bins\n    non_random_fittable_indices = np.where(~random_fittable_bins_mask)[0]\n    priorities[fittable_bins_mask][non_random_fittable_indices] = greedy_scores[non_random_fittable_indices]\n\n    # Normalize priorities to be between 0 and 1\n    if np.max(priorities) > 0:\n        priorities /= np.max(priorities)\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(valid_bins_mask):\n        return np.zeros_like(bins_remain_cap)\n\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n    \n    utility = valid_bins_remain_cap - item\n    \n    exp_utility = np.exp(utility)\n    \n    probabilities = exp_utility / np.sum(exp_utility)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins_mask] = probabilities\n    \n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]