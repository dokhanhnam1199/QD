{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit's tightness with a modified Fill Ratio (item/bin_capacity).\n    Prioritizes bins that fit the item snugly and are already substantially full.\n    This aims for denser packing by favoring bins that are both a good fit and well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the current item.\n    eligible_bins_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return all zeros.\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    # Get the remaining capacities of only the eligible bins.\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # --- Best Fit Component ---\n    # This component prioritizes bins where the item leaves the least remaining capacity.\n    # A smaller remaining capacity after packing (eligible_bins_caps - item) results in a higher score.\n    # Adding a small epsilon (1e-9) prevents division by zero for bins that will be exactly full.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # --- Fill Ratio Component ---\n    # This component prioritizes bins that are already more full, relative to the item's size.\n    # A higher item size relative to the bin's remaining capacity indicates a better \"fill\".\n    # This encourages using bins that have already been utilized to a greater extent.\n    fill_ratio_scores = item / (eligible_bins_caps + 1e-9)\n\n    # --- Combined Score ---\n    # Multiply the Best Fit and Fill Ratio scores. This multiplicative approach\n    # ensures that bins excelling in BOTH criteria receive disproportionately higher scores.\n    # Bins that are a tight fit AND are already quite full are strongly preferred.\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign the calculated combined scores back to the priorities array for the eligible bins.\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1]. This makes scores comparable\n    # across different item/bin configurations and helps in selecting the top bin.\n    # Avoid division by zero if all priorities are zero (which shouldn't happen here\n    # if eligible_bins_mask is true, but good practice).\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a penalty for bins that are too large,\n    using a multiplicative scoring to encourage tighter fits and penalize waste.\n    Includes an adaptive term that favors bins with remaining capacity closer to item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins that leave less remaining capacity after fitting.\n    # Add a small epsilon to prevent division by zero.\n    best_fit_component = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Penalty for \"too large\" bins: Bins with significantly more remaining capacity than needed\n    # are less desirable as they might be better utilized by larger items later.\n    # We use an inverse relationship with the excess capacity.\n    excess_capacity = fittable_bins_remain_cap - item\n    # Penalty is higher for larger excess capacity. Cap to avoid extremely small values.\n    large_bin_penalty_component = 1.0 / (excess_capacity + 1.0)\n\n    # Adaptive \"Tightness\" Score: Aims to pick bins where the remaining capacity\n    # is *just enough* or slightly more than the item.\n    # This is similar to Best Fit but can be weighted differently.\n    # We want to maximize the remaining capacity if it's very close to the item size.\n    # We use a Gaussian-like function centered slightly above the item size.\n    # The goal is to favor bins where (remaining_cap - item) is small.\n    # For a given item, we want to find bins where remaining_cap is close to item.\n    # Let's use a score that is high when (remaining_cap - item) is small.\n    # A negative exponential function on the squared difference can work.\n    # Shifted to be centered around 0 remaining capacity after fit.\n    # Adding 1 to the exponent to avoid exp(0) = 1 and ensure lower values for larger gaps.\n    tightness_component = np.exp(-0.1 * (excess_capacity**2))\n\n\n    # Combine components using a multiplicative approach.\n    # This encourages all components to be good simultaneously.\n    # We use the inverse of the large bin penalty as a multiplier: higher penalty (smaller value)\n    # reduces the overall score.\n    # The tightness component directly contributes positively.\n    combined_scores = best_fit_component * (1.0 - large_bin_penalty_component) * tightness_component\n\n    # Normalize priorities to a [0, 1] range.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1st (weighted additive with log bonus) vs. Heuristic 2nd (multiplicative best-fit and fill ratio): Heuristic 1st attempts a more nuanced combination with a logarithmic term to manage leftover space, which can be more stable. Heuristic 2nd uses a simple multiplicative approach which can be too aggressive.\n\nComparing Heuristic 1st (weighted additive with log bonus) vs. Heuristic 3rd (complex additive with multiple components): Heuristic 1st is simpler and more direct. Heuristic 3rd's attempt at \"Proximity to Half-Capacity\" and \"Worst Fit Incentive\" without clear definitions or robust proxies makes it less reliable.\n\nComparing Heuristic 2nd (multiplicative best-fit and fill ratio) vs. Heuristic 5th (identical to 2nd, possibly a copy-paste error): They are identical, making comparison moot for ranking. However, the core idea of multiplicative best-fit and fill ratio is present in 2nd, 5th, 6th, 7th, 8th, 10th, 15th, 16th, 17th, 18th, 19th, 20th. Heuristic 10th uses a logarithmic fill bonus, which is a slight variation. Heuristics 5th, 6th, 7th, 8th are indeed identical.\n\nComparing Heuristic 4th (multiplicative with explicit penalty/bonus) vs. Heuristic 9th (multiplicative best-fit and normalized fullness): Heuristic 4th's explicit `1.0 / (1.0 + leftover_space_penalty)` is a reasonable way to incorporate a penalty, but the interaction with other terms might be sensitive. Heuristic 9th's `fullness_scores = 1.0 - (fittable_bins_remain_cap / max_initial_remain_cap)` attempts to normalize fullness, which can be more robust than absolute remaining capacity. However, it adds a constant `+ 0.1` to `fullness_scores` before multiplication, which is a heuristic dampener.\n\nComparing Heuristic 1st (weighted additive) vs. Heuristic 12th (multiplicative with adaptive tightness): Heuristic 1st's additive approach is generally more controllable than Heuristic 12th's multiplicative approach, especially with an exponential tightness component which can be sensitive. Heuristic 12th's `(1.0 - large_bin_penalty_component)` might lead to negative values if `large_bin_penalty_component` is greater than 1, which is unlikely here but a potential issue.\n\nComparing Heuristic 2nd (multiplicative best-fit and fill ratio) vs. Heuristic 10th (multiplicative best-fit and log fullness bonus): Heuristic 10th's use of `log1p(1.0 / (fittable_bins_remain_cap + 1e-9))` for fullness is a more sophisticated way to handle varying levels of fullness compared to Heuristic 2nd's simple inverse.\n\nOverall: Heuristic 1st seems to strike a good balance between simplicity, interpretability, and robustness with its weighted additive approach. Multiplicative combinations (like Heuristics 2nd, 4th, 9th, 10th) can be powerful but risk being too sensitive to specific term values or interactions. Heuristics involving complex adaptive terms or unclear proxies (like parts of Heuristic 3rd, 12th, 13th, 14th) are harder to justify without empirical validation. The numerous identical heuristics (5th, 6th, 7th, 8th) are a clear weakness in the list.\n- \nHere's a redefined \"Current self-reflection\" focused on designing better heuristics, avoiding pitfalls of ineffective self-reflection:\n\n*   **Keywords:** Multi-objective, Adaptive Weighting, Robustness, Interpretability, Granular Control.\n*   **Advice:** Design heuristics with granular control via additive components, carefully normalized. Prioritize explicit balancing of immediate packing efficiency and future bin utility. Implement adaptive weighting based on item characteristics for improved robustness.\n*   **Avoid:** Redundant heuristics, overly aggressive multiplicative combinations without clear justification, and implicit assumptions about scale or edge cases. Do not rely on near-identical implementations.\n*   **Explanation:** This approach emphasizes clarity, adaptability, and the avoidance of duplication. It suggests building complex behaviors from well-understood, controlled components rather than relying on opaque, potentially brittle multiplicative interactions or redundant strategies.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}