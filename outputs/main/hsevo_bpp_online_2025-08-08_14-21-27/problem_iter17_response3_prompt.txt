{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a bonus for already full bins, using a logarithmic bonus\n    to balance tight fits with encouraging fuller bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins that leave less remaining capacity.\n    # Adding a small epsilon to avoid division by zero.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Bonus: A bonus for bins that are already more full.\n    # Using the inverse of remaining capacity on fittable bins.\n    # Normalize by the maximum remaining capacity among fittable bins to get a relative measure.\n    max_remaining_cap_fittable = np.max(fittable_bins_remain_cap)\n    fullness_bonus = (max_remaining_cap_fittable - fittable_bins_remain_cap) / (max_remaining_cap_fittable + 1e-6)\n\n    # Adaptive Bonus using logarithm of remaining capacity after fit.\n    # This penalizes leaving excessively large gaps but gives smaller penalties for smaller gaps.\n    # Adding 1 to prevent log(0) and ensure positive values.\n    adaptive_bonus = np.log1p(fittable_bins_remain_cap - item)\n\n    # Combine: Weighted sum of Best Fit and Fullness Bonus, with Adaptive Bonus as a modifier.\n    # Weights are heuristic and can be tuned. Here, Best Fit is primary, Fullness adds context,\n    # and the Adaptive Bonus influences the penalty for leftover space.\n    # We invert the adaptive bonus as smaller leftover space (lower log) should be better.\n    combined_scores = (best_fit_scores * 1.0) + (fullness_bonus * 0.5) - (adaptive_bonus * 0.2)\n\n    # Normalize priorities to a [0, 1] range for better comparability and to avoid extreme values.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit's tightness with a modified Fill Ratio (item/bin_capacity).\n    Prioritizes bins that fit the item snugly and are already substantially full.\n    This aims for denser packing by favoring bins that are both a good fit and well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the current item.\n    eligible_bins_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return all zeros.\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    # Get the remaining capacities of only the eligible bins.\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # --- Best Fit Component ---\n    # This component prioritizes bins where the item leaves the least remaining capacity.\n    # A smaller remaining capacity after packing (eligible_bins_caps - item) results in a higher score.\n    # Adding a small epsilon (1e-9) prevents division by zero for bins that will be exactly full.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # --- Fill Ratio Component ---\n    # This component prioritizes bins that are already more full, relative to the item's size.\n    # A higher item size relative to the bin's remaining capacity indicates a better \"fill\".\n    # This encourages using bins that have already been utilized to a greater extent.\n    fill_ratio_scores = item / (eligible_bins_caps + 1e-9)\n\n    # --- Combined Score ---\n    # Multiply the Best Fit and Fill Ratio scores. This multiplicative approach\n    # ensures that bins excelling in BOTH criteria receive disproportionately higher scores.\n    # Bins that are a tight fit AND are already quite full are strongly preferred.\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign the calculated combined scores back to the priorities array for the eligible bins.\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1]. This makes scores comparable\n    # across different item/bin configurations and helps in selecting the top bin.\n    # Avoid division by zero if all priorities are zero (which shouldn't happen here\n    # if eligible_bins_mask is true, but good practice).\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1st (weighted additive with log bonus) vs. Heuristic 2nd (multiplicative best-fit and fill ratio): Heuristic 1st attempts a more nuanced combination with a logarithmic term to manage leftover space, which can be more stable. Heuristic 2nd uses a simple multiplicative approach which can be too aggressive.\n\nComparing Heuristic 1st (weighted additive with log bonus) vs. Heuristic 3rd (complex additive with multiple components): Heuristic 1st is simpler and more direct. Heuristic 3rd's attempt at \"Proximity to Half-Capacity\" and \"Worst Fit Incentive\" without clear definitions or robust proxies makes it less reliable.\n\nComparing Heuristic 2nd (multiplicative best-fit and fill ratio) vs. Heuristic 5th (identical to 2nd, possibly a copy-paste error): They are identical, making comparison moot for ranking. However, the core idea of multiplicative best-fit and fill ratio is present in 2nd, 5th, 6th, 7th, 8th, 10th, 15th, 16th, 17th, 18th, 19th, 20th. Heuristic 10th uses a logarithmic fill bonus, which is a slight variation. Heuristics 5th, 6th, 7th, 8th are indeed identical.\n\nComparing Heuristic 4th (multiplicative with explicit penalty/bonus) vs. Heuristic 9th (multiplicative best-fit and normalized fullness): Heuristic 4th's explicit `1.0 / (1.0 + leftover_space_penalty)` is a reasonable way to incorporate a penalty, but the interaction with other terms might be sensitive. Heuristic 9th's `fullness_scores = 1.0 - (fittable_bins_remain_cap / max_initial_remain_cap)` attempts to normalize fullness, which can be more robust than absolute remaining capacity. However, it adds a constant `+ 0.1` to `fullness_scores` before multiplication, which is a heuristic dampener.\n\nComparing Heuristic 1st (weighted additive) vs. Heuristic 12th (multiplicative with adaptive tightness): Heuristic 1st's additive approach is generally more controllable than Heuristic 12th's multiplicative approach, especially with an exponential tightness component which can be sensitive. Heuristic 12th's `(1.0 - large_bin_penalty_component)` might lead to negative values if `large_bin_penalty_component` is greater than 1, which is unlikely here but a potential issue.\n\nComparing Heuristic 2nd (multiplicative best-fit and fill ratio) vs. Heuristic 10th (multiplicative best-fit and log fullness bonus): Heuristic 10th's use of `log1p(1.0 / (fittable_bins_remain_cap + 1e-9))` for fullness is a more sophisticated way to handle varying levels of fullness compared to Heuristic 2nd's simple inverse.\n\nOverall: Heuristic 1st seems to strike a good balance between simplicity, interpretability, and robustness with its weighted additive approach. Multiplicative combinations (like Heuristics 2nd, 4th, 9th, 10th) can be powerful but risk being too sensitive to specific term values or interactions. Heuristics involving complex adaptive terms or unclear proxies (like parts of Heuristic 3rd, 12th, 13th, 14th) are harder to justify without empirical validation. The numerous identical heuristics (5th, 6th, 7th, 8th) are a clear weakness in the list.\n- \nHere's a redefined \"Current self-reflection\" focused on designing better heuristics, avoiding pitfalls of ineffective self-reflection:\n\n*   **Keywords:** Multi-objective, Adaptive Weighting, Robustness, Interpretability, Granular Control.\n*   **Advice:** Design heuristics with granular control via additive components, carefully normalized. Prioritize explicit balancing of immediate packing efficiency and future bin utility. Implement adaptive weighting based on item characteristics for improved robustness.\n*   **Avoid:** Redundant heuristics, overly aggressive multiplicative combinations without clear justification, and implicit assumptions about scale or edge cases. Do not rely on near-identical implementations.\n*   **Explanation:** This approach emphasizes clarity, adaptability, and the avoidance of duplication. It suggests building complex behaviors from well-understood, controlled components rather than relying on opaque, potentially brittle multiplicative interactions or redundant strategies.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}