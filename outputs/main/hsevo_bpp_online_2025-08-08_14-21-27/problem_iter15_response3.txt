```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Aims to improve upon v1 by using a multiplicative scoring approach that
    inherently balances competing objectives and is less sensitive to arbitrary
    weight adjustments. It prioritizes bins that offer a tight fit AND have
    substantial remaining capacity (to avoid prematurely fragmenting larger spaces),
    while also penalizing bins that are already nearly full to encourage
    utilization of less occupied bins.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    fittable_bins_mask = bins_remain_cap >= item

    if not np.any(fittable_bins_mask):
        return priorities

    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]

    # Score 1: Tight Fit Preference (similar to Best Fit).
    # Higher score for smaller leftover space. Add epsilon for numerical stability.
    tight_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)

    # Score 2: Space Utilization Preference.
    # Prioritize bins that are already more utilized (i.e., have less remaining capacity).
    # This encourages filling up existing bins before opening new ones.
    # Normalize by bin capacity (assuming capacity is uniform, which it is in BPP)
    # Or more generally, by the maximum capacity if it varied. Here, remaining capacity is sufficient.
    # Higher score for smaller remaining capacity among fittable bins.
    space_utilization_score = 1.0 / (fittable_bins_remain_cap + 1e-9)

    # Score 3: Robustness/Avoidance of Over-fragmentation.
    # Penalize bins that, after fitting the item, leave a very large amount of capacity.
    # This aims to avoid packing an item into a very large bin if a medium-sized bin is available.
    # We want to prefer bins that leave a "reasonable" amount of space, not too little and not too much.
    # Using a Gaussian-like penalty centered around a "good" leftover space, or more simply,
    # penalizing very large leftovers. A simple inverse square of remaining capacity after fit.
    # Or even simpler, penalize bins that leave capacity significantly larger than the item size.
    # Let's use a penalty proportional to the log of the remaining capacity AFTER the fit.
    # Smaller log means better.
    leftover_space_penalty = np.log1p(fittable_bins_remain_cap - item) # Smaller is better

    # Combine scores multiplicatively. This creates a synergy where bins must perform well
    # on multiple criteria. A bin with a good tight fit but terrible space utilization (e.g., very empty)
    # will be penalized. Similarly, a bin with high utilization but a very poor fit will be penalized.

    # We want to:
    # 1. Maximize tight fit (high tight_fit_score)
    # 2. Maximize space utilization (high space_utilization_score)
    # 3. Minimize leftover space penalty (low leftover_space_penalty)

    # Multiplicative combination: Score = (TightFit) * (SpaceUtil) / (1 + LeftoverPenalty)
    # Adding 1 to penalty to avoid division by zero and to ensure it acts as a penalty.
    # A lower leftover_space_penalty should result in a higher combined score.
    # So, divide by (1 + penalty) or multiply by 1/(1+penalty)
    combined_scores = tight_fit_score * space_utilization_score * (1.0 / (1.0 + leftover_space_penalty))

    # Normalize priorities to a [0, 1] range.
    max_score = np.max(combined_scores)
    if max_score > 1e-9:
        priorities[fittable_bins_mask] = combined_scores / max_score
    else:
        # If all scores are effectively zero, assign a small uniform priority to fittable bins.
        priorities[fittable_bins_mask] = 0.1

    return priorities
```
