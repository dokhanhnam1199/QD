```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    fittable_bins_mask = bins_remain_cap >= item

    if not np.any(fittable_bins_mask):
        return priorities

    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]

    # Best Fit Score: Inverse of remaining capacity after fit.
    # Higher score for bins leaving less space. Add epsilon for stability.
    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)

    # Fullness Bonus: Proportional to how full the bin is *before* fitting the item.
    # This encourages using bins that are already substantially filled.
    # We use the inverse of the remaining capacity, normalized by a conceptual maximum initial capacity (e.g., 1.0 for normalized bin sizes).
    # If bin sizes are not normalized, using a large constant or the max initial capacity would be better.
    # For simplicity here, we normalize by the maximum capacity *among fittable bins before fitting*.
    max_cap_before_fit = np.max(bins_remain_cap[fittable_bins_mask] + item) # approximate initial capacity of the most full fittable bin
    fullness_scores = (max_cap_before_fit - fittable_bins_remain_cap) / (max_cap_before_fit + 1e-6)


    # Adaptive Gap Penalty: Penalize leaving large gaps, but with diminishing returns for smaller gaps.
    # Logarithm of the *remaining* capacity after fitting the item.
    # We use log1p to handle cases where remaining capacity is 0.
    # Lower values are better (smaller gaps), so we'll invert this for the final score.
    gap_penalty = np.log1p(fittable_bins_remain_cap - item)


    # Combine scores using a multiplicative approach with adaptive weighting.
    # This aims to balance the objectives more dynamically.
    # Best Fit is the primary driver.
    # Fullness Bonus is multiplicative, boosting scores of fuller bins.
    # Gap Penalty is used to reduce scores if the fit leaves a large gap.
    # We invert the gap penalty and scale it to be additive, acting as a bonus for small gaps.

    # Initial combined score heavily favoring best fit
    combined_scores = best_fit_scores * (1 + fullness_scores * 0.5) # Multiplicative bonus for fullness

    # Add a bonus for small gaps, inversely related to the gap penalty
    # Max value of gap_penalty is log1p(max_remaining_cap_fittable - item)
    # We want to reward smaller gap_penalty values.
    # A simple way is to subtract a scaled version of the gap_penalty.
    # The scaling factor needs careful tuning based on typical item sizes and bin capacities.
    # Let's use a factor derived from the range of gap_penalties.
    min_gap_penalty = np.min(gap_penalty)
    max_gap_penalty = np.max(gap_penalty)
    gap_range = max_gap_penalty - min_gap_penalty

    if gap_range > 1e-9:
        # Normalize gap_penalty to [0, 1] and subtract from 1 to get a bonus for small gaps.
        # Small gap_penalty -> large bonus. Large gap_penalty -> small bonus.
        small_gap_bonus = 1.0 - (gap_penalty - min_gap_penalty) / gap_range
        combined_scores += small_gap_bonus * 0.3 # Additive bonus for small gaps
    else:
        # If all gaps are similar, add a small uniform bonus
        combined_scores += 0.3 * 0.5


    # Normalize priorities to a [0, 1] range.
    max_score = np.max(combined_scores)
    if max_score > 1e-9:
        priorities[fittable_bins_mask] = np.clip(combined_scores / max_score, 0, 1)
    else:
        priorities[fittable_bins_mask] = 0.1

    return priorities
```
