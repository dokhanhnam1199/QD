{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n    fittable_indices = np.where(fittable_bins_mask)[0]\n\n    # Component 1: Best Fit - Prioritize bins that leave minimal remaining capacity.\n    # This encourages tighter packing. Use inverse of remaining space + epsilon.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Component 2: Worst Fit Incentive - Prioritize bins that have a larger remaining capacity\n    # among the fittable bins. This aims to keep smaller remaining capacities available for\n    # smaller items later, potentially leading to fewer bins being used overall.\n    # Calculate the gap created if the item is placed, and then rank bins by the *largest* gap.\n    gaps = fittable_bins_remain_cap - item\n    worst_fit_score = gaps # Higher gap is better here.\n\n    # Component 3: Proximity to Half-Capacity Bonus - This heuristic aims to balance bins\n    # around the mid-point of their capacity. Bins that, after fitting, are closer to\n    # half-full might be more versatile for future items.\n    # We are interested in bins where (remaining_cap - item) is close to bin_capacity / 2.\n    # For simplicity, we can approximate this by looking at the remaining capacity\n    # relative to a \"medium\" size. Let's consider bins that, after fitting the item,\n    # have a remaining capacity that is not too small and not too large.\n    # A score that peaks when remaining_cap - item is around some threshold (e.g., 0.5 * bin_capacity).\n    # For simplicity here, let's use a score that is high when the remaining capacity\n    # after fit is \"reasonable\" (not too close to 0, not too close to full).\n    # This is a simplification, a more robust approach might involve estimating typical item sizes.\n    # For now, we'll use a score that is high when the leftover space is moderate.\n    # A simple Gaussian-like function centered around a moderate leftover space.\n    # Let's assume a moderate leftover space is around 0.3 of the original bin capacity.\n    # Since we don't know the original bin capacity, we can use a proxy like the average\n    # remaining capacity of fittable bins. This is heuristic.\n    avg_fittable_remain_cap = np.mean(fittable_bins_remain_cap)\n    # Score is higher when (fittable_bins_remain_cap - item) is closer to avg_fittable_remain_cap\n    # We can use a Gaussian-like function, or simpler: penalize extremes.\n    # Let's reward bins that leave a moderate amount of space, not too little (handled by BF)\n    # and not too much (handled by WF).\n    # Score is higher for leftover space that is not too small (but not too large either).\n    # Let's consider the relative leftover space.\n    relative_leftover = (fittable_bins_remain_cap - item) / (np.max(fittable_bins_remain_cap) + 1e-9)\n    # We want to favor bins where relative_leftover is in a middle range, e.g., 0.2 to 0.7.\n    # A simple approach: penalize very small or very large relative leftovers.\n    # This is tricky without knowing the distribution of item sizes or bin capacities.\n    # A simpler proxy: favor bins that are not already almost full, but also not almost empty.\n    # Let's use a score that is higher for bins that are neither very full nor very empty.\n    # This can be seen as a \"balance\" score.\n    balance_score = (fittable_bins_remain_cap - item) / (fittable_bins_remain_cap + 1e-9) # Score closer to 1 means less remaining space.\n    # We want to reward bins that have *some* remaining space, but not excessive.\n    # So we want balance_score to be less than 1.\n    # Let's invert it: higher score for more remaining space, capped.\n    # Alternatively, prioritize bins that are \"medium\" full.\n    # Consider remaining capacity as a proportion of total capacity (which is unknown, assume 1.0 for normalized).\n    # A score that peaks when remaining_cap - item is around 0.5.\n    # Let's simplify: reward bins that have a moderate remaining capacity after fitting.\n    # This is inherently difficult without knowledge of total capacity.\n    # Alternative interpretation of \"balance\": favor bins that are not too empty after fitting.\n    # This means favoring bins where fittable_bins_remain_cap - item is not extremely small.\n    # This is implicitly handled by Best Fit to some extent.\n\n    # Let's try a different approach for Component 3: Affinity for a \"central\" remaining capacity.\n    # Suppose we want to keep bins with remaining capacities in a mid-range.\n    # This is hard to define without bin capacity.\n    # A simpler approach: Reward bins that are not *too* full after placing the item.\n    # Penalize bins that would become very full.\n    # Score = 1 - (remaining_cap - item) / max_possible_remaining_space (which is max(bins_remain_cap))\n    # This is similar to penalizing tight fits.\n\n    # Let's combine Best Fit and Worst Fit with a multiplicative approach,\n    # and add a term that encourages moderate usage of bins.\n    # Multiplicative combines scores more aggressively.\n\n    # Normalize component scores to a comparable range, e.g., [0, 1] or similar.\n    # Best Fit: Already inverse, higher is better. Max value can be large.\n    # Worst Fit: Higher gap is better. Max value can be large.\n    # Let's normalize gaps to be in [0, 1] where 1 is the largest gap.\n    normalized_worst_fit = gaps / (np.max(gaps) + 1e-9)\n\n    # Let's try a score that favors bins that aren't too full, but also not too empty.\n    # A score that is higher when the remaining capacity after fit is moderate.\n    # This is hard without knowing the bin capacity.\n    # Alternative: Reward bins that are \"moderately used\".\n    # If we consider the remaining capacity `r` after fitting item `i`, we want `r` not too small and not too large.\n    # A simple score could be: `exp(-k * (r - target_r)^2)`. But `target_r` is unknown.\n    # Let's try a score that is higher for bins that have *some* remaining space, but not a lot.\n    # This is difficult to formulate generally.\n\n    # Let's reconsider the objective: Minimize the number of bins.\n    # Heuristics typically aim to either:\n    # 1. Pack tightly (Best Fit) to reduce wasted space *within* a bin.\n    # 2. Leave larger gaps (Worst Fit) to accommodate potentially larger future items.\n    # 3. Fill bins \"evenly\" (First Fit Decreasing style).\n\n    # For v2, let's prioritize bins that are *close* to fitting the item (Best Fit aspect),\n    # AND among those that are a \"good fit\", prefer those that are *more full* overall\n    # (but not so full they become unusable later), and also slightly favor those that leave\n    # a decent remaining space (Worst Fit aspect).\n\n    # Let's try a weighted additive combination with focus on robustness and interaction.\n    # Score = w1 * (BestFit) + w2 * (WorstFit) + w3 * (ModerateRemaining)\n\n    # Best Fit score: Higher for smaller leftover space.\n    # Let's scale it by the item size itself. The smaller the leftover relative to item size, the better.\n    # scaled_best_fit = 1.0 / ((fittable_bins_remain_cap - item) / item + 1e-9)\n    # This can be unstable if item size is small. Let's stick to inverse of absolute leftover.\n    best_fit_term = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Worst Fit score: Higher for larger leftover space.\n    # Let's normalize by the maximum possible leftover space.\n    # Max leftover space can be the max remaining capacity among fittable bins.\n    max_fittable_rem = np.max(fittable_bins_remain_cap)\n    worst_fit_term = (fittable_bins_remain_cap - item) / (max_fittable_rem + 1e-9)\n\n    # New component: \"Bin Utilization Balance\"\n    # Favor bins that are not excessively empty or excessively full after fitting.\n    # Consider the remaining capacity `r = fittable_bins_remain_cap[i] - item`.\n    # We want `r` to be neither too close to 0 nor too close to `fittable_bins_remain_cap[i]`.\n    # A simple score: The more remaining capacity, the less \"balanced\" it is in terms of filling.\n    # However, we want to balance *usage*, not necessarily remaining space.\n    # Let's try to encourage bins that are \"moderately full\".\n    # If `fittable_bins_remain_cap[i]` is the current remaining capacity, and `item` is placed.\n    # The *new* remaining capacity is `r = fittable_bins_remain_cap[i] - item`.\n    # We want `r` to be \"reasonable\".\n    # Consider the ratio of current remaining capacity to the capacity used.\n    # Current remaining capacity: `c`. Item size: `i`. New remaining capacity: `c - i`.\n    # Capacity used: `TotalCapacity - c`. Capacity used by item: `i`.\n    # Let's consider the proportion of remaining capacity relative to the *original* bin capacity.\n    # Since original bin capacity is unknown, let's use the *current* remaining capacity as a proxy for how \"full\" the bin is.\n    # A bin with high `fittable_bins_remain_cap` is less full.\n    # We want bins that are not too empty. So, `fittable_bins_remain_cap[i]` shouldn't be extremely large.\n    # Let's create a score that penalizes bins that have a very large remaining capacity.\n    # Higher score for smaller `fittable_bins_remain_cap`.\n    # Let's use inverse of remaining capacity, but capped.\n    # Or, inverse of remaining capacity to the power of some factor.\n    # Let's try: `fittable_bins_remain_cap[i] / (fittable_bins_remain_cap[i] + item)` - proportion of capacity already filled with current item.\n    # This doesn't consider the bin's state.\n\n    # Let's try a score that promotes bins that are *not* almost full, and also *not* almost empty.\n    # This is the \"balanced\" idea.\n    # Score for being \"not too empty\": penalize large `fittable_bins_remain_cap`.\n    # Score for being \"not too full\": penalize small `fittable_bins_remain_cap - item`.\n    # This is conflicting with Best Fit.\n\n    # Let's refine the idea of balancing: Aim for bins where the remaining capacity after fitting\n    # is not too small (to avoid wasting tiny gaps) and not too large (to encourage fuller bins).\n    # This is like a soft \"Best Fit\" and a soft \"Worst Fit\" simultaneously.\n\n    # Let's consider the \"effective remaining capacity\" as `fittable_bins_remain_cap - item`.\n    # We want this to be small (BestFit) but not too small.\n    # And we want the bin to not be excessively full.\n    # The previous v1 used `log1p(fittable_bins_remain_cap - item)` which penalizes larger gaps.\n    # We want to penalize *very small* gaps and *very large* gaps.\n\n    # Let's try a score that combines Best Fit and Worst Fit multiplicatively,\n    # and add a term that rewards bins that are \"medium\" full.\n    # Multiplicative combination: `(BestFitTerm) * (WorstFitTerm) * (MediumFillTerm)`\n    # This requires all terms to be positive and well-behaved.\n\n    # Let's define terms for the fittable bins:\n    # Term 1: Tightness score (Best Fit proxy) - higher for less remaining space.\n    # Score is proportional to 1 / (remaining_cap - item).\n    tightness_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Term 2: Gap score (Worst Fit proxy) - higher for more remaining space.\n    # Score is proportional to (remaining_cap - item).\n    gap_score = fittable_bins_remain_cap - item\n\n    # Term 3: Balance score - Higher for moderate remaining capacity.\n    # This is tricky without bin capacity. Let's assume we want remaining capacity to be\n    # in a \"central\" range. If the max remaining capacity among fittable bins is `M`,\n    # we might want `fittable_bins_remain_cap[i] - item` to be around `M/2` or `item`.\n    # Let's try a score that is higher when `fittable_bins_remain_cap[i] - item` is\n    # not extremely small and not extremely large.\n    # A Gaussian-like score: `exp(-k * (gap - target_gap)^2)`.\n    # Let's simplify: penalize bins that leave very little space and bins that leave very much space.\n    # This can be achieved by penalizing `gap` near 0 and `gap` near `max_fittable_rem`.\n    # A score that is high in the middle range of gaps.\n    # We can use a function like `sin(pi * gap / (max_fittable_rem + epsilon))` which peaks at `max_fittable_rem / 2`.\n    # Or a simple heuristic: favor bins that are not already mostly full.\n    # Let's consider the ratio of `item` to `fittable_bins_remain_cap`. A higher ratio means the item fills more of the *available* space.\n    # `item / fittable_bins_remain_cap` -> higher means more \"efficient\" use of *current* remaining space.\n    # However, `fittable_bins_remain_cap` itself varies.\n\n    # Let's try a simpler additive combination with adjusted weights and terms.\n    # We want to balance tight packing (Best Fit) with leaving useful gaps (Worst Fit).\n    # Add a term that considers the absolute \"fullness\" of the bin relative to its current state.\n    # Favor bins that have a good amount of remaining capacity, but not so much that they are nearly empty.\n    # This is a delicate balance.\n\n    # Proposed v2 strategy:\n    # 1. Best Fit component: score = 1 / (residual_capacity + epsilon) - promotes tight fits.\n    # 2. Worst Fit component: score = residual_capacity - promotes leaving larger gaps.\n    # 3. \"Fill Balance\" component: score = (current_remaining_cap - residual_capacity) / (current_remaining_cap + epsilon)\n    #    This term represents the proportion of the bin's *current available space* that is used by the item.\n    #    A higher score means the item uses a larger fraction of the *current available space*.\n    #    This favors bins that are not extremely empty, but also not extremely full.\n    #    If a bin has 100 capacity and item is 60, score is 60/100 = 0.6.\n    #    If a bin has 10 capacity and item is 8, score is 8/10 = 0.8.\n    #    This implicitly favors bins that are more full.\n\n    # Let's redefine components for fittable bins:\n    residual_capacity = fittable_bins_remain_cap - item\n\n    # Component 1: Best Fit (inverse residual)\n    # Higher score for smaller residual capacity.\n    best_fit_val = 1.0 / (residual_capacity + 1e-9)\n\n    # Component 2: Worst Fit (residual capacity itself)\n    # Higher score for larger residual capacity.\n    worst_fit_val = residual_capacity\n\n    # Component 3: \"Proportional Fill\" - How much of the *available space* does the item consume?\n    # Score = item_size / available_space = item_size / fittable_bins_remain_cap\n    # This favors using up a larger chunk of the existing available space.\n    # If fittable_bins_remain_cap is small, this ratio can be large.\n    # This term might favor bins that are already quite full.\n    proportional_fill_val = item / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine these terms. A multiplicative combination can be powerful but sensitive.\n    # Let's use weighted additive combination for better control.\n    # Weights can be tuned. Let's give Best Fit a primary role, Worst Fit a secondary,\n    # and Proportional Fill a moderating role.\n\n    # Normalize terms to prevent dominance by scale.\n    # Best Fit: can be large. Normalize by max BF score.\n    normalized_bf = best_fit_val / (np.max(best_fit_val) + 1e-9)\n\n    # Worst Fit: range is 0 to max_fittable_rem. Normalize by max_fittable_rem.\n    normalized_wf = worst_fit_val / (np.max(fittable_bins_remain_cap) + 1e-9)\n\n    # Proportional Fill: range is 0 to 1 (if item <= fittable_bins_remain_cap).\n    normalized_pf = proportional_fill_val\n\n    # Combine with weights.\n    # Let's try:\n    # w_bf = 1.0\n    # w_wf = 0.5  # Slightly favor leaving gaps\n    # w_pf = 0.3  # Moderate preference for using a good portion of available space\n    # This combination aims to find bins that are a good fit (BF), and among them,\n    # favors those that leave decent gaps (WF), and also prefer bins where the item\n    # consumes a noticeable fraction of the current available space (PF).\n\n    # Let's consider a different balance: Best Fit vs. Worst Fit.\n    # Standard BF puts item in bin with minimum remaining capacity.\n    # Standard WF puts item in bin with maximum remaining capacity.\n\n    # For v2, let's try to bridge BF and WF.\n    # Consider bins that are \"good fits\" (residual_capacity not too large).\n    # Among these, prefer those that are tighter (BF) but also those that leave\n    # a \"reasonable\" gap (WF).\n\n    # How about a score that is a combination of the \"tightness\" and the \"gap left\"?\n    # Let's use a score that is higher for bins that are a good fit,\n    # and among those, prefer tighter fits, but not *extreme* tight fits if they leave\n    # a very large capacity unused in other bins.\n\n    # Let's reconsider the problem as selecting a bin that offers a good trade-off.\n    # Consider the score as a function of the residual capacity `r = fittable_bins_remain_cap - item`.\n    # We want `r` to be small (BF) but not zero if that means leaving other bins very empty.\n    # We want `r` to be moderate (WF proxy).\n\n    # Let's try a score that is high when `r` is small and when `fittable_bins_remain_cap` is also not too large.\n    # This encourages using bins that are already somewhat full.\n\n    # New strategy: Prioritize bins that have a remaining capacity not much larger than the item itself.\n    # This is a \"close fit\" idea, but not necessarily the absolute tightest.\n    # Score = 1.0 / (abs(fittable_bins_remain_cap - item - target_gap) + epsilon)\n    # Where `target_gap` could be 0 (BF), or something positive.\n\n    # Let's try a score based on the *ratio* of residual capacity to the bin's current remaining capacity.\n    # `residual_capacity / fittable_bins_remain_cap`\n    # This is `(fittable_bins_remain_cap - item) / fittable_bins_remain_cap`\n    # This score is lower when the bin is more full.\n    # We want this score to be not too high (meaning small residual) and not too low (meaning large residual).\n    # This is like a \"middle ground\" score for the residual.\n\n    # Let's combine Best Fit with a penalty for leaving *too much* empty space.\n    # Score = BestFitScore * (1 - penalty for large residual)\n    # Penalty for large residual could be `residual / max_residual`.\n\n    # Proposed v2: Multiplicative combination of Best Fit and a \"Fill Preference\".\n    # Best Fit Score: 1 / (residual_capacity + epsilon). Higher is better.\n    # Fill Preference Score: Favor bins that are not \"too empty\".\n    # If `fittable_bins_remain_cap` is large, the bin is \"more empty\".\n    # So, we want to penalize large `fittable_bins_remain_cap`.\n    # Score = `1 / (fittable_bins_remain_cap + epsilon)`. Higher is better.\n    # Let's try `(1 / (residual_capacity + epsilon)) * (1 / (fittable_bins_remain_cap + epsilon))`\n    # This would favor bins that are both tight fits AND are already quite full.\n    # This might be too aggressive on filling early bins.\n\n    # Let's try an additive combination that balances tight fits with leaving moderate gaps.\n    # Term 1: Best Fit (inverse residual capacity)\n    # Term 2: Worst Fit (residual capacity)\n    # Combine: `w1 * (1 / residual) + w2 * residual`\n    # This form tends to have a minimum when `w1 / residual^2 = w2`, so `residual = sqrt(w1/w2)`.\n    # This suggests that this combination favors residuals around a specific value.\n\n    # Let's use weighted combination of Best Fit and a \"Balance\" score.\n    # Best Fit: `1 / (residual_capacity + epsilon)`\n    # Balance: Favor bins that are not excessively full. This means penalizing bins\n    # where `fittable_bins_remain_cap` is small.\n    # So, favor bins with larger `fittable_bins_remain_cap`, but not too large.\n    # Let's use `fittable_bins_remain_cap` itself as a score (higher is better, means more space).\n    # This is akin to Worst Fit, but we want it to be moderate.\n\n    # Let's consider the *efficiency* of filling.\n    # Score = (item_size) / (bin_capacity). This requires bin capacity.\n    # Proxy: (item_size) / (fittable_bins_remain_cap + item_size)\n    # This is the proportion of the *used* space relative to the *new remaining* space.\n    # This is `item / new_remaining_cap`.\n    # This term is higher for tight fits. It's similar to Best Fit.\n\n    # Let's try a score that balances Best Fit and Worst Fit, using a sigmoid-like function to shape the preference.\n    # `score = BF_score * (1 - WF_score)`\n    # `score = (1 / residual_capacity) * (1 - residual_capacity / max_residual)`\n    # This rewards small residuals, but penalizes extremely small ones if max_residual is large.\n\n    # Let's use a weighted sum of Best Fit and Worst Fit, with an adjustment factor.\n    # Final proposed v2 strategy:\n    # 1. Primary: Best Fit (favoring tightness)\n    # 2. Secondary: Balance (favoring bins that are not too full, but also not too empty)\n    #    This balance is tricky. Let's try favoring bins where the residual capacity\n    #    is not excessively large compared to the item itself.\n    #    Score: `1 - residual_capacity / (item + epsilon)`\n    #    This term is higher when `residual_capacity` is small relative to `item`.\n    #    So, it rewards tighter fits, but also penalizes leaving *much* more space than the item's size.\n\n    residual_capacity = fittable_bins_remain_cap - item\n\n    # Component 1: Best Fit (inverse of residual capacity)\n    # Favors bins with smallest leftover space.\n    best_fit_score = 1.0 / (residual_capacity + 1e-9)\n\n    # Component 2: Balance / Moderate Fit\n    # Favor bins where the residual capacity is not excessively large compared to the item.\n    # This acts as a penalty for leaving very large gaps, especially if other bins could be filled more.\n    # Score is higher when residual_capacity is small relative to item size.\n    # `balance_score = (item + 1e-9) / (residual_capacity + item + 1e-9)`\n    # This score is close to 1 for tight fits, and close to 0 for very large residuals.\n    # Let's normalize it to make it more robust.\n    # A simpler approach: `1 - (residual_capacity / (item + epsilon))`\n    # This score is 1 when residual is 0, and goes to -inf as residual increases.\n    # Let's try `exp(-k * residual_capacity / item)` for some k.\n    # Or, a capped version: `max(0, 1 - residual_capacity / (item * 2))`\n    # Let's use a simpler form: favor bins whose remaining capacity `fittable_bins_remain_cap` is not overwhelmingly large.\n    # Use `1 / (fittable_bins_remain_cap + epsilon)` as a proxy for \"not too empty\".\n\n    # Let's use a weighted sum of Best Fit and a \"Gap Management\" score.\n    # Best Fit: `1 / residual_capacity`\n    # Gap Management: Favor residual capacities that are not too small and not too large.\n    # Let's normalize residual capacity by the maximum residual capacity among fittable bins.\n    # `norm_residual = residual_capacity / (np.max(residual_capacity) + 1e-9)`\n    # We want to avoid `norm_residual` being too close to 0 (tight fit, covered by BF)\n    # and too close to 1 (large gap).\n    # A score that peaks in the middle, e.g., `1 - (2 * norm_residual - 1)^2` or similar.\n\n    # Final proposal for v2:\n    # Combine Best Fit with a term that prefers bins that are neither too empty nor too full *after* fitting.\n    # This means the `residual_capacity` should be in a moderate range.\n    # Let's aim for residual capacity to be roughly proportional to the item size, but not excessively so.\n\n    # Term 1: Best Fit (inverse of residual capacity)\n    best_fit_term = 1.0 / (residual_capacity + 1e-9)\n\n    # Term 2: Moderate Residual Capacity Preference\n    # We want to favor `residual_capacity` that are not extremely small (handled by BF)\n    # and not extremely large.\n    # Let's try to score bins based on how close their residual capacity is to the *average* residual capacity.\n    # `avg_residual = np.mean(residual_capacity)`\n    # `balance_score = 1.0 / (abs(residual_capacity - avg_residual) + 1e-9)`\n    # This could be unstable if `avg_residual` is close to `residual_capacity`.\n\n    # Alternative Balance Term: Favor bins that use a good fraction of their available capacity.\n    # Score = `item / fittable_bins_remain_cap` (already considered).\n\n    # Let's try a simpler weighted sum, but with more carefully chosen terms.\n    # Term 1: Best Fit (tightness) - `1 / (residual_capacity + epsilon)`\n    # Term 2: Fill Preference (favoring not-too-empty bins) - `fittable_bins_remain_cap` itself.\n    # This favors bins that have more space, which is \"Worst Fit\" like.\n\n    # Let's aim for a score that rewards tightness, but with diminishing returns for extreme tightness.\n    # And also rewards leaving some space, but with diminishing returns for extreme openness.\n\n    # Final proposed v2 using multiplicative combination for stronger interactions:\n    # Score = (BestFitScore) * (BalanceScore)\n    # BestFitScore = 1 / (residual_capacity + epsilon)\n    # BalanceScore = how \"balanced\" the bin is. Let's favor bins that have\n    # a moderate amount of remaining capacity after fitting.\n    # If `fittable_bins_remain_cap` is the current remaining capacity, and `r` is residual.\n    # We want `r` to be not too small and not too large.\n    # Let's define a \"good\" residual range. Suppose it's `[min_res, max_res]`.\n    # Score is high when `r` is in this range.\n    # This is hard to define without context.\n\n    # Let's use Best Fit and Worst Fit combined, where the combination is non-linear.\n    # Consider a score that prioritizes bins with small residuals, but gives a bonus\n    # if the bin was already quite full.\n\n    # Try: Score = (BestFit) + Alpha * (FillRatio)\n    # FillRatio = `item / fittable_bins_remain_cap`\n\n    # Let's try a score that is a trade-off between Best Fit and Worst Fit.\n    # Score = `(1 / residual_capacity) * (1 - residual_capacity / max_possible_gap)`\n    # `max_possible_gap` can be `max(fittable_bins_remain_cap)`.\n    # `score = (1 / residual_capacity) * (1 - residual_capacity / max_fittable_rem)`\n    # This score peaks when `residual_capacity` is around `max_fittable_rem / 3`.\n\n    # Let's define our v2 heuristic as:\n    # Combine Best Fit with a \"fill percentage\" score.\n    # Best Fit: `1 / (residual_capacity + epsilon)`\n    # Fill Percentage: The percentage of the *current available capacity* that the item uses.\n    # This is `item / fittable_bins_remain_cap`.\n    # Higher fill percentage is good, means the item is utilizing a good chunk of what's available.\n\n    # Weighted Sum:\n    # `score = w1 * (1 / residual_capacity) + w2 * (item / fittable_bins_remain_cap)`\n    # Weights `w1` and `w2` need tuning.\n\n    # Normalization:\n    # Max residual capacity among fittable bins.\n    max_residual = np.max(residual_capacity)\n    # Max value for `item / fittable_bins_remain_cap` is 1.\n\n    # Let's try a multiplicative approach again, with normalized terms.\n    # Normalized Best Fit: `(1 / residual_capacity) / max(1 / residual_capacity)`\n    # Normalized Fill Percentage: `(item / fittable_bins_remain_cap) / max(item / fittable_bins_remain_cap)`\n    # This can be unstable if `max` is zero or very small.\n\n    # Let's use an additive approach with robust terms.\n    # Term 1: Best Fit - `1.0 / (residual_capacity + 1e-9)`\n    # Term 2: \"Bin Usage Balance\" - Favor bins that are not nearly empty.\n    # The \"fuller\" a bin is, the less remaining capacity it has.\n    # So, we want to favor bins with *smaller* `fittable_bins_remain_cap`.\n    # Score for this: `1.0 / (fittable_bins_remain_cap + 1e-9)`\n    # This term encourages using bins that are already quite full.\n\n    # Combine: `score = w1 * (1.0 / residual_capacity) + w2 * (1.0 / fittable_bins_remain_cap)`\n    # Weights `w1` and `w2` determine the trade-off.\n    # `w1` for tightness, `w2` for pre-existing fullness.\n    # If `w1` is high, it's like Best Fit. If `w2` is high, it prefers already full bins.\n\n    # Let's tune weights:\n    # `w1 = 1.0` (primary focus on tightness)\n    # `w2 = 0.5` (secondary focus on pre-existing fullness)\n\n    # Calculate scores for fittable bins\n    best_fit_score_fittable = 1.0 / (residual_capacity + 1e-9)\n    bin_fullness_score_fittable = 1.0 / (fittable_bins_remain_cap + 1e-9) # Favor bins with less remaining capacity\n\n    # Combine scores\n    combined_scores = (best_fit_score_fittable * 1.0) + (bin_fullness_score_fittable * 0.5)\n\n    # Normalize the combined scores to a [0, 1] range.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a Fill Ratio that penalizes large remaining capacities.\n    Prioritizes bins that snugly fit the item and are already substantially full.\n\n    Args:\n        item: The size of the item to be placed.\n        bins_remain_cap: A numpy array representing the remaining capacity of each bin.\n        epsilon: A small value added for numerical stability.\n\n    Returns:\n        A numpy array representing the priority of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1st (weighted additive with log bonus) vs. Heuristic 2nd (multiplicative best-fit and fill ratio): Heuristic 1st attempts a more nuanced combination with a logarithmic term to manage leftover space, which can be more stable. Heuristic 2nd uses a simple multiplicative approach which can be too aggressive.\n\nComparing Heuristic 1st (weighted additive with log bonus) vs. Heuristic 3rd (complex additive with multiple components): Heuristic 1st is simpler and more direct. Heuristic 3rd's attempt at \"Proximity to Half-Capacity\" and \"Worst Fit Incentive\" without clear definitions or robust proxies makes it less reliable.\n\nComparing Heuristic 2nd (multiplicative best-fit and fill ratio) vs. Heuristic 5th (identical to 2nd, possibly a copy-paste error): They are identical, making comparison moot for ranking. However, the core idea of multiplicative best-fit and fill ratio is present in 2nd, 5th, 6th, 7th, 8th, 10th, 15th, 16th, 17th, 18th, 19th, 20th. Heuristic 10th uses a logarithmic fill bonus, which is a slight variation. Heuristics 5th, 6th, 7th, 8th are indeed identical.\n\nComparing Heuristic 4th (multiplicative with explicit penalty/bonus) vs. Heuristic 9th (multiplicative best-fit and normalized fullness): Heuristic 4th's explicit `1.0 / (1.0 + leftover_space_penalty)` is a reasonable way to incorporate a penalty, but the interaction with other terms might be sensitive. Heuristic 9th's `fullness_scores = 1.0 - (fittable_bins_remain_cap / max_initial_remain_cap)` attempts to normalize fullness, which can be more robust than absolute remaining capacity. However, it adds a constant `+ 0.1` to `fullness_scores` before multiplication, which is a heuristic dampener.\n\nComparing Heuristic 1st (weighted additive) vs. Heuristic 12th (multiplicative with adaptive tightness): Heuristic 1st's additive approach is generally more controllable than Heuristic 12th's multiplicative approach, especially with an exponential tightness component which can be sensitive. Heuristic 12th's `(1.0 - large_bin_penalty_component)` might lead to negative values if `large_bin_penalty_component` is greater than 1, which is unlikely here but a potential issue.\n\nComparing Heuristic 2nd (multiplicative best-fit and fill ratio) vs. Heuristic 10th (multiplicative best-fit and log fullness bonus): Heuristic 10th's use of `log1p(1.0 / (fittable_bins_remain_cap + 1e-9))` for fullness is a more sophisticated way to handle varying levels of fullness compared to Heuristic 2nd's simple inverse.\n\nOverall: Heuristic 1st seems to strike a good balance between simplicity, interpretability, and robustness with its weighted additive approach. Multiplicative combinations (like Heuristics 2nd, 4th, 9th, 10th) can be powerful but risk being too sensitive to specific term values or interactions. Heuristics involving complex adaptive terms or unclear proxies (like parts of Heuristic 3rd, 12th, 13th, 14th) are harder to justify without empirical validation. The numerous identical heuristics (5th, 6th, 7th, 8th) are a clear weakness in the list.\n- \nHere's a redefined \"Current self-reflection\" focused on designing better heuristics, avoiding pitfalls of ineffective self-reflection:\n\n*   **Keywords:** Multi-objective, Adaptive Weighting, Robustness, Interpretability, Granular Control.\n*   **Advice:** Design heuristics with granular control via additive components, carefully normalized. Prioritize explicit balancing of immediate packing efficiency and future bin utility. Implement adaptive weighting based on item characteristics for improved robustness.\n*   **Avoid:** Redundant heuristics, overly aggressive multiplicative combinations without clear justification, and implicit assumptions about scale or edge cases. Do not rely on near-identical implementations.\n*   **Explanation:** This approach emphasizes clarity, adaptability, and the avoidance of duplication. It suggests building complex behaviors from well-understood, controlled components rather than relying on opaque, potentially brittle multiplicative interactions or redundant strategies.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}