```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    fittable_bins_mask = bins_remain_cap >= item

    if not np.any(fittable_bins_mask):
        return priorities

    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]
    fittable_bin_indices = np.where(fittable_bins_mask)[0]

    # 1. Best Fit (BF): Prioritize bins that leave the smallest remaining capacity.
    # This is crucial for minimizing wasted space immediately.
    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)

    # 2. First Fit Decreasing (FFD) like idea: Prioritize bins that have been used for larger items.
    # This is implicitly captured by looking at the remaining capacity, but we can add a bonus
    # for bins that are *already* significantly filled, as they likely contain larger items
    # and are good candidates to continue filling.
    # We use the inverse of remaining capacity as a proxy for fullness.
    fullness_scores = 1.0 / (fittable_bins_remain_cap + 1e-9)

    # 3. Next Fit Decreasing (NFD) related: Consider the 'tightness' of the fit relative
    # to the bin's original capacity. While we don't know the original capacity directly
    # here, we can approximate by assuming bins with larger *remaining* capacity
    # might have had more space to begin with, and thus a tighter fit might be more valuable.
    # This is a weaker heuristic but adds another dimension.
    # Let's consider a penalty for leaving *too much* space.
    # We want to favor bins where (remaining_cap - item) is small.
    # log1p is good for diminishing returns on small remaining spaces.
    # Let's use log of the *original* capacity if we knew it. Since we don't,
    # we can use the *current* remaining capacity as a proxy for "how much space is left to play with".
    # A bin with a lot of remaining capacity might be better to keep for a large item later.
    # So, we want to penalize using bins that have lots of remaining capacity if a tighter fit exists.
    # Let's use the log of the remaining capacity after the fit. A smaller log value is better.
    # We will invert it so higher values are better.
    log_remaining_after_fit = np.log1p(fittable_bins_remain_cap - item)
    space_utilization_scores = 1.0 / (log_remaining_after_fit + 1e-9)


    # Combination Strategy:
    # - BF is the primary driver: we want tight fits.
    # - Fullness provides a secondary boost: encouraging to fill up bins that are already somewhat full.
    # - Space Utilization adds a nuanced preference: preferring bins where the remaining space
    #   after fitting is not excessively large (using the log to moderate this effect).

    # Weights are adjusted to give primacy to Best Fit, with secondary consideration to fullness
    # and the impact on future packing potential (space_utilization).
    # We use a slightly more aggressive weighting for BF and a balanced approach for others.
    combined_scores = (best_fit_scores * 1.5) + (fullness_scores * 0.7) + (space_utilization_scores * 0.5)

    # Normalize scores for the fittable bins to a [0, 1] range.
    max_score = np.max(combined_scores)
    if max_score > 1e-9:
        normalized_priorities = np.clip(combined_scores / max_score, 0, 1)
        priorities[fittable_bins_mask] = normalized_priorities
    else:
        # If all scores are near zero (e.g., all remaining capacities are very close),
        # assign a uniform moderate priority to fittable bins.
        priorities[fittable_bins_mask] = 0.5

    return priorities
```
