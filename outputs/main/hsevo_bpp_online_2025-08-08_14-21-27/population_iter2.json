[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": null,
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Invalid response!"
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by favoring those with minimal remaining capacity after packing, while also considering the overall bin count.\n\n    This heuristic aims to fill bins as much as possible (Best Fit like) while\n    implicitly encouraging the use of fewer bins by giving a slight boost to bins\n    that are already well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins_mask = bins_remain_cap >= item\n\n    if not np.any(valid_bins_mask):\n        return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 5.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": null,
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Invalid response!"
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on a balance of minimal wasted space and avoiding fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    valid_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(valid_bins_mask):\n        return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 5.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Priority: Combines 'Best Fit' with an 'Almost Full' bias.\n    Prioritizes bins that leave minimal space, favoring near-perfect fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity for bins that can fit the item\n    remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Heuristic: Prioritize bins that result in less remaining capacity.\n    # This is a \"Best Fit\" like strategy.\n    # Using 1 / (1 + residual_capacity) to give higher scores to smaller residuals.\n    # A residual capacity of 0 gets a score of 1. A large residual gets a score close to 0.\n    priorities[can_fit_mask] = 1.0 / (1.0 + remaining_capacity_after_fit)\n    \n    # Additional bias: Slightly boost priority for bins that become nearly full (e.g., residual < 0.1 * bin_capacity)\n    # This \"almost full\" bias encourages tighter packing and potentially better overall utilization.\n    # We'll apply a small multiplier to these bins.\n    original_bin_capacities = bins_remain_cap[can_fit_mask] # Assuming we know original capacities or can infer\n    # For this example, let's assume a fixed bin capacity, say 1.0, for demonstration\n    # In a real scenario, bin capacity would be a parameter or known context.\n    # If bin_capacity is not fixed, this bias needs adjustment or a different approach.\n    # For simplicity here, let's assume a standard bin capacity is known or implied.\n    # Let's use a placeholder if bin capacity is not explicitly available.\n    # If bin_capacity is available, it would be:\n    # almost_full_mask = remaining_capacity_after_fit < (bin_capacity * 0.1) \n    \n    # Without explicit bin capacity, we'll use a small absolute residual as a proxy for 'almost full'\n    # For example, if the remaining capacity is very small (e.g., less than 0.05)\n    small_residual_bias_mask = remaining_capacity_after_fit < 0.05\n    priorities[can_fit_mask][small_residual_bias_mask] *= 1.1 # Apply a small boost\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines a greedy approach with a small probability of random selection\n    to balance exploration and exploitation for bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    eligible_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(eligible_bins_mask):\n        return priorities\n        \n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    \n    greedy_scores = 1.0 / (eligible_bins_remain_cap - item + 1e-9)\n    \n    \n    epsilon = 0.05 # Small exploration rate\n    num_eligible_bins = eligible_bins_mask.sum()\n    \n    \n    exploration_indices = np.random.choice(\n        np.arange(num_eligible_bins), \n        size=int(epsilon * num_eligible_bins), \n        replace=False\n    )\n    \n    \n    priorities[eligible_bins_mask][exploration_indices] = 1.0 \n    \n    \n    exploitation_indices = np.setdiff1d(np.arange(num_eligible_bins), exploration_indices)\n    priorities[eligible_bins_mask][exploitation_indices] = greedy_scores[exploitation_indices]\n    \n    \n    if np.max(priorities) > 0:\n        priorities = priorities / np.max(priorities)\n        \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 20.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": null,
    "response_id": 6,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Invalid response!"
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by favoring those with least remaining capacity after packing,\n    while also considering the likelihood of future fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate the remaining capacity if the item is placed in each bin\n    potential_remaining_cap = bins_remain_cap - item\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit the item, assign priority based on remaining capacity\n    # Higher priority for bins with less remaining capacity (tightest fit)\n    # Add a small epsilon to avoid division by zero\n    priorities[can_fit_mask] = 1.0 / (potential_remaining_cap[can_fit_mask] + 1e-9)\n    \n    # Further adjust priorities: bins that leave more remaining capacity\n    # after packing might be preferred if they are large enough to fit\n    # future, potentially larger items. This is a simple form of adaptive\n    # prioritization, favoring slightly less tight fits that retain more 'room'.\n    # We multiply by the potential remaining capacity itself.\n    # This is a heuristic that balances tight fits with future flexibility.\n    priorities[can_fit_mask] *= potential_remaining_cap[can_fit_mask]\n\n    # Normalize priorities to avoid extremely large values and ensure a better distribution\n    # This makes the heuristic less sensitive to extreme differences in remaining capacity.\n    if np.any(priorities):\n        priorities /= np.max(priorities)\n        \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the \"Best Fit\" greedy strategy with an exploration component.\n    Prioritizes bins that best fit the item, with a small chance of exploring other options.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    # Calculate greedy scores: inverse of remaining capacity after placement (Best Fit)\n    # Higher score for bins with less remaining capacity after placing the item\n    greedy_scores = 1.0 / (bins_remain_cap[fittable_bins_mask] - item + 1e-9)\n\n    # Introduce a small exploration factor: slightly boost all fittable bins\n    # This encourages trying bins that might not be the absolute best fit but could lead to better overall packing later.\n    exploration_boost = 0.05\n    priorities[fittable_bins_mask] = greedy_scores + exploration_boost\n\n    # Normalize priorities to ensure they are comparable and avoid extreme values\n    if np.max(priorities) > 1e-9: # Avoid division by zero if all priorities are zero\n        priorities /= np.max(priorities)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by favoring those that leave minimal remaining capacity after packing,\n    with an adaptive sigmoid scaling to emphasize better fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    valid_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(valid_bins_mask):\n        return priorities\n\n    remaining_caps_for_valid_bins = bins_remain_cap[valid_bins_mask]\n    diffs = remaining_caps_for_valid_bins - item\n    \n    # Using a scaled inverse difference for a preference towards tighter fits\n    # Add a small epsilon to avoid division by zero if diff is exactly 0\n    inverse_diff_scores = 1.0 / (diffs + 1e-9)\n    \n    # Adaptive sigmoid scaling to emphasize bins with very small differences (better fits)\n    # This part is inspired by v1's idea of using sigmoid for better differentiation\n    # We center the sigmoid around the median difference to adapt to the current state\n    median_diff = np.median(diffs)\n    k = 10.0 # Sensitivity parameter for sigmoid\n    sigmoid_scores = 1 / (1 + np.exp(-k * (diffs - median_diff)))\n    \n    # Combine inverse difference for general preference and sigmoid for fine-tuning\n    # The sigmoid amplifies the preference for bins closer to the median difference\n    priorities[valid_bins_mask] = inverse_diff_scores * sigmoid_scores\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 73.11527722377345,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]