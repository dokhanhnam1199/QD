[
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a multiplicative bonus for fuller bins,\n    using a logarithmic scale to favor bins that are mostly full but can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins with minimal remaining capacity after fitting.\n    # Adding epsilon for numerical stability.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Bonus: A bonus reflecting how full the bin is *before* fitting the item.\n    # We use a logarithmic scale for the remaining capacity to give diminishing returns\n    # as bins get very full, but still reward those that are significantly filled.\n    # The idea is to slightly favor bins that are already quite full (smaller remaining capacity)\n    # to encourage consolidation. Adding 1 to avoid log(0).\n    fullness_bonus = np.log1p(bins_remain_cap[fittable_bins_mask])\n\n    # Combine scores multiplicatively: Prioritize bins that are both a good fit (low residual)\n    # and are already quite full. The fullness bonus acts as a multiplier on the best-fit score.\n    combined_scores = best_fit_scores * (1.0 + fullness_bonus * 0.2) # Add 1 to ensure positive multiplier\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a 'fill ratio' bonus, prioritizing bins that are both a tight fit\n    and already well-utilized, aiming for efficient packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # Best Fit Score: Inversely proportional to the remaining capacity after fitting the item.\n    # Adding a small epsilon to avoid division by zero.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Fill Ratio Score: Proportional to how full the bin is *relative to its capacity after packing*.\n    # This emphasizes bins that will have less remaining space after the item is placed.\n    fill_ratio_scores = (bins_remain_cap[eligible_bins_mask] - item) / (bins_remain_cap[eligible_bins_mask] + 1e-9)\n\n\n    # Combined Score: Multiplicative combination.\n    # Prioritizes bins that are a good fit (high best_fit_scores) AND are already quite full (high fill_ratio_scores).\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison across different item sizes and bin states.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a bonus for bins that are already utilized,\n    prioritizing snug fits in partially filled bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Best Fit score: Inverse of remaining capacity after fitting. High score for tight fits.\n    proximity_score = 1.0 / (fitting_bins_remain_cap - item + 1e-9)\n    \n    # Fill Ratio Score: Bonus for bins that are already mostly full.\n    # We use the inverse of the remaining capacity *before* placing the item as a proxy for fullness.\n    # A higher value means the bin was less full, so we want to penalize that.\n    # The lower the remaining capacity (before fitting), the fuller the bin.\n    fullness_bonus = 1.0 / (fitting_bins_remain_cap + 1e-9)\n    \n    # Combine scores multiplicatively: prioritize tight fits that are also on already utilized bins.\n    combined_score = proximity_score * fullness_bonus\n    \n    # Normalize scores to [0, 1] for better comparability and to avoid extreme values.\n    # Add a small epsilon to avoid division by zero if all scores are zero.\n    max_score = np.max(combined_score)\n    if max_score > 1e-9:\n        priorities[can_fit_mask] = combined_score / max_score\n    else:\n        # If all combined scores are near zero (e.g., only very large gaps available)\n        # fallback to a simple proximity score, normalized.\n        max_proximity = np.max(proximity_score)\n        if max_proximity > 1e-9:\n            priorities[can_fit_mask] = proximity_score / max_proximity\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a Fill Ratio bonus, using a multiplicative approach.\n    This prioritizes bins that fit tightly and are already relatively full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Inverse of remaining capacity after packing. Higher is better.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fill Ratio Score: Inverse of the bin's total capacity (assuming total capacity is 1 for simplicity or can be passed).\n    # Here we use the inverse of the *original* remaining capacity before fitting the item,\n    # to represent how full the bin *was*. A higher fill ratio (lower remaining capacity) is better.\n    # Add 1 to avoid division by zero if a bin was already full (though fittable_bins_mask should prevent this).\n    fill_ratio_score = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine multiplicatively: Prioritize bins that are both a tight fit and were already full.\n    # This balances immediate packing efficiency with the goal of consolidating items.\n    combined_scores = best_fit_score * fill_ratio_score\n\n    # Normalize to [0, 1]\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a Fullness bonus multiplicatively.\n    Prioritizes bins that are a tight fit and are already more utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Score 1: Best Fit - Higher score for smaller remaining capacity after packing.\n    # This encourages minimizing immediate wasted space.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Score 2: Fullness Bonus - Higher score for bins that are already more full.\n    # This is calculated as the inverse of the remaining capacity among fittable bins.\n    # Encourages consolidation into fewer bins.\n    fullness_bonus = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine scores multiplicatively. This ensures that bins must perform well on both\n    # metrics to achieve a high priority. A bin that is a perfect fit but very empty,\n    # or a very full bin that is a poor fit, will receive a lower combined score.\n    combined_scores = best_fit_score * fullness_bonus\n\n    # Normalize priorities to a [0, 1] range for consistent behavior.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are effectively zero (e.g., very large items or very similar capacities),\n        # assign a small uniform priority to fittable bins to ensure selection.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a multiplicative bonus for bins that are already fuller,\n    aiming for efficient packing and reduced bin count.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher score for bins with less remaining capacity after fit.\n    # This strongly favors tight fits. Add epsilon for stability.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Score: Higher score for bins that are already more full.\n    # This encourages consolidating items into fewer bins.\n    # Normalize by the maximum remaining capacity among fittable bins for relative comparison.\n    max_rem_cap_fittable = np.max(fittable_bins_remain_cap)\n    fullness_scores = (max_rem_cap_fittable - fittable_bins_remain_cap) / (max_rem_cap_fittable + 1e-6)\n\n    # Combine scores multiplicatively.\n    # The multiplication ensures that a good fit (high best_fit_scores) is prioritized,\n    # and this priority is boosted if the bin is also already fuller (high fullness_scores).\n    # This heuristic balances the desire for a tight fit with the objective of using fewer bins.\n    combined_scores = best_fit_scores * (1 + 0.5 * fullness_scores)\n\n    # Normalize priorities to a [0, 1] range.\n    max_combined_score = np.max(combined_scores)\n    if max_combined_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_combined_score\n    else:\n        # Fallback: if all combined scores are near zero, assign a small uniform priority.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a fill ratio bonus using a multiplicative approach,\n    prioritizing bins that offer a tight fit and are already well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    fitting_bins_indices = np.where(can_fit_mask)[0]\n    \n    if fitting_bins_indices.size > 0:\n        fitting_bins_cap = bins_remain_cap[fitting_bins_indices]\n        \n        # Best Fit component: Smaller difference is better (higher score)\n        differences = fitting_bins_cap - item\n        best_fit_score = 1.0 / (differences + 1e-9)\n        \n        # Fill Ratio component: Higher fill ratio is better (higher score)\n        # Assuming bin capacity is constant (e.g., 1.0 for normalized problems or a known max_capacity)\n        # Here, we use the total capacity before packing as the reference for fill ratio.\n        # A simpler proxy for fullness is (bin_capacity - remaining_capacity).\n        # Let's assume a hypothetical bin capacity of 1.0 for this calculation if not provided.\n        # If bin_capacity is known, replace 1.0 with it.\n        bin_capacity = 1.0 \n        fullness = (bin_capacity - fitting_bins_cap) / bin_capacity\n        fill_ratio_score = fullness \n        \n        # Combine scores multiplicatively: Boosts bins that are both tight fits and fuller.\n        # Adding a small constant to fill_ratio_score to avoid multiplying by zero if a bin is empty.\n        combined_scores = best_fit_score * (fill_ratio_score + 0.1) # Add small bonus to slightly full bins\n        \n        priorities[fitting_bins_indices] = combined_scores\n        \n        # Normalize priorities to be between 0 and 1 for the fitting bins\n        max_priority = np.max(priorities[fitting_bins_indices])\n        if max_priority > 0:\n            priorities[fitting_bins_indices] /= max_priority\n            \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response7.txt_stdout.txt",
    "code_path": "problem_iter11_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive fill ratio bonus, prioritizing tight fits\n    that also contribute to fuller bins, weighted by item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Best Fit Component ---\n    # Score based on how little capacity is left after fitting.\n    # Higher score for smaller remaining capacity.\n    best_fit_score = 1.0 / (fitting_bins_remain_cap - item + 1e-9)\n    \n    # --- Adaptive Fill Ratio Component ---\n    # This component encourages filling bins more, but it's modulated by how large the item is relative to the bin's capacity.\n    # If an item is a large fraction of the bin's total capacity, we slightly de-emphasize the fill ratio contribution\n    # to avoid over-packing small items into partially filled bins at the expense of better fits for larger items.\n    # Assume a nominal bin capacity of 1.0 for fill ratio calculation.\n    bin_capacity = 1.0\n    current_fill_ratio = (bin_capacity - fitting_bins_remain_cap) / bin_capacity\n    \n    # Adaptive weight for fill ratio: Higher weight for smaller items relative to bin capacity.\n    # We want to encourage filling, but more so for smaller items that are less likely to \"ruin\" a bin for future items.\n    # The item_size_ratio helps normalize this. A small item (e.g., 0.1) gets a higher weight (e.g., 1.0 / (0.1+1) = 0.9)\n    # A large item (e.g., 0.8) gets a lower weight (e.g., 1.0 / (0.8+1) = 0.55).\n    # We add 1 to the denominator to ensure the weight is <= 1 and to avoid issues when item_size_ratio is 0.\n    item_size_ratio = item / bin_capacity \n    adaptive_fill_weight = 1.0 / (item_size_ratio + 1.0)\n\n    fill_ratio_score = current_fill_ratio * adaptive_fill_weight\n    \n    # --- Combined Score ---\n    # Multiplicatively combine Best Fit and the weighted Fill Ratio.\n    # This prioritizes bins that are both a tight fit and contribute to overall bin fullness,\n    # with the fill ratio component being more influential for smaller items.\n    combined_score = best_fit_score * (1 + fill_ratio_score) # Add 1 to fill_ratio_score to ensure it boosts, not reduces, the BF score if fill_ratio_score is small.\n    \n    # Normalize scores to [0, 1]\n    max_score = np.max(combined_score)\n    if max_score > 1e-9:\n        priorities[can_fit_mask] = combined_score / max_score\n    else: # Handle cases where all scores are zero or near-zero\n        priorities[can_fit_mask] = 1.0 / (len(fitting_bins_remain_cap) + 1e-9) # Give equal priority if no clear differentiator\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a modified Fill Ratio for denser packing.\n    Prioritizes bins that fit the item snugly and are already substantially full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # Score 1: Best Fit - inverse of remaining capacity after packing.\n    # Higher score for smaller remaining capacity.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Score 2: Fill Ratio - remaining capacity relative to the item size.\n    # Prioritizes bins where the item occupies a larger fraction of the remaining space,\n    # promoting tighter packing. Avoids penalizing bins with very large remaining capacity.\n    fill_ratio_scores = item / (eligible_bins_caps + 1e-9)\n\n    # Combine scores multiplicatively: accentuates bins that excel in both criteria.\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign combined scores to the priorities array for eligible bins.\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a Fill Ratio bonus multiplicatively,\n    prioritizing bins that are both a tight fit and already well-utilized.\n    This aims for efficient packing by favoring dense bins that can snugly fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Best Fit Component ---\n    # Higher score for smaller remaining capacity after fitting.\n    remaining_capacity_after_fit = fitting_bins_remain_cap - item\n    proximity_score = 1.0 / (remaining_capacity_after_fit + 1e-9)\n    \n    # --- Fill Ratio Component ---\n    # Using 1.0 as the assumed bin capacity. Higher fill ratio (less remaining capacity) is better.\n    # This encourages using bins that are already somewhat full.\n    bin_capacity = 1.0 \n    current_fill_ratio = (bin_capacity - fitting_bins_remain_cap) / bin_capacity\n    fill_ratio_score = current_fill_ratio\n    \n    # --- Combined Score ---\n    # Multiplicatively combine Best Fit and Fill Ratio.\n    # This prioritizes bins that are both a good fit (high proximity) AND already well-utilized (high fill ratio).\n    # A bin that is nearly full and can snugly fit the item will get a high score.\n    combined_score = proximity_score * fill_ratio_score\n    \n    # --- Refinement: Ensure proximity is considered for empty bins ---\n    # If a bin was empty (fill_ratio=0), combined_score would be 0.\n    # We want to ensure that even in this case, the proximity score is still considered,\n    # as an empty bin might be the only option or a good first fit.\n    # We take the maximum of the combined score and a modified proximity score\n    # where the fill_ratio_score component is only applied if fill_ratio > 0.\n    # This ensures that even empty bins get a score based on their proximity.\n    priorities[can_fit_mask] = np.maximum(combined_score, proximity_score * (fill_ratio_score > 1e-9))\n    \n    # Add a small constant to all valid priorities to ensure that even if\n    # all scores are very low, they are distinct and positive, aiding tie-breaking.\n    priorities[can_fit_mask] += 1e-6\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a multiplicative bonus for bin fullness, \n    aiming for a more aggressive filling strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Prefer bins that leave minimal remaining capacity after fitting the item.\n    # We use 1 / (remaining_capacity - item + epsilon) so smaller remaining capacity yields higher score.\n    # Adding 1 to the denominator to avoid division by zero and to give a base score.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1.0)\n\n    # Fullness Ratio: Measure how full a bin is *after* the item is placed.\n    # A higher ratio means the bin is more full, which is desirable.\n    # We calculate this based on the remaining capacity *before* placing the item,\n    # assuming a standard bin capacity, let's say 1.0 for normalization.\n    # If bin capacity is variable, it should be passed as an argument.\n    # For now, assuming a nominal capacity of 1.0 for calculating fill ratio's component.\n    # A more accurate fullness would consider the total capacity of the bin.\n    # Let's assume a fixed bin capacity of 1.0 for simplicity in this example,\n    # or a normalized capacity.\n    # A better approach might be to use the *initial* remaining capacity if available,\n    # or the capacity that was left *before* the item was placed.\n    # Here, we use the remaining capacity *after* placing the item to represent how full it *becomes*.\n    # A higher value of (1.0 - (fittable_bins_remain_cap - item)) / 1.0 represents a fuller bin.\n    # To avoid issues with different bin capacities, let's use the \"space left before fitting\"\n    # divided by a reference capacity (e.g., total capacity of the largest bin encountered so far,\n    # or a fixed value like 1.0 if capacities are normalized).\n    # For simplicity, we'll consider the \"space available\" as a proxy for fullness if we don't\n    # have total capacity. The more space *was* available, the less \"full\" the bin was initially.\n    # So, a smaller `fittable_bins_remain_cap` means the bin was fuller *before* fitting.\n    # Let's aim for a metric that rewards bins that are *already* fuller.\n    # A simple proxy for fullness (higher is better) is the inverse of remaining capacity.\n    # However, we already have best_fit which uses this.\n    # Let's redefine fullness as the ratio of *space used* to *total capacity*.\n    # If we assume total capacity is 1.0 for all bins for simplicity:\n    # Fullness = (1.0 - fittable_bins_remain_cap) / 1.0\n    # But this would penalize bins with large initial capacity even if they are mostly full.\n    # A better approach: The percentage of capacity *already taken*.\n    # Let's use the complement of the remaining capacity *before* fitting,\n    # normalized by the maximum possible remaining capacity (which is the maximum capacity if we knew it).\n    # Without knowing total capacity, we can use a surrogate:\n    # How \"close\" is the bin to being full?\n    # Higher score if `fittable_bins_remain_cap` is small (relative to other fittable bins).\n    # This is similar to Best Fit, so let's ensure it's distinct.\n\n    # Let's try a multiplicative approach. We want to maximize both \"best fit\" and \"fullness\".\n    # Fullness metric: percentage of capacity *already filled*.\n    # If we don't know total capacity, we can use the available capacity as a base.\n    # Consider bins that are already \"mostly full\".\n    # A bin that has `C` capacity and `r` remaining capacity, has `C-r` filled.\n    # Fill ratio = (C-r) / C = 1 - r/C.\n    # To make it usable without C, we can normalize `r` by the maximum possible `r` among fittable bins.\n    # `fullness_score` = 1 - (fittable_bins_remain_cap / max(fittable_bins_remain_cap))\n    # This rewards bins that had less remaining capacity *before* fitting.\n    max_initial_remain_cap = np.max(fittable_bins_remain_cap)\n    fullness_scores = 1.0 - (fittable_bins_remain_cap / (max_initial_remain_cap + 1e-6))\n\n    # Combine: Multiplicative interaction between Best Fit and Fullness.\n    # This encourages bins that are both a good fit and already relatively full.\n    # Add a small epsilon to prevent multiplication by zero.\n    combined_scores = best_fit_scores * (fullness_scores + 0.1) # Adding 0.1 to ensure scores are positive and not zeroed out easily\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n    \n    # Metric 1: Best Fit (minimize remaining capacity)\n    # A smaller remaining capacity after fitting is better.\n    best_fit_metric = fittable_bins_remain_cap - item\n    \n    # Metric 2: Fill Ratio (maximize current fill level)\n    # This encourages using bins that are already relatively full.\n    # We consider the capacity used by the item relative to the bin's original capacity.\n    # Assuming bins have a standard capacity (e.g., bin_capacity), this would be (bin_capacity - bins_remain_cap + item) / bin_capacity\n    # However, without bin_capacity, we can use the inverse of remaining capacity as a proxy for fullness.\n    # A higher inverse remaining capacity means the bin is more full.\n    # Adding a small epsilon to avoid division by zero and to make smaller remaining capacities yield larger values.\n    fullness_metric = 1.0 / (fittable_bins_remain_cap + 1e-6)\n\n    # Combine metrics multiplicatively to encourage both good fit and high fill ratio.\n    # We want to minimize best_fit_metric and maximize fullness_metric.\n    # So, we use 1 / (1 + best_fit_metric) to map it to a [0, 1] range where smaller is better,\n    # and directly use fullness_metric (or a normalized version).\n    # Let's normalize both to [0, 1] first for a cleaner multiplicative combination.\n\n    # Normalize best_fit_metric: Smaller is better, so we invert and scale.\n    # If best_fit_metric is 0, it's a perfect fit.\n    normalized_best_fit = 1.0 - (best_fit_metric / np.max(fittable_bins_remain_cap + 1e-6))\n    normalized_best_fit = np.clip(normalized_best_fit, 0, 1) # Ensure it's in [0, 1]\n\n    # Normalize fullness_metric: Higher is better.\n    # Use the inverse of remaining capacity.\n    normalized_fullness = fullness_metric / np.max(fullness_metric + 1e-6)\n    normalized_fullness = np.clip(normalized_fullness, 0, 1) # Ensure it's in [0, 1]\n\n    # Multiplicative combination: Encourages bins that are both good fits and already full.\n    # A bin needs to score well on *both* metrics.\n    combined_scores = normalized_best_fit * normalized_fullness\n\n    # Adjust weights if needed for emphasis. Let's keep it simple with equal weighting via multiplication.\n    # For example, to give more weight to best fit: (normalized_best_fit**w1) * (normalized_fullness**w2)\n    \n    # Scale to [0, 1] range for priorities.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / np.max(combined_scores)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines a tight fit score (similar to Best Fit) with a bin fullness score\n    using a multiplicative approach. It also incorporates a penalty for large remaining gaps.\n    The multiplicative approach aims to prioritize bins that are both a good fit\n    and contribute to overall higher bin utilization.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Score 1: Tight Fit - Prioritize bins that leave minimal remaining capacity.\n    # Adding a small epsilon to avoid division by zero and to prevent zero scores.\n    # A higher score means a tighter fit.\n    tight_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Score 2: Bin Fullness - Prioritize bins that are already relatively full.\n    # This encourages packing into already occupied bins.\n    # We use the inverse of the remaining capacity (before fitting the item) as a proxy for fullness.\n    # Higher remaining capacity means less full, so we invert it.\n    # Adding a small epsilon to avoid division by zero.\n    # We cap this score to avoid overly dominating the multiplicaton if some bins are almost empty.\n    bin_fullness_score = 1.0 / (bins_remain_cap[fittable_bins_mask] + 1e-6)\n\n    # Score 3: Gap Penalty - Penalize bins that will have a large remaining capacity after fitting the item.\n    # This discourages creating very large empty spaces.\n    # We use the logarithm of the remaining capacity after fitting.\n    # Lower log values (smaller gaps) are better, so we'll subtract this.\n    # Adding 1 to prevent log(0) and ensure positive values.\n    # Smaller gaps should result in a higher overall priority.\n    gap_penalty = np.log1p(fittable_bins_remain_cap - item)\n\n    # Combine scores multiplicatively for tight fit and fullness,\n    # then add the inverse of the gap penalty to boost bins with small gaps.\n    # Weights are chosen to balance the influence of each component.\n    # The multiplicative part ensures that both tight fit and fullness are important.\n    # The additive part for the gap penalty provides a fine-tuning adjustment.\n    combined_scores = (tight_fit_score * 0.8) * (bin_fullness_score * 0.7) + (1.0 / (gap_penalty + 1e-6) * 0.5)\n\n    # Normalize the combined scores for the fittable bins to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response3.txt_stdout.txt",
    "code_path": "problem_iter12_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and First Fit Decreasing ideas with a focus on filling\n    bins as much as possible, prioritizing bins that are nearly full or\n    can accommodate the item with minimal remaining space.\n    This version uses a multiplicative approach to balance fitting tightly\n    and maintaining a good fill ratio.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 5.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 5.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]