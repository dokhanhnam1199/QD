{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a \"fill ratio\" bonus. Prioritizes bins that fit the item snugly\n    and are already relatively full, aiming for denser packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # Score 1: Best Fit - favors bins with minimal remaining capacity after packing.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Score 2: Fill Ratio - favors bins that are already more full.\n    # Using the ratio of current capacity to maximum possible capacity for fitting bins.\n    max_eligible_cap = np.max(eligible_bins_caps)\n    fill_ratio_scores = eligible_bins_caps / (max_eligible_cap + 1e-9)\n\n    # Combine scores multiplicatively: prioritize bins that are both a good fit and already full.\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign combined scores to the priorities array\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Core Strategy: Prioritize bins that leave minimal remaining capacity (Best Fit).\n    # Use the inverse of remaining capacity after fitting. Add a small epsilon for stability.\n    # This directly targets the objective of minimizing wasted space.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Predictive Component: Consider the \"potential\" of a bin for future items.\n    # A bin with slightly more remaining capacity after fitting a current item might be\n    # more versatile for subsequent items. This is a trade-off: a tighter fit is good now,\n    # but a slightly looser fit might be better overall.\n    # We can model this by giving a bonus to bins that are \"almost full\" but can still fit the item,\n    # prioritizing those that would have a \"just right\" remaining capacity for common item sizes.\n    # A simple approach is to penalize bins that leave a very large gap.\n    # We can use the negative logarithm of the remaining capacity after fit. Smaller remaining capacity is better,\n    # so a smaller value for log1p(remaining_cap) is better. We invert this by multiplying by -1.\n    # Using log1p to handle cases where remaining capacity is 0 gracefully.\n    future_potential_score = -np.log1p(fittable_bins_remain_cap - item)\n\n    # Adaptability: The relative importance of \"tight fit\" vs. \"future potential\" can change.\n    # For instance, if items are generally small, prioritizing slightly larger remaining capacity might be good.\n    # If items are large, tight fits are paramount.\n    # We can introduce a dynamic weighting factor based on the item size relative to the bin capacity (implicitly, the median or average remaining capacity).\n    # For simplicity, let's consider the item size relative to the bin capacity if we knew it, but we only have remaining capacities.\n    # A proxy could be the item size relative to the *average* remaining capacity of fittable bins.\n    # If the item is small relative to available space, future potential might be more important.\n    # If the item is large, fitting it tightly is more important.\n\n    avg_remaining_fittable = np.mean(fittable_bins_remain_cap)\n    item_size_ratio = item / (avg_remaining_fittable + 1e-9)\n\n    # Weighting:\n    # If item_size_ratio is high (item is large relative to average remaining capacity),\n    # prioritize Best Fit more. If low (item is small), give more weight to future potential.\n    # A sigmoid-like function could map item_size_ratio to a weight for Best Fit.\n    # Let's use a simple linear scaling for now.\n\n    # Normalize item_size_ratio to a [0, 1] range (approximate).\n    # A more robust normalization might involve historical data or a fixed large value.\n    # For now, assume item sizes are within a reasonable range compared to bin capacities.\n    # A heuristic upper bound for item_size_ratio could be the bin capacity itself (if items <= bin_cap).\n    # Let's consider the max possible ratio for a single item being 1 if item == bin_cap.\n    # So, max_ratio_considered = 1.0 (for item fitting exactly).\n    # The weight for best_fit_score will increase as item_size_ratio increases.\n    # The weight for future_potential_score will decrease as item_size_ratio increases.\n\n    # Let's use a sigmoid-like weighting for Best Fit: w_bf = 1 / (1 + exp(-k * (item_size_ratio - threshold)))\n    # A simpler approach: linear interpolation.\n    # If item_size_ratio is small (e.g., 0.1), bf_weight=0.2, fp_weight=0.8\n    # If item_size_ratio is large (e.g., 1.0), bf_weight=1.0, fp_weight=0.0\n    # We can use an exponential decay for future potential weight.\n    bf_weight = 1.0 - np.exp(-item_size_ratio * 2.0)  # As item_size_ratio grows, bf_weight approaches 1\n    fp_weight = np.exp(-item_size_ratio * 2.0)       # As item_size_ratio grows, fp_weight approaches 0\n\n    # Combine scores with adaptive weights\n    combined_scores = (best_fit_score * bf_weight) + (future_potential_score * fp_weight)\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are effectively zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1st vs. Heuristics 2nd:** These are identical. The ranking suggests a tie or a misunderstanding in the prompt.\n*   **Heuristics 3rd vs. Heuristics 4th:** Heuristic 3rd uses a multiplicative combination of Best Fit and Fill Ratio. Heuristic 4th uses Best Fit multiplied by an exponential `residual_quality_factor`. Heuristic 3rd's multiplicative approach with a simple fill ratio is conceptually clearer for dense packing than the exponential penalty on small residuals, which might be too aggressive or not well-calibrated without tuning.\n*   **Heuristics 5th vs. Heuristics 6th:** Heuristic 5th is identical to Heuristic 4th. Heuristic 6th introduces multiple scores (Best Fit, Worst Fit, Fullness, Fit Tightness Penalty) and adaptive weights, making it more complex and potentially harder to tune than simpler combinations. The \"adaptive weights\" in Heuristic 6th seem intended to react to item size but are not clearly defined or implemented in a way that demonstrably improves upon simpler strategies without extensive parameter tuning.\n*   **Heuristics 7th vs. Heuristics 8th:** Heuristic 7th is identical to Heuristic 6th. Heuristic 8th combines Best Fit with a simple \"fullness bonus\" (inverse of remaining capacity). This is less sophisticated than Heuristic 1st or 3rd, as it doesn't directly penalize large residual gaps or explicitly consider the \"tightness\" of the fit in its bonus calculation.\n*   **Heuristics 9th vs. Heuristics 10th:** Heuristic 9th is identical to Heuristics 4th and 5th. Heuristic 10th is identical to Heuristic 3rd.\n*   **Heuristics 11th vs. Heuristics 12th:** Heuristic 11th combines Best Fit proximity with a logarithmic \"Usefulness Bonus\" on remaining capacity. Heuristic 12th combines tightness, fullness, and a negative logarithmic \"Future Fit Score.\" Heuristic 12th's approach is more comprehensive, attempting to balance multiple aspects (tightness, fullness, and not leaving *too* much space) but with a subtraction of the future fit score, which might be counter-intuitive. Heuristic 11th's multiplicative approach with `(1 + 0.2 * adaptive_bonus)` is a more direct way to boost good fits that also leave reasonable space.\n*   **Heuristics 13th vs. Heuristics 14th:** These are identical. They use adaptive weighting based on item size ratio to balance Best Fit and Future Potential. The exponential weighting is a reasonable approach for adaptability.\n*   **Heuristics 15th vs. Heuristics 16th:** Heuristic 15th is identical to Heuristics 13th and 14th. Heuristic 16th is incomplete, only containing imports and docstrings, and includes unused library imports (random, math, scipy, torch).\n*   **Heuristics 17th vs. Heuristics 18th:** Heuristics 17th and 20th are identical. They combine Best Fit (proximity) and Fill Ratio, using a multiplicative approach, with a refinement to handle empty bins. Heuristic 18th is identical to Heuristic 16th, incomplete.\n*   **Heuristics 19th vs. Heuristics 20th:** Heuristic 19th is identical to Heuristics 17th and 20th.\n\n**Overall:** The higher-ranked heuristics (1st, 3rd, 11th, 17th/19th/20th) tend to combine Best Fit with another factor (fullness, fill ratio, or a bonus for moderate remaining space) using either additive or multiplicative logic. Lower-ranked heuristics either introduce too many complex, potentially conflicting scores (6th, 7th), use simpler additive combinations without nuanced logic (8th), or are incomplete (16th, 18th). Heuristics that attempt adaptive weighting based on item size (13th, 14th, 15th) are conceptually good but rely on careful tuning of those weights. The multiplicative approach of combining Best Fit with a Fill Ratio (3rd, 10th, 17th, 19th, 20th) seems robust.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective optimization, multiplicative scoring, adaptive weighting, robustness, simplification.\n*   **Advice:** Design heuristics that explicitly balance immediate packing gains (e.g., Best Fit) with long-term bin utilization (e.g., fill ratio). Experiment with multiplicative combinations of these metrics.\n*   **Avoid:** Redundant implementations, overly complex scoring functions without clear justification, and heuristics that don't directly address the trade-off between immediate and future packing efficiency.\n*   **Explanation:** Focusing on combining well-performing, conceptually distinct metrics multiplicatively creates synergistic effects. Avoiding complexity ensures interpretability and easier tuning, leading to more robust and generalizable heuristics.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}