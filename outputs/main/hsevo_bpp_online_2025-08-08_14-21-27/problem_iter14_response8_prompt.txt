{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit with a bonus for already full bins, using a logarithmic bonus\n    to balance tight fits with encouraging fuller bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins that leave less remaining capacity.\n    # Adding a small epsilon to avoid division by zero.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Bonus: A bonus for bins that are already more full.\n    # Using the inverse of remaining capacity on fittable bins.\n    # Normalize by the maximum remaining capacity among fittable bins to get a relative measure.\n    max_remaining_cap_fittable = np.max(fittable_bins_remain_cap)\n    fullness_bonus = (max_remaining_cap_fittable - fittable_bins_remain_cap) / (max_remaining_cap_fittable + 1e-6)\n\n    # Adaptive Bonus using logarithm of remaining capacity after fit.\n    # This penalizes leaving excessively large gaps but gives smaller penalties for smaller gaps.\n    # Adding 1 to prevent log(0) and ensure positive values.\n    adaptive_bonus = np.log1p(fittable_bins_remain_cap - item)\n\n    # Combine: Weighted sum of Best Fit and Fullness Bonus, with Adaptive Bonus as a modifier.\n    # Weights are heuristic and can be tuned. Here, Best Fit is primary, Fullness adds context,\n    # and the Adaptive Bonus influences the penalty for leftover space.\n    # We invert the adaptive bonus as smaller leftover space (lower log) should be better.\n    combined_scores = (best_fit_scores * 1.0) + (fullness_bonus * 0.5) - (adaptive_bonus * 0.2)\n\n    # Normalize priorities to a [0, 1] range for better comparability and to avoid extreme values.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a 'fill ratio' bonus, prioritizing bins that are both a tight fit\n    and already well-utilized, aiming for efficient packing.\n\n    Args:\n        item (float): The size of the item to be packed.\n        bins_remain_cap (np.ndarray): A numpy array representing the remaining capacity of each bin.\n        epsilon (float, optional): A small constant to prevent division by zero. Defaults to 1e-9.\n\n    Returns:\n        np.ndarray: A numpy array of priorities for each bin, normalized to [0, 1].\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 & 2 vs. 3 & 5:** Heuristics 1 and 2 use a weighted sum and include a logarithmic adaptive bonus, which is more nuanced than the multiplicative combination of Best Fit and Fill Ratio in 3 and 5. The inclusion of a \"fullness bonus\" (inverse of remaining capacity) and an \"adaptive bonus\" (logarithm of remaining capacity) in 1 and 2 provides a more sophisticated scoring mechanism. Heuristics 3 and 5 use a simple multiplicative combination, which might be less robust to extreme values.\n*   **Heuristics 1 & 2 vs. 4:** Heuristic 4 uses a multiplicative combination with a simpler fullness score than 1 and 2. Heuristics 1 and 2's additive combination with a logarithmic penalty seems more robust and less prone to over-penalizing due to multiplication. The \"adaptive bonus\" in 1 and 2 offers finer control over penalizing large leftover spaces.\n*   **Heuristics 1 & 2 vs. 6 & 9:** Heuristics 6 and 9 also use a multiplicative combination with a logarithmic bonus. However, they apply it as `best_fit_scores * (1.0 + fullness_bonus * 0.2)`, which might be less balanced than the additive approach in 1 and 2, especially if `fullness_bonus` becomes very large. Heuristics 1 and 2's use of a weighted sum with an *inversion* of the adaptive bonus (`- (adaptive_bonus * 0.2)`) suggests a more deliberate attempt to balance fitting tightness and residual space.\n*   **Heuristics 3 & 5 vs. 7 & 11 & 12 & 14 & 20:** Heuristics 7, 11, 12, 14, and 20 are similar in their multiplicative combination of Best Fit and Fill Ratio. However, 11, 12, 14, and 20 attempt to refine this by handling empty bins or adding small constants, making them slightly more robust. Heuristic 7's fill ratio calculation (`1.0 / (fittable_bins_remain_cap + 1e-9)`) is a bit simplistic and might not clearly represent \"fullness\" as well as calculating `1 - remaining_capacity/capacity`. Heuristics 11, 12, 14, and 20 are very similar, with the `np.maximum` refinement in 11, 12, and 14 adding a useful layer.\n*   **Heuristics 8 vs. others:** Heuristic 8 uses a multiplicative combination with a fullness score based on `1.0 - (fittable_bins_remain_cap / max_initial_remain_cap)`. This is a reasonable approach, but the specific formula for `best_fit_scores` (`1.0 / (fittable_bins_remain_cap - item + 1.0)`) is less aggressive than `1.0 / (fittable_bins_remain_cap - item + epsilon)`, potentially making it less sensitive to very tight fits.\n*   **Heuristics 10, 13, 15, 17, 19:** These heuristics have incomplete code bodies (only the function signature and docstring, or just the signature and mask). Their actual logic is not present, making direct comparison impossible. They seem to be placeholders or intended to be filled.\n*   **Heuristics 16 & 18:** Similar to the above, these also have incomplete implementations. They mention a \"fill ratio\" bonus but don't show its calculation or how it's combined.\n*   **Overall Ranking Rationale:** Heuristics 1 and 2 stand out due to their additive combination strategy, the inclusion of a weighted sum of multiple factors (Best Fit, Fullness Bonus, Adaptive Bonus), and the use of logarithmic scaling for finer control. This suggests a more balanced and adaptable approach. Heuristics 11, 12, 14, and 20 follow with their multiplicative Best Fit + Fill Ratio approach, enhanced by refinements for edge cases like empty bins. Heuristic 4 is a simpler version of the multiplicative approach. Heuristics 3 and 5 are basic multiplicative combinations. Heuristic 8 has a slightly less aggressive Best Fit component. Heuristics 7 is similar but with a less robust fill ratio calculation. Heuristics 6 and 9 use a multiplicative approach that might be less balanced than the additive approach in 1 and 2. The incomplete heuristics (10, 13, 15, 16, 17, 18, 19) are ranked lowest due to their lack of implementational detail.\n- \nHere's a redefined approach to self-reflection for designing better heuristics, focusing on overcoming ineffective practices:\n\n*   **Keywords:** Objective Combination, Adaptive Weighting, Multiplicative Scoring, Robustness.\n*   **Advice:** Focus on *why* certain objective combinations work, not just *that* they work. Explicitly model trade-offs using multiplicative or weighted additive functions, and proactively test for edge cases that break simple rules.\n*   **Avoid:** Redundant comparisons of nearly identical implementations, treating similar scoring mechanisms as distinct, and vague justifications for complexity. Do not overlook the *interaction* between objective components.\n*   **Explanation:** Effective self-reflection means dissecting the *mechanism* of success. Instead of stating \"combine objectives,\" analyze *how* a multiplicative approach balances fitting an item now versus leaving usable space for later. This analytical depth guides the creation of truly novel and robust heuristics.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}