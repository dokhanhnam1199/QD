[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a Fill Ratio that penalizes large remaining capacities.\n    Prioritizes bins that snugly fit the item and are already substantially full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    eligible_bins_caps = bins_remain_cap[fittable_bins_mask]\n\n    # Score 1: Best Fit (inverse of remaining capacity after packing)\n    # Higher score for smaller remaining capacity. Adding epsilon for numerical stability.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # Score 2: Fill Ratio (inversely proportional to remaining capacity)\n    # Prioritizes bins that are more full. This is a refinement to penalize bins\n    # with a lot of leftover space more strongly than a simple ratio.\n    fill_ratio_scores = 1.0 / (eligible_bins_caps + 1e-9)\n\n    # Combine scores multiplicatively. This emphasizes bins that are good in both aspects.\n    # The addition of 1.0 in the fill_ratio_scores is removed to directly use the inverse\n    # of remaining capacity for a stronger penalty on larger remaining spaces.\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign combined scores to the priorities array for eligible bins.\n    priorities[fittable_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1] for consistent comparison.\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and Fullness Ratio with an adaptive bonus,\n    prioritizing bins that offer a tight fit and are already well-utilized.\n    This aims for efficient packing by balancing immediate fit with future bin usage.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n    \n    # Best Fit Score: Inverted remaining capacity after fit. Tighter fits get higher scores.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n    \n    # Fullness Score: (Bin Capacity - Remaining Capacity) / Bin Capacity. Higher for fuller bins.\n    # Assuming a bin capacity of 1.0 for normalization.\n    bin_capacity = 1.0\n    current_fill_ratio = (bin_capacity - fittable_bins_remain_cap) / bin_capacity\n    fill_ratio_score = current_fill_ratio\n\n    # Adaptive Bonus: Penalizes bins with large remaining capacity more heavily.\n    # This encourages using bins that would leave smaller unusable gaps.\n    # A lower remaining capacity (higher fill ratio) leads to a smaller (less negative) adaptive bonus.\n    adaptive_bonus = -np.log(fittable_bins_remain_cap + 1e-9) * 0.5\n\n    # Combine scores: Multiplicatively combine Best Fit and Fill Ratio,\n    # then add the adaptive bonus. This prioritizes tight fits and full bins,\n    # with an adjustment for leftover space.\n    combined_scores = best_fit_scores * (1 + fill_ratio_score) + adaptive_bonus\n    \n    # Ensure that even if combined_scores are very low or negative, a small positive priority exists\n    # for fittable bins, mainly driven by the best_fit_scores component.\n    # This prevents entirely eliminating bins that are only a decent fit.\n    priorities[fittable_bins_mask] = np.maximum(combined_scores, best_fit_scores * 0.1)\n\n    # Normalize priorities to a [0, 1] range for consistent behavior.\n    max_priority = np.max(priorities)\n    if max_priority > 1e-9:\n        priorities[fittable_bins_mask] /= max_priority\n    else:\n        # Fallback for cases where all calculated priorities are near zero.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a modified Fill Ratio (item/bin_capacity).\n    Prioritizes bins that fit the item snugly and are already substantially full.\n    This aims for denser packing by favoring bins that are both a good fit and well-utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the current item.\n    eligible_bins_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return all zeros.\n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    # Get the remaining capacities of only the eligible bins.\n    eligible_bins_caps = bins_remain_cap[eligible_bins_mask]\n\n    # --- Best Fit Component ---\n    # This component prioritizes bins where the item leaves the least remaining capacity.\n    # A smaller remaining capacity after packing (eligible_bins_caps - item) results in a higher score.\n    # Adding a small epsilon (1e-9) prevents division by zero for bins that will be exactly full.\n    best_fit_scores = 1.0 / (eligible_bins_caps - item + 1e-9)\n\n    # --- Fill Ratio Component ---\n    # This component prioritizes bins that are already more full, relative to the item's size.\n    # A higher item size relative to the bin's remaining capacity indicates a better \"fill\".\n    # This encourages using bins that have already been utilized to a greater extent.\n    fill_ratio_scores = item / (eligible_bins_caps + 1e-9)\n\n    # --- Combined Score ---\n    # Multiply the Best Fit and Fill Ratio scores. This multiplicative approach\n    # ensures that bins excelling in BOTH criteria receive disproportionately higher scores.\n    # Bins that are a tight fit AND are already quite full are strongly preferred.\n    combined_scores = best_fit_scores * fill_ratio_scores\n\n    # Assign the calculated combined scores back to the priorities array for the eligible bins.\n    priorities[eligible_bins_mask] = combined_scores\n\n    # Normalize priorities to the range [0, 1]. This makes scores comparable\n    # across different item/bin configurations and helps in selecting the top bin.\n    # Avoid division by zero if all priorities are zero (which shouldn't happen here\n    # if eligible_bins_mask is true, but good practice).\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities = priorities / max_priority\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's preference for tight fits with a multiplicative\n    fullness bonus, prioritizing bins that are nearly full and can\n    accommodate the item with minimal remaining space.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit component: Prioritize bins with smallest remaining capacity after fitting\n    # Adding a small epsilon to avoid division by zero if remaining capacity is exactly item size\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fullness component: Prioritize bins that are already more full.\n    # Assuming a normalized bin capacity of 1.0. If capacity varies, this needs adjustment.\n    # Higher fullness means smaller remaining capacity, so we want to penalize larger remaining capacities.\n    # A simple way is to use the inverse of remaining capacity, but to avoid zero for empty bins\n    # and to make it more comparable to best_fit, let's use a score derived from 1 - (remaining_cap / capacity)\n    # where capacity is assumed to be 1.0.\n    fullness_score = 1.0 - fittable_bins_remain_cap # Higher score for smaller remaining capacity\n\n    # Combine scores multiplicatively: Boosts bins that are both tight fits and more full.\n    # A small constant is added to fullness_score to prevent it from being zero,\n    # ensuring that even less full bins contribute to the multiplicative factor.\n    combined_scores = best_fit_score * (fullness_score + 0.5) # Adding a small boost to less full bins\n\n    priorities[fittable_bins_mask] = combined_scores\n\n    # Normalize priorities for fittable bins to a [0, 1] range.\n    max_priority = np.max(priorities[fittable_bins_mask])\n    if max_priority > 0:\n        priorities[fittable_bins_mask] /= max_priority\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness and a logarithmic fullness bonus multiplicatively.\n    This prioritizes bins that are already quite full and can snugly fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins with minimal remaining capacity after fitting.\n    # Adding epsilon for numerical stability.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Bonus: A bonus reflecting how full the bin is *before* fitting the item.\n    # Uses a logarithmic scale to give diminishing returns for very full bins,\n    # but still rewards moderately full bins. Add 1 to avoid log(0).\n    # We use the *inverse* of remaining capacity to represent fullness.\n    fullness_bonus = np.log1p(1.0 / (fittable_bins_remain_cap + 1e-6))\n\n    # Combined Score: Multiplicatively combine Best Fit and Fullness Bonus.\n    # This prioritizes bins that are both a good fit (low residual space)\n    # and are already quite full.\n    combined_scores = best_fit_scores * (1.0 + fullness_bonus * 0.5) # Adjust weight for fullness bonus\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's tightness with a multiplicative Fill Ratio bonus,\n    prioritizing bins that are both a good fit and already relatively full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Inverse of the remaining capacity after packing. Higher is better.\n    # Adding epsilon to avoid division by zero.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fill Ratio Score: Represents how full the bin *was* before this item.\n    # A higher fill ratio (lower remaining capacity) is generally better for consolidation.\n    # We use the inverse of the remaining capacity (plus epsilon) as a proxy.\n    fill_ratio_score = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine multiplicatively: Prioritize bins that are both a tight fit (high best_fit_score)\n    # and were already quite full (high fill_ratio_score).\n    combined_scores = best_fit_score * fill_ratio_score\n\n    # Normalize scores to the range [0, 1] for consistent priority assignment.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit's preference for tight fits with a refined 'fill ratio' bonus,\n    prioritizing bins that are both a good fit and already significantly utilized.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins that leave less remaining capacity.\n    # Add epsilon to avoid division by zero and prioritize tighter fits.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Refined Fill Ratio Bonus: Prioritizes bins that are more full.\n    # This is calculated as 1 - (remaining_capacity / max_possible_capacity),\n    # which directly indicates how much space is already occupied.\n    # We consider the initial maximum remaining capacity to establish a baseline for \"fullness\".\n    max_initial_remain_cap = np.max(bins_remain_cap)\n    fill_ratio_bonus = 1.0 - (fittable_bins_remain_cap / (max_initial_remain_cap + 1e-9))\n\n    # Combine: Use a multiplicative approach for Best Fit and Fill Ratio.\n    # This aims to reward bins that are *both* a tight fit and already full.\n    # A small constant is added to the fill ratio bonus to avoid zeroing out\n    # the score if a bin is completely empty but a tight fit.\n    combined_scores = best_fit_scores * (fill_ratio_bonus + 0.1)\n\n    # Normalize priorities to a [0, 1] range.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a normalized \"fullness\" score multiplicatively,\n    prioritizing bins that are both a tight fit and already quite full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Inverse of remaining capacity after fitting. Smaller remaining capacity is better.\n    # Adding a small epsilon to prevent division by zero.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fullness Score: Ratio of capacity already used. Higher is better.\n    # Normalized by the maximum remaining capacity among fittable bins to gauge how \"full\" a bin is relative to others.\n    # A bin with less initial remaining capacity is considered fuller.\n    max_initial_remain_cap = np.max(fittable_bins_remain_cap)\n    # Handle the case where max_initial_remain_cap is very small or zero to avoid division by zero.\n    if max_initial_remain_cap < 1e-9:\n        fullness_scores = np.ones_like(fittable_bins_remain_cap) # All bins are equally \"full\" if none have significant remaining capacity\n    else:\n        fullness_scores = 1.0 - (fittable_bins_remain_cap / max_initial_remain_cap)\n\n    # Combine scores multiplicatively. This rewards bins that are both a good fit and already full.\n    # Add a small constant to fullness scores to prevent the combined score from becoming zero easily\n    # if Best Fit score is high but Fullness is low (or vice-versa).\n    combined_scores = best_fit_scores * (fullness_scores + 0.1)\n\n    # Normalize the combined scores to be between 0 and 1 for consistent priority representation.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all combined scores are near zero (e.g., all bins are large and empty),\n        # assign a uniform small priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive penalty for leftover space,\n    prioritizing tight fits while discouraging large wasted capacities.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit: Higher score for bins with less remaining capacity after fitting.\n    # Add a small epsilon to avoid division by zero and to ensure non-zero scores for perfect fits.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Adaptive Penalty: Penalize leaving large gaps using a logarithmic function.\n    # Logarithm of (1 + remaining capacity after fit) smooths the penalty,\n    # giving diminishing returns to larger remaining spaces.\n    # We invert this to reward smaller leftover spaces.\n    adaptive_penalty = np.log1p(fittable_bins_remain_cap - item + 1)\n\n    # Combine: A weighted sum. Best Fit is the primary driver,\n    # with the adaptive penalty acting as a penalty for suboptimal fits (large remaining capacity).\n    # The weight for adaptive_penalty is negative to penalize.\n    combined_scores = (best_fit_scores * 1.0) - (adaptive_penalty * 0.3)\n\n    # Normalize scores to the [0, 1] range.\n    # If all scores are very close to zero or negative, assign a small positive value\n    # to ensure fittable bins have some priority.\n    max_score = np.max(combined_scores)\n    min_score = np.min(combined_scores)\n\n    if max_score - min_score > 1e-9:\n        priorities[fittable_bins_mask] = np.clip((combined_scores - min_score) / (max_score - min_score), 0, 1)\n    else:\n        # If all calculated scores are effectively the same (e.g., all perfect fits or all similarly poor fits)\n        # assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.5\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a logarithmic fill ratio bonus multiplicatively.\n    Prioritizes bins that are a tight fit and already quite full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins with minimal remaining capacity after fitting.\n    # Add epsilon for numerical stability and to avoid division by zero.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Fullness Bonus: Logarithmic scale of how full the bin is *before* fitting.\n    # Use log1p to handle remaining capacity of 0 gracefully.\n    # This term is inversely related to remaining capacity.\n    fullness_bonus = np.log1p(1.0 / (fittable_bins_remain_cap + 1e-9))\n\n    # Combine scores multiplicatively: Emphasizes bins that are both a good fit and already full.\n    combined_scores = best_fit_scores * (1.0 + fullness_bonus * 0.5) # Adjust multiplier for balance\n\n    # Normalize priorities to a [0, 1] range for consistent comparison.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # Fallback: if all combined scores are near zero, assign uniform small priority.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response0.txt_stdout.txt",
    "code_path": "problem_iter15_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n    fittable_indices = np.where(fittable_bins_mask)[0]\n\n    # Component 1: Best Fit - Prioritize bins that leave minimal remaining capacity.\n    # This encourages tighter packing. Use inverse of remaining space + epsilon.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Component 2: Worst Fit Incentive - Prioritize bins that have a larger remaining capacity\n    # among the fittable bins. This aims to keep smaller remaining capacities available for\n    # smaller items later, potentially leading to fewer bins being used overall.\n    # Calculate the gap created if the item is placed, and then rank bins by the *largest* gap.\n    gaps = fittable_bins_remain_cap - item\n    worst_fit_score = gaps # Higher gap is better here.\n\n    # Component 3: Proximity to Half-Capacity Bonus - This heuristic aims to balance bins\n    # around the mid-point of their capacity. Bins that, after fitting, are closer to\n    # half-full might be more versatile for future items.\n    # We are interested in bins where (remaining_cap - item) is close to bin_capacity / 2.\n    # For simplicity, we can approximate this by looking at the remaining capacity\n    # relative to a \"medium\" size. Let's consider bins that, after fitting the item,\n    # have a remaining capacity that is not too small and not too large.\n    # A score that peaks when remaining_cap - item is around some threshold (e.g., 0.5 * bin_capacity).\n    # For simplicity here, let's use a score that is high when the remaining capacity\n    # after fit is \"reasonable\" (not too close to 0, not too close to full).\n    # This is a simplification, a more robust approach might involve estimating typical item sizes.\n    # For now, we'll use a score that is high when the leftover space is moderate.\n    # A simple Gaussian-like function centered around a moderate leftover space.\n    # Let's assume a moderate leftover space is around 0.3 of the original bin capacity.\n    # Since we don't know the original bin capacity, we can use a proxy like the average\n    # remaining capacity of fittable bins. This is heuristic.\n    avg_fittable_remain_cap = np.mean(fittable_bins_remain_cap)\n    # Score is higher when (fittable_bins_remain_cap - item) is closer to avg_fittable_remain_cap\n    # We can use a Gaussian-like function, or simpler: penalize extremes.\n    # Let's reward bins that leave a moderate amount of space, not too little (handled by BF)\n    # and not too much (handled by WF).\n    # Score is higher for leftover space that is not too small (but not too large either).\n    # Let's consider the relative leftover space.\n    relative_leftover = (fittable_bins_remain_cap - item) / (np.max(fittable_bins_remain_cap) + 1e-9)\n    # We want to favor bins where relative_leftover is in a middle range, e.g., 0.2 to 0.7.\n    # A simple approach: penalize very small or very large relative leftovers.\n    # This is tricky without knowing the distribution of item sizes or bin capacities.\n    # A simpler proxy: favor bins that are not already almost full, but also not almost empty.\n    # Let's use a score that is higher for bins that are neither very full nor very empty.\n    # This can be seen as a \"balance\" score.\n    balance_score = (fittable_bins_remain_cap - item) / (fittable_bins_remain_cap + 1e-9) # Score closer to 1 means less remaining space.\n    # We want to reward bins that have *some* remaining space, but not excessive.\n    # So we want balance_score to be less than 1.\n    # Let's invert it: higher score for more remaining space, capped.\n    # Alternatively, prioritize bins that are \"medium\" full.\n    # Consider remaining capacity as a proportion of total capacity (which is unknown, assume 1.0 for normalized).\n    # A score that peaks when remaining_cap - item is around 0.5.\n    # Let's simplify: reward bins that have a moderate remaining capacity after fitting.\n    # This is inherently difficult without knowledge of total capacity.\n    # Alternative interpretation of \"balance\": favor bins that are not too empty after fitting.\n    # This means favoring bins where fittable_bins_remain_cap - item is not extremely small.\n    # This is implicitly handled by Best Fit to some extent.\n\n    # Let's try a different approach for Component 3: Affinity for a \"central\" remaining capacity.\n    # Suppose we want to keep bins with remaining capacities in a mid-range.\n    # This is hard to define without bin capacity.\n    # A simpler approach: Reward bins that are not *too* full after placing the item.\n    # Penalize bins that would become very full.\n    # Score = 1 - (remaining_cap - item) / max_possible_remaining_space (which is max(bins_remain_cap))\n    # This is similar to penalizing tight fits.\n\n    # Let's combine Best Fit and Worst Fit with a multiplicative approach,\n    # and add a term that encourages moderate usage of bins.\n    # Multiplicative combines scores more aggressively.\n\n    # Normalize component scores to a comparable range, e.g., [0, 1] or similar.\n    # Best Fit: Already inverse, higher is better. Max value can be large.\n    # Worst Fit: Higher gap is better. Max value can be large.\n    # Let's normalize gaps to be in [0, 1] where 1 is the largest gap.\n    normalized_worst_fit = gaps / (np.max(gaps) + 1e-9)\n\n    # Let's try a score that favors bins that aren't too full, but also not too empty.\n    # A score that is higher when the remaining capacity after fit is moderate.\n    # This is hard without knowing the bin capacity.\n    # Alternative: Reward bins that are \"moderately used\".\n    # If we consider the remaining capacity `r` after fitting item `i`, we want `r` not too small and not too large.\n    # A simple score could be: `exp(-k * (r - target_r)^2)`. But `target_r` is unknown.\n    # Let's try a score that is higher for bins that have *some* remaining space, but not a lot.\n    # This is difficult to formulate generally.\n\n    # Let's reconsider the objective: Minimize the number of bins.\n    # Heuristics typically aim to either:\n    # 1. Pack tightly (Best Fit) to reduce wasted space *within* a bin.\n    # 2. Leave larger gaps (Worst Fit) to accommodate potentially larger future items.\n    # 3. Fill bins \"evenly\" (First Fit Decreasing style).\n\n    # For v2, let's prioritize bins that are *close* to fitting the item (Best Fit aspect),\n    # AND among those that are a \"good fit\", prefer those that are *more full* overall\n    # (but not so full they become unusable later), and also slightly favor those that leave\n    # a decent remaining space (Worst Fit aspect).\n\n    # Let's try a weighted additive combination with focus on robustness and interaction.\n    # Score = w1 * (BestFit) + w2 * (WorstFit) + w3 * (ModerateRemaining)\n\n    # Best Fit score: Higher for smaller leftover space.\n    # Let's scale it by the item size itself. The smaller the leftover relative to item size, the better.\n    # scaled_best_fit = 1.0 / ((fittable_bins_remain_cap - item) / item + 1e-9)\n    # This can be unstable if item size is small. Let's stick to inverse of absolute leftover.\n    best_fit_term = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Worst Fit score: Higher for larger leftover space.\n    # Let's normalize by the maximum possible leftover space.\n    # Max leftover space can be the max remaining capacity among fittable bins.\n    max_fittable_rem = np.max(fittable_bins_remain_cap)\n    worst_fit_term = (fittable_bins_remain_cap - item) / (max_fittable_rem + 1e-9)\n\n    # New component: \"Bin Utilization Balance\"\n    # Favor bins that are not excessively empty or excessively full after fitting.\n    # Consider the remaining capacity `r = fittable_bins_remain_cap[i] - item`.\n    # We want `r` to be neither too close to 0 nor too close to `fittable_bins_remain_cap[i]`.\n    # A simple score: The more remaining capacity, the less \"balanced\" it is in terms of filling.\n    # However, we want to balance *usage*, not necessarily remaining space.\n    # Let's try to encourage bins that are \"moderately full\".\n    # If `fittable_bins_remain_cap[i]` is the current remaining capacity, and `item` is placed.\n    # The *new* remaining capacity is `r = fittable_bins_remain_cap[i] - item`.\n    # We want `r` to be \"reasonable\".\n    # Consider the ratio of current remaining capacity to the capacity used.\n    # Current remaining capacity: `c`. Item size: `i`. New remaining capacity: `c - i`.\n    # Capacity used: `TotalCapacity - c`. Capacity used by item: `i`.\n    # Let's consider the proportion of remaining capacity relative to the *original* bin capacity.\n    # Since original bin capacity is unknown, let's use the *current* remaining capacity as a proxy for how \"full\" the bin is.\n    # A bin with high `fittable_bins_remain_cap` is less full.\n    # We want bins that are not too empty. So, `fittable_bins_remain_cap[i]` shouldn't be extremely large.\n    # Let's create a score that penalizes bins that have a very large remaining capacity.\n    # Higher score for smaller `fittable_bins_remain_cap`.\n    # Let's use inverse of remaining capacity, but capped.\n    # Or, inverse of remaining capacity to the power of some factor.\n    # Let's try: `fittable_bins_remain_cap[i] / (fittable_bins_remain_cap[i] + item)` - proportion of capacity already filled with current item.\n    # This doesn't consider the bin's state.\n\n    # Let's try a score that promotes bins that are *not* almost full, and also *not* almost empty.\n    # This is the \"balanced\" idea.\n    # Score for being \"not too empty\": penalize large `fittable_bins_remain_cap`.\n    # Score for being \"not too full\": penalize small `fittable_bins_remain_cap - item`.\n    # This is conflicting with Best Fit.\n\n    # Let's refine the idea of balancing: Aim for bins where the remaining capacity after fitting\n    # is not too small (to avoid wasting tiny gaps) and not too large (to encourage fuller bins).\n    # This is like a soft \"Best Fit\" and a soft \"Worst Fit\" simultaneously.\n\n    # Let's consider the \"effective remaining capacity\" as `fittable_bins_remain_cap - item`.\n    # We want this to be small (BestFit) but not too small.\n    # And we want the bin to not be excessively full.\n    # The previous v1 used `log1p(fittable_bins_remain_cap - item)` which penalizes larger gaps.\n    # We want to penalize *very small* gaps and *very large* gaps.\n\n    # Let's try a score that combines Best Fit and Worst Fit multiplicatively,\n    # and add a term that rewards bins that are \"medium\" full.\n    # Multiplicative combination: `(BestFitTerm) * (WorstFitTerm) * (MediumFillTerm)`\n    # This requires all terms to be positive and well-behaved.\n\n    # Let's define terms for the fittable bins:\n    # Term 1: Tightness score (Best Fit proxy) - higher for less remaining space.\n    # Score is proportional to 1 / (remaining_cap - item).\n    tightness_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Term 2: Gap score (Worst Fit proxy) - higher for more remaining space.\n    # Score is proportional to (remaining_cap - item).\n    gap_score = fittable_bins_remain_cap - item\n\n    # Term 3: Balance score - Higher for moderate remaining capacity.\n    # This is tricky without bin capacity. Let's assume we want remaining capacity to be\n    # in a \"central\" range. If the max remaining capacity among fittable bins is `M`,\n    # we might want `fittable_bins_remain_cap[i] - item` to be around `M/2` or `item`.\n    # Let's try a score that is higher when `fittable_bins_remain_cap[i] - item` is\n    # not extremely small and not extremely large.\n    # A Gaussian-like score: `exp(-k * (gap - target_gap)^2)`.\n    # Let's simplify: penalize bins that leave very little space and bins that leave very much space.\n    # This can be achieved by penalizing `gap` near 0 and `gap` near `max_fittable_rem`.\n    # A score that is high in the middle range of gaps.\n    # We can use a function like `sin(pi * gap / (max_fittable_rem + epsilon))` which peaks at `max_fittable_rem / 2`.\n    # Or a simple heuristic: favor bins that are not already mostly full.\n    # Let's consider the ratio of `item` to `fittable_bins_remain_cap`. A higher ratio means the item fills more of the *available* space.\n    # `item / fittable_bins_remain_cap` -> higher means more \"efficient\" use of *current* remaining space.\n    # However, `fittable_bins_remain_cap` itself varies.\n\n    # Let's try a simpler additive combination with adjusted weights and terms.\n    # We want to balance tight packing (Best Fit) with leaving useful gaps (Worst Fit).\n    # Add a term that considers the absolute \"fullness\" of the bin relative to its current state.\n    # Favor bins that have a good amount of remaining capacity, but not so much that they are nearly empty.\n    # This is a delicate balance.\n\n    # Proposed v2 strategy:\n    # 1. Best Fit component: score = 1 / (residual_capacity + epsilon) - promotes tight fits.\n    # 2. Worst Fit component: score = residual_capacity - promotes leaving larger gaps.\n    # 3. \"Fill Balance\" component: score = (current_remaining_cap - residual_capacity) / (current_remaining_cap + epsilon)\n    #    This term represents the proportion of the bin's *current available space* that is used by the item.\n    #    A higher score means the item uses a larger fraction of the *current available space*.\n    #    This favors bins that are not extremely empty, but also not extremely full.\n    #    If a bin has 100 capacity and item is 60, score is 60/100 = 0.6.\n    #    If a bin has 10 capacity and item is 8, score is 8/10 = 0.8.\n    #    This implicitly favors bins that are more full.\n\n    # Let's redefine components for fittable bins:\n    residual_capacity = fittable_bins_remain_cap - item\n\n    # Component 1: Best Fit (inverse residual)\n    # Higher score for smaller residual capacity.\n    best_fit_val = 1.0 / (residual_capacity + 1e-9)\n\n    # Component 2: Worst Fit (residual capacity itself)\n    # Higher score for larger residual capacity.\n    worst_fit_val = residual_capacity\n\n    # Component 3: \"Proportional Fill\" - How much of the *available space* does the item consume?\n    # Score = item_size / available_space = item_size / fittable_bins_remain_cap\n    # This favors using up a larger chunk of the existing available space.\n    # If fittable_bins_remain_cap is small, this ratio can be large.\n    # This term might favor bins that are already quite full.\n    proportional_fill_val = item / (fittable_bins_remain_cap + 1e-9)\n\n    # Combine these terms. A multiplicative combination can be powerful but sensitive.\n    # Let's use weighted additive combination for better control.\n    # Weights can be tuned. Let's give Best Fit a primary role, Worst Fit a secondary,\n    # and Proportional Fill a moderating role.\n\n    # Normalize terms to prevent dominance by scale.\n    # Best Fit: can be large. Normalize by max BF score.\n    normalized_bf = best_fit_val / (np.max(best_fit_val) + 1e-9)\n\n    # Worst Fit: range is 0 to max_fittable_rem. Normalize by max_fittable_rem.\n    normalized_wf = worst_fit_val / (np.max(fittable_bins_remain_cap) + 1e-9)\n\n    # Proportional Fill: range is 0 to 1 (if item <= fittable_bins_remain_cap).\n    normalized_pf = proportional_fill_val\n\n    # Combine with weights.\n    # Let's try:\n    # w_bf = 1.0\n    # w_wf = 0.5  # Slightly favor leaving gaps\n    # w_pf = 0.3  # Moderate preference for using a good portion of available space\n    # This combination aims to find bins that are a good fit (BF), and among them,\n    # favors those that leave decent gaps (WF), and also prefer bins where the item\n    # consumes a noticeable fraction of the current available space (PF).\n\n    # Let's consider a different balance: Best Fit vs. Worst Fit.\n    # Standard BF puts item in bin with minimum remaining capacity.\n    # Standard WF puts item in bin with maximum remaining capacity.\n\n    # For v2, let's try to bridge BF and WF.\n    # Consider bins that are \"good fits\" (residual_capacity not too large).\n    # Among these, prefer those that are tighter (BF) but also those that leave\n    # a \"reasonable\" gap (WF).\n\n    # How about a score that is a combination of the \"tightness\" and the \"gap left\"?\n    # Let's use a score that is higher for bins that are a good fit,\n    # and among those, prefer tighter fits, but not *extreme* tight fits if they leave\n    # a very large capacity unused in other bins.\n\n    # Let's reconsider the problem as selecting a bin that offers a good trade-off.\n    # Consider the score as a function of the residual capacity `r = fittable_bins_remain_cap - item`.\n    # We want `r` to be small (BF) but not zero if that means leaving other bins very empty.\n    # We want `r` to be moderate (WF proxy).\n\n    # Let's try a score that is high when `r` is small and when `fittable_bins_remain_cap` is also not too large.\n    # This encourages using bins that are already somewhat full.\n\n    # New strategy: Prioritize bins that have a remaining capacity not much larger than the item itself.\n    # This is a \"close fit\" idea, but not necessarily the absolute tightest.\n    # Score = 1.0 / (abs(fittable_bins_remain_cap - item - target_gap) + epsilon)\n    # Where `target_gap` could be 0 (BF), or something positive.\n\n    # Let's try a score based on the *ratio* of residual capacity to the bin's current remaining capacity.\n    # `residual_capacity / fittable_bins_remain_cap`\n    # This is `(fittable_bins_remain_cap - item) / fittable_bins_remain_cap`\n    # This score is lower when the bin is more full.\n    # We want this score to be not too high (meaning small residual) and not too low (meaning large residual).\n    # This is like a \"middle ground\" score for the residual.\n\n    # Let's combine Best Fit with a penalty for leaving *too much* empty space.\n    # Score = BestFitScore * (1 - penalty for large residual)\n    # Penalty for large residual could be `residual / max_residual`.\n\n    # Proposed v2: Multiplicative combination of Best Fit and a \"Fill Preference\".\n    # Best Fit Score: 1 / (residual_capacity + epsilon). Higher is better.\n    # Fill Preference Score: Favor bins that are not \"too empty\".\n    # If `fittable_bins_remain_cap` is large, the bin is \"more empty\".\n    # So, we want to penalize large `fittable_bins_remain_cap`.\n    # Score = `1 / (fittable_bins_remain_cap + epsilon)`. Higher is better.\n    # Let's try `(1 / (residual_capacity + epsilon)) * (1 / (fittable_bins_remain_cap + epsilon))`\n    # This would favor bins that are both tight fits AND are already quite full.\n    # This might be too aggressive on filling early bins.\n\n    # Let's try an additive combination that balances tight fits with leaving moderate gaps.\n    # Term 1: Best Fit (inverse residual capacity)\n    # Term 2: Worst Fit (residual capacity)\n    # Combine: `w1 * (1 / residual) + w2 * residual`\n    # This form tends to have a minimum when `w1 / residual^2 = w2`, so `residual = sqrt(w1/w2)`.\n    # This suggests that this combination favors residuals around a specific value.\n\n    # Let's use weighted combination of Best Fit and a \"Balance\" score.\n    # Best Fit: `1 / (residual_capacity + epsilon)`\n    # Balance: Favor bins that are not excessively full. This means penalizing bins\n    # where `fittable_bins_remain_cap` is small.\n    # So, favor bins with larger `fittable_bins_remain_cap`, but not too large.\n    # Let's use `fittable_bins_remain_cap` itself as a score (higher is better, means more space).\n    # This is akin to Worst Fit, but we want it to be moderate.\n\n    # Let's consider the *efficiency* of filling.\n    # Score = (item_size) / (bin_capacity). This requires bin capacity.\n    # Proxy: (item_size) / (fittable_bins_remain_cap + item_size)\n    # This is the proportion of the *used* space relative to the *new remaining* space.\n    # This is `item / new_remaining_cap`.\n    # This term is higher for tight fits. It's similar to Best Fit.\n\n    # Let's try a score that balances Best Fit and Worst Fit, using a sigmoid-like function to shape the preference.\n    # `score = BF_score * (1 - WF_score)`\n    # `score = (1 / residual_capacity) * (1 - residual_capacity / max_residual)`\n    # This rewards small residuals, but penalizes extremely small ones if max_residual is large.\n\n    # Let's use a weighted sum of Best Fit and Worst Fit, with an adjustment factor.\n    # Final proposed v2 strategy:\n    # 1. Primary: Best Fit (favoring tightness)\n    # 2. Secondary: Balance (favoring bins that are not too full, but also not too empty)\n    #    This balance is tricky. Let's try favoring bins where the residual capacity\n    #    is not excessively large compared to the item itself.\n    #    Score: `1 - residual_capacity / (item + epsilon)`\n    #    This term is higher when `residual_capacity` is small relative to `item`.\n    #    So, it rewards tighter fits, but also penalizes leaving *much* more space than the item's size.\n\n    residual_capacity = fittable_bins_remain_cap - item\n\n    # Component 1: Best Fit (inverse of residual capacity)\n    # Favors bins with smallest leftover space.\n    best_fit_score = 1.0 / (residual_capacity + 1e-9)\n\n    # Component 2: Balance / Moderate Fit\n    # Favor bins where the residual capacity is not excessively large compared to the item.\n    # This acts as a penalty for leaving very large gaps, especially if other bins could be filled more.\n    # Score is higher when residual_capacity is small relative to item size.\n    # `balance_score = (item + 1e-9) / (residual_capacity + item + 1e-9)`\n    # This score is close to 1 for tight fits, and close to 0 for very large residuals.\n    # Let's normalize it to make it more robust.\n    # A simpler approach: `1 - (residual_capacity / (item + epsilon))`\n    # This score is 1 when residual is 0, and goes to -inf as residual increases.\n    # Let's try `exp(-k * residual_capacity / item)` for some k.\n    # Or, a capped version: `max(0, 1 - residual_capacity / (item * 2))`\n    # Let's use a simpler form: favor bins whose remaining capacity `fittable_bins_remain_cap` is not overwhelmingly large.\n    # Use `1 / (fittable_bins_remain_cap + epsilon)` as a proxy for \"not too empty\".\n\n    # Let's use a weighted sum of Best Fit and a \"Gap Management\" score.\n    # Best Fit: `1 / residual_capacity`\n    # Gap Management: Favor residual capacities that are not too small and not too large.\n    # Let's normalize residual capacity by the maximum residual capacity among fittable bins.\n    # `norm_residual = residual_capacity / (np.max(residual_capacity) + 1e-9)`\n    # We want to avoid `norm_residual` being too close to 0 (tight fit, covered by BF)\n    # and too close to 1 (large gap).\n    # A score that peaks in the middle, e.g., `1 - (2 * norm_residual - 1)^2` or similar.\n\n    # Final proposal for v2:\n    # Combine Best Fit with a term that prefers bins that are neither too empty nor too full *after* fitting.\n    # This means the `residual_capacity` should be in a moderate range.\n    # Let's aim for residual capacity to be roughly proportional to the item size, but not excessively so.\n\n    # Term 1: Best Fit (inverse of residual capacity)\n    best_fit_term = 1.0 / (residual_capacity + 1e-9)\n\n    # Term 2: Moderate Residual Capacity Preference\n    # We want to favor `residual_capacity` that are not extremely small (handled by BF)\n    # and not extremely large.\n    # Let's try to score bins based on how close their residual capacity is to the *average* residual capacity.\n    # `avg_residual = np.mean(residual_capacity)`\n    # `balance_score = 1.0 / (abs(residual_capacity - avg_residual) + 1e-9)`\n    # This could be unstable if `avg_residual` is close to `residual_capacity`.\n\n    # Alternative Balance Term: Favor bins that use a good fraction of their available capacity.\n    # Score = `item / fittable_bins_remain_cap` (already considered).\n\n    # Let's try a simpler weighted sum, but with more carefully chosen terms.\n    # Term 1: Best Fit (tightness) - `1 / (residual_capacity + epsilon)`\n    # Term 2: Fill Preference (favoring not-too-empty bins) - `fittable_bins_remain_cap` itself.\n    # This favors bins that have more space, which is \"Worst Fit\" like.\n\n    # Let's aim for a score that rewards tightness, but with diminishing returns for extreme tightness.\n    # And also rewards leaving some space, but with diminishing returns for extreme openness.\n\n    # Final proposed v2 using multiplicative combination for stronger interactions:\n    # Score = (BestFitScore) * (BalanceScore)\n    # BestFitScore = 1 / (residual_capacity + epsilon)\n    # BalanceScore = how \"balanced\" the bin is. Let's favor bins that have\n    # a moderate amount of remaining capacity after fitting.\n    # If `fittable_bins_remain_cap` is the current remaining capacity, and `r` is residual.\n    # We want `r` to be not too small and not too large.\n    # Let's define a \"good\" residual range. Suppose it's `[min_res, max_res]`.\n    # Score is high when `r` is in this range.\n    # This is hard to define without context.\n\n    # Let's use Best Fit and Worst Fit combined, where the combination is non-linear.\n    # Consider a score that prioritizes bins with small residuals, but gives a bonus\n    # if the bin was already quite full.\n\n    # Try: Score = (BestFit) + Alpha * (FillRatio)\n    # FillRatio = `item / fittable_bins_remain_cap`\n\n    # Let's try a score that is a trade-off between Best Fit and Worst Fit.\n    # Score = `(1 / residual_capacity) * (1 - residual_capacity / max_possible_gap)`\n    # `max_possible_gap` can be `max(fittable_bins_remain_cap)`.\n    # `score = (1 / residual_capacity) * (1 - residual_capacity / max_fittable_rem)`\n    # This score peaks when `residual_capacity` is around `max_fittable_rem / 3`.\n\n    # Let's define our v2 heuristic as:\n    # Combine Best Fit with a \"fill percentage\" score.\n    # Best Fit: `1 / (residual_capacity + epsilon)`\n    # Fill Percentage: The percentage of the *current available capacity* that the item uses.\n    # This is `item / fittable_bins_remain_cap`.\n    # Higher fill percentage is good, means the item is utilizing a good chunk of what's available.\n\n    # Weighted Sum:\n    # `score = w1 * (1 / residual_capacity) + w2 * (item / fittable_bins_remain_cap)`\n    # Weights `w1` and `w2` need tuning.\n\n    # Normalization:\n    # Max residual capacity among fittable bins.\n    max_residual = np.max(residual_capacity)\n    # Max value for `item / fittable_bins_remain_cap` is 1.\n\n    # Let's try a multiplicative approach again, with normalized terms.\n    # Normalized Best Fit: `(1 / residual_capacity) / max(1 / residual_capacity)`\n    # Normalized Fill Percentage: `(item / fittable_bins_remain_cap) / max(item / fittable_bins_remain_cap)`\n    # This can be unstable if `max` is zero or very small.\n\n    # Let's use an additive approach with robust terms.\n    # Term 1: Best Fit - `1.0 / (residual_capacity + 1e-9)`\n    # Term 2: \"Bin Usage Balance\" - Favor bins that are not nearly empty.\n    # The \"fuller\" a bin is, the less remaining capacity it has.\n    # So, we want to favor bins with *smaller* `fittable_bins_remain_cap`.\n    # Score for this: `1.0 / (fittable_bins_remain_cap + 1e-9)`\n    # This term encourages using bins that are already quite full.\n\n    # Combine: `score = w1 * (1.0 / residual_capacity) + w2 * (1.0 / fittable_bins_remain_cap)`\n    # Weights `w1` and `w2` determine the trade-off.\n    # `w1` for tightness, `w2` for pre-existing fullness.\n    # If `w1` is high, it's like Best Fit. If `w2` is high, it prefers already full bins.\n\n    # Let's tune weights:\n    # `w1 = 1.0` (primary focus on tightness)\n    # `w2 = 0.5` (secondary focus on pre-existing fullness)\n\n    # Calculate scores for fittable bins\n    best_fit_score_fittable = 1.0 / (residual_capacity + 1e-9)\n    bin_fullness_score_fittable = 1.0 / (fittable_bins_remain_cap + 1e-9) # Favor bins with less remaining capacity\n\n    # Combine scores\n    combined_scores = (best_fit_score_fittable * 1.0) + (bin_fullness_score_fittable * 0.5)\n\n    # Normalize the combined scores to a [0, 1] range.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 38.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response1.txt_stdout.txt",
    "code_path": "problem_iter15_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Inverse of remaining capacity after fit.\n    # Higher score for bins leaving less space. Add epsilon for stability.\n    best_fit_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Fullness Bonus: Proportional to how full the bin is *before* fitting the item.\n    # This encourages using bins that are already substantially filled.\n    # We use the inverse of the remaining capacity, normalized by a conceptual maximum initial capacity (e.g., 1.0 for normalized bin sizes).\n    # If bin sizes are not normalized, using a large constant or the max initial capacity would be better.\n    # For simplicity here, we normalize by the maximum capacity *among fittable bins before fitting*.\n    max_cap_before_fit = np.max(bins_remain_cap[fittable_bins_mask] + item) # approximate initial capacity of the most full fittable bin\n    fullness_scores = (max_cap_before_fit - fittable_bins_remain_cap) / (max_cap_before_fit + 1e-6)\n\n\n    # Adaptive Gap Penalty: Penalize leaving large gaps, but with diminishing returns for smaller gaps.\n    # Logarithm of the *remaining* capacity after fitting the item.\n    # We use log1p to handle cases where remaining capacity is 0.\n    # Lower values are better (smaller gaps), so we'll invert this for the final score.\n    gap_penalty = np.log1p(fittable_bins_remain_cap - item)\n\n\n    # Combine scores using a multiplicative approach with adaptive weighting.\n    # This aims to balance the objectives more dynamically.\n    # Best Fit is the primary driver.\n    # Fullness Bonus is multiplicative, boosting scores of fuller bins.\n    # Gap Penalty is used to reduce scores if the fit leaves a large gap.\n    # We invert the gap penalty and scale it to be additive, acting as a bonus for small gaps.\n\n    # Initial combined score heavily favoring best fit\n    combined_scores = best_fit_scores * (1 + fullness_scores * 0.5) # Multiplicative bonus for fullness\n\n    # Add a bonus for small gaps, inversely related to the gap penalty\n    # Max value of gap_penalty is log1p(max_remaining_cap_fittable - item)\n    # We want to reward smaller gap_penalty values.\n    # A simple way is to subtract a scaled version of the gap_penalty.\n    # The scaling factor needs careful tuning based on typical item sizes and bin capacities.\n    # Let's use a factor derived from the range of gap_penalties.\n    min_gap_penalty = np.min(gap_penalty)\n    max_gap_penalty = np.max(gap_penalty)\n    gap_range = max_gap_penalty - min_gap_penalty\n\n    if gap_range > 1e-9:\n        # Normalize gap_penalty to [0, 1] and subtract from 1 to get a bonus for small gaps.\n        # Small gap_penalty -> large bonus. Large gap_penalty -> small bonus.\n        small_gap_bonus = 1.0 - (gap_penalty - min_gap_penalty) / gap_range\n        combined_scores += small_gap_bonus * 0.3 # Additive bonus for small gaps\n    else:\n        # If all gaps are similar, add a small uniform bonus\n        combined_scores += 0.3 * 0.5\n\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / max_score, 0, 1)\n    else:\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response2.txt_stdout.txt",
    "code_path": "problem_iter15_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Score 1: Best Fit (Inverse of remaining capacity after placing the item)\n    # This encourages placing the item in a bin where it leaves the least amount of empty space.\n    # Adding epsilon to prevent division by zero.\n    best_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Score 2: Fullness Factor (Inverse of remaining capacity before placing the item)\n    # This encourages using bins that are already relatively full, promoting tighter packing.\n    # Adding epsilon to prevent division by zero.\n    fullness_factor = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Score 3: Proportional Remaining Space (Penalizes bins that leave a large percentage of space unused)\n    # This aims to prevent placing a small item into a very large bin if a tighter fit exists.\n    # Adding epsilon to the denominator to avoid division by zero.\n    proportional_remaining = (fittable_bins_remain_cap - item) / (bins_remain_cap.max() + 1e-9)\n\n    # Combine scores multiplicatively for a more nuanced interaction.\n    # Higher values indicate a better fit according to all criteria.\n    # We use (1 - proportional_remaining) so that smaller proportional remaining space leads to a higher score.\n    combined_scores = best_fit_score * fullness_factor * (1.0 - proportional_remaining)\n\n    # Normalize scores to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        normalized_scores = combined_scores / max_score\n        priorities[fittable_bins_mask] = normalized_scores\n    else:\n        # If all combined scores are near zero, assign a uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response3.txt_stdout.txt",
    "code_path": "problem_iter15_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Aims to improve upon v1 by using a multiplicative scoring approach that\n    inherently balances competing objectives and is less sensitive to arbitrary\n    weight adjustments. It prioritizes bins that offer a tight fit AND have\n    substantial remaining capacity (to avoid prematurely fragmenting larger spaces),\n    while also penalizing bins that are already nearly full to encourage\n    utilization of less occupied bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Score 1: Tight Fit Preference (similar to Best Fit).\n    # Higher score for smaller leftover space. Add epsilon for numerical stability.\n    tight_fit_score = 1.0 / (fittable_bins_remain_cap - item + 1e-9)\n\n    # Score 2: Space Utilization Preference.\n    # Prioritize bins that are already more utilized (i.e., have less remaining capacity).\n    # This encourages filling up existing bins before opening new ones.\n    # Normalize by bin capacity (assuming capacity is uniform, which it is in BPP)\n    # Or more generally, by the maximum capacity if it varied. Here, remaining capacity is sufficient.\n    # Higher score for smaller remaining capacity among fittable bins.\n    space_utilization_score = 1.0 / (fittable_bins_remain_cap + 1e-9)\n\n    # Score 3: Robustness/Avoidance of Over-fragmentation.\n    # Penalize bins that, after fitting the item, leave a very large amount of capacity.\n    # This aims to avoid packing an item into a very large bin if a medium-sized bin is available.\n    # We want to prefer bins that leave a \"reasonable\" amount of space, not too little and not too much.\n    # Using a Gaussian-like penalty centered around a \"good\" leftover space, or more simply,\n    # penalizing very large leftovers. A simple inverse square of remaining capacity after fit.\n    # Or even simpler, penalize bins that leave capacity significantly larger than the item size.\n    # Let's use a penalty proportional to the log of the remaining capacity AFTER the fit.\n    # Smaller log means better.\n    leftover_space_penalty = np.log1p(fittable_bins_remain_cap - item) # Smaller is better\n\n    # Combine scores multiplicatively. This creates a synergy where bins must perform well\n    # on multiple criteria. A bin with a good tight fit but terrible space utilization (e.g., very empty)\n    # will be penalized. Similarly, a bin with high utilization but a very poor fit will be penalized.\n\n    # We want to:\n    # 1. Maximize tight fit (high tight_fit_score)\n    # 2. Maximize space utilization (high space_utilization_score)\n    # 3. Minimize leftover space penalty (low leftover_space_penalty)\n\n    # Multiplicative combination: Score = (TightFit) * (SpaceUtil) / (1 + LeftoverPenalty)\n    # Adding 1 to penalty to avoid division by zero and to ensure it acts as a penalty.\n    # A lower leftover_space_penalty should result in a higher combined score.\n    # So, divide by (1 + penalty) or multiply by 1/(1+penalty)\n    combined_scores = tight_fit_score * space_utilization_score * (1.0 / (1.0 + leftover_space_penalty))\n\n    # Normalize priorities to a [0, 1] range.\n    max_score = np.max(combined_scores)\n    if max_score > 1e-9:\n        priorities[fittable_bins_mask] = combined_scores / max_score\n    else:\n        # If all scores are effectively zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response4.txt_stdout.txt",
    "code_path": "problem_iter15_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a penalty for bins that are too large,\n    using a multiplicative scoring to encourage tighter fits and penalize waste.\n    Includes an adaptive term that favors bins with remaining capacity closer to item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fittable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(fittable_bins_mask):\n        return priorities\n\n    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]\n\n    # Best Fit Score: Higher for bins that leave less remaining capacity after fitting.\n    # Add a small epsilon to prevent division by zero.\n    best_fit_component = 1.0 / (fittable_bins_remain_cap - item + 1e-6)\n\n    # Penalty for \"too large\" bins: Bins with significantly more remaining capacity than needed\n    # are less desirable as they might be better utilized by larger items later.\n    # We use an inverse relationship with the excess capacity.\n    excess_capacity = fittable_bins_remain_cap - item\n    # Penalty is higher for larger excess capacity. Cap to avoid extremely small values.\n    large_bin_penalty_component = 1.0 / (excess_capacity + 1.0)\n\n    # Adaptive \"Tightness\" Score: Aims to pick bins where the remaining capacity\n    # is *just enough* or slightly more than the item.\n    # This is similar to Best Fit but can be weighted differently.\n    # We want to maximize the remaining capacity if it's very close to the item size.\n    # We use a Gaussian-like function centered slightly above the item size.\n    # The goal is to favor bins where (remaining_cap - item) is small.\n    # For a given item, we want to find bins where remaining_cap is close to item.\n    # Let's use a score that is high when (remaining_cap - item) is small.\n    # A negative exponential function on the squared difference can work.\n    # Shifted to be centered around 0 remaining capacity after fit.\n    # Adding 1 to the exponent to avoid exp(0) = 1 and ensure lower values for larger gaps.\n    tightness_component = np.exp(-0.1 * (excess_capacity**2))\n\n\n    # Combine components using a multiplicative approach.\n    # This encourages all components to be good simultaneously.\n    # We use the inverse of the large bin penalty as a multiplier: higher penalty (smaller value)\n    # reduces the overall score.\n    # The tightness component directly contributes positively.\n    combined_scores = best_fit_component * (1.0 - large_bin_penalty_component) * tightness_component\n\n    # Normalize priorities to a [0, 1] range.\n    if np.max(combined_scores) > 1e-9:\n        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)\n    else:\n        # If all scores are near zero, assign a small uniform priority to fittable bins.\n        priorities[fittable_bins_mask] = 0.1\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.816513761467886,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]