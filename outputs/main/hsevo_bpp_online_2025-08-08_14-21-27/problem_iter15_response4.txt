```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit with a penalty for bins that are too large,
    using a multiplicative scoring to encourage tighter fits and penalize waste.
    Includes an adaptive term that favors bins with remaining capacity closer to item size.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    fittable_bins_mask = bins_remain_cap >= item

    if not np.any(fittable_bins_mask):
        return priorities

    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]

    # Best Fit Score: Higher for bins that leave less remaining capacity after fitting.
    # Add a small epsilon to prevent division by zero.
    best_fit_component = 1.0 / (fittable_bins_remain_cap - item + 1e-6)

    # Penalty for "too large" bins: Bins with significantly more remaining capacity than needed
    # are less desirable as they might be better utilized by larger items later.
    # We use an inverse relationship with the excess capacity.
    excess_capacity = fittable_bins_remain_cap - item
    # Penalty is higher for larger excess capacity. Cap to avoid extremely small values.
    large_bin_penalty_component = 1.0 / (excess_capacity + 1.0)

    # Adaptive "Tightness" Score: Aims to pick bins where the remaining capacity
    # is *just enough* or slightly more than the item.
    # This is similar to Best Fit but can be weighted differently.
    # We want to maximize the remaining capacity if it's very close to the item size.
    # We use a Gaussian-like function centered slightly above the item size.
    # The goal is to favor bins where (remaining_cap - item) is small.
    # For a given item, we want to find bins where remaining_cap is close to item.
    # Let's use a score that is high when (remaining_cap - item) is small.
    # A negative exponential function on the squared difference can work.
    # Shifted to be centered around 0 remaining capacity after fit.
    # Adding 1 to the exponent to avoid exp(0) = 1 and ensure lower values for larger gaps.
    tightness_component = np.exp(-0.1 * (excess_capacity**2))


    # Combine components using a multiplicative approach.
    # This encourages all components to be good simultaneously.
    # We use the inverse of the large bin penalty as a multiplier: higher penalty (smaller value)
    # reduces the overall score.
    # The tightness component directly contributes positively.
    combined_scores = best_fit_component * (1.0 - large_bin_penalty_component) * tightness_component

    # Normalize priorities to a [0, 1] range.
    if np.max(combined_scores) > 1e-9:
        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)
    else:
        # If all scores are near zero, assign a small uniform priority to fittable bins.
        priorities[fittable_bins_mask] = 0.1

    return priorities
```
