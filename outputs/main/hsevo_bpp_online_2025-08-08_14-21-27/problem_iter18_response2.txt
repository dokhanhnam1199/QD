```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Best Fit, Worst Fit (for potentially larger items later), and
    a penalty for bins that would become too empty after packing.
    Weights are adaptive based on item size relative to bin capacity.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    fittable_bins_mask = bins_remain_cap >= item

    if not np.any(fittable_bins_mask):
        return priorities

    fittable_bins_remain_cap = bins_remain_cap[fittable_bins_mask]

    # Component 1: Best Fit (BF) - Prioritize bins that minimize remaining capacity
    # Add epsilon to prevent division by zero. Smaller remaining capacity after fit is better.
    bf_scores = 1.0 / (fittable_bins_remain_cap - item + 1e-6)

    # Component 2: Worst Fit (WF) - Prioritize bins that leave more remaining capacity (less tight fit)
    # This can be beneficial for potentially packing larger items later if a loose fit is available.
    # Larger remaining capacity after fit is better.
    wf_scores = fittable_bins_remain_cap - item

    # Component 3: Emptying Penalty (EP) - Penalize bins that become very empty after packing.
    # A bin that becomes too empty might be considered "wasted" space.
    # We want to penalize (fittable_bins_remain_cap - item) when it's large.
    # Using log1p to dampen the effect of very large remaining capacities.
    ep_scores = -np.log1p(fittable_bins_remain_cap - item) # Negative because we want to penalize large values

    # Adaptive Weighting based on item size relative to the *average* remaining capacity of fittable bins
    avg_fittable_remain_cap = np.mean(fittable_bins_remain_cap) if fittable_bins_remain_cap.size > 0 else 1.0
    # If item is relatively large compared to average remaining capacity, BF is more important.
    # If item is relatively small, WF might be more useful.
    bf_weight = np.clip(item / (avg_fittable_remain_cap + 1e-6), 0.5, 2.0)
    wf_weight = 1.0 - bf_weight / 2.0 # Reduce WF weight if BF is highly favored
    wf_weight = np.clip(wf_weight, 0.1, 0.8)
    ep_weight = 0.3 # A moderate penalty for creating very empty bins

    # Combine scores with adaptive weights
    # Normalize components before combining to prevent one component from dominating due to scale.
    # Normalize BF scores: Higher is better.
    norm_bf = (bf_scores - np.min(bf_scores)) / (np.max(bf_scores) - np.min(bf_scores) + 1e-6)
    # Normalize WF scores: Higher is better.
    norm_wf = (wf_scores - np.min(wf_scores)) / (np.max(wf_scores) - np.min(wf_scores) + 1e-6)
    # Normalize EP scores: Higher (less negative) is better, meaning less penalty.
    norm_ep = (ep_scores - np.min(ep_scores)) / (np.max(ep_scores) - np.min(ep_scores) + 1e-6)

    # The combined score aims to balance BF (tight fit), WF (loose fit), and EP (avoiding too empty bins)
    combined_scores = (bf_weight * norm_bf) + (wf_weight * norm_wf) + (ep_weight * norm_ep)

    # Assign priorities to the fittable bins
    if np.max(combined_scores) > 1e-9:
        priorities[fittable_bins_mask] = np.clip(combined_scores / np.max(combined_scores), 0, 1)
    else:
        # If all scores are effectively zero, assign a small uniform priority.
        priorities[fittable_bins_mask] = 0.1

    return priorities
```
