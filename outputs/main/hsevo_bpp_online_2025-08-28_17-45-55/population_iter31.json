[
  {
    "stdout_filepath": "problem_iter29_response0.txt_stdout.txt",
    "code_path": "problem_iter29_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with sigmoid exploration based on remaining capacity.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    priorities[valid_bins] = 1 / (1 + np.exp(-waste * 2.0))\n    \n    avg_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    \n    exploration_factor = 0.1 * (std_waste / (avg_waste + 1e-6))\n    \n    priorities[valid_bins] += exploration_factor\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 27.173913043478258,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 143.95954188301644,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response1.txt_stdout.txt",
    "code_path": "problem_iter29_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with dynamic exploration based on waste statistics and sigmoid scaling.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    avg_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    if std_waste == 0:\n        std_waste = 1e-6\n    scaled_waste = (waste - avg_waste) / std_waste\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-scaled_waste * 5.0))\n    priorities[valid_bins] = sigmoid_scaled_waste\n    exploration_boost = np.random.rand(n_bins) * 0.1 * (1 + avg_waste/item)\n    priorities[valid_bins] += exploration_boost[valid_bins]\n    best_bin_index = np.argmin(waste)\n    priorities[np.where(valid_bins)[0][best_bin_index]] += 1.0\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.946150777822112,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 227.8930302777963,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response2.txt_stdout.txt",
    "code_path": "problem_iter29_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with sigmoid scaling and dynamic exploration based on waste std.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    sigmoid_scale = 1.0\n    std_waste = np.std(waste)\n    exploration_bonus_factor = 0.1 * (std_waste / (np.mean(bins_remain_cap) + 1e-6))\n    priorities[valid_bins] = 1 / (1 + np.exp(-waste * sigmoid_scale))\n    priorities[np.where(valid_bins)[0][best_bin_index]] += exploration_bonus_factor\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 76.90466693258877,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 143.95954188301644,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response3.txt_stdout.txt",
    "code_path": "problem_iter29_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with sigmoid scaling and dynamic exploration based on waste standard deviation.\"\"\"\n    possible_bins = bins_remain_cap >= item\n    if np.sum(possible_bins) == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[possible_bins] - item\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[possible_bins] = 1 / (1 + np.exp(-waste * 2.0))\n\n    std_waste = np.std(waste)\n    exploration_factor = np.maximum(0.1, std_waste)\n    \n    best_bin_index = np.argmin(waste)\n    priorities[possible_bins][best_bin_index] += exploration_factor\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 27.173913043478258,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 99.40434618240934,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response4.txt_stdout.txt",
    "code_path": "problem_iter29_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with sigmoid scaling and dynamic exploration based on waste std.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    std_waste = np.std(waste)\n    sigmoid_scale = 0.5\n    exploration_factor = 0.1 * np.exp(-std_waste / (np.mean(waste) + 1e-6))\n    priorities[valid_bins] = 1 / (1 + np.exp(-waste * sigmoid_scale)) + exploration_factor\n    priorities[np.where(valid_bins)[0][best_bin_index]] += 0.1\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 139.73873155165538,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 171.1759500778849,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response5.txt_stdout.txt",
    "code_path": "problem_iter29_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a diversity component and dynamic exploration.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_fit_component = 1 / (1 + np.exp(-waste * 5))\n    bin_usage = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    diversity_component = bin_usage\n\n    alpha = 0.7\n    beta = 0.3\n    priorities[valid_bins] = alpha * best_fit_component + beta * diversity_component\n\n    waste_std = np.std(waste)\n    exploration_boost = 0.1 * np.exp(-waste_std * 2)\n    priorities[valid_bins] += exploration_boost\n\n    best_bin_index = np.argmin(waste)\n    priorities[valid_bins[best_bin_index]] += 0.5\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 5.574391703230963,
    "SLOC": 19.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 244.19821638001633,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response6.txt_stdout.txt",
    "code_path": "problem_iter29_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with dynamic exploration based on waste statistics.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    avg_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    if std_waste == 0:\n        std_waste = 1e-6\n    scaled_waste = (waste - avg_waste) / std_waste\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-scaled_waste * 5.0))\n    priorities[valid_bins] = sigmoid_scaled_waste\n    exploration_boost = np.random.rand(n_bins) * 0.1 * (1 + avg_waste/item)\n    priorities[valid_bins] += exploration_boost[valid_bins]\n    best_bin_index = np.argmin(waste)\n    priorities[np.where(valid_bins)[0][best_bin_index]] += 1.0\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 5.055843637814125,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 227.8930302777963,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response7.txt_stdout.txt",
    "code_path": "problem_iter29_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a diversity component based on bin usage, enhanced by dynamic exploration.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    best_fit_component = 1 / (1 + np.exp(-waste * 5))\n    bin_usage = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    diversity_component = bin_usage\n    alpha = 0.7\n    beta = 0.3\n    priorities[valid_bins] = alpha * best_fit_component + beta * diversity_component\n    std_waste = np.std(waste)\n    exploration_bonus = np.exp(-std_waste) * 0.2\n    priorities[valid_bins] += exploration_bonus\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 5.574391703230963,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 206.0894050155578,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response8.txt_stdout.txt",
    "code_path": "problem_iter29_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with dynamic exploration based on waste statistics using sigmoid scaling.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    avg_waste = np.mean(waste)\n    std_waste = np.std(waste)\n\n    if std_waste == 0:\n        std_waste = 1e-6\n\n    scaled_waste = (waste - avg_waste) / std_waste\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-scaled_waste * 5.0))\n    priorities[valid_bins] = sigmoid_scaled_waste\n\n    exploration_boost = np.random.rand(n_bins) * 0.1 * (1 + avg_waste/item)\n    priorities[valid_bins] += exploration_boost[valid_bins]\n\n    best_bin_index = np.argmin(waste)\n    priorities[np.where(valid_bins)[0][best_bin_index]] += 1.0\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.926206621459921,
    "SLOC": 19.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 227.8930302777963,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response9.txt_stdout.txt",
    "code_path": "problem_iter29_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with sigmoid scaling and dynamic exploration based on waste std.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    priorities[valid_bins] = 1 / (1 + np.exp(-waste * 2.0))\n    if len(waste) > 0:\n        std_waste = np.std(waste)\n        exploration_bonus = 0.1 * np.exp(-std_waste / np.mean(waste) if np.mean(waste) > 0 else 0)\n        best_bin_index = np.argmin(waste)\n        priorities[valid_bins[best_bin_index]] += exploration_bonus\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 27.134024730753904,
    "SLOC": 14.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 173.06477719407374,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter30_response0.txt_stdout.txt",
    "code_path": "problem_iter30_code0.py",
    "code": "import numpy as np\n\nsigmoid_scale = 1.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    normalized_waste = (bins_remain_cap[valid_bins] - item) / bins_remain_cap[valid_bins]\n    std_waste = np.std(normalized_waste)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if std_waste > 0:\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        best_bin_index = np.argmin(normalized_waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    else:\n        priorities[valid_bins] = 1.0\n        best_bin_index = np.argmin(bins_remain_cap[valid_bins])\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n        \n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 143.95954188301644,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter30_response1.txt_stdout.txt",
    "code_path": "problem_iter30_code1.py",
    "code": "import numpy as np\n\nsigmoid_scale = 5.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    normalized_waste = (bins_remain_cap[valid_bins] - item) / bins_remain_cap[valid_bins]\n    \n    waste_std = np.std(normalized_waste)\n    \n    exploration_factor = np.exp(-waste_std)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n    \n    priorities[valid_bins] = sigmoid_scaled_waste * (1 + exploration_factor)\n    \n    best_bin_index = np.argmin(normalized_waste)\n    \n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.357798165137619,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 153.24725426256592,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter30_response2.txt_stdout.txt",
    "code_path": "problem_iter30_code2.py",
    "code": "import numpy as np\n\nsigmoid_scale = 1.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    normalized_waste = (bins_remain_cap[valid_bins] - item) / np.max(bins_remain_cap[valid_bins] - item) if np.max(bins_remain_cap[valid_bins] - item) > 0 else np.zeros_like(bins_remain_cap[valid_bins] - item)\n    \n    sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = sigmoid_scaled_waste\n    \n    best_bin_index = np.argmin(bins_remain_cap[valid_bins] - item)\n    priorities[valid_bins[best_bin_index]] += best_bin_boost\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 19, in priority_v2\n    \nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n3\n192.29419688230416\n"
  },
  {
    "stdout_filepath": "problem_iter30_response3.txt_stdout.txt",
    "code_path": "problem_iter30_code3.py",
    "code": "import numpy as np\n\nsigmoid_scale = 5.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    normalized_waste = (bins_remain_cap[valid_bins] - item) / bins_remain_cap[valid_bins]\n    waste_std = np.std(normalized_waste)\n    \n    sigmoid_input = normalized_waste * sigmoid_scale + waste_std\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-sigmoid_input))\n\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = sigmoid_scaled_waste\n\n    best_bin_index = np.argmin(bins_remain_cap[valid_bins] - item)\n    priorities[valid_bins][best_bin_index] += best_bin_boost\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 142.13383752235586,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter30_response4.txt_stdout.txt",
    "code_path": "problem_iter30_code4.py",
    "code": "import numpy as np\n\nsigmoid_scale = 1.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit (waste minimization) with sigmoid scaling and dynamic exploration.\n    \"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    normalized_waste = (bins_remain_cap[valid_bins] - item) / bins_remain_cap[valid_bins]\n    \n    std_waste = np.std(normalized_waste)\n    \n    exploration_factor = np.exp(-std_waste)\n    \n    sigmoid_input = normalized_waste * sigmoid_scale\n    \n    sigmoid_scaled_waste = 1 / (1 + np.exp(-sigmoid_input))\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = sigmoid_scaled_waste * (1 + exploration_factor)\n    \n    best_bin_index = np.argmin(normalized_waste)\n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.357798165137619,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 153.24725426256592,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter31_response0.txt_stdout.txt",
    "code_path": "problem_iter31_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigmoid_scale: float = 4.393238334028896, best_bin_boost: float = 0.9058853350418888) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "SLOC": 4.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 11.60964047443681,
    "exec_success": true
  }
]