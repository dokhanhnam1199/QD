{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\nsigmoid_scale = 1.0\nbest_bin_boost = 1.0\n\n    \"\"\"Combines best-fit with modulated sigmoid scaling based on waste standard deviation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        best_bin_index = np.argmin(waste)\n        waste_std = np.std(waste)\n        sigmoid_mod = 1.0 + waste_std\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale * sigmoid_mod))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with sigmoid scaling and dynamic exploration based on waste std.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    priorities[valid_bins] = 1 / (1 + np.exp(-waste * 2.0))\n    if len(waste) > 0:\n        std_waste = np.std(waste)\n        exploration_bonus = 0.1 * np.maximum(0.1, std_waste)\n        best_bin_index = np.argmin(waste)\n        priorities[valid_bins[best_bin_index]] += exploration_bonus\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), both are nearly identical, employing best-fit with sigmoid scaling. However, the 1st has pre-tuned `sigmoid_scale` and `best_bin_boost` while the 2nd uses default values, suggesting parameter tuning is critical. Comparing (1st) vs (3rd), the 3rd normalizes waste before sigmoid scaling, which can improve stability across different bin sizes, but uses a fixed boost. (3rd) vs (4th): these are identical, highlighting redundancy. Comparing (1st) vs (6th), 6th introduces `waste_std` modulation, potentially adding adaptability, and a larger `best_bin_boost`, but introduces potential instability. (6th) vs (7th): 7th uses normalized waste and average waste. (7th) vs (8th): again identical. (7th) vs (9th): 9th uses squared waste standard deviation in modulation, potentially amplifying the effect of variance. (9th) vs (10th): 10th uses a simpler normalization and a small boost. Comparing (11th) to (12th), both use similar modulation, but (12th) adds `waste_std` directly to the sigmoid input, potentially causing overflow. (13th) and (14th) have lower exploration factor. (14th) and (15th) through (20th) introduce more variability in the exploration bonus, aiming to adjust exploration dynamically, but often with smaller, less impactful bonuses. Overall, the best heuristics (1st-6th) demonstrate the value of combining best-fit with well-tuned sigmoid scaling and exploration based on waste statistics. The later heuristics suffer from either redundant code, smaller exploration values, or instability with sigmoid scaling.\n- \nOkay, here's a redefined approach to self-reflection for heuristic design, aimed at maximizing effectiveness, based on dissecting the provided text. This is geared towards designing *better* heuristics, not just bin-packing ones.\n\n* **Keywords:** Meta-optimization, Dynamic Modulation, Stability, Interpretability.\n* **Advice:** Focus on *modulating* existing, stable heuristics (like best-fit) via waste statistics (std_dev) *directly within* priority functions (sigmoid). Prioritize interpretable components and tunable parameters controlling exploration/exploitation.\n* **Avoid:** Directly optimizing for the objective function during heuristic *design* (waste minimization is the *result*, not the guiding principle). Shun redundant code, complex statefulness, and ad-hoc boosts/penalties without clear rationale.\n* **Explanation:** The core issue is the previous self-reflection got stuck in local optima by focusing too much on the immediate objective. True improvement comes from systematically *controlling* exploration around a strong base heuristic, guided by data about the search landscape\u2014not by trying to directly \u201csolve\u201d the problem within the heuristic itself.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}