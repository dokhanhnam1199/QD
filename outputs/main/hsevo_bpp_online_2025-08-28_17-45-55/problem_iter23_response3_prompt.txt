{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit (inverse waste) with a mild worst-fit penalty, handling edge cases.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[valid_bins] - item\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1.0 / (waste + 1e-9)\n    worst_bin_index = np.argmax(waste)\n    priorities[np.where(valid_bins)[0][worst_bin_index]] += 0.1\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive prioritization combining best-fit, worst-fit, and a diversity component.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    best_fit_score = 1.0 / (1.0 + waste)\n    worst_fit_score = waste\n    diversity_score = 1.0 / (np.sum(valid_bins) + 1e-6)\n\n    weight_best_fit = 0.6\n    weight_worst_fit = 0.2\n    weight_diversity = 0.2\n\n    priorities[valid_bins] = (weight_best_fit * best_fit_score +\n                              weight_worst_fit * worst_fit_score +\n                              weight_diversity * diversity_score)\n\n    priorities[np.where(valid_bins)[0][best_bin_index]] += 0.1\n    priorities[np.where(valid_bins)[0][worst_bin_index]] -= 0.05\n\n    return priorities\n\n### Analyze & experience\n- Comparing heuristics 1st vs 2nd, both are sophisticated but the 1st incorporates exploration and diversity more elegantly with adjustable weights, while the 2nd relies on fixed boosts/penalties and a sigmoid scaling that might not generalize well. The 1st\u2019s `exploration_rate` and weighted combination of best-fit and diversity offer a tunable balance.\n\nComparing 3rd vs 4th, they are identical, indicating redundancy.\n\nComparing 1st vs 5th, both use exploration and weighted best-fit/diversity, but the 1st has slightly cleaner implementation. The 5th feels like a nearly identical copy.\n\nComparing 6th vs 7th & 8th, the 6th and 7th/8th use inverse waste but 6th uses a very small constant to avoid division by zero, which is good practice. However, the magnitude of the worst-fit penalty is small (-0.1), and the heuristics are almost the same. \n\nComparing 9th vs 10th, these are very similar, only differing in how they handle the `~possible_bins` case. 10th explicitly sets them to zero which is preferred.\n\nComparing 12th vs 13th & 14th, the 12th and 14th are almost identical. The 13th has a larger best-fit boost.\n\nComparing 15th vs 16th & 17th, these are similar and the 16th & 17th add exploration. The 16th and 17th are identical.\n\nComparing 18th, 19th, & 20th, they all utilize weighted components of best-fit, worst-fit, and diversity. They are effectively the same.\n\nOverall: The best heuristics (1st, 2nd, 16th & 17th) combine multiple factors (best-fit, diversity, exploration) and allow for tunable parameters.  The core idea of combining best-fit with a penalty for the worst-fit bin, and explicitly handling edge cases (no valid bins) is present in many, but the weighting and scaling are crucial.  Explicitly handling cases where no bins are valid is important. Redundancy is present across many of the heuristics. Simpler approaches (like 6th, 7th, 8th) can work reasonably well but lack flexibility.\n- \nOkay, here's a refined self-reflection guide focused on heuristic *design*, drawing from the provided texts, aiming for that $999K reward!\n\n* **Keywords:** Adaptability, Dynamic Parameters, Exploration/Exploitation Balance, Robustness.\n* **Advice:** Focus on *how* parameters interact, not just tuning individual values. Prioritize mechanisms for dynamic parameter adjustment *based on problem state* \u2013 monitor performance & adjust. Explore combinations of mild penalties *and* boosts.\n* **Avoid:** Over-reliance on problem-specific normalization (waste/sigmoid). Premature optimization for bin-packing *alone*; focus on heuristic *structure*. Constant scaling if adaptability is desired.\n* **Explanation:** The previous reflection fixated on *bin packing* performance. This revision centers on building *flexible* heuristics. Adaptability\u2014through dynamic parameters & balanced exploration\u2014is crucial for generalization and superior long-term performance across varying problem instances.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}