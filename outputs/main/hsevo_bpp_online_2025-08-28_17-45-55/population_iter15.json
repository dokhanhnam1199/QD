[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a worst-fit penalty to promote bin diversity.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    priorities[valid_bins] = 1 / (1 + np.exp(-waste))\n    \n    worst_bin_index = np.argmax(waste)\n    priorities[np.where(valid_bins)[0][worst_bin_index]] += 1.0\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 74.23092131656186,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a small worst-fit penalty to encourage diversity.\"\"\"\n    sigmoid_scale = 5.0\n    best_bin_boost = 0.5\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        best_bin_index = np.argmin(waste)\n        \n        sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        \n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n        \n        worst_bin_index = np.argmax(waste)\n        priorities[np.where(valid_bins)[0][worst_bin_index]] -= 0.2\n    \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 13.40247307538892,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 97.70233280920246,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization with a best-bin boost and a worst-fit penalty.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n\n    if std_waste > 0:\n        normalized_waste = (waste - mean_waste) / std_waste\n    else:\n        normalized_waste = np.zeros_like(waste)\n\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1 / (1 + np.exp(-normalized_waste))\n\n    best_bin_index = np.argmin(waste)\n    priorities[valid_bins[best_bin_index]] = np.max(priorities[valid_bins])\n\n    worst_bin_index = np.argmax(waste)\n    priorities[valid_bins[worst_bin_index]] -= 0.5\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 25, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n18\n3\n124.86408532184433\n"
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit and worst-fit strategies with sigmoid scaling for robust bin selection.\"\"\"\n    sigmoid_scale = 5.0\n    best_bin_boost = 1.0\n    worst_fit_penalty = 0.5\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n    priorities[valid_bins] = sigmoid_scaled_waste\n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    priorities[np.where(valid_bins)[0][worst_bin_index]] -= worst_fit_penalty\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.397686477862,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 109.80793556946902,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a controlled worst-fit exploration to avoid local optima.\"\"\"\n    sigmoid_scale = 5.0\n    best_bin_boost = 1.0\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n    priorities[valid_bins] = sigmoid_scaled_waste\n\n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    priorities[np.where(valid_bins)[0][worst_bin_index]] += 0.5\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.397686477862,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 109.80793556946902,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a worst-fit penalty to encourage diversity.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    priorities[valid_bins] = 1.0 / (1.0 + waste)\n    \n    if np.any(valid_bins):\n        priorities[valid_bins[best_bin_index]] += 0.2 \n        priorities[valid_bins[worst_bin_index]] += 0.1\n        \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 18, in priority_v2\n    priorities[~possible_bins] = 0.0\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n13\n3\n80.0\n"
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with a worst-fit penalty to promote diversity.\"\"\"\n    possible_bins = bins_remain_cap >= item\n    if np.sum(possible_bins) == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[possible_bins] - item\n    priorities = 1.0 / (waste + 1e-9)\n    \n    best_bin_index = np.argmin(waste)\n    priorities[possible_bins][best_bin_index] += 1.0\n    \n    worst_bin_index = np.argmax(waste)\n    priorities[possible_bins][worst_bin_index] += 0.5\n\n    priorities[~possible_bins] = 0.0\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 97.70233280920246,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a controlled worst-fit to promote diversity.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    sigmoid_scale = 5.0\n    best_bin_boost = 1.0\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n    priorities[valid_bins] = sigmoid_scaled_waste\n\n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    priorities[np.where(valid_bins)[0][worst_bin_index]] += 0.5\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.397686477862,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 109.80793556946902,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a worst-fit penalty to promote diversity.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = 1.0 / (waste + 1e-9)\n        \n        worst_bin_index = np.argmax(waste)\n        priorities[valid_bins][worst_bin_index] += 0.5\n        \n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 55.506595772116384,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with a worst-fit penalty to promote diversity.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1.0 / (waste + 1e-9)\n\n    best_bin_index = np.argmin(waste)\n    priorities[valid_bins][best_bin_index] += 1.0\n\n    worst_bin_index = np.argmax(waste)\n    priorities[valid_bins][worst_bin_index] -= 0.5\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 80.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response0.txt_stdout.txt",
    "code_path": "problem_iter15_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    \n    best_bin_index = np.argmin(waste)\n    \n    priorities[valid_bins] = 1.0 / (waste + 1e-6)\n    \n    exploration_factor = 0.2\n    \n    for i in range(len(bins_remain_cap)):\n        if valid_bins[i]:\n            if i != np.where(valid_bins)[0][best_bin_index]:\n                priorities[i] += exploration_factor * np.random.rand()\n                \n    \n    bin_utilization = 1 - (bins_remain_cap / bins_remain_cap.max())\n    \n    deprioritize_factor = 0.1\n    \n    for i in range(len(bins_remain_cap)):\n        if valid_bins[i]:\n            priorities[i] -= deprioritize_factor * bin_utilization[i]\n            \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999970029999986 seconds"
  },
  {
    "stdout_filepath": "problem_iter15_response1.txt_stdout.txt",
    "code_path": "problem_iter15_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins with medium remaining capacity and occasionally accepts worse fits.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        \n        median_cap = np.median(bins_remain_cap[valid_bins])\n        \n        distance_from_median = np.abs(bins_remain_cap[valid_bins] - median_cap)\n        \n        priorities[valid_bins] = 1 / (1 + distance_from_median)\n        \n        \n        random_bin_index = np.random.randint(0, len(bins_remain_cap[valid_bins]))\n        \n        \n        if np.random.rand() < 0.1:\n            \n            worst_bin_index = np.argmax(waste)\n            \n            priorities[valid_bins[worst_bin_index]] += 0.5\n        else:\n            \n            best_bin_index = np.argmin(waste)\n            priorities[valid_bins[best_bin_index]] += 0.2\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 28, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n16\n3\n101.95026032264605\n"
  },
  {
    "stdout_filepath": "problem_iter15_response2.txt_stdout.txt",
    "code_path": "problem_iter15_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Dynamic prioritization with controlled exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        \n        best_bin_index = np.argmin(waste)\n        worst_bin_index = np.argmax(waste)\n        \n        priorities[valid_bins] = 1 / (waste + 1e-6)\n        \n        exploration_factor = 0.2\n        priorities[np.where(valid_bins)[0][worst_bin_index]] += exploration_factor\n        \n        \n        bin_utilization = 1 - (bins_remain_cap / bins_remain_cap.max())\n        \n        deprioritization_factor = 0.1 * bin_utilization\n        priorities[valid_bins] -= deprioritization_factor\n\n        priorities[np.where(valid_bins)[0][best_bin_index]] += 0.5\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\n    \nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n15\n2\n133.78294855911892\n"
  },
  {
    "stdout_filepath": "problem_iter15_response3.txt_stdout.txt",
    "code_path": "problem_iter15_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        \n        priorities[valid_bins] = 1.0 / (1.0 + waste)\n        \n        bin_usage = (bins_remain_cap - item) / bins_remain_cap\n        bin_usage = np.where(valid_bins, bin_usage, 0.0)\n        \n        exploration_bonus = np.exp(-bin_usage * exploration_factor)\n        priorities[valid_bins] += exploration_bonus\n        \n        \n        worst_fit_index = np.argmax(waste)\n        priorities[np.where(valid_bins)[0][worst_fit_index]] += worst_fit_boost\n\n    return priorities\n\nexploration_factor = 2.0\nworst_fit_boost = 0.1",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 15, in priority_v2\n    best_bin_index = np.argmin(waste)\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n13\n2\n125.33591475173351\n"
  },
  {
    "stdout_filepath": "problem_iter15_response4.txt_stdout.txt",
    "code_path": "problem_iter15_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing that balances best-fit with\n    exploration of less-utilized bins.\n    \"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    priorities = np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[valid_bins] - item\n\n    best_bin_index = np.argmin(waste)\n    \n    priorities[valid_bins] = 1.0 / (waste + 1e-6)\n\n    exploration_factor = 0.2\n    \n    for i in range(len(bins_remain_cap)):\n        if valid_bins[i]:\n            if i != best_bin_index:\n                priorities[i] += exploration_factor * np.random.rand()\n            else:\n                priorities[i] += exploration_factor * 0.2 * np.random.rand()\n\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997639000003 seconds"
  }
]