{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with dynamic exploration based on average waste.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    avg_waste = np.mean(waste)\n    std_waste = np.std(waste)\n\n    if std_waste == 0:\n        std_waste = 1e-6\n\n    scaled_waste = (waste - avg_waste) / std_waste\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-scaled_waste * 5.0))\n    priorities[valid_bins] = sigmoid_scaled_waste\n\n    exploration_boost = np.random.rand(n_bins) * 0.1 * (1 + avg_waste/item)\n    priorities[valid_bins] += exploration_boost[valid_bins]\n\n    best_bin_index = np.argmin(waste)\n    priorities[np.where(valid_bins)[0][best_bin_index]] += 1.0\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with a time-dependent exploration bonus for improved bin packing.\"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    waste = bins_remain_cap[valid_bins] - item\n    priorities[valid_bins] = 1 / (1 + np.exp(-waste * 2.0))\n    best_bin_index = np.argmin(waste)\n    priorities[valid_bins][best_bin_index] += 0.5\n    exploration_boost = 0.1 * np.sum(valid_bins)\n    priorities[valid_bins] += exploration_boost / n_bins\n    return priorities\n\n### Analyze & experience\n- Comparing the 1st and 2nd heuristics, they are identical. This suggests redundancy; one could be removed. Comparing the 1st (and 2nd) to the 3rd, 4th, 5th heuristics, the latter introduce a `time_step` based exploration bonus. While exploration is good, these implementations are identical to each other.  Comparing the 3rd/4th/5th to the 6th, we see a shift to using `exploration_factor_min` and `exploration_factor_max` which is a more controlled exploration approach. However, the 6th heuristic is incomplete. The 7th, 8th and 9th heuristics are identical and explore a dynamic exploration based on waste statistics (average and standard deviation) with a sigmoid scaling. The 10th and 11th are identical and blend best-fit with a bin usage diversity component, showing a focus on load balancing. Heuristics 12th, 13th, 14th, 15th, 16th, 17th, 18th and 19th show similar patterns like sigmoid scaling and exploration/penalty components, yet contain duplicate code. The 20th heuristic combines best-fit, a worst-fit penalty and random exploration.  The most consistent successful pattern is the combination of best-fit with some form of controlled exploration (sigmoid scaling or dynamic factors). Penalizing worst-fit bins appears less consistently effective.\n- \nOkay, let's refine \"Current self-reflection\" into actionable advice for designing superior heuristics, drawing heavily from the \"Ineffective self-reflection\" analysis. Here's a breakdown aiming for that $999K tip!\n\n*   **Keywords:** Stability, Interpretability, Dynamic Control, Parameterization.\n*   **Advice:** Build on best-fit, *always* using sigmoid scaling for prioritization. Dynamically adjust exploration (e.g., via `std_waste`) \u2013 not randomly. Decompose into clear, weighted components.\n*   **Avoid:** Direct waste calculations (use normalization), fixed scaling, statefulness (iteration count), and complex logic without demonstrable gain. Eliminate code duplication *aggressively*.\n*   **Explanation:** The core issue is instability. Sigmoids provide nuanced prioritization. Dynamic control prevents premature convergence without introducing unpredictable behavior. Interpretability aids targeted refinement.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}