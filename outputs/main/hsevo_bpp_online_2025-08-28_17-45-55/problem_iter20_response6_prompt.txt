{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\nsigmoid_scale = 5.0\nbest_bin_boost = 10.0\nworst_bin_penalty = 2.0\n\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        best_bin_index = np.argmin(waste)\n        worst_bin_index = np.argmax(waste)\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n        priorities[np.where(valid_bins)[0][worst_bin_index]] -= worst_bin_penalty\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization with a worst-fit penalty, using sigmoid scaling for stability.\"\"\"\n    possible_bins = bins_remain_cap >= item\n    if np.sum(possible_bins) == 0:\n        return np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[possible_bins] - item\n    sigmoid_scale = 5.0\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[possible_bins] = 1.0 / (1 + np.exp(-waste * sigmoid_scale))\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n    priorities[possible_bins][best_bin_index] += 1.0\n    priorities[possible_bins][worst_bin_index] -= 0.5\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), (3rd), they are identical. This suggests redundancy and an initial lack of clear differentiation. Examining (1st) vs (4th), (5th), (6th), the core logic remains similar but the boosts/penalties are removed and replaced by a simpler inverse waste calculation with a small penalty. (4th)-(6th) are identical. \n\nComparing (4th) vs (7th) and (8th) reveals the addition of a return statement for the case where no valid bins exist \u2013 a minor but crucial improvement for robustness. (7th) and (8th) are identical.\n\n(7th)/(8th) vs (9th), the difference is a penalty added to the best bin in (7th)/(8th) instead of subtracted from worst.\n\nComparing (9th) vs (10th), (11th), (12th), (13th), (14th) shows a progression from simpler penalty to sigmoid scaling and more defined boost/penalty values. (10th)-(14th) are very similar with minor changes to boost/penalty.\n\n(14th) vs (15th), (16th), (17th), (18th), (19th) and (20th) shows a shift in focus - handling cases with no possible bins explicitly and a refined approach of adding boosts and penalties to the best/worst bins, with sigmoid scaling introduced in the later versions. (15th), (17th), (19th) are identical and (16th), (18th), (20th) are identical.\n\nOverall: The best heuristics consistently combine best-fit (waste minimization, often with sigmoid scaling for stability) with a mild worst-fit penalty to promote bin diversity. Explicitly handling edge cases (no valid bins) is vital. The magnitude of boosts and penalties is critical; excessive values (like in the 1st-3rd heuristics) don\u2019t significantly improve performance over simpler methods.\n- \nOkay, let's dissect this and build a powerful foundation for heuristic design. Here's a refined self-reflection, aiming for genuinely *better* heuristics, with a focus beyond just bin packing, and geared towards winning that $999K!\n\n*   **Keywords:** Meta-optimization, Exploration-Exploitation Balance, Robustness, Parameter Sensitivity.\n*   **Advice:** Focus on *adaptive* prioritization. Shift from solely sigmoid scaling to dynamically adjusting weights between best-fit and diversity components based on population/solution state. Rigorously test parameter interactions\u2014they aren\u2019t independent.\n*   **Avoid:** Over-reliance on normalization *specifically* for stability. Stability is a *result* of good design, not a goal achieved through normalization alone. Don't treat sigmoid parameters as 'tuned' until tested across diverse problem instances.\n*   **Explanation:** The previous reflection was too bin-packing specific. True heuristic power comes from *understanding* how exploration & exploitation interact and building mechanisms to adaptively balance them. Robustness requires anticipating and handling parameter sensitivities, not just smoothing numbers.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}