{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigmoid_scale: float = 2.5369418572825637, best_bin_boost: float = 1.704707830932726) -> np.ndarray:\n    \"\"\"Combines best-fit (waste minimization) with sigmoid scaling for stability.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        best_bin_index = np.argmin(waste)\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        priorities[np.where(valid_bins)[0][best_bin_index]] = best_bin_boost\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigmoid_scale: float = 2.5369418572825637, best_bin_boost: float = 1.704707830932726) -> np.ndarray:\n    \"\"\"Combines best-fit (waste minimization) with sigmoid scaling for stability.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        best_bin_index = np.argmin(waste)\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        priorities[np.where(valid_bins)[0][best_bin_index]] = best_bin_boost\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with sigmoid scaling and normalization to enhance stability.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[valid_bins] - item\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    if std_waste == 0:\n        normalized_waste = np.zeros_like(waste)\n    else:\n        normalized_waste = (waste - mean_waste) / std_waste\n    priorities = np.zeros_like(bins_remain_cap)\n    sigmoid_scale = 1.0\n    best_bin_boost = 2.0\n    priorities[valid_bins] = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n    best_bin_index = np.argmin(waste)\n    priorities[np.where(valid_bins)[0][best_bin_index]] = best_bin_boost\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, sigmoid scaling, and a best-bin boost,\n    with robust handling of edge cases and numerical stability.\"\"\"\n    sigmoid_scale = 5.0\n    best_bin_boost = 1.0\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        mean_waste = np.mean(waste)\n        std_waste = np.std(waste)\n        if std_waste == 0:\n            normalized_waste = np.zeros_like(waste)\n        else:\n            normalized_waste = (waste - mean_waste) / std_waste\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigmoid_scale: float = 9.73767708582636, best_bin_boost: float = 3.788704854914895) -> np.ndarray:\n    \"\"\"Combines waste minimization, sigmoid scaling, and a best-bin boost, with robust handling of edge cases and numerical stability.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        mean_waste = np.mean(waste)\n        std_waste = np.std(waste)\n        if std_waste == 0:\n            normalized_waste = np.zeros_like(waste)\n        else:\n            normalized_waste = (waste - mean_waste) / std_waste\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, worst-fit, and a capacity-based score with adaptive weighting.\n    Uses a statistical approach to bin selection, aiming for robustness.\n    \"\"\"\n    sigmoid_scale = 5.0\n    best_bin_boost = 1.0\n    worst_fit_penalty = 0.5\n\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        capacities = bins_remain_cap[valid_bins]\n        normalized_capacities = capacities / np.max(capacities)\n        capacity_score = normalized_capacities\n\n        best_fit_score = np.zeros_like(capacity_score)\n        best_fit_score[np.argmin(waste)] = 1.0\n\n        worst_fit_score = np.zeros_like(capacity_score)\n        worst_fit_score[np.argmax(waste)] = -worst_fit_penalty\n\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n\n        combined_score = 0.5 * sigmoid_scaled_waste + 0.3 * capacity_score + 0.2 * (best_fit_score + worst_fit_score)\n        priorities[valid_bins] = combined_score\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, sigmoid_scale: float = 9.73767708582636, best_bin_boost: float = 3.788704854914895) -> np.ndarray:\n    \"\"\"Combines waste minimization, sigmoid scaling, and a best-bin boost, with robust handling of edge cases and numerical stability.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        mean_waste = np.mean(waste)\n        std_waste = np.std(waste)\n        if std_waste == 0:\n            normalized_waste = np.zeros_like(waste)\n        else:\n            normalized_waste = (waste - mean_waste) / std_waste\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha=1.0, beta=0.5, gamma=2.0) -> np.ndarray:\n    \"\"\"\n    A mutated priority function for online Bin Packing Problem (BPP).\n    Combines best-fit with a dynamically adjusted priority based on bin utilization and item size.\n    Uses parameters alpha, beta, and gamma to control the weighting of different factors.\n    \"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        bin_utilization = bins_remain_cap[valid_bins] / np.max(bins_remain_cap)\n        waste = bins_remain_cap[valid_bins] - item\n        \n        priority_component1 = np.exp(-alpha * waste / np.max(bins_remain_cap))\n        priority_component2 = bin_utilization**beta\n        \n        combined_priority = priority_component1 * priority_component2\n        priorities[valid_bins] = combined_priority\n\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += gamma\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, sigmoid scaling, and a best-bin boost,\n    with robust handling of edge cases and numerical stability.\"\"\"\n    sigmoid_scale = 5.0\n    best_bin_boost = 1.0\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        mean_waste = np.mean(waste)\n        std_waste = np.std(waste)\n        if std_waste == 0:\n            normalized_waste = np.zeros_like(waste)\n        else:\n            normalized_waste = (waste - mean_waste) / std_waste\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha=1.0, beta=0.5, gamma=2.0) -> np.ndarray:\n    \"\"\"\n    A mutated priority function for online Bin Packing Problem (BPP).\n    Combines best-fit with a dynamically adjusted priority based on bin utilization and item size.\n    Uses parameters alpha, beta, and gamma to control the weighting of different factors.\n    \"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        bin_utilization = bins_remain_cap[valid_bins] / np.max(bins_remain_cap)\n        waste = bins_remain_cap[valid_bins] - item\n        \n        priority_component1 = np.exp(-alpha * waste / np.max(bins_remain_cap))\n        priority_component2 = bin_utilization**beta\n        \n        combined_priority = priority_component1 * priority_component2\n        priorities[valid_bins] = combined_priority\n\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += gamma\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha=1.0, beta=0.5, gamma=2.0) -> np.ndarray:\n    \"\"\"\n    A mutated priority function for online Bin Packing Problem (BPP).\n    Combines best-fit with a dynamically adjusted priority based on bin utilization and item size.\n    Uses parameters alpha, beta, and gamma to control the weighting of different factors.\n    \"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        bin_utilization = bins_remain_cap[valid_bins] / np.max(bins_remain_cap)\n        waste = bins_remain_cap[valid_bins] - item\n        \n        priority_component1 = np.exp(-alpha * waste / np.max(bins_remain_cap))\n        priority_component2 = bin_utilization**beta\n        \n        combined_priority = priority_component1 * priority_component2\n        priorities[valid_bins] = combined_priority\n\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += gamma\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with sigmoid scaling and normalization to enhance stability.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[valid_bins] - item\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    if std_waste == 0:\n        normalized_waste = np.zeros_like(waste)\n    else:\n        normalized_waste = (waste - mean_waste) / std_waste\n    priorities = np.zeros_like(bins_remain_cap)\n    sigmoid_scale = 1.0\n    best_bin_boost = 2.0\n    priorities[valid_bins] = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n    best_bin_index = np.argmin(waste)\n    priorities[np.where(valid_bins)[0][best_bin_index]] = best_bin_boost\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization with a best-bin boost for stable priority.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n\n    if std_waste > 0:\n        normalized_waste = (waste - mean_waste) / std_waste\n    else:\n        normalized_waste = np.zeros_like(waste)\n\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1 / (1 + np.exp(-normalized_waste))\n\n    best_bin_index = np.argmin(waste)\n    priorities[valid_bins[best_bin_index]] = np.max(priorities[valid_bins])\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste normalization with a best-bin boost for stable priority.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n\n    if std_waste > 0:\n        normalized_waste = (waste - mean_waste) / std_waste\n    else:\n        normalized_waste = np.zeros_like(waste)\n\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1 / (1 + np.exp(-normalized_waste))\n\n    best_bin_index = np.argmin(waste)\n    priorities[valid_bins[best_bin_index]] = np.max(priorities[valid_bins])\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\nsigmoid_scale = 5.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing, combining best-fit,\n    worst-fit (to promote diversity), and sigmoid scaling with a dynamic\n    adjustment based on bin utilization.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    bin_utilization = bins_remain_cap / np.max(bins_remain_cap)\n    utilization_factor = 1 + bin_utilization\n\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n    priorities[valid_bins] = sigmoid_scaled_waste * utilization_factor[valid_bins]\n\n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    priorities[np.where(valid_bins)[0][worst_bin_index]] += 0.5\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\nsigmoid_scale = 5.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing, combining best-fit,\n    worst-fit (to promote diversity), and sigmoid scaling with a dynamic\n    adjustment based on bin utilization.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    bin_utilization = bins_remain_cap / np.max(bins_remain_cap)\n    utilization_factor = 1 + bin_utilization\n\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n    priorities[valid_bins] = sigmoid_scaled_waste * utilization_factor[valid_bins]\n\n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    priorities[np.where(valid_bins)[0][worst_bin_index]] += 0.5\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\nsigmoid_scale = 5.0\nbest_bin_boost = 1.0\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A priority function for online bin packing, combining best-fit,\n    worst-fit (to promote diversity), and sigmoid scaling with a dynamic\n    adjustment based on bin utilization.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities\n\n    waste = bins_remain_cap[valid_bins] - item\n    best_bin_index = np.argmin(waste)\n    worst_bin_index = np.argmax(waste)\n\n    bin_utilization = bins_remain_cap / np.max(bins_remain_cap)\n    utilization_factor = 1 + bin_utilization\n\n    sigmoid_scaled_waste = 1 / (1 + np.exp(-waste * sigmoid_scale))\n    priorities[valid_bins] = sigmoid_scaled_waste * utilization_factor[valid_bins]\n\n    priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    priorities[np.where(valid_bins)[0][worst_bin_index]] += 0.5\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with sigmoid scaling and a best-bin boost, normalizing waste.\"\"\"\n    possible_bins = bins_remain_cap >= item\n    if np.sum(possible_bins) == 0:\n        return np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[possible_bins] - item\n    priorities = 1.0 / (waste + 1e-9)\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    if std_waste > 0:\n        normalized_waste = (waste - mean_waste) / std_waste\n    else:\n        normalized_waste = np.zeros_like(waste)\n    sigmoid_scaled_waste = 1.0 / (1.0 + np.exp(-normalized_waste * 2.0))\n    priorities = sigmoid_scaled_waste\n    priorities[~possible_bins] = 0.0\n    best_bin_index = np.argmin(waste)\n    priorities[possible_bins][best_bin_index] += 1.0\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with sigmoid scaling and a best-bin boost, normalizing waste.\"\"\"\n    possible_bins = bins_remain_cap >= item\n    if np.sum(possible_bins) == 0:\n        return np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[possible_bins] - item\n    priorities = 1.0 / (waste + 1e-9)\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    if std_waste > 0:\n        normalized_waste = (waste - mean_waste) / std_waste\n    else:\n        normalized_waste = np.zeros_like(waste)\n    sigmoid_scaled_waste = 1.0 / (1.0 + np.exp(-normalized_waste * 2.0))\n    priorities = sigmoid_scaled_waste\n    priorities[~possible_bins] = 0.0\n    best_bin_index = np.argmin(waste)\n    priorities[possible_bins][best_bin_index] += 1.0\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with sigmoid scaling and a best-bin boost, normalizing waste.\"\"\"\n    possible_bins = bins_remain_cap >= item\n    if np.sum(possible_bins) == 0:\n        return np.zeros_like(bins_remain_cap)\n    waste = bins_remain_cap[possible_bins] - item\n    priorities = 1.0 / (waste + 1e-9)\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n    if std_waste > 0:\n        normalized_waste = (waste - mean_waste) / std_waste\n    else:\n        normalized_waste = np.zeros_like(waste)\n    sigmoid_scaled_waste = 1.0 / (1.0 + np.exp(-normalized_waste * 2.0))\n    priorities = sigmoid_scaled_waste\n    priorities[~possible_bins] = 0.0\n    best_bin_index = np.argmin(waste)\n    priorities[possible_bins][best_bin_index] += 1.0\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}