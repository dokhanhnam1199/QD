{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, sigmoid scaling, and a best-bin boost, with robust handling of edge cases and numerical stability.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        mean_waste = np.mean(waste)\n        std_waste = np.std(waste)\n        if std_waste == 0:\n            normalized_waste = np.zeros_like(waste)\n        else:\n            normalized_waste = (waste - mean_waste) / std_waste\n        sigmoid_scaled_waste = 1 / (1 + np.exp(-normalized_waste * sigmoid_scale))\n        priorities[valid_bins] = sigmoid_scaled_waste\n        best_bin_index = np.argmin(waste)\n        priorities[np.where(valid_bins)[0][best_bin_index]] += best_bin_boost\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste normalization with a best-bin boost for stable priority.\"\"\"\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[valid_bins] - item\n    mean_waste = np.mean(waste)\n    std_waste = np.std(waste)\n\n    if std_waste > 0:\n        normalized_waste = (waste - mean_waste) / std_waste\n    else:\n        normalized_waste = np.zeros_like(waste)\n\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1 / (1 + np.exp(-normalized_waste))\n\n    best_bin_index = np.argmin(waste)\n    priorities[valid_bins[best_bin_index]] = np.max(priorities[valid_bins])\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1st vs 2nd, they are identical, indicating a redundancy. Heuristics 1st/2nd vs 3rd show the introduction of waste normalization, which attempts to improve stability, but the fixed sigmoid scale of 1.0 seems limiting.  Heuristics 3rd vs 4th reveals a slight change in `best_bin_boost` and `sigmoid_scale`, alongside a subtle difference in how the boost is added (+ vs. +=), with 4th showing a more robust approach.\n\nComparing Heuristics 1st/2nd vs 5th shows the tuning of `sigmoid_scale` and `best_bin_boost`. Heuristics 6th introduces worst-fit penalty and capacity scoring, adding complexity but attempting to balance bin utilization. Heuristics 7th is functionally similar to 5th. \n\nHeuristics 8th introduces `alpha`, `beta`, and `gamma` parameters, offering more control over the weighting of different factors but at the cost of increased tuning complexity. Heuristics 9th, 10th, 11th are essentially the same. Heuristics 12th-14th are very similar with minor changes.\n\nHeuristics 15th-17th are nearly duplicates, incorporating utilization factors alongside best and worst fit. Finally, Heuristics 18th-20th focus on waste normalization and attempt to handle cases with zero standard deviation, but lack the diversity promotion strategies of earlier heuristics.  \n\nOverall, the best heuristics (1st/2nd) provide a solid base of best-fit and sigmoid scaling. Introducing diversity (worst-fit) as in 6th and 15th seems beneficial, while normalization (3rd, 18th) is helpful for stability but might require more careful parameter tuning. The redundant entries highlight the need for thorough testing and comparison.\n- \nOkay, let's dissect this and craft a response geared towards designing *better* heuristics, leveraging the provided analyses. Here's a breakdown, aiming for that $999K tip!\n\n**Here's the response:**\n\n*   **Keywords:** Exploration, Diversity, Dynamic Prioritization, Robustness\n*   **Advice:** Embrace *controlled* randomness. Introduce mechanisms rewarding 'worse' fits occasionally. Dynamically shift focus *away* from highly utilized bins, but cautiously.\n*   **Avoid:** Over-reliance on smoothing/normalization (sigmoid). Stability isn't the primary goal if it stifles exploration. Don't prioritize minimizing immediate waste; focus on long-term potential.\n*   **Explanation:** The 'Ineffective' reflection prioritized local optimization & stability. The 'Current' shows exploration is key. Better heuristics need to *balance* exploitation with diverse searching\u2014even if it means temporarily worsening waste\u2014to escape local optima.\n\n\n\n**Step-by-step thinking behind this:**\n\n1.  **Core Conflict:** The two analyses represent a fundamental tension: stability vs. exploration. The 'Ineffective' analysis fixated on stability (sigmoid, normalization, best-fit focus). The 'Current' acknowledges that can lead to premature convergence.\n2.  **The Key Insight:** The 'Current' analysis's success with exploring 'worse' fits is the most valuable piece. This suggests the algorithm was getting stuck in local optima and needed a nudge to consider alternative solutions.\n3.  **Reframing Advice:** Instead of smoothing and stabilizing, we want to *introduce* controlled disruption. Rewarding 'worse' fits and de-prioritizing popular bins accomplishes this.\n4.  **Conciseness:** Kept it brief, as requested, while still conveying the crucial shift in thinking.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}