[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        epsilon: Exploration rate.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate the 'greedy' priority (best fit)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        best_fit_bin_index = np.argmin(bins_remain_cap[eligible_bins] - item)\n        best_fit_bin_index = np.where(eligible_bins)[0][best_fit_bin_index]\n        priorities[best_fit_bin_index] = 1.0\n\n    # Epsilon-greedy exploration\n    if np.random.rand() < epsilon:\n        # Assign a random priority to eligible bins\n        eligible_bins = bins_remain_cap >= item\n        if np.any(eligible_bins):\n            random_bin_indices = np.where(eligible_bins)[0]\n            random_index = np.random.choice(random_bin_indices)\n            priorities[random_index] = np.random.rand()\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 36.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score with improved penalties and tuning.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the fit score for each bin.  Higher is better.\n    fit_scores = item / bins_remain_cap\n    fit_scores[np.isinf(fit_scores)] = 0.0  # Handle cases where item > bin_remain_cap\n\n    # Apply a sigmoid function to the fit scores to normalize and enhance selection.\n    # Scaling factor (k) controls the steepness, and shift (x0) controls the center.\n    k = 5.0  # Increased steepness for more selective binning\n    x0 = 0.4  # Adjusted center to favor reasonably full bins\n    sigmoid_scores = 1 / (1 + np.exp(-k * (fit_scores - x0)))\n\n    # Penalize bins that have very small remaining capacity. This discourages fragmentation.\n    capacity_penalty = bins_remain_cap / np.max(bins_remain_cap)\n    sigmoid_scores = sigmoid_scores * capacity_penalty\n\n    # Strict penalty for bins where the item doesn't fit at all. This is crucial.\n    no_fit_penalty = np.where(bins_remain_cap < item, 0.0, 1.0)\n    sigmoid_scores = sigmoid_scores * no_fit_penalty\n\n    # Add a small amount of randomness for exploration, particularly when multiple bins have similar scores\n    randomness = np.random.rand(len(bins_remain_cap)) * 1e-6\n    sigmoid_scores = sigmoid_scores + randomness\n\n    return sigmoid_scores",
    "response_id": 1,
    "obj": 149.30195452732352,
    "SLOC": 13.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 158.32466846199546,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n\n    if np.any(possible_bins):\n        # Prioritize tight fits\n        fit_score = 1.0 / (bins_remain_cap[possible_bins] - item + 1e-6)\n\n        # Encourage diversity: bins that are less full get a boost.\n        diversity_bonus = (bins_remain_cap[possible_bins] / np.max(bins_remain_cap)) * 0.2\n\n        # Add some randomness for exploration\n        randomness = np.random.rand(np.sum(possible_bins)) * 1e-5\n\n        priorities[possible_bins] = fit_score + diversity_bonus + randomness\n\n    return priorities",
    "response_id": 2,
    "obj": 4.198244914240141,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 120.40465370320703,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the fit score for each bin\n    fit_scores = item / bins_remain_cap\n    fit_scores[np.isinf(fit_scores)] = 0  # Handle cases where item > bin_remain_cap to avoid inf\n\n    # Apply a sigmoid function to the fit scores. A larger fit score will result in\n    # a priority closer to 1, representing a better fit. The sigmoid function\n    # ensures that the score remains between 0 and 1. We also introduce a scaling factor\n    # (e.g., 4) and a shift (e.g., -0.2) to adjust the sigmoid's slope and center.\n    # This could be tuned during experimentation. Adjusting the sigmoid's shape\n    # will influence the strategy; a steeper slope means more aggressive use of tight bins.\n    sigmoid_scores = 1 / (1 + np.exp(-4 * (fit_scores - 0.2)))\n\n    # Penalize bins that have very small remaining capacity. Adding the item to an\n    # almost full bin can lead to fragmentation.\n    capacity_penalty = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    sigmoid_scores = sigmoid_scores * capacity_penalty\n\n    # Additional penalty if the item doesn't fit at all in a particular bin. Avoids NaNs.\n    no_fit_penalty = np.where(bins_remain_cap < item, 0.0, 1.0)\n    sigmoid_scores = sigmoid_scores * no_fit_penalty\n\n    return sigmoid_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 140.55415752892034,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities  # No bin can fit the item\n\n    # 1. Prioritize empty bins (or bins with very little in them)\n    empty_bins = bins_remain_cap <= item * 0.01\n    priorities[empty_bins] = 1.0\n\n    # 2. Calculate fit score (sigmoid function) for eligible bins\n    fit_scores = np.where(eligible_bins, 1.0 / (1.0 + np.exp(-10 * (bins_remain_cap - item))), 0.0)\n\n    # 3. Prioritize near-size bins\n    size_diff = np.where(eligible_bins, np.abs(bins_remain_cap - item), np.inf)\n    near_size_bonus = np.where(eligible_bins, np.exp(-size_diff / (item * 0.1)), 0.0)  # Adjust sensitivity\n\n    # 4. Combine scores\n    priorities = fit_scores + 0.5 * near_size_bonus\n\n    # Add small random noise to break ties and encourage exploration\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.005\n\n    return priorities",
    "response_id": 4,
    "obj": 6.661348224970079,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 237.80142289857002,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined sigmoid fit score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the fit score for each bin.  Lower is better (less wasted space)\n    fit_scores = item / bins_remain_cap\n    fit_scores[np.isinf(fit_scores)] = 1.0  # Cap at 1.0 to avoid inf, item cannot fit.\n\n    # Apply a sigmoid function to the fit scores. A larger fit score will result in\n    # a priority closer to 0, representing a worse fit.  The sigmoid function\n    # ensures that the score remains between 0 and 1.  We also introduce a scaling factor\n    # (e.g., 5) and a shift (e.g., -1) to adjust the sigmoid's slope and center.\n    # This could be tuned during experimentation.\n    sigmoid_scores = 1 / (1 + np.exp(-5 * (fit_scores - 0.5)))\n\n    # Penalize bins that have very small remaining capacity. Adding the item to an\n    # almost full bin can lead to fragmentation.\n    capacity_penalty = bins_remain_cap / np.max(bins_remain_cap)\n    sigmoid_scores = sigmoid_scores * capacity_penalty\n\n    # Additional penalty if the item doesn't fit at all in a particular bin.\n    no_fit_penalty = np.where(bins_remain_cap < item, 0.0, 1.0)\n    sigmoid_scores = sigmoid_scores * no_fit_penalty\n\n    return sigmoid_scores",
    "response_id": 5,
    "obj": 11.916633426406063,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 125.33591475173351,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if np.any(possible_bins):\n        remaining_space = bins_remain_cap[possible_bins] - item\n        priorities[possible_bins] = (1.0 / (remaining_space + 1e-6)) + np.random.rand(np.sum(possible_bins)) * 1e-4\n    return priorities",
    "response_id": 6,
    "obj": 4.188272836059035,
    "SLOC": 7.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 72.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n\n    if np.any(possible_bins):\n        # Prioritize bins with less remaining capacity (better fit)\n        fit_score = 1.0 / (bins_remain_cap[possible_bins] - item + 1e-6)\n\n        # Add a diversity bonus: bins that are less full get a slight boost.\n        # This encourages exploration and avoids filling up bins too quickly.\n        diversity_bonus = (bins_remain_cap[possible_bins] / np.max(bins_remain_cap)) * 0.2\n\n        # Add some randomness for exploration - decaying randomness\n        randomness = np.random.rand(np.sum(possible_bins)) * 1e-6\n\n        priorities[possible_bins] = fit_score + diversity_bonus + randomness\n\n    return priorities",
    "response_id": 7,
    "obj": 4.198244914240141,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 118.59257041502654,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if np.any(possible_bins):\n        remaining_space = bins_remain_cap[possible_bins] - item\n        priorities[possible_bins] = 1.0 / (remaining_space + 1e-6)\n        # Add a small random element to avoid always choosing the same bin\n        priorities[possible_bins] += np.random.rand(np.sum(possible_bins)) * 1e-4\n    return priorities",
    "response_id": 8,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 19, in priority_v2\n    best_fit_bin_index = np.argmin(bins_remain_cap[eligible_bins] - item)\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n8\n2\n72.0\n"
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.1) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        epsilon: Exploration rate.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Greedy: Best-fit\n        best_fit_bin_index = np.argmin(bins_remain_cap[eligible_bins] - item)\n        best_fit_bin_index = np.where(eligible_bins)[0][best_fit_bin_index]\n        priorities[best_fit_bin_index] = 1.0\n\n        # Epsilon-greedy exploration\n        if np.random.rand() < epsilon:\n            random_bin_indices = np.where(eligible_bins)[0]\n            random_index = np.random.choice(random_bin_indices)\n            priorities[random_index] = np.random.rand()\n\n    return priorities",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 27.0,
    "exec_success": true
  }
]