[2025-04-27 03:25:30,322][root][INFO] - Workspace: C:\Users\Nam\Documents\GitHub\HSEvo\outputs\main\eoh_bpp_online_2025-04-27_03-25-30
[2025-04-27 03:25:30,322][root][INFO] - Project Root: C:\Users\Nam\Documents\GitHub\HSEvo
[2025-04-27 03:25:30,322][root][INFO] - Using LLM: gemini/gemini-2.0-flash
[2025-04-27 03:25:30,322][root][INFO] - Using Algorithm: eoh
[2025-04-27 03:25:32,769][httpx][INFO] - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json "HTTP/1.1 200 OK"
[2025-04-27 03:25:34,604][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:37,524][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:37,532][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:37,534][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:37,535][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:37,537][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:37,542][root][INFO] - LLM usage: prompt_tokens = 165, completion_tokens = 158
[2025-04-27 03:25:37,544][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:40,512][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:40,515][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:40,516][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:40,517][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:40,519][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:40,520][root][INFO] - LLM usage: prompt_tokens = 330, completion_tokens = 318
[2025-04-27 03:25:40,521][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:42,843][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:42,846][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:42,847][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:42,848][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:42,851][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:42,852][root][INFO] - LLM usage: prompt_tokens = 495, completion_tokens = 491
[2025-04-27 03:25:42,854][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:45,445][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:45,450][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:45,452][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:45,452][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:45,455][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:45,455][root][INFO] - LLM usage: prompt_tokens = 660, completion_tokens = 596
[2025-04-27 03:25:45,459][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:48,234][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:48,238][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:48,239][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:48,240][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:48,242][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:48,243][root][INFO] - LLM usage: prompt_tokens = 825, completion_tokens = 733
[2025-04-27 03:25:48,247][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:50,106][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:50,109][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:50,111][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:50,111][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:50,114][root][INFO] - LLM usage: prompt_tokens = 990, completion_tokens = 851
[2025-04-27 03:25:50,114][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:50,116][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:52,012][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:52,015][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:52,017][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:52,017][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:52,020][root][INFO] - LLM usage: prompt_tokens = 1155, completion_tokens = 992
[2025-04-27 03:25:52,019][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:52,022][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:55,029][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:55,032][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:55,033][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:55,033][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:55,036][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:55,037][root][INFO] - LLM usage: prompt_tokens = 1320, completion_tokens = 1161
[2025-04-27 03:25:55,039][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:57,564][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:57,568][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:57,569][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:57,569][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:57,572][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:57,573][root][INFO] - LLM usage: prompt_tokens = 1485, completion_tokens = 1258
[2025-04-27 03:25:57,575][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:25:59,724][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:25:59,729][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:25:59,730][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:59,731][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:59,732][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:25:59,733][root][INFO] - LLM usage: prompt_tokens = 1650, completion_tokens = 1411
[2025-04-27 03:25:59,753][root][INFO] - Iteration 0: Running Code 4265388547730409092
[2025-04-27 03:25:59,907][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:25:59,907][root][INFO] - Iteration 0: Running Code 2946250829343075960
[2025-04-27 03:26:00,070][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:26:00,071][root][INFO] - Iteration 0: Running Code 4625339055292163725
[2025-04-27 03:26:00,232][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:00,232][root][INFO] - Iteration 0: Running Code 8274885487755603836
[2025-04-27 03:26:00,358][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:00,359][root][INFO] - Iteration 0: Running Code -7535762677561541998
[2025-04-27 03:26:00,499][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:00,499][root][INFO] - Iteration 0: Running Code 8095508451679226818
[2025-04-27 03:26:00,650][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:00,650][root][INFO] - Iteration 0: Running Code -9111562473624161702
[2025-04-27 03:26:00,800][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:00,800][root][INFO] - Iteration 0: Running Code 5521862027618362092
[2025-04-27 03:26:00,954][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:00,955][root][INFO] - Iteration 0: Running Code -1997413050019716552
[2025-04-27 03:26:01,116][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:01,116][root][INFO] - Iteration 0: Running Code -4811931200648196356
[2025-04-27 03:26:01,298][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:26:51,298][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999370000023 seconds
[2025-04-27 03:26:51,316][root][ERROR] - Traceback for response_id 1: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
  File "C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py", line 2
    else:
IndentationError: unexpected indent

[2025-04-27 03:26:51,316][root][INFO] - Iteration 0, response_id 1: Objective value: inf
[2025-04-27 03:26:51,328][root][ERROR] - Traceback for response_id 2: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 112, in <module>
    avg_num_bins = -evaluate(dataset)
                    ~~~~~~~~^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 55, in evaluate
    _, bins_packed = online_binpack(items.astype(float), bins)
                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 28, in online_binpack
    priorities = priority(item, bins[valid_bin_indices])
  File "C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py", line 16, in priority_v2
NameError: name 'priority' is not defined. Did you mean: 'priorities'?

[2025-04-27 03:26:51,328][root][INFO] - Iteration 0, response_id 2: Objective value: inf
[2025-04-27 03:26:51,338][root][ERROR] - Traceback for response_id 3: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 112, in <module>
    avg_num_bins = -evaluate(dataset)
                    ~~~~~~~~^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 55, in evaluate
    _, bins_packed = online_binpack(items.astype(float), bins)
                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 28, in online_binpack
    priorities = priority(item, bins[valid_bin_indices])
  File "C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py", line 10, in priority_v2
    else:
     ^^^^
NameError: name 'priority' is not defined. Did you mean: 'priorities'?

[2025-04-27 03:26:51,338][root][INFO] - Iteration 0, response_id 3: Objective value: inf
[2025-04-27 03:27:35,738][root][INFO] - Iteration 0, response_id 4: Objective value: 4.048663741523748
[2025-04-27 03:27:35,740][root][INFO] - Iteration 0, response_id 5: Objective value: 4.048663741523748
[2025-04-27 03:28:25,740][root][ERROR] - Timeout for response_id 6: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999998100000084 seconds
[2025-04-27 03:28:25,742][root][INFO] - Iteration 0, response_id 7: Objective value: 4.487435181491823
[2025-04-27 03:28:25,745][root][INFO] - Iteration 0, response_id 8: Objective value: 149.30195452732352
[2025-04-27 03:28:28,579][root][INFO] - Iteration 0, response_id 9: Objective value: 3.8791384124451627
[2025-04-27 03:28:28,583][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:30,749][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:30,752][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:30,754][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:30,754][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:30,757][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:30,759][root][INFO] - LLM usage: prompt_tokens = 1815, completion_tokens = 1571
[2025-04-27 03:28:30,761][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:33,366][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:33,390][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:33,391][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:33,391][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:33,393][root][INFO] - LLM usage: prompt_tokens = 1980, completion_tokens = 1695
[2025-04-27 03:28:33,393][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:33,395][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:36,290][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:36,293][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:36,295][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:36,295][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:36,298][root][INFO] - LLM usage: prompt_tokens = 2145, completion_tokens = 1857
[2025-04-27 03:28:36,298][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:36,300][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:38,139][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:38,142][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:38,143][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:38,144][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:38,146][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:38,147][root][INFO] - LLM usage: prompt_tokens = 2310, completion_tokens = 1974
[2025-04-27 03:28:38,150][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:40,834][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:40,837][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:40,838][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:40,838][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:40,841][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:40,842][root][INFO] - LLM usage: prompt_tokens = 2475, completion_tokens = 2101
[2025-04-27 03:28:40,844][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:43,014][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:43,018][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:43,019][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:43,019][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:43,022][root][INFO] - LLM usage: prompt_tokens = 2640, completion_tokens = 2279
[2025-04-27 03:28:43,022][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:43,024][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:45,771][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:45,775][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:45,776][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:45,776][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:45,778][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:45,779][root][INFO] - LLM usage: prompt_tokens = 2805, completion_tokens = 2428
[2025-04-27 03:28:45,780][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:48,426][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:48,429][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:48,430][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:48,431][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:48,433][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:48,434][root][INFO] - LLM usage: prompt_tokens = 2970, completion_tokens = 2562
[2025-04-27 03:28:48,436][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:51,347][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:51,350][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:51,351][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:51,352][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:51,354][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:51,355][root][INFO] - LLM usage: prompt_tokens = 3135, completion_tokens = 2736
[2025-04-27 03:28:51,358][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:28:54,324][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:28:54,326][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:28:54,327][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:54,327][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:54,329][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:28:54,331][root][INFO] - LLM usage: prompt_tokens = 3300, completion_tokens = 2879
[2025-04-27 03:28:54,350][root][INFO] - Iteration 0: Running Code -2142371549380472841
[2025-04-27 03:28:54,510][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:54,510][root][INFO] - Iteration 0: Running Code 3106309306673192367
[2025-04-27 03:28:54,668][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:54,668][root][INFO] - Iteration 0: Running Code -7408854503743644445
[2025-04-27 03:28:54,815][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:54,816][root][INFO] - Iteration 0: Running Code -8468072890947725684
[2025-04-27 03:28:54,960][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:54,961][root][INFO] - Iteration 0: Running Code 905434501193626892
[2025-04-27 03:28:55,114][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:55,115][root][INFO] - Iteration 0: Running Code 2898964755494636880
[2025-04-27 03:28:55,281][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:55,281][root][INFO] - Iteration 0: Running Code 469140937993323908
[2025-04-27 03:28:55,464][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:55,465][root][INFO] - Iteration 0: Running Code 2774450592268284618
[2025-04-27 03:28:55,997][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:56,005][root][INFO] - Iteration 0: Running Code 2117088876383230675
[2025-04-27 03:28:56,920][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:28:56,949][root][INFO] - Iteration 0: Running Code 5028567518312580479
[2025-04-27 03:28:58,284][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:29:48,328][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999690000004 seconds
[2025-04-27 03:30:38,351][root][ERROR] - Timeout for response_id 1: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999659999958 seconds
[2025-04-27 03:31:28,357][root][ERROR] - Timeout for response_id 2: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.9999973999993 seconds
[2025-04-27 03:31:28,369][root][INFO] - Iteration 0, response_id 3: Objective value: 4.11846828879138
[2025-04-27 03:31:28,370][root][INFO] - Iteration 0, response_id 4: Objective value: 86.58755484643
[2025-04-27 03:31:28,372][root][INFO] - Iteration 0, response_id 5: Objective value: 4.487435181491823
[2025-04-27 03:32:18,378][root][ERROR] - Timeout for response_id 6: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.9999983000007 seconds
[2025-04-27 03:32:18,380][root][INFO] - Iteration 0, response_id 7: Objective value: 4.048663741523748
[2025-04-27 03:33:08,392][root][ERROR] - Timeout for response_id 8: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999509999998 seconds
[2025-04-27 03:33:08,395][root][INFO] - Iteration 0, response_id 9: Objective value: 4.487435181491823
[2025-04-27 03:33:08,400][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:10,603][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:10,606][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:10,607][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:10,608][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:10,611][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:10,612][root][INFO] - LLM usage: prompt_tokens = 3814, completion_tokens = 3056
[2025-04-27 03:33:10,614][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:13,552][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:13,555][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:13,556][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:13,557][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:13,559][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:13,560][root][INFO] - LLM usage: prompt_tokens = 4332, completion_tokens = 3210
[2025-04-27 03:33:13,563][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:15,378][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:15,381][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:15,382][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:15,382][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:15,385][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:15,386][root][INFO] - LLM usage: prompt_tokens = 4846, completion_tokens = 3325
[2025-04-27 03:33:15,387][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:17,103][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:17,106][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:17,107][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:17,107][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:17,110][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:17,111][root][INFO] - LLM usage: prompt_tokens = 5397, completion_tokens = 3427
[2025-04-27 03:33:17,114][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:19,614][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:19,618][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:19,619][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:19,619][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:19,622][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:19,624][root][INFO] - LLM usage: prompt_tokens = 5893, completion_tokens = 3524
[2025-04-27 03:33:19,626][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:21,485][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:21,488][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:21,489][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:21,490][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:21,492][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:21,493][root][INFO] - LLM usage: prompt_tokens = 6407, completion_tokens = 3625
[2025-04-27 03:33:21,496][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:23,228][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:23,232][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:23,233][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:23,233][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:23,236][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:23,237][root][INFO] - LLM usage: prompt_tokens = 6968, completion_tokens = 3733
[2025-04-27 03:33:23,240][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:24,943][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:24,946][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:24,947][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:24,947][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:24,950][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:24,951][root][INFO] - LLM usage: prompt_tokens = 7530, completion_tokens = 3828
[2025-04-27 03:33:24,954][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:27,702][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:27,705][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:27,706][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:27,707][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:27,710][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:27,711][root][INFO] - LLM usage: prompt_tokens = 8076, completion_tokens = 3954
[2025-04-27 03:33:27,714][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:33:30,506][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:33:30,509][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:33:30,510][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:30,510][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:30,512][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:33:30,514][root][INFO] - LLM usage: prompt_tokens = 8612, completion_tokens = 4096
[2025-04-27 03:33:30,534][root][INFO] - Iteration 0: Running Code 2428239458541079006
[2025-04-27 03:33:30,693][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:30,694][root][INFO] - Iteration 0: Running Code 5779955455625094674
[2025-04-27 03:33:30,849][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:30,850][root][INFO] - Iteration 0: Running Code -5840577009134266670
[2025-04-27 03:33:31,025][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:31,026][root][INFO] - Iteration 0: Running Code 4266137048407614738
[2025-04-27 03:33:31,165][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:31,165][root][INFO] - Iteration 0: Running Code 4434356290042113393
[2025-04-27 03:33:31,320][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:31,321][root][INFO] - Iteration 0: Running Code -1519430134133825445
[2025-04-27 03:33:31,482][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:31,483][root][INFO] - Iteration 0: Running Code -6432581968791002841
[2025-04-27 03:33:31,662][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:31,664][root][INFO] - Iteration 0: Running Code 4327923825939564884
[2025-04-27 03:33:31,996][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:31,997][root][INFO] - Iteration 0: Running Code -8615309204651641223
[2025-04-27 03:33:32,591][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:33:32,634][root][INFO] - Iteration 0: Running Code -643152441596998377
[2025-04-27 03:33:33,926][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:34:23,978][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999670000034 seconds
[2025-04-27 03:35:13,994][root][ERROR] - Timeout for response_id 1: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999750000006 seconds
[2025-04-27 03:35:13,997][root][INFO] - Iteration 0, response_id 2: Objective value: 4.048663741523748
[2025-04-27 03:35:13,999][root][INFO] - Iteration 0, response_id 3: Objective value: 4.048663741523748
[2025-04-27 03:35:14,000][root][INFO] - Iteration 0, response_id 4: Objective value: 4.048663741523748
[2025-04-27 03:35:14,001][root][INFO] - Iteration 0, response_id 5: Objective value: 4.048663741523748
[2025-04-27 03:35:14,004][root][INFO] - Iteration 0, response_id 6: Objective value: 4.048663741523748
[2025-04-27 03:36:04,015][root][ERROR] - Timeout for response_id 7: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999800000023 seconds
[2025-04-27 03:36:04,018][root][INFO] - Iteration 0, response_id 8: Objective value: 4.048663741523748
[2025-04-27 03:36:04,028][root][INFO] - Iteration 0, response_id 9: Objective value: 76.4260071798963
[2025-04-27 03:36:04,030][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:07,490][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:07,493][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:07,495][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:07,495][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:07,497][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:07,499][root][INFO] - LLM usage: prompt_tokens = 9196, completion_tokens = 4340
[2025-04-27 03:36:07,500][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:10,559][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:10,562][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:10,564][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:10,564][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:10,567][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:10,569][root][INFO] - LLM usage: prompt_tokens = 9762, completion_tokens = 4505
[2025-04-27 03:36:10,570][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:13,302][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:13,305][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:13,306][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:13,307][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:13,309][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:13,310][root][INFO] - LLM usage: prompt_tokens = 10313, completion_tokens = 4640
[2025-04-27 03:36:13,313][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:16,015][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:16,018][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:16,019][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:16,019][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:16,022][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:16,023][root][INFO] - LLM usage: prompt_tokens = 10890, completion_tokens = 4776
[2025-04-27 03:36:16,025][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:17,927][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:17,930][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:17,931][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:17,931][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:17,934][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:17,935][root][INFO] - LLM usage: prompt_tokens = 11467, completion_tokens = 4916
[2025-04-27 03:36:17,937][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:20,775][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:20,778][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:20,780][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:20,780][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:20,783][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:20,784][root][INFO] - LLM usage: prompt_tokens = 12010, completion_tokens = 5085
[2025-04-27 03:36:20,787][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:23,309][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:23,311][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:23,312][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:23,312][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:23,314][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:23,315][root][INFO] - LLM usage: prompt_tokens = 12539, completion_tokens = 5197
[2025-04-27 03:36:23,316][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:25,183][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:25,186][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:25,187][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:25,188][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:25,191][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:25,192][root][INFO] - LLM usage: prompt_tokens = 13090, completion_tokens = 5337
[2025-04-27 03:36:25,195][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:27,654][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:27,658][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:27,659][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:27,659][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:27,662][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:27,664][root][INFO] - LLM usage: prompt_tokens = 13663, completion_tokens = 5538
[2025-04-27 03:36:27,666][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:36:30,190][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:36:30,192][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:36:30,193][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:30,193][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:30,195][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:36:30,196][root][INFO] - LLM usage: prompt_tokens = 14203, completion_tokens = 5643
[2025-04-27 03:36:30,214][root][INFO] - Iteration 0: Running Code -1153853169602703538
[2025-04-27 03:36:30,388][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:30,389][root][INFO] - Iteration 0: Running Code -1486988830483162976
[2025-04-27 03:36:30,545][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:30,545][root][INFO] - Iteration 0: Running Code 3878918094919359760
[2025-04-27 03:36:30,700][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:30,701][root][INFO] - Iteration 0: Running Code 8906372933494160949
[2025-04-27 03:36:30,862][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:30,863][root][INFO] - Iteration 0: Running Code 6146821474112607034
[2025-04-27 03:36:31,040][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:31,041][root][INFO] - Iteration 0: Running Code -7713248975156226936
[2025-04-27 03:36:31,241][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:31,245][root][INFO] - Iteration 0: Running Code -705784449445437795
[2025-04-27 03:36:31,737][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:31,765][root][INFO] - Iteration 0: Running Code -5688746347684092134
[2025-04-27 03:36:32,433][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:32,449][root][INFO] - Iteration 0: Running Code -6431336278591731023
[2025-04-27 03:36:33,063][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:36:33,085][root][INFO] - Iteration 0: Running Code -7788159329517768015
[2025-04-27 03:36:34,172][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:37:24,251][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999630000002 seconds
[2025-04-27 03:38:14,289][root][ERROR] - Timeout for response_id 1: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999993899999936 seconds
[2025-04-27 03:38:14,292][root][INFO] - Iteration 0, response_id 2: Objective value: 4.048663741523748
[2025-04-27 03:38:14,293][root][INFO] - Iteration 0, response_id 3: Objective value: 4.048663741523748
[2025-04-27 03:39:04,298][root][ERROR] - Timeout for response_id 4: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999690000004 seconds
[2025-04-27 03:39:54,298][root][ERROR] - Timeout for response_id 5: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999509999998 seconds
[2025-04-27 03:39:54,300][root][INFO] - Iteration 0, response_id 6: Objective value: 4.048663741523748
[2025-04-27 03:40:44,303][root][ERROR] - Timeout for response_id 7: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999690000004 seconds
[2025-04-27 03:41:34,305][root][ERROR] - Timeout for response_id 8: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.9999928999996 seconds
[2025-04-27 03:41:34,308][root][INFO] - Iteration 0, response_id 9: Objective value: 4.048663741523748
[2025-04-27 03:41:34,311][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:37,321][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:37,325][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:37,325][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:37,326][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:37,329][root][INFO] - LLM usage: prompt_tokens = 14600, completion_tokens = 5792
[2025-04-27 03:41:37,328][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:37,330][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:40,061][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:40,065][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:40,066][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:40,066][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:40,068][root][INFO] - LLM usage: prompt_tokens = 14971, completion_tokens = 5917
[2025-04-27 03:41:40,068][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:40,069][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:43,097][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:43,100][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:43,102][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:43,102][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:43,105][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:43,106][root][INFO] - LLM usage: prompt_tokens = 15368, completion_tokens = 6087
[2025-04-27 03:41:43,108][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:46,098][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:46,101][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:46,102][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:46,103][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:46,106][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:46,107][root][INFO] - LLM usage: prompt_tokens = 15706, completion_tokens = 6251
[2025-04-27 03:41:46,109][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:49,174][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:49,176][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:49,178][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:49,178][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:49,181][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:49,182][root][INFO] - LLM usage: prompt_tokens = 16044, completion_tokens = 6409
[2025-04-27 03:41:49,185][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:51,663][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:51,667][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:51,668][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:51,668][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:51,670][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:51,671][root][INFO] - LLM usage: prompt_tokens = 16393, completion_tokens = 6517
[2025-04-27 03:41:51,673][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:54,498][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:54,502][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:54,503][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:54,504][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:54,507][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:54,509][root][INFO] - LLM usage: prompt_tokens = 16774, completion_tokens = 6775
[2025-04-27 03:41:54,511][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:41:57,280][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:41:57,283][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:41:57,285][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:57,285][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:57,288][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:41:57,289][root][INFO] - LLM usage: prompt_tokens = 17130, completion_tokens = 6905
[2025-04-27 03:41:57,291][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:42:00,067][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:42:00,071][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:42:00,072][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:42:00,072][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:42:00,075][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:42:00,076][root][INFO] - LLM usage: prompt_tokens = 17479, completion_tokens = 7055
[2025-04-27 03:42:00,078][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:42:03,019][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:42:03,022][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:42:03,024][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:42:03,024][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:42:03,026][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:42:03,029][root][INFO] - LLM usage: prompt_tokens = 17876, completion_tokens = 7193
[2025-04-27 03:42:03,045][root][INFO] - Iteration 0: Running Code -7756319518314296719
[2025-04-27 03:42:03,215][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:42:03,216][root][INFO] - Iteration 0: Running Code -1067658997193703095
[2025-04-27 03:42:03,354][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:42:03,354][root][INFO] - Iteration 0: Running Code -5412792792602827234
[2025-04-27 03:42:03,504][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:42:03,504][root][INFO] - Iteration 0: Running Code -8834957796532182290
[2025-04-27 03:42:03,635][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:42:03,635][root][INFO] - Iteration 0: Running Code 8411362588712836107
[2025-04-27 03:42:03,785][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:42:03,785][root][INFO] - Iteration 0: Running Code -195760854483294362
[2025-04-27 03:42:03,936][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:42:03,936][root][INFO] - Iteration 0: Running Code -6778112976251736622
[2025-04-27 03:42:04,149][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:42:04,149][root][INFO] - Iteration 0: Running Code -5539612166477188493
[2025-04-27 03:42:04,298][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:42:04,299][root][INFO] - Iteration 0: Running Code 7854863225101753327
[2025-04-27 03:42:04,461][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:42:04,461][root][INFO] - Iteration 0: Running Code 4390939877308932193
[2025-04-27 03:42:04,639][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:42:04,641][root][ERROR] - Traceback for response_id 0: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:42:04,642][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-04-27 03:42:54,647][root][ERROR] - Timeout for response_id 1: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999680000019 seconds
[2025-04-27 03:42:54,649][root][ERROR] - Traceback for response_id 2: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:42:54,650][root][INFO] - Iteration 0, response_id 2: Objective value: inf
[2025-04-27 03:43:17,658][root][INFO] - Iteration 0, response_id 3: Objective value: 4.11846828879138
[2025-04-27 03:43:50,600][root][INFO] - Iteration 0, response_id 4: Objective value: 6.661348224970079
[2025-04-27 03:43:50,602][root][INFO] - Iteration 0, response_id 5: Objective value: 4.048663741523748
[2025-04-27 03:43:50,603][root][ERROR] - Traceback for response_id 6: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:43:50,603][root][INFO] - Iteration 0, response_id 6: Objective value: inf
[2025-04-27 03:43:54,482][root][INFO] - Iteration 0, response_id 7: Objective value: 149.30195452732352
[2025-04-27 03:43:54,484][root][INFO] - Iteration 0, response_id 8: Objective value: 4.048663741523748
[2025-04-27 03:43:54,485][root][INFO] - Iteration 0, response_id 9: Objective value: 4.048663741523748
[2025-04-27 03:43:54,487][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:43:56,633][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:43:56,634][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:43:56,635][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:43:56,635][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:43:56,636][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:43:56,636][root][INFO] - LLM usage: prompt_tokens = 18204, completion_tokens = 7355
[2025-04-27 03:43:56,638][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:43:58,455][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:43:58,458][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:43:58,459][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:43:58,459][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:43:58,462][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:43:58,464][root][INFO] - LLM usage: prompt_tokens = 18592, completion_tokens = 7486
[2025-04-27 03:43:58,466][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:01,369][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:01,372][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:01,373][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:01,373][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:01,376][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:01,378][root][INFO] - LLM usage: prompt_tokens = 18953, completion_tokens = 7633
[2025-04-27 03:44:01,380][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:03,393][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:03,394][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:03,395][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:03,395][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:03,398][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:03,398][root][INFO] - LLM usage: prompt_tokens = 19324, completion_tokens = 7792
[2025-04-27 03:44:03,401][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:05,258][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:05,261][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:05,262][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:05,263][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:05,265][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:05,266][root][INFO] - LLM usage: prompt_tokens = 19663, completion_tokens = 7928
[2025-04-27 03:44:05,269][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:07,151][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:07,154][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:07,155][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:07,156][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:07,158][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:07,159][root][INFO] - LLM usage: prompt_tokens = 20024, completion_tokens = 8070
[2025-04-27 03:44:07,161][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:10,011][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:10,014][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:10,016][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:10,016][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:10,018][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:10,019][root][INFO] - LLM usage: prompt_tokens = 20411, completion_tokens = 8243
[2025-04-27 03:44:10,022][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:11,769][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:11,772][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:11,774][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:11,774][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:11,777][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:11,778][root][INFO] - LLM usage: prompt_tokens = 20739, completion_tokens = 8351
[2025-04-27 03:44:11,780][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:13,893][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:13,896][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:13,898][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:13,898][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:13,901][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:13,902][root][INFO] - LLM usage: prompt_tokens = 21126, completion_tokens = 8516
[2025-04-27 03:44:13,905][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:44:16,429][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:44:16,432][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:44:16,433][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:16,433][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:16,436][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:44:16,437][root][INFO] - LLM usage: prompt_tokens = 21465, completion_tokens = 8616
[2025-04-27 03:44:16,455][root][INFO] - Iteration 0: Running Code 8853058795257368940
[2025-04-27 03:44:16,622][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:44:16,623][root][INFO] - Iteration 0: Running Code 2825139141688452484
[2025-04-27 03:44:16,774][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:44:16,775][root][INFO] - Iteration 0: Running Code -3120742467314257470
[2025-04-27 03:44:16,938][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:44:16,939][root][INFO] - Iteration 0: Running Code -1689661046301357119
[2025-04-27 03:44:17,090][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:44:17,090][root][INFO] - Iteration 0: Running Code -7195179165489433403
[2025-04-27 03:44:17,256][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:44:17,256][root][INFO] - Iteration 0: Running Code 1288176763686230368
[2025-04-27 03:44:17,410][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:44:17,410][root][INFO] - Iteration 0: Running Code -1761935122009662820
[2025-04-27 03:44:17,571][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:44:17,572][root][INFO] - Iteration 0: Running Code -8150292914961328711
[2025-04-27 03:44:17,719][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:44:17,719][root][INFO] - Iteration 0: Running Code 4474944725951652835
[2025-04-27 03:44:17,885][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:44:17,885][root][INFO] - Iteration 0: Running Code -556786802261779012
[2025-04-27 03:44:18,074][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:45:08,082][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999996999999894 seconds
[2025-04-27 03:45:08,085][root][ERROR] - Traceback for response_id 1: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:45:08,086][root][INFO] - Iteration 0, response_id 1: Objective value: inf
[2025-04-27 03:45:08,087][root][ERROR] - Traceback for response_id 2: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:45:08,087][root][INFO] - Iteration 0, response_id 2: Objective value: inf
[2025-04-27 03:45:45,865][root][INFO] - Iteration 0, response_id 3: Objective value: 149.30195452732352
[2025-04-27 03:46:04,827][root][INFO] - Iteration 0, response_id 4: Objective value: 5.10570402871959
[2025-04-27 03:46:04,829][root][ERROR] - Traceback for response_id 5: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:46:04,829][root][INFO] - Iteration 0, response_id 5: Objective value: inf
[2025-04-27 03:46:04,831][root][INFO] - Iteration 0, response_id 6: Objective value: 4.487435181491823
[2025-04-27 03:46:54,833][root][ERROR] - Timeout for response_id 7: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999670000034 seconds
[2025-04-27 03:46:54,836][root][INFO] - Iteration 0, response_id 8: Objective value: 4.9760670123653865
[2025-04-27 03:46:54,838][root][ERROR] - Traceback for response_id 9: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:46:54,839][root][INFO] - Iteration 0, response_id 9: Objective value: inf
[2025-04-27 03:46:54,842][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:46:57,697][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:46:57,711][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:46:57,712][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:46:57,712][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:46:57,715][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:46:57,715][root][INFO] - LLM usage: prompt_tokens = 21961, completion_tokens = 8754
[2025-04-27 03:46:57,718][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:46:59,687][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:46:59,690][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:46:59,691][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:46:59,691][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:46:59,694][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:46:59,695][root][INFO] - LLM usage: prompt_tokens = 22505, completion_tokens = 8880
[2025-04-27 03:46:59,697][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:01,717][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:01,721][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:01,722][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:01,722][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:01,726][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:01,726][root][INFO] - LLM usage: prompt_tokens = 23083, completion_tokens = 9029
[2025-04-27 03:47:01,729][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:03,894][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:03,897][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:03,898][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:03,898][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:03,901][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:03,903][root][INFO] - LLM usage: prompt_tokens = 23597, completion_tokens = 9201
[2025-04-27 03:47:03,905][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:06,618][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:06,621][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:06,623][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:06,623][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:06,626][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:06,628][root][INFO] - LLM usage: prompt_tokens = 24175, completion_tokens = 9321
[2025-04-27 03:47:06,629][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:08,857][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:08,858][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:08,859][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:08,860][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:08,861][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:08,863][root][INFO] - LLM usage: prompt_tokens = 24761, completion_tokens = 9483
[2025-04-27 03:47:08,864][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:11,492][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:11,495][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:11,496][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:11,496][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:11,498][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:11,499][root][INFO] - LLM usage: prompt_tokens = 25338, completion_tokens = 9591
[2025-04-27 03:47:11,501][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:13,604][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:13,606][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:13,608][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:13,608][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:13,611][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:13,613][root][INFO] - LLM usage: prompt_tokens = 25894, completion_tokens = 9738
[2025-04-27 03:47:13,615][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:16,280][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:16,283][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:16,284][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:16,285][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:16,287][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:16,288][root][INFO] - LLM usage: prompt_tokens = 26480, completion_tokens = 9839
[2025-04-27 03:47:16,291][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:47:18,992][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:47:18,996][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:47:18,997][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:18,997][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:19,000][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:47:19,001][root][INFO] - LLM usage: prompt_tokens = 27057, completion_tokens = 9954
[2025-04-27 03:47:19,022][root][INFO] - Iteration 0: Running Code 2120768181144469734
[2025-04-27 03:47:19,183][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:19,184][root][INFO] - Iteration 0: Running Code 5460869858790551421
[2025-04-27 03:47:19,325][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:19,325][root][INFO] - Iteration 0: Running Code 1537611050002846559
[2025-04-27 03:47:19,479][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:19,479][root][INFO] - Iteration 0: Running Code -4719276621440430763
[2025-04-27 03:47:19,639][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:19,639][root][INFO] - Iteration 0: Running Code -2472498001906593889
[2025-04-27 03:47:19,794][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:19,794][root][INFO] - Iteration 0: Running Code 4242687431900337054
[2025-04-27 03:47:19,952][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:19,953][root][INFO] - Iteration 0: Running Code -2037897244633305409
[2025-04-27 03:47:20,136][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:20,139][root][INFO] - Iteration 0: Running Code 5684824165647998017
[2025-04-27 03:47:20,459][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:20,461][root][INFO] - Iteration 0: Running Code -7154237584130179146
[2025-04-27 03:47:21,128][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:47:21,168][root][INFO] - Iteration 0: Running Code -5436319832631383425
[2025-04-27 03:47:21,998][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:48:12,044][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999997100000655 seconds
[2025-04-27 03:48:58,361][root][INFO] - Iteration 0, response_id 1: Objective value: 4.487435181491823
[2025-04-27 03:48:58,370][root][INFO] - Iteration 0, response_id 2: Objective value: 3.839250099720782
[2025-04-27 03:48:58,372][root][INFO] - Iteration 0, response_id 3: Objective value: 4.048663741523748
[2025-04-27 03:48:58,373][root][INFO] - Iteration 0, response_id 4: Objective value: 4.048663741523748
[2025-04-27 03:49:25,546][root][INFO] - Iteration 0, response_id 5: Objective value: 149.1822895891504
[2025-04-27 03:49:25,547][root][INFO] - Iteration 0, response_id 6: Objective value: 149.30195452732352
[2025-04-27 03:49:27,973][root][INFO] - Iteration 0, response_id 7: Objective value: 149.30195452732352
[2025-04-27 03:49:27,975][root][INFO] - Iteration 0, response_id 8: Objective value: 4.487435181491823
[2025-04-27 03:49:27,977][root][INFO] - Iteration 0, response_id 9: Objective value: 4.048663741523748
[2025-04-27 03:49:27,980][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:30,776][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:30,779][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:30,781][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:30,781][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:30,784][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:30,785][root][INFO] - LLM usage: prompt_tokens = 27656, completion_tokens = 10095
[2025-04-27 03:49:30,787][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:32,463][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:32,466][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:32,467][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:32,467][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:32,470][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:32,472][root][INFO] - LLM usage: prompt_tokens = 28192, completion_tokens = 10195
[2025-04-27 03:49:32,473][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:34,425][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:34,428][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:34,430][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:34,430][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:34,434][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:34,434][root][INFO] - LLM usage: prompt_tokens = 28802, completion_tokens = 10337
[2025-04-27 03:49:34,437][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:38,426][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:38,429][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:38,431][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:38,431][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:38,434][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:38,436][root][INFO] - LLM usage: prompt_tokens = 29386, completion_tokens = 10697
[2025-04-27 03:49:38,438][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:41,504][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:41,506][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:41,507][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:41,507][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:41,509][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:41,510][root][INFO] - LLM usage: prompt_tokens = 30029, completion_tokens = 10868
[2025-04-27 03:49:41,511][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:44,802][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:44,805][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:44,807][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:44,807][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:44,808][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:44,810][root][INFO] - LLM usage: prompt_tokens = 30639, completion_tokens = 11063
[2025-04-27 03:49:44,812][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:47,668][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:47,671][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:47,672][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:47,673][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:47,675][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:47,677][root][INFO] - LLM usage: prompt_tokens = 31216, completion_tokens = 11197
[2025-04-27 03:49:47,679][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:50,603][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:50,606][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:50,607][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:50,608][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:50,610][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:50,611][root][INFO] - LLM usage: prompt_tokens = 31841, completion_tokens = 11345
[2025-04-27 03:49:50,614][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:52,790][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:52,793][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:52,795][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:52,795][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:52,797][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:52,798][root][INFO] - LLM usage: prompt_tokens = 32413, completion_tokens = 11489
[2025-04-27 03:49:52,800][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:49:54,836][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:49:54,838][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:49:54,840][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:54,840][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:54,842][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:49:54,845][root][INFO] - LLM usage: prompt_tokens = 33039, completion_tokens = 11646
[2025-04-27 03:49:54,856][root][INFO] - Iteration 0: Running Code -8833163344887711024
[2025-04-27 03:49:55,017][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:55,017][root][INFO] - Iteration 0: Running Code 3365404875967634432
[2025-04-27 03:49:55,179][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:55,179][root][INFO] - Iteration 0: Running Code 8436746753691809773
[2025-04-27 03:49:55,321][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:55,321][root][INFO] - Iteration 0: Running Code -3177419887279448581
[2025-04-27 03:49:55,464][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:55,464][root][INFO] - Iteration 0: Running Code -8805668111433160188
[2025-04-27 03:49:55,625][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:55,625][root][INFO] - Iteration 0: Running Code 266462732088394124
[2025-04-27 03:49:55,793][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:55,794][root][INFO] - Iteration 0: Running Code 8001917691274797685
[2025-04-27 03:49:55,973][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:55,974][root][INFO] - Iteration 0: Running Code -1027646298948851852
[2025-04-27 03:49:56,297][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:56,311][root][INFO] - Iteration 0: Running Code 8255541079242142274
[2025-04-27 03:49:56,837][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:49:56,872][root][INFO] - Iteration 0: Running Code 6595871854242921541
[2025-04-27 03:49:58,142][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:50:48,194][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999997099999746 seconds
[2025-04-27 03:51:38,236][root][ERROR] - Timeout for response_id 1: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999720000051 seconds
[2025-04-27 03:52:28,262][root][ERROR] - Timeout for response_id 2: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999740000021 seconds
[2025-04-27 03:52:58,480][root][INFO] - Iteration 0, response_id 3: Objective value: 5.055843637814125
[2025-04-27 03:52:58,482][root][INFO] - Iteration 0, response_id 4: Objective value: 4.048663741523748
[2025-04-27 03:52:58,493][root][INFO] - Iteration 0, response_id 5: Objective value: 5.993218986836871
[2025-04-27 03:52:58,505][root][INFO] - Iteration 0, response_id 6: Objective value: 13.901076984443566
[2025-04-27 03:52:58,507][root][INFO] - Iteration 0, response_id 7: Objective value: 4.487435181491823
[2025-04-27 03:52:58,520][root][INFO] - Iteration 0, response_id 8: Objective value: 4.98603909054647
[2025-04-27 03:52:58,522][root][INFO] - Iteration 0, response_id 9: Objective value: 7.947746310331078
[2025-04-27 03:52:58,525][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:01,505][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:01,508][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:01,510][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:01,510][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:01,513][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:01,514][root][INFO] - LLM usage: prompt_tokens = 33414, completion_tokens = 11815
[2025-04-27 03:53:01,516][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:03,740][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:03,743][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:03,744][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:03,745][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:03,747][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:03,749][root][INFO] - LLM usage: prompt_tokens = 33811, completion_tokens = 12018
[2025-04-27 03:53:03,751][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:06,050][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:06,052][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:06,054][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:06,054][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:06,056][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:06,057][root][INFO] - LLM usage: prompt_tokens = 34186, completion_tokens = 12204
[2025-04-27 03:53:06,060][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:07,950][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:07,952][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:07,953][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:07,953][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:07,954][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:07,956][root][INFO] - LLM usage: prompt_tokens = 34554, completion_tokens = 12348
[2025-04-27 03:53:07,958][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:10,047][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:10,051][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:10,052][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:10,052][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:10,056][root][INFO] - LLM usage: prompt_tokens = 34969, completion_tokens = 12520
[2025-04-27 03:53:10,055][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:10,057][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:12,215][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:12,218][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:12,220][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:12,220][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:12,222][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:12,226][root][INFO] - LLM usage: prompt_tokens = 35351, completion_tokens = 12707
[2025-04-27 03:53:12,228][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:15,280][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:15,283][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:15,284][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:15,284][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:15,287][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:15,288][root][INFO] - LLM usage: prompt_tokens = 35733, completion_tokens = 12897
[2025-04-27 03:53:15,290][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:18,520][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:18,523][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:18,524][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:18,524][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:18,526][root][INFO] - LLM usage: prompt_tokens = 36115, completion_tokens = 13123
[2025-04-27 03:53:18,526][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:18,527][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:21,741][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:21,744][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:21,746][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:21,746][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:21,749][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:21,751][root][INFO] - LLM usage: prompt_tokens = 36707, completion_tokens = 13371
[2025-04-27 03:53:21,753][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:53:24,329][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:53:24,332][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:53:24,333][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:24,334][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:24,337][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:53:24,338][root][INFO] - LLM usage: prompt_tokens = 37077, completion_tokens = 13506
[2025-04-27 03:53:24,350][root][INFO] - Iteration 0: Running Code 9062477511661309299
[2025-04-27 03:53:24,507][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:24,508][root][INFO] - Iteration 0: Running Code -7990633131463859052
[2025-04-27 03:53:24,660][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:24,660][root][INFO] - Iteration 0: Running Code 8304930306111390750
[2025-04-27 03:53:24,816][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:24,817][root][INFO] - Iteration 0: Running Code -5124328728450747355
[2025-04-27 03:53:24,978][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:53:24,978][root][INFO] - Iteration 0: Running Code -1718844858182636604
[2025-04-27 03:53:25,123][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:25,123][root][INFO] - Iteration 0: Running Code -5490988118190852132
[2025-04-27 03:53:25,284][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:25,284][root][INFO] - Iteration 0: Running Code 2176541208834664593
[2025-04-27 03:53:25,449][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:25,449][root][INFO] - Iteration 0: Running Code 9130695515397511898
[2025-04-27 03:53:25,631][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:25,632][root][INFO] - Iteration 0: Running Code -4534680356953624283
[2025-04-27 03:53:25,945][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:53:25,967][root][INFO] - Iteration 0: Running Code -8528242923171397402
[2025-04-27 03:53:26,435][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:54:16,478][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999997099999746 seconds
[2025-04-27 03:55:06,501][root][ERROR] - Timeout for response_id 1: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999730000127 seconds
[2025-04-27 03:55:22,412][root][INFO] - Iteration 0, response_id 2: Objective value: 4.048663741523748
[2025-04-27 03:55:22,413][root][ERROR] - Traceback for response_id 3: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:55:22,414][root][INFO] - Iteration 0, response_id 3: Objective value: inf
[2025-04-27 03:55:44,584][root][INFO] - Iteration 0, response_id 4: Objective value: 4.048663741523748
[2025-04-27 03:55:44,593][root][INFO] - Iteration 0, response_id 5: Objective value: 4.2181890706023095
[2025-04-27 03:55:47,305][root][INFO] - Iteration 0, response_id 6: Objective value: 4.048663741523748
[2025-04-27 03:55:47,315][root][INFO] - Iteration 0, response_id 7: Objective value: 59.403669724770644
[2025-04-27 03:56:30,689][root][INFO] - Iteration 0, response_id 8: Objective value: 4.048663741523748
[2025-04-27 03:56:30,691][root][INFO] - Iteration 0, response_id 9: Objective value: 4.048663741523748
[2025-04-27 03:56:30,693][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:33,557][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:33,560][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:33,561][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:33,561][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:33,564][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:33,566][root][INFO] - LLM usage: prompt_tokens = 37464, completion_tokens = 13647
[2025-04-27 03:56:33,568][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:36,210][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:36,213][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:36,214][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:36,214][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:36,217][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:36,217][root][INFO] - LLM usage: prompt_tokens = 37836, completion_tokens = 13776
[2025-04-27 03:56:36,221][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:38,387][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:38,390][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:38,391][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:38,392][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:38,396][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:38,397][root][INFO] - LLM usage: prompt_tokens = 38252, completion_tokens = 13962
[2025-04-27 03:56:38,399][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:41,284][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:41,287][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:41,288][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:41,289][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:41,291][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:41,291][root][INFO] - LLM usage: prompt_tokens = 38639, completion_tokens = 14119
[2025-04-27 03:56:41,292][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:44,300][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:44,303][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:44,305][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:44,305][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:44,308][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:44,309][root][INFO] - LLM usage: prompt_tokens = 39026, completion_tokens = 14306
[2025-04-27 03:56:44,311][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:46,641][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:46,644][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:46,645][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:46,646][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:46,649][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:46,650][root][INFO] - LLM usage: prompt_tokens = 39431, completion_tokens = 14468
[2025-04-27 03:56:46,652][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:49,442][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:49,445][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:49,447][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:49,447][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:49,450][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:49,451][root][INFO] - LLM usage: prompt_tokens = 39818, completion_tokens = 14594
[2025-04-27 03:56:49,453][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:52,356][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:52,359][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:52,360][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:52,361][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:52,364][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:52,365][root][INFO] - LLM usage: prompt_tokens = 40190, completion_tokens = 14755
[2025-04-27 03:56:52,368][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:55,143][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:55,147][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:55,148][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:55,149][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:55,150][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:55,151][root][INFO] - LLM usage: prompt_tokens = 40562, completion_tokens = 14899
[2025-04-27 03:56:55,152][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:56:57,123][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:56:57,126][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:56:57,127][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:57,127][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:57,128][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:56:57,129][root][INFO] - LLM usage: prompt_tokens = 40922, completion_tokens = 15021
[2025-04-27 03:56:57,143][root][INFO] - Iteration 0: Running Code 7655712645449300006
[2025-04-27 03:56:57,299][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:56:57,299][root][INFO] - Iteration 0: Running Code -7926817589791143248
[2025-04-27 03:56:57,462][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:56:57,462][root][INFO] - Iteration 0: Running Code -8080204917345421352
[2025-04-27 03:56:57,612][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:56:57,612][root][INFO] - Iteration 0: Running Code 1418378602176780334
[2025-04-27 03:56:57,764][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:56:57,764][root][INFO] - Iteration 0: Running Code -5618974957100754313
[2025-04-27 03:56:57,914][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:56:57,914][root][INFO] - Iteration 0: Running Code -1250717165932786036
[2025-04-27 03:56:58,064][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:56:58,064][root][INFO] - Iteration 0: Running Code -4161713012038686576
[2025-04-27 03:56:58,219][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:56:58,219][root][INFO] - Iteration 0: Running Code -7655631146316677800
[2025-04-27 03:56:58,387][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:56:58,388][root][INFO] - Iteration 0: Running Code -778216371463727986
[2025-04-27 03:56:58,571][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:56:58,571][root][INFO] - Iteration 0: Running Code 8311844123426010804
[2025-04-27 03:56:58,771][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:57:48,775][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999670000034 seconds
[2025-04-27 03:57:48,777][root][ERROR] - Traceback for response_id 1: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:57:48,777][root][INFO] - Iteration 0, response_id 1: Objective value: inf
[2025-04-27 03:58:02,610][root][INFO] - Iteration 0, response_id 2: Objective value: 4.716792979656956
[2025-04-27 03:58:52,618][root][ERROR] - Timeout for response_id 3: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999580000076 seconds
[2025-04-27 03:58:52,620][root][INFO] - Iteration 0, response_id 4: Objective value: 4.487435181491823
[2025-04-27 03:58:52,623][root][ERROR] - Traceback for response_id 5: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:58:52,623][root][INFO] - Iteration 0, response_id 5: Objective value: inf
[2025-04-27 03:58:52,626][root][INFO] - Iteration 0, response_id 6: Objective value: 4.048663741523748
[2025-04-27 03:58:52,638][root][INFO] - Iteration 0, response_id 7: Objective value: 7.289589150378953
[2025-04-27 03:58:52,640][root][ERROR] - Traceback for response_id 8: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:58:52,641][root][INFO] - Iteration 0, response_id 8: Objective value: inf
[2025-04-27 03:58:52,643][root][ERROR] - Traceback for response_id 9: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 03:58:52,643][root][INFO] - Iteration 0, response_id 9: Objective value: inf
[2025-04-27 03:58:52,648][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:58:55,696][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:58:55,699][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:58:55,700][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:58:55,700][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:58:55,703][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:58:55,705][root][INFO] - LLM usage: prompt_tokens = 41749, completion_tokens = 15175
[2025-04-27 03:58:55,707][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:58:57,707][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:58:57,709][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:58:57,711][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:58:57,711][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:58:57,714][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:58:57,715][root][INFO] - LLM usage: prompt_tokens = 42352, completion_tokens = 15302
[2025-04-27 03:58:57,718][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:01,408][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:01,411][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:01,412][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:01,412][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:01,415][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:01,417][root][INFO] - LLM usage: prompt_tokens = 43013, completion_tokens = 15561
[2025-04-27 03:59:01,419][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:03,285][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:03,290][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:03,292][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:03,292][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:03,295][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:03,296][root][INFO] - LLM usage: prompt_tokens = 43575, completion_tokens = 15659
[2025-04-27 03:59:03,299][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:06,254][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:06,257][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:06,259][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:06,259][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:06,262][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:06,264][root][INFO] - LLM usage: prompt_tokens = 44148, completion_tokens = 15794
[2025-04-27 03:59:06,266][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:08,583][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:08,586][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:08,587][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:08,588][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:08,591][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:08,592][root][INFO] - LLM usage: prompt_tokens = 44751, completion_tokens = 15975
[2025-04-27 03:59:08,594][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:11,207][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:11,210][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:11,212][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:11,212][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:11,215][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:11,217][root][INFO] - LLM usage: prompt_tokens = 45354, completion_tokens = 16205
[2025-04-27 03:59:11,219][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:13,899][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:13,902][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:13,904][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:13,904][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:13,906][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:13,907][root][INFO] - LLM usage: prompt_tokens = 45957, completion_tokens = 16325
[2025-04-27 03:59:13,910][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:16,581][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:16,585][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:16,586][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:16,586][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:16,589][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:16,590][root][INFO] - LLM usage: prompt_tokens = 46534, completion_tokens = 16447
[2025-04-27 03:59:16,593][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 03:59:18,770][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 03:59:18,774][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 03:59:18,775][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:18,775][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:18,779][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 03:59:18,780][root][INFO] - LLM usage: prompt_tokens = 47166, completion_tokens = 16629
[2025-04-27 03:59:18,803][root][INFO] - Iteration 0: Running Code -4988358940856022447
[2025-04-27 03:59:18,960][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:18,961][root][INFO] - Iteration 0: Running Code -8696422346118761204
[2025-04-27 03:59:19,121][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:19,121][root][INFO] - Iteration 0: Running Code -2974964528523467462
[2025-04-27 03:59:19,258][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:19,258][root][INFO] - Iteration 0: Running Code -4933565813008911491
[2025-04-27 03:59:19,411][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:19,412][root][INFO] - Iteration 0: Running Code -8246912894138856117
[2025-04-27 03:59:19,568][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 03:59:19,569][root][INFO] - Iteration 0: Running Code 3025560784174211106
[2025-04-27 03:59:19,721][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:19,722][root][INFO] - Iteration 0: Running Code -4118101900159831428
[2025-04-27 03:59:19,886][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:19,886][root][INFO] - Iteration 0: Running Code 4589951201404270381
[2025-04-27 03:59:20,069][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:20,071][root][INFO] - Iteration 0: Running Code -4239613115474389267
[2025-04-27 03:59:20,469][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 03:59:20,494][root][INFO] - Iteration 0: Running Code 1702835875489163884
[2025-04-27 03:59:21,190][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:00:11,207][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999996999998984 seconds
[2025-04-27 04:00:27,286][root][INFO] - Iteration 0, response_id 1: Objective value: 4.487435181491823
[2025-04-27 04:01:17,289][root][ERROR] - Timeout for response_id 2: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999750000097 seconds
[2025-04-27 04:01:17,292][root][INFO] - Iteration 0, response_id 3: Objective value: 4.048663741523748
[2025-04-27 04:01:17,305][root][ERROR] - Traceback for response_id 4: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
  File "C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py", line 2
    priority = []
IndentationError: unexpected indent

[2025-04-27 04:01:17,306][root][INFO] - Iteration 0, response_id 4: Objective value: inf
[2025-04-27 04:02:07,309][root][ERROR] - Timeout for response_id 5: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.9999945999989 seconds
[2025-04-27 04:02:07,313][root][INFO] - Iteration 0, response_id 6: Objective value: 4.487435181491823
[2025-04-27 04:02:07,315][root][INFO] - Iteration 0, response_id 7: Objective value: 30.943358595931393
[2025-04-27 04:02:07,316][root][INFO] - Iteration 0, response_id 8: Objective value: 4.048663741523748
[2025-04-27 04:02:57,324][root][ERROR] - Timeout for response_id 9: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999770000068 seconds
[2025-04-27 04:02:57,326][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:00,413][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:00,428][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:00,429][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:00,429][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:00,431][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:00,433][root][INFO] - LLM usage: prompt_tokens = 47827, completion_tokens = 16780
[2025-04-27 04:03:00,434][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:03,508][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:03,511][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:03,513][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:03,513][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:03,516][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:03,516][root][INFO] - LLM usage: prompt_tokens = 48452, completion_tokens = 16956
[2025-04-27 04:03:03,519][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:06,761][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:06,764][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:06,766][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:06,766][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:06,769][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:06,771][root][INFO] - LLM usage: prompt_tokens = 48981, completion_tokens = 17151
[2025-04-27 04:03:06,772][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:09,248][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:09,250][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:09,251][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:09,252][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:09,254][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:09,256][root][INFO] - LLM usage: prompt_tokens = 49606, completion_tokens = 17352
[2025-04-27 04:03:09,259][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:12,246][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:12,250][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:12,251][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:12,251][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:12,254][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:12,255][root][INFO] - LLM usage: prompt_tokens = 50183, completion_tokens = 17510
[2025-04-27 04:03:12,257][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:15,393][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:15,396][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:15,397][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:15,397][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:15,399][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:15,402][root][INFO] - LLM usage: prompt_tokens = 50811, completion_tokens = 17691
[2025-04-27 04:03:15,404][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:18,051][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:18,088][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:18,089][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:18,090][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:18,092][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:18,094][root][INFO] - LLM usage: prompt_tokens = 51450, completion_tokens = 17974
[2025-04-27 04:03:18,096][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:21,140][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:21,144][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:21,145][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:21,145][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:21,148][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:21,149][root][INFO] - LLM usage: prompt_tokens = 52093, completion_tokens = 18147
[2025-04-27 04:03:21,151][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:24,297][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:24,301][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:24,302][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:24,302][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:24,306][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:24,306][root][INFO] - LLM usage: prompt_tokens = 52699, completion_tokens = 18350
[2025-04-27 04:03:24,309][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:03:27,849][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:03:27,852][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:03:27,853][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:27,854][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:27,855][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:03:27,857][root][INFO] - LLM usage: prompt_tokens = 53519, completion_tokens = 18586
[2025-04-27 04:03:27,869][root][INFO] - Iteration 0: Running Code 4871722771243416635
[2025-04-27 04:03:28,034][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:28,034][root][INFO] - Iteration 0: Running Code 5982971002780007168
[2025-04-27 04:03:28,194][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:28,194][root][INFO] - Iteration 0: Running Code 2739678289881987548
[2025-04-27 04:03:28,338][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:28,339][root][INFO] - Iteration 0: Running Code 3075174788637744315
[2025-04-27 04:03:28,493][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:28,493][root][INFO] - Iteration 0: Running Code 112219561504864236
[2025-04-27 04:03:28,633][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:28,634][root][INFO] - Iteration 0: Running Code 1490345300303914497
[2025-04-27 04:03:28,782][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:28,782][root][INFO] - Iteration 0: Running Code -5251645541997674997
[2025-04-27 04:03:28,949][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:03:28,950][root][INFO] - Iteration 0: Running Code -196287886262602917
[2025-04-27 04:03:29,108][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:29,109][root][INFO] - Iteration 0: Running Code 6011067874154042300
[2025-04-27 04:03:29,285][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:03:29,286][root][INFO] - Iteration 0: Running Code -3608518193673667856
[2025-04-27 04:03:29,474][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:04:19,488][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.99999719999869 seconds
[2025-04-27 04:04:19,501][root][ERROR] - Traceback for response_id 1: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 112, in <module>
    avg_num_bins = -evaluate(dataset)
                    ~~~~~~~~^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 55, in evaluate
    _, bins_packed = online_binpack(items.astype(float), bins)
                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 28, in online_binpack
    priorities = priority(item, bins[valid_bin_indices])
  File "C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py", line 10, in priority_v2
    priority.append(priority_score)
                             ^^^^
NameError: name 'math' is not defined. Did you forget to import 'math'?

[2025-04-27 04:04:19,501][root][INFO] - Iteration 0, response_id 1: Objective value: inf
[2025-04-27 04:05:09,500][root][ERROR] - Timeout for response_id 2: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999997099999746 seconds
[2025-04-27 04:05:09,513][root][INFO] - Iteration 0, response_id 3: Objective value: 6.860789788591938
[2025-04-27 04:05:24,622][root][INFO] - Iteration 0, response_id 4: Objective value: 12.21579577183885
[2025-04-27 04:05:24,634][root][INFO] - Iteration 0, response_id 5: Objective value: 11.437973673713607
[2025-04-27 04:05:24,644][root][ERROR] - Traceback for response_id 6: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
  File "C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py", line 1
    defined target waste range, and adapting the target range dynamically based on the item size.}
                                                                                                 ^
SyntaxError: unmatched '}'

[2025-04-27 04:05:24,645][root][INFO] - Iteration 0, response_id 6: Objective value: inf
[2025-04-27 04:05:24,646][root][INFO] - Iteration 0, response_id 7: Objective value: 4.048663741523748
[2025-04-27 04:05:24,659][root][ERROR] - Traceback for response_id 8: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 112, in <module>
    avg_num_bins = -evaluate(dataset)
                    ~~~~~~~~^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 55, in evaluate
    _, bins_packed = online_binpack(items.astype(float), bins)
                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 28, in online_binpack
    priorities = priority(item, bins[valid_bin_indices])
  File "C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py", line 10, in priority_v2
NameError: name 'exp' is not defined

[2025-04-27 04:05:24,660][root][INFO] - Iteration 0, response_id 8: Objective value: inf
[2025-04-27 04:05:24,669][root][INFO] - Iteration 0, response_id 9: Objective value: 8.326685281212605
[2025-04-27 04:05:24,671][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:27,226][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:27,230][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:27,231][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:27,231][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:27,234][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:27,235][root][INFO] - LLM usage: prompt_tokens = 53868, completion_tokens = 18694
[2025-04-27 04:05:27,238][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:29,965][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:29,968][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:29,969][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:29,969][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:29,972][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:29,973][root][INFO] - LLM usage: prompt_tokens = 54294, completion_tokens = 18800
[2025-04-27 04:05:29,976][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:31,985][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:31,988][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:31,989][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:31,990][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:31,993][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:31,994][root][INFO] - LLM usage: prompt_tokens = 54709, completion_tokens = 18947
[2025-04-27 04:05:31,997][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:33,704][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:33,708][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:33,709][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:33,709][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:33,712][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:33,713][root][INFO] - LLM usage: prompt_tokens = 55058, completion_tokens = 19045
[2025-04-27 04:05:33,716][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:36,570][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:36,572][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:36,574][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:36,574][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:36,577][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:36,578][root][INFO] - LLM usage: prompt_tokens = 55440, completion_tokens = 19200
[2025-04-27 04:05:36,580][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:38,959][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:38,962][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:38,963][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:38,963][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:38,966][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:38,967][root][INFO] - LLM usage: prompt_tokens = 55811, completion_tokens = 19398
[2025-04-27 04:05:38,970][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:42,598][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:42,601][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:42,602][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:42,602][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:42,605][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:42,607][root][INFO] - LLM usage: prompt_tokens = 56403, completion_tokens = 19685
[2025-04-27 04:05:42,609][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:45,741][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:45,744][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:45,745][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:45,746][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:45,748][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:45,749][root][INFO] - LLM usage: prompt_tokens = 56995, completion_tokens = 19895
[2025-04-27 04:05:45,752][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:48,834][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:48,837][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:48,839][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:48,839][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:48,842][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:48,843][root][INFO] - LLM usage: prompt_tokens = 57392, completion_tokens = 20052
[2025-04-27 04:05:48,846][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:05:50,822][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:05:50,824][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:05:50,826][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:50,826][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:50,829][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:05:50,830][root][INFO] - LLM usage: prompt_tokens = 57818, completion_tokens = 20192
[2025-04-27 04:05:50,846][root][INFO] - Iteration 0: Running Code 8925957346407699622
[2025-04-27 04:05:51,005][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:05:51,006][root][INFO] - Iteration 0: Running Code -3545374439997168503
[2025-04-27 04:05:51,159][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:05:51,160][root][INFO] - Iteration 0: Running Code 6673381342842295711
[2025-04-27 04:05:51,304][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:05:51,304][root][INFO] - Iteration 0: Running Code 7751552635671528214
[2025-04-27 04:05:51,447][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:05:51,447][root][INFO] - Iteration 0: Running Code -8821428771005593862
[2025-04-27 04:05:51,597][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:05:51,598][root][INFO] - Iteration 0: Running Code 7792880795564012658
[2025-04-27 04:05:51,753][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:05:51,753][root][INFO] - Iteration 0: Running Code -6464693285628037127
[2025-04-27 04:05:51,923][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:05:51,924][root][INFO] - Iteration 0: Running Code -3420364186146675001
[2025-04-27 04:05:52,104][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:05:52,105][root][INFO] - Iteration 0: Running Code -5113859495028853158
[2025-04-27 04:05:52,590][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:05:52,596][root][INFO] - Iteration 0: Running Code -6766330244291680260
[2025-04-27 04:05:52,991][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:06:41,437][root][INFO] - Iteration 0, response_id 0: Objective value: 4.048663741523748
[2025-04-27 04:06:41,438][root][ERROR] - Traceback for response_id 1: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:06:41,438][root][INFO] - Iteration 0, response_id 1: Objective value: inf
[2025-04-27 04:07:22,364][root][INFO] - Iteration 0, response_id 2: Objective value: 4.048663741523748
[2025-04-27 04:07:22,366][root][INFO] - Iteration 0, response_id 3: Objective value: 149.30195452732352
[2025-04-27 04:07:22,367][root][INFO] - Iteration 0, response_id 4: Objective value: 4.078579976067022
[2025-04-27 04:07:52,214][root][INFO] - Iteration 0, response_id 5: Objective value: 5.743917032309547
[2025-04-27 04:08:07,853][root][INFO] - Iteration 0, response_id 6: Objective value: 4.048663741523748
[2025-04-27 04:08:07,864][root][INFO] - Iteration 0, response_id 7: Objective value: 9.114479457518957
[2025-04-27 04:08:07,867][root][ERROR] - Traceback for response_id 8: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:08:07,867][root][INFO] - Iteration 0, response_id 8: Objective value: inf
[2025-04-27 04:08:07,869][root][INFO] - Iteration 0, response_id 9: Objective value: 4.98603909054647
[2025-04-27 04:08:07,871][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:10,595][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:10,598][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:10,599][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:10,599][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:10,602][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:10,603][root][INFO] - LLM usage: prompt_tokens = 58205, completion_tokens = 20344
[2025-04-27 04:08:10,605][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:13,248][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:13,252][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:13,253][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:13,253][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:13,256][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:13,258][root][INFO] - LLM usage: prompt_tokens = 58563, completion_tokens = 20497
[2025-04-27 04:08:13,260][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:14,974][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:14,977][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:14,978][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:14,978][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:14,980][root][INFO] - LLM usage: prompt_tokens = 58979, completion_tokens = 20618
[2025-04-27 04:08:14,981][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:14,983][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:17,669][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:17,672][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:17,673][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:17,674][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:17,676][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:17,677][root][INFO] - LLM usage: prompt_tokens = 59395, completion_tokens = 20744
[2025-04-27 04:08:17,679][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:20,313][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:20,316][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:20,318][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:20,318][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:20,321][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:20,323][root][INFO] - LLM usage: prompt_tokens = 59767, completion_tokens = 20877
[2025-04-27 04:08:20,325][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:22,979][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:22,982][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:22,983][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:22,983][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:22,984][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:22,985][root][INFO] - LLM usage: prompt_tokens = 60172, completion_tokens = 21007
[2025-04-27 04:08:22,987][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:25,094][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:25,097][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:25,098][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:25,099][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:25,101][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:25,102][root][INFO] - LLM usage: prompt_tokens = 60559, completion_tokens = 21175
[2025-04-27 04:08:25,105][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:27,676][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:27,679][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:27,680][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:27,680][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:27,683][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:27,684][root][INFO] - LLM usage: prompt_tokens = 60964, completion_tokens = 21304
[2025-04-27 04:08:27,686][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:30,361][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:30,364][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:30,365][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:30,365][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:30,368][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:30,369][root][INFO] - LLM usage: prompt_tokens = 61325, completion_tokens = 21444
[2025-04-27 04:08:30,371][LiteLLM][INFO] - 
LiteLLM completion() model= gemini-2.0-flash; provider = gemini
[2025-04-27 04:08:32,486][httpx][INFO] - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyDWz_8AG8ir2JnMbK_fzFl4H66epIQkqFs "HTTP/1.1 200 OK"
[2025-04-27 04:08:32,490][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-04-27 04:08:32,491][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:32,491][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:32,494][LiteLLM][INFO] - selected model name for cost calculation: gemini/gemini-2.0-flash
[2025-04-27 04:08:32,495][root][INFO] - LLM usage: prompt_tokens = 61730, completion_tokens = 21597
[2025-04-27 04:08:32,517][root][INFO] - Iteration 0: Running Code -969911059333391850
[2025-04-27 04:08:32,672][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:08:32,672][root][INFO] - Iteration 0: Running Code 4946556099112271279
[2025-04-27 04:08:32,827][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:08:32,827][root][INFO] - Iteration 0: Running Code -9212578277993342723
[2025-04-27 04:08:32,966][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:08:32,966][root][INFO] - Iteration 0: Running Code -2095994133407372535
[2025-04-27 04:08:33,120][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:08:33,120][root][INFO] - Iteration 0: Running Code -3382335960040543129
[2025-04-27 04:08:33,281][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:08:33,281][root][INFO] - Iteration 0: Running Code -195049252014059973
[2025-04-27 04:08:33,441][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:08:33,442][root][INFO] - Iteration 0: Running Code 825950125470799077
[2025-04-27 04:08:33,586][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:08:33,586][root][INFO] - Iteration 0: Running Code -6222923230903663479
[2025-04-27 04:08:33,742][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-04-27 04:08:33,742][root][INFO] - Iteration 0: Running Code -4794059401753145439
[2025-04-27 04:08:33,890][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:08:33,890][root][INFO] - Iteration 0: Running Code 1326253425710978918
[2025-04-27 04:08:34,038][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-04-27 04:09:24,040][root][ERROR] - Timeout for response_id 0: Command '['python', '-u', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo/problems/bpp_online/eval.py', '5000', 'C:\\Users\\Nam\\Documents\\GitHub\\HSEvo', 'train']' timed out after 49.999997099999746 seconds
[2025-04-27 04:09:24,043][root][ERROR] - Traceback for response_id 1: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:09:24,043][root][INFO] - Iteration 0, response_id 1: Objective value: inf
[2025-04-27 04:09:24,045][root][ERROR] - Traceback for response_id 2: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:09:24,045][root][INFO] - Iteration 0, response_id 2: Objective value: inf
[2025-04-27 04:09:24,047][root][ERROR] - Traceback for response_id 3: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:09:24,048][root][INFO] - Iteration 0, response_id 3: Objective value: inf
[2025-04-27 04:09:24,049][root][ERROR] - Traceback for response_id 4: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:09:24,049][root][INFO] - Iteration 0, response_id 4: Objective value: inf
[2025-04-27 04:09:55,431][root][INFO] - Iteration 0, response_id 5: Objective value: 4.048663741523748
[2025-04-27 04:09:55,433][root][ERROR] - Traceback for response_id 6: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:09:55,433][root][INFO] - Iteration 0, response_id 6: Objective value: inf
[2025-04-27 04:09:55,435][root][ERROR] - Traceback for response_id 7: Traceback (most recent call last):
  File "C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py", line 9, in <module>
    from gpt import priority_v2 as priority
ImportError: cannot import name 'priority_v2' from 'gpt' (C:\Users\Nam\Documents\GitHub\HSEvo\problems\bpp_online\gpt.py). Did you mean: 'priority_v3'?

[2025-04-27 04:09:55,435][root][INFO] - Iteration 0, response_id 7: Objective value: inf
[2025-04-27 04:09:55,437][root][INFO] - Iteration 0, response_id 8: Objective value: 12.963701635420822
[2025-04-27 04:10:01,425][root][INFO] - Iteration 0, response_id 9: Objective value: 4.048663741523748
[2025-04-27 04:10:01,429][root][INFO] - Best Code Overall: def priority_v2(item, bins_remain_cap):
    """{This algorithm assigns a priority to each bin based on the wasted space if the item is placed in it, penalizing bins with excessive or very little wasted space.}"""
    priority = []
    for cap in bins_remain_cap:
        if cap >= item:
            waste = cap - item
            if waste > 20:  # Penalize excessive waste
                priority.append(0.1)
            elif waste < 5: # Penalize very little waste
                priority.append(0.5)
            else:
                priority.append(1 / (waste + 1))
        else:
            priority.append(-1)
    return priority
[2025-04-27 04:10:01,429][root][INFO] - Best Code Path Overall: ./best_population_generation_3.json
[2025-04-27 04:10:01,431][root][INFO] - Running validation script...: C:\Users\Nam\Documents\GitHub\HSEvo/problems/bpp_online/eval.py
[2025-04-27 04:10:33,064][root][INFO] - Validation script finished. Results are saved in best_code_overall_val_stdout.txt.
[2025-04-27 04:10:33,076][root][INFO] - [*] Running ...
[2025-04-27 04:10:33,077][root][INFO] - weibull_5k_val.pickle
[2025-04-27 04:10:33,077][root][INFO] - Average number of bins: 2085.8
[2025-04-27 04:10:33,077][root][INFO] - Lower bound on optimum: 2008.8
[2025-04-27 04:10:33,077][root][INFO] - Excess: 3.83%
[2025-04-27 04:10:33,078][root][INFO] - [*] Average:
[2025-04-27 04:10:33,078][root][INFO] - 3.833134209478307
