[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers both the remaining capacity of the bin\n    and how well the item fits relative to that capacity. Bins with capacity\n    slightly larger than the item are preferred (best fit). It penalizes\n    bins where the item would result in very little space left or bins where\n    the item is too small relative to the available space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Iterate through each bin and calculate its priority\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        if item <= remaining_capacity:\n            # Calculate the remaining space after placing the item\n            remaining_space = remaining_capacity - item\n\n            # Calculate a 'fit' score.  Smaller remaining space implies better fit, but we add a small\n            # constant to avoid division by zero problems or infinite penalties\n            fit_score = 1.0 / (remaining_space + 0.01)\n\n            # Optionally, we can also incentivize the use of bins that aren't 'too full' to start,\n            # and/or penalize overly small item relative to the bins capacity.\n            # This part prevents extremely small items constantly getting stuffed into bins due to high `fit_score`\n            #  due to little `remaining_space` because an item of ~ 0 size was added to that bin.\n            size_ratio_penalty = np.abs(item/remaining_capacity - 0.5) # Prefer capacities close to 2x the item.\n\n            priorities[i] = fit_score - size_ratio_penalty\n            #priorities[i] = fit_score # Removed size ratio penalty since it caused worse packing.\n        else:\n            # If the item doesn't fit, give a very low priority\n            priorities[i] = -np.inf\n\n    return priorities",
    "response_id": 28,
    "tryHS": true,
    "obj": 1.0071798962903893,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 136.16184010614157,
    "mi": 75.16787843984393,
    "token_count": 133.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering fit and remaining space variance.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        if item <= remaining_capacity:\n            remaining_space = remaining_capacity - item\n            fit_score = 1.0 / (remaining_space + 0.01)\n\n            # Penalize extreme remaining space relative to item size.\n            size_ratio_penalty = np.abs(item / remaining_capacity - 0.5)\n\n            priorities[i] = fit_score - size_ratio_penalty\n        else:\n            priorities[i] = -np.inf\n\n    # Normalize priorities to improve numerical stability.  Prevents divergence\n    # and potential overflow issues, especially in complex sequences.\n    if np.any(np.isfinite(priorities)):\n        priorities = (priorities - np.min(priorities[np.isfinite(priorities)])) / \\\n                     (np.max(priorities[np.isfinite(priorities)]) - np.min(priorities[np.isfinite(priorities)]))\n    else:\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 1.0071798962903893,
    "SLOC": 12.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 106.27403387250884,
    "mi": 82.99629701222835,
    "token_count": 135.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, fit_score_epsilon: float = 0.034899251036890254, size_ratio_target: float = 0.565918552991385) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers both the remaining capacity of the bin\n    and how well the item fits relative to that capacity. Bins with capacity\n    slightly larger than the item are preferred (best fit). It penalizes\n    bins where the item would result in very little space left or bins where\n    the item is too small relative to the available space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        fit_score_epsilon: Small constant added to remaining space to avoid division by zero.\n        size_ratio_target: Target ratio of item size to remaining capacity (e.g., 0.5 for capacities close to 2x the item).\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Iterate through each bin and calculate its priority\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        if item <= remaining_capacity:\n            # Calculate the remaining space after placing the item\n            remaining_space = remaining_capacity - item\n\n            # Calculate a 'fit' score.  Smaller remaining space implies better fit, but we add a small\n            # constant to avoid division by zero problems or infinite penalties\n            fit_score = 1.0 / (remaining_space + fit_score_epsilon)\n\n            # Optionally, we can also incentivize the use of bins that aren't 'too full' to start,\n            # and/or penalize overly small item relative to the bins capacity.\n            # This part prevents extremely small items constantly getting stuffed into bins due to high `fit_score`\n            #  due to little `remaining_space` because an item of ~ 0 size was added to that bin.\n            size_ratio_penalty = np.abs(item/remaining_capacity - size_ratio_target) # Prefer capacities close to 2x the item.\n\n            priorities[i] = fit_score - size_ratio_penalty\n            #priorities[i] = fit_score # Removed size ratio penalty since it caused worse packing.\n        else:\n            # If the item doesn't fit, give a very low priority\n            priorities[i] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": true,
    "obj": 2.762265656162749,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 92.0,
    "mi": 62.825726172130864,
    "token_count": 152.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fit and fragmentation, normalized.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        if item <= remaining_capacity:\n            remaining_space = remaining_capacity - item\n            fit_score = 1.0 / (remaining_space + 0.01)\n            size_ratio_penalty = np.abs(item / remaining_capacity - 0.5)\n            priorities[i] = fit_score - size_ratio_penalty\n        else:\n            priorities[i] = -np.inf\n\n    if np.any(np.isfinite(priorities)):\n        min_finite = np.min(priorities[np.isfinite(priorities)])\n        max_finite = np.max(priorities[np.isfinite(priorities)])\n        priorities = (priorities - min_finite) / (max_finite - min_finite)\n    else:\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 1.0071798962903893,
    "SLOC": 18.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 140.55415752892034,
    "mi": 78.41646910566149,
    "token_count": 209.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response3.txt_stdout.txt",
    "code_path": "problem_iter10_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, fit_score_epsilon: float = 0.07577767453392294, size_ratio_target: float = 0.36785158342024216, size_ratio_penalty_weight: float = 0.8668197082411182) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers both the remaining capacity of the bin\n    and how well the item fits relative to that capacity. Bins with capacity\n    slightly larger than the item are preferred (best fit). It penalizes\n    bins where the item would result in very little space left or bins where\n    the item is too small relative to the available space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        fit_score_epsilon: small constant to avoid division by zero problems or infinite penalties\n        size_ratio_target: target value for the size ratio (item/remaining_capacity)\n        size_ratio_penalty_weight: Weight of the size ratio penalty.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Iterate through each bin and calculate its priority\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        if item <= remaining_capacity:\n            # Calculate the remaining space after placing the item\n            remaining_space = remaining_capacity - item\n\n            # Calculate a 'fit' score.  Smaller remaining space implies better fit, but we add a small\n            # constant to avoid division by zero problems or infinite penalties\n            fit_score = 1.0 / (remaining_space + fit_score_epsilon)\n\n            # Optionally, we can also incentivize the use of bins that aren't 'too full' to start,\n            # and/or penalize overly small item relative to the bins capacity.\n            # This part prevents extremely small items constantly getting stuffed into bins due to high `fit_score`\n            #  due to little `remaining_space` because an item of ~ 0 size was added to that bin.\n            size_ratio_penalty = size_ratio_penalty_weight * np.abs(item/remaining_capacity - size_ratio_target) # Prefer capacities close to 2x the item.\n\n            priorities[i] = fit_score - size_ratio_penalty\n            #priorities[i] = fit_score # Removed size ratio penalty since it caused worse packing.\n        else:\n            # If the item doesn't fit, give a very low priority\n            priorities[i] = -np.inf\n\n    return priorities",
    "response_id": 3,
    "tryHS": true,
    "obj": 1.565616274431596,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 110.44611534953322,
    "mi": 60.46161361301367,
    "token_count": 160.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with capacity awareness and normalization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            rem = cap - item\n            fit = 1.0 / (rem + 0.01)  # Best-fit score\n            size_ratio = np.abs(item / cap - 0.5)  # Avoid tiny/huge space\n            priorities[i] = fit - size_ratio\n        else:\n            priorities[i] = -np.inf\n    # Normalize to stabilize selection\n    if np.max(priorities) > -np.inf:  # prevent all -inf\n        priorities = (priorities - np.min(priorities)) / (np.max(priorities) - np.min(priorities))\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 1.0071798962903893,
    "SLOC": 23.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 204.46016259302917,
    "mi": 78.52414684663239,
    "token_count": 243.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities considering fit and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            remaining_space = cap - item\n            fit_score = 1.0 / (remaining_space + 0.01)\n            size_ratio_penalty = np.abs(item / cap - 0.5)\n            priorities[i] = fit_score - size_ratio_penalty\n        else:\n            priorities[i] = -np.inf\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 1.0071798962903893,
    "SLOC": 16.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 192.29419688230416,
    "mi": 56.62865857178005,
    "token_count": 176.0,
    "exec_success": true
  }
]