{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Focuses on maximizing bin utilization by prioritizing bins that offer the highest proportional fill.\n\n    This heuristic adaptively weighs each bin's suitability based on the item's\n    relative size to the bin's current capacity, exploiting the pattern\n    of high-density packing for efficient bin closure.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity, ensuring bins where\n    # the item cannot fit are never selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins with sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate the 'fill ratio': the proportion of the bin's\n    # current remaining capacity that the item would occupy.\n    # This adaptively prioritizes bins that, upon accommodating the item, achieve\n    # the highest relative utilization, leading to a more compact packing strategy.\n    # A higher ratio indicates a tighter fit relative to the available space,\n    # exploiting the pattern of efficient, high-density placement.\n    # Note: Assumes item > 0. If item is 0, division would be 0/X (score 0), which is handled.\n    # If item > 0 and bins_remain_cap is 0, can_fit_mask would be False.\n    scores[can_fit_mask] = item / bins_remain_cap[can_fit_mask]\n\n    return scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    item: float,\n    bins_remain_cap: np.ndarray,\n    k_util_bonus: float = 7.319413531498309,\n    k_fragment_penalty: float = 0.7487749313617348,\n    exp_sharpness: float = 9.629372706567462,\n    epsilon: float = 0.0009242249516489776,\n    fragment_threshold: float = 0.018191772657974892) -> np.ndarray:\n    \"\"\"Combines proportional fill, non-linear high utilization bonus, and fragmentation penalty.\n\n    Prioritizes bins by relative fill, rewards perfect/near-perfect fits,\n    and penalizes creating very small, often unusable, remaining space.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can actually fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, return scores with -inf for all\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), (3rd) vs (4th), (5th) vs (9th), (6th) vs (7th) vs (8th), (12th) vs (17th), (13th) vs (15th), and (14th) vs (16th), we observe that the source code for the functions is *identical* within these ranked groups. This implies that their differences in ranking from best to worst must stem entirely from the specific *default parameter values* chosen, highlighting the paramount importance of hyperparameter tuning for heuristic performance, rather than fundamental algorithmic differences between these identically coded functions.\n\nComparing (best - 1st) vs (worst - 20th), the 1st heuristic employs a sophisticated, multi-factor scoring combining a non-linear penalty for remaining capacity (`rem_cap_penalty_exponent`) and a bonus for the item's relative size to the bin's current available space (`relative_fill_bonus`). This aggressively favors tight fits and efficient bin utilization. In stark contrast, the 20th heuristic is trivial, returning `np.zeros_like`, effectively assigning equal priority to all bins and offering no strategic guidance for packing, resulting in arbitrary or First Fit-like behavior, explaining its lowest rank.\n\nComparing (19th - second worst) vs (20th - worst), even though Heuristic 19th is incomplete, its comments and initial structure reveal an intention to combine proportional fill, non-linear high utilization bonuses, and fragmentation penalties. This demonstrates a conceptual attempt at a complex, multi-criteria heuristic, which is inherently more sophisticated than the completely non-discriminatory, zero-priority approach of Heuristic 20th. This difference in design philosophy justifies 19th being ranked above 20th, despite its incompleteness.\n\nComparing (6th/7th/8th) vs (5th/9th), heuristics 6-8 build upon the \"Best Fit\" principle (similar to 5th/9th) by explicitly adding a `perfect_fit_bonus`. This strategic bonus incentivizes \"closing\" bins, which is crucial for efficient packing. Their higher ranking suggests that directly rewarding perfect fits improves performance over a purely linear remaining capacity penalty.\n\nComparing the top-ranked (1st-4th) with other sophisticated variants like (14th/16th) and (18th), the 1st-4th heuristic's specific combination of a non-linear `rem_cap_penalty_exponent` and a `relative_fill_bonus` appears to be a highly effective formulation. The more complex 18th heuristic, despite its advanced multi-factor, context-sensitive adaptive scoring with probabilistic elements, is ranked very low. This suggests that over-engineering, poorly chosen default parameters, or the introduction of noise can significantly hinder performance in greedy heuristics, where simplicity and well-calibrated core principles often prevail.\n\nOverall, the ranking suggests that a blend of \"Best Fit\" (minimizing remaining capacity, especially with non-linear penalties), rewarding high relative utilization, and potentially incentivizing bin closure (either directly or implicitly) are key components for high-performing heuristics. Simple, pure strategies (like 10th's basic Best Fit or 12th/17th's pure fill ratio) tend to perform less well than well-tuned hybrid approaches.\n- \nHere's the redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Intelligent Bin Closure, Tuned Simplicity, Validated Complexity, Strategic Scoring.\n*   **Advice:** Prioritize aggressive bin closure using a refined Best Fit, with non-linear capacity penalties and utilization bonuses. Embrace simple, well-tuned core logic. Introduce complexity only with rigorous performance validation. Ensure choices are strategically discriminating.\n*   **Avoid:** Generic software quality discussions as primary design drivers; untuned or unvalidated complexity; heuristics offering non-discriminating choices.\n*   **Explanation:** This redefinition provides actionable, performance-centric design principles, focusing on strategic decision-making and disciplined complexity to achieve superior heuristic outcomes.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}