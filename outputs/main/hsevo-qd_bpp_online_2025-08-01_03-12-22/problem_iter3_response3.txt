```python
import numpy as np

# Assume a standard bin capacity. In many Bin Packing Problem (BPP) contexts,
# item sizes and capacities are normalized such that the bin capacity is 1.0.
# If the actual bin capacity can vary or is known to be different (e.g., if
# `bins_remain_cap` elements could be much larger than 1.0 or very small),
# this constant would ideally be passed as an argument or inferred from the
# problem context (e.g., `max(bins_remain_cap)` if a brand new bin always starts at max capacity).
BIN_CAPACITY = 1.0 

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns a priority score for each bin, indicating the desirability of
    placing the current item into it.

    This heuristic, termed "Penalized Best Fit with Gap Discrimination,"
    evolves from the traditional Best Fit approach. Its core idea is to apply
    a non-linear penalty to very small, non-zero remaining capacities within bins.
    The primary goal is to actively discourage the creation of "dead space"â€”gaps
    that are too small to be effectively utilized by subsequent items, which
    can lead to premature opening of new bins. It still strongly prioritizes
    perfect fits.

    Rationale and Scoring Logic:
    1.  **Perfect Fit (remaining capacity == 0):**
        -   **Logic:** This represents the most efficient use of bin space, leaving
            no waste. It is universally considered the ideal outcome.
        -   **Score:** `BIN_CAPACITY + 1.0`. This ensures it's the highest possible
            score, unequivocally chosen over any other fit.

    2.  **"Awkwardly Small" Gaps (0 < remaining capacity <= epsilon_gap_threshold):**
        -   **Logic:** These are often problematic. Such minuscule remaining capacities
            are frequently too small to accommodate any realistically sized future item,
            effectively becoming "dead space" or fragmentation. This leads to wasted
            space within a bin, potentially forcing the opening of a new bin even if
            overall bin utilization is low due to these tiny, unusable pockets.
        -   **Score:** `awkward_gap_penalty_base`. A constant, very low (negative) score
            is assigned. This heavily penalizes these fits, pushing the algorithm to
            explore alternatives that are either perfect or leave more substantial,
            potentially usable gaps.

    3.  **Usable Gaps (remaining capacity > epsilon_gap_threshold):**
        -   **Logic:** For remaining capacities larger than the `epsilon_gap_threshold`,
            the heuristic reverts to a modified Best Fit principle. We still prefer
            bins that leave smaller remaining capacities (as this typically leads
            to denser packing). However, the scoring is adjusted to ensure these
            "usable" gaps are always preferred over "awkwardly small" ones.
        -   **Score:** `normalized_r * awkward_gap_penalty_base`. This is a linearly
            decreasing score:
            -   A remaining capacity just above `epsilon_gap_threshold` will result
                in `normalized_r` close to 0, yielding a score close to 0.
            -   A remaining capacity close to `BIN_CAPACITY` will result in
                `normalized_r` close to 1, yielding a score close to `awkward_gap_penalty_base`.
            This creates a score range from approximately 0 down to `awkward_gap_penalty_base`,
            ensuring that smaller usable gaps are preferred and are strictly better
            than any "awkwardly small" gap.

    Tunable Parameters:
    -   `epsilon_gap_threshold`: Defines what constitutes an "awkwardly small" gap.
        This value is critical and depends on the typical item size distribution.
        It should ideally be determined empirically based on test data.
    -   `awkward_gap_penalty_base`: The severity of the penalty for awkward gaps.
        This also needs empirical tuning to balance the trade-off between
        avoiding small gaps and general best-fit performance.

    Args:
        item: Size of the item to be added to the bin.
        bins_remain_cap: A NumPy array containing the remaining capacity of each bin.

    Returns:
        A NumPy array of the same size as `bins_remain_cap`, with the priority
        score for each bin. The bin with the largest (least negative) score
        will be selected.
    """
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Mask to identify bins where the item physically fits
    can_fit_mask = bins_remain_cap >= item

    # Calculate remaining capacity for only those bins where the item can fit
    remaining_after_fit = bins_remain_cap[can_fit_mask] - item

    # --- Tunable Parameters ---
    # Defines the upper bound for what is considered an "awkwardly small" gap.
    # For example, if items are typically not smaller than 0.05, then a remaining
    # gap of less than 0.05 is "awkward".
    epsilon_gap_threshold = 0.05 * BIN_CAPACITY 
    
    # This value represents the lowest score a "usable" gap can achieve, and also
    # the fixed score for an "awkwardly small" gap. It should be negative.
    # Its magnitude should be chosen so that:
    # `awkward_gap_penalty_base < 0`
    # `awkward_gap_penalty_base` is more negative than any score from a `priority_v1`
    # for a "good" fit (e.g., `-0.1`), but less negative than `-inf`.
    awkward_gap_penalty_base = -0.5 * BIN_CAPACITY # Example: -0.5 for BIN_CAPACITY=1.0

    # Iterate through only the bins where the item can fit to calculate scores
    fitting_indices = np.where(can_fit_mask)[0]
    
    for idx, r in zip(fitting_indices, remaining_after_fit):
        if np.isclose(r, 0.0, atol=1e-9): # Use np.isclose for robust float comparison to zero
            # Perfect fit: Highest priority. Score is set to be clearly maximal.
            scores[idx] = BIN_CAPACITY + 1.0 
        elif 0 < r <= epsilon_gap_threshold:
            # Awkwardly small gap: Assign a fixed, heavy penalty.
            scores[idx] = awkward_gap_penalty_base
        else: # r > epsilon_gap_threshold: Usable gap
            # Normalize 'r' within the 'usable' range [epsilon_gap_threshold, BIN_CAPACITY].
            # This maps the range to [0, 1]:
            #   - r == epsilon_gap_threshold maps to 0
            #   - r == BIN_CAPACITY maps to 1
            effective_range = BIN_CAPACITY - epsilon_gap_threshold
            
            if effective_range <= 1e-9: # Handle cases where the threshold is too high or bin capacity is tiny
                # If the 'usable' range is non-existent or too small, treat as the best usable fit.
                normalized_r = 0.0 
            else:
                normalized_r = (r - epsilon_gap_threshold) / effective_range
            
            # The score for usable gaps decreases linearly from 0 (for the smallest usable gap)
            # down to `awkward_gap_penalty_base` (for the largest usable gap).
            # This ensures (0 >= score > awkward_gap_penalty_base).
            scores[idx] = normalized_r * awkward_gap_penalty_base 

    return scores
```
