{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the principles of efficient space-time utilization, this\n    heuristic aims to find the 'tightest fit' for the item.\n    A tighter fit means less wasted space within a bin, optimizing the\n    overall density of packing and minimizing the necessity for new bins.\n\n    From my perspective, 'Best Fit' is analogous to minimizing the\n    residual 'field distortion' (unused capacity) in a local region\n    (a bin). We prioritize bins that, upon accommodating the item, leave\n    the smallest possible, yet positive, remaining capacity. A perfect fit,\n    leaving zero residual capacity, is the most efficient use of space\n    and is therefore given the highest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are calculated as the negative of the remaining capacity after\n        the item is placed. Bins where the item does not fit receive a score\n        of -infinity to ensure they are never chosen.\n        The bin with the largest (least negative) score is the 'best fit'.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity.\n    # This ensures that bins where the item cannot fit will never be selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For the bins where the item fits, calculate the remaining capacity\n    # if the item were to be placed there.\n    # We want to minimize this remaining capacity to achieve a 'tight fit'.\n    # Hence, we take the negative of this value:\n    # A smaller positive remainder (e.g., 0.1) becomes a larger negative score (-0.1).\n    # A perfect fit (0.0 remainder) becomes the highest score (0.0).\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    scores[can_fit_mask] = -remaining_after_fit\n\n    return scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see functionally identical \"Best Fit\" heuristics. The distinction lies in their narrative and variable naming. The first heuristic uses \"quantum particle\" analogy and calculates `potential_residual_space` before masking, while the second uses \"Rosalind Franklin\" and masks earlier for `remaining_space_after_fit`. Both correctly assign negative infinity for non-fitting bins and negative of residual space for fitting ones. The subtle ranking difference implies a preference for the \"quantum\" analogy or slight structural choice.\n\nComparing (2nd) vs (3rd), both are Best Fit. Heuristic 3rd introduces a \"Galileo\" analogy and variable `potential_remainders`. The code logic remains effectively identical to the best fit strategy, emphasizing that the narrative and stylistic choices in explanations play a significant role in their perceived quality.\n\nComparing (3rd) vs (4th), both implement Best Fit but use slightly different mathematical forms for the priority score: 3rd uses `-potential_remainders` (i.e., `-(bins_remain_cap - item)`) while 4th uses `item - bins_remain_cap`. These are mathematically equivalent for ranking. The 4th heuristic employs a \"Nikola Tesla\" analogy. The ranking suggests a slight preference for the `-(capacity - item)` expression for conceptual clarity or the \"Galileo\" analogy over \"Tesla\".\n\nComparing (4th) vs (5th), (5th) vs (6th), (6th) vs (7th), and (7th) vs (8th), we observe that Heuristics 1st, 5th, and 7th are identical, as are 4th, 6th, and 9th. Heuristic 8th is also functionally identical to 1st, 2nd, 3rd, 5th, 7th, and 10th. The differences are purely in the docstrings and comments' analogies (quantum, Rosalind Franklin, Galileo, Tesla, Einstein-like). The ranking among these functionally identical heuristics demonstrates subjective preference for certain narrative styles or scientific metaphors.\n\nComparing (9th) vs (10th), Heuristic 9th is a duplicate of the \"Tesla\" analogy (which uses `item - bins_remain_cap`), while 10th uses a straightforward \"Best Fit\" explanation and the `-(potential_remaining)` calculation. Heuristic 10th's higher rank suggests that a clear, concise, and direct explanation can be preferred over a more elaborate or less universally appreciated analogy, or that the `-(C-I)` form is subtly clearer.\n\nComparing (10th) vs (11th), this marks a significant functional difference. Heuristic 10th correctly implements the \"Best Fit\" logic. In stark contrast, Heuristic 11th returns `np.zeros_like(bins_remain_cap)`, effectively providing no meaningful prioritization and is thus a very poor heuristic for \"Best Fit\". It would either pick the first available bin or arbitrarily based on other tie-breaking rules, leading to suboptimal packing.\n\nComparing (11th) to (20th), all are identical and exhibit the same critical flaw of returning zeros, making them equally ineffective as \"Best Fit\" heuristics. Additionally, they include unused imports (`random`, `math`, `scipy`, `torch`), indicating poor code hygiene. This consistent functional failure and code clutter explain their lowest ranking.\n\nOverall: The ranking primarily distinguishes between functionally correct \"Best Fit\" heuristics (1-10) and functionally broken/meaningless ones (11-20). Among the correct ones, the ranking is determined by the quality, clarity, and perhaps subjective appeal of the docstrings, comments, and chosen analogies, with a slight preference for the `-(capacity - item)` calculation form.\n- \nHere's a redefined self-reflection for designing better heuristics:\n\n### Redefined Current Self-reflection\n\n*   **Keywords:** Empirical, Iterative, Aligned, Transparent.\n*   **Advice:** Rigorously test heuristics' empirical performance on diverse problem sets and edge cases. Ensure all design choices and mathematical logic directly align with the optimization objective. Document design rationale, benchmark results, and trade-offs to facilitate future improvements. Adopt an iterative design process, continuously refining based on performance analysis.\n*   **Avoid:** Designing heuristics without empirical validation or diverse test data; employing complex, opaque logic that obscures its alignment with the objective; neglecting to document design decisions, performance metrics, or identified limitations; treating heuristic design as a one-off, static process instead of iterative.\n*   **Explanation:** This self-reflection promotes a data-driven, scientific approach to heuristic design, ensuring not just correctness but also practical effectiveness, continuous improvement, and deep understanding across varied problem landscapes.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}