{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    base_fit_priority: float = 50.0,\n    rem_cap_penalty_factor: float = 3.5,\n    rem_cap_penalty_exponent: float = 1.7,\n    relative_fill_bonus_factor: float = 8.0,\n    perfect_fit_bonus: float = 150.0,  # Significant bonus for perfect closure\n    perfect_fit_tolerance: float = 1e-9,  # Tolerance for float comparison of perfect fit\n    min_allowed_priority: float = 0.5,\n    non_fitting_priority: float = -10.0\n) -> np.ndarray:\n    \"\"\"Refined Best Fit prioritizing tight fits and high utilization with a\n    significant bonus for perfect bin closure, aiming to minimize total bins.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, fill_value=non_fitting_priority, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        remaining_after_placement = fitting_bins_remain_cap - item\n\n        # 1. Non-linear Penalty for Remaining Capacity (Enhanced Best Fit)\n        # Heavily penalizes bins that leave a lot of unused space.\n        rem_cap_penalty = rem_cap_penalty_factor * (remaining_after_placement ** rem_cap_penalty_exponent)\n\n        # 2. Relative Fill Bonus\n        # Rewards placing the item where it occupies a larger proportion of the bin's current capacity.\n        # Avoids division by zero as fitting_bins_remain_cap >= item > 0.\n        relative_fill_ratio = item / fitting_bins_remain_cap\n        relative_fill_bonus = relative_fill_bonus_factor * relative_fill_ratio\n\n        # Initialize calculated priorities with base + relative fill bonus - remaining capacity penalty\n        calculated_priorities = base_fit_priority - rem_cap_penalty + relative_fill_bonus\n\n        # 3. Explicit Perfect Fit Bonus (Inspired by 'tightest fit' and bin closure)\n        # Apply a substantial bonus for bins where the item perfectly fills the remaining space.\n        # Use a small tolerance for floating-point precision.\n        perfect_fit_mask_local = np.abs(remaining_after_placement) < perfect_fit_tolerance\n        calculated_priorities[perfect_fit_mask_local] += perfect_fit_bonus\n\n        # Ensure priorities do not fall below a minimum allowed value for fitting bins\n        calculated_priorities = np.maximum(calculated_priorities, min_allowed_priority)\n\n        priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the principles of efficient space-time utilization, this\n    heuristic aims to find the 'tightest fit' for the item.\n    A tighter fit means less wasted space within a bin, optimizing the\n    overall density of packing and minimizing the necessity for new bins.\n\n    From my perspective, 'Best Fit' is analogous to minimizing the\n    residual 'field distortion' (unused capacity) in a local region\n    (a bin). We prioritize bins that, upon accommodating the item, leave\n    the smallest possible, yet positive, remaining capacity. A perfect fit,\n    leaving zero residual capacity, is the most efficient use of space\n    and is therefore given the highest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are calculated as the negative of the remaining capacity after\n        the item is placed. Bins where the item does not fit receive a score\n        of -infinity to ensure they are never chosen.\n        The bin with the largest (least negative) score is the 'best fit'.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity.\n    # This ensures that bins where the item cannot fit will never be selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For the bins where the item fits, calculate the remaining capacity\n    # if the item were to be placed there.\n    # We want to minimize this remaining capacity to achieve a 'tight fit'.\n    # Hence, we take the negative of this value:\n    # A smaller positive remainder (e.g., 0.1) becomes a larger negative score (-0.1).\n    # A perfect fit (0.0 remainder) becomes the highest score (0.0).\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    scores[can_fit_mask] = -remaining_after_fit\n\n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that Heuristic 1st employs a sophisticated multi-factor scoring system, incorporating a non-linear penalty for remaining capacity and a bonus for relative fill, aiming to optimize bin utilization. In stark contrast, Heuristic 20th simply returns an array of zeros, effectively providing no intelligent guidance for bin selection and leading to arbitrary placement. This fundamental difference in strategy explains why 1st is ranked best and 20th is worst.\n\nComparing (2nd) vs (19th), Heuristic 2nd is a highly refined strategy similar to 1st, adding an explicit bonus for perfect fits. Heuristic 19th, like 20th, returns all zeros, offering no strategic value. The performance difference mirrors that of 1st vs 20th, showcasing the superiority of intelligent heuristics over no strategy.\n\nComparing (1st) vs (2nd), Heuristic 1st omits the explicit `perfect_fit_bonus` found in Heuristic 2nd. The fact that 1st performs better suggests that its combination of a non-linear penalty (where `rem_cap_penalty_exponent > 1`) and a relative fill bonus (rewarding `item / fitting_bins_remain_cap`) implicitly handles perfect and tight fits so effectively that an additional, large, explicit bonus becomes redundant or even detrimental. An overly aggressive, discrete bonus might lead to local optima that are not globally efficient, perhaps by prioritizing a perfect fit in a bin when another less \"perfect\" fit could lead to better overall packing for future items.\n\nComparing (3rd) vs (4th), both implement a `perfect_fit_bonus`. However, Heuristic 4th applies a higher bonus (`180.0` vs `150.0`) and uses a `perfect_fit_threshold` to define \"near-perfect fits\" more broadly (i.e., `remaining_after_placement <= threshold`) than 3rd's stricter `np.abs(remaining_after_placement) < perfect_fit_tolerance`. Heuristic 3rd being better than 4th indicates that making the \"perfect fit\" bonus too large or applying it too broadly (to a wider threshold) can degrade performance. This reinforces the idea that over-incentivizing specific conditions might lead to less optimal global solutions in complex packing scenarios.\n\nComparing (19th) vs (20th), both heuristics are identical, returning `np.zeros_like(bins_remain_cap)`. This implies they offer no intelligence in bin selection and are thus equally poor, ranking at the very bottom.\n\nOverall: The best-performing heuristics (1st-6th) leverage multi-component scoring. A non-linear penalty for remaining capacity is highly effective for promoting tight fits. The \"relative fill bonus\" (prioritizing items that occupy a large proportion of *current* available bin space) appears to be a crucial component for efficient bin utilization. Simpler heuristics, such as pure \"Best Fit\" (13th, 14th) or \"Proportional Fill\" (10th, 15th), perform poorly, as do those relying only on linear penalties (7th, 8th). Explicit \"perfect fit\" bonuses, while intuitive, need careful calibration, as the top heuristic (1st) excels without one, suggesting a smoothly weighted function can implicitly capture this goal better than an abrupt, large bonus. Complex heuristics (e.g., 16th), even with good ideas, can perform poorly if parameters are not optimally tuned.\n- \nHere's a redefined 'Current self-reflection' to design better heuristics:\n\n*   **Keywords:** Continuous Scoring, Parameter Calibration, Performance Validation, Objective Alignment.\n*   **Advice:** Design heuristics with continuous, multi-factor scoring functions that non-linearly prioritize efficient resource utilization and bin closure. Meticulously calibrate all parameters to align precisely with the optimization objective, enhancing foundational principles like Best Fit.\n*   **Avoid:** Relying on untuned, overly simplistic, or unvalidated complex strategies. Do not conflate basic functional correctness or code clarity with core heuristic performance design principles. Shun non-discriminating or trivial decision rules.\n*   **Explanation:** Superior heuristics emerge from rigorously tuned, objective-driven scoring functions, where every component is validated to maximize strategic decision-making and overall system performance.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}