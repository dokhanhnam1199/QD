{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                base_fit_priority: float = 40.67957013415283,\n                remaining_capacity_penalty_factor: float = 2.527225052325968,\n                min_allowed_priority: float = 0.5896372460377476,\n                non_fitting_priority: float = -8.783827459234484) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function calculates priority based on a \"Best Fit\" strategy:\n    bins that can accommodate the item and have less remaining capacity after\n    placement are prioritized higher.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        base_fit_priority: A base score given to any bin where the item can fit.\n                           This sets the initial priority before any penalties.\n        remaining_capacity_penalty_factor: A multiplier for the penalty applied\n                                           based on the remaining capacity after\n                                           the item is placed. A higher value\n                                           means larger remaining capacities\n                                           are penalized more heavily,\n                                           encouraging a \"best-fit\" approach.\n        min_allowed_priority: The minimum priority score a bin can receive if\n                              the item fits. This acts as a floor, preventing\n                              priorities from becoming too low or negative\n                              for valid placements.\n        non_fitting_priority: The priority score assigned to bins where the\n                              item does not fit. Typically 0 or a negative value.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities with the value for non-fitting bins\n    priorities = np.full_like(bins_remain_cap, fill_value=non_fitting_priority, dtype=float)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only process if there are bins where the item can fit\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity for bins where the item could be placed\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Calculate the priority for these bins\n        # The formula applies a penalty based on the remaining capacity:\n        # P = base_fit_priority - (penalty_factor * remaining_capacity)\n        # This encourages smaller remaining capacities (best fit).\n        calculated_priorities = base_fit_priority - (remaining_capacity_penalty_factor * remaining_after_placement)\n\n        # Ensure that the calculated priority does not fall below a minimum allowed value\n        calculated_priorities = np.maximum(calculated_priorities, min_allowed_priority)\n\n        # Assign the calculated priorities to the corresponding bins\n        priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global constant for bin capacity. In a real system, this might be a parameter\n# passed around or part of a Bin class. For simplicity, assuming a standard capacity.\nBIN_CAPACITY = 1.0 \n\n    \"\"\"\n    Returns a priority score for each bin, guiding the selection of where to place an item.\n    This heuristic embodies multi-factor, context-sensitive adaptive scoring with\n    an element of probabilistic selection to foster emergent packing patterns,\n    going beyond simple 'Best Fit'.\n\n    The priority score for a bin is a complex function considering:\n    1.  **Fundamental Tightness (Quantum Fit)**: A non-linear assessment of how\n        perfectly the item fits, emphasizing minimal remaining space with an\n        exponential decay. It serves as the primary driver for efficient space\n        utilization.\n    2.  **Desired State Affinity (Harmonic Fullness)**: Rewards bins that, after\n        the item is placed, achieve a dynamically adjusted 'ideal' fullness level.\n        This ideal shifts based on the incoming item's size, aiming to create\n        a balanced distribution of bin states rather than just emptying them or\n        always starting new ones.\n    3.  **Boundary Avoidance (Flux Equilibrium)**: Introduces penalties for\n        situations where placing the item would result in leaving either an\n        extremely small, potentially unusable fragment of space, or an\n        excessively large, underutilized space. This encourages more 'useful'\n        bin states.\n\n    The weights for these components are not fixed but are dynamically\n    calculated based on the incoming item's size and the current statistical\n    distribution of remaining capacities across all bins. This aims for a\n    self-adjusting behavior without explicit historical learning within this\n    function call itself. A small, normally distributed noise component is also\n    added to introduce a 'probabilistic selection' element, preventing rigid\n    deterministic ties and encouraging exploration of potentially similar-priority\n    bins, which can lead to more diverse and robust packing solutions over time.\n\n    Args:\n        item: Size of item to be added to the bin (float, assumed normalized to BIN_CAPACITY).\n        bins_remain_cap: NumPy array of remaining capacities for each bin.\n\n    Returns:\n        NumPy array of the same size as bins_remain_cap, where each element\n        is the priority score for the corresponding bin. Bins where the item\n        cannot fit receive a score of -np.inf to ensure they are never chosen.\n        The bin with the highest score is the preferred choice.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    \n    # If no bin can fit the item, return early with all scores as -inf.\n    if not np.any(can_fit_mask):\n        return scores\n\n    fitting_bins_idx = np.where(can_fit_mask)[0]\n    current_bin_caps = bins_remain_cap[fitting_bins_idx]\n    remaining_after_fit = current_bin_caps - item\n\n    # --- Adaptive Parameters & Context-Sensitive Weighting ---\n    # These internal parameters dynamically adjust based on the current problem state.\n    # This reflects the \"adaptive scoring\" and \"high-dimensional tuning\" aspects,\n    # fostering emergent and context-sensitive behavior.\n    \n    item_relative_size = item / BIN_CAPACITY # Item size normalized to bin capacity\n    \n    # Calculate properties of the current bin capacity distribution for context\n    # Use clip to prevent division by zero if all capacities are identical\n    std_remain_cap = np.std(bins_remain_cap) \n    std_remain_cap_normalized = std_remain_cap / BIN_CAPACITY if BIN_CAPACITY > 0 else 0\n    avg_remain_cap_normalized = np.mean(bins_remain_cap) / BIN_CAPACITY if BIN_CAPACITY > 0 else 0\n    \n    # --- Dynamic Weights for Scoring Components ---\n    # These weights are functions of the current state, allowing for non-monotonic\n    # and context-sensitive behavior in the overall heuristic.\n\n    # Weight for Quantum Fit: Prioritize tight fit more for smaller items or if bins are generally full.\n    # This encourages finishing bins when items are small or space is scarce.\n    weight_quantum_fit = 1.0 + 0.5 * (1.0 - item_relative_size) * (1.0 - avg_remain_cap_normalized)\n\n    # Weight for Harmonic Fullness: Emphasize achieving a target fullness more for 'medium' items\n    # and when bin capacities are diverse (more options for optimal filling).\n    weight_harmonic_fullness = 0.8 + 0.7 * (1.0 - np.abs(item_relative_size - 0.5) * 2) * std_remain_cap_normalized\n    \n    # Weight for Flux Equilibrium: Penalize extreme remaining capacities more when bins are already polarized\n    # (high std_remain_cap) or when there's a strong need to balance bin states.\n    weight_flux_equilibrium = 0.6 + 0.8 * std_remain_cap_normalized\n\n    # === Scoring Components Calculation ===\n\n    # Component 1: Fundamental Tightness (Quantum Fit)\n    # A non-linear, exponentially decaying reward. A perfect fit (remainder 0) gives a score of 0.\n    # Larger remainders yield increasingly negative (worse) scores. This is a mutated version\n    # of the 'Best Fit' concept from priority_v1, making the penalty for wasted space more severe.\n    score_quantum_fit = -np.expm1(remaining_after_fit / BIN_CAPACITY) # exp(x)-1, gives 0 for x=0, negative for x>0\n\n    # Component 2: Desired State Affinity (Harmonic Fullness)\n    # Rewards bins that achieve a specific target fullness after the item is placed.\n    # The target fullness dynamically shifts: smaller items tend to be used to 'top off'\n    # bins (higher target fullness), while larger items might aim for less full bins.\n    dynamic_target_fullness = 0.65 + 0.3 * (1.0 - item_relative_size) # Ranges from 0.65 (large item) to 0.95 (small item)\n    \n    # New fullness of the bin after placing the item\n    new_fullness = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n    \n    # The variance scale (width of the Gaussian peak) also adapts. Wider for extreme item sizes,\n    # tighter for medium items (desiring more precise placement).\n    fullness_variance_scale = 0.05 + 0.15 * (np.abs(item_relative_size - 0.5) * 2) \n    \n    # Gaussian-like reward: peaks at dynamic_target_fullness, range [0, 1]\n    # Small epsilon in denominator for numerical stability if variance is extremely small.\n    epsilon_denominator = 1e-9 \n    score_harmonic_fullness = np.exp(-((new_fullness - dynamic_target_fullness)**2) / (2.0 * fullness_variance_scale**2 + epsilon_denominator))\n\n    # Component 3: Boundary Avoidance (Flux Equilibrium)\n    # Penalizes leaving very small, potentially unusable fragments, or very large unused spaces.\n    # This guides towards creating 'useful' remaining capacities and balancing bin utilization.\n    \n    # Adaptive thresholds for \"too small\" or \"too large\" remaining capacity\n    min_fragment_threshold = 0.02 * BIN_CAPACITY + 0.05 * item # Penalize leaving tiny unusable bits more\n    max_open_space_threshold = 0.9 * BIN_CAPACITY - 0.05 * item # Penalize wasting a bin for a small item\n    \n    # Sigmoid steepness for smooth, non-linear transitions in penalty\n    sigmoid_steepness = 100.0 / BIN_CAPACITY \n    \n    # Penalty for leaving very small remaining capacity (approaches 1 as remainder -> 0)\n    penalty_low_rem = 1.0 / (1.0 + np.exp((remaining_after_fit - min_fragment_threshold) * sigmoid_steepness))\n    # Penalty for leaving very large remaining capacity (approaches 1 as remainder -> BIN_CAPACITY-item)\n    penalty_high_rem = 1.0 / (1.0 + np.exp(-(remaining_after_fit - max_open_space_threshold) * sigmoid_steepness))\n    \n    # Combined flux penalty. This is a negative contribution to the total score.\n    score_flux_equilibrium = -(penalty_low_rem + penalty_high_rem)\n    \n    # === Combined Score Calculation ===\n    # A weighted sum of the components. The weights are dynamic, and a small\n    # amount of Gaussian noise is added for 'probabilistic selection' and\n    # to encourage exploration of similar-priority bins, fostering emergent behavior.\n    \n    exploration_noise_scale = 1e-4 * BIN_CAPACITY # Small noise relative to bin capacity, ensures exploration without dominating\n    \n    combined_scores_for_fitting_bins = (\n        weight_quantum_fit * score_quantum_fit +\n        weight_harmonic_fullness * score_harmonic_fullness +\n        weight_flux_equilibrium * score_flux_equilibrium +\n        np.random.normal(0, scale=exploration_noise_scale, size=len(fitting_bins_idx))\n    )\n\n    # Assign the calculated scores back to the original scores array,\n    # leaving -np.inf for bins where the item does not fit.\n    scores[fitting_bins_idx] = combined_scores_for_fitting_bins\n\n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), (3rd) vs (4th), (5th) vs (9th), (6th) vs (7th) vs (8th), (12th) vs (17th), (13th) vs (15th), and (14th) vs (16th), we observe that the source code for the functions is *identical* within these ranked groups. This implies that their differences in ranking from best to worst must stem entirely from the specific *default parameter values* chosen, highlighting the paramount importance of hyperparameter tuning for heuristic performance, rather than fundamental algorithmic differences between these identically coded functions.\n\nComparing (best - 1st) vs (worst - 20th), the 1st heuristic employs a sophisticated, multi-factor scoring combining a non-linear penalty for remaining capacity (`rem_cap_penalty_exponent`) and a bonus for the item's relative size to the bin's current available space (`relative_fill_bonus`). This aggressively favors tight fits and efficient bin utilization. In stark contrast, the 20th heuristic is trivial, returning `np.zeros_like`, effectively assigning equal priority to all bins and offering no strategic guidance for packing, resulting in arbitrary or First Fit-like behavior, explaining its lowest rank.\n\nComparing (19th - second worst) vs (20th - worst), even though Heuristic 19th is incomplete, its comments and initial structure reveal an intention to combine proportional fill, non-linear high utilization bonuses, and fragmentation penalties. This demonstrates a conceptual attempt at a complex, multi-criteria heuristic, which is inherently more sophisticated than the completely non-discriminatory, zero-priority approach of Heuristic 20th. This difference in design philosophy justifies 19th being ranked above 20th, despite its incompleteness.\n\nComparing (6th/7th/8th) vs (5th/9th), heuristics 6-8 build upon the \"Best Fit\" principle (similar to 5th/9th) by explicitly adding a `perfect_fit_bonus`. This strategic bonus incentivizes \"closing\" bins, which is crucial for efficient packing. Their higher ranking suggests that directly rewarding perfect fits improves performance over a purely linear remaining capacity penalty.\n\nComparing the top-ranked (1st-4th) with other sophisticated variants like (14th/16th) and (18th), the 1st-4th heuristic's specific combination of a non-linear `rem_cap_penalty_exponent` and a `relative_fill_bonus` appears to be a highly effective formulation. The more complex 18th heuristic, despite its advanced multi-factor, context-sensitive adaptive scoring with probabilistic elements, is ranked very low. This suggests that over-engineering, poorly chosen default parameters, or the introduction of noise can significantly hinder performance in greedy heuristics, where simplicity and well-calibrated core principles often prevail.\n\nOverall, the ranking suggests that a blend of \"Best Fit\" (minimizing remaining capacity, especially with non-linear penalties), rewarding high relative utilization, and potentially incentivizing bin closure (either directly or implicitly) are key components for high-performing heuristics. Simple, pure strategies (like 10th's basic Best Fit or 12th/17th's pure fill ratio) tend to perform less well than well-tuned hybrid approaches.\n- \nHere's the redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Intelligent Bin Closure, Tuned Simplicity, Validated Complexity, Strategic Scoring.\n*   **Advice:** Prioritize aggressive bin closure using a refined Best Fit, with non-linear capacity penalties and utilization bonuses. Embrace simple, well-tuned core logic. Introduce complexity only with rigorous performance validation. Ensure choices are strategically discriminating.\n*   **Avoid:** Generic software quality discussions as primary design drivers; untuned or unvalidated complexity; heuristics offering non-discriminating choices.\n*   **Explanation:** This redefinition provides actionable, performance-centric design principles, focusing on strategic decision-making and disciplined complexity to achieve superior heuristic outcomes.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}