{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                base_fit_priority: float = 40.67957013415283,\n                remaining_capacity_penalty_factor: float = 2.527225052325968,\n                min_allowed_priority: float = 0.5896372460377476,\n                non_fitting_priority: float = -8.783827459234484) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function calculates priority based on a \"Best Fit\" strategy:\n    bins that can accommodate the item and have less remaining capacity after\n    placement are prioritized higher.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        base_fit_priority: A base score given to any bin where the item can fit.\n                           This sets the initial priority before any penalties.\n        remaining_capacity_penalty_factor: A multiplier for the penalty applied\n                                           based on the remaining capacity after\n                                           the item is placed. A higher value\n                                           means larger remaining capacities\n                                           are penalized more heavily,\n                                           encouraging a \"best-fit\" approach.\n        min_allowed_priority: The minimum priority score a bin can receive if\n                              the item fits. This acts as a floor, preventing\n                              priorities from becoming too low or negative\n                              for valid placements.\n        non_fitting_priority: The priority score assigned to bins where the\n                              item does not fit. Typically 0 or a negative value.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities with the value for non-fitting bins\n    priorities = np.full_like(bins_remain_cap, fill_value=non_fitting_priority, dtype=float)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only process if there are bins where the item can fit\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity for bins where the item could be placed\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Calculate the priority for these bins\n        # The formula applies a penalty based on the remaining capacity:\n        # P = base_fit_priority - (penalty_factor * remaining_capacity)\n        # This encourages smaller remaining capacities (best fit).\n        calculated_priorities = base_fit_priority - (remaining_capacity_penalty_factor * remaining_after_placement)\n\n        # Ensure that the calculated priority does not fall below a minimum allowed value\n        calculated_priorities = np.maximum(calculated_priorities, min_allowed_priority)\n\n        # Assign the calculated priorities to the corresponding bins\n        priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Focuses on maximizing bin utilization by prioritizing bins that offer the highest proportional fill.\n\n    This heuristic adaptively weighs each bin's suitability based on the item's\n    relative size to the bin's current capacity, exploiting the pattern\n    of high-density packing for efficient bin closure.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity, ensuring bins where\n    # the item cannot fit are never selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins with sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate the 'fill ratio': the proportion of the bin's\n    # current remaining capacity that the item would occupy.\n    # This adaptively prioritizes bins that, upon accommodating the item, achieve\n    # the highest relative utilization, leading to a more compact packing strategy.\n    # A higher ratio indicates a tighter fit relative to the available space,\n    # exploiting the pattern of efficient, high-density placement.\n    # Note: Assumes item > 0. If item is 0, division would be 0/X (score 0), which is handled.\n    # If item > 0 and bins_remain_cap is 0, can_fit_mask would be False.\n    scores[can_fit_mask] = item / bins_remain_cap[can_fit_mask]\n\n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the top-ranked heuristic employs a \"Best Fit\" strategy with meticulously tuned parameters (`base_fit_priority`, `remaining_capacity_penalty_factor`, `min_allowed_priority`), actively seeking to minimize remaining bin capacity after item placement. In contrast, the worst-ranked heuristic (and others in the lowest tier, 15th-20th) effectively assigns uniform or zero priority to all fitting bins, resulting in no strategic choice. This stark performance difference highlights the profound impact of even a simple, well-defined greedy strategy over a non-discriminating approach, demonstrating the immense value of strategic prioritization.\n\nComparing (1st) vs (2nd) and (3rd) vs (4th), the heuristics are identical in their implementation and parameter values. Their consecutive ranking suggests either negligible performance differences (statistical ties) or an extremely robust performance for this specific \"Best Fit\" variant, making it consistently the best choice. Similarly, comparing (19th) vs (20th), these heuristics are functionally identical, both providing no strategic prioritization, confirming their equally poor performance and serving as a baseline for non-optimized bin assignment.\n\nComparing the simpler \"Best Fit\" heuristics (1st-4th) against the more complex, multi-factor adaptive heuristics (5th, 9th, 12th, 14th), the simpler approach surprisingly performed better. The adaptive heuristics incorporate dynamic weighting, non-linear scoring, and probabilistic elements to account for \"Quantum Fit,\" \"Harmonic Fullness,\" and \"Flux Equilibrium.\" Their lower ranking indicates that increased complexity, dynamic adjustments, and stochasticity do not guarantee superior performance and can even hinder it if not perfectly balanced or if they lead to less stable decision-making in the given problem context.\n\nFurthermore, heuristics like 6th, 7th, 8th, and 13th, which augment Best Fit with specific penalties for small fragments or bonuses for high utilization, are ranked in the mid-tier. This suggests that while these additions are conceptually sound, their specific implementation or parameterization might not have yielded sufficient gains to surpass the top-performing, simpler \"Best Fit\" with its optimized fixed parameters. The \"Proportional Fill\" strategy (10th, 11th) which prioritizes items filling a larger *proportion* of the remaining bin space, performed notably worse than Best Fit, indicating that minimizing absolute remaining space is more effective than maximizing relative fill in this scenario.\n\nOverall: The best performing heuristics are simple and consistently apply a 'Best Fit' strategy, indicating that simplicity with strong, fixed parameters can often outperform complex, dynamically-tuned strategies in this context. The worst performing heuristics are those that lack any specific prioritization logic.\n- \nHere's a redefined 'Current self-reflection' to design better heuristics, avoiding the pitfalls of 'Ineffective self-reflection':\n\n### Redefined 'Current self-reflection'\n1.  **Prioritize Core Intuition:** Design around fundamental, domain-specific principles (e.g., minimizing waste) that are inherently effective and interpretable.\n2.  **Controlled Refinement:** Incremental additions to heuristic logic must demonstrate measurable, consistent performance gains beyond simpler baselines.\n3.  **Focused Discrimination:** Heuristics must provide clear, non-trivial guidance, actively differentiating choices based on the primary optimization objective.\n4.  **Parameter Prudence:** Optimize a minimal set of well-understood parameters for robustness; complex, untuned schemes typically underperform.\n\n---\n\n*   **Keywords:** Core Principles, Simplicity, Validation, Focused Guidance, Parameter Tuning.\n*   **Advice:** Design heuristics grounded in clear core principles, rigorously validating any added complexity, and precisely tuning minimal parameters for robust optimization.\n*   **Avoid:** Generic implementation concerns, unvalidated multi-factor scoring, or vague problem data advice that doesn't translate to specific heuristic logic.\n*   **Explanation:** This approach prioritizes effective, interpretable heuristic logic over over-engineered or poorly justified solutions, leading to more reliable and performing systems.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}