```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines Best Fit with a non-linear remainder penalty and a relative fill bonus.
    Aims to minimize fragmentation by penalizing very small, non-zero remainders.
    """
    # Initialize scores for all bins to negative infinity, ensuring un-fittable bins are never chosen.
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Mask for bins where the item can fit.
    can_fit_mask = bins_remain_cap >= item

    # If no bin can fit the item, return the scores array with -inf.
    if not np.any(can_fit_mask):
        return scores

    # Extract relevant data for bins where the item can fit.
    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]
    remaining_after_fit = fitting_bins_remain_cap - item

    # --- Core Multi-Factor Scoring Components ---

    # 1. Base Best Fit Score: Smaller remainder yields higher score. Perfect fit (0 remainder) gets 0.
    base_best_fit_score = -remaining_after_fit

    # 2. Non-linear Penalty for Remaining Capacity: Punish larger remainders more aggressively.
    # An exponent > 1 makes the penalty grow faster for larger remainders, promoting tighter fits.
    # A weighting factor controls the influence of this penalty.
    PENALTY_EXPONENT = 2.5  # Higher exponent for more aggressive non-linearity
    NON_LINEAR_PENALTY_WEIGHT = 0.6  # Weight to control its impact
    non_linear_penalty = -(remaining_after_fit ** PENALTY_EXPONENT) * NON_LINEAR_PENALTY_WEIGHT

    # 3. Relative Fill Bonus: Rewards bins where the item consumes a large proportion of the *initial* available capacity.
    # This implicitly encourages using bins that are 'just right' for the item.
    # Add a small epsilon for numerical stability to prevent division by zero or extreme values.
    RELATIVE_FILL_WEIGHT = 0.08  # Weight to control its impact
    epsilon = 1e-9
    relative_fill_bonus = (item / (fitting_bins_remain_cap + epsilon)) * RELATIVE_FILL_WEIGHT

    # Combine these primary scoring components.
    scores[can_fit_mask] = base_best_fit_score + non_linear_penalty + relative_fill_bonus

    # --- Fragmentation Control (Fine-tuning from priority_v0) ---
    # Apply an additional penalty for very small, non-zero remainders to discourage unusable fragmentation.
    # These thresholds are empirical and should ideally be calibrated.
    TINY_REMAINDER_THRESHOLD = 0.05  # e.g., 5% of bin capacity (assuming normalized capacity)
    PENALTY_FOR_TINY_REMAINDER = 0.015  # A distinct penalty value

    # Identify bins that would result in a tiny, non-zero remainder.
    # Using epsilon to robustly check for non-zero floating-point values.
    tiny_remainder_cond = (remaining_after_fit > epsilon) & (remaining_after_fit < TINY_REMAINDER_THRESHOLD)

    # Apply the penalty to the scores of identified bins.
    scores[can_fit_mask][tiny_remainder_cond] -= PENALTY_FOR_TINY_REMAINDER

    return scores
```
