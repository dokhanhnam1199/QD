{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                bins_remain_cap: np.ndarray,\n                base_fit_priority: float = 40.67957013415283,\n                remaining_capacity_penalty_factor: float = 2.527225052325968,\n                min_allowed_priority: float = 0.5896372460377476,\n                non_fitting_priority: float = -8.783827459234484) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function calculates priority based on a \"Best Fit\" strategy:\n    bins that can accommodate the item and have less remaining capacity after\n    placement are prioritized higher.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        base_fit_priority: A base score given to any bin where the item can fit.\n                           This sets the initial priority before any penalties.\n        remaining_capacity_penalty_factor: A multiplier for the penalty applied\n                                           based on the remaining capacity after\n                                           the item is placed. A higher value\n                                           means larger remaining capacities\n                                           are penalized more heavily,\n                                           encouraging a \"best-fit\" approach.\n        min_allowed_priority: The minimum priority score a bin can receive if\n                              the item fits. This acts as a floor, preventing\n                              priorities from becoming too low or negative\n                              for valid placements.\n        non_fitting_priority: The priority score assigned to bins where the\n                              item does not fit. Typically 0 or a negative value.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities with the value for non-fitting bins\n    priorities = np.full_like(bins_remain_cap, fill_value=non_fitting_priority, dtype=float)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only process if there are bins where the item can fit\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity for bins where the item could be placed\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Calculate the priority for these bins\n        # The formula applies a penalty based on the remaining capacity:\n        # P = base_fit_priority - (penalty_factor * remaining_capacity)\n        # This encourages smaller remaining capacities (best fit).\n        calculated_priorities = base_fit_priority - (remaining_capacity_penalty_factor * remaining_after_placement)\n\n        # Ensure that the calculated priority does not fall below a minimum allowed value\n        calculated_priorities = np.maximum(calculated_priorities, min_allowed_priority)\n\n        # Assign the calculated priorities to the corresponding bins\n        priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority scores for each bin, based on an \"Adaptive Fullness Prioritization\" heuristic.\n\n    This heuristic mutates the standard 'Best Fit' by introducing strategic considerations\n    for space management beyond simple minimization of remaining capacity. It aims to:\n\n    1.  **Strongly Reward Perfect Fits**: A perfect fit (leaving 0 remaining capacity)\n        is the most efficient use of space, effectively \"closing\" a bin. This is\n        given a significant bonus.\n    2.  **Prioritize High Overall Utilization**: Similar to Best Fit, bins that\n        become very full after placing the item are generally preferred.\n    3.  **Penalize Fragmented Space**: A minor penalty is applied to bins that\n        are left with a very small, non-zero remaining capacity. Such 'fragments'\n        are often too small to be useful for subsequent items and can lead to\n        wasted space or increased bin count if many such bins accumulate.\n        This encourages the selection of bins that either achieve a perfect fit,\n        or leave a more 'useful' (larger) amount of remaining space, allowing for\n        greater flexibility for future items.\n\n    The goal is to not just minimize residual space, but to do so in a way\n    that minimizes \"unusable\" small fragments, promoting overall\n    packing efficiency and potentially reducing the number of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        BIN_CAPACITY: The maximum capacity of a single bin. Default to 1.0,\n                      assuming item and capacities are normalized.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        Higher scores indicate a more desirable bin. Bins where the item does not\n        fit receive a score of -infinity.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity after hypothetical placement for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Primary scoring component: Utilization after placing the item.\n    # A higher utilization means less remaining space, similar to Best Fit.\n    # Scores range from 0 (empty bin after placement) to 1 (full bin).\n    utilization_score = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n\n    # Define a small epsilon for floating point comparisons to handle near-zero values.\n    epsilon = 1e-9\n\n    # Strategic Bonus: Strongly reward perfect fits.\n    # Using np.isclose for robust floating point comparison to zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=epsilon)\n    # Adding a substantial bonus (e.g., 1.0) makes perfect fits unequivocally\n    # the highest priority, pushing their score beyond the normal 0-1 range.\n    utilization_score[perfect_fit_mask] += 1.0\n\n    # Strategic Penalty: Slightly penalize very small, non-zero remaining capacities.\n    # These are deemed \"fragmented\" or potentially \"wasted\" space.\n    # The threshold for what constitutes a \"small fragment\" can be tuned,\n    # here set to 5% of the bin capacity.\n    fragment_threshold = 0.05 * BIN_CAPACITY\n    \n    # Identify bins that have a small, non-zero remainder.\n    # Ensure it's greater than epsilon to not penalize perfect fits.\n    fragment_mask = (remaining_after_fit > epsilon) & (remaining_after_fit < fragment_threshold)\n    \n    # Subtract a small penalty (e.g., 0.1) to make these bins slightly less\n    # attractive compared to those leaving a more useful or zero remainder.\n    utilization_score[fragment_mask] -= 0.1\n\n    # Assign the calculated scores to the bins where the item can fit.\n    scores[can_fit_mask] = utilization_score\n\n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), (3rd) vs (4th), (5th) vs (9th), (6th) vs (7th) vs (8th), (12th) vs (17th), (13th) vs (15th), and (14th) vs (16th), we observe that the source code for the functions is *identical* within these ranked groups. This implies that their differences in ranking from best to worst must stem entirely from the specific *default parameter values* chosen, highlighting the paramount importance of hyperparameter tuning for heuristic performance, rather than fundamental algorithmic differences between these identically coded functions.\n\nComparing (best - 1st) vs (worst - 20th), the 1st heuristic employs a sophisticated, multi-factor scoring combining a non-linear penalty for remaining capacity (`rem_cap_penalty_exponent`) and a bonus for the item's relative size to the bin's current available space (`relative_fill_bonus`). This aggressively favors tight fits and efficient bin utilization. In stark contrast, the 20th heuristic is trivial, returning `np.zeros_like`, effectively assigning equal priority to all bins and offering no strategic guidance for packing, resulting in arbitrary or First Fit-like behavior, explaining its lowest rank.\n\nComparing (19th - second worst) vs (20th - worst), even though Heuristic 19th is incomplete, its comments and initial structure reveal an intention to combine proportional fill, non-linear high utilization bonuses, and fragmentation penalties. This demonstrates a conceptual attempt at a complex, multi-criteria heuristic, which is inherently more sophisticated than the completely non-discriminatory, zero-priority approach of Heuristic 20th. This difference in design philosophy justifies 19th being ranked above 20th, despite its incompleteness.\n\nComparing (6th/7th/8th) vs (5th/9th), heuristics 6-8 build upon the \"Best Fit\" principle (similar to 5th/9th) by explicitly adding a `perfect_fit_bonus`. This strategic bonus incentivizes \"closing\" bins, which is crucial for efficient packing. Their higher ranking suggests that directly rewarding perfect fits improves performance over a purely linear remaining capacity penalty.\n\nComparing the top-ranked (1st-4th) with other sophisticated variants like (14th/16th) and (18th), the 1st-4th heuristic's specific combination of a non-linear `rem_cap_penalty_exponent` and a `relative_fill_bonus` appears to be a highly effective formulation. The more complex 18th heuristic, despite its advanced multi-factor, context-sensitive adaptive scoring with probabilistic elements, is ranked very low. This suggests that over-engineering, poorly chosen default parameters, or the introduction of noise can significantly hinder performance in greedy heuristics, where simplicity and well-calibrated core principles often prevail.\n\nOverall, the ranking suggests that a blend of \"Best Fit\" (minimizing remaining capacity, especially with non-linear penalties), rewarding high relative utilization, and potentially incentivizing bin closure (either directly or implicitly) are key components for high-performing heuristics. Simple, pure strategies (like 10th's basic Best Fit or 12th/17th's pure fill ratio) tend to perform less well than well-tuned hybrid approaches.\n- \nHere's the redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Intelligent Bin Closure, Tuned Simplicity, Validated Complexity, Strategic Scoring.\n*   **Advice:** Prioritize aggressive bin closure using a refined Best Fit, with non-linear capacity penalties and utilization bonuses. Embrace simple, well-tuned core logic. Introduce complexity only with rigorous performance validation. Ensure choices are strategically discriminating.\n*   **Avoid:** Generic software quality discussions as primary design drivers; untuned or unvalidated complexity; heuristics offering non-discriminating choices.\n*   **Explanation:** This redefinition provides actionable, performance-centric design principles, focusing on strategic decision-making and disciplined complexity to achieve superior heuristic outcomes.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}