{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    base_fit_priority: float = 50.0,\n    rem_cap_penalty_factor: float = 3.5,\n    rem_cap_penalty_exponent: float = 1.7,\n    relative_fill_bonus_factor: float = 8.0,\n    min_allowed_priority: float = 0.5,\n    non_fitting_priority: float = -10.0\n) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function implements a refined \"Best Fit\" strategy, designed to more\n    aggressively prioritize optimal fits and encourage efficient bin utilization.\n    It introduces a non-linear penalty for remaining capacity and a significant\n    bonus for the item's relative size compared to the bin's current available space.\n\n    Args:\n        item: Size of item to be added to the bin. Must be greater than 0.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        base_fit_priority: A base score given to any bin where the item can fit.\n                           This sets the initial priority before any adjustments.\n        rem_cap_penalty_factor: A multiplier for the non-linear penalty applied\n                                based on the remaining capacity after item placement.\n                                Higher values penalize larger remaining capacities more.\n        rem_cap_penalty_exponent: An exponent (typically > 1) applied to the\n                                  remaining capacity when calculating the penalty.\n                                  A value greater than 1 makes the penalty for\n                                  larger remaining capacities disproportionately\n                                  more severe, thereby strongly favoring very tight fits\n                                  (i.e., less remaining space).\n        relative_fill_bonus_factor: A multiplier for a bonus that rewards placing\n                                    an item into a bin where it occupies a significant\n                                    proportion of the bin's *current* available capacity.\n                                    This encourages \"filling up\" bins that are already\n                                    partially utilized or finding relatively large items\n                                    for smaller remaining spaces.\n        min_allowed_priority: The minimum priority score a bin can receive if\n                              the item fits. This acts as a floor, preventing\n                              valid placement priorities from becoming too low.\n        non_fitting_priority: The priority score assigned to bins where the\n                              item does not fit. Typically a low or negative value.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities with the score for non-fitting bins\n    priorities = np.full_like(bins_remain_cap, fill_value=non_fitting_priority, dtype=float)\n\n    # Identify bins where the item can fit\n    # Item size must be strictly greater than 0 for typical BPP, so bins_remain_cap[can_fit_mask] > 0\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only process if there are bins where the item can fit\n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        remaining_after_placement = fitting_bins_remain_cap - item\n\n        # 1. Non-linear Penalty for Remaining Capacity (Enhanced Best Fit)\n        # Applying an exponent > 1 ensures that as remaining_after_placement increases,\n        # the penalty grows disproportionately faster than a linear penalty,\n        # thus heavily favoring bins that result in very little remaining space.\n        rem_cap_penalty = rem_cap_penalty_factor * (remaining_after_placement ** rem_cap_penalty_exponent)\n\n        # 2. Relative Fill Bonus\n        # This bonus term rewards placing the item where it constitutes a larger\n        # fraction of the *current* available capacity in the bin.\n        # This encourages filling up bins that are already partially full,\n        # or fitting smaller items into smaller remaining gaps, thereby \"tidying up\" bins.\n        # Division by zero is inherently avoided here because if item > 0, then\n        # fitting_bins_remain_cap must be > 0 (as fitting_bins_remain_cap >= item).\n        relative_fill_ratio = item / fitting_bins_remain_cap\n        relative_fill_bonus = relative_fill_bonus_factor * relative_fill_ratio\n\n        # Combine the base priority, non-linear penalty, and relative fill bonus\n        calculated_priorities = base_fit_priority - rem_cap_penalty + relative_fill_bonus\n\n        # Ensure that the calculated priority does not fall below a minimum allowed value\n        calculated_priorities = np.maximum(calculated_priorities, min_allowed_priority)\n\n        # Assign the calculated priorities to the corresponding bins\n        priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority scores for each bin, based on an \"Adaptive Fullness Prioritization\" heuristic.\n\n    This heuristic mutates the standard 'Best Fit' by introducing strategic considerations\n    for space management beyond simple minimization of remaining capacity. It aims to:\n\n    1.  **Strongly Reward Perfect Fits**: A perfect fit (leaving 0 remaining capacity)\n        is the most efficient use of space, effectively \"closing\" a bin. This is\n        given a significant bonus.\n    2.  **Prioritize High Overall Utilization**: Similar to Best Fit, bins that\n        become very full after placing the item are generally preferred.\n    3.  **Penalize Fragmented Space**: A minor penalty is applied to bins that\n        are left with a very small, non-zero remaining capacity. Such 'fragments'\n        are often too small to be useful for subsequent items and can lead to\n        wasted space or increased bin count if many such bins accumulate.\n        This encourages the selection of bins that either achieve a perfect fit,\n        or leave a more 'useful' (larger) amount of remaining space, allowing for\n        greater flexibility for future items.\n\n    The goal is to not just minimize residual space, but to do so in a way\n    that minimizes \"unusable\" small fragments, promoting overall\n    packing efficiency and potentially reducing the number of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        BIN_CAPACITY: The maximum capacity of a single bin. Default to 1.0,\n                      assuming item and capacities are normalized.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        Higher scores indicate a more desirable bin. Bins where the item does not\n        fit receive a score of -infinity.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity after hypothetical placement for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Primary scoring component: Utilization after placing the item.\n    # A higher utilization means less remaining space, similar to Best Fit.\n    # Scores range from 0 (empty bin after placement) to 1 (full bin).\n    utilization_score = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n\n    # Define a small epsilon for floating point comparisons to handle near-zero values.\n    epsilon = 1e-9\n\n    # Strategic Bonus: Strongly reward perfect fits.\n    # Using np.isclose for robust floating point comparison to zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=epsilon)\n    # Adding a substantial bonus (e.g., 1.0) makes perfect fits unequivocally\n    # the highest priority, pushing their score beyond the normal 0-1 range.\n    utilization_score[perfect_fit_mask] += 1.0\n\n    # Strategic Penalty: Slightly penalize very small, non-zero remaining capacities.\n    # These are deemed \"fragmented\" or potentially \"wasted\" space.\n    # The threshold for what constitutes a \"small fragment\" can be tuned,\n    # here set to 5% of the bin capacity.\n    fragment_threshold = 0.05 * BIN_CAPACITY\n    \n    # Identify bins that have a small, non-zero remainder.\n    # Ensure it's greater than epsilon to not penalize perfect fits.\n    fragment_mask = (remaining_after_fit > epsilon) & (remaining_after_fit < fragment_threshold)\n    \n    # Subtract a small penalty (e.g., 0.1) to make these bins slightly less\n    # attractive compared to those leaving a more useful or zero remainder.\n    utilization_score[fragment_mask] -= 0.1\n\n    # Assign the calculated scores to the bins where the item can fit.\n    scores[can_fit_mask] = utilization_score\n\n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that Heuristic 1st employs a sophisticated multi-factor scoring system, incorporating a non-linear penalty for remaining capacity and a bonus for relative fill, aiming to optimize bin utilization. In stark contrast, Heuristic 20th simply returns an array of zeros, effectively providing no intelligent guidance for bin selection and leading to arbitrary placement. This fundamental difference in strategy explains why 1st is ranked best and 20th is worst.\n\nComparing (2nd) vs (19th), Heuristic 2nd is a highly refined strategy similar to 1st, adding an explicit bonus for perfect fits. Heuristic 19th, like 20th, returns all zeros, offering no strategic value. The performance difference mirrors that of 1st vs 20th, showcasing the superiority of intelligent heuristics over no strategy.\n\nComparing (1st) vs (2nd), Heuristic 1st omits the explicit `perfect_fit_bonus` found in Heuristic 2nd. The fact that 1st performs better suggests that its combination of a non-linear penalty (where `rem_cap_penalty_exponent > 1`) and a relative fill bonus (rewarding `item / fitting_bins_remain_cap`) implicitly handles perfect and tight fits so effectively that an additional, large, explicit bonus becomes redundant or even detrimental. An overly aggressive, discrete bonus might lead to local optima that are not globally efficient, perhaps by prioritizing a perfect fit in a bin when another less \"perfect\" fit could lead to better overall packing for future items.\n\nComparing (3rd) vs (4th), both implement a `perfect_fit_bonus`. However, Heuristic 4th applies a higher bonus (`180.0` vs `150.0`) and uses a `perfect_fit_threshold` to define \"near-perfect fits\" more broadly (i.e., `remaining_after_placement <= threshold`) than 3rd's stricter `np.abs(remaining_after_placement) < perfect_fit_tolerance`. Heuristic 3rd being better than 4th indicates that making the \"perfect fit\" bonus too large or applying it too broadly (to a wider threshold) can degrade performance. This reinforces the idea that over-incentivizing specific conditions might lead to less optimal global solutions in complex packing scenarios.\n\nComparing (19th) vs (20th), both heuristics are identical, returning `np.zeros_like(bins_remain_cap)`. This implies they offer no intelligence in bin selection and are thus equally poor, ranking at the very bottom.\n\nOverall: The best-performing heuristics (1st-6th) leverage multi-component scoring. A non-linear penalty for remaining capacity is highly effective for promoting tight fits. The \"relative fill bonus\" (prioritizing items that occupy a large proportion of *current* available bin space) appears to be a crucial component for efficient bin utilization. Simpler heuristics, such as pure \"Best Fit\" (13th, 14th) or \"Proportional Fill\" (10th, 15th), perform poorly, as do those relying only on linear penalties (7th, 8th). Explicit \"perfect fit\" bonuses, while intuitive, need careful calibration, as the top heuristic (1st) excels without one, suggesting a smoothly weighted function can implicitly capture this goal better than an abrupt, large bonus. Complex heuristics (e.g., 16th), even with good ideas, can perform poorly if parameters are not optimally tuned.\n- \nHere's a redefined 'Current self-reflection' to design better heuristics:\n\n*   **Keywords:** Continuous Scoring, Parameter Calibration, Performance Validation, Objective Alignment.\n*   **Advice:** Design heuristics with continuous, multi-factor scoring functions that non-linearly prioritize efficient resource utilization and bin closure. Meticulously calibrate all parameters to align precisely with the optimization objective, enhancing foundational principles like Best Fit.\n*   **Avoid:** Relying on untuned, overly simplistic, or unvalidated complex strategies. Do not conflate basic functional correctness or code clarity with core heuristic performance design principles. Shun non-discriminating or trivial decision rules.\n*   **Explanation:** Superior heuristics emerge from rigorously tuned, objective-driven scoring functions, where every component is validated to maximize strategic decision-making and overall system performance.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}