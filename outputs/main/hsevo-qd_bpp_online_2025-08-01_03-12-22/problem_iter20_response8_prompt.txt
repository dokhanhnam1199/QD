{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                bins_remain_cap: np.ndarray,\n                base_fit_priority: float = 40.67957013415283,\n                remaining_capacity_penalty_factor: float = 2.527225052325968,\n                min_allowed_priority: float = 0.5896372460377476,\n                non_fitting_priority: float = -8.783827459234484,\n                perfect_fit_bonus: float = 10.0,\n                perfect_fit_epsilon: float = 1e-9) -> np.ndarray:\n    \"\"\"Combines Best Fit with a strong bonus for perfect item placement.\n    Prioritizes minimizing remaining bin capacity while significantly rewarding bins\n    that are completely filled by the item, improving space utilization.\n    \"\"\"\n    # Initialize all priorities with the value for non-fitting bins\n    priorities = np.full_like(bins_remain_cap, fill_value=non_fitting_priority, dtype=float)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only process if there are bins where the item can fit\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity for bins where the item could be placed\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n\n        # Calculate the base priority using a \"Best Fit\" approach\n        # This penalizes larger remaining capacities, encouraging a tight fit.\n        calculated_priorities = base_fit_priority - (remaining_capacity_penalty_factor * remaining_after_placement)\n\n        # Apply a significant bonus for \"perfect fits\" (remaining capacity is nearly zero).\n        # This incentivizes closing bins efficiently.\n        perfect_fit_mask_local = np.isclose(remaining_after_placement, 0.0, atol=perfect_fit_epsilon)\n        calculated_priorities[perfect_fit_mask_local] += perfect_fit_bonus\n\n        # Ensure that the calculated priority does not fall below a minimum allowed value\n        calculated_priorities = np.maximum(calculated_priorities, min_allowed_priority)\n\n        # Assign the calculated priorities to the corresponding bins\n        priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that Heuristic 1st employs a sophisticated multi-factor scoring system, incorporating a non-linear penalty for remaining capacity and a bonus for relative fill, aiming to optimize bin utilization. In stark contrast, Heuristic 20th simply returns an array of zeros, effectively providing no intelligent guidance for bin selection and leading to arbitrary placement. This fundamental difference in strategy explains why 1st is ranked best and 20th is worst.\n\nComparing (2nd) vs (19th), Heuristic 2nd is a highly refined strategy similar to 1st, adding an explicit bonus for perfect fits. Heuristic 19th, like 20th, returns all zeros, offering no strategic value. The performance difference mirrors that of 1st vs 20th, showcasing the superiority of intelligent heuristics over no strategy.\n\nComparing (1st) vs (2nd), Heuristic 1st omits the explicit `perfect_fit_bonus` found in Heuristic 2nd. The fact that 1st performs better suggests that its combination of a non-linear penalty (where `rem_cap_penalty_exponent > 1`) and a relative fill bonus (rewarding `item / fitting_bins_remain_cap`) implicitly handles perfect and tight fits so effectively that an additional, large, explicit bonus becomes redundant or even detrimental. An overly aggressive, discrete bonus might lead to local optima that are not globally efficient, perhaps by prioritizing a perfect fit in a bin when another less \"perfect\" fit could lead to better overall packing for future items.\n\nComparing (3rd) vs (4th), both implement a `perfect_fit_bonus`. However, Heuristic 4th applies a higher bonus (`180.0` vs `150.0`) and uses a `perfect_fit_threshold` to define \"near-perfect fits\" more broadly (i.e., `remaining_after_placement <= threshold`) than 3rd's stricter `np.abs(remaining_after_placement) < perfect_fit_tolerance`. Heuristic 3rd being better than 4th indicates that making the \"perfect fit\" bonus too large or applying it too broadly (to a wider threshold) can degrade performance. This reinforces the idea that over-incentivizing specific conditions might lead to less optimal global solutions in complex packing scenarios.\n\nComparing (19th) vs (20th), both heuristics are identical, returning `np.zeros_like(bins_remain_cap)`. This implies they offer no intelligence in bin selection and are thus equally poor, ranking at the very bottom.\n\nOverall: The best-performing heuristics (1st-6th) leverage multi-component scoring. A non-linear penalty for remaining capacity is highly effective for promoting tight fits. The \"relative fill bonus\" (prioritizing items that occupy a large proportion of *current* available bin space) appears to be a crucial component for efficient bin utilization. Simpler heuristics, such as pure \"Best Fit\" (13th, 14th) or \"Proportional Fill\" (10th, 15th), perform poorly, as do those relying only on linear penalties (7th, 8th). Explicit \"perfect fit\" bonuses, while intuitive, need careful calibration, as the top heuristic (1st) excels without one, suggesting a smoothly weighted function can implicitly capture this goal better than an abrupt, large bonus. Complex heuristics (e.g., 16th), even with good ideas, can perform poorly if parameters are not optimally tuned.\n- \nHere's a redefined 'Current self-reflection' to design better heuristics:\n\n*   **Keywords:** Continuous Scoring, Parameter Calibration, Performance Validation, Objective Alignment.\n*   **Advice:** Design heuristics with continuous, multi-factor scoring functions that non-linearly prioritize efficient resource utilization and bin closure. Meticulously calibrate all parameters to align precisely with the optimization objective, enhancing foundational principles like Best Fit.\n*   **Avoid:** Relying on untuned, overly simplistic, or unvalidated complex strategies. Do not conflate basic functional correctness or code clarity with core heuristic performance design principles. Shun non-discriminating or trivial decision rules.\n*   **Explanation:** Superior heuristics emerge from rigorously tuned, objective-driven scoring functions, where every component is validated to maximize strategic decision-making and overall system performance.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}