```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes bins by Best Fit (minimizing remainder) and penalizes tiny,
    fragmented spaces. Combines core efficiency with strategic waste reduction.
    """
    # Initialize scores for all bins to negative infinity, ensuring un-fittable bins are never chosen.
    # This is a fundamental step for "Focused Discrimination".
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Mask for bins where the item can fit. Only these bins are valid candidates.
    can_fit_mask = bins_remain_cap >= item

    # Calculate remaining capacity if item were placed. This is the core "Best Fit" principle,
    # which directly minimizes absolute wasted space (a "Core Intuition").
    remaining_after_fit = bins_remain_cap[can_fit_mask] - item
    
    # Initial score: negative of remaining capacity. A perfect fit (0 remainder) gets the highest score (0.0).
    scores[can_fit_mask] = -remaining_after_fit

    # Define thresholds for what constitutes a "tiny" and potentially "unusable" remainder.
    # These parameters are fixed and are chosen for "Parameter Prudence", balancing overall performance.
    TINY_REMAINDER_THRESHOLD = 0.05  # e.g., 5% of an assumed normalized bin capacity
    PENALTY_FOR_TINY_REMAINDER = 0.001 # A small penalty, ensuring perfect fits remain highest.

    # Identify valid bins that would result in a very small, non-zero remainder.
    # A small epsilon (1e-9) is used to robustly check for non-zero floating-point values.
    tiny_remainder_cond = (remaining_after_fit > 1e-9) & (remaining_after_fit < TINY_REMAINDER_THRESHOLD)

    # Apply a penalty to scores of bins leaving tiny, potentially unusable fragments.
    # This "Controlled Refinement" discourages highly fragmented space, promoting either
    # perfect fits or larger, potentially useful remaining gaps.
    scores[can_fit_mask][tiny_remainder_cond] -= PENALTY_FOR_TINY_REMAINDER

    return scores
```
