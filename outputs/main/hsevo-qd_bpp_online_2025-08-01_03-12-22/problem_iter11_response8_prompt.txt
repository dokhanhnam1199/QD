{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which to add an item to each bin, evolving beyond simple\n    'Best Fit' by incorporating a strategic incentive for achieving high bin utilization.\n\n    This heuristic implements an 'Adaptive Strategy' by dynamically weighting\n    the decision based on the resulting fullness of a bin. It refines the\n    'Search Dynamics' by guiding the placement towards configurations that\n    efficiently consolidate items, thus leading to potentially fewer bins.\n    The function 'exploits patterns' by recognizing and significantly rewarding\n    scenarios where placing an item results in a very highly utilized bin,\n    thereby aiming to 'close' bins effectively. While direct 'Parameter Learning'\n    is outside this function's scope, the strategic parameters (e.g., UTIL_POWER,\n    BONUS_SCALING_FACTOR) are designed to be tunable to adapt to different\n    problem characteristics or distributions, allowing for emergent, superior performance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        BIN_CAPACITY: The total capacity of a single bin. This is a crucial\n                      parameter for calculating utilization and is assumed to be uniform.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are a composite of the 'Best Fit' principle (minimizing remaining\n        capacity) and a non-linear bonus for bins that become highly utilized.\n        Bins where the item does not fit receive a score of -infinity.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the base Best Fit score for fitting bins.\n    # This is the negative of the remaining capacity after placing the item.\n    # A perfect fit (0 remaining) yields a base score of 0, which is the highest.\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    best_fit_scores = -remaining_after_fit\n\n    # Calculate the new utilization of the bin if the item were placed there.\n    # Utilization is the filled portion of the bin relative to its total capacity.\n    new_utilization = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n\n    # --- Strategic Utilization Bonus ---\n    # This component drives the 'adaptive strategy' and 'pattern exploitation'.\n    # We apply a non-linear bonus to highly utilized bins.\n    # The higher the new_utilization, the disproportionately larger the bonus becomes.\n    # This strongly incentivizes configurations that make bins very full,\n    # thereby contributing to overall bin reduction.\n\n    # POWER determines how aggressively the bonus increases with utilization.\n    # A higher power (e.g., 3.0, 4.0) heavily penalizes lower utilization\n    # and significantly rewards extremely high utilization.\n    UTIL_POWER = 4.0\n\n    # SCALING_FACTOR controls the overall magnitude of the bonus relative to the base score.\n    # This can be tuned to balance the 'tight fit' vs. 'full bin' objectives.\n    BONUS_SCALING_FACTOR = 5.0\n\n    # CLIP_MIN_UTIL sets a threshold below which the utilization bonus starts to apply.\n    # This prevents giving a bonus for bins that are still mostly empty after placement,\n    # focusing the incentive on bins genuinely moving towards completion.\n    CLIP_MIN_UTIL = 0.5\n\n    # Calculate an 'effective utilization' for bonus calculation.\n    # This ensures that only the portion of utilization above CLIP_MIN_UTIL contributes,\n    # and no bonus is applied if utilization is below the threshold.\n    effective_utilization = np.maximum(0.0, new_utilization - CLIP_MIN_UTIL)\n\n    # The bonus is scaled by the item size to reflect that larger items\n    # contributing to a full bin have a more significant impact.\n    # The exponential application of `UTIL_POWER` makes this bonus highly\n    # sensitive to the final utilization, prioritizing near-full bins.\n    utilization_bonus = (effective_utilization**UTIL_POWER) * item * BONUS_SCALING_FACTOR\n\n    # Combine the Best Fit score with the strategic utilization bonus.\n    # The final score guides the 'search dynamics' towards a more globally\n    # optimal packing arrangement by balancing local tightness with overall\n    # bin consolidation.\n    scores[can_fit_mask] = best_fit_scores + utilization_bonus\n\n    return scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see that they are identical. They implement a \"proportional fill\" heuristic, prioritizing bins where the item consumes the highest ratio of the bin's *remaining* capacity (`item / bins_remain_cap`). This approach, surprisingly ranked highest, suggests that aggressively filling a bin relative to its current emptiness, thereby quickly pushing it towards full utilization or closure, is more effective for this problem than minimizing absolute remaining space or relying on broader utilization bonuses.\n\nComparing (3rd) vs (4th), Heuristic 3rd, a complex Best Fit combined with a non-linear bonus for high bin utilization, significantly outperforms Heuristic 4th, which is Best Fit with a simple penalty for tiny remainders. This indicates that a strong, non-linear incentive to achieve very full bins (as in 3rd) is a more potent strategy for overall efficiency than merely discouraging small fragments. The scaling of the bonus by `item` in 3rd also suggests valuing larger items' contribution to bin completion.\n\nComparing (5th) vs (6th), Heuristic 6th, which adds a minor penalty for leaving very small, non-zero remainders on top of Best Fit, performs better than Heuristic 5th, the pure Best Fit. This demonstrates that even subtle improvements like discouraging fragmentation can yield measurable gains over a foundational heuristic, highlighting the importance of managing \"unusable\" leftover space.\n\nComparing (7th) vs (8th), Heuristic 7th, an \"Adaptive Fullness Prioritization\" which explicitly rewards perfect fits and penalizes fragments, is ranked higher than Heuristic 8th, the standard Best Fit. This reinforces that targeted bonuses for perfect fits (leading to full bin closure) and explicit penalties for fragmented space significantly improve packing efficiency beyond simple minimization of remaining capacity.\n\nComparing (9th) vs (10th), Heuristic 9th (identical to 3rd), with its non-linear utilization bonus, outperforms Heuristic 10th (identical to 5th and 8th), the standard Best Fit. This further supports the value of sophisticated, goal-oriented scoring mechanisms over basic heuristics.\n\nComparing (19th) vs (20th), these two are identical and ranked lowest. They return an array of zeros or a constant priority, effectively providing no intelligent guidance for bin selection. Their position at the bottom of the list unequivocally demonstrates that any form of thoughtful prioritization, even a simple Best Fit, is vastly superior to a non-discriminating approach.\n\nOverall: The ranking strongly suggests that for optimal bin packing, heuristics should move beyond simple \"best fit\" to incorporate sophisticated strategies. The best performing heuristics prioritize relative progress towards bin completion (proportional fill) or provide strong, non-linear incentives for achieving high utilization and perfect fits, while also actively managing fragmented space through penalties. Simply returning zeros or a constant value yields the worst performance, underscoring the necessity of intelligent decision-making at each placement step.\n- \n*   **Keywords**: Emergent Complexity, Adaptive Scoring, Probabilistic Selection, High-Dimensional Tuning.\n*   **Advice**: Design heuristics with self-adjusting weights for multi-factor scores based on observed performance. Integrate probabilistic decision components that evolve over time, favoring highly utilized states. Explore non-monotonic, context-sensitive reward functions.\n*   **Avoid**: Simple objectives, explicit problem data mapping for informed decisions, intuitive expressions, or focusing on implementation clarity and predefined optimal differentiation.\n*   **Explanation**: This approach fosters emergent, dynamic behaviors beyond fixed logic, requiring sophisticated tuning across a complex, adaptive landscape, pushing past superficial simplicity.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}