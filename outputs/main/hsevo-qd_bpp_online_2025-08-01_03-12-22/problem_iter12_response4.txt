```python
import numpy as np

def _sigmoid(x: float) -> float:
    """Helper sigmoid function for non-linear weighting, ensuring numerical stability."""
    # Clip x to prevent overflow in np.exp for very large negative values
    x = np.clip(x, -500, 500) 
    return 1 / (1 + np.exp(-x))

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    This heuristic transcends simple 'Best Fit' by embodying principles of
    emergent complexity, adaptive scoring, and probabilistic selection. It
    constructs a non-monotonic, context-sensitive reward function by blending
    multiple objectives:

    1.  **Hyper-Tight Fit Preference (Non-linear Gaussian-like Peak):**
        Provides an exceedingly high reward for bins where the item fits
        perfectly or leaves a minuscule, near-zero remaining capacity. This
        component utilizes a squared exponential (Gaussian-like) function,
        creating a sharp, disproportionate peak at zero remainder, emphasizing
        the 'perfect fit' as a highly desirable, almost crystallizing state.

    2.  **Strategic Remaining Capacity Utility (Sigmoid-based):**
        Actively manages the utility of the remaining space. It applies a soft
        penalty for 'awkwardly small' non-zero remainders (which might be too
        small to be useful for subsequent items, leading to fragmentation) and
        progressively rewards bins that leave a 'sufficiently large' amount
        of space. This component employs a sigmoid function, allowing for a
        smooth, non-linear transition in utility perception around a defined
        'useful space' threshold.

    3.  **Stochastic Exploration Component:**
        Introduces a small, dynamic perturbation to the final score. This
        probabilistic element serves to:
        a) Break strict deterministic ties in scenarios where multiple bins
           yield very similar composite scores, preventing pathological
           selections.
        b) Foster emergent packing patterns by occasionally favoring a slightly
           sub-optimal local choice, potentially leading to superior global
           configurations over time through exploration of the solution space.
        The "adaptive" aspect, in a full system, would involve this component
        evolving based on historical performance or problem state, but here,
        its magnitude is a fixed, high-dimensional tuning parameter.

    The combination of these elements moves beyond explicit, intuitive
    mappings, encouraging dynamic behaviors and a complex, adaptive scoring
    landscape, embodying the notion of "emergent complexity."

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.
                         Assumes bins are normalized (e.g., total capacity 1.0).

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Bins where the item does not fit receive a score of -infinity.
        The bin with the largest composite score is chosen.
    """
    # --- Tunable Parameters (representing "High-Dimensional Tuning") ---
    # These values define the "adaptive" and "emergent" behavior of the heuristic.
    # In a truly adaptive system, these would self-adjust based on observed performance.

    # Weight for the non-linear tight-fit component. Dominant factor.
    WEIGHT_HYPER_TIGHT_FIT = 100.0
    # Steepness of the tight-fit peak (higher = sharper preference for zero remainder).
    ALPHA_HYPER_TIGHT_FIT = 150.0 

    # Weight for the strategic useful-remainder component.
    WEIGHT_STRATEGIC_REMAINDER = 10.0
    # Steepness of the sigmoid transition for useful remainder.
    BETA_STRATEGIC_REMAINDER = 30.0
    # Threshold below which remaining space is considered 'awkward' or less useful.
    # E.g., if a bin has <15% of its capacity left after placing an item, it's less preferred
    # UNLESS it's a perfect fit (handled by HYPER_TIGHT_FIT).
    THRESHOLD_USEFUL_SPACE = 0.15 

    # Magnitude of the stochastic perturbation. Small to avoid randomizing good choices,
    # but large enough to break ties and encourage exploration.
    WEIGHT_STOCHASTIC_EXPLORATION = 0.08 

    # Initialize scores for all bins to negative infinity.
    # This ensures bins where the item cannot fit are never selected.
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Identify bins where the item has sufficient remaining capacity.
    can_fit_mask = bins_remain_cap >= item

    # Calculate the *new* remaining capacity for valid bins after placing the item.
    remainder = bins_remain_cap[can_fit_mask] - item

    # --- Component 1: Hyper-Tight Fit Preference ---
    # Rewards remainders very close to zero with a steep, non-linear function.
    # Emphasizes perfect or near-perfect utilization.
    score_hyper_tight_fit = WEIGHT_HYPER_TIGHT_FIT * np.exp(-ALPHA_HYPER_TIGHT_FIT * (remainder**2))

    # --- Component 2: Strategic Remaining Capacity Utility ---
    # Values remaining space that is either zero (handled by C1) or sufficiently large.
    # It penalizes remainders that are small but non-zero, as they might be less useful.
    score_strategic_remainder = WEIGHT_STRATEGIC_REMAINDER * _sigmoid(BETA_STRATEGIC_REMAINDER * (remainder - THRESHOLD_USEFUL_SPACE))

    # --- Component 3: Stochastic Exploration ---
    # Adds a small, random component to scores, enabling probabilistic selection
    # and exploration of the solution space for emergent patterns.
    score_stochastic_exploration = WEIGHT_STOCHASTIC_EXPLORATION * np.random.rand(len(remainder))

    # Combine all components for the final priority score for valid bins.
    scores[can_fit_mask] = score_hyper_tight_fit + score_strategic_remainder + score_stochastic_exploration

    return scores
```
