{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Focuses on maximizing bin utilization by prioritizing bins that offer the highest proportional fill.\n\n    This heuristic adaptively weighs each bin's suitability based on the item's\n    relative size to the bin's current capacity, exploiting the pattern\n    of high-density packing for efficient bin closure.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity, ensuring bins where\n    # the item cannot fit are never selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins with sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate the 'fill ratio': the proportion of the bin's\n    # current remaining capacity that the item would occupy.\n    # This adaptively prioritizes bins that, upon accommodating the item, achieve\n    # the highest relative utilization, leading to a more compact packing strategy.\n    # A higher ratio indicates a tighter fit relative to the available space,\n    # exploiting the pattern of efficient, high-density placement.\n    # Note: Assumes item > 0. If item is 0, division would be 0/X (score 0), which is handled.\n    # If item > 0 and bins_remain_cap is 0, can_fit_mask would be False.\n    scores[can_fit_mask] = item / bins_remain_cap[can_fit_mask]\n\n    return scores\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Focuses on maximizing bin utilization by prioritizing bins that offer the highest proportional fill.\n\n    This heuristic adaptively weighs each bin's suitability based on the item's\n    relative size to the bin's current capacity, exploiting the pattern\n    of high-density packing for efficient bin closure.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity, ensuring bins where\n    # the item cannot fit are never selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins with sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate the 'fill ratio': the proportion of the bin's\n    # current remaining capacity that the item would occupy.\n    # This adaptively prioritizes bins that, upon accommodating the item, achieve\n    # the highest relative utilization, leading to a more compact packing strategy.\n    # A higher ratio indicates a tighter fit relative to the available space,\n    # exploiting the pattern of efficient, high-density placement.\n    # Note: Assumes item > 0. If item is 0, division would be 0/X (score 0), which is handled.\n    # If item > 0 and bins_remain_cap is 0, can_fit_mask would be False.\n    scores[can_fit_mask] = item / bins_remain_cap[can_fit_mask]\n\n    return scores\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add an item to each bin, evolving beyond simple\n    'Best Fit' by incorporating a strategic incentive for achieving high bin utilization.\n\n    This heuristic implements an 'Adaptive Strategy' by dynamically weighting\n    the decision based on the resulting fullness of a bin. It refines the\n    'Search Dynamics' by guiding the placement towards configurations that\n    efficiently consolidate items, thus leading to potentially fewer bins.\n    The function 'exploits patterns' by recognizing and significantly rewarding\n    scenarios where placing an item results in a very highly utilized bin,\n    thereby aiming to 'close' bins effectively. While direct 'Parameter Learning'\n    is outside this function's scope, the strategic parameters (e.g., UTIL_POWER,\n    BONUS_SCALING_FACTOR) are designed to be tunable to adapt to different\n    problem characteristics or distributions, allowing for emergent, superior performance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        BIN_CAPACITY: The total capacity of a single bin. This is a crucial\n                      parameter for calculating utilization and is assumed to be uniform.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are a composite of the 'Best Fit' principle (minimizing remaining\n        capacity) and a non-linear bonus for bins that become highly utilized.\n        Bins where the item does not fit receive a score of -infinity.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the base Best Fit score for fitting bins.\n    # This is the negative of the remaining capacity after placing the item.\n    # A perfect fit (0 remaining) yields a base score of 0, which is the highest.\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    best_fit_scores = -remaining_after_fit\n\n    # Calculate the new utilization of the bin if the item were placed there.\n    # Utilization is the filled portion of the bin relative to its total capacity.\n    new_utilization = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n\n    # --- Strategic Utilization Bonus ---\n    # This component drives the 'adaptive strategy' and 'pattern exploitation'.\n    # We apply a non-linear bonus to highly utilized bins.\n    # The higher the new_utilization, the disproportionately larger the bonus becomes.\n    # This strongly incentivizes configurations that make bins very full,\n    # thereby contributing to overall bin reduction.\n\n    # POWER determines how aggressively the bonus increases with utilization.\n    # A higher power (e.g., 3.0, 4.0) heavily penalizes lower utilization\n    # and significantly rewards extremely high utilization.\n    UTIL_POWER = 4.0\n\n    # SCALING_FACTOR controls the overall magnitude of the bonus relative to the base score.\n    # This can be tuned to balance the 'tight fit' vs. 'full bin' objectives.\n    BONUS_SCALING_FACTOR = 5.0\n\n    # CLIP_MIN_UTIL sets a threshold below which the utilization bonus starts to apply.\n    # This prevents giving a bonus for bins that are still mostly empty after placement,\n    # focusing the incentive on bins genuinely moving towards completion.\n    CLIP_MIN_UTIL = 0.5\n\n    # Calculate an 'effective utilization' for bonus calculation.\n    # This ensures that only the portion of utilization above CLIP_MIN_UTIL contributes,\n    # and no bonus is applied if utilization is below the threshold.\n    effective_utilization = np.maximum(0.0, new_utilization - CLIP_MIN_UTIL)\n\n    # The bonus is scaled by the item size to reflect that larger items\n    # contributing to a full bin have a more significant impact.\n    # The exponential application of `UTIL_POWER` makes this bonus highly\n    # sensitive to the final utilization, prioritizing near-full bins.\n    utilization_bonus = (effective_utilization**UTIL_POWER) * item * BONUS_SCALING_FACTOR\n\n    # Combine the Best Fit score with the strategic utilization bonus.\n    # The final score guides the 'search dynamics' towards a more globally\n    # optimal packing arrangement by balancing local tightness with overall\n    # bin consolidation.\n    scores[can_fit_mask] = best_fit_scores + utilization_bonus\n\n    return scores\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority score for each bin. Combines Best Fit with a penalty for very small, non-zero remainders.\n    Prioritizes perfect fits, then larger useful gaps over tiny unusable ones, aiming to minimize wasted fragmented space.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity, ensuring un-fittable bins are never chosen.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity if item were placed. This is the core Best Fit principle.\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    # Initial score: negative of remaining capacity. Perfect fit (0 remainder) gets 0.0 (highest).\n    scores[can_fit_mask] = -remaining_after_fit\n\n    # Define thresholds for what constitutes a \"tiny\" and potentially \"unusable\" remainder.\n    # These values are empirical and might need tuning based on typical item/bin size distributions.\n    TINY_REMAINDER_THRESHOLD = 0.05  # e.g., 5% of an assumed normalized bin capacity (e.g., if max capacity is 1.0)\n    PENALTY_FOR_TINY_REMAINDER = 0.001 # A small penalty, ensuring a perfect fit (0 remainder) still receives the highest score.\n\n    # Identify valid bins that would result in a very small, non-zero remainder.\n    # A small epsilon (1e-9) is used to robustly check for non-zero floating-point values.\n    tiny_remainder_cond = (remaining_after_fit > 1e-9) & (remaining_after_fit < TINY_REMAINDER_THRESHOLD)\n\n    # Apply a penalty to the scores of bins that leave a tiny, potentially unusable remainder.\n    # This slightly discourages leaving highly fragmented space, encouraging either a perfect fit\n    # or a more substantial, potentially useful remaining gap for future, larger items.\n    scores[can_fit_mask][tiny_remainder_cond] -= PENALTY_FOR_TINY_REMAINDER\n\n    return scores\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the principles of efficient space-time utilization, this\n    heuristic aims to find the 'tightest fit' for the item.\n    A tighter fit means less wasted space within a bin, optimizing the\n    overall density of packing and minimizing the necessity for new bins.\n\n    From my perspective, 'Best Fit' is analogous to minimizing the\n    residual 'field distortion' (unused capacity) in a local region\n    (a bin). We prioritize bins that, upon accommodating the item, leave\n    the smallest possible, yet positive, remaining capacity. A perfect fit,\n    leaving zero residual capacity, is the most efficient use of space\n    and is therefore given the highest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are calculated as the negative of the remaining capacity after\n        the item is placed. Bins where the item does not fit receive a score\n        of -infinity to ensure they are never chosen.\n        The bin with the largest (least negative) score is the 'best fit'.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity.\n    # This ensures that bins where the item cannot fit will never be selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For the bins where the item fits, calculate the remaining capacity\n    # if the item were to be placed there.\n    # We want to minimize this remaining capacity to achieve a 'tight fit'.\n    # Hence, we take the negative of this value:\n    # A smaller positive remainder (e.g., 0.1) becomes a larger negative score (-0.1).\n    # A perfect fit (0.0 remainder) becomes the highest score (0.0).\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    scores[can_fit_mask] = -remaining_after_fit\n\n    return scores\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority score for each bin. Combines Best Fit with a penalty for very small, non-zero remainders.\n    Prioritizes perfect fits, then larger useful gaps over tiny unusable ones, aiming to minimize wasted fragmented space.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity, ensuring un-fittable bins are never chosen.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity if item were placed. This is the core Best Fit principle.\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    # Initial score: negative of remaining capacity. Perfect fit (0 remainder) gets 0.0 (highest).\n    scores[can_fit_mask] = -remaining_after_fit\n\n    # Define thresholds for what constitutes a \"tiny\" and potentially \"unusable\" remainder.\n    # These values are empirical and might need tuning based on typical item/bin size distributions.\n    TINY_REMAINDER_THRESHOLD = 0.05  # e.g., 5% of an assumed normalized bin capacity (e.g., if max capacity is 1.0)\n    PENALTY_FOR_TINY_REMAINDER = 0.001 # A small penalty, ensuring a perfect fit (0 remainder) still receives the highest score.\n\n    # Identify valid bins that would result in a very small, non-zero remainder.\n    # A small epsilon (1e-9) is used to robustly check for non-zero floating-point values.\n    tiny_remainder_cond = (remaining_after_fit > 1e-9) & (remaining_after_fit < TINY_REMAINDER_THRESHOLD)\n\n    # Apply a penalty to the scores of bins that leave a tiny, potentially unusable remainder.\n    # This slightly discourages leaving highly fragmented space, encouraging either a perfect fit\n    # or a more substantial, potentially useful remaining gap for future, larger items.\n    scores[can_fit_mask][tiny_remainder_cond] -= PENALTY_FOR_TINY_REMAINDER\n\n    return scores\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin, based on an \"Adaptive Fullness Prioritization\" heuristic.\n\n    This heuristic mutates the standard 'Best Fit' by introducing strategic considerations\n    for space management beyond simple minimization of remaining capacity. It aims to:\n\n    1.  **Strongly Reward Perfect Fits**: A perfect fit (leaving 0 remaining capacity)\n        is the most efficient use of space, effectively \"closing\" a bin. This is\n        given a significant bonus.\n    2.  **Prioritize High Overall Utilization**: Similar to Best Fit, bins that\n        become very full after placing the item are generally preferred.\n    3.  **Penalize Fragmented Space**: A minor penalty is applied to bins that\n        are left with a very small, non-zero remaining capacity. Such 'fragments'\n        are often too small to be useful for subsequent items and can lead to\n        wasted space or increased bin count if many such bins accumulate.\n        This encourages the selection of bins that either achieve a perfect fit,\n        or leave a more 'useful' (larger) amount of remaining space, allowing for\n        greater flexibility for future items.\n\n    The goal is to not just minimize residual space, but to do so in a way\n    that minimizes \"unusable\" small fragments, promoting overall\n    packing efficiency and potentially reducing the number of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        BIN_CAPACITY: The maximum capacity of a single bin. Default to 1.0,\n                      assuming item and capacities are normalized.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score for each bin.\n        Higher scores indicate a more desirable bin. Bins where the item does not\n        fit receive a score of -infinity.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity after hypothetical placement for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Primary scoring component: Utilization after placing the item.\n    # A higher utilization means less remaining space, similar to Best Fit.\n    # Scores range from 0 (empty bin after placement) to 1 (full bin).\n    utilization_score = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n\n    # Define a small epsilon for floating point comparisons to handle near-zero values.\n    epsilon = 1e-9\n\n    # Strategic Bonus: Strongly reward perfect fits.\n    # Using np.isclose for robust floating point comparison to zero.\n    perfect_fit_mask = np.isclose(remaining_after_fit, 0.0, atol=epsilon)\n    # Adding a substantial bonus (e.g., 1.0) makes perfect fits unequivocally\n    # the highest priority, pushing their score beyond the normal 0-1 range.\n    utilization_score[perfect_fit_mask] += 1.0\n\n    # Strategic Penalty: Slightly penalize very small, non-zero remaining capacities.\n    # These are deemed \"fragmented\" or potentially \"wasted\" space.\n    # The threshold for what constitutes a \"small fragment\" can be tuned,\n    # here set to 5% of the bin capacity.\n    fragment_threshold = 0.05 * BIN_CAPACITY\n    \n    # Identify bins that have a small, non-zero remainder.\n    # Ensure it's greater than epsilon to not penalize perfect fits.\n    fragment_mask = (remaining_after_fit > epsilon) & (remaining_after_fit < fragment_threshold)\n    \n    # Subtract a small penalty (e.g., 0.1) to make these bins slightly less\n    # attractive compared to those leaving a more useful or zero remainder.\n    utilization_score[fragment_mask] -= 0.1\n\n    # Assign the calculated scores to the bins where the item can fit.\n    scores[can_fit_mask] = utilization_score\n\n    return scores\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the principles of efficient space-time utilization, this\n    heuristic aims to find the 'tightest fit' for the item.\n    A tighter fit means less wasted space within a bin, optimizing the\n    overall density of packing and minimizing the necessity for new bins.\n\n    From my perspective, 'Best Fit' is analogous to minimizing the\n    residual 'field distortion' (unused capacity) in a local region\n    (a bin). We prioritize bins that, upon accommodating the item, leave\n    the smallest possible, yet positive, remaining capacity. A perfect fit,\n    leaving zero residual capacity, is the most efficient use of space\n    and is therefore given the highest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are calculated as the negative of the remaining capacity after\n        the item is placed. Bins where the item does not fit receive a score\n        of -infinity to ensure they are never chosen.\n        The bin with the largest (least negative) score is the 'best fit'.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity.\n    # This ensures that bins where the item cannot fit will never be selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For the bins where the item fits, calculate the remaining capacity\n    # if the item were to be placed there.\n    # We want to minimize this remaining capacity to achieve a 'tight fit'.\n    # Hence, we take the negative of this value:\n    # A smaller positive remainder (e.g., 0.1) becomes a larger negative score (-0.1).\n    # A perfect fit (0.0 remainder) becomes the highest score (0.0).\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    scores[can_fit_mask] = -remaining_after_fit\n\n    return scores\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, BIN_CAPACITY: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Returns priority with which to add an item to each bin, evolving beyond simple\n    'Best Fit' by incorporating a strategic incentive for achieving high bin utilization.\n\n    This heuristic implements an 'Adaptive Strategy' by dynamically weighting\n    the decision based on the resulting fullness of a bin. It refines the\n    'Search Dynamics' by guiding the placement towards configurations that\n    efficiently consolidate items, thus leading to potentially fewer bins.\n    The function 'exploits patterns' by recognizing and significantly rewarding\n    scenarios where placing an item results in a very highly utilized bin,\n    thereby aiming to 'close' bins effectively. While direct 'Parameter Learning'\n    is outside this function's scope, the strategic parameters (e.g., UTIL_POWER,\n    BONUS_SCALING_FACTOR) are designed to be tunable to adapt to different\n    problem characteristics or distributions, allowing for emergent, superior performance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        BIN_CAPACITY: The total capacity of a single bin. This is a crucial\n                      parameter for calculating utilization and is assumed to be uniform.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are a composite of the 'Best Fit' principle (minimizing remaining\n        capacity) and a non-linear bonus for bins that become highly utilized.\n        Bins where the item does not fit receive a score of -infinity.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the base Best Fit score for fitting bins.\n    # This is the negative of the remaining capacity after placing the item.\n    # A perfect fit (0 remaining) yields a base score of 0, which is the highest.\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    best_fit_scores = -remaining_after_fit\n\n    # Calculate the new utilization of the bin if the item were placed there.\n    # Utilization is the filled portion of the bin relative to its total capacity.\n    new_utilization = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n\n    # --- Strategic Utilization Bonus ---\n    # This component drives the 'adaptive strategy' and 'pattern exploitation'.\n    # We apply a non-linear bonus to highly utilized bins.\n    # The higher the new_utilization, the disproportionately larger the bonus becomes.\n    # This strongly incentivizes configurations that make bins very full,\n    # thereby contributing to overall bin reduction.\n\n    # POWER determines how aggressively the bonus increases with utilization.\n    # A higher power (e.g., 3.0, 4.0) heavily penalizes lower utilization\n    # and significantly rewards extremely high utilization.\n    UTIL_POWER = 4.0\n\n    # SCALING_FACTOR controls the overall magnitude of the bonus relative to the base score.\n    # This can be tuned to balance the 'tight fit' vs. 'full bin' objectives.\n    BONUS_SCALING_FACTOR = 5.0\n\n    # CLIP_MIN_UTIL sets a threshold below which the utilization bonus starts to apply.\n    # This prevents giving a bonus for bins that are still mostly empty after placement,\n    # focusing the incentive on bins genuinely moving towards completion.\n    CLIP_MIN_UTIL = 0.5\n\n    # Calculate an 'effective utilization' for bonus calculation.\n    # This ensures that only the portion of utilization above CLIP_MIN_UTIL contributes,\n    # and no bonus is applied if utilization is below the threshold.\n    effective_utilization = np.maximum(0.0, new_utilization - CLIP_MIN_UTIL)\n\n    # The bonus is scaled by the item size to reflect that larger items\n    # contributing to a full bin have a more significant impact.\n    # The exponential application of `UTIL_POWER` makes this bonus highly\n    # sensitive to the final utilization, prioritizing near-full bins.\n    utilization_bonus = (effective_utilization**UTIL_POWER) * item * BONUS_SCALING_FACTOR\n\n    # Combine the Best Fit score with the strategic utilization bonus.\n    # The final score guides the 'search dynamics' towards a more globally\n    # optimal packing arrangement by balancing local tightness with overall\n    # bin consolidation.\n    scores[can_fit_mask] = best_fit_scores + utilization_bonus\n\n    return scores\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the principles of efficient space-time utilization, this\n    heuristic aims to find the 'tightest fit' for the item.\n    A tighter fit means less wasted space within a bin, optimizing the\n    overall density of packing and minimizing the necessity for new bins.\n\n    From my perspective, 'Best Fit' is analogous to minimizing the\n    residual 'field distortion' (unused capacity) in a local region\n    (a bin). We prioritize bins that, upon accommodating the item, leave\n    the smallest possible, yet positive, remaining capacity. A perfect fit,\n    leaving zero residual capacity, is the most efficient use of space\n    and is therefore given the highest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are calculated as the negative of the remaining capacity after\n        the item is placed. Bins where the item does not fit receive a score\n        of -infinity to ensure they are never chosen.\n        The bin with the largest (least negative) score is the 'best fit'.\n    \"\"\"\n    # Initialize scores for all bins to negative infinity.\n    # This ensures that bins where the item cannot fit will never be selected.\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Determine which bins have sufficient remaining capacity for the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For the bins where the item fits, calculate the remaining capacity\n    # if the item were to be placed there.\n    # We want to minimize this remaining capacity to achieve a 'tight fit'.\n    # Hence, we take the negative of this value:\n    # A smaller positive remainder (e.g., 0.1) becomes a larger negative score (-0.1).\n    # A perfect fit (0.0 remainder) becomes the highest score (0.0).\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    scores[can_fit_mask] = -remaining_after_fit\n\n    return scores\n\n[Heuristics 11th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, default_priority_value: float = 0.6879606910044531) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        default_priority_value: The base priority value used to initialize the priority array.\n                                In the original implementation, this was implicitly 0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # The original implementation implicitly returned an array filled with zeros.\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, default_priority_value: float = 0.6879606910044531) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        default_priority_value: The base priority value used to initialize the priority array.\n                                In the original implementation, this was implicitly 0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # The original implementation implicitly returned an array filled with zeros.\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, default_priority_value: float = 0.6879606910044531) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        default_priority_value: The base priority value used to initialize the priority array.\n                                In the original implementation, this was implicitly 0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # The original implementation implicitly returned an array filled with zeros.\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, default_priority_value: float = 0.6879606910044531) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        default_priority_value: The base priority value used to initialize the priority array.\n                                In the original implementation, this was implicitly 0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # The original implementation implicitly returned an array filled with zeros.\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, default_priority_value: float = 0.6879606910044531) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        default_priority_value: The base priority value used to initialize the priority array.\n                                In the original implementation, this was implicitly 0.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # The original implementation implicitly returned an array filled with zeros.\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}