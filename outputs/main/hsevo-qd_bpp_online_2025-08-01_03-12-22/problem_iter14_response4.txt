```python
import numpy as np

# Global constant for bin capacity. In a real system, this might be a parameter
# passed around or part of a Bin class. For simplicity, assuming a standard capacity.
BIN_CAPACITY = 1.0

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritizes bins using an aggressive "Best Fit" strategy, emphasizing
    minimal remaining capacity with non-linear penalties and subtle noise.
    """
    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    can_fit_mask = bins_remain_cap >= item
    
    # If no bin can fit the item, return early with all scores as -inf.
    if not np.any(can_fit_mask):
        return scores

    fitting_bins_idx = np.where(can_fit_mask)[0]
    current_bin_caps = bins_remain_cap[fitting_bins_idx]
    remaining_after_fit = current_bin_caps - item

    # --- Core Best Fit (Aggressive Quantum Fit) ---
    # This is the primary driver, applying a non-linear penalty for wasted space.
    # A perfect fit (0 remaining) yields a score of 0, while any remaining capacity
    # results in an increasingly negative score, exponentially worse for larger remainders.
    # This strongly encourages minimizing the empty space in a bin.
    score_quantum_fit = -np.expm1(remaining_after_fit / BIN_CAPACITY)

    # --- Simple Fragment Penalty ---
    # Introduce a fixed penalty for leaving very small, potentially unusable fragments
    # (e.g., less than 1% of bin capacity), discouraging inefficient leftover spaces.
    MIN_USABLE_FRAGMENT = 0.01 * BIN_CAPACITY 
    FRAGMENT_PENALTY_MAGNITUDE = 0.2 
    
    score_fragment_penalty = np.zeros_like(remaining_after_fit)
    is_small_fragment = (remaining_after_fit > 0) & (remaining_after_fit < MIN_USABLE_FRAGMENT)
    score_fragment_penalty[is_small_fragment] = -FRAGMENT_PENALTY_MAGNITUDE

    # --- Exploration Noise ---
    # A very small, constant amount of Gaussian noise is added to break ties
    # between bins with otherwise identical or extremely similar priority scores.
    # This subtly encourages exploration without overriding the core deterministic logic.
    EXPLORATION_NOISE_SCALE = 1e-6 * BIN_CAPACITY 
    noise = np.random.normal(0, scale=EXPLORATION_NOISE_SCALE, size=len(fitting_bins_idx))

    # --- Combined Score Calculation ---
    # The overall priority score is primarily driven by the "Quantum Fit" (Best Fit),
    # with a fixed penalty for creating tiny, unusable fragments, and a tiny noise
    # component for tie-breaking. This combines strong core strategy with minor,
    # well-defined refinements.
    combined_scores_for_fitting_bins = score_quantum_fit + score_fragment_penalty + noise

    # Assign the calculated scores back to the original scores array,
    # leaving -np.inf for bins where the item does not fit.
    scores[fitting_bins_idx] = combined_scores_for_fitting_bins

    return scores
```
