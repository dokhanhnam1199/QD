{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    base_fit_priority: float = 50.0,\n    rem_cap_penalty_factor: float = 3.5,\n    rem_cap_penalty_exponent: float = 1.7,\n    relative_fill_bonus_factor: float = 8.0,\n    min_allowed_priority: float = 0.5,\n    non_fitting_priority: float = -10.0\n) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function implements a refined \"Best Fit\" strategy, designed to more\n    aggressively prioritize optimal fits and encourage efficient bin utilization.\n    It introduces a non-linear penalty for remaining capacity and a significant\n    bonus for the item's relative size compared to the bin's current available space.\n\n    Args:\n        item: Size of item to be added to the bin. Must be greater than 0.\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        base_fit_priority: A base score given to any bin where the item can fit.\n                           This sets the initial priority before any adjustments.\n        rem_cap_penalty_factor: A multiplier for the non-linear penalty applied\n                                based on the remaining capacity after item placement.\n                                Higher values penalize larger remaining capacities more.\n        rem_cap_penalty_exponent: An exponent (typically > 1) applied to the\n                                  remaining capacity when calculating the penalty.\n                                  A value greater than 1 makes the penalty for\n                                  larger remaining capacities disproportionately\n                                  more severe, thereby strongly favoring very tight fits\n                                  (i.e., less remaining space).\n        relative_fill_bonus_factor: A multiplier for a bonus that rewards placing\n                                    an item into a bin where it occupies a significant\n                                    proportion of the bin's *current* available capacity.\n                                    This encourages \"filling up\" bins that are already\n                                    partially utilized or finding relatively large items\n                                    for smaller remaining spaces.\n        min_allowed_priority: The minimum priority score a bin can receive if\n                              the item fits. This acts as a floor, preventing\n                              valid placement priorities from becoming too low.\n        non_fitting_priority: The priority score assigned to bins where the\n                              item does not fit. Typically a low or negative value.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize all priorities with the score for non-fitting bins\n    priorities = np.full_like(bins_remain_cap, fill_value=non_fitting_priority, dtype=float)\n\n    # Identify bins where the item can fit\n    # Item size must be strictly greater than 0 for typical BPP, so bins_remain_cap[can_fit_mask] > 0\n    can_fit_mask = bins_remain_cap >= item\n\n    # Only process if there are bins where the item can fit\n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        remaining_after_placement = fitting_bins_remain_cap - item\n\n        # 1. Non-linear Penalty for Remaining Capacity (Enhanced Best Fit)\n        # Applying an exponent > 1 ensures that as remaining_after_placement increases,\n        # the penalty grows disproportionately faster than a linear penalty,\n        # thus heavily favoring bins that result in very little remaining space.\n        rem_cap_penalty = rem_cap_penalty_factor * (remaining_after_placement ** rem_cap_penalty_exponent)\n\n        # 2. Relative Fill Bonus\n        # This bonus term rewards placing the item where it constitutes a larger\n        # fraction of the *current* available capacity in the bin.\n        # This encourages filling up bins that are already partially full,\n        # or fitting smaller items into smaller remaining gaps, thereby \"tidying up\" bins.\n        # Division by zero is inherently avoided here because if item > 0, then\n        # fitting_bins_remain_cap must be > 0 (as fitting_bins_remain_cap >= item).\n        relative_fill_ratio = item / fitting_bins_remain_cap\n        relative_fill_bonus = relative_fill_bonus_factor * relative_fill_ratio\n\n        # Combine the base priority, non-linear penalty, and relative fill bonus\n        calculated_priorities = base_fit_priority - rem_cap_penalty + relative_fill_bonus\n\n        # Ensure that the calculated priority does not fall below a minimum allowed value\n        calculated_priorities = np.maximum(calculated_priorities, min_allowed_priority)\n\n        # Assign the calculated priorities to the corresponding bins\n        priorities[can_fit_mask] = calculated_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which to add an item to each bin, evolving beyond simple\n    'Best Fit' by incorporating a strategic incentive for achieving high bin utilization.\n\n    This heuristic implements an 'Adaptive Strategy' by dynamically weighting\n    the decision based on the resulting fullness of a bin. It refines the\n    'Search Dynamics' by guiding the placement towards configurations that\n    efficiently consolidate items, thus leading to potentially fewer bins.\n    The function 'exploits patterns' by recognizing and significantly rewarding\n    scenarios where placing an item results in a very highly utilized bin,\n    thereby aiming to 'close' bins effectively. While direct 'Parameter Learning'\n    is outside this function's scope, the strategic parameters (e.g., UTIL_POWER,\n    BONUS_SCALING_FACTOR) are designed to be tunable to adapt to different\n    problem characteristics or distributions, allowing for emergent, superior performance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        BIN_CAPACITY: The total capacity of a single bin. This is a crucial\n                      parameter for calculating utilization and is assumed to be uniform.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores are a composite of the 'Best Fit' principle (minimizing remaining\n        capacity) and a non-linear bonus for bins that become highly utilized.\n        Bins where the item does not fit receive a score of -infinity.\n    \"\"\"\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the base Best Fit score for fitting bins.\n    # This is the negative of the remaining capacity after placing the item.\n    # A perfect fit (0 remaining) yields a base score of 0, which is the highest.\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    best_fit_scores = -remaining_after_fit\n\n    # Calculate the new utilization of the bin if the item were placed there.\n    # Utilization is the filled portion of the bin relative to its total capacity.\n    new_utilization = (BIN_CAPACITY - remaining_after_fit) / BIN_CAPACITY\n\n    # --- Strategic Utilization Bonus ---\n    # This component drives the 'adaptive strategy' and 'pattern exploitation'.\n    # We apply a non-linear bonus to highly utilized bins.\n    # The higher the new_utilization, the disproportionately larger the bonus becomes.\n    # This strongly incentivizes configurations that make bins very full,\n    # thereby contributing to overall bin reduction.\n\n    # POWER determines how aggressively the bonus increases with utilization.\n    # A higher power (e.g., 3.0, 4.0) heavily penalizes lower utilization\n    # and significantly rewards extremely high utilization.\n    UTIL_POWER = 4.0\n\n    # SCALING_FACTOR controls the overall magnitude of the bonus relative to the base score.\n    # This can be tuned to balance the 'tight fit' vs. 'full bin' objectives.\n    BONUS_SCALING_FACTOR = 5.0\n\n    # CLIP_MIN_UTIL sets a threshold below which the utilization bonus starts to apply.\n    # This prevents giving a bonus for bins that are still mostly empty after placement,\n    # focusing the incentive on bins genuinely moving towards completion.\n    CLIP_MIN_UTIL = 0.5\n\n    # Calculate an 'effective utilization' for bonus calculation.\n    # This ensures that only the portion of utilization above CLIP_MIN_UTIL contributes,\n    # and no bonus is applied if utilization is below the threshold.\n    effective_utilization = np.maximum(0.0, new_utilization - CLIP_MIN_UTIL)\n\n    # The bonus is scaled by the item size to reflect that larger items\n    # contributing to a full bin have a more significant impact.\n    # The exponential application of `UTIL_POWER` makes this bonus highly\n    # sensitive to the final utilization, prioritizing near-full bins.\n    utilization_bonus = (effective_utilization**UTIL_POWER) * item * BONUS_SCALING_FACTOR\n\n    # Combine the Best Fit score with the strategic utilization bonus.\n    # The final score guides the 'search dynamics' towards a more globally\n    # optimal packing arrangement by balancing local tightness with overall\n    # bin consolidation.\n    scores[can_fit_mask] = best_fit_scores + utilization_bonus\n\n    return scores\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), (3rd) vs (4th), (5th) vs (9th), (6th) vs (7th) vs (8th), (12th) vs (17th), (13th) vs (15th), and (14th) vs (16th), we observe that the source code for the functions is *identical* within these ranked groups. This implies that their differences in ranking from best to worst must stem entirely from the specific *default parameter values* chosen, highlighting the paramount importance of hyperparameter tuning for heuristic performance, rather than fundamental algorithmic differences between these identically coded functions.\n\nComparing (best - 1st) vs (worst - 20th), the 1st heuristic employs a sophisticated, multi-factor scoring combining a non-linear penalty for remaining capacity (`rem_cap_penalty_exponent`) and a bonus for the item's relative size to the bin's current available space (`relative_fill_bonus`). This aggressively favors tight fits and efficient bin utilization. In stark contrast, the 20th heuristic is trivial, returning `np.zeros_like`, effectively assigning equal priority to all bins and offering no strategic guidance for packing, resulting in arbitrary or First Fit-like behavior, explaining its lowest rank.\n\nComparing (19th - second worst) vs (20th - worst), even though Heuristic 19th is incomplete, its comments and initial structure reveal an intention to combine proportional fill, non-linear high utilization bonuses, and fragmentation penalties. This demonstrates a conceptual attempt at a complex, multi-criteria heuristic, which is inherently more sophisticated than the completely non-discriminatory, zero-priority approach of Heuristic 20th. This difference in design philosophy justifies 19th being ranked above 20th, despite its incompleteness.\n\nComparing (6th/7th/8th) vs (5th/9th), heuristics 6-8 build upon the \"Best Fit\" principle (similar to 5th/9th) by explicitly adding a `perfect_fit_bonus`. This strategic bonus incentivizes \"closing\" bins, which is crucial for efficient packing. Their higher ranking suggests that directly rewarding perfect fits improves performance over a purely linear remaining capacity penalty.\n\nComparing the top-ranked (1st-4th) with other sophisticated variants like (14th/16th) and (18th), the 1st-4th heuristic's specific combination of a non-linear `rem_cap_penalty_exponent` and a `relative_fill_bonus` appears to be a highly effective formulation. The more complex 18th heuristic, despite its advanced multi-factor, context-sensitive adaptive scoring with probabilistic elements, is ranked very low. This suggests that over-engineering, poorly chosen default parameters, or the introduction of noise can significantly hinder performance in greedy heuristics, where simplicity and well-calibrated core principles often prevail.\n\nOverall, the ranking suggests that a blend of \"Best Fit\" (minimizing remaining capacity, especially with non-linear penalties), rewarding high relative utilization, and potentially incentivizing bin closure (either directly or implicitly) are key components for high-performing heuristics. Simple, pure strategies (like 10th's basic Best Fit or 12th/17th's pure fill ratio) tend to perform less well than well-tuned hybrid approaches.\n- \nHere's the redefined self-reflection for designing better heuristics:\n\n*   **Keywords:** Intelligent Bin Closure, Tuned Simplicity, Validated Complexity, Strategic Scoring.\n*   **Advice:** Prioritize aggressive bin closure using a refined Best Fit, with non-linear capacity penalties and utilization bonuses. Embrace simple, well-tuned core logic. Introduce complexity only with rigorous performance validation. Ensure choices are strategically discriminating.\n*   **Avoid:** Generic software quality discussions as primary design drivers; untuned or unvalidated complexity; heuristics offering non-discriminating choices.\n*   **Explanation:** This redefinition provides actionable, performance-centric design principles, focusing on strategic decision-making and disciplined complexity to achieve superior heuristic outcomes.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}