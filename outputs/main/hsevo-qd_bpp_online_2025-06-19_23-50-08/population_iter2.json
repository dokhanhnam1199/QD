[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Prioritize bins where the item fits well, leaving minimal wasted space.\n    # However, strongly penalize bins where the item *doesn't* fit.\n\n    fit = item <= bins_remain_cap\n    waste = bins_remain_cap - item\n    \n    priorities[~fit] = -np.inf  # Impossible to fit, very low priority\n\n    # Emphasize filling up more capacity (higher fill rate is better), and punish little wasted space to incentivize near-perfect fills, avoid smaller fragments.\n\n    priorities[fit] = (item / bins_remain_cap[fit]) + np.exp(-waste[waste >= 0] * 10) # Adjusted exponent\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 199.7052750908657,
    "mi": 82.52195939041982,
    "token_count": 162.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering fill rate, waste, and infeasibility.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    fit = item <= bins_remain_cap\n    waste = bins_remain_cap - item\n\n    priorities[~fit] = -np.inf  # Impossible to fit\n\n    # Fill ratio + waste penalty, adjusted penalty strength for finer control.\n    priorities[fit] = (item / bins_remain_cap[fit]) + np.exp(-waste[waste >= 0] * 5)\n\n    # Refinement: slight bonus for bins that will have remaining capacity close to the average item size.\n    avg_item_size = np.mean(item)  # Average item for online setting\n    remaining_after_fit = bins_remain_cap[fit] - item\n    priorities[fit] += np.exp(-np.abs(remaining_after_fit - avg_item_size) * 2) # Add bonus\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 3.9589150378939015,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 103.72627427729671,
    "mi": 91.14963151192664,
    "token_count": 105.0,
    "exec_success": true
  }
]