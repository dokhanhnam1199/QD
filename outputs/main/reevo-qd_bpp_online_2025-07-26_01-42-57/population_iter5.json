[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on prioritizing exact fits, penalizing large gaps,\n    and considering item characteristics to efficiently manage bin space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin, where capacity is the\n                       difference between bin size and the current total size of items inside the bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score means higher priority to place the item in the bin.\n    \"\"\"\n    # Exact fits get the highest priority\n    exact_fit_mask = (bins_remain_cap == item).astype(int) * 1000\n    \n    # Bins that can't fit the item get a very low priority\n    cannot_fit_mask = (bins_remain_cap < item).astype(int) * -1000\n    \n    # Small penalty for remaining capacity to avoid wasting space\n    small_penalty = bins_remain_cap * -0.1\n    \n    # Larger penalty for large remaining capacity to strongly discourage leaving large gaps\n    remaining_cap_diff = bins_remain_cap - item\n    large_gap_penalty = np.where(remaining_cap_diff > 0, remaining_cap_diff ** 2 * -0.01, 0)\n    \n    # Adjust penalty based on item size\n    adjusted_penalty = large_gap_penalty * (1 + np.log(item + 1) / 5)\n    \n    # Total priority score combining various components\n    priority_score = exact_fit_mask + cannot_fit_mask + small_penalty + adjusted_penalty\n    \n    return priority_score",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on prioritizing exact fits, penalizing large gaps,\n    and considering item characteristics to efficiently manage bin space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin, where capacity is the\n                       difference between bin size and the current total size of items inside the bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher score means higher priority to place the item in the bin.\n    \"\"\"\n    # Exact fits get the highest priority\n    exact_fit_mask = (bins_remain_cap == item).astype(int) * 1000\n    \n    # Bins that can't fit the item get a very low priority\n    cannot_fit_mask = (bins_remain_cap < item).astype(int) * -1000\n    \n    # Small penalty for remaining capacity to avoid wasting space\n    small_penalty = bins_remain_cap * -0.1\n    \n    # Larger penalty for large remaining capacity to strongly discourage leaving large gaps\n    remaining_cap_difference = bins_remain_cap - item\n    large_gap_penalty = np.where(remaining_cap_difference > 0, remaining_cap_difference ** 2 * -0.01, 0)\n    \n    # Adjust penalties by item size\n    item_size_adjustment = item * 0.5\n    \n    # Total priority score combining various components\n    priority_score = exact_fit_mask + cannot_fit_mask + small_penalty + large_gap_penalty + item_size_adjustment\n    \n    return priority_score",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses a logistic function to prioritize bins with minimal gaps and penalizes larger unused capacities.\n    Feasible bins (those with enough capacity) are prioritized over infeasible ones. The logistic function is used to\n    smoothly handle the transition between feasible and infeasible bins, while also penalizing larger gaps within feasible bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    import numpy as np\n\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = bins_remain_cap - item\n    # Logistic function to prioritize bins that can fit the item with minimal gap\n    feasibility_factor = 1 / (1 + np.exp(-10 * diff))\n    # Logistic function to penalize larger unused capacities smoothly\n    penalty_factor = 1 / (1 + np.exp(10 * (diff - 0.01 * bins_remain_cap)))  # Smaller gaps are more preferred\n    # Combine feasibility and penalty to get priority scores\n    priority_scores = feasibility_factor * penalty_factor\n    return priority_scores",
    "response_id": 2,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 1, in <module>\n    def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\nNameError: name 'np' is not defined\n6\n1\n"
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on prioritizing exact fits, penalizing large gaps, and considering item characteristics to efficiently manage bin space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin, where capacity is the difference between bin size and the current total size of items inside the bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin. Higher score means higher priority to place the item in the bin.\n    \"\"\"\n    # Exact fits get the highest priority\n    exact_fit_mask = (bins_remain_cap == item).astype(int) * 1000\n    \n    # Bins that can't fit the item get a very low priority\n    cannot_fit_mask = (bins_remain_cap < item).astype(int) * -1000\n    \n    # Small penalty for remaining capacity to avoid wasting space\n    small_penalty = bins_remain_cap * -0.1\n    \n    # Larger penalty for large remaining capacity to strongly discourage leaving large gaps\n    large_gap_penalty = -((bins_remain_cap - item) ** 2) * 0.01\n    \n    # Total priority score combining various components\n    priority_score = exact_fit_mask + cannot_fit_mask + small_penalty + large_gap_penalty\n    \n    return priority_score",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses a logistic function to prioritize bins with minimal gaps and penalizes larger unused capacities.\n    Infeasible bins (those with insufficient capacity) are given a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = bins_remain_cap - item\n    # Logistic function to prioritize bins that can fit the item\n    feasible = (diff >= 0).astype(float)\n    # Penalize larger unused capacities using a sigmoid function\n    penalty_factor = 1 / (1 + np.exp(diff / item))\n    # Combine feasibility and penalty to get priority scores\n    priority_scores = feasible * (1 - penalty_factor)\n    return priority_scores",
    "response_id": 4,
    "obj": 149.27203829278022,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses a logistic function to prioritize bins with minimal gaps and penalizes larger unused capacities.\n    Infeasible bins (those with insufficient capacity) are given a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = bins_remain_cap - item\n    # Logistic function to prioritize bins that can fit the item\n    feasible = (diff >= 0).astype(float)\n    # Penalize larger unused capacities using a sigmoid function\n    penalty_factor = 1 / (1 + np.exp(diff / item))\n    # Combine feasibility and penalty to get priority scores\n    priority_scores = feasible * (1 - penalty_factor)\n    return priority_scores",
    "response_id": 5,
    "obj": 149.27203829278022,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that can fit the item while also considering the remaining capacity\n    after the item is added. It aims to minimize the capacity usage post-fit, while heavily penalizing bins that\n    would be nearly filled by the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Check if the item can fit in each bin\n    can_fit = (bins_remain_cap >= item).astype(float)\n    \n    # Avoid division by zero by adding a small epsilon value\n    epsilon = 1e-6\n    \n    # Calculate the remaining capacity after adding the item for bins where the item can fit\n    remaining_capacity_after_fit = bins_remain_cap - item\n    \n    # Calculate the priority score: prioritize bins with larger remaining capacity after adding the item\n    # Use a more nuanced approach to penalize bins that fill up nearly\n    priority_scores = can_fit * (np.exp(-(item / (remaining_capacity_after_fit + epsilon))))\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 149.30195452732352,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation minimizes gaps between item size and remaining bin capacity,\n    prioritizing bins that nearly fit the item while ensuring the bin can actually fit the item.\n    A sigmoid function is used to create a smooth transition in priority scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Strong penalty for bins that cannot fit the item\n    priority_scores = np.where(bins_remain_cap >= item, bins_remain_cap - item, -10000 * np.ones_like(bins_remain_cap))\n    \n    # Use sigmoid function to smooth the priority scores\n    priority_scores = 1 / (1 + np.exp(-priority_scores / item))\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 149.27203829278022,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to fill bins with the minimal capacity difference to the item size,\n    provided the bin has enough capacity to fit the item, promoting compact packing efficiently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate absolute difference between item size and remaining capacity in each bin\n    diff = np.abs(bins_remain_cap - item)\n    # Priority is high if the difference is low and the bin has enough capacity\n    priority_scores = np.where(bins_remain_cap >= item, 1 / (1 + diff), 0)\n    # Normalize scores to be between 0 and 1\n    priority_scores = priority_scores / (np.max(priority_scores) + 1e-6)\n    return priority_scores",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to minimize the gaps between item size and bin capacity,\n    penalize larger unused capacities while ensuring feasibility. It uses a modified\n    logistic function to achieve a balanced prioritization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = bins_remain_cap - item\n    \n    # Penalize larger unused capacities using a sigmoid-like function\n    penalty_factor = 1 / (1 + np.exp(diff / item))  # Adjusting the scale with item size\n    \n    # Feasible bins should have a positive score, infeasible ones get zero\n    feasible = (diff >= 0).astype(float)\n    \n    # Combine feasibility and penalty to get priority scores\n    priority_scores = feasible * penalty_factor\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on exact fits, penalizes large gaps using a logistic function for flexible penalties,\n    and prioritizes bins nearly fitting the item size while discouraging large unused capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = np.abs(bins_remain_cap - item)\n    # Logistic function to create penalty for large gaps\n    penalty = 1 / (1 + np.exp(0.5 * diff))\n    # Ensure only bins with enough capacity are considered\n    priority_scores = np.where(bins_remain_cap >= item, penalty, 0)\n    return priority_scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on exact fits, penalizes large gaps using a logistic function for flexible penalties,\n    and prioritizes bins nearly fitting the item size while discouraging large unused capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = np.abs(bins_remain_cap - item)\n    # Logistic function to create penalty for large gaps\n    penalty = 1 / (1 + np.exp(0.5 * diff))\n    # Ensure only bins with enough capacity are considered\n    priority_scores = np.where(bins_remain_cap >= item, penalty, 0)\n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on exact fits, penalizes large gaps using a logistic function for flexible penalties,\n    and prioritizes bins nearly fitting the item size while discouraging large unused capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = np.abs(bins_remain_cap - item)\n    # Logistic function to create penalty for large gaps\n    penalty = 1 / (1 + np.exp(0.5 * (diff - 0.1 * bins_remain_cap)))\n    # Priority is high if the difference is low, the bin has enough capacity, and the penalty is low\n    priority_scores = np.where(bins_remain_cap >= item, 1 - penalty, 0)\n    return priority_scores",
    "response_id": 2,
    "obj": 148.06541683286798,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on exact fits, penalizes large gaps using a logistic function to flexibly penalize unused capacity, and prioritizes bins nearly fitting the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the gap between item size and remaining capacity in each bin\n    gap = bins_remain_cap - item\n    # Logistic function to penalize large gaps\n    log_penalization = 1 / (1 + np.exp(-0.5 * gap))\n    # Priority is high if the bin has enough capacity and the gap is penalized\n    priority_scores = np.where(bins_remain_cap >= item, 1 - log_penalization, 0)\n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on exact fits, penalizes large gaps using a logistic function for flexible penalties,\n    and prioritizes bins nearly fitting the item size while discouraging large unused capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between item size and remaining capacity in each bin\n    diff = np.abs(bins_remain_cap - item)\n    # Logistic function to give high priority to bins with small differences and enough capacity\n    priority_scores = np.where(bins_remain_cap >= item, 1 / (1 + np.exp(diff)), 0)\n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]