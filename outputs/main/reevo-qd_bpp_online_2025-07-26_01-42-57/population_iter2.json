[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on minimizing gaps by prioritizing bins with minimal\n    remaining capacity above the item size and penalizes larger unused capacities.\n    It also slightly devalues newer bins for balanced utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Find bins that can accommodate the item\n    possible_bins = bins_remain_cap >= item\n    \n    # Initialize scores with negative infinity for impossible bins\n    scores = np.full_like(bins_remain_cap, -np.inf)\n    \n    # Calculate the gap for possible bins\n    gaps = bins_remain_cap[possible_bins] - item\n    \n    # Prioritize bins with minimal gaps\n    scores[possible_bins] = 1 / (1 + gaps)  # Use 1/(1+gap) to assign higher priority to smaller gaps\n    \n    # Penalize larger unused capacities in possible bins\n    scores[possible_bins] -= 0.5 * (bins_remain_cap[possible_bins] - item)\n    \n    # Slightly devalue newer bins for balanced utilization\n    scores -= 0.01 * np.arange(len(bins_remain_cap))  # Assuming bins_remain_cap is in order of creation\n    \n    return scores",
    "response_id": 0,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 34, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n4\n1\n"
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins with more remaining capacity that can fit the item.\n    Bins that cannot accommodate the item receive a priority score of -np.inf.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority values to the remaining capacity\n    priority_values = bins_remain_cap.copy()\n    \n    # Set priority of bins which cannot fit the current item to a very low value\n    priority_values[bins_remain_cap < item] = -np.inf\n    \n    return priority_values",
    "response_id": 1,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 23, in priority_v2\n    # Set a very low priority for bins that cannot fit the item\nOverflowError: cannot convert float infinity to integer\n4\n1\n"
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses a logistic function to give higher priority to bins\n    that are closer to being full (encouraging space utilization). It heavily\n    penalizes bins that cannot fit the item by setting their priority to a very low\n    value. The logistic function ensures that bins with enough remaining capacity\n    are favored, with a preference towards more full bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Set a very low priority for bins that cannot fit the item\n    priority_scores = np.where(bins_remain_cap >= item, bins_remain_cap - item, -10000 * np.ones_like(bins_remain_cap))\n    # Use logistic function to transform remaining capacities to priority scores\n    priority_scores = 1 / (1 + np.exp(-priority_scores))\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 77.46310331072995,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on prioritizing exact fits, penalizing large gaps, and considering item characteristics to efficiently manage bin space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin, where capacity is the difference between bin size and the current total size of items inside the bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin. Higher score means higher priority to place the item in the bin.\n    \"\"\"\n    # Exact fits get the highest priority\n    exact_fit_mask = (bins_remain_cap == item).astype(int) * 1000\n    \n    # Bins that can't fit the item get a very low priority\n    cannot_fit_mask = (bins_remain_cap < item).astype(int) * -1000\n    \n    # Small penalty for remaining capacity to avoid wasting space\n    small_penalty = bins_remain_cap * -0.1\n    \n    # Larger penalty for large remaining capacity to strongly discourage leaving large gaps\n    large_gap_penalty = np.maximum((bins_remain_cap - item) ** 2 * -0.01, -5)\n    \n    # Total priority score combining various components\n    priority_score = exact_fit_mask + cannot_fit_mask + small_penalty + large_gap_penalty\n    \n    return priority_score",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on whether the item can fit in each bin and minimizes the capacity usage\n    in order to keep bins open for future items. It penalizes bins that would be filled too much by the item.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Check if the item can fit in each bin\n    can_fit = (bins_remain_cap >= item).astype(int)\n    \n    # Avoid division by zero by adding a small epsilon value\n    epsilon = 1e-6\n    \n    # Calculate the remaining capacity after adding the item for bins where the item can fit\n    remaining_capacity_after_fit = bins_remain_cap - item\n    \n    # Calculate the priority score: prioritize bins with larger remaining capacity after adding the item\n    # Inverse of remaining capacity after fit + epsilon ensures that bins that fill up the item completely get low priority\n    priority_scores = can_fit / (remaining_capacity_after_fit + epsilon)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are closer to being full, but strongly penalizes\n    bins that cannot fit the item. A sigmoid function is used to create a smooth transition in\n    priority scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Strong penalty for bins that cannot fit the item\n    priority_scores = np.where(bins_remain_cap >= item, bins_remain_cap, -10000 * np.ones_like(bins_remain_cap))\n    \n    # Use sigmoid function to smooth the priority scores\n    priority_scores = 1 / (1 + np.exp(-priority_scores / item))\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 149.27203829278022,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on the remaining capacity, penalizes bins\n    that cannot fit the item, and boosts the bin with the second smallest gap to\n    minimize fragmentation and maximize bin usage.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority scores\n    priority = np.zeros_like(bins_remain_cap)\n    \n    # Calculate remaining capacity if item is added\n    remaining_after_insertion = bins_remain_cap - item\n    \n    # Penalize bins that cannot fit the item\n    priority[remaining_after_insertion < 0] = -np.inf\n    \n    # Prioritize bins with the least gaps (highest remaining capacity after insertion)\n    priority[remaining_after_insertion >= 0] = remaining_after_insertion\n    \n    # Find the second smallest gap (excluding non-feasible bins)\n    feasible_remainings = remaining_after_insertion[remaining_after_insertion >= 0]\n    if len(feasible_remainings) > 1:\n        # Sort unique remaining capacities to find the second smallest\n        unique_remainings = np.unique(feasible_remainings)\n        if len(unique_remainings) > 1:\n            second_smallest_gap = unique_remainings[1]\n            # Boost the bin(s) with the second smallest gap\n            priority[bins_remain_cap == (second_smallest_gap + item)] += 1\n    \n    return priority",
    "response_id": 6,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 28, in priority_v2\nOverflowError: cannot convert float infinity to integer\n4\n1\n"
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to minimize gaps between item size and remaining bin capacity,\n    prioritizing bins that nearly fit the item while ensuring the bin can actually fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item in each bin\n    remaining_capacity_after_item = bins_remain_cap - item\n    \n    # Priority is high if the remaining capacity after placing the item is minimal (minimizing gaps)\n    # and the bin has enough capacity to fit the item\n    priority_scores = np.where(bins_remain_cap >= item, 1 / (1 + remaining_capacity_after_item), 0)\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on minimizing gaps by prioritizing bins with minimal\n    remaining capacity above the item size and penalizes larger unused capacities.\n    It also slightly devalues newer bins for balanced utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Find bins that can accommodate the item\n    possible_bins = bins_remain_cap >= item\n    \n    # Initialize scores with negative infinity for impossible bins\n    scores = np.full_like(bins_remain_cap, -np.inf)\n    \n    # Calculate the gap for possible bins\n    gaps = bins_remain_cap[possible_bins] - item\n    \n    # Prioritize bins with minimal gaps\n    scores[possible_bins] = 1 / (1 + gaps)  # Use 1/(1+gap) to assign higher priority to smaller gaps\n    \n    # Penalize larger unused capacities in possible bins\n    scores[possible_bins] -= 0.5 * (bins_remain_cap[possible_bins] - item)\n    \n    # Slightly devalue newer bins for balanced utilization\n    scores -= 0.01 * np.arange(len(bins_remain_cap))  # Assuming bins_remain_cap is in order of creation\n    \n    return scores",
    "response_id": 8,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 34, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n4\n1\n"
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses a logistic function to balance the priority of bins\n    based on their remaining capacity. Infeasible bins (where the remaining capacity\n    is less than the item size) are heavily penalized by assigning them a very low\n    priority score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Assign a very low score to bins that cannot fit the item\n    priority_scores = np.where(bins_remain_cap >= item, bins_remain_cap, -10000)\n    \n    # Use logistic function to balance priorities\n    priority_scores = 1 / (1 + np.exp(-priority_scores))\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 21.02114080574391,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]