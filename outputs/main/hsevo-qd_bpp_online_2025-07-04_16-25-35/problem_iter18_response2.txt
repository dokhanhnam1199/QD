```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, bin_history: np.ndarray = None) -> np.ndarray:
    """
    Combines capacity, waste, fragmentation, and empty bin considerations with adaptive weights and bin history.

    Args:
        item (float): The size of the item to be packed.
        bins_remain_cap (np.ndarray): A NumPy array containing the remaining capacity of each bin.
        bin_history (np.ndarray, optional): An array tracking how many items are already packed into each bin.
            Defaults to None (in which case it's ignored).

    Returns:
        np.ndarray: A NumPy array containing the priority score for each bin.
    """

    priority = np.zeros_like(bins_remain_cap, dtype=float)
    num_bins = len(bins_remain_cap)

    # Adaptive weights based on item size relative to average bin capacity
    avg_cap = np.mean(bins_remain_cap)
    item_ratio = item / avg_cap if avg_cap > 0 else 0

    # Sufficient capacity boost, adaptive weight
    sufficient_capacity = bins_remain_cap >= item
    sufficient_cap_weight = 1.8 + 0.6 * min(item_ratio, 1)  # Increased weight if item is large relative to bin size
    priority[sufficient_capacity] += sufficient_cap_weight

    # Minimize waste boost, adaptive weight
    waste = bins_remain_cap - item
    positive_waste = waste[waste >= 0]
    if len(positive_waste) > 0:
        min_waste = np.min(positive_waste)
        min_waste_bins_idx = np.where(waste == min_waste)[0]
        min_waste_weight = 1.2 + 0.4 * (1 - min(item_ratio, 1))  # Increased weight if item is small relative to bin size
        priority[min_waste_bins_idx] += min_waste_weight

    # Nearly full bin boost, adaptive threshold and weight
    nearly_full_threshold = 1.1 - 0.05 * min(item_ratio, 1) # Reduce threshold if item is large, encouraging packing
    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= nearly_full_threshold * item) & (bins_remain_cap >= item)
    nearly_full_weight = 2.4 + 0.8 * min(item_ratio, 1) # Increase weight if item is large
    priority[nearly_full] += nearly_full_weight

    # Small capacity based on relative availability, normalized
    small_cap = (bins_remain_cap >= item)
    if np.max(bins_remain_cap) > 0:  # Prevent division by zero
        priority[small_cap] += (bins_remain_cap[small_cap] - item) / np.max(bins_remain_cap)
    
    # Emptiness boost, adaptive weight
    is_empty = bins_remain_cap == np.max(bins_remain_cap)
    empty_bins_weight = 0.7 - 0.3 * min(item_ratio, 1) # Reduce weight if item is large, discouraging opening new bins
    priority[is_empty] += empty_bins_weight

    # Bin history: Penalize bins that already have many items packed (reduce fragmentation)
    if bin_history is not None:
        history_penalty = bin_history / np.max(bin_history) if np.max(bin_history) > 0 else 0 # Normalize bin history
        priority -= 0.5 * history_penalty

    return priority
```
