[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    priority[sufficient_capacity] += 1  # Base priority if bin can fit item\n\n    # Heuristic 2: Minimize Waste (Maximize filled space).\n    waste = bins_remain_cap - item\n    positive_waste = waste[waste >= 0] # Consider only valid waste\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where(waste == min_waste)[0]\n        priority[min_waste_bins_idx] += 2\n\n    # Heuristic 3: Prevent Fragmentation (Bins near full have high priority).\n    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= 2 * item) & (bins_remain_cap >= item)\n    priority[nearly_full] += 1.5\n\n    # Heuristic 4: Small amount of available capacity.\n    small_cap = (bins_remain_cap >= item)\n    priority[small_cap] += (bins_remain_cap[small_cap] - item) / np.max(bins_remain_cap) # Add scaled value based on relative small capacity.\n    \n    # Heuristic 5: Give higher preference if it is an empty bin.\n    is_empty = bins_remain_cap == np.max(bins_remain_cap)\n    priority[is_empty] += 0.5\n\n    return priority",
    "response_id": 1,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 53.77443751081735,
    "mi": 67.91077893705676,
    "token_count": 88.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratios with waste minimization for bin prioritization.\"\"\"\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority[sufficient_capacity] += 1\n\n    # Heuristic 2: Minimize Waste (Only for bins with sufficient capacity)\n    waste = bins_remain_cap - item\n    min_waste = np.min(waste[sufficient_capacity]) if np.any(sufficient_capacity) else np.inf\n    min_waste_bins_idx = np.where((waste == min_waste) & sufficient_capacity)[0]\n    priority[min_waste_bins_idx] += 2\n\n    # Heuristic 3: Capacity Ratio (Only for bins with sufficient capacity)\n    ratios = item / bins_remain_cap\n    ratios[~sufficient_capacity] = 0  # Ignore bins without sufficient capacity\n    priority += ratios\n\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 144.75398259382442,
    "mi": 86.58537321553837,
    "token_count": 155.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Heuristic 1: Feasibility (Essential)\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return priority  # No feasible bin, all priorities remain 0\n\n    priority[feasible] += 1.0 # Base priority for feasible bins\n\n    # Heuristic 2: Minimize Waste (First-Fit Decreasing variant)\n    waste = bins_remain_cap - item\n    positive_waste = waste[feasible] # Only consider waste in feasible bins\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where((waste == min_waste) & feasible)[0]  #Ensure we choose within the feasible set\n        priority[min_waste_bins_idx] += 3.0 # Higher priority for minimizing waste\n\n    # Heuristic 3: Avoid Fragmentation (Balancing Bin Usage)\n    # Give a slightly higher priority to bins that, after placing the item,\n    # will have a remaining capacity in the middle range of possible remaining capacities.\n    post_fill_capacities = bins_remain_cap - item\n    post_fill_capacities_feasible = post_fill_capacities[feasible]\n    if len(post_fill_capacities_feasible) > 0:\n        median_capacity = np.median(post_fill_capacities_feasible)\n        capacity_diff = np.abs(post_fill_capacities - median_capacity)\n        # Scale the priority boost inversely proportional to the capacity difference.\n        # Bins closer to the median capacity get a higher boost.\n        priority[feasible] += np.clip(1.0 - capacity_diff[feasible] / np.max(bins_remain_cap), 0, 1) #Scale and clip. Prevents negative values\n        \n\n    # Heuristic 4: Prioritize emptier bins if the item is relatively large.\n    # This helps distribute items more evenly across bins initially.\n    if item > np.mean(bins_remain_cap): # Scale by item size relative to average capacity.\n        empty_bin_indices = np.where(bins_remain_cap == np.max(bins_remain_cap))[0]\n        priority[empty_bin_indices] += 1.5\n\n    # Heuristic 5: Add a slight randomness to break ties and explore the solution space.\n    priority[feasible] += np.random.rand(np.sum(feasible)) * 0.1\n\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 26.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 385.74374433250205,
    "mi": 76.827568796314,
    "token_count": 299.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response1.txt_stdout.txt",
    "code_path": "problem_iter7_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                 sufficient_capacity_weight: float = 1.9596220015949373,\n                 min_waste_weight: float = 4.237844712440302,\n                 nearly_full_threshold_multiplier: float = 2.0406124655988833,\n                 nearly_full_weight: float = 4.224367911090436,\n                 empty_bin_weight: float = 4.8338513308698) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sufficient_capacity_weight: Weight for bins with sufficient capacity.\n        min_waste_weight: Weight for bins that minimize waste.\n        nearly_full_threshold_multiplier: Multiplier for item size to determine nearly full threshold.\n        nearly_full_weight: Weight for bins that are nearly full.\n        empty_bin_weight: Weight for empty bins.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    priority[sufficient_capacity] += sufficient_capacity_weight  # Base priority if bin can fit item\n\n    # Heuristic 2: Minimize Waste (Maximize filled space).\n    waste = bins_remain_cap - item\n    positive_waste = waste[waste >= 0] # Consider only valid waste\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where(waste == min_waste)[0]\n        priority[min_waste_bins_idx] += min_waste_weight\n\n    # Heuristic 3: Prevent Fragmentation (Bins near full have high priority).\n    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= nearly_full_threshold_multiplier * item) & (bins_remain_cap >= item)\n    priority[nearly_full] += nearly_full_weight\n\n    # Heuristic 4: Small amount of available capacity.\n    small_cap = (bins_remain_cap >= item)\n    priority[small_cap] += (bins_remain_cap[small_cap] - item) / np.max(bins_remain_cap) # Add scaled value based on relative small capacity.\n    \n    # Heuristic 5: Give higher preference if it is an empty bin.\n    is_empty = bins_remain_cap == np.max(bins_remain_cap)\n    priority[is_empty] += empty_bin_weight\n\n    return priority",
    "response_id": 1,
    "tryHS": true,
    "obj": 3.8791384124451627,
    "SLOC": 22.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 307.756981016698,
    "mi": 81.80209096280826,
    "token_count": 238.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratios, waste minimization, and fragmentation avoidance.\"\"\"\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority[sufficient_capacity] += 1\n\n    # Heuristic 2: Minimize Waste (Only for bins with sufficient capacity)\n    waste = bins_remain_cap - item\n    positive_waste = waste[sufficient_capacity]\n    min_waste = np.min(positive_waste) if positive_waste.size > 0 else np.inf\n    min_waste_bins_idx = np.where((waste == min_waste) & sufficient_capacity)[0]\n    priority[min_waste_bins_idx] += 2\n\n    # Heuristic 3: Capacity Ratio (Only for bins with sufficient capacity)\n    ratios = item / bins_remain_cap\n    ratios[~sufficient_capacity] = 0  # Ignore bins without sufficient capacity\n    priority += ratios\n\n    # Heuristic 4: Prevent Fragmentation (Bins near full have high priority).\n    nearly_full_threshold = 1.2 * item  # Adjust as needed\n    nearly_full = (bins_remain_cap > 0) & (bins_remain_cap <= nearly_full_threshold) & (bins_remain_cap >= item)\n    priority[nearly_full] += 1.5\n\n    # Heuristic 5: Prioritize Emptier Bins for Larger Items\n    empty_bin_threshold = np.max(bins_remain_cap)\n    is_empty = bins_remain_cap == empty_bin_threshold\n    priority[is_empty] += 0.8   # Slightly favor empty bins\n\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 309.6277232931715,
    "mi": 79.19005722310375,
    "token_count": 233.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                  sufficient_capacity_weight: float = 1.8066941616372154,\n                  min_waste_weight: float = 1.2369759055947915,\n                  nearly_full_threshold_multiplier: float = 1.164912650607926,\n                  nearly_full_weight: float = 2.4304538888032448,\n                  empty_bin_weight: float = 0.7700931706376539,\n                  waste_capacity_ratio_weight: float = 0.5,\n                  bin_utilization_weight: float = 1.0) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sufficient_capacity_weight: Weight for bins with sufficient capacity.\n        min_waste_weight: Weight for bins that minimize waste.\n        nearly_full_threshold_multiplier: Multiplier for item size to determine nearly full threshold.\n        nearly_full_weight: Weight for bins that are nearly full.\n        empty_bin_weight: Weight for empty bins.\n        waste_capacity_ratio_weight: Weight for the ratio of waste to bin capacity\n        bin_utilization_weight: Weight for the current bin utilization\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bin_capacity = np.max(bins_remain_cap)\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    priority[sufficient_capacity] += sufficient_capacity_weight  # Base priority if bin can fit item\n\n    # Heuristic 2: Minimize Waste (Maximize filled space).\n    waste = bins_remain_cap - item\n    positive_waste = waste[waste >= 0] # Consider only valid waste\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where(waste == min_waste)[0]\n        priority[min_waste_bins_idx] += min_waste_weight\n\n    # Heuristic 3: Prevent Fragmentation (Bins near full have high priority).\n    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= nearly_full_threshold_multiplier * item) & (bins_remain_cap >= item)\n    priority[nearly_full] += nearly_full_weight\n\n    # Heuristic 4: Small amount of available capacity and weight by normalized waste\n    sufficient_bins = bins_remain_cap >= item\n    if np.any(sufficient_bins):\n        waste_ratios = waste[sufficient_bins] / bin_capacity\n        priority[sufficient_bins] += waste_capacity_ratio_weight * (1 - waste_ratios)\n    \n    # Heuristic 5: Give higher preference if it is an empty bin.\n    is_empty = bins_remain_cap == bin_capacity\n    priority[is_empty] += empty_bin_weight\n\n    # Heuristic 6: Bin Utilization\n    bin_utilization = (bin_capacity - bins_remain_cap) / bin_capacity\n    priority += bin_utilization_weight * bin_utilization\n\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 31.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 433.2579304308557,
    "mi": 79.47398562180626,
    "token_count": 331.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity, waste, fragmentation, and empty bin considerations.\"\"\"\n\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Sufficient capacity boost\n    sufficient_capacity = bins_remain_cap >= item\n    priority[sufficient_capacity] += 1.8 #Sufficient cap weight\n\n    # Minimize waste boost\n    waste = bins_remain_cap - item\n    positive_waste = waste[waste >= 0]\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where(waste == min_waste)[0]\n        priority[min_waste_bins_idx] += 1.2  #Min waste weight\n\n    # Nearly full bin boost\n    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= 1.1 * item) & (bins_remain_cap >= item) #threshold multiplier = 1.1\n    priority[nearly_full] += 2.4 #Nearly full weight\n\n    #Small capacity based on relative availability\n    small_cap = (bins_remain_cap >= item)\n    priority[small_cap] += (bins_remain_cap[small_cap] - item) / np.max(bins_remain_cap)\n\n    #Emptiness boost\n    is_empty = bins_remain_cap == np.max(bins_remain_cap)\n    priority[is_empty] += 0.7 #Empty bins weight\n\n    return priority",
    "response_id": 9,
    "tryHS": false,
    "obj": 2.6924611088950936,
    "SLOC": 17.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 307.756981016698,
    "mi": 84.16086853866355,
    "token_count": 207.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity, waste, fragmentation, and empty bin considerations with dynamic adjustments.\"\"\"\n\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # 1. Sufficient Capacity Boost with Item Size Consideration\n    sufficient_capacity = bins_remain_cap >= item\n    priority[sufficient_capacity] += 1.8\n\n    # 2. Minimize Waste Boost with Adaptive Waste Threshold\n    waste = bins_remain_cap - item\n    positive_waste = waste[waste >= 0]\n\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where(waste == min_waste)[0]\n        priority[min_waste_bins_idx] += 1.2\n\n        #Adaptive waste threshold based on the item size\n        adaptive_waste_threshold = 0.2 * item\n        small_waste_bins = (waste >= 0) & (waste <= adaptive_waste_threshold)\n        priority[small_waste_bins] += 0.6 # Added small waste weight\n\n    # 3. Nearly Full Bin Boost with Dynamic Threshold\n    nearly_full_threshold = 1.1 # Initial threshold\n    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= nearly_full_threshold * item) & (bins_remain_cap >= item)\n    priority[nearly_full] += 2.4\n\n    # 4. Small Capacity Based on Relative Availability (Normalized)\n    sufficient_bins = bins_remain_cap >= item\n    if np.any(sufficient_bins):\n        max_remaining_cap = np.max(bins_remain_cap[sufficient_bins])\n        priority[sufficient_bins] += (bins_remain_cap[sufficient_bins] - item) / max_remaining_cap #Normalizing\n    \n    # 5. Empty Bin Consideration with bin utilization\n    is_empty = bins_remain_cap == np.max(bins_remain_cap)\n    priority[is_empty] += 0.7\n\n    #6. Penalize bins close to full but can't fit the item\n\n    cannot_fit = (bins_remain_cap < item) & (bins_remain_cap > 0)\n    priority[cannot_fit] -= 0.5\n\n    #7. Reward higher bin utilization globally (Encourage packing)\n\n    total_capacity = np.sum(bins_remain_cap)\n    bin_utilization_score = (num_bins - (total_capacity/np.max(bins_remain_cap)))/num_bins #Scale between 0 and 1\n    priority += 0.2 * bin_utilization_score\n\n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 2.9417630634224174,
    "SLOC": 31.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 856.9045644567952,
    "mi": 74.43441032100107,
    "token_count": 376.0,
    "exec_success": true
  }
]