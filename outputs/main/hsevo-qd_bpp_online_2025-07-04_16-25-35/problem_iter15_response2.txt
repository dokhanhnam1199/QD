```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines capacity, waste, fragmentation, and empty bin considerations with adaptive weights."""

    priority = np.zeros_like(bins_remain_cap, dtype=float)

    # Sufficient capacity boost
    sufficient_capacity = bins_remain_cap >= item
    priority[sufficient_capacity] += 1.9  #Sufficient cap weight increased

    # Minimize waste boost
    waste = bins_remain_cap - item
    positive_waste = waste[waste >= 0]
    if len(positive_waste) > 0:
        min_waste = np.min(positive_waste)
        min_waste_bins_idx = np.where(waste == min_waste)[0]
        priority[min_waste_bins_idx] += 1.3 #Min waste weight increased
        #Boost inversely proportional to waste
        priority[min_waste_bins_idx] += 0.5/(min_waste + 0.00001)

    # Nearly full bin boost
    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= 1.1 * item) & (bins_remain_cap >= item)  #threshold multiplier = 1.1
    priority[nearly_full] += 2.5 #Nearly full weight increased

    #Small capacity based on relative availability - tweaked formula
    small_cap = (bins_remain_cap >= item)
    if np.max(bins_remain_cap) > 0:
        priority[small_cap] += 0.7 * (bins_remain_cap[small_cap] - item) / np.max(bins_remain_cap) # Scaling factor added

    #Emptiness boost
    is_empty = bins_remain_cap == np.max(bins_remain_cap)
    priority[is_empty] += 0.8 #Empty bins weight increased.

    #Prioritize bins that have already been used somewhat (discourage creating lots of bins with tiny amounts of item)
    partially_full = (bins_remain_cap < np.max(bins_remain_cap)) & (bins_remain_cap > 0)
    priority[partially_full] += 0.3


    return priority
```
