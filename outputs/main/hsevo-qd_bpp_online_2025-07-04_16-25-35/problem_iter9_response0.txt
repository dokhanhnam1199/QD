```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines capacity, waste, fragmentation, emptiness, and item-size awareness."""

    priority = np.zeros_like(bins_remain_cap, dtype=float)

    # 1. Sufficient Capacity Boost (Scaled by item size)
    sufficient_capacity = bins_remain_cap >= item
    priority[sufficient_capacity] += 1.8 * (1 - item)  # Smaller items prefer fitting

    # 2. Minimize Waste (Prioritize smaller waste proportionally)
    waste = bins_remain_cap - item
    positive_waste = waste[waste >= 0]
    if len(positive_waste) > 0:
        min_waste = np.min(positive_waste)
        min_waste_bins_idx = np.where(waste == min_waste)[0]
        priority[min_waste_bins_idx] += 1.2 * (1 - min_waste)  # Smaller waste is better

    # 3. Nearly Full Bin Boost (Adjusted threshold based on item size)
    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= (1 + 0.1 * item) * item) & (bins_remain_cap >= item)
    priority[nearly_full] += 2.4 * (1 - np.abs(bins_remain_cap[nearly_full] - item) / item)  # Closer to item size is better

    # 4. Small Capacity with Relative Availability (Penalize larger gaps)
    small_cap = (bins_remain_cap >= item)
    if np.any(small_cap):  # Avoid division by zero
        max_cap = np.max(bins_remain_cap)
        priority[small_cap] += (bins_remain_cap[small_cap] - item) / max_cap * (1-item)  #Smaller items have greater weight

    # 5. Emptiness Boost (Reduced impact if item is large)
    is_empty = bins_remain_cap == np.max(bins_remain_cap)
    priority[is_empty] += 0.7 * (1 - item) #Smaller items are better for empty bins

    # 6. Moderate Bin Penalty
    moderate_bins = (bins_remain_cap > item) & (bins_remain_cap < np.max(bins_remain_cap))
    priority[moderate_bins] -= 0.1 * item #Penalize moderate bins for larger items, encourage filling up fully

    return priority
```
