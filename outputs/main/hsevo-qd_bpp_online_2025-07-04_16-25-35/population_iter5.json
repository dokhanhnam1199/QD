[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    priority[sufficient_capacity] += 1  # Base priority if bin can fit item\n\n    # Heuristic 2: Minimize Waste (Maximize filled space).\n    waste = bins_remain_cap - item\n    positive_waste = waste[waste >= 0] # Consider only valid waste\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where(waste == min_waste)[0]\n        priority[min_waste_bins_idx] += 2\n\n    # Heuristic 3: Prevent Fragmentation (Bins near full have high priority).\n    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= 2 * item) & (bins_remain_cap >= item)\n    priority[nearly_full] += 1.5\n\n    # Heuristic 4: Small amount of available capacity.\n    small_cap = (bins_remain_cap >= item)\n    priority[small_cap] += (bins_remain_cap[small_cap] - item) / np.max(bins_remain_cap) # Add scaled value based on relative small capacity.\n    \n    # Heuristic 5: Give higher preference if it is an empty bin.\n    is_empty = bins_remain_cap == np.max(bins_remain_cap)\n    priority[is_empty] += 0.5\n\n    return priority",
    "response_id": 1,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 53.77443751081735,
    "mi": 67.91077893705676,
    "token_count": 88.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratios with waste minimization for bin prioritization.\"\"\"\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority[sufficient_capacity] += 1\n\n    # Heuristic 2: Minimize Waste (Only for bins with sufficient capacity)\n    waste = bins_remain_cap - item\n    min_waste = np.min(waste[sufficient_capacity]) if np.any(sufficient_capacity) else np.inf\n    min_waste_bins_idx = np.where((waste == min_waste) & sufficient_capacity)[0]\n    priority[min_waste_bins_idx] += 2\n\n    # Heuristic 3: Capacity Ratio (Only for bins with sufficient capacity)\n    ratios = item / bins_remain_cap\n    ratios[~sufficient_capacity] = 0  # Ignore bins without sufficient capacity\n    priority += ratios\n\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 144.75398259382442,
    "mi": 86.58537321553837,
    "token_count": 155.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Heuristic 1: Feasibility (Essential)\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return priority  # No feasible bin, all priorities remain 0\n\n    priority[feasible] += 1.0 # Base priority for feasible bins\n\n    # Heuristic 2: Minimize Waste (First-Fit Decreasing variant)\n    waste = bins_remain_cap - item\n    positive_waste = waste[feasible] # Only consider waste in feasible bins\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where((waste == min_waste) & feasible)[0]  #Ensure we choose within the feasible set\n        priority[min_waste_bins_idx] += 3.0 # Higher priority for minimizing waste\n\n    # Heuristic 3: Avoid Fragmentation (Balancing Bin Usage)\n    # Give a slightly higher priority to bins that, after placing the item,\n    # will have a remaining capacity in the middle range of possible remaining capacities.\n    post_fill_capacities = bins_remain_cap - item\n    post_fill_capacities_feasible = post_fill_capacities[feasible]\n    if len(post_fill_capacities_feasible) > 0:\n        median_capacity = np.median(post_fill_capacities_feasible)\n        capacity_diff = np.abs(post_fill_capacities - median_capacity)\n        # Scale the priority boost inversely proportional to the capacity difference.\n        # Bins closer to the median capacity get a higher boost.\n        priority[feasible] += np.clip(1.0 - capacity_diff[feasible] / np.max(bins_remain_cap), 0, 1) #Scale and clip. Prevents negative values\n        \n\n    # Heuristic 4: Prioritize emptier bins if the item is relatively large.\n    # This helps distribute items more evenly across bins initially.\n    if item > np.mean(bins_remain_cap): # Scale by item size relative to average capacity.\n        empty_bin_indices = np.where(bins_remain_cap == np.max(bins_remain_cap))[0]\n        priority[empty_bin_indices] += 1.5\n\n    # Heuristic 5: Add a slight randomness to break ties and explore the solution space.\n    priority[feasible] += np.random.rand(np.sum(feasible)) * 0.1\n\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 26.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 385.74374433250205,
    "mi": 76.827568796314,
    "token_count": 299.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                  bins_remain_cap: np.ndarray,\n                  sufficient_capacity_weight: float = 1.8066941616372154,\n                  min_waste_weight: float = 1.2369759055947915,\n                  nearly_full_threshold_multiplier: float = 1.164912650607926,\n                  nearly_full_weight: float = 2.4304538888032448,\n                  empty_bin_weight: float = 0.7700931706376539) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        sufficient_capacity_weight: Weight for bins with sufficient capacity.\n        min_waste_weight: Weight for bins that minimize waste.\n        nearly_full_threshold_multiplier: Multiplier for item size to determine nearly full threshold.\n        nearly_full_weight: Weight for bins that are nearly full.\n        empty_bin_weight: Weight for empty bins.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n    priority[sufficient_capacity] += sufficient_capacity_weight  # Base priority if bin can fit item\n\n    # Heuristic 2: Minimize Waste (Maximize filled space).\n    waste = bins_remain_cap - item\n    positive_waste = waste[waste >= 0] # Consider only valid waste\n    if len(positive_waste) > 0:\n        min_waste = np.min(positive_waste)\n        min_waste_bins_idx = np.where(waste == min_waste)[0]\n        priority[min_waste_bins_idx] += min_waste_weight\n\n    # Heuristic 3: Prevent Fragmentation (Bins near full have high priority).\n    nearly_full = (bins_remain_cap > 0.0) & (bins_remain_cap <= nearly_full_threshold_multiplier * item) & (bins_remain_cap >= item)\n    priority[nearly_full] += nearly_full_weight\n\n    # Heuristic 4: Small amount of available capacity.\n    small_cap = (bins_remain_cap >= item)\n    priority[small_cap] += (bins_remain_cap[small_cap] - item) / np.max(bins_remain_cap) # Add scaled value based on relative small capacity.\n    \n    # Heuristic 5: Give higher preference if it is an empty bin.\n    is_empty = bins_remain_cap == np.max(bins_remain_cap)\n    priority[is_empty] += empty_bin_weight\n\n    return priority",
    "response_id": 1,
    "tryHS": true,
    "obj": 2.762265656162749,
    "SLOC": 23.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 307.756981016698,
    "mi": 82.27673816203726,
    "token_count": 239.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity ratios, waste minimization, and fragmentation avoidance.\"\"\"\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: Sufficient Capacity\n    sufficient_capacity = bins_remain_cap >= item\n    priority[sufficient_capacity] += 1\n\n    # Heuristic 2: Minimize Waste (Only for bins with sufficient capacity)\n    waste = bins_remain_cap - item\n    positive_waste = waste[sufficient_capacity]\n    min_waste = np.min(positive_waste) if positive_waste.size > 0 else np.inf\n    min_waste_bins_idx = np.where((waste == min_waste) & sufficient_capacity)[0]\n    priority[min_waste_bins_idx] += 2\n\n    # Heuristic 3: Capacity Ratio (Only for bins with sufficient capacity)\n    ratios = item / bins_remain_cap\n    ratios[~sufficient_capacity] = 0  # Ignore bins without sufficient capacity\n    priority += ratios\n\n    # Heuristic 4: Prevent Fragmentation (Bins near full have high priority).\n    nearly_full_threshold = 1.2 * item  # Adjust as needed\n    nearly_full = (bins_remain_cap > 0) & (bins_remain_cap <= nearly_full_threshold) & (bins_remain_cap >= item)\n    priority[nearly_full] += 1.5\n\n    # Heuristic 5: Prioritize Emptier Bins for Larger Items\n    empty_bin_threshold = np.max(bins_remain_cap)\n    is_empty = bins_remain_cap == empty_bin_threshold\n    priority[is_empty] += 0.8   # Slightly favor empty bins\n\n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 309.6277232931715,
    "mi": 79.19005722310375,
    "token_count": 233.0,
    "exec_success": true
  }
]