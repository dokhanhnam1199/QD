```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority for packing an item into bins using a unified scoring mechanism
    that balances fit tightness and bin scarcity, employing a Softmax-like approach.

    This heuristic prioritizes bins that offer a "tightest fit" for an incoming item,
    meaning the bin has just enough remaining capacity to accommodate the item,
    minimizing wasted space. It also considers the overall scarcity of suitable bins
    using a Softmax-like function.

    The scoring mechanism works as follows:
    1. For bins that can fit the item (`remaining_capacity >= item`), calculate a
       "fit score" that is higher for tighter fits. This is achieved using a
       sigmoid function: `1 / (1 + exp(k * (remaining_capacity - item)))`.
       - `k` is a sensitivity parameter (tunable) controlling the preference for
         tighter fits. Higher `k` means sharper preference.
       - A perfect fit (`remaining_capacity == item`) results in a score of 0.5.
       - Bins with larger remaining capacity (greater "mismatch") get lower scores.
    2. Apply a Softmax-like transformation to these fit scores. This considers
       the relative desirability of each suitable bin. The Softmax function,
       `exp(score) / sum(exp(scores))`, converts scores into probabilities,
       where bins with higher fit scores get a proportionally higher probability
       (priority). This also implicitly handles bin scarcity by normalizing
       across all suitable bins.
    3. Bins that cannot fit the item receive a priority of 0.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.

    Returns:
        A NumPy array of the same size as `bins_remain_cap`, where each element
        is the priority score for the corresponding bin. Bins that cannot fit the item
        will have a priority of 0.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    suitable_bins_mask = bins_remain_cap >= item
    suitable_bins_cap = bins_remain_cap[suitable_bins_mask]

    # If no bin can fit the item, return all zeros
    if suitable_bins_cap.size == 0:
        return priorities

    # Tunable parameter for the sigmoid's steepness.
    # Higher k emphasizes tighter fits more strongly.
    k_fit = 5.0

    # Calculate the "mismatch" for suitable bins
    mismatch = suitable_bins_cap - item

    # Calculate fit scores using sigmoid: higher score for smaller mismatch
    # Score is in [0, 1], with 0.5 for a perfect fit.
    # Cap the exponent argument to prevent overflow in np.exp.
    # A value of 35.0 for `k * mismatch` yields `exp(35)`, which is large.
    # Scores below this threshold will still be distinguishable.
    max_exponent_arg = 35.0
    capped_exponent_arg = np.minimum(k_fit * mismatch, max_exponent_arg)
    fit_scores = 1 / (1 + np.exp(capped_exponent_arg))

    # Softmax-like transformation to get relative priorities
    # This converts fit scores into a distribution, where higher fit scores
    # get proportionally higher probabilities (priorities).
    # It also balances exploration/exploitation by considering all suitable bins.
    exp_fit_scores = np.exp(fit_scores)
    
    # Avoid division by zero if all exp_fit_scores are zero (highly unlikely with sigmoid)
    sum_exp_fit_scores = np.sum(exp_fit_scores)
    if sum_exp_fit_scores == 0:
        # If for some reason sum is zero, distribute uniformly among suitable bins
        softmax_priorities = np.ones_like(fit_scores) / fit_scores.size
    else:
        softmax_priorities = exp_fit_scores / sum_exp_fit_scores

    # Place the calculated softmax priorities back into the main priorities array
    priorities[suitable_bins_mask] = softmax_priorities

    return priorities
```
