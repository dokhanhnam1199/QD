```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, temperature: float = 1.0) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a softmax-based heuristic.

    This heuristic prioritizes bins that can accommodate the item, with a stronger
    preference for "tight fits" (bins with remaining capacity close to the item size).
    The `temperature` parameter controls the exploration vs. exploitation trade-off.
    Higher temperatures lead to more uniform probabilities (more exploration), while
    lower temperatures focus on the best-fitting bins (more exploitation).
    Bins that are too small for the item receive a priority of 0.

    The core idea is to generate a score that is higher for bins where the remaining
    capacity is just enough for the item. A good measure for this "tightness" is
    the reciprocal of the "wasted space" after packing, `(remaining_capacity - item)`.
    Specifically, `1.0 / (1.0 + wasted_space)` maps small positive wasted space to values
    close to 1 (good fits), and large wasted space to values close to 0 (poor fits).

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.
        temperature: Controls the sharpness of the softmax distribution. Defaults to 1.0.
                     A temperature of 0 would be greedy (best fit only). Higher values
                     increase randomness.

    Returns:
        Array of same size as bins_remain_cap with priority score (probability) of each bin.
        The sum of priorities for bins that can fit the item will be 1.0.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # If no bins can fit the item, return all zeros
    if not np.any(can_fit_mask):
        return priorities

    # Calculate the "wasted space" for bins that can fit the item
    # wasted_space = remaining_capacity - item
    wasted_space = bins_remain_cap[can_fit_mask] - item

    # Generate scores for bins that can fit.
    # We want higher scores for smaller wasted_space (tighter fits).
    # Using `1.0 / (1.0 + wasted_space)` maps:
    # - wasted_space = 0 (perfect fit) -> score = 1.0
    # - small positive wasted_space -> score close to 1.0
    # - large positive wasted_space -> score close to 0.0
    # This ensures that bins with less leftover space are preferred.
    scores_for_softmax = 1.0 / (1.0 + wasted_space)

    # Apply softmax to convert scores into probabilities.
    # The temperature parameter controls the "smoothness" of the probability distribution.
    # A low temperature makes the distribution sharply peaked towards the best score (greedy).
    # A high temperature makes the distribution flatter, favoring more exploration.
    if temperature <= 0:
        # If temperature is zero or negative, make it purely greedy.
        # The bin with the maximum score (minimum wasted space) gets probability 1.
        max_score = np.max(scores_for_softmax)
        probabilities = (scores_for_softmax == max_score).astype(float)
    else:
        # Standard softmax calculation: exp(score / temperature) / sum(exp(score / temperature))
        # To prevent potential overflow with large scores or small temperatures,
        # subtract the maximum score before exponentiating.
        max_score_val = np.max(scores_for_softmax)
        scaled_scores = (scores_for_softmax - max_score_val) / temperature
        exp_scores = np.exp(scaled_scores)
        probabilities = exp_scores / np.sum(exp_scores)

    # Assign the calculated probabilities back to the original priorities array
    priorities[can_fit_mask] = probabilities

    return priorities
```
