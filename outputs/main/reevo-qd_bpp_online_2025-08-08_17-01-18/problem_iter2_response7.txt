```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a Softmax-Based Best Fit strategy.

    This strategy prioritizes bins that have a remaining capacity closest to the item size,
    encouraging tighter packing. It uses a softmax function to convert the "closeness"
    score into a probability-like priority, controlled by a temperature parameter.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    num_bins = len(bins_remain_cap)
    priorities = np.zeros(num_bins)

    # Identify bins that can accommodate the item
    suitable_bins_mask = bins_remain_cap >= item
    suitable_bins_indices = np.where(suitable_bins_mask)[0]

    if len(suitable_bins_indices) == 0:
        # If no bin can fit the item, return all zeros
        return priorities

    # Calculate the "closeness" to a perfect fit.
    # We want to minimize the remaining capacity after placing the item.
    # A smaller difference (bins_remain_cap - item) is a better fit.
    # To use softmax effectively, we convert this to a score where higher is better.
    # We can use the negative of the difference, or a transformation that maps
    # smaller differences to larger positive scores.
    # A simple approach is to consider the inverse of the remaining capacity after fit.
    # To prioritize tighter fits, we want bins where (bins_remain_cap - item) is small.
    # Let's calculate the slack: slack = bins_remain_cap[suitable_bins_indices] - item
    # We want to give higher priority to smaller slacks.
    slack_values = bins_remain_cap[suitable_bins_indices] - item

    # Transform slack values into scores where smaller slack means higher score.
    # We can use 1 / (slack + epsilon) or exp(-slack / temperature) etc.
    # Using exp(-slack / temperature) directly relates to Softmax and is more robust.
    # A lower temperature will favor bins with very little slack more strongly.
    temperature = 0.2  # Hyperparameter: controls the "sharpness" of the preference for tight fits
    epsilon = 1e-9     # Small value to avoid division by zero or log(0) if using other transformations

    # Calculate scores for softmax. Higher scores for tighter fits.
    # Using exp(-slack / temperature) makes smaller slack values result in larger scores.
    # We add epsilon to slack_values before division to prevent potential issues if slack is exactly 0.
    # Alternatively, directly use exp(-slack / temperature).
    # Let's use exp(-slack / temperature) for a more direct softmax interpretation.
    try:
        softmax_input_scores = -slack_values / temperature
        exp_scores = np.exp(softmax_input_scores)
        # Normalize scores to get probabilities (priorities)
        probabilities = exp_scores / np.sum(exp_scores)
    except OverflowError:
        # If scores are too large, it means some bins are extremely good fits.
        # In such cases, a simpler approach might be to give a high score to the best fit(s).
        # For now, we can distribute probabilities more evenly if overflow occurs,
        # or assign a very high probability to the bin with minimum slack.
        min_slack_idx = np.argmin(slack_values)
        probabilities = np.zeros_like(slack_values)
        probabilities[min_slack_idx] = 1.0

    # Assign these calculated priorities back to the original bins
    priorities[suitable_bins_indices] = probabilities

    return priorities
```
