{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy.\n\n    The strategy favors bins that are a \"good fit\" for the item (i.e., leaving\n    a small remaining capacity), but with a probability epsilon, it assigns a\n    consistent exploration score to encourage trying less optimal bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.2  # Probability of exploration\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bins_indices = np.where(suitable_bins_mask)[0]\n\n    if len(suitable_bins_indices) == 0:\n        return priorities  # No bin can fit the item\n\n    # --- Exploitation Component (Good Fit) ---\n    # Calculate a score based on how well the item fits.\n    # We want to prioritize bins that leave minimal remaining capacity.\n    # Score = 1 / (remaining_capacity - item + epsilon)\n    # A smaller difference means a higher score.\n    fit_scores = 1.0 / (bins_remain_cap[suitable_bins_indices] - item + 1e-6)\n\n    # Normalize fit_scores to a 0-1 range to represent the \"exploitation\" priority.\n    # Higher score means better fit.\n    if fit_scores.max() > fit_scores.min():\n        exploitation_priorities = (fit_scores - fit_scores.min()) / (fit_scores.max() - fit_scores.min())\n    else:\n        exploitation_priorities = np.ones(len(suitable_bins_indices)) # All fits are equally good\n\n    # Assign the exploitation priorities to the suitable bins\n    priorities[suitable_bins_indices] = exploitation_priorities\n\n    # --- Exploration Component ---\n    # With probability epsilon, overwrite the exploitation priority with a\n    # consistent, lower exploration score for a random subset of suitable bins.\n    # This encourages exploration of bins that might not be the immediate best fit.\n    exploration_score = 0.1 # A fixed low score for exploration\n\n    # Determine which suitable bins will be subject to exploration\n    num_suitable = len(suitable_bins_indices)\n    explore_indices_in_suitable = np.random.choice(\n        num_suitable,\n        size=int(np.ceil(epsilon * num_suitable)),\n        replace=False\n    )\n    \n    # Get the actual indices in the original bins_remain_cap array\n    bins_to_explore_indices = suitable_bins_indices[explore_indices_in_suitable]\n\n    # Assign the exploration score to these bins\n    priorities[bins_to_explore_indices] = exploration_score\n\n    # Ensure that bins that cannot fit the item have zero priority\n    priorities[~suitable_bins_mask] = 0\n\n    # Optional: Normalize final priorities if a specific range is required by downstream logic.\n    # For now, we return the scores as calculated, where higher means more preferred.\n    # A simple max-min normalization can be applied if needed:\n    # if priorities.max() > priorities.min():\n    #     final_priorities = (priorities - priorities.min()) / (priorities.max() - priorities.min())\n    # else:\n    #     final_priorities = np.ones(num_bins) * 0.5\n    # return final_priorities\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority probabilities for packing an item into bins using a\n    combination of tight fit, bin scarcity, tie-breaking, and Softmax for exploration.\n\n    This heuristic prioritizes:\n    1.  **Tight Fits:** Bins that have just enough remaining capacity for the item.\n        This is handled by a sigmoid function on the \"mismatch\" (remaining_capacity - item).\n    2.  **Bin Scarcity:** Slightly favors bins that are less empty (have less remaining capacity),\n        as these are scarcer resources. A bonus is added inversely proportional to remaining capacity.\n    3.  **Earlier Bin Preference:** If multiple bins have similar scores, favors bins that\n        appear earlier in the `bins_remain_cap` array (i.e., were opened earlier).\n    4.  **Probabilistic Exploration (Softmax):** Converts the computed priority scores\n        into probabilities using the Softmax function. The `temperature` parameter\n        controls the exploration-exploitation trade-off:\n        - Low temperature (close to 0): Exploitation (favors the highest score).\n        - High temperature (large value): Exploration (probabilities are more uniform).\n\n    The final priority for each bin is calculated as:\n    `Score_i = SigmoidFit(bins_remain_cap[i], item, k) + gamma * (1 / (bins_remain_cap[i] + epsilon)) + delta * (1 / (i + 1))`\n    Then, probabilities are derived using Softmax:\n    `P_i = exp(Score_i / temperature) / sum(exp(Score_j / temperature))`\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.\n        temperature: Controls the Softmax exploration/exploitation balance.\n                     Higher values lead to more exploration. Defaults to 1.0.\n        k: Sensitivity parameter for the sigmoid function (tightest fit preference).\n           Higher `k` increases preference for tighter fits. Defaults to 5.0.\n        gamma: Weight for the bin scarcity bonus. Higher `gamma` increases\n               preference for less empty bins. Defaults to 0.1.\n        delta: Weight for the earlier bin preference tie-breaker. Higher `delta`\n               increases preference for earlier bins. Defaults to 0.01.\n        epsilon: Small value to prevent division by zero in scarcity calculation.\n                 Defaults to 1e-6.\n\n    Returns:\n        A NumPy array of probabilities, same size as `bins_remain_cap`.\n        Bins that cannot fit the item will have a probability of 0.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    raw_scores = np.zeros(num_bins, dtype=float)\n\n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    # Calculate base sigmoid fit score for suitable bins\n    suitable_bins_cap = bins_remain_cap[suitable_bins_mask]\n    \n    if suitable_bins_cap.size > 0:\n        # Calculate the \"mismatch\" or wasted space\n        mismatch = suitable_bins_cap - item\n        \n        # Cap exponent argument to prevent overflow in np.exp\n        max_exponent_arg = 35.0\n        capped_exponent_arg = np.minimum(k * mismatch, max_exponent_arg)\n        \n        # Sigmoid score: Higher for tighter fits (smaller mismatch)\n        sigmoid_scores = 1 / (1 + np.exp(capped_exponent_arg))\n\n        # Apply scarcity bonus: Add bonus for bins with less remaining capacity\n        # Using 1 / (capacity + epsilon) as a proxy for \"fullness\"\n        scarcity_bonus = gamma * (1.0 / (suitable_bins_cap + epsilon))\n\n        # Apply tie-breaking bonus: Add bonus for earlier bins\n        # Find the indices of the suitable bins in the original array\n        suitable_bin_indices = np.where(suitable_bins_mask)[0]\n        tie_breaker_bonus = delta * (1.0 / (suitable_bin_indices + 1.0))\n\n        # Combine scores for suitable bins\n        combined_scores = sigmoid_scores + scarcity_bonus + tie_breaker_bonus\n        \n        # Assign combined scores back to the raw_scores array\n        raw_scores[suitable_bins_mask] = combined_scores\n\n    # If temperature is very low (close to 0), effectively select the max score bin.\n    # Avoid division by zero if temperature is 0.\n    if temperature <= epsilon:\n        if np.max(raw_scores) > -np.inf: # Check if there's at least one valid score\n             # Assign probability 1 to the bin(s) with the maximum score\n             max_score = np.max(raw_scores)\n             probabilities = np.where(raw_scores == max_score, 1.0, 0.0)\n             # Normalize to ensure sum is 1 if multiple max scores exist\n             num_max_scores = np.sum(probabilities)\n             if num_max_scores > 0:\n                 probabilities /= num_max_scores\n        else: # All scores are -inf (e.g., no suitable bins)\n             probabilities = np.zeros(num_bins)\n        return probabilities\n\n    # Apply Softmax to convert scores to probabilities\n    # Add a small constant to scores before exp to avoid issues with very small negative scores\n    # Or simply handle potential underflow/overflow.\n    # A common trick is to subtract the max score before exponentiation:\n    # exp(x_i / T) / sum(exp(x_j / T)) = exp((x_i - max(x)) / T) / sum(exp((x_j - max(x)) / T))\n    # This stabilizes calculations.\n    \n    # Find the maximum score to shift all scores down for numerical stability\n    max_raw_score = np.max(raw_scores)\n    \n    # Ensure we don't get NaN or inf if all scores are -inf (e.g., no suitable bins)\n    if max_raw_score == -np.inf:\n        return np.zeros(num_bins)\n\n    shifted_scores = (raw_scores - max_raw_score) / temperature\n    \n    # Calculate exponential of shifted scores\n    exp_scores = np.exp(shifted_scores)\n    \n    # Calculate sum of exponential scores for normalization\n    sum_exp_scores = np.sum(exp_scores)\n    \n    # Calculate probabilities\n    probabilities = exp_scores / sum_exp_scores\n    \n    # Ensure probabilities sum to 1 (due to potential floating point inaccuracies)\n    # And handle cases where sum_exp_scores might be 0 (e.g., all shifted scores were -inf)\n    if sum_exp_scores > 0:\n        probabilities /= np.sum(probabilities) # Re-normalize\n    else:\n        # This case should ideally not happen if max_raw_score was handled correctly,\n        # but as a fallback, if all exp_scores resulted in 0, distribute uniformly or zero out.\n        # Given our max_raw_score shift, this implies all shifted scores were extremely negative.\n        probabilities = np.zeros(num_bins)\n\n    # Ensure probabilities are not NaN\n    probabilities = np.nan_to_num(probabilities)\n\n    return probabilities\n\n[Reflection]\nIncorporate multiple objectives and probabilistic selection for better bin packing heuristics.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}