{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-based approach\n    that also incorporates an epsilon-greedy exploration strategy.\n\n    This heuristic first calculates a \"fit score\" for each bin, where a better fit (less remaining capacity)\n    results in a higher score. These scores are then transformed using softmax to get probabilities.\n    An epsilon-greedy component is added: with a small probability `epsilon`, a bin is chosen randomly\n    from the *suitable* bins to encourage exploration. Otherwise, the greedy (softmax-derived)\n    priorities are used.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploring a random suitable bin\n\n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bin_indices = np.where(suitable_bins_mask)[0]\n\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n\n    if len(suitable_bin_indices) == 0:\n        # No bin can fit the item, return all zeros\n        return priorities\n\n    # Epsilon-greedy choice: With probability epsilon, pick a random suitable bin\n    if np.random.rand() < epsilon:\n        # Choose one suitable bin randomly\n        chosen_index = np.random.choice(suitable_bin_indices)\n        # Assign a high priority to this randomly chosen bin\n        priorities[chosen_index] = 1.0\n        # For other bins, assign a very low priority to make the chosen one stand out\n        priorities[suitable_bin_indices] = 1e-9\n        # Ensure non-suitable bins remain at 0\n        return priorities\n\n    # If not exploring, use a greedy strategy based on how well the item fits.\n    # We want bins where the remaining capacity is just enough for the item.\n    # The score should be higher for bins with `bins_remain_cap - item` closer to 0.\n    # Use `-(bins_remain_cap - item)` as the score, which is `item - bins_remain_cap`.\n    # This makes smaller positive differences (better fits) have higher scores.\n\n    scores = item - bins_remain_cap\n\n    # For bins that cannot fit the item, assign a very low score.\n    # This ensures their softmax probability is negligible.\n    scores[~suitable_bins_mask] = -np.inf  # Effectively -infinity for softmax\n\n    # Calculate softmax probabilities\n    # exp_scores = np.exp(scores)\n    # To prevent potential overflow with large positive scores or underflow with large negative scores,\n    # we can use `np.exp(scores - np.max(scores))` if scores are not all -inf.\n    # Since we set non-suitable bins to -inf, and suitable bins have scores >= 0,\n    # np.max(scores) will be at least 0 for suitable bins.\n    \n    # Calculate logits, ensuring they are not all -inf\n    max_score = np.max(scores[suitable_bins_mask]) if np.any(suitable_bins_mask) else 0\n    \n    # Shift scores so that the maximum is 0 to avoid large exponents\n    shifted_scores = scores - max_score\n    \n    # Ensure exp_scores are non-negative and sum is positive before division\n    exp_scores = np.exp(shifted_scores)\n    \n    sum_exp_scores = np.sum(exp_scores)\n    \n    if sum_exp_scores == 0:\n        # This case should ideally not be reached if there's at least one suitable bin\n        # but as a safeguard, return uniform probabilities for suitable bins.\n        # This would mean assigning equal probability to all bins that can fit.\n        if np.any(suitable_bins_mask):\n            priorities[suitable_bins_mask] = 1.0 / len(suitable_bin_indices)\n        return priorities\n    \n    priorities = exp_scores / sum_exp_scores\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit Decreasing-like heuristic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # First Fit strategy: find the first bin that can accommodate the item.\n    # For priority, we want to favor bins that are a \"tight fit\" but still fit.\n    # This means we prefer bins where the remaining capacity is just enough for the item.\n    # A bin with remaining capacity exactly equal to the item size is ideal.\n    # Bins that are too small should have a priority of 0.\n\n    # Create a mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Initialize priorities to a very low value (effectively zero for unusable bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # For bins that can fit the item, calculate a priority score.\n    # We want to prioritize bins where the remaining capacity is closest to the item size,\n    # without going below the item size.\n    # The difference (bins_remain_cap - item) represents the \"slack\".\n    # We want to minimize slack, so a smaller difference is better.\n    # However, we want the *first* such bin in the array to be prioritized in case of ties,\n    # which is naturally handled by numpy's vectorized operations if we consider\n    # negative of the slack as a priority. A smaller slack means a larger negative slack,\n    # which translates to a higher priority in a max-priority queue sense.\n\n    # Calculate slack for bins that can fit the item\n    slack = bins_remain_cap[can_fit_mask] - item\n\n    # The priority is the negative of the slack.\n    # Smaller slack -> larger negative slack -> higher priority.\n    # If multiple bins have the same slack, their relative order in the original\n    # bins_remain_cap array will be preserved in terms of priority calculation.\n    priorities[can_fit_mask] = -slack\n\n    # In a true First Fit, we'd just take the first bin that fits.\n    # To simulate this \"first fit\" behavior in a priority context,\n    # we can add a small bonus to earlier bins with good fits, or more directly,\n    # simply return priorities such that the first available bin with the \"best\" fit\n    # (smallest slack) gets the highest priority. The `-slack` already achieves this.\n    # If multiple bins have the same minimal slack, the one appearing first in the\n    # `bins_remain_cap` array will naturally get the higher priority due to the way\n    # numpy operations often preserve order in selection when values are equal.\n    # For absolute certainty of 'first fit' logic within this priority framework,\n    # we can make bins that are \"exact fits\" have a slightly higher priority\n    # than slightly looser fits.\n\n    # Refined priority: Exact fits (slack=0) get highest priority.\n    # Then, among bins that fit, prioritize smaller slack (tighter fit).\n    # The current -slack already prioritizes smaller slack.\n    # To enforce the \"first fit\" aspect: consider the index.\n    # A bin with smaller index is preferred if slack is equal.\n\n    # Let's use a more explicit priority:\n    # 1. Highest priority for exact fits.\n    # 2. Then, prioritize bins with smaller slack.\n    # 3. If slack is equal, prioritize the bin with the smaller index.\n\n    # Initialize priorities for fitting bins\n    fit_priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Calculate slack for fitting bins\n    slack_values = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities:\n    # For exact fits (slack_values == 0), assign a very high priority (e.g., 1e9)\n    # For other fits, assign priority based on negative slack.\n    # To break ties and enforce \"first fit\", we can penalize later bins.\n    # Let's assign priority = 10000 - slack - (index * 0.1) for fitting bins.\n    # This way, smaller slack is better, and smaller index is better for same slack.\n\n    indices = np.where(can_fit_mask)[0]\n    # Create a score: (ideal_fit - slack) + (bonus_for_early_bins)\n    # We want to maximize this score.\n    # Ideal fit = 0 (when remaining_capacity == item)\n    # So, priority component from slack is -slack.\n    # Bonus for early bins: -index * small_constant.\n    # We want to maximize priority.\n    # Maximize: (-slack) - (index * 0.01)\n    \n    # A simpler way is to use a very large number for exact fits, then -slack.\n    # Let's consider the \"best\" fit for the priority.\n    # The best fit is the one that minimizes `remaining_capacity - item`.\n    # This is equivalent to maximizing `-(remaining_capacity - item)`.\n    # So, `priority = -(remaining_capacity - item)` for fitting bins.\n    # To ensure first-fit, if there are multiple bins with the same minimal slack,\n    # the one with the lower index should be preferred.\n    # We can achieve this by adding a very small penalty to the priority based on index.\n    # `priority = -(remaining_capacity - item) - index * epsilon`\n    # where epsilon is a very small positive number. This ensures that a bin at a\n    # lower index with the same slack gets a slightly higher priority.\n\n    epsilon = 1e-6  # Small value to break ties for first-fit\n    fit_priorities[can_fit_mask] = -(slack_values) - (indices * epsilon)\n    \n    # We want the bin with the highest priority score to be selected.\n    # The current calculation `-(slack_values) - (indices * epsilon)` will work.\n    # A more direct \"First Fit Decreasing-like\" priority would be to assign\n    # priorities such that the smallest slack is maximized.\n    # And for ties in slack, the lowest index is maximized.\n    # So, `priority = (some_large_number - slack) - index * epsilon`.\n    # Or simply, `priority = -slack - index * epsilon`.\n    # A higher value means higher priority.\n\n    # Final check: The priority should reflect our preference.\n    # We prefer bins that are a tight fit, and among tight fits, the earliest one.\n    # This means a bin where `bins_remain_cap - item` is small is good.\n    # And smaller index is good for ties.\n    # So, the score should be high for small `bins_remain_cap - item` and small `index`.\n    # Let's use a score that is large for best fits:\n    # Priority = MAX_SCORE - (bins_remain_cap - item) - (index * penalty)\n    # A large MAX_SCORE ensures any fitting bin is better than non-fitting.\n    \n    MAX_BENEFIT_SCORE = 1000000  # A large number to indicate a good fit\n    INDEX_PENALTY_FACTOR = 1000  # Penalty for later bins\n\n    # Prioritize bins that can fit the item.\n    # For bins that fit, the score is determined by how \"tight\" the fit is\n    # (smaller remaining capacity after placement is better) and by their index\n    # (earlier bins are preferred for first-fit).\n\n    # Calculate the \"tightness\" score: a larger value means a tighter fit (less waste).\n    # We want to maximize `MAX_BENEFIT_SCORE - slack`.\n    tightness_score = np.zeros_like(bins_remain_cap)\n    tightness_score[can_fit_mask] = MAX_BENEFIT_SCORE - slack\n\n    # Introduce a penalty for bins with higher indices to enforce the \"first fit\" logic.\n    # Subtract a scaled index. Smaller index should have higher priority.\n    index_penalty = indices * INDEX_PENALTY_FACTOR\n    \n    # Combine scores. We want to maximize the overall priority.\n    # Prioritize based on tightness, then index.\n    # This means higher tightness_score is better.\n    # Lower index_penalty is better.\n    # So, we want to MAXIMIZE: `tightness_score - index_penalty`\n    \n    priorities = np.full_like(bins_remain_cap, -np.inf) # Initialize with low priority\n\n    if np.any(can_fit_mask):\n        fitting_indices = np.where(can_fit_mask)[0]\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the \"fit quality\": how close the remaining capacity is to the item size.\n        # A smaller difference (bins_remain_cap - item) is better.\n        fit_quality = -(fitting_bins_remain_cap - item) # Maximize this (smaller difference is better)\n\n        # To implement \"First Fit\", we prefer earlier bins when fit quality is the same.\n        # We can achieve this by adding a small bonus for earlier indices.\n        # This means we want to maximize `fit_quality + bonus_for_early_bins`.\n        # The bonus should decrease with index. So, `bonus = constant - index * small_factor`.\n        # Let's use a simple approach: a very high priority for the tightest fits,\n        # and then penalize for looser fits and later indices.\n\n        # Consider the inverse: we want to minimize waste (slack) and index.\n        # So, we want to minimize `slack + index * epsilon`.\n        # Priority should be inverse of this minimization.\n        # Priority = - (slack + index * epsilon)\n\n        epsilon_tiebreaker = 1e-6\n        priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item) - (np.arange(len(bins_remain_cap))[can_fit_mask] * epsilon_tiebreaker)\n\n    # The current priority definition maximizes (tight fit) + (early index).\n    # This correctly aligns with First Fit logic.\n    return priorities\n\n[Reflection]\nPrioritize tight fits, then earlier bins for First Fit. Minimize waste and index.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}