{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy.\n\n    The Epsilon-Greedy strategy aims to balance exploration (trying less optimal bins)\n    and exploitation (choosing the best bin).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.2  # Probability of exploration\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bins = np.where(suitable_bins_mask)[0]\n\n    if len(suitable_bins) == 0:\n        # If no bin can fit the item, return all zeros (or handle as an error)\n        return priorities\n\n    # --- Exploitation Component ---\n    # Calculate a \"goodness\" score for suitable bins.\n    # A common heuristic is the \"Best Fit\" approach: prioritize bins with\n    # the least remaining capacity after placing the item (minimizing waste).\n    # Here, we want the *highest* priority for the *best* fit, so we\n    # transform the remaining capacity difference into a positive score.\n    # A simple approach is (max_capacity - item) - remaining_capacity\n    # or more directly, prioritize smaller remaining capacities after fitting.\n    # We can use a value inversely related to remaining capacity, e.g., 1 / (remaining_capacity - item + 1e-6)\n    # to give higher priority to bins with less slack.\n\n    # Calculate the 'fit_score' for suitable bins: higher is better fit (less wasted space)\n    # This is 1 / (remaining_capacity - item + small_epsilon)\n    # A bin with remaining_capacity = item will have the highest score.\n    fit_scores = 1 / (bins_remain_cap[suitable_bins] - item + 1e-6)\n\n    # Normalize fit_scores to a 0-1 range (optional but can be helpful)\n    if fit_scores.max() > fit_scores.min():\n        exploitation_priorities = (fit_scores - fit_scores.min()) / (fit_scores.max() - fit_scores.min())\n    else:\n        exploitation_priorities = np.ones(len(suitable_bins)) # All are equally \"good\"\n\n    # Assign exploitation priorities to the suitable bins\n    priorities[suitable_bins] = exploitation_priorities\n\n    # --- Exploration Component ---\n    # Introduce randomness: with probability epsilon, choose a random suitable bin.\n    # Assign a small, uniform \"exploration\" priority to all suitable bins.\n    # This encourages trying out bins that might not be the immediate \"best fit\".\n    exploration_priority_value = 0.1 # A small constant value to represent exploration\n\n    # For the bins that are suitable, decide whether to explore\n    explore_mask = np.random.rand(len(suitable_bins)) < epsilon\n\n    # Update priorities for bins chosen for exploration\n    priorities[suitable_bins[explore_mask]] = exploration_priority_value\n\n    # Normalize the final priorities to ensure a meaningful range, e.g., 0 to 1\n    # (This step might be adjusted based on how the priority scores are used elsewhere)\n    if priorities.max() > priorities.min():\n        final_priorities = (priorities - priorities.min()) / (priorities.max() - priorities.min())\n    else:\n        final_priorities = np.ones(num_bins) * 0.5 # Default if all are same\n\n    # Ensure that bins that cannot fit the item have zero priority\n    final_priorities[~suitable_bins_mask] = 0\n\n    return final_priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-Based Fit strategy.\n\n    The strategy assigns higher priority to bins that have a remaining capacity\n    just slightly larger than the item size, aiming to fill bins more compactly.\n    A temperature parameter controls the \"softness\" of the softmax, influencing\n    how aggressively we favor these \"almost fitting\" bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Filter out bins that cannot fit the item\n    can_fit_mask = bins_remain_cap >= item\n    eligible_bins_cap = bins_remain_cap[can_fit_mask]\n\n    if not eligible_bins_cap.size:\n        # If no bin can fit the item, return zeros for all original bins\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate the \"fit score\": how much space is left after placing the item.\n    # Smaller values indicate a tighter fit.\n    fit_scores = eligible_bins_cap - item\n\n    # Use a Softmax-like approach to convert fit scores to priorities.\n    # We invert the fit scores to give higher priority to smaller remaining capacities (tighter fits).\n    # Adding a small epsilon to avoid division by zero or log(0) if all fit_scores are 0.\n    epsilon = 1e-9\n    inverted_fit_scores = 1.0 / (fit_scores + epsilon)\n\n    # The temperature parameter controls the \"softness\" of the softmax.\n    # A lower temperature makes the distribution sharper (more peaky),\n    # favoring the best fitting bins more strongly.\n    # A higher temperature makes it more uniform.\n    temperature = 0.5  # This can be tuned as a hyperparameter\n\n    # Apply softmax to the inverted fit scores\n    try:\n        exp_scores = np.exp(inverted_fit_scores / temperature)\n        softmax_priorities = exp_scores / np.sum(exp_scores)\n    except OverflowError:\n        # Handle potential overflow if scores become too large\n        # In such cases, a simple proportional scaling might be better\n        # or clamping the input to exp. For simplicity here, we can\n        # assign equal high probability to all if overflow occurs.\n        softmax_priorities = np.ones_like(eligible_bins_cap) / eligible_bins_cap.size\n\n\n    # Create the final priority array, mapping priorities back to original bin indices\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[can_fit_mask] = softmax_priorities\n\n    return priorities\n\n[Reflection]\nPrioritize tighter fits, consider softmax for smooth distribution, tune temperature for exploration.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}