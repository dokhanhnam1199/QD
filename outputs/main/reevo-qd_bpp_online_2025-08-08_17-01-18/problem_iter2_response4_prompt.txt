{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using an epsilon-greedy strategy.\n\n    The strategy favors bins that are a \"good fit\" for the item (i.e., leaving\n    a small remaining capacity), but with a probability epsilon, it explores\n    other bins randomly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.2  # Probability of exploring\n\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n\n    # Calculate a \"goodness of fit\" score for each bin\n    # A smaller remaining capacity after fitting the item is considered better.\n    # We use 1 / (remaining_capacity - item + 1e-9) to ensure division by zero is avoided\n    # and to give higher scores to bins with less remaining capacity.\n    # Only consider bins that can actually fit the item.\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities[suitable_bins_mask] = 1.0 / (bins_remain_cap[suitable_bins_mask] - item + 1e-9)\n\n    # Epsilon-greedy part: with probability epsilon, choose a random suitable bin\n    if np.random.rand() < epsilon:\n        # Get indices of suitable bins\n        suitable_indices = np.where(suitable_bins_mask)[0]\n        if len(suitable_indices) > 0:\n            # Randomly pick one suitable bin\n            chosen_index = np.random.choice(suitable_indices)\n            # Assign a very high priority to the randomly chosen bin\n            priorities[chosen_index] = np.max(priorities) + 1.0 # Give it a slightly higher priority than the best greedy choice\n    else:\n        # Otherwise, follow the greedy approach (already calculated in `priorities`)\n        pass # priorities are already set to the greedy scores\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-Based Fit strategy.\n\n    The strategy assigns higher priority to bins that have a remaining capacity\n    just slightly larger than the item size, aiming to fill bins more compactly.\n    A temperature parameter controls the \"softness\" of the softmax, influencing\n    how aggressively we favor these \"almost fitting\" bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Filter out bins that cannot fit the item\n    can_fit_mask = bins_remain_cap >= item\n    eligible_bins_cap = bins_remain_cap[can_fit_mask]\n\n    if not eligible_bins_cap.size:\n        # If no bin can fit the item, return zeros for all original bins\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate the \"fit score\": how much space is left after placing the item.\n    # Smaller values indicate a tighter fit.\n    fit_scores = eligible_bins_cap - item\n\n    # Use a Softmax-like approach to convert fit scores to priorities.\n    # We invert the fit scores to give higher priority to smaller remaining capacities (tighter fits).\n    # Adding a small epsilon to avoid division by zero or log(0) if all fit_scores are 0.\n    epsilon = 1e-9\n    inverted_fit_scores = 1.0 / (fit_scores + epsilon)\n\n    # The temperature parameter controls the \"softness\" of the softmax.\n    # A lower temperature makes the distribution sharper (more peaky),\n    # favoring the best fitting bins more strongly.\n    # A higher temperature makes it more uniform.\n    temperature = 0.5  # This can be tuned as a hyperparameter\n\n    # Apply softmax to the inverted fit scores\n    try:\n        exp_scores = np.exp(inverted_fit_scores / temperature)\n        softmax_priorities = exp_scores / np.sum(exp_scores)\n    except OverflowError:\n        # Handle potential overflow if scores become too large\n        # In such cases, a simple proportional scaling might be better\n        # or clamping the input to exp. For simplicity here, we can\n        # assign equal high probability to all if overflow occurs.\n        softmax_priorities = np.ones_like(eligible_bins_cap) / eligible_bins_cap.size\n\n\n    # Create the final priority array, mapping priorities back to original bin indices\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[can_fit_mask] = softmax_priorities\n\n    return priorities\n\n[Reflection]\nPrioritize tight fits, explore options wisely, and tune parameters for optimal performance.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}