```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Sigmoid Fit Score strategy.

    The Sigmoid Fit Score prioritizes bins that can accommodate the item and
    have remaining capacity close to the item's size, aiming for a tighter fit.
    A higher score indicates a preferred bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # A reasonable "ideal" remaining capacity to aim for when fitting an item.
    # This could be the item's size itself, or slightly larger.
    # Here, we'll use the item size directly.
    ideal_fit_capacity = item

    # Calculate the difference between the ideal fit capacity and the bin's remaining capacity.
    # We want to penalize bins that are too small or have a lot of excess space.
    # A negative difference means the bin is too small.
    # A large positive difference means the bin has a lot of unused space.
    capacity_difference = bins_remain_cap - ideal_fit_capacity

    # Apply the sigmoid function. The sigmoid function squashes values to a range between 0 and 1.
    # We need to map the capacity_difference to an input suitable for the sigmoid.
    # The steepness of the sigmoid (controlled by 'k') determines how sensitive the priority is to the difference.
    # A larger 'k' makes the transition sharper around the "ideal" fit.
    # A 'midpoint' shifts the sigmoid along the x-axis; we want the midpoint to be near 0 (ideal fit).
    
    # Let's define some parameters for the sigmoid:
    # k: steepness of the sigmoid. Higher k means a sharper transition.
    # midpoint: the value of capacity_difference where the sigmoid output is 0.5. We want this to be near 0.
    k = 5.0  # This parameter can be tuned. A higher value emphasizes closer fits.
    midpoint = 0.0 # We want the ideal fit (capacity_difference = 0) to be at the midpoint.

    # We can use a shifted and scaled sigmoid: 1 / (1 + exp(-k * (x - midpoint)))
    # However, we also need to handle cases where the item *cannot* fit.
    # Bins with remaining capacity less than the item size should have a priority of 0.
    
    # First, identify bins that can actually fit the item.
    can_fit_mask = bins_remain_cap >= item

    # Calculate a "fit score" for bins that can fit.
    # We want to maximize the priority when `bins_remain_cap` is close to `item`.
    # So, `bins_remain_cap - item` should be close to 0.
    # A larger `bins_remain_cap - item` means more wasted space.
    # We can map this difference using a sigmoid.
    # A good transformation is `1 / (1 + exp(-k * (bins_remain_cap - item)))`.
    # This maps `bins_remain_cap - item = 0` to 0.5, `bins_remain_cap - item < 0` to <0.5,
    # and `bins_remain_cap - item > 0` to >0.5.
    
    # To make it a priority score where higher is better, and to ensure it's 0 for non-fitting bins:
    
    # Calculate the "closeness" score. We want higher scores for bins where remaining capacity is closer to item size.
    # Let's use a shifted sigmoid on the negative difference to make larger positive differences (more slack) less preferred.
    # Or, more directly, use a sigmoid on the positive difference, and then transform.
    
    # A common way to use sigmoid for prioritization in this context is to map the
    # 'waste' or 'slack' to a desirability score.
    # If we define desirability as high when slack is low and the item fits:
    
    # Calculate slack: `slack = bins_remain_cap - item`
    # We want high priority when slack is close to 0.
    
    # Let's use a sigmoid that outputs 1 when slack is 0, and approaches 0 for large positive slacks.
    # A form like `exp(-k * slack)` can work, but sigmoid provides a bounded [0, 1] range.
    # Consider the function `1 - sigmoid(k * slack)`. This would give 0.5 for slack=0,
    # approaching 1 for negative slack (not fitting) and approaching 0 for positive slack.
    # This is not quite right.

    # Let's try to directly map a "goodness" measure.
    # A bin is good if it fits and has minimal remaining capacity after packing.
    # Let's consider `item / bins_remain_cap`. This ratio is good if close to 1.
    # However, this doesn't account for negative differences (cannot fit).
    
    # Back to the sigmoid on the difference.
    # We want a higher score when `bins_remain_cap` is close to `item`.
    # So, `bins_remain_cap - item` should be close to 0.
    
    # Let's define the priority based on the remaining capacity `c` and item size `i`:
    # P(c, i) is high when `c >= i` and `c - i` is small.
    
    # Sigmoid approach: map `c - i` to a score.
    # `sigmoid(x)` goes from 0 to 1.
    # We want a higher score when `c - i` is small and positive.
    # If `c < i`, the score should be 0.

    # Let's define `x = c - i`.
    # We want a function f(x) where f(0) is high, and f(large positive) is low, and f(negative) is 0.
    
    # Option 1: Use `1 - sigmoid(k * x)` on positive differences.
    # `sigmoid(k * x)` for `x >= 0`:
    #  - If x is slightly > 0, sigmoid is slightly > 0.5. `1 - sigmoid` is slightly < 0.5.
    #  - If x is large positive, sigmoid is close to 1. `1 - sigmoid` is close to 0.
    # This makes smaller positive differences (less waste) result in higher scores.
    
    # Let's define the sigmoid transformation on the difference `bins_remain_cap - item`:
    # We want the sigmoid to output higher values for smaller *positive* differences.
    # The standard sigmoid is `1 / (1 + exp(-slope * value))`.
    # If `value = bins_remain_cap - item`:
    #  - If `value` is large positive (lots of slack), sigmoid is close to 1.
    #  - If `value` is 0, sigmoid is 0.5.
    #  - If `value` is large negative (cannot fit), sigmoid is close to 0.
    
    # We want to invert this for slack, so smaller slack is better.
    # Consider `1 - sigmoid(k * (bins_remain_cap - item))`.
    #  - If `bins_remain_cap < item`: `bins_remain_cap - item` is negative.
    #    `k * negative` is negative. `exp(-k * negative)` is large.
    #    `sigmoid` is close to 1. `1 - sigmoid` is close to 0. This correctly handles non-fitting bins.
    #  - If `bins_remain_cap == item`: `bins_remain_cap - item` is 0.
    #    `sigmoid(0)` is 0.5. `1 - sigmoid(0)` is 0.5.
    #  - If `bins_remain_cap > item`: `bins_remain_cap - item` is positive.
    #    `k * positive` is positive. `exp(-k * positive)` is small.
    #    `sigmoid` is close to 1. `1 - sigmoid` is close to 0. This is also wrong.

    # Let's rethink the mapping to the sigmoid input.
    # We want the input to the sigmoid to be *low* when the remaining capacity is close to the item size.
    # If `bins_remain_cap - item` is the slack:
    #  - Slack = 0 (ideal fit): Low input for sigmoid to get high output (if we use `1 - sigmoid`).
    #  - Slack large positive: High input for sigmoid to get low output.
    #  - Slack negative (cannot fit): Very high input for sigmoid to get very low output.

    # Let `x = bins_remain_cap - item`.
    # We want a function `f(x)` such that:
    # f(negative) = 0
    # f(0) = high
    # f(large positive) = low
    
    # Try a sigmoid on the *negative* of the slack: `sigmoid(k * -(bins_remain_cap - item))`
    # = `sigmoid(k * (item - bins_remain_cap))`
    
    # Let `y = k * (item - bins_remain_cap)`
    #  - If `bins_remain_cap < item`: `item - bins_remain_cap` is positive. `y` is positive. `sigmoid(y)` is close to 1.
    #  - If `bins_remain_cap == item`: `item - bins_remain_cap` is 0. `y` is 0. `sigmoid(y)` is 0.5.
    #  - If `bins_remain_cap > item`: `item - bins_remain_cap` is negative. `y` is negative. `sigmoid(y)` is close to 0.
    
    # This gives a high score for items that cannot fit, which is not desired.
    
    # The core idea of sigmoid fit is to map the *remaining capacity* to a score.
    # We want higher scores for bins where `remaining_capacity` is `item`, and
    # lower scores if `remaining_capacity` is much larger or smaller than `item`.
    
    # Let's define the sigmoid input based on the deviation from `item`.
    # We want the input to the sigmoid to be small when `bins_remain_cap` is close to `item`.
    
    # Consider `abs(bins_remain_cap - item)` as the "distance from ideal".
    # We want this distance to be small.
    # `sigmoid(k * abs(bins_remain_cap - item))` would be small for small differences, and large for large differences.
    # We want the opposite: high priority for small differences.
    # So, `1 / (1 + exp(k * abs(bins_remain_cap - item)))` is one form.
    #  - If `abs(...)` is small, exp is close to 1. Denominator close to 2. Score close to 0.5.
    #  - If `abs(...)` is large, exp is large. Denominator large. Score close to 0.
    
    # This also doesn't seem right as it doesn't handle the "cannot fit" case gracefully.
    
    # The common way Sigmoid Fit is implemented for BPP is to define a score
    # where a bin is preferred if its remaining capacity `c` is such that `c >= item`
    # and `c - item` is minimized.

    # Let's focus on the probability of a "good fit".
    # A bin `j` with remaining capacity `c_j` is a good candidate for item `i` if `c_j >= i`.
    # Among those, we prefer bins where `c_j` is closer to `i`.
    
    # We can model this as a score that is 0 if `c_j < i`, and
    # peaks when `c_j = i` and decays as `c_j` increases.
    
    # Consider the logistic function `L / (1 + exp(-k * (x - x0)))`.
    # Let `x = bins_remain_cap`. We want the peak when `x = item`.
    # So `x0 = item`.
    # We also want the score to be 0 for `x < item`.
    
    # A modified sigmoid approach:
    # Score is 0 if `bins_remain_cap < item`.
    # For `bins_remain_cap >= item`, we want a score that decreases as `bins_remain_cap` increases beyond `item`.
    
    # Let's use the sigmoid to represent the desirability of the remaining capacity relative to the item size.
    # We want the sigmoid to be "high" when `bins_remain_cap` is close to `item`.
    
    # Consider the value `k * (bins_remain_cap - item)`.
    # For the sigmoid `S(v) = 1 / (1 + exp(-v))`:
    #  - if `v` is large positive (large remaining capacity): `S(v)` is close to 1.
    #  - if `v` is 0 (perfect fit): `S(v)` is 0.5.
    #  - if `v` is large negative (too small): `S(v)` is close to 0.

    # We want high priority for `v=0`.
    # We want lower priority for `v > 0`.
    # We want priority 0 for `v < 0`.
    
    # So, for `bins_remain_cap >= item`: let `v = -k * (bins_remain_cap - item)`
    # This is `v = k * (item - bins_remain_cap)`
    #  - If `bins_remain_cap = item`, `v=0`, `S(0)=0.5`.
    #  - If `bins_remain_cap > item`, `v` is negative, `S(v)` is <0.5.
    #  - If `bins_remain_cap` is much larger than `item`, `v` is large negative, `S(v)` is close to 0.
    
    # This structure `S(k * (item - bins_remain_cap))` provides a score that is:
    #  - 0.5 for perfect fit
    #  - Decreasing as remaining capacity increases beyond perfect fit
    #  - Approaches 0 for large remaining capacities.

    # Now we need to enforce the "cannot fit" constraint (priority 0).
    
    priorities = np.zeros_like(bins_remain_cap)
    
    # Define the steepness parameter for the sigmoid. Higher value means sharper transition.
    steepness = 5.0  # This parameter can be tuned.
    
    # Calculate the argument for the sigmoid: `steepness * (item - remaining_capacity)`
    # This means:
    # - If remaining_capacity == item, argument is 0. Sigmoid is 0.5.
    # - If remaining_capacity > item, argument is negative. Sigmoid is <0.5.
    # - If remaining_capacity < item, argument is positive. Sigmoid is >0.5.
    
    # We want the opposite for priority. So, we'll invert the sigmoid or transform the argument.
    # A common form for such prioritized selection is to use `1 - sigmoid` of some measure of "badness".
    # Or use `sigmoid` of some measure of "goodness".
    
    # Let's try to directly score "goodness":
    # Goodness is high if `remaining_capacity` is just enough.
    # The function `1 / (1 + exp(-k * (x - x0)))` peaks at `x0`.
    # Let `x = bins_remain_cap`. We want the peak when `x = item`.
    # The "ideal" remaining capacity `x0` should be `item`.
    
    # The issue with standard sigmoid is that it doesn't naturally go to 0 for non-fitting bins.
    # A practical approach for online BPP often involves a piecewise function or a modified sigmoid.
    
    # Let's define a score `s(c, i)` for a bin with capacity `c` and item `i`:
    # if `c < i`: s = 0
    # if `c >= i`: s = sigmoid_like_function(c - i) where it's high for `c-i` near 0 and decreases.
    
    # A common formulation is based on the ratio of remaining capacity to bin size,
    # or the difference.
    
    # Sigmoid Fit Score Strategy:
    # The strategy aims to fill bins as full as possible. It prioritizes bins
    # where the remaining capacity is close to the item size.
    
    # Let's model the priority `P(c, i)` for bin capacity `c` and item `i`.
    # We want `P(c, i) = 0` if `c < i`.
    # We want `P(c, i)` to be maximal when `c = i`.
    # We want `P(c, i)` to decrease as `c` increases beyond `i`.
    
    # Consider the sigmoid function `f(x) = 1 / (1 + exp(-k*x))`.
    # If we map `x` to `item - c`:
    # `f(k * (item - c))`:
    #   - `c < i`: `item - c > 0`, `k * (item - c) > 0`. `f(...)` is > 0.5, approaches 1. (High priority, bad)
    #   - `c = i`: `item - c = 0`. `f(...)` is 0.5. (Medium priority)
    #   - `c > i`: `item - c < 0`. `f(...)` is <0.5, approaches 0. (Low priority, good)
    
    # This means we need to apply it only to bins that can fit and invert the logic.
    
    # A robust implementation:
    # 1. For bins where `bins_remain_cap < item`, set priority to 0.
    # 2. For bins where `bins_remain_cap >= item`, calculate a score.
    #    We want this score to be high when `bins_remain_cap - item` is small.
    #    Use the sigmoid function to represent this.
    
    # Let `slack = bins_remain_cap - item`.
    # We want to transform `slack` such that small non-negative slack gives high priority.
    # Consider `sigmoid(-k * slack)` for `slack >= 0`.
    #   - If `slack = 0`: `-k * 0 = 0`. `sigmoid(0) = 0.5`.
    #   - If `slack > 0`: `-k * slack < 0`. `sigmoid(-k*slack) < 0.5`.
    #   - If `slack` is large positive: `-k * slack` is large negative. `sigmoid(...)` is close to 0.
    
    # This gives the highest priority (0.5) for perfect fit and decreasing priority for more slack.
    # This is the core "Sigmoid Fit Score" for fitting.
    
    # The resulting priority would be:
    # `priorities[i] = sigmoid(k * (item - bins_remain_cap[i]))` if `bins_remain_cap[i] >= item`, else 0.
    
    # Let's implement this.
    
    # Use a steepness factor. A common choice could be related to the maximum possible bin capacity,
    # or simply a tuned parameter.
    steepness_factor = 5.0
    
    # Calculate the argument for the sigmoid function.
    # We want higher priority when (item - remaining_capacity) is close to zero (meaning remaining_capacity is close to item).
    # So, the argument to sigmoid should be positive when remaining_capacity is close to item, and negative otherwise.
    # Using `item - bins_remain_cap` achieves this.
    # A perfectly fitting bin has `item - bins_remain_cap = 0`, leading to sigmoid(0) = 0.5.
    # A bin with more remaining capacity has `item - bins_remain_cap < 0`, leading to sigmoid(<0), which is <0.5.
    # A bin with less remaining capacity has `item - bins_remain_cap > 0`, leading to sigmoid(>0), which is >0.5.

    # This is not what we want. We want to prioritize bins that are ALMOST FULL.
    # So, if remaining capacity `c` is `i`, `c-i=0`.
    # If `c` is slightly more than `i`, `c-i` is slightly positive.
    # We want to give a high score for `c-i` near 0.
    
    # Let `x = bins_remain_cap - item`.
    # We want a score that is high when `x` is small non-negative.
    # `sigmoid(-k * x)` seems promising.
    #   - x = 0 => sigmoid(0) = 0.5
    #   - x = small positive => sigmoid(-k * small positive) < 0.5
    #   - x = large positive => sigmoid(-k * large positive) close to 0.
    
    # This assigns higher priority to bins that are *more full* relative to the item size.
    # This seems to align with "fitting snugly".

    # So, the score is `sigmoid(steepness_factor * (item - bins_remain_cap))` but ONLY for bins that can fit.
    
    # Calculate the raw sigmoid score for all bins:
    raw_sigmoid_scores = 1 / (1 + np.exp(-steepness_factor * (item - bins_remain_cap)))
    
    # Apply the mask: priority is 0 for bins that cannot fit the item.
    # The `raw_sigmoid_scores` will naturally be greater than 0.5 for bins that cannot fit
    # if we use `item - bins_remain_cap`. So we need to explicitly set them to 0.
    
    # Alternative approach: Let's define the argument to the sigmoid based on "waste" or "slack".
    # Waste = `bins_remain_cap - item`.
    # We want high priority when Waste is 0.
    # `sigmoid(k * (item - Waste))` or `sigmoid(k * (item - (bins_remain_cap - item)))`
    # `sigmoid(k * (2*item - bins_remain_cap))`
    
    # Let's try the most common interpretation of Sigmoid Fit: prioritizing bins where the remaining capacity is close to the item size.
    # This means minimizing `bins_remain_cap - item` for `bins_remain_cap >= item`.
    
    # We want to map `bins_remain_cap` to a priority.
    # Let's use the sigmoid `S(x) = 1 / (1 + exp(-k*x))`
    # We want the sigmoid to output a high value when `bins_remain_cap` is close to `item`.
    # Let's consider `k * (item - bins_remain_cap)` as input.
    # When `bins_remain_cap = item`, input is 0, S(0) = 0.5.
    # When `bins_remain_cap < item`, input is positive, S > 0.5.
    # When `bins_remain_cap > item`, input is negative, S < 0.5.
    
    # This structure gives higher scores to bins that are too small. We want to avoid that.
    
    # The sigmoid can be used to model a probability or desirability.
    # Let's consider the desired property: if `c` is remaining capacity, `i` is item size.
    # Priority is high if `c >= i` and `c - i` is small.
    
    # Consider the function: `priority = sigmoid(k * (item - (bins_remain_cap - item)))`
    # `priority = sigmoid(k * (2*item - bins_remain_cap))`
    
    # Let's test this:
    # `steepness = 5.0`
    # `argument = 2 * item - bins_remain_cap`
    # `priorities = 1 / (1 + exp(-steepness * argument))`
    
    # If `bins_remain_cap = item`: `argument = 2*item - item = item`. `priorities = sigmoid(k*item)` (depends on item size). Not ideal.
    
    # The fundamental idea of sigmoid fit is to make the decision based on the *shape* of the remaining capacity distribution.
    # The "First Fit Decreasing" heuristic often works well because it tries to fit large items first.
    # For online, "Best Fit" aims to minimize remaining capacity after packing.
    
    # Sigmoid Fit:
    # Prioritize bins `j` with remaining capacity `c_j` such that `c_j` is close to `item`.
    # A score `s(c, i)`:
    # `s(c, i) = 0` if `c < i`
    # `s(c, i) = 1 / (1 + exp(-k * (i - c)))` if `c >= i`. This yields:
    #   - 0.5 for c=i
    #   - values < 0.5 for c>i
    #   - values > 0.5 for c<i (which we exclude)
    
    # So, if we take this formula `1 / (1 + exp(-k * (i - c)))` and then clamp it to 0 for `c < i`:
    # Let `arg = k * (item - bins_remain_cap)`
    # `scores = 1 / (1 + np.exp(-arg))`
    # For bins where `bins_remain_cap < item`: `item - bins_remain_cap > 0`, `arg > 0`, `scores > 0.5`. We need these to be 0.
    # For bins where `bins_remain_cap >= item`: `item - bins_remain_cap <= 0`, `arg <= 0`, `scores <= 0.5`.
    # This means bins with remaining capacity equal to item size get 0.5, and bins with larger remaining capacity get less than 0.5.
    # This gives highest priority to bins that are *almost full but can still fit the item*.
    
    # This seems like a reasonable interpretation of "Sigmoid Fit Score" aiming to reduce wasted space.
    
    priorities = np.zeros_like(bins_remain_cap)
    steepness = 7.0  # Tune this parameter: controls how quickly the score drops as remaining capacity increases.

    # Calculate the "fit quality" score.
    # We want higher scores when `bins_remain_cap` is close to `item`.
    # Let's use `item - bins_remain_cap` as the argument to the sigmoid.
    # When `bins_remain_cap` is slightly larger than `item` (small slack): `item - bins_remain_cap` is small negative. Sigmoid is < 0.5.
    # When `bins_remain_cap` equals `item` (zero slack): `item - bins_remain_cap` is 0. Sigmoid is 0.5.
    # When `bins_remain_cap` is significantly larger than `item` (large slack): `item - bins_remain_cap` is larger negative. Sigmoid is closer to 0.
    
    # This means that `sigmoid(k * (item - bins_remain_cap))` results in:
    # - Higher scores for bins that are closer to being full.
    # - Maximum score of 0.5 for perfect fits.
    # - Scores decreasing towards 0 as remaining capacity increases.
    
    # We also need to ensure bins that *cannot* fit the item get a priority of 0.
    # If `bins_remain_cap < item`, then `item - bins_remain_cap` is positive.
    # `sigmoid(k * positive)` will be > 0.5. These should be zero.
    
    # So, we calculate the sigmoid score only for bins that can fit:
    
    can_fit_indices = np.where(bins_remain_cap >= item)[0]
    
    if len(can_fit_indices) > 0:
        # For bins that can fit, calculate the sigmoid score.
        # The argument `steepness * (item - bins_remain_cap)` means:
        # - if `bins_remain_cap = item`, arg = 0, sigmoid = 0.5 (best fit)
        # - if `bins_remain_cap > item`, arg < 0, sigmoid < 0.5 (more waste)
        # - as `bins_remain_cap` increases, arg becomes more negative, sigmoid approaches 0.
        
        fit_scores = 1 / (1 + np.exp(-steepness * (item - bins_remain_cap[can_fit_indices])))
        priorities[can_fit_indices] = fit_scores

    # The priorities are now in the range [0, 0.5] for fitting bins, and 0 for non-fitting bins.
    # This strategy effectively prioritizes bins that offer a tighter fit.
    # It is a variant of "Best Fit" using a sigmoid to smooth the scoring.
    
    return priorities
```
