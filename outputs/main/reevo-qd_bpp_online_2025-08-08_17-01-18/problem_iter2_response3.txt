```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a blended strategy.

    This strategy combines the preference for exact fits with the soft preference
    for near-exact fits using a Softmax-like approach. It prioritizes bins
    where the remaining capacity is exactly the item size, and then assigns
    decreasing priority to bins with slightly larger remaining capacities.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    eligible_bins_cap = bins_remain_cap[can_fit_mask]

    if not eligible_bins_cap.size:
        return np.zeros_like(bins_remain_cap)

    # Calculate the "fit score": how much space is left after placing the item.
    # Smaller values indicate a tighter fit.
    fit_scores = eligible_bins_cap - item

    # Assign a base priority of 1.0 to exact fits and a lower base priority to partial fits.
    # This ensures exact fits are always preferred over partial fits before softmax.
    base_priorities = np.where(fit_scores == 0, 1.0, 0.5)

    # To incorporate the "near-exact" preference smoothly, we can modify the
    # base priorities based on how close the fit is, using a logistic or exponential decay.
    # Here, we use a simple exponential decay for remaining space.
    # Smaller remaining space (after fitting) should get higher priority.
    # We add 1 to fit_scores to handle the case of exact fit (fit_score=0) gracefully
    # and ensure positive values for exponentiation.
    # The scaling factor (e.g., 1.0) and the decay rate (e.g., 0.1) can be tuned.
    decay_rate = 0.1
    near_fit_scores = np.exp(-decay_rate * fit_scores)

    # Blend the base priority with the near-fit score.
    # Exact fits should retain their high base priority, while near-fits get a boost.
    # We prioritize exact fits (score 1.0) and then near-exact fits.
    # A simple way to blend is to amplify the scores of exact fits and give
    # a scaled score to near-fits.
    combined_scores = np.where(fit_scores == 0, 1.0, near_fit_scores)

    # Apply a Softmax-like transformation to normalize and create probabilities.
    # This smooths the preferences, giving higher probability to better fits.
    # The temperature parameter controls the "softness".
    temperature = 0.5
    try:
        # Add a small epsilon to prevent log(0) or division by zero issues
        epsilon = 1e-9
        scaled_scores = combined_scores / temperature
        exp_scores = np.exp(scaled_scores)
        softmax_priorities = exp_scores / np.sum(exp_scores)
    except OverflowError:
        # Fallback for overflow: assign uniform probability if scores are too extreme
        softmax_priorities = np.ones_like(eligible_bins_cap) / eligible_bins_cap.size


    # Map the calculated priorities back to the original bin indices
    priorities[can_fit_mask] = softmax_priorities

    return priorities
```
