```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin, prioritizing tight fits.

    This heuristic prioritizes bins that can accommodate the item, favoring "tight fits"
    (smaller remaining capacity after packing) to minimize wasted space.
    A softmax function is used to convert these preferences into probabilities,
    allowing for some exploration. The temperature parameter controls the
    aggressiveness of the selection. Bins that are too small for the item receive a priority of 0.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    temperature = 1.0  # Tune this parameter: lower for more greedy, higher for more exploration

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # For bins that can fit, calculate a score based on how tight the fit is.
    # A smaller remaining capacity after packing means a tighter fit.
    # We add a small epsilon to avoid division by zero if a bin has exactly the item's size.
    tight_fit_scores = 1.0 / (bins_remain_cap[can_fit_mask] - item + 1e-9)

    # Apply softmax to convert scores into probabilities/priorities
    # Ensure no division by zero if all scores are effectively zero (e.g., no bin fits)
    if np.sum(tight_fit_scores) > 0:
        # Softmax calculation: exp(score / temperature) / sum(exp(score / temperature))
        # To avoid numerical instability with large scores, we can subtract the max score.
        max_score = np.max(tight_fit_scores)
        exp_scores = np.exp((tight_fit_scores - max_score) / temperature)
        sum_exp_scores = np.sum(exp_scores)

        if sum_exp_scores > 0:
            priorities[can_fit_mask] = exp_scores / sum_exp_scores
        else:
            # Handle cases where sum of exp_scores might be zero due to extreme values or temperature
            # In such rare cases, fall back to uniform distribution among fitting bins
            num_fitting_bins = np.sum(can_fit_mask)
            if num_fitting_bins > 0:
                priorities[can_fit_mask] = 1.0 / num_fitting_bins
    else:
        # If no bins can fit, priorities remain zero.
        pass

    # Tie-breaking: Favor earlier bins (lower index) if priorities are very close.
    # This can be implicitly handled by the order of processing or explicitly added
    # by adding a small negative value based on index to the score before softmax,
    # e.g., score - index * epsilon_tiebreaker. For simplicity here, we rely on
    # the original order and potential floating point differences.

    return priorities
```
