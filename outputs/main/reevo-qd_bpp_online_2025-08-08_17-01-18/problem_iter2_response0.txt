```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a Softmax-based approach
    that also incorporates an epsilon-greedy exploration strategy.

    This heuristic first calculates a "fit score" for each bin, where a better fit (less remaining capacity)
    results in a higher score. These scores are then transformed using softmax to get probabilities.
    An epsilon-greedy component is added: with a small probability `epsilon`, a bin is chosen randomly
    from the *suitable* bins to encourage exploration. Otherwise, the greedy (softmax-derived)
    priorities are used.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    epsilon = 0.1  # Probability of exploring a random suitable bin

    # Identify bins that can accommodate the item
    suitable_bins_mask = bins_remain_cap >= item
    suitable_bin_indices = np.where(suitable_bins_mask)[0]

    n_bins = len(bins_remain_cap)
    priorities = np.zeros(n_bins)

    if len(suitable_bin_indices) == 0:
        # No bin can fit the item, return all zeros
        return priorities

    # Epsilon-greedy choice: With probability epsilon, pick a random suitable bin
    if np.random.rand() < epsilon:
        # Choose one suitable bin randomly
        chosen_index = np.random.choice(suitable_bin_indices)
        # Assign a high priority to this randomly chosen bin
        priorities[chosen_index] = 1.0
        # For other bins, assign a very low priority to make the chosen one stand out
        priorities[suitable_bin_indices] = 1e-9
        # Ensure non-suitable bins remain at 0
        return priorities

    # If not exploring, use a greedy strategy based on how well the item fits.
    # We want bins where the remaining capacity is just enough for the item.
    # The score should be higher for bins with `bins_remain_cap - item` closer to 0.
    # Use `-(bins_remain_cap - item)` as the score, which is `item - bins_remain_cap`.
    # This makes smaller positive differences (better fits) have higher scores.

    scores = item - bins_remain_cap

    # For bins that cannot fit the item, assign a very low score.
    # This ensures their softmax probability is negligible.
    scores[~suitable_bins_mask] = -np.inf  # Effectively -infinity for softmax

    # Calculate softmax probabilities
    # exp_scores = np.exp(scores)
    # To prevent potential overflow with large positive scores or underflow with large negative scores,
    # we can use `np.exp(scores - np.max(scores))` if scores are not all -inf.
    # Since we set non-suitable bins to -inf, and suitable bins have scores >= 0,
    # np.max(scores) will be at least 0 for suitable bins.
    
    # Calculate logits, ensuring they are not all -inf
    max_score = np.max(scores[suitable_bins_mask]) if np.any(suitable_bins_mask) else 0
    
    # Shift scores so that the maximum is 0 to avoid large exponents
    shifted_scores = scores - max_score
    
    # Ensure exp_scores are non-negative and sum is positive before division
    exp_scores = np.exp(shifted_scores)
    
    sum_exp_scores = np.sum(exp_scores)
    
    if sum_exp_scores == 0:
        # This case should ideally not be reached if there's at least one suitable bin
        # but as a safeguard, return uniform probabilities for suitable bins.
        # This would mean assigning equal probability to all bins that can fit.
        if np.any(suitable_bins_mask):
            priorities[suitable_bins_mask] = 1.0 / len(suitable_bin_indices)
        return priorities
    
    priorities = exp_scores / sum_exp_scores

    return priorities
```
