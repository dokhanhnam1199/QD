```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority scores for packing an item into bins using a refined
    heuristic that combines Exact Fit, Best Fit, and a touch of exploration,
    guided by bin scarcity and using Softmax for probabilistic selection.

    The heuristic prioritizes bins based on the following criteria, combined
    into a single score:

    1.  **Exact Fit Bonus:** Bins where `bins_remain_cap == item` receive a
        significant bonus, encouraging zero waste.
    2.  **Best Fit Score (Inverse Gap):** For bins that can fit the item but
        are not an exact fit, a score is calculated based on the inverse of
        the remaining capacity after packing (`bins_remain_cap - item`). This
        prioritizes bins with minimal leftover space (smallest positive gap).
        A small epsilon is added to avoid division by zero.
    3.  **Bin Scarcity Score:** Bins with less remaining capacity overall are
        considered scarcer and are slightly favored. This is modeled using
        `1 / (bins_remain_cap + epsilon)`.
    4.  **Exploration (Softmax):** All computed raw scores are converted into
        probabilities using the Softmax function. A temperature parameter
        controls the level of exploration: a higher temperature leads to more
        uniform probabilities, encouraging exploration of less optimal bins.

    The final priority score for each bin is its probability derived from
    the Softmax application.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.

    Returns:
        A NumPy array of the same size as `bins_remain_cap`, where each element
        is the probability score for the corresponding bin. Bins that cannot
        fit the item will have a priority of 0.
    """
    n_bins = len(bins_remain_cap)
    priorities = np.zeros(n_bins, dtype=float)

    # Identify bins that can accommodate the item
    suitable_bins_mask = bins_remain_cap >= item
    suitable_bin_indices = np.where(suitable_bins_mask)[0]

    if len(suitable_bin_indices) == 0:
        return priorities

    # --- Calculate Raw Scores ---
    raw_scores = np.zeros_like(bins_remain_cap, dtype=float)
    
    # Parameters for scoring
    exact_fit_bonus = 10.0  # Significant bonus for exact fits
    best_fit_weight = 1.0   # Weight for the best fit component
    scarcity_weight = 0.1   # Weight for the bin scarcity component
    epsilon = 1e-6          # Small value for numerical stability

    for i in suitable_bin_indices:
        remaining_cap = bins_remain_cap[i]
        
        # 1. Exact Fit Bonus
        if remaining_cap == item:
            exact_fit_score = exact_fit_bonus
        else:
            exact_fit_score = 0.0

        # 2. Best Fit Score (Inverse Gap)
        gap = remaining_cap - item
        # A smaller gap (closer to 0) should have a higher score.
        # Use 1 / (gap + epsilon) to make smaller gaps result in larger values.
        best_fit_score = best_fit_weight * (1.0 / (gap + epsilon))

        # 3. Bin Scarcity Score
        # Favors bins with less remaining capacity.
        scarcity_score = scarcity_weight * (1.0 / (remaining_cap + epsilon))
        
        # Combine scores. Exact fit is a large bonus, best fit and scarcity contribute additively.
        # We can think of exact_fit_score as a large additive bonus to other scores.
        raw_scores[i] = exact_fit_score + best_fit_score + scarcity_score

    # --- Apply Softmax for Probabilistic Selection ---
    # This converts the raw scores into probabilities, allowing for exploration.
    
    # Temperature parameter: controls the 'softness' of the probability distribution.
    # Lower temperature -> favors higher scores more strongly (closer to greedy)
    # Higher temperature -> probabilities are more uniform (more exploration)
    temperature = 0.5  # Tunable parameter

    # Ensure only suitable bins contribute to the sum and receive probabilities
    suitable_raw_scores = raw_scores[suitable_bins_mask]
    
    # For numerical stability in Softmax, subtract the maximum score
    # before exponentiation.
    if len(suitable_raw_scores) > 0:
        stable_scores = (suitable_raw_scores / temperature) - np.max(suitable_raw_scores / temperature)
        exp_scores = np.exp(stable_scores)
        probabilities = exp_scores / np.sum(exp_scores)
        
        # Assign the computed probabilities to the corresponding bins
        priorities[suitable_bins_mask] = probabilities

    return priorities
```
