```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, temperature: float = 1.0, epsilon: float = 1e-9) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a tunable heuristic.

    This heuristic prioritizes bins that can accommodate the item. It uses a function
    that maps the "wasted space" (remaining capacity - item size) to a priority score.
    Smaller wasted space (tighter fits) result in higher priority scores.

    The function used is `1 / (1 + wasted_space^gamma)`, where `gamma` controls the
    sensitivity to the fit tightness.
    - `gamma = 1` (similar to v1) gives a linear penalty for wasted space.
    - `gamma > 1` penalizes larger wasted spaces more severely, thus strongly
      favoring tight fits.
    - `0 < gamma < 1` makes the function less sensitive to wasted space,
      prioritizing "good enough" fits more broadly.

    The `temperature` parameter controls the exploration vs. exploitation trade-off
    when converting these scores into selection probabilities using softmax.
    Higher temperatures lead to more uniform probabilities (more exploration), while
    lower temperatures focus on the best-fitting bins (more exploitation).
    Bins that are too small for the item receive a priority of 0.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.
        temperature: Controls the sharpness of the softmax distribution. Must be positive.
        epsilon: A small value to prevent division by zero and handle perfect fits.

    Return:
        Array of same size as bins_remain_cap with priority score (probability) of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # For bins that can fit, calculate a "goodness" score based on wasted space.
    # Wasted space = remaining_capacity - item
    # We want to maximize the score when wasted space is small (tight fit).
    # Using `1.0 / (epsilon + wasted_space**gamma)` where gamma is a tunable parameter.
    # A higher gamma emphasizes tighter fits.
    # Let's set gamma to a default that favors tighter fits but is not overly aggressive.
    # gamma = 1.5 is a reasonable starting point.
    gamma = 1.5
    wasted_space = bins_remain_cap[can_fit_mask] - item

    # The score is higher for smaller wasted_space.
    # Add epsilon to prevent division by zero for perfect fits (wasted_space = 0).
    # Power of gamma amplifies the effect of wasted space.
    scores_for_softmax = 1.0 / (epsilon + wasted_space**gamma)

    # Apply softmax to get probabilities.
    if temperature <= 0:
        raise ValueError("Temperature must be positive.")

    # Avoid potential issues with very large exponentiated scores if temperature is very small
    # and scores_for_softmax are large. Clamp values if necessary, though unlikely with 1/(1+x^g).
    # We can also use `np.finfo(float).eps` for epsilon, but a small fixed value is often sufficient.
    try:
        exp_scores = np.exp(scores_for_softmax / temperature)
    except OverflowError:
        # If scores are extremely large, this can happen. Re-scale or clip.
        # For simplicity here, we might assume reasonable inputs or clip.
        # A safer approach might involve log-sum-exp trick if scores get huge.
        # For now, let's assume typical bin packing scenarios won't cause this.
        print("Warning: OverflowError in np.exp. Consider adjusting temperature or gamma.")
        # As a fallback, distribute probability more uniformly for extreme cases.
        exp_scores = np.ones_like(scores_for_softmax) # Treat all as equally good if overflow

    # Normalize to get probabilities
    sum_exp_scores = np.sum(exp_scores)
    if sum_exp_scores > 0:
        probabilities = exp_scores / sum_exp_scores
    else:
        # This case should ideally not happen if can_fit_mask is true and scores are valid
        probabilities = np.zeros_like(exp_scores)

    # Assign probabilities to the original priorities array
    priorities[can_fit_mask] = probabilities

    # Ensure that the sum of priorities is 1 if there's at least one valid bin.
    # This normalization is implicitly done by softmax if sum_exp_scores > 0.
    # If no bins can fit, priorities remains all zeros, which is correct.

    return priorities
```
