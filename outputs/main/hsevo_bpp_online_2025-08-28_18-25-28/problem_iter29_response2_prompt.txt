{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with adaptive softmax, utilizing bin utilization for temperature scaling.\"\"\"\n    n_bins = len(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    remaining_caps = bins_remain_cap[possible_bins]\n    fit_scores = - (remaining_caps - item)\n    bin_utilization = np.sum(bins_remain_cap) / (n_bins * np.max(bins_remain_cap))\n    temperature = np.mean(remaining_caps) / item if np.mean(remaining_caps) > 0 else 1.0\n    temperature = np.clip(temperature * (1.0 - bin_utilization), 0.1, 1.0)\n    probabilities = np.exp(fit_scores / temperature)\n    probabilities /= np.sum(probabilities)\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[possible_bins] = probabilities\n    best_bin_index = np.argmax(probabilities)\n    if possible_bins[best_bin_index]:\n        priorities[best_bin_index] += 0.1\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with adaptive softmax exploration and utilization-based temperature.\"\"\"\n    n_bins = len(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    remaining_caps = bins_remain_cap[possible_bins]\n    fit_scores = 1.0 / (remaining_caps - item + 1e-6)\n    bin_utilization = np.sum(bins_remain_cap) / (n_bins * np.max(bins_remain_cap))\n    temperature = np.clip(1.0 - bin_utilization, 0.1, 1.0)\n    exp_scores = np.exp(fit_scores / temperature)\n    probabilities = exp_scores / np.sum(exp_scores)\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[possible_bins] = probabilities\n    best_bin_index = np.argmax(priorities)\n    priorities[best_bin_index] += 0.2\n    return priorities\n\n### Analyze & experience\n- Comparing heuristics 1st vs 2nd, the only difference is the `np.clip` function in the 2nd heuristic, limiting the temperature between 0.1 and 1.0. This suggests the temperature calculation in the first heuristic can sometimes result in values outside a reasonable range, which the clipping in the 2nd heuristic addresses.  Heuristics 1st, 2nd, and 3rd are identical, indicating no improvement.\n\nComparing 4th vs 5th, the 4th version directly uses `np.zeros_like` for initialization which is slightly cleaner and potentially faster. It also sets the temperature clip to be explicitly between 0.1 and 1.0. The 5th heuristic re-calculates `fit_scores` unnecessarily, and seems less readable. \n\nComparing 6th/7th vs 8th/9th, the versions seem largely identical except that 6th/7th use `if possible_bins[best_bin_index]` condition after `np.argmax` to avoid errors (improving robustness), and the 7th version consolidates the max/min logic into a single line.\n\nComparing 10th vs 11th/12th, 10th explicitly addresses a potential divide-by-zero error in the temperature calculation by adding a small value (1e-6). Heuristics 11th and 12th attempt similar temperature handling but are less concise.\n\nHeuristics 13th, 14th, and 15th are nearly identical. 16th/17th/18th are also similar, but simplify code. Heuristic 19th is very similar to 18th. \n\nOverall: The best heuristics (1st-4th) focus on combining best-fit with a temperature-scaled softmax, adapting temperature based on bin utilization.  The later heuristics often refine temperature calculations for stability and readability, often adding a clipping mechanism. The addition of a small bonus to the best bin (e.g., multiplying the probability by 1.2 or 0.2) is consistent but its value is empirically driven. Utilizing `np.zeros_like` for array initialization and avoiding unnecessary re-calculations are minor but beneficial improvements.\n- \nOkay, let's distill that extensive self-reflection into actionable heuristic design guidance. Here's a breakdown aiming for that $999K tip!\n\n*   **Keywords:** Adaptive Temperature, Softmax, Bin Utilization, Robustness, Exploration/Exploitation.\n*   **Advice:** Focus on *dynamically* adjusting softmax temperature based on bin utilization. Prioritize a robust fit score (handling edge cases like division by zero) and small, normalized exploration boosts *within* the softmax framework.\n*   **Avoid:** Static rewards, `argmax` selection, arbitrary constants, and overly complex implementations. Don't prematurely commit to a single bin *before* normalization via softmax.\n*   **Explanation:** The core is balancing immediate gain (best-fit) with exploration. Adaptive temperature scaling, driven by bin utilization, is the key. Softmax provides probabilistic selection; avoid manipulating probabilities *after* this normalization unless demonstrably beneficial via rigorous testing.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}