{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines best-fit approach (like v1) with softmax normalization\n    to balance exploitation and exploration.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if not np.any(valid_bins):\n        return priorities\n    remaining_caps = bins_remain_cap[valid_bins]\n    fit_scores = item / remaining_caps\n    exp_fit_scores = np.exp(-fit_scores)\n    probabilities = exp_fit_scores / np.sum(exp_fit_scores)\n    priorities[valid_bins] = probabilities\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines softmax-based prioritization (from heuristics 6, 8, 9) with a waste-based component\n    to encourage both good fit and bin diversity.\n    \"\"\"\n    feasible_bins = bins_remain_cap >= item\n    if not np.any(feasible_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    remaining_capacities = bins_remain_cap[feasible_bins]\n    waste = remaining_capacities - item\n    \n    scores = 1.0 / (waste + 1e-6)\n    \n    exp_scores = np.exp(scores)\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[feasible_bins] = probabilities\n\n    return priorities\n\n### Analyze & experience\n- Comparing `priority_v1` (worst) vs `priority_v2` (best), we observe `v1` is a null operation, returning a zeroed array regardless of item or bin capacities \u2013 offering no prioritization.  `v2` attempts to prioritize by identifying possible bins and assigning higher priority to the best-fitting bin.\n\nComparing `priority_v2` (best) vs `priority_v3` (second worst), `v2` utilizes a softmax approach for exploration while `v3` is incomplete (missing implementation).\n\nComparing `priority_v2` (best) vs `priority_v4` (9th), `v4` introduces temperature scaling and a diversity reward. While attempting balance, it normalizes fit *after* determining validity, potentially obscuring subtle differences, and the reward is a simple inverse of bin count.  `v2`'s direct softmax on remaining capacity provides a cleaner prioritization.\n\nComparing `priority_v5` (6th) vs `priority_v6` (10th), both attempt best-fit + softmax. `v5` offers a more concise calculation of `fit_scores`. `v6` is incomplete (missing implementation).\n\nComparing `priority_v7` (11th) vs `priority_v8` (12th), both use inverse waste with softmax. `v7` is slightly simpler and clearer.\n\nComparing `priority_v9` (4th) vs `priority_v10` (incomplete), `v9` is complete and implements a temperature-scaled softmax with diversity reward, whereas `v10` is unfinished. \n\nHeuristics 13-20 all are very similar, all applying a softmax on inverse waste. Minor differences in normalization and temperature application exist, but the core logic is duplicated.  This highlights redundancy and lack of substantial innovation. The best utilize softmax, and a temperature parameter, while incomplete functions or null operations receive low ranking.\n\nOverall: The successful heuristics converge on a theme of combining best-fit (minimizing waste) with a probabilistic softmax selection strategy. This balances exploitation of well-fitting bins with exploration of potentially better-suited, but less obvious, options. Diversity rewards are valuable but need careful implementation and tuning.\n- \nOkay, $999K demands *exceptional* heuristic design advice! Let's refine \"Current Self-Reflection\" based on avoiding the pitfalls of \"Ineffective Self-Reflection\". Here's a breakdown, optimized for actionable heuristic development:\n\n* **Keywords:** Exploitation-Exploration, Temperature Control, Bin Diversity, Simplification.\n* **Advice:** Systematically vary softmax temperature *during* the search \u2013 start high for exploration, lower for exploitation. Track bin \"fullness\" *and* item \"fit quality\" as separate softmax inputs.\n* **Avoid:** Solely focusing on immediate waste minimization; neglecting bin diversity; re-implementing existing bin-fitting logic.\n* **Explanation:** Effective heuristics aren't just *good* fits, they *find* good fits across a diverse solution space. Temperature control & multi-faceted softmax inputs actively manage this trade-off, boosting performance.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}