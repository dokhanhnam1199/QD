{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    return priorities\n\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return priorities\n    \n    best_bin_index = np.argmin(bins_remain_cap[possible_bins] - item)\n    priorities[possible_bins] = 1.0\n    priorities[best_bin_index] = 2.0\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with adaptive softmax temperature, prioritizing bin utilization and robustness.\"\"\"\n    n_bins = len(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return np.zeros_like(bins_remain_cap)\n    remaining_caps = bins_remain_cap[possible_bins]\n    fit_scores = - (remaining_caps - item)\n    bin_utilization = np.sum(bins_remain_cap) / (n_bins * np.max(bins_remain_cap))\n    temperature = np.mean(remaining_caps) / item if np.mean(remaining_caps) > 0 else 1.0\n    temperature = np.clip(temperature * (1.0 - bin_utilization), 0.1, 1.0)\n    probabilities = np.exp(fit_scores / temperature)\n    probabilities /= np.sum(probabilities)\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[possible_bins] = probabilities\n    best_bin_index = np.argmax(probabilities)\n    if possible_bins[best_bin_index]:\n        priorities[best_bin_index] += 0.1\n    return priorities\n\n### Analyze & experience\n- Comparing `priority_v2` (1st) vs `priority_v1` (2nd), the first introduces a sophisticated scoring system based on best-fit, bin utilization, and a temperature-scaled softmax, while the second returns zero priorities.  The 1st uses a temperature parameter adjusted by bin utilization for more nuanced bin selection, crucial for performance.\n\nComparing `priority_v2` (3rd) vs `priority_v2` (4th), both are identical implementations, representing a redundant entry.\n\nComparing `priority_v2` (1st) vs `priority_v2` (5th), we see the 1st is a more robust implementation using temperature scaling and softmax for a probabilistic choice, while the 5th only assigns 1 or 2 to bins, lacking smoothness.\n\n`priority_v2` (7th) and `priority_v2` (8th) are duplicates.  Analyzing `priority_v2` (10th) reveals it tries to normalize scores but ultimately assigns all probability to the best bin, eliminating exploration. `priority_v2` (13th) is similar, but better temperature control.  `priority_v2` (17th) uses reciprocal fit scores which can be problematic with near-zero remaining capacity.  `priority_v2` (18th) and `priority_v2` (20th) add a small boost to the best bin, which is a minor improvement, but not as effective as the temperature-scaled softmax. The later heuristics (11th, 12th, 14th, 15th, 16th, 19th) include duplicates or variations that simplify temperature calculation without the adaptive quality of the best heuristics.\n\nOverall: The core strength of the best heuristics lies in the adaptive temperature scaling based on bin utilization and the softmax probability distribution.  This balance between exploitation (best fit) and exploration (probabilistic bin selection) is key.  Avoiding division by zero or near-zero values in the scoring function is critical. The repeated, and simpler heuristics lack these crucial features and therefore perform worse.\n- \nOkay, let's distill actionable heuristic design advice from this extensive self-reflection. Here's a breakdown geared towards maximizing performance, aiming for that $999K tip!\n\n* **Keywords:** Adaptive Temperature Scaling, Softmax, Bin Utilization, Exploration/Exploitation, Robustness.\n* **Advice:** Dynamically adjust softmax temperature *directly* with bin utilization \u2013 higher temperature when bins are full (encourage exploration), lower when empty (exploit best fit). Implement temperature clamping (0.1-1.0). Focus on *complete* and readable code.\n* **Avoid:** Static exploration bonuses, `argmax` selections, arbitrary constants, & complex heuristics solely prioritizing immediate gain. Don't prematurely commit to a single bin.\n* **Explanation:** The core issue is balancing exploration & exploitation. Bin utilization is a *direct* indicator of how much exploration is needed. Softmax with adaptive temperature provides a stable, probabilistic selection mechanism avoiding local optima.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}