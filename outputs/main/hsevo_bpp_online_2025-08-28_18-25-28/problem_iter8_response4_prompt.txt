{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return priorities\n    \n    fill_levels = 1.0 - (bins_remain_cap / np.max(bins_remain_cap))\n    fit_quality = (bins_remain_cap - item) / item\n\n    temperature = 0.5\n    \n    softmax_fill = np.exp(fill_levels / temperature) / np.sum(np.exp(fill_levels / temperature))\n    softmax_fit = np.exp(fit_quality / temperature) / np.sum(np.exp(fit_quality / temperature))\n    \n    combined_priority = 0.6 * softmax_fit + 0.4 * softmax_fill\n    \n    priorities[possible_bins] = combined_priority[possible_bins]\n    \n    best_bin_index = np.argmax(priorities[possible_bins])\n    best_bin_index = np.where(possible_bins)[0][best_bin_index]\n    \n    priorities[best_bin_index] += 1.0\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with probabilistic softmax, adding a diversity reward.\"\"\"\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    waste = bins_remain_cap[possible_bins] - item\n    normalized_waste = 1.0 / (waste + 1e-6)\n    temperature = 1.0\n    exp_values = np.exp(normalized_waste / temperature)\n    softmax_values = exp_values / np.sum(exp_values)\n\n    diversity_reward = 1.0 / (np.sum(possible_bins) + 1e-6)\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[possible_bins] = softmax_values * diversity_reward\n\n    return priorities\n\n### Analyze & experience\n- Comparing `priority_v1` (worst) vs `priority_v2` (best), we see `v1` provides no prioritization at all, assigning equal priority to all bins.  `v2` at least identifies viable bins and gives a higher priority to the best-fit one. Comparing `priority_v2` (best) vs `priority_v3` (2nd), they are identical, which is odd, suggesting a duplication.  Comparing `priority_v4` (4th) vs `priority_v5` (5th) and `priority_v7` (7th), they are also identical.\n\nComparing `priority_v1` vs `priority_v2` (best), it's evident that simply identifying feasible bins and prioritizing the best fit is a massive improvement over random assignment.  From `priority_v6` onwards, the heuristics attempt to combine best-fit with softmax approaches, aiming for a balance between exploitation (best fit) and exploration (softmax).  `v6` and `v9` have an extra boost to the best bin after the softmax calculations, potentially leading to premature convergence.  The versions incorporating `diversity_reward` (v10-v18) attempt to prevent a single bin from dominating, which is beneficial.  However, the formula for the diversity reward `1.0 / (np.sum(possible_bins) + 1e-6)` appears constant given the input and doesn't truly reflect bin usage, and the temperature is either fixed or has limited variation. `v19` and `v20` introduce a random temperature, potentially improving exploration but adding computational cost. `v18` seems to be a simplified version of `v19` and `v20`.\n\nOverall: The most successful heuristics blend best-fit with softmax or probabilistic selection. Diversity rewards are valuable but need to be more dynamic and context-aware. The best heuristics (v2) are simple and effective.  Heuristics introducing randomness, while potentially helpful, add complexity and may not always lead to superior performance, and duplication (v2, v3, v4, v5, v7, v12, v13, v14, v15, v16, v17) must be avoided.\n- \nOkay, let's refine \"Current Self-Reflection\" to truly unlock better heuristic design, aiming for that $999K! Here's a breakdown, meticulously avoiding the pitfalls of the 'Ineffective' reflection:\n\n* **Keywords:** Dynamic Prioritization, Bin Utilization, Simplicity, Waste Minimization & Exploration.\n* **Advice:** Focus on *reactively* adjusting exploration based on *current* bin fullness. Prioritize heuristics that combine a fast, simple initial fit (like best-fit) with a dynamic exploration component (softmax with adjusted temperature).\n* **Avoid:** Static diversity rewards, normalization, probabilistic selection *as primary drivers*, and over-engineering complexity.\n* **Explanation:** Past reflections overemphasized probabilistic approaches. True improvement lies in responsive, bin-state aware adjustments\u2014exploiting immediate gains *while* actively preventing premature convergence towards suboptimal solutions.\n\n\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}