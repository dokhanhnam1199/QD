```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Best Fit Sigmoid Score.

    This heuristic prioritizes bins that are the "tightest fit" for the item.
    A tight fit means the bin's remaining capacity is as close as possible to the item's size,
    but still large enough to contain it. This is the essence of the "Best Fit" strategy.
    The sigmoid function is used to provide a smooth priority score between 0 and 1.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Initialize priorities to zero. Bins that cannot fit the item will retain a score of 0.
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins where the item can actually fit.
    can_fit_indices = np.where(bins_remain_cap >= item)[0]

    # If no bins can fit the item, return all zeros.
    if len(can_fit_indices) == 0:
        return priorities

    # Get the remaining capacities of the bins that can fit the item.
    valid_bins_remain_cap = bins_remain_cap[can_fit_indices]

    # To implement "Best Fit" using a sigmoid, we want to prioritize bins where
    # `bins_remain_cap` is small (but still >= `item`).
    # This means the "gap" (`bins_remain_cap - item`) should be minimized.

    # A good metric for "tightness" that works well with sigmoid is the ratio of item size
    # to the remaining capacity. For a tight fit, this ratio `item / bins_remain_cap` will be close to 1.
    # Bins with a higher ratio are considered better fits.
    # We use `item / (valid_bins_remain_cap + epsilon)` to avoid division by zero and handle perfect fits gracefully.
    # A small epsilon is added to the denominator for numerical stability.
    epsilon = 1e-9
    fit_metric = item / (valid_bins_remain_cap + epsilon)

    # The sigmoid function `sigmoid(x) = 1 / (1 + exp(-x))` increases monotonically.
    # To make our priority score higher for higher `fit_metric` values (tighter fits),
    # we pass `scale_factor * fit_metric` as the argument to sigmoid.
    # The `scale_factor` is a hyperparameter that controls the sensitivity of the priority to the fit metric.
    # A larger `scale_factor` means that smaller differences in `fit_metric` will result in larger differences in priority.
    scale_factor = 3.0  # This value can be tuned.

    # Calculate the sigmoid score for the valid bins.
    # The scores will naturally fall between 0 and 1.
    # Higher fit_metric values result in scores closer to 1.
    sigmoid_scores = 1.0 / (1.0 + np.exp(-(scale_factor * fit_metric)))

    # Assign these calculated scores to the corresponding bins.
    priorities[can_fit_indices] = sigmoid_scores

    return priorities
```
