[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that can accommodate the item and\n    leave the *least* amount of remaining capacity. This means we are looking\n    for bins where `bins_remain_cap - item` is minimized (but non-negative).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a priority of negative infinity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)  # Initialize with a very low priority\n\n    # Calculate the remaining capacity if the item is placed in each bin\n    potential_remaining_cap = bins_remain_cap - item\n\n    # Identify bins that can accommodate the item (remaining capacity is non-negative)\n    can_fit_mask = potential_remaining_cap >= 0\n\n    # For bins that can fit the item, assign a priority score.\n    # The Best Fit strategy prioritizes bins that have the *least* remaining capacity\n    # after placing the item. This means we want to maximize the *negative* of the\n    # remaining capacity (or minimize the remaining capacity itself).\n    # To make it a \"higher is better\" score, we can use the negative of the remaining\n    # capacity, or a large constant minus the remaining capacity.\n    # We want to prioritize smaller `potential_remaining_cap`.\n    # A simple way to do this for a \"higher is better\" score is to use a large\n    # value minus the `potential_remaining_cap`.\n    if np.any(can_fit_mask):\n        # Calculate a score that is higher for smaller remaining capacities.\n        # The 'priority' is the negative of the remaining capacity.\n        # So, a bin with remaining capacity 1 will have priority -1,\n        # and a bin with remaining capacity 5 will have priority -5.\n        # -1 is higher than -5.\n        priorities[can_fit_mask] = -potential_remaining_cap[can_fit_mask]\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 31.699250014423125,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy.\n\n    The Best Fit strategy aims to place the item into the bin that leaves the least\n    remaining capacity after placement. This heuristic prioritizes bins that are\n    \"almost full\" with the current item, aiming to minimize wasted space within each bin\n    and thus potentially reduce the total number of bins used. Bins that cannot fit\n    the item are given a priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher priority means the bin is more suitable according to the Best Fit strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after fitting\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priority. Higher priority for bins that result in the smallest remaining capacity.\n    # We can invert the remaining capacity to make smaller remaining capacity higher priority.\n    # A small epsilon is added to prevent division by zero if remaining_after_fit is exactly 0.\n    # Using a large number for a perfect fit (remaining_after_fit == 0) can be beneficial.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_fit + 1e-9)\n\n    return priorities",
    "response_id": 1,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority using a sigmoid-based function that favors bins with small positive residuals.\n\n    This heuristic prioritizes bins where the remaining capacity (`r`) after placing the item\n    is as close to zero as possible, but still non-negative. The sigmoid function\n    `1 / (1 + exp(k * r))` is used, where `k` is a sensitivity parameter.\n    A higher `k` makes the priority drop faster as `r` increases.\n    Bins where the item does not fit (i.e., `r < 0`) receive a priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Sensitivity parameter for the sigmoid function.\n    # A higher k means a sharper drop in priority as the remaining capacity increases.\n    # This value can be tuned based on experimental results.\n    k = 5.0  \n\n    # Initialize priorities to 0. Bins where the item cannot fit will keep this score.\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate the remaining capacity if the item were placed in each bin.\n    residuals = bins_remain_cap - item\n\n    # Identify bins where the item can fit (residual >= 0).\n    can_fit_mask = residuals >= 0\n\n    # For bins that can fit the item, calculate the priority score using the sigmoid function.\n    # The function 1 / (1 + exp(k * residual)) produces scores between 0 and 1.\n    # - When residual is 0 (perfect fit), score is 1 / (1 + exp(0)) = 0.5.\n    # - When residual is small positive (e.g., 0.01, k=5), arg is 0.05, score is ~0.95 (HIGH priority).\n    # - When residual is large positive (e.g., 1.0, k=5), arg is 5.0, score is ~0.0067 (LOW priority).\n    # This correctly prioritizes bins with the smallest positive residuals.\n    if np.any(can_fit_mask):\n        priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(k * residuals[can_fit_mask]))\n\n    return priorities",
    "response_id": 2,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 2.0,
    "halstead": 57.110323830864054,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a sigmoid-based Best Fit score.\n\n    This heuristic prioritizes bins that have the smallest remaining capacity while still being able to accommodate the item.\n    This is the \"Best Fit\" strategy. The sigmoid function is used to translate this preference into a smooth priority score.\n\n    Specifically, for bins where `bins_remain_cap >= item`:\n    - Bins with `bins_remain_cap` closest to `item` (i.e., smallest positive gap) receive the highest scores.\n    - Bins with `bins_remain_cap` much larger than `item` receive lower scores.\n    - Bins where `bins_remain_cap < item` receive a score of 0, as they cannot fit the item.\n\n    The priority score is calculated as:\n    `score = sigmoid(scale_factor * (item / (bins_remain_cap + epsilon)))`\n    for valid bins. A higher `item / bins_remain_cap` ratio implies a tighter fit (smaller remaining capacity relative to the item size).\n    The sigmoid function then maps these ratios to a priority score between 0 and 1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Define a small epsilon to avoid division by zero and to handle perfect fits gracefully.\n    epsilon = 1e-6\n    \n    # Scale factor to control the steepness of the sigmoid.\n    # A higher value makes the priority more sensitive to small differences in remaining capacity.\n    # Tune this value based on empirical performance.\n    scale_factor = 3.0 \n\n    # Identify bins that have enough remaining capacity to fit the item.\n    valid_indices = np.where(bins_remain_cap >= item)[0]\n\n    if len(valid_indices) > 0:\n        valid_capacities = bins_remain_cap[valid_indices]\n\n        # Calculate a \"fit metric\": the ratio of item size to remaining capacity.\n        # A higher ratio indicates a tighter fit (smaller remaining capacity relative to the item).\n        # This metric is a proxy for how \"good\" a bin is according to the Best Fit strategy.\n        fit_metric = item / (valid_capacities + epsilon)\n\n        # Apply the sigmoid function to the scaled fit metric.\n        # sigmoid(x) = 1 / (1 + exp(-x))\n        # - If fit_metric is high (tight fit), scale_factor * fit_metric is large.\n        #   exp(-(large positive)) is close to 0, so sigmoid is close to 1.\n        # - If fit_metric is low (loose fit), scale_factor * fit_metric is smaller.\n        #   exp(-(smaller positive)) is larger, so sigmoid is closer to 0.5.\n        # This assigns higher priority to bins with tighter fits.\n        priorities[valid_indices] = 1.0 / (1.0 + np.exp(-(scale_factor * fit_metric)))\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 97.70233280920246,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit Sigmoid Score.\n\n    This heuristic prioritizes bins that are the \"tightest fit\" for the item.\n    A tight fit means the bin's remaining capacity is as close as possible to the item's size,\n    but still large enough to contain it. This is the essence of the \"Best Fit\" strategy.\n    The sigmoid function is used to provide a smooth priority score between 0 and 1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to zero. Bins that cannot fit the item will retain a score of 0.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can actually fit.\n    can_fit_indices = np.where(bins_remain_cap >= item)[0]\n\n    # If no bins can fit the item, return all zeros.\n    if len(can_fit_indices) == 0:\n        return priorities\n\n    # Get the remaining capacities of the bins that can fit the item.\n    valid_bins_remain_cap = bins_remain_cap[can_fit_indices]\n\n    # To implement \"Best Fit\" using a sigmoid, we want to prioritize bins where\n    # `bins_remain_cap` is small (but still >= `item`).\n    # This means the \"gap\" (`bins_remain_cap - item`) should be minimized.\n\n    # A good metric for \"tightness\" that works well with sigmoid is the ratio of item size\n    # to the remaining capacity. For a tight fit, this ratio `item / bins_remain_cap` will be close to 1.\n    # Bins with a higher ratio are considered better fits.\n    # We use `item / (valid_bins_remain_cap + epsilon)` to avoid division by zero and handle perfect fits gracefully.\n    # A small epsilon is added to the denominator for numerical stability.\n    epsilon = 1e-9\n    fit_metric = item / (valid_bins_remain_cap + epsilon)\n\n    # The sigmoid function `sigmoid(x) = 1 / (1 + exp(-x))` increases monotonically.\n    # To make our priority score higher for higher `fit_metric` values (tighter fits),\n    # we pass `scale_factor * fit_metric` as the argument to sigmoid.\n    # The `scale_factor` is a hyperparameter that controls the sensitivity of the priority to the fit metric.\n    # A larger `scale_factor` means that smaller differences in `fit_metric` will result in larger differences in priority.\n    scale_factor = 3.0  # This value can be tuned.\n\n    # Calculate the sigmoid score for the valid bins.\n    # The scores will naturally fall between 0 and 1.\n    # Higher fit_metric values result in scores closer to 1.\n    sigmoid_scores = 1.0 / (1.0 + np.exp(-(scale_factor * fit_metric)))\n\n    # Assign these calculated scores to the corresponding bins.\n    priorities[can_fit_indices] = sigmoid_scores\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 97.70233280920246,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a hybrid approach:\n    Exact Fit First, then Best Fit, and finally First Fit for remaining capacity.\n\n    This strategy aims to find the most suitable bin for the item.\n    1. Exact Fit: Prioritize bins where the item fits exactly (remaining capacity == item size).\n    2. Best Fit: If no exact fit, prioritize bins that can accommodate the item and minimize the remaining capacity after placement.\n    3. First Fit (implicit): If multiple bins offer the same \"best fit\" or no exact fit exists, it will implicitly select the first one encountered due to how numpy indexing works if no further tie-breaking is applied. However, to make it more deterministic and to favor bins that have *some* remaining capacity but still fit, we'll assign a score based on the *amount* of remaining capacity that is *still greater than the item*.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item fits exactly\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n\n    if len(exact_fit_indices) > 0:\n        # Assign a very high priority to exact fits.\n        # We can add the index in descending order to prefer earlier bins if multiple exact fits exist,\n        # though for exact fits, it doesn't practically matter which exact fit is chosen first.\n        # Using a large base value to clearly distinguish from other strategies.\n        priorities[exact_fit_indices] = 1e6 + (len(bins_remain_cap) - 1 - exact_fit_indices)\n    else:\n        # Identify bins where the item can fit (remaining capacity >= item size)\n        can_fit_mask = bins_remain_cap >= item\n        can_fit_indices = np.where(can_fit_mask)[0]\n\n        if len(can_fit_indices) > 0:\n            # For bins that can fit, calculate the \"waste\" or remaining capacity after placement.\n            # We want to minimize this waste (i.e., find the best fit).\n            # The score should be higher for bins with less waste.\n            # So, we can use a large value minus the waste.\n            residual_capacities = bins_remain_cap[can_fit_mask] - item\n\n            # Assign priorities: Higher score for smaller residual capacity.\n            # Using a large base value to distinguish from exact fits.\n            # The score is inversely proportional to residual_capacity, plus a term\n            # to break ties (e.g., prefer bins with more total capacity if residual is the same, or just index).\n            # A simple way is to use a large number minus the residual capacity.\n            # Add a small epsilon to residual_capacities before inverse to avoid division by zero if not already handled,\n            # but here we are doing subtraction.\n            \n            # The priority should be higher for smaller residuals.\n            # Score = BaseValue - ResidualCapacity\n            # This naturally prioritizes bins that leave less empty space.\n            priorities[can_fit_indices] = 1e5 - residual_capacities\n\n        # If no bins can fit, priorities remain 0, which is correct.\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 114.6940428629768,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic implements a \"Best Fit\" strategy by prioritizing bins that\n    will have the *minimal remaining capacity* after placing the item.\n    This aims to leave larger contiguous spaces in other bins for potentially\n    larger future items.\n\n    The priority is calculated as the inverse of the remaining capacity\n    after placing the item, plus a small epsilon to avoid division by zero.\n    A smaller remaining capacity after fitting results in a higher priority score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        # Calculate the remaining capacity after placing the item in fitting bins\n        remaining_capacity_after_fit = bins_remain_cap[can_fit_mask] - item\n\n        # Prioritize bins that leave the *least* remaining capacity.\n        # We use the inverse of this remaining capacity as the priority.\n        # Add a small epsilon to avoid division by zero for perfect fits.\n        epsilon = 1e-6\n        priorities[can_fit_mask] = 1.0 / (remaining_capacity_after_fit + epsilon)\n    \n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Sigmoid-based Best Fit strategy.\n\n    This strategy prioritizes bins that are \"almost full\" by assigning higher\n    priority scores to bins with a higher fill ratio (item size / remaining capacity),\n    capped by the remaining capacity of the bin. A sigmoid function is used to\n    smoothly transition these scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mask for bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate fill ratio for bins that can fit the item.\n    # Fill ratio is item_size / bin_capacity. Since we don't have bin_capacity,\n    # we use bins_remain_cap to imply how \"full\" the bin is relative to the item.\n    # A higher fill ratio (item_size / bins_remain_cap) means bins_remain_cap is smaller relative to item_size.\n    # This implies the bin is \"closer\" to being full with this item.\n    # We want to prioritize bins where `item / bins_remain_cap` is high.\n\n    # Handle item size of 0: A zero item can fit anywhere and doesn't fill anything.\n    # We assign a neutral priority score (e.g., 0.5 via sigmoid(0)) to any bin it fits in.\n    if item == 0:\n        # If item is 0, it fits in all bins.\n        # The fill ratio is effectively 0. Sigmoid(k*0) = 0.5.\n        priorities[can_fit_mask] = 0.5\n        return priorities\n\n    # For item size > 0\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # To avoid division by zero and ensure ratios are meaningful, we only consider bins with positive capacity.\n    # `can_fit_mask` already ensures `bins_remain_cap >= item`.\n    # If `item > 0`, then `fitting_bins_remain_cap` will be strictly positive.\n    \n    # Calculate fill ratio: item_size / remaining_capacity.\n    # A smaller remaining_capacity (for a given item_size) means a higher fill ratio.\n    # We want to prioritize bins with higher fill ratios.\n    fill_ratios = item / fitting_bins_remain_cap\n\n    # The fill_ratios are in the range (0, infinity) if item > 0 and bins_remain_cap can be anything.\n    # However, our `can_fit_mask` ensures `bins_remain_cap >= item`.\n    # So, `fill_ratios` are in the range (0, 1] if `bins_remain_cap >= item > 0`.\n    # Specifically, if `bins_remain_cap == item`, fill_ratio = 1.\n    # If `bins_remain_cap > item`, fill_ratio < 1.\n\n    # Using sigmoid: `sigmoid(x) = 1 / (1 + exp(-x))`.\n    # We want to maximize priority as `fill_ratio` approaches 1.\n    # `sigmoid(k * fill_ratio)` will have higher values for higher `fill_ratio`.\n    # Let `k` be a steepness parameter.\n    k = 15.0 # Tuning parameter for sigmoid steepness. Adjust for desired behavior.\n\n    # Apply sigmoid to the fill ratios.\n    # Ensure input to exp is within reasonable bounds to avoid overflow.\n    # Since fill_ratios are <= 1 and k is moderate, `k * fill_ratios` should be fine.\n    sigmoid_input = k * fill_ratios\n    \n    # Calculate priorities for bins that can fit the item.\n    # Scores will be in the range (0.5, ~1) because fill_ratios are >= 0.\n    # Specifically, if fill_ratio is 0 (e.g., item=0, handled above) -> 0.5\n    # If fill_ratio = 1 -> sigmoid(k) ~ 1.\n    # If fill_ratio < 1 -> sigmoid(k * fill_ratio) < sigmoid(k).\n    priorities[can_fit_mask] = 1 / (1 + np.exp(-sigmoid_input))\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 80.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that have the smallest remaining capacity\n    that can still accommodate the item. This aims to fill bins as tightly as possible,\n    minimizing wasted space in the selected bin. The priority is calculated as\n    the negative of the remaining capacity after the item is placed.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the item\n        will have a priority of negative infinity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)  # Initialize with a very low priority\n\n    # Calculate priority for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit, the priority is the negative of the remaining capacity\n    # after placing the item. This means a smaller remaining capacity (more negative)\n    # results in a higher (less negative) priority score.\n    priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 30.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Minimum Remaining Capacity Fit strategy.\n\n    The Minimum Remaining Capacity Fit strategy aims to place the item into the bin\n    that will have the least remaining capacity after the item is placed. This means\n    prioritizing bins where the remaining capacity is just enough or slightly more\n    than the item size. This aims to \"fill up\" bins more effectively.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very small negative number.\n    # Bins that cannot accommodate the item will have the lowest priority.\n    priorities = np.full_like(bins_remain_cap, -float('inf'))\n\n    # Identify bins that can accommodate the current item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, the priority is determined by how much\n    # capacity will be left after placing the item.\n    # We want to minimize the remaining capacity, so higher priority should be given\n    # to bins where `bins_remain_cap - item` is smaller.\n    # A common way to achieve this is to use the inverse of the remaining capacity\n    # after placing the item. To avoid division by zero and to give higher priority\n    # to smaller positive remaining capacities, we can use `1 / (remaining_capacity + epsilon)`.\n    # This ensures that bins with the smallest positive `bins_remain_cap - item` get the highest priority.\n\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # Add a small epsilon to avoid division by zero, especially if remaining_after_fit is 0.\n    epsilon = 1e-9\n    priorities[can_fit_mask] = 1.0 / (remaining_after_fit + epsilon)\n\n    return priorities",
    "response_id": 9,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 51.80615605397529,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that can accommodate the item and\n    then selects the bin that leaves the minimum remaining capacity after packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on minimizing the leftover capacity (bins_remain_cap - item),\n        favoring tighter fits.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, assign a priority score.\n    # We want to prioritize bins where the remaining capacity *after* packing\n    # (bins_remain_cap[i] - item) is minimized.\n    # This means smaller (bins_remain_cap[i] - item) values get higher priorities.\n    # We can achieve this by calculating -(bins_remain_cap[i] - item) or\n    # equivalent (item - bins_remain_cap[i]).\n    # To ensure these priorities are generally higher than -1, we can add a\n    # constant offset. A good offset is related to the maximum possible\n    # remaining capacity to ensure scores are positive for fitting bins.\n    # Let's use max(bins_remain_cap) as a reference for the offset.\n\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n\n    if fitting_bins_capacities.size > 0:\n        # Calculate leftover capacity for fitting bins\n        leftover_capacities = fitting_bins_capacities - item\n\n        # We want to minimize leftover_capacities.\n        # A score where higher means better priority can be:\n        # (max_possible_leftover - current_leftover) or\n        # -(current_leftover) + large_constant\n        # Let's use a large_constant that ensures positivity and rank preservation.\n        # A simple approach is to use max_leftover as the basis.\n        max_leftover = np.max(leftover_capacities)\n        \n        # The priority is designed such that smaller 'leftover_capacities' yield higher scores.\n        # So, max_leftover - leftover_capacities works.\n        # If max_leftover is 0 (perfect fit), priority is 0. If leftover is max, priority is 0.\n        # Let's use a safer constant like max(bins_remain_cap) to avoid zero priorities.\n        # Using max_leftover + small_epsilon would be better for relative order.\n        # Or, simply, item - bins_remain_cap[i] will be maximized when bins_remain_cap[i] is minimized.\n        # Let's use `bins_remain_cap[i] - item` and minimize it.\n        # To get a score where higher is better: `C - (bins_remain_cap[i] - item)`\n        # Let C be `np.max(bins_remain_cap)` for a reasonable scale.\n        \n        # A more direct approach for Best Fit: we want to minimize `bins_remain_cap[i] - item`.\n        # So, priority should be inversely related to `bins_remain_cap[i] - item`.\n        # `priority = K - (bins_remain_cap[i] - item)` where K is a constant.\n        # A suitable K would be `np.max(bins_remain_cap)` or `np.max(bins_remain_cap) + item`.\n        # Let's use `np.max(bins_remain_cap)` for simplicity as the additive term.\n        \n        # Calculate priority for fitting bins: maximize `bins_remain_cap[i] - item` is wrong.\n        # Minimize `bins_remain_cap[i] - item`.\n        # So, we want `-(bins_remain_cap[i] - item)` to be as large as possible.\n        # `item - bins_remain_cap[i]` maximized.\n        # Let's use `np.max(bins_remain_cap)` as a base value, and then subtract the difference.\n        # This ensures smaller leftover is better.\n        \n        # The score should be `score = C - (bins_remain_cap[i] - item)`\n        # Let C be `np.max(bins_remain_cap)` to make it scale positively.\n        # If all bins have capacity 10 and item is 8, leftover is 2.\n        # Bins: [10, 10, 10]. Item: 8.\n        # leftover = [2, 2, 2]. We want them all equal priority.\n        # C = 10. Scores = 10 - 2 = 8.\n        \n        # If bins_remain_cap = [5, 3, 7], item = 2.\n        # C = 7.\n        # Bin 0 (rem=5): score = 7 - (5-2) = 7 - 3 = 4\n        # Bin 1 (rem=3): score = 7 - (3-2) = 7 - 1 = 6\n        # Bin 2 (rem=7): score = 7 - (7-2) = 7 - 5 = 2\n        \n        # This works.\n        \n        max_current_cap = np.max(bins_remain_cap) # Use the actual max remaining cap as a stable reference\n        priorities[can_fit_mask] = max_current_cap - (fitting_bins_capacities - item)\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 60.94436251225966,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, favoring tighter fits.\n\n    This strategy prioritizes bins that can accommodate the item and, among those,\n    favors bins that will have the smallest remaining capacity after packing.\n    This encourages \"tighter\" fits, potentially leading to better packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        inversely proportional to their remaining capacity after packing,\n        strongly favoring minimal remainders.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n    epsilon = 1e-9  # A small value to prevent division by zero and ensure positive priorities for fitting bins\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the residual capacity after packing\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    if fitting_bins_capacities.size > 0:\n        # Calculate the residual capacity for each fitting bin\n        residuals = fitting_bins_capacities - item\n\n        # Assign priorities inversely proportional to the residual capacity.\n        # Smaller residuals get higher scores.\n        # Add epsilon to avoid division by zero and ensure non-negative scores.\n        priorities[can_fit_mask] = 1.0 / (residuals + epsilon)\n\n    return priorities",
    "response_id": 1,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a modified First Fit strategy.\n\n    This version aims to prioritize bins that, after packing the item,\n    will have the *least* remaining capacity. This is a common heuristic\n    for minimizing wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on the *resulting* remaining capacity after packing, favoring\n        bins with the smallest resulting capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity *after* packing\n    if np.any(can_fit_mask):\n        resulting_remain_cap = bins_remain_cap[can_fit_mask] - item\n\n        # We want to prioritize bins with the *least* resulting remaining capacity.\n        # This means a smaller `resulting_remain_cap` should have a higher priority.\n        # We can achieve this by using a transformation that maps smaller values\n        # to larger scores. A simple way is to use a large constant minus the\n        # resulting remaining capacity. This ensures that bins with very little\n        # space left after packing get the highest scores.\n        # We need a reference value that is guaranteed to be larger than any\n        # possible `resulting_remain_cap`. The maximum initial bin capacity plus\n        # the item size is a safe upper bound for the original capacity, so\n        # `max(bins_remain_cap) + item` is a safe upper bound for the original\n        # capacity, and thus `max(bins_remain_cap)` is a safe upper bound for\n        # `resulting_remain_cap`. Let's use `max(bins_remain_cap)` to scale.\n        # A more robust large number could be used, but this is generally sufficient.\n        # A very large constant ensures that these prioritized bins have scores\n        # significantly higher than the default -1.\n        large_constant = 1e9\n        priorities[can_fit_mask] = large_constant - resulting_remain_cap\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 34.86917501586544,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that can accommodate the item and\n    then selects the bin that results in the smallest remaining capacity after\n    packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on the *remaining capacity after packing*, favoring smaller\n        remaining capacities.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Calculate remaining capacity if the item fits in each bin\n    potential_remaining_caps = bins_remain_cap - item\n\n    # Identify bins that can fit the item\n    can_fit_mask = potential_remaining_caps >= 0\n\n    # For bins that can fit the item, assign a priority score.\n    # We want to prioritize bins that will have the *smallest* remaining capacity\n    # after packing the item. So, we use the potential_remaining_caps directly,\n    # and we want to maximize this value (since higher score means higher priority).\n    # A larger remaining capacity after packing is *worse* for Best Fit,\n    # so we want to prioritize smaller values of potential_remaining_caps.\n    # To make higher scores better, we can invert the priority, e.g., by\n    # subtracting from a large constant.\n    fitting_bins_potential_remaining = potential_remaining_caps[can_fit_mask]\n\n    if fitting_bins_potential_remaining.size > 0:\n        # To prioritize smaller remaining capacities (Best Fit), we can use\n        # a large number minus the potential remaining capacity.\n        # This way, a smaller potential remaining capacity results in a higher score.\n        # We use a value larger than any possible potential remaining capacity.\n        # The maximum possible original remaining capacity would be the bin capacity itself,\n        # so a value larger than that plus item size is safe.\n        max_original_cap = np.max(bins_remain_cap) if bins_remain_cap.size > 0 else 0\n        large_constant = max_original_cap + item # Ensure it's larger than any possible remaining capacity\n\n        priorities[can_fit_mask] = large_constant - fitting_bins_potential_remaining\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 76.14709844115208,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a strategy\n    that prioritizes bins with minimal remaining capacity after packing (tighter fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on their remaining capacity after packing, favoring those that\n        leave minimal remaining capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity *after* packing the item\n    remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n\n    # We want to prioritize bins where remaining_after_packing is minimal (tighter fit).\n    # A simple way to achieve this is to sort by remaining_after_packing in ascending order.\n    # The priority score should be higher for smaller remaining capacities.\n    # We can achieve this by taking the negative of the remaining capacity\n    # and potentially shifting it to ensure it's higher than the default -1.\n    if remaining_after_packing.size > 0:\n        # Prioritize by minimal remaining capacity after packing.\n        # A larger score for smaller remaining capacity.\n        # Using the negative of remaining capacity: smaller remaining_after_packing -> less negative score.\n        # Adding a large constant to ensure positive scores and distinguish from non-fitting bins.\n        # The constant should be larger than any possible negative score.\n        # A safe bet is to use a value that's larger than the maximum possible\n        # negative remaining capacity, which is related to the bin size.\n        # Let's use a simple approach: a large multiplier for inverse proportion.\n        # Or even simpler, just the negative of the remaining capacity,\n        # and ensure it's greater than -1 by adding a sufficiently large value.\n        # Example: if remaining is 0.1, score is -0.1. If remaining is 0.01, score is -0.01. -0.01 > -0.1.\n        # To make it clearly higher than -1, we can add a large value.\n        # The maximum possible remaining capacity would be if we pack an item into a full bin.\n        # So, remaining_after_packing will be between 0 and (max_bin_cap - min_item_size).\n        # The most negative value it can take is when the bin is almost full and the item is small,\n        # leaving a large remainder. The most positive value is when the bin is just big enough.\n        # We want to prioritize bins with remainder close to 0.\n        # So, we can use `1 / (remaining_after_packing + epsilon)` or `max_val - remaining_after_packing`.\n        # Let's use the latter for simplicity and better control of scale.\n        # A large value for `max_val` ensures higher scores for smaller remainders.\n        # A safe `max_val` could be slightly larger than any possible remaining capacity.\n        # If bins have capacity up to `C`, and items are at least `m`, max remaining is `C-m`.\n        # Let's pick a value that's guaranteed to be larger than any potential remaining capacity.\n        # A value like `1000` or `np.max(bins_remain_cap) + 1` should be sufficient if capacities are not excessively large.\n        # Or, we can simply use the negative of the remaining capacity and add 1 to make it positive if needed.\n        # A simpler approach that maintains relative order and ensures higher priority for smaller remainders:\n        # Prioritize by `-(remaining_after_packing)`. For remaining=0.1, score=-0.1. For remaining=0.01, score=-0.01.\n        # We need these scores to be greater than -1.\n        # So, let's use `-(remaining_after_packing) + offset`. The offset needs to be large enough.\n        # A simple monotonic transformation: `1.0 / (remaining_after_packing + 1e-9)` would also work,\n        # prioritizing smaller positive values.\n        # Let's go with `max_possible_remaining - remaining_after_packing` for clarity.\n        # Max possible remaining capacity is max_initial_capacity - min_item_size.\n        # A simple approach is to take the negative of the remaining capacity.\n        # Bins with smaller remaining capacity will have scores closer to zero (less negative).\n        # We want these scores to be greater than -1.\n        # So, we can add a constant that ensures this.\n        # A simple proportional inverse relationship: a large constant minus the remaining capacity.\n        # This prioritizes smaller remaining capacities with higher scores.\n        # Let's use `max_initial_capacity - item` as a reference for a maximally \"bad\" fit.\n        # This logic seems to align with First Fit Decreasing's intuition of filling up bins efficiently.\n        # The goal is to have `remaining_after_packing` be as close to 0 as possible.\n        # So, `max_val - remaining_after_packing` prioritizes smaller `remaining_after_packing`.\n        # We can set `max_val` to a value larger than any possible `remaining_after_packing`.\n        # Example: if bins_remain_cap are [10, 5, 8] and item is 3.\n        # Fits: [10, 5, 8]. Remaining after packing: [7, 2, 5].\n        # We want to prioritize the bin with remaining capacity 2.\n        # Scores: Bin1: 10-3=7. Bin2: 5-3=2. Bin3: 8-3=5.\n        # The bin with remaining capacity 2 gets score 2. This is not higher priority.\n        # We want higher priority for smaller remaining capacity.\n        # So, the score should be inversely related to remaining capacity.\n        # Option 1: Use negative of remaining capacity.\n        # Remaining: [7, 2, 5]. Scores: [-7, -2, -5]. Highest is -2, which is correct.\n        # We need to ensure these are > -1. So add an offset.\n        # offset = 10 (or any value > 7). Scores: [3, 8, 5]. Highest is 8.\n        # Option 2: Use 1 / (remaining_capacity + epsilon)\n        # Remaining: [7, 2, 5]. Scores: [1/7, 1/2, 1/5]. Highest is 1/2, which is correct.\n        # Option 3: Use max_possible_value - remaining_capacity.\n        # max_possible_remaining could be considered the capacity of the largest bin minus the smallest item.\n        # Let's consider a large number for simplicity, like 1000, assuming bin capacities are reasonable.\n        # Remaining: [7, 2, 5]. Scores: [1000-7, 1000-2, 1000-5] = [993, 998, 995]. Highest is 998.\n        # This is equivalent to prioritizing smaller remaining capacities.\n        # The reflection mentions \"adjusting sensitivity to residual size\". This implies that the *difference*\n        # matters. The `max_val - remaining` approach reflects this directly.\n\n        # Let's use `max_val - remaining_after_packing`.\n        # A safe `max_val` could be related to the maximum bin capacity, ensuring it's larger than any possible remaining capacity.\n        # If we don't know the max capacity, a large constant is fine. Let's assume a typical range of capacities.\n        # Or, we can use the maximum *initial* remaining capacity as `max_val`.\n        # max_initial_remaining = np.max(bins_remain_cap[can_fit_mask])\n        # However, this can lead to values close to zero for the best fit.\n        # Let's stick to a fixed large offset for clear separation from -1.\n        # The negative of remaining capacity is directly proportional to how full the bin becomes.\n        # We want to maximize \"fullness\".\n        # Let's use `-remaining_after_packing`. To make it greater than -1, add a buffer.\n        # The minimum remaining capacity is 0, so the maximum negative score is 0.\n        # The maximum remaining capacity can be `max(bins_remain_cap) - min(item_sizes)`.\n        # So, the scores will range from -(max_initial_capacity) to 0.\n        # Adding a buffer ensures we are above -1.\n        # A buffer of 1 makes the range [0, max_initial_capacity - 1].\n        # This means smaller remaining capacities have higher (less negative) scores.\n        priorities[can_fit_mask] = -remaining_after_packing\n\n    # Now, ensure all fitting bins have a priority higher than non-fitting bins (-1).\n    # If any fitting bin has a score <= -1 (e.g., remaining_after_packing is very large, making -remaining_after_packing <= -1),\n    # we should adjust. However, remaining_after_packing will always be >= 0.\n    # So, -remaining_after_packing will always be <= 0.\n    # If we want strictly higher than -1, we can add a small epsilon or a constant.\n    # A simple way to prioritize smaller remaining capacities:\n    # Directly use `-remaining_after_packing`. The highest value here corresponds to the smallest `remaining_after_packing`.\n    # To ensure these are clearly higher than -1, we can add a value.\n    # Let's assign `1.0 / (remaining_after_packing + epsilon)` for a direct inverse relationship.\n    # Or, a large number minus the remaining capacity.\n    # `large_number - remaining_after_packing` -> prioritizing smaller `remaining_after_packing`.\n    # A suitable large number could be `np.max(bins_remain_cap) + 1`.\n    # Let's use a simpler form that still prioritizes smaller remainders:\n    # `1 / (remaining_after_packing + 1e-9)`\n    # This assigns a large score to small remainders and smaller scores to large remainders.\n    # And ensures these are positive, hence > -1.\n    epsilon = 1e-9\n    priorities[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)\n\n    return priorities",
    "response_id": 4,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 74.23092131656186,
    "exec_success": true
  }
]