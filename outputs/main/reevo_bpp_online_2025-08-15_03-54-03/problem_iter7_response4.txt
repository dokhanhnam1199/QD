```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a strategy
    that prioritizes bins with minimal *positive* residual capacity after packing.

    This version aims to find the "tightest" fit by favoring bins that, after
    packing the item, have the least remaining capacity. To differentiate between
    multiple tight fits, it also considers the initial remaining capacity of the bin;
    bins that were already quite full (less initial remaining capacity) are
    slightly preferred if they result in a similar final small residual capacity.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        A higher score indicates a higher priority. Bins that cannot fit the
        item are given a score of -1. Bins that can fit are scored based on
        minimizing residual capacity, with a tie-breaker favouring bins that
        were initially less capacious (more full).
    """
    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # For bins that can fit the item, calculate the remaining capacity *after* packing
    fitting_bins_indices = np.where(can_fit_mask)[0]

    if fitting_bins_indices.size > 0:
        fitting_bins_capacities = bins_remain_cap[fitting_bins_indices]
        resulting_remain_cap = fitting_bins_capacities - item

        # Strategy: Prioritize bins with minimal *positive* residual capacity.
        # This means we want to minimize `resulting_remain_cap`.
        # To convert minimization to maximization for priority score, we can use
        # a large constant minus the value, or the inverse.
        # Using the inverse `1 / (resulting_remain_cap + epsilon)` gives higher scores
        # for smaller `resulting_remain_cap`.

        # Tie-breaker: If multiple bins have very similar `resulting_remain_cap`,
        # prefer the one that was initially less capacious (meaning it was more full).
        # This can be achieved by adding a term that is inversely proportional to
        # the initial `fitting_bins_capacities` or directly using it.
        # If we want to prefer smaller initial capacity, we can subtract it.
        # `priority = 1 / (resulting_remain_cap + epsilon) - fitting_bins_capacities`
        # This would mean a smaller initial capacity gives a lower (more negative)
        # subtraction, resulting in a higher overall priority.
        # However, we want a positive score. Let's rephrase:
        # Primary score component: inverse of resulting capacity (higher is better)
        # Secondary score component: inverse of initial capacity (higher is better, if we want to favor nearly full bins, which is not the case here).
        # If we want to favor bins that were *already fuller*, we want to prefer bins with *smaller* `fitting_bins_capacities`.
        # So, a simple score could be:
        # `score = C - resulting_remain_cap - alpha * fitting_bins_capacities`
        # where C and alpha are constants.
        # A more direct way to prioritize minimal positive residual capacity:
        # use `1 / (resulting_remain_cap + epsilon)` as the primary component.
        # For the tie-breaker, to prefer bins that were initially *less* full (i.e., had *more* capacity),
        # we would add a term proportional to `fitting_bins_capacities`.
        # `priority = 1 / (resulting_remain_cap + epsilon) + alpha * fitting_bins_capacities`
        # This still feels a bit counter to "minimal positive residual capacity" for *tighter* fits.

        # Let's refine the "tightest fit" idea:
        # We want `resulting_remain_cap` to be as small as possible.
        # Primary goal: Minimize `resulting_remain_cap`.
        # Secondary goal: Among those with minimal `resulting_remain_cap`, pick the one that was initially "most full" relative to its capacity.
        # Initial fullness relative to capacity is `1 - fitting_bins_capacities / BinCapacity`.
        # But we don't have BinCapacity. We only have `fitting_bins_capacities`.
        # So, let's assume all bins have the same implicit original capacity (e.g., the maximum initial capacity seen or a standard bin size).
        # If we assume a standard bin size `B`, then initial fullness is `(B - fitting_bins_capacities) / B`. Maximizing this means minimizing `fitting_bins_capacities`.

        # Revised Strategy:
        # 1. Prioritize minimal `resulting_remain_cap`. (Higher score for smaller `resulting_remain_cap`)
        # 2. As a tie-breaker, prioritize bins that were initially *less* full (i.e., larger `fitting_bins_capacities`). This seems more aligned with the "minimal *positive* residual capacity" which implies we want to use up space effectively.

        # Let's try:
        # Primary: `1 / (resulting_remain_cap + epsilon)` (high score for small remaining cap)
        # Secondary: `fitting_bins_capacities` (if two bins have same `resulting_remain_cap`, pick the one that started with more space, implying the item took a larger chunk of its current state). This is *not* what we want.

        # The reflection asks for "minimal *positive* residual capacity". This means we want `resulting_remain_cap` to be small.
        # "Prioritize minimal *positive* residual capacity for tighter fits."
        # This means, if a bin has remaining capacity of 0.1, it's a better fit than a bin with remaining capacity of 0.5.
        # So, `1 / (resulting_remain_cap + epsilon)` is a good basis.

        # "Consider relative fullness and smooth, non-linear functions for graduated scores."
        # Relative fullness: Let's consider `item / fitting_bins_capacities`. This measures how much of the *current available space* the item occupies. Higher is better for a tight fit.
        # `priority = item / fitting_bins_capacities`
        # This prioritizes larger items relative to the current bin capacity.
        # If `item=7`, `bin_cap=10`, `resulting=3`. Score = 7/10 = 0.7
        # If `item=7`, `bin_cap=100`, `resulting=93`. Score = 7/100 = 0.07
        # This prioritizes the first case, which is good.
        # But if `item=7`, `bin_cap=8`, `resulting=1`. Score = 7/8 = 0.875. This is even better.
        # This directly aligns with minimizing `resulting_remain_cap` as well.

        # Let's combine minimizing `resulting_remain_cap` and maximizing `item / fitting_bins_capacities`.
        # If `resulting_remain_cap` is minimal, `item / fitting_bins_capacities` is maximal. They are inversely related for a fixed item.
        # So, `item / fitting_bins_capacities` seems like a good candidate.
        # However, we want a graduated score that doesn't just depend on this ratio.
        # Let's stick to prioritizing minimal residual capacity as the primary goal.
        # `priority_component_1 = 1 / (resulting_remain_cap + epsilon)`

        # For the "graduated scores" and "relative fullness", let's consider how much "space is left unused" relative to the item size.
        # `unutilized_space = resulting_remain_cap`
        # `priority_component_2 = 1 / (unutilized_space + epsilon)` - this is already covered by component 1.

        # What about relative fullness of the bin *before* packing?
        # `relative_fullness_before = 1 - fitting_bins_capacities / B` (assuming a Bin Capacity B)
        # Or, relative to its current capacity: `item / fitting_bins_capacities`
        # This measure `item / fitting_bins_capacities` is good for identifying items that fill a significant portion of their *current* space.

        # Let's try to blend:
        # Prioritize small `resulting_remain_cap` (good for tightest fit).
        # Also, consider the "efficiency" of the fit: `item / fitting_bins_capacities`.
        # A bin that is almost full (small `fitting_bins_capacities`) and can accommodate the item well (low `resulting_remain_cap`) is ideal.

        # Consider the score as a combination of how small the remaining capacity is, and how much of the bin's current capacity was used.
        # Score = `alpha * (1 / (resulting_remain_cap + epsilon)) + beta * (item / fitting_bins_capacities)`
        # Where `alpha` and `beta` are weights.
        # If we set `alpha=1` and `beta=1`, we are adding these two metrics.
        # This would strongly favor bins with small `resulting_remain_cap`, and among those, favor bins where the item occupied a larger proportion of the current space.

        epsilon = 1e-9
        # Metric 1: Inverse of remaining capacity (prioritizes smallest residual space)
        score_residual = 1.0 / (resulting_remain_cap + epsilon)

        # Metric 2: Proportion of current capacity filled by the item (prioritizes items that take a larger chunk of the bin's current available space)
        score_proportion = item / (fitting_bins_capacities + epsilon)

        # Combine them. We want higher scores for better fits.
        # Both metrics point towards better fits when they are higher.
        # A simple sum or average can be used. Let's try sum for stronger emphasis on both.
        priorities[fitting_bins_indices] = score_residual + score_proportion

    return priorities
```
