[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority using a sigmoid-based function that favors bins with small positive residuals.\n\n    This heuristic prioritizes bins where the remaining capacity (`r`) after placing the item\n    is as close to zero as possible, but still non-negative. The sigmoid function\n    `1 / (1 + exp(k * r))` is used, where `k` is a sensitivity parameter.\n    A higher `k` makes the priority drop faster as `r` increases.\n    Bins where the item does not fit (i.e., `r < 0`) receive a priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Sensitivity parameter for the sigmoid function.\n    # A higher k means a sharper drop in priority as the remaining capacity increases.\n    # This value can be tuned based on experimental results.\n    k = 15.0  # Increased sensitivity\n\n    # Initialize priorities to 0. Bins where the item cannot fit will keep this score.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate the remaining capacity if the item were placed in each bin.\n    residuals = bins_remain_cap - item\n\n    # Identify bins where the item can fit (residual >= 0).\n    can_fit_mask = residuals >= 0\n\n    # For bins that can fit the item, calculate the priority score using the sigmoid function.\n    # The function 1 / (1 + exp(k * residual)) produces scores between 0 and 1.\n    # - When residual is 0 (perfect fit), score is 1 / (1 + exp(0)) = 0.5.\n    # - When residual is small positive (e.g., 0.01, k=15), arg is 0.15, score is ~0.53 (slightly higher priority).\n    # - When residual is large positive (e.g., 1.0, k=15), arg is 15.0, score is ~0.000003 (very low priority).\n    # This correctly prioritizes bins with the smallest positive residuals.\n    if np.any(can_fit_mask):\n        # Apply sigmoid to the residuals. Higher `k` will make the priority drop more sharply\n        # as the residual increases, effectively favoring bins with minimal remaining capacity.\n        priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(k * residuals[can_fit_mask]))\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 57.110323830864054,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority using a strategy that favors bins with small positive residuals (Best Fit).\n\n    This heuristic prioritizes bins where the remaining capacity (`r`) after placing the item\n    is as close to zero as possible, but still non-negative. This is a direct implementation\n    of the Best Fit strategy. Bins where the item does not fit (i.e., `r < 0`) receive a\n    priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher priority indicates a better fit for the item.\n    \"\"\"\n    # Initialize priorities to 0. Bins where the item cannot fit will keep this score.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate the remaining capacity if the item were placed in each bin.\n    residuals = bins_remain_cap - item\n\n    # Identify bins where the item can fit (residual >= 0).\n    can_fit_mask = residuals >= 0\n\n    # For bins that can fit the item, calculate the priority.\n    # The goal is to have the smallest non-negative residual.\n    # We can achieve this by taking the inverse of the residual.\n    # A small epsilon is added to avoid division by zero for bins with exact fits.\n    # A large value for exact fits ensures they are prioritized.\n    if np.any(can_fit_mask):\n        # Using 1 / (residual + epsilon) prioritizes smaller residuals.\n        # An exact fit (residual=0) will get a very high priority (1/epsilon).\n        priorities[can_fit_mask] = 1.0 / (residuals[can_fit_mask] + 1e-9)\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 43.01955000865388,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that can accommodate the item and\n    leave the *least* amount of remaining capacity. This means we are looking\n    for bins where `bins_remain_cap - item` is minimized (but non-negative).\n    This function implements Best Fit by assigning a higher priority to bins\n    that result in a smaller non-negative residual.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a priority of negative infinity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)  # Initialize with a very low priority\n\n    # Calculate the remaining capacity if the item is placed in each bin\n    potential_remaining_cap = bins_remain_cap - item\n\n    # Identify bins that can accommodate the item (remaining capacity is non-negative)\n    can_fit_mask = potential_remaining_cap >= 0\n\n    # For bins that can fit the item, assign a priority score.\n    # The Best Fit strategy prioritizes bins with the smallest non-negative residual.\n    # To achieve this with a \"higher is better\" priority, we want to assign\n    # higher scores to smaller residuals. A simple linear mapping is to\n    # use the negative of the residual.\n    # E.g., if residuals are [0.1, 0.5, 1.0], the priorities will be [-0.1, -0.5, -1.0].\n    # Since -0.1 > -0.5 > -1.0, this correctly prioritizes the bin with the smallest residual.\n    if np.any(can_fit_mask):\n        priorities[can_fit_mask] = -potential_remaining_cap[can_fit_mask]\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 31.699250014423125,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Best Fit strategy,\n    prioritizing minimizing waste.\n\n    This heuristic prioritizes bins that, after placing the item, will have the least\n    remaining capacity. This aims to minimize wasted space within each bin,\n    potentially leading to fewer bins being used overall. Bins that cannot fit\n    the item are assigned a priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher priority indicates a more suitable bin according to the Best Fit strategy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the residual capacity after placement\n    residuals = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priority: higher priority for smaller residuals (tighter fits).\n    # We use a large constant minus the residual. This way, smaller residuals\n    # result in higher priority scores. A perfect fit (residual = 0) gets the\n    # highest score.\n    # Adding 1e-9 to the residual before inversion (as in v1) can lead to very large\n    # scores for near-perfect fits, potentially overshadowing other considerations.\n    # A simple approach is to directly use the negative residual, which means\n    # less negative (closer to zero) is better, or a transformation like\n    # `max_possible_residual - residual`.\n    # Let's use `1 / (residual + epsilon)` for directness, similar to v1, but\n    # conceptually understanding that we want to minimize `residual`.\n    # The key idea is that smaller residuals mean a better fit.\n    # We'll use `1 / (residual + a_small_constant)` to keep it simple and\n    # prioritize smaller residuals. A perfect fit (residual = 0) will yield\n    # the highest priority.\n\n    # A very small epsilon to prevent division by zero if residual is exactly 0.\n    epsilon = 1e-9\n    priorities[can_fit_mask] = 1.0 / (residuals + epsilon)\n\n    return priorities",
    "response_id": 3,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that can accommodate the item and\n    then selects the bin that results in the smallest remaining capacity after\n    packing. This version refines the scoring to more directly reflect the \"best fit\"\n    by minimizing the remaining capacity after placement.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on the *remaining capacity after packing*, favoring smaller\n        remaining capacities. A lower remaining capacity after packing yields a higher score.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with a low priority score\n\n    # Calculate potential remaining capacity if the item fits in each bin\n    potential_remaining_caps = bins_remain_cap - item\n\n    # Identify bins that can accommodate the current item\n    can_fit_mask = potential_remaining_caps >= 0\n\n    # For bins that can fit the item, assign a priority score.\n    # The \"best fit\" is achieved when the remaining capacity after placing the item is minimized.\n    # To translate minimizing remaining capacity into maximizing priority score,\n    # we can use the negative of the potential remaining capacity.\n    # A smaller positive remaining capacity will result in a larger negative number,\n    # thus a higher score when we want to prioritize it.\n    fitting_bins_potential_remaining = potential_remaining_caps[can_fit_mask]\n\n    if fitting_bins_potential_remaining.size > 0:\n        # Assign priorities: -potential_remaining_caps.\n        # This way, a smaller potential_remaining_caps (meaning a better fit)\n        # will result in a larger (less negative) or positive value, hence higher priority.\n        priorities[can_fit_mask] = -fitting_bins_potential_remaining\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 44.97261104228487,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin, favoring tighter fits smoothly.\n\n    This heuristic prioritizes bins that can accommodate the item, and among those,\n    it favors bins that will have the smallest remaining capacity after packing.\n    This is a variation of the \"Best Fit\" strategy, but uses a smooth, graduated\n    priority based on the *gap* between the bin's remaining capacity and the item size.\n\n    Specifically, for bins where `bins_remain_cap >= item`:\n    - The priority is determined by the remaining capacity *after* packing (`bins_remain_cap - item`).\n    - Smaller positive gaps (tighter fits) receive higher priority.\n    - Larger gaps receive lower priority.\n    - Bins that cannot fit the item receive a priority of 0.\n\n    The priority score is calculated as:\n    `score = exp(-scale_factor * (bins_remain_cap - item))`\n    for valid bins. The negative exponential function ensures that as the\n    remaining capacity after packing decreases (i.e., the fit gets tighter),\n    the priority score increases smoothly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Define a small epsilon to avoid issues with near-zero gaps and ensure positive values for exp.\n    epsilon = 1e-9\n    \n    # Scale factor to control the steepness of the exponential decay.\n    # A higher value makes the priority drop off more quickly as the gap increases.\n    # Tune this value based on empirical performance.\n    scale_factor = 1.0\n\n    # Identify bins that have enough remaining capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the residual capacity after packing for bins that can fit the item.\n    fitting_bins_residual_cap = bins_remain_cap[can_fit_mask] - item\n\n    # Assign priorities using a negative exponential function on the residual capacity.\n    # This provides a smooth, graduated priority:\n    # - As residual capacity approaches 0 (tight fit), exp(-scale_factor * 0) = 1 (highest priority).\n    # - As residual capacity increases (loose fit), exp(-scale_factor * large_value) approaches 0 (low priority).\n    # We add epsilon to the residual capacity before exponentiation to avoid exp(0) precisely,\n    # and to ensure that bins with exactly zero residual capacity (perfect fits) get a score of 1.\n    # However, simply using the residual capacity directly is more aligned with the goal.\n    # The exponential function itself handles the smooth decay.\n    priorities[can_fit_mask] = np.exp(-scale_factor * fitting_bins_residual_cap)\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 36.541209043760986,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a strategy\n    that prioritizes bins with minimal remaining capacity after packing (tighter fit).\n\n    This version uses an inverse relationship with the resulting remaining capacity\n    to strongly favor bins that will be almost full after packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on the *resulting* remaining capacity after packing, favoring\n        those that leave minimal remaining capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity *after* packing\n    if np.any(can_fit_mask):\n        resulting_remain_cap = bins_remain_cap[can_fit_mask] - item\n\n        # Prioritize bins with the *least* resulting remaining capacity.\n        # Using `1 / (resulting_remain_cap + epsilon)` creates an inverse relationship,\n        # giving much higher scores to bins with smaller remaining capacities.\n        # An epsilon is added to avoid division by zero if remaining capacity is exactly 0.\n        # This also ensures that scores are positive, thus clearly higher than -1.\n        epsilon = 1e-9\n        priorities[can_fit_mask] = 1.0 / (resulting_remain_cap + epsilon)\n\n    return priorities",
    "response_id": 6,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 50.18947501009619,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined First Fit strategy.\n\n    This strategy prioritizes bins that can accommodate the item and among those,\n    favors bins that are \"more full\" (i.e., have less remaining capacity). This\n    aims to leave larger capacity bins available for potentially larger future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher priority indicates a more suitable bin. Bins that cannot fit\n        the item are given a priority of -1. Bins that can fit are scored\n        based on their remaining capacity, with smaller remaining capacities\n        receiving higher scores.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority for non-fitting bins\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, assign a priority score.\n    # We want to prioritize bins with LESS remaining capacity.\n    # A simple way to achieve this is to assign a score that is the negative\n    # of the remaining capacity. The smaller the remaining capacity, the\n    # less negative (i.e., higher) the score will be.\n    # We add the item size to the remaining capacity calculation to\n    # reflect how \"full\" the bin becomes *after* packing.\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n\n    if fitting_bins_capacities.size > 0:\n        # Calculate the remaining capacity *after* placing the item.\n        # Smaller values here are better.\n        remaining_after_fit = fitting_bins_capacities - item\n\n        # To make smaller remaining capacities have higher priority,\n        # we can use a transformation. A simple one is:\n        # max_possible_capacity - remaining_after_fit.\n        # We use a value slightly larger than any possible remaining capacity\n        # to ensure all fitting bins have positive and distinct priorities\n        # relative to the -1 baseline.\n        # A reasonable upper bound for remaining capacity could be the bin's original capacity.\n        # If we don't know original capacity, a sufficiently large number will do.\n        # Let's use the max of current remaining capacities plus the item size as a proxy for a \"large enough\" value.\n        large_constant = np.max(bins_remain_cap) + item if bins_remain_cap.size > 0 else item\n\n        priorities[can_fit_mask] = large_constant - remaining_after_fit\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 76.14709844115208,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority using First Fit strategy, favoring bins with minimal remaining capacity.\n\n    This heuristic prioritizes bins that can fit the item and among those,\n    prefers bins with the least remaining capacity. This is a direct implementation\n    of the First Fit strategy where the \"priority\" is simply a score that ranks\n    eligible bins by their remaining capacity. Bins that cannot fit the item\n    receive a score of -1, effectively excluding them from selection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority. Bins that can fit the item are\n        scored based on their remaining capacity, with smaller capacities being better.\n        Bins that cannot fit the item have a score of -1.\n    \"\"\"\n    # Initialize priorities to -1, indicating that the item cannot fit or it's the lowest priority.\n    priorities = np.full_like(bins_remain_cap, -1.0)\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, assign a priority score.\n    # We want to prioritize bins with *less* remaining capacity.\n    # A simple way to achieve this is to use the negative of the remaining capacity.\n    # This way, a bin with remaining capacity 'r' gets a score of '-r'.\n    # A smaller 'r' (e.g., 0.1) will result in a higher score (-0.1) than a larger 'r' (e.g., 1.0, score -1.0).\n    # This directly implements the First Fit logic of choosing the first available bin\n    # that can accommodate the item, effectively prioritizing those with less slack.\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    if fitting_bins_capacities.size > 0:\n        priorities[can_fit_mask] = -fitting_bins_capacities\n\n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 31.699250014423125,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority using a strategy that favors bins with minimal positive residuals.\n\n    This heuristic prioritizes bins where the remaining capacity after placing the item\n    is as close to zero as possible, but still non-negative. This aims to fill bins\n    more tightly. Bins where the item does not fit will have the lowest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value, so bins that cannot fit the item\n    # have the lowest priority.\n    priorities = np.full_like(bins_remain_cap, -float('inf'))\n\n    # Calculate the remaining capacity if the item were placed in each bin.\n    residuals = bins_remain_cap - item\n\n    # Identify bins where the item can fit (residual >= 0).\n    can_fit_mask = residuals >= 0\n\n    # For bins that can fit the item, the priority is inversely proportional to the residual.\n    # We want to minimize the residual (residual >= 0), so a smaller residual means higher priority.\n    # Using `1 / (residual + epsilon)` ensures that bins with smaller positive residuals\n    # get higher scores. Adding epsilon avoids division by zero when residual is exactly 0.\n    epsilon = 1e-9\n    priorities[can_fit_mask] = 1.0 / (residuals[can_fit_mask] + epsilon)\n\n    return priorities",
    "response_id": 9,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 53.30296890880645,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a heuristic that prioritizes tighter fits.\n\n    This heuristic aims to find bins where the remaining capacity is just enough\n    to fit the item, or close to it. It penalizes bins with very large remaining\n    capacities and prioritizes bins with smaller remaining capacities that still\n    accommodate the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on their remaining capacity, favoring smaller remaining capacities.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, assign a priority score.\n    # We want to prioritize bins with the smallest sufficient remaining capacity.\n    # A good heuristic is to maximize (remaining_capacity - item) for fitting bins,\n    # or equivalently, minimize (remaining_capacity) for fitting bins.\n    # To make smaller remaining capacities have higher scores, we can use\n    # a transformation that maps smaller values to larger values.\n    # For example, 1 / (remaining_capacity - item + epsilon) or (max_capacity - remaining_capacity).\n    # Let's use a scaled difference approach. Prioritize bins where remaining_capacity is just slightly larger than item.\n    # We can define priority as a value that is high when (bins_remain_cap - item) is small and positive.\n    # A simple approach: (large_constant - (bins_remain_cap - item)) for fitting bins.\n    # This prioritizes bins where (bins_remain_cap - item) is minimal.\n    \n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n\n    if fitting_bins_capacities.size > 0:\n        # Calculate the \"slack\" or excess capacity for fitting bins\n        slack = fitting_bins_capacities - item\n        \n        # We want to prioritize bins with minimal slack.\n        # A common heuristic is to use a value that is inversely related to slack,\n        # or directly related to a transformation that maps small slacks to large priorities.\n        # For example, max_slack - slack.\n        # To ensure scores are distinct and generally higher for better fits,\n        # we can use a large base value and subtract the slack.\n        # Let's use a base value that is larger than any possible slack.\n        # The maximum possible slack is related to the maximum initial bin capacity,\n        # but for simplicity, we can use a large constant or derive one from the input.\n        # A simple inverse relation can be problematic if slack is zero.\n        # Using `max_slack - slack` or `1 / (slack + epsilon)` are options.\n        # Let's try `max_possible_slack - slack` for a graded priority.\n        # A safe \"max_possible_slack\" would be max(bins_remain_cap) - min_item_size if we knew it,\n        # or just a sufficiently large number.\n        # Alternatively, we can simply use a function that is monotonically decreasing with slack.\n        # Example: `1 / (slack + 1e-6)` or `some_large_number - slack`.\n        # Let's use `1 / (slack + epsilon)` for a stronger preference for tighter fits,\n        # scaled by a factor to ensure positive and distinct values.\n        # Using `max(slack) - slack` would give the tightest fit the highest score.\n        \n        # Alternative: prioritize based on remaining capacity directly, inverted.\n        # A simple inverted remaining capacity: some_large_number - remaining_capacity\n        # This also favors smaller remaining capacities.\n        # Let's use `max_remaining_capacity - remaining_capacity` for fitting bins.\n        \n        # Maximize (bin_capacity - item) where bin_capacity >= item.\n        # This means minimizing bin_capacity for fitting bins.\n        # We want higher scores for bins with smaller remaining_capacity.\n        # So, `constant - remaining_capacity` works.\n        # To ensure positive and meaningful scores, we can use:\n        # `1000 - remaining_capacity` or `max(bins_remain_cap) - remaining_capacity`.\n        \n        # Let's refine the idea: We want to prioritize bins where `remaining_capacity` is small,\n        # but still `>= item`. The \"best\" bin has `remaining_capacity` closest to `item`.\n        # So, `remaining_capacity - item` should be minimized.\n        # To map minimal `remaining_capacity - item` to maximal priority:\n        # `constant - (remaining_capacity - item)` or `1 / (remaining_capacity - item + epsilon)`.\n        # Using `max_slack - slack` is quite robust.\n        \n        max_slack_for_fitting = np.max(slack)\n        priorities[can_fit_mask] = max_slack_for_fitting - slack\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 50.18947501009619,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined strategy.\n\n    This strategy prioritizes bins that can accommodate the item. Among those,\n    it favors bins with the smallest remaining capacity (tightest fit).\n    To achieve this, scores are calculated as (bin_capacity - item) for fitting bins,\n    effectively prioritizing bins where the remaining capacity is just enough.\n    A small offset is added to differentiate between bins with the same remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on how tightly they fit the item.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, assign a priority score.\n    # We want to prioritize bins with the *least* remaining capacity that still fit the item.\n    # This is equivalent to finding bins where (remaining_capacity - item) is minimized.\n    # A smaller (remaining_capacity - item) means a tighter fit.\n    # We want higher scores for tighter fits, so we use a large constant minus this difference.\n    # Alternatively, we can simply use the negative of (remaining_capacity - item),\n    # so the smallest positive residual gets the highest (least negative) score.\n    # Let's use a strategy that prioritizes minimal *positive* residual capacity.\n    # A simple way is to use -(remaining_capacity - item) which means the largest\n    # negative residual (closest to 0) gets the highest score.\n    # This implicitly prioritizes bins with smaller remaining capacities.\n\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    if fitting_bins_capacities.size > 0:\n        # Calculate the \"slack\" or remaining capacity after fitting the item\n        slack = fitting_bins_capacities - item\n        # We want to prioritize bins with minimal slack (tightest fit).\n        # So, a smaller slack should result in a higher priority score.\n        # We can achieve this by using a large number minus the slack.\n        # Adding a small epsilon to the slack before negating can help distinguish\n        # between bins with identical remaining capacities.\n        epsilon = 1e-9 # A small value to differentiate\n        priorities[can_fit_mask] = -(slack - epsilon) # Prioritize smaller slack\n\n    return priorities",
    "response_id": 1,
    "obj": 4.11846828879138,
    "cyclomatic_complexity": 2.0,
    "halstead": 59.207035490257475,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version aims to prioritize bins that are \"tighter fits\" by\n    considering the inverse of remaining capacity, but scaled to provide\n    a graduated priority rather than just inverse proportionality. It also\n    considers the relative fullness of the bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n\n        # Strategy: Prioritize bins with minimal remaining capacity (tighter fit).\n        # We can use the difference between the item size and the remaining capacity\n        # as a measure of how \"tight\" the fit is. A smaller positive difference is better.\n        # Or, more directly, use a function of remaining capacity that increases as capacity decreases.\n        #\n        # Let's use a scaled inverse:  1 / (remaining_capacity - item + epsilon)\n        # This prioritizes bins where remaining_capacity is just slightly larger than item.\n        # Adding epsilon to avoid division by zero if remaining_capacity == item.\n        epsilon = 1e-9\n        priorities[can_fit_mask] = 1.0 / (fitting_bins_capacities - item + epsilon)\n\n        # Alternative consideration for relative fullness:\n        # If all bins are nearly empty, any fit might be fine. If bins are nearly full,\n        # a tight fit is crucial.\n        # We can also incorporate the concept of \"how much space is left\" by taking\n        # the difference from a maximum possible remaining capacity (e.g., sum of all items\n        # or a theoretical large capacity).\n        # A more direct approach for \"tightness\" could be:\n        # priorities[can_fit_mask] = np.max(fitting_bins_capacities) - fitting_bins_capacities\n        # This prioritizes bins with the smallest remaining capacity among the fitting ones.\n        #\n        # Let's refine the scaled inverse to be more robust and provide a clearer gradient.\n        # We want smaller remaining capacities to have higher scores.\n        # Let's consider the \"slack\" or \"waste\" space for a perfect fit.\n        # If remaining capacity is R and item is I, the ideal scenario is R = I.\n        # The \"waste\" is R - I. We want to minimize R - I.\n        # So, a score proportional to -(R - I) or 1/(R - I + epsilon) works.\n        #\n        # To make it more distinct from simple First Fit, we can consider\n        # how much *extra* space there is. A bin with R=10 and item=5 gives R-I=5.\n        # A bin with R=12 and item=5 gives R-I=7. We prefer R=10.\n        #\n        # Let's use a transformation that emphasizes smaller positive differences (R - I).\n        # We can use a concave function of (R - I) which gives higher priority to smaller positive differences.\n        # For example, log(slack + 1) or sqrt(slack + 1) would favor smaller slacks.\n        # However, the prompt implies a higher score is better.\n        #\n        # Let's stick to a form that clearly prioritizes minimum remaining capacity among fitting bins,\n        # but with a scaling that gives a more graduated response.\n        # We can use the inverse of (remaining_capacity - item + epsilon) but normalize it.\n        #\n        # Let's go with prioritizing minimum remaining capacity among fitting bins,\n        # as it directly reflects the \"tighter fit\" idea. The previous `priority_v1`\n        # already does this effectively by `max_possible_capacity - fitting_bins_capacities`.\n        #\n        # To introduce \"smoothness\" and \"graduation\", consider mapping the\n        # available slack (remaining_capacity - item) to a priority score.\n        # A higher score for smaller slack.\n        #\n        # Let `slack = fitting_bins_capacities - item`\n        # We want to maximize `f(slack)` where `f` is decreasing.\n        # For example, `f(slack) = 1 / (slack + epsilon)` or `f(slack) = -slack`.\n        #\n        # Let's try a formulation that uses the inverse of the *full* remaining capacity,\n        # but only for fitting bins, then scale it. This implicitly prefers bins\n        # that were less full to begin with if they have a tight fit for the *current* item.\n        #\n        # Consider: priority = 1 / (remaining_capacity + epsilon)\n        # This would favor bins that have less total capacity available, IF they fit the item.\n        # This might not be what we want; we want to prioritize based on how well the *item* fits.\n        #\n        # Revisit: prioritize bins with minimal remaining capacity that are still sufficient.\n        # This is exactly what `priority_v1` with `max_possible_capacity - fitting_bins_capacities` does.\n        #\n        # To introduce \"graduation\" and \"smoothness\" beyond simple inverse proportionality:\n        # We can map the range of `fitting_bins_capacities` to a new range of priorities.\n        # A common approach for graduated priorities is to use a sigmoid-like function\n        # or simply a scaled inverse.\n        #\n        # Let's try `1 / (remaining_capacity - item + epsilon)`. This emphasizes *very* small positive differences.\n        #\n        # We can refine the inverse by shifting and scaling:\n        # `scaled_priority = A * (1 / (fitting_bins_capacities - item + epsilon)) + B`\n        #\n        # A simpler way to achieve graduated priorities for \"tightest fit\" is to\n        # use the negative of the remaining capacity (as in v1), but then perhaps\n        # normalize it within the set of fitting bins, or apply a non-linear transformation.\n        #\n        # Let's try a score that is directly related to the *lack* of excessive space.\n        # For a fitting bin with remaining capacity `R` and item size `I`:\n        # Score = MaxPossibleRemainingCapacity - R\n        # This prioritizes bins with the smallest `R`.\n        #\n        # To make it \"smoother\" or \"graduated\":\n        # We can map `R` to a score such that small `R` values (close to `I`) get\n        # high scores, and `R` values far from `I` get lower scores.\n        #\n        # Let's use the reciprocal of the *waste* space `(R-I)`.\n        # `waste = fitting_bins_capacities - item`\n        # `priorities[can_fit_mask] = 1.0 / (waste + epsilon)`\n        #\n        # This prioritizes bins where `waste` is minimal (i.e., `R` is just slightly larger than `I`).\n        # This is a strong candidate for \"tighter fits\" and provides a graduated priority.\n\n        waste = fitting_bins_capacities - item\n        # Ensure we don't have negative waste (handled by can_fit_mask)\n        # Add epsilon for numerical stability and to give a finite priority\n        # even when waste is exactly zero.\n        priorities[can_fit_mask] = 1.0 / (waste + epsilon)\n\n        # To ensure \"graduation\" and sensitivity adjustment, we could scale this.\n        # For instance, scaling by the average waste or max waste might be useful.\n        # For simplicity, let's stick to the direct reciprocal of waste for now,\n        # as it naturally provides higher values for smaller waste.\n\n        # Consider normalizing:\n        # raw_priorities = 1.0 / (waste + epsilon)\n        # if raw_priorities.size > 0:\n        #     min_p = np.min(raw_priorities)\n        #     max_p = np.max(raw_priorities)\n        #     if max_p - min_p > epsilon:\n        #         priorities[can_fit_mask] = (raw_priorities - min_p) / (max_p - min_p)\n        #     else:\n        #         priorities[can_fit_mask] = 0.5 # All same priority if range is tiny\n\n        # The normalization might be too aggressive or change the relative ordering\n        # in a way that's not intended. The inverse of waste is usually sufficient.\n\n        # Let's consider the \"relative fullness\" of bins.\n        # A bin with remaining capacity `R` relative to some max capacity `M` (e.g., bin capacity, or overall max capacity).\n        # Suppose all bins have a maximum capacity of `C`.\n        # Relative fullness could be `(C - R) / C`.\n        # We want to pack into bins that have a tight fit.\n        #\n        # Let's go back to the core idea: prioritize bins with minimal remaining capacity that are still sufficient.\n        # `priority = -remaining_capacity` (as in v1, but without the `max_capacity` offset)\n        # `priorities[can_fit_mask] = -fitting_bins_capacities`\n        # This is still essentially First Fit.\n        #\n        # The reflection asks for \"inverse, scaled differences, or positive residuals for tighter fits.\"\n        # \"Positive residuals\" -> `remaining_capacity - item`. We want to minimize this.\n        # So, priority should be inversely related to `remaining_capacity - item`.\n        # `priority = 1 / (remaining_capacity - item + epsilon)` is a good choice.\n        #\n        # \"Scaled differences\" could mean scaling this inverse.\n        # E.g., `priority = scale * (1 / (remaining_capacity - item + epsilon))`\n        # or `priority = scale_factor * (1 / (remaining_capacity + epsilon))`\n        # where `scale_factor` depends on `item`.\n        #\n        # Let's consider a \"positive residual\" transformed:\n        # `residual = remaining_capacity - item`.\n        # We want to favor smaller positive residuals.\n        #\n        # Consider a score that reflects how much 'empty' space is left AFTER fitting the item.\n        # `space_left = remaining_capacity - item`\n        # We want bins with small `space_left`.\n        # A priority score that is `1 / (space_left + epsilon)` will give higher scores to smaller `space_left`.\n        # This fits the \"inverse\" and \"positive residuals for tighter fits\" criteria.\n\n        space_left = fitting_bins_capacities - item\n        priorities[can_fit_mask] = 1.0 / (space_left + epsilon)\n\n        # To introduce more graduation, we can apply a non-linear transformation to `space_left`\n        # before taking the inverse, or scale the inverse itself.\n        # For example, `log(1 + space_left)` is a decreasing function, so `1 / log(1 + space_left)`\n        # would prioritize smaller `space_left`.\n        #\n        # Let's consider a different approach: prioritize bins that have *less* total capacity available,\n        # IF they can fit the item. This is not directly about \"tightness\" but about using up less \"valuable\"\n        # (less capacious) bins first.\n        # `priorities[can_fit_mask] = 1.0 / (fitting_bins_capacities + epsilon)`\n        # This prioritizes bins with smaller `remaining_capacity`. This is also a form of First Fit.\n        #\n        # The goal is a *priority function* that guides selection. The highest priority score is chosen.\n        #\n        # Let's ensure \"smoothness\" and \"graduation\".\n        # The `1 / (waste + epsilon)` approach already provides a good graduation where the slope\n        # is steeper for very small waste values.\n        #\n        # Consider a scenario:\n        # Bins: [10, 12, 15]\n        # Item: 5\n        #\n        # Fitting bins: [10, 12, 15]\n        # Waste: [5, 7, 10]\n        #\n        # Priority (1 / (waste + epsilon)):\n        # 1/5.000000001 \u2248 0.2\n        # 1/7.000000001 \u2248 0.14\n        # 1/10.000000001 \u2248 0.1\n        #\n        # This correctly prioritizes the bin with remaining capacity 10.\n        #\n        # What if we want to adjust sensitivity? We could introduce a parameter `alpha`.\n        # `priority = 1 / (waste + epsilon)**alpha`\n        # For `alpha = 1`, we get the above.\n        # For `alpha < 1`, the function is less steep for small waste.\n        # For `alpha > 1`, the function is more steep for small waste.\n        #\n        # Let's use `alpha = 0.5` (square root of waste) as an example of \"smoother graduation\".\n        # `priority = 1 / sqrt(waste + epsilon)`\n        #\n        # Or maybe prioritize the bin that results in the *least* remaining capacity after packing.\n        # This is equivalent to prioritizing the bin with minimum `remaining_capacity` that fits the item.\n        # Which is `priority = -remaining_capacity`.\n\n        # Final decision: prioritize bins with the smallest *positive* slack (remaining capacity - item).\n        # This is achieved by `1 / (remaining_capacity - item + epsilon)`.\n        # This naturally gives higher priority to tighter fits and has a graduated nature.\n        # We can potentially scale this to adjust sensitivity.\n        # A simple scaling: multiply by a constant `K`.\n        # `priority = K * (1 / (waste + epsilon))`\n        # The magnitude of `K` doesn't change the *ordering* but affects the relative differences.\n        # For simplicity, let's not add an arbitrary scaling factor unless specified.\n\n        # Consider the \"relative fullness\": if bins are generally very full, a tight fit is more important.\n        # If bins are generally empty, any fit might be acceptable.\n        # The `1 / (waste + epsilon)` already captures this implicitly because 'waste' is relative to the item.\n\n        # Let's try a formulation that directly uses the remaining capacity in a way that\n        # emphasizes smaller values for fitting bins, but is not just inverse.\n        # A simple non-linear transformation could be `remaining_capacity**2` (prioritizing smaller capacities)\n        # or `1 / remaining_capacity` (prioritizing smaller capacities).\n        #\n        # The reflection mentions \"inverse, scaled differences, or positive residuals\".\n        # `1 / (remaining_capacity - item + epsilon)` seems to best capture \"inverse of positive residuals for tighter fits\".\n        #\n        # To make it more \"graduated\" and less \"binary\" than simple First Fit (which picks the first one that fits),\n        # we need scores that distinguish between fitting bins.\n        #\n        # Let's re-evaluate the `priority_v1` approach: `max_possible_capacity - fitting_bins_capacities`.\n        # This prioritizes bins with the *least* remaining capacity among those that fit.\n        # This IS the First Fit logic.\n        #\n        # The reflection suggests \"positive residuals\" for \"tighter fits\".\n        # Residual = `remaining_capacity - item`. We want to minimize this positive residual.\n        #\n        # Let's try a form that explicitly penalizes larger residuals more heavily:\n        # `priority = - (remaining_capacity - item)` --> This prioritizes smaller residuals, but is linear.\n        # `priority = - (remaining_capacity - item)**2` --> Prioritizes smaller residuals more strongly.\n        # `priority = 1 / (remaining_capacity - item + epsilon)` --> Prioritizes smaller residuals.\n        #\n        # The \"scaled differences\" part could imply scaling `remaining_capacity - item`.\n        #\n        # Let's try prioritizing bins that have `remaining_capacity` closer to `item`.\n        # This means we want to maximize a function that is high when `remaining_capacity` is close to `item`.\n        #\n        # Let's use the *difference* from the ideal fit, but make it a positive value that is smaller for better fits.\n        # `diff = abs(remaining_capacity - item)`\n        # We want to prioritize bins where `diff` is small.\n        # So, priority should be inversely related to `diff`.\n        # `priority = 1 / (abs(remaining_capacity - item) + epsilon)`\n        #\n        # However, for online BPP, we *must* fit the item. So we only consider bins where `remaining_capacity >= item`.\n        # For these bins, `abs(remaining_capacity - item)` is just `remaining_capacity - item`.\n        #\n        # So, `priority = 1 / (remaining_capacity - item + epsilon)` seems to be the most direct interpretation of \"prioritize\n        # bins with minimal remaining capacity that are still sufficient\" and \"positive residuals for tighter fits\".\n        #\n        # To add \"scaled differences\" and \"graduated priorities\":\n        # Consider a function `f(remaining_capacity)` that is decreasing.\n        # E.g., `f(R) = 1 / (R - I + epsilon)`.\n        # We can modify this:\n        # `f(R) = 1 / ( (R - I) / C + epsilon )` where C is some scaling factor (e.g., bin capacity, max item size).\n        # Or `f(R) = K * (1 / (R - I + epsilon))` where K adjusts overall priority magnitude.\n        #\n        # Let's try a slightly different angle for \"graduated\":\n        # Prioritize bins that are not too empty, but can fit the item.\n        #\n        # What if we prioritize bins that have a larger *proportion* of their remaining capacity used?\n        # `fill_ratio = item / remaining_capacity` (for fitting bins)\n        # This gives higher priority to bins where the item fills a larger portion of the remaining space.\n        # This is still similar to `1 / remaining_capacity`.\n        #\n        # Let's stick with prioritizing the tightest fit using the inverse of the slack.\n        #\n        # `slack = fitting_bins_capacities - item`\n        # `priorities[can_fit_mask] = 1.0 / (slack + epsilon)`\n        #\n        # To make it more \"graduated\" and less sensitive to very small slacks,\n        # we can raise the slack to a power greater than 1 before taking the inverse.\n        # `priorities[can_fit_mask] = 1.0 / ((slack + epsilon)**power)` where `power > 1`.\n        # E.g., `power = 1.5` or `power = 2.0`. This would make the priority drop off faster\n        # as slack increases.\n        #\n        # Let's try `power = 1.5` for a smoother, graduated decrease in priority as slack grows.\n\n        slack = fitting_bins_capacities - item\n        power = 1.5  # Adjust for graduation sensitivity\n        priorities[can_fit_mask] = 1.0 / ((slack + epsilon)**power)\n\n    return priorities",
    "response_id": 2,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 193.26196660226546,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined strategy.\n\n    This strategy prioritizes bins that can accommodate the item and then\n    selects bins with the *tightest fit* (smallest remaining capacity) but\n    also considers the *relative fullness* of the bin. Bins that cannot fit\n    the item are given a score of -1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, assign a priority score.\n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    \n    if fitting_bins_capacities.size > 0:\n        # Strategy: Prioritize bins with the tightest fit (smallest remaining capacity).\n        # To achieve this, we can use a score that is inversely related to the\n        # remaining capacity. A simple approach is to subtract the remaining\n        # capacity from a large constant or from the maximum possible remaining\n        # capacity to ensure smaller remaining capacities get higher scores.\n        # We also want to be sensitive to the *relative fullness*.\n        # A good heuristic might be to penalize bins that are *almost full*\n        # or *almost empty* relative to their capacity if they can fit the item.\n        # For this version, let's focus on the tightest fit with a positive residual.\n\n        # Calculate a score that favors smaller remaining capacities.\n        # A larger value means a tighter fit.\n        # We subtract remaining_capacity from a large enough number.\n        # A value like np.max(bins_remain_cap) + item ensures all fitting bins get a positive score.\n        # However, to make it more nuanced, we can consider the difference from the item size.\n        # A bin with remaining capacity R for an item I has a \"gap\" of R - I. We want to minimize this gap.\n        # So, we can use a score proportional to -(R - I), or equivalently, (I - R).\n        # However, a higher score is better. So, we want larger values for smaller R.\n        # Let's use a scaled inverse.\n        # Consider the \"waste\" if we put the item in: bins_remain_cap - item. We want to minimize waste.\n        # So, a higher priority should correspond to smaller waste.\n        # We can map waste `w` to a priority `p`.\n        # A simple mapping is `p = C - w`, where C is a large constant.\n        # Let's use a value that ensures all fitting bins have a priority higher than -1.\n        # The maximum possible remaining capacity can be around the bin capacity itself\n        # if we consider a newly opened bin. So, let's use a value derived from the item size and capacities.\n        \n        # Prioritize bins with less remaining capacity.\n        # We can achieve this by assigning a score that decreases as remaining capacity increases.\n        # A common approach is to use `1 / (remaining_capacity - item + epsilon)` or\n        # `(max_capacity_of_any_bin_ever_seen) - remaining_capacity`.\n        \n        # Let's try a score that is the negative of the remaining capacity plus a large offset.\n        # This prioritizes smaller remaining capacities.\n        # Adding the item size can also help differentiate bins for the same item.\n        # A score based on `remaining_capacity - item` would represent the 'slack' or 'waste'.\n        # We want to minimize slack, so a higher priority for smaller slack.\n        # Let's use a score proportional to the negative slack, scaled.\n        \n        # Positive residual strategy:\n        # For a bin with remaining capacity `r` and an item of size `i`:\n        # The \"fit difference\" is `r - i`. We want to minimize this non-negative difference.\n        # A score that is `- (r - i)` (i.e., `i - r`) would mean smaller `r` gives a larger score.\n        # However, we need to handle cases where `r - i` is small.\n        # A simple inverse of the remaining capacity can work, but might be too sensitive.\n        \n        # Let's try a simple approach: prioritize smaller remaining capacities.\n        # `max_capacity_for_scaling` should be larger than any `bins_remain_cap` value.\n        # A safe bet is the maximum possible capacity of a bin, or a reasonable upper bound.\n        # If we don't know the initial bin capacity, we can use `np.max(bins_remain_cap)`\n        # or a generous constant. Let's assume `bins_remain_cap` can be large.\n        # We want a higher score for smaller `fitting_bins_capacities`.\n        # The expression `max_val - x` results in higher scores for smaller `x`.\n        # Let's use a `max_val` that is sufficiently large.\n        # A value derived from the current `bins_remain_cap` can adapt.\n        \n        # Option 1: Inverse of remaining capacity (can be unstable if capacities are close to 0)\n        # `priorities[can_fit_mask] = 1.0 / (fitting_bins_capacities + 1e-6)` # add epsilon for stability\n        \n        # Option 2: Scaled difference to emphasize tight fits more.\n        # We want to prioritize bins with `r` such that `r` is small and `r >= item`.\n        # This means `r - item` (waste) is small.\n        # A good priority could be `- (r - item)`, so smaller waste gets higher priority.\n        # To make scores positive and distinct, we can add an offset.\n        # Let's try `offset - (r - item)`. A larger offset gives higher scores.\n        # The offset could be related to the maximum possible remaining capacity or item size.\n        \n        # Let's consider the \"goodness of fit\": `bins_remain_cap - item`. We want to minimize this.\n        # A higher priority should be assigned to a smaller `bins_remain_cap - item`.\n        # We can achieve this by using a score like `max_possible_slack - (bins_remain_cap - item)`.\n        # The `max_possible_slack` should be larger than any `bins_remain_cap - item`.\n        # A simple way is to use `bins_remain_cap` itself, but this is not ideal as\n        # it mixes capacity and slack.\n\n        # A robust strategy for prioritizing tighter fits is to use a large number minus\n        # the remaining capacity. This ensures that smaller remaining capacities get higher scores.\n        # Let's make the priority directly related to the \"closeness\" to the item size.\n        # The value `bins_remain_cap - item` is the slack. We want to minimize slack.\n        # A score of `C - slack` would work.\n        # Let's use `bins_remain_cap` as a basis, as it implicitly orders bins.\n        # By subtracting `bins_remain_cap` from a large constant, we reverse the order.\n        \n        # Let's use a score that is the negative of remaining capacity.\n        # This makes smaller remaining capacities have less negative (higher) scores.\n        # We can also add the item size to differentiate bins when remaining capacities are similar.\n        # `bins_remain_cap[can_fit_mask] - item` would be the slack.\n        # We want to prioritize smaller slack.\n        # A good priority could be `(max_val - item) - bins_remain_cap`.\n        # Or simply, higher priority for smaller `bins_remain_cap`.\n\n        # Let's use a score that prioritizes bins with less remaining capacity.\n        # A simple way is to use a large constant minus the remaining capacity.\n        # This ensures smaller remaining capacities get higher scores.\n        # The constant should be larger than any possible remaining capacity.\n        # `np.max(bins_remain_cap)` is a reasonable choice if we assume bins start from some capacity.\n        # To ensure scores are always positive and distinct, we can add a small epsilon.\n        \n        # Refined approach: prioritize bins with the smallest `bins_remain_cap` that fit.\n        # This is essentially First Fit. The priority should reflect this.\n        # The value `bins_remain_cap` itself can be used if we want to prioritize smaller values.\n        # However, higher score means higher priority.\n        # So, we want `bins_remain_cap` to be small.\n        # We can use `-(bins_remain_cap)` and add a large constant.\n        # Or, `max_capacity_value - bins_remain_cap`.\n\n        # Let's consider the difference from the item size, `bins_remain_cap - item`.\n        # We want to minimize this difference.\n        # A score `(bins_remain_cap - item)` would favor larger remaining capacities, which is wrong.\n        # A score `-(bins_remain_cap - item)` or `item - bins_remain_cap` would favor smaller remaining capacities.\n        # To make scores positive and ordered: `max_slack - (bins_remain_cap - item)`.\n        # The maximum possible slack could be related to the bin's initial capacity.\n        \n        # Let's simplify: a higher priority for a bin means it's a \"better\" fit.\n        # \"Better\" here means smaller remaining capacity.\n        # We can assign a score that is inversely proportional to the remaining capacity.\n        # To avoid division by zero and instability, we can use `C - bins_remain_cap`.\n        # Let C be a value larger than any remaining capacity.\n        # `np.max(bins_remain_cap)` is a good candidate if we assume bins start with some capacity.\n        # If we don't have an upper bound, we can use a sufficiently large number.\n\n        # For a tighter fit, we want `bins_remain_cap` to be close to `item`.\n        # This means `bins_remain_cap - item` should be small and non-negative.\n        # A priority could be `-(bins_remain_cap - item)`.\n        # To make these positive and distinct:\n        # `max_waste - (bins_remain_cap - item)`\n        # `max_waste` can be `np.max(bins_remain_cap) - item`.\n        # Let's set a scaling factor to control the sensitivity.\n        \n        # Simple inverse of remaining capacity, scaled and offset for positive values.\n        # Prioritize smaller `bins_remain_cap`.\n        # Let's consider `bins_remain_cap` as the primary indicator for tightness.\n        # A higher priority is given to smaller `bins_remain_cap`.\n        # We can achieve this with a score proportional to the negative of remaining capacity.\n        # `priorities[can_fit_mask] = -fitting_bins_capacities`\n        # To ensure positive and distinct scores:\n        # `priorities[can_fit_mask] = 1000.0 - fitting_bins_capacities`  (1000.0 is an arbitrary large constant)\n        # This prioritizes bins with the least remaining capacity.\n\n        # Alternative using slack: `slack = bins_remain_cap - item`. Minimize slack.\n        # Priority could be `1 / (slack + epsilon)`.\n        # Or `max_slack - slack`.\n        \n        # Let's go with a strategy that emphasizes smaller remaining capacities.\n        # We want a higher score for smaller `fitting_bins_capacities`.\n        # We can use a base value and subtract the remaining capacity.\n        # This directly implements the \"smaller remaining capacity is better\" logic.\n        # The base value should be large enough to ensure positive and distinct scores.\n        \n        # Using the inverse of the remaining capacity can be sensitive to small values.\n        # Using a large constant minus the remaining capacity is more stable.\n        # Let's use a score that is simply the negative of the remaining capacity.\n        # Smaller remaining capacity means a less negative score, which is higher priority.\n        # To ensure these are generally higher than the -1 default for non-fitting bins,\n        # we can add a sufficiently large constant.\n        \n        # Final refined strategy: Prioritize bins with the smallest remaining capacity.\n        # This is the core of First Fit.\n        # The priority score should reflect this: higher score for smaller remaining capacity.\n        # A simple and effective way is to use `C - remaining_capacity`.\n        # `C` should be a value greater than any possible `remaining_capacity`.\n        # `np.max(bins_remain_cap)` could be a baseline, but if a new bin is opened,\n        # its remaining capacity is the full bin capacity.\n        # Let's use a scaled inverse approach where we emphasize the tightness.\n        # Consider `(bins_remain_cap - item)` as slack. We want to minimize slack.\n        # A score of `1 / (bins_remain_cap - item + epsilon)` will rank bins by increasing slack.\n        # To get higher priority for smaller slack, we can use `1 / (slack + epsilon)` directly.\n        # Or, `max_slack - slack`.\n        \n        # Let's try a scaled inverse of the remaining capacity for prioritization.\n        # This emphasizes bins that are nearly full (small remaining capacity).\n        # `priorities[can_fit_mask] = 1.0 / (fitting_bins_capacities + 1e-9)`\n        # This gives higher scores to bins with smaller remaining capacities.\n        \n        # Let's consider the \"fit quality\" as `bins_remain_cap - item`.\n        # We want to minimize this.\n        # A score proportional to `-(bins_remain_cap - item)` is desired.\n        # To make these positive and distinguishable, we can use:\n        # `scaling_factor * (max_possible_remaining_capacity - (bins_remain_cap - item))`\n        # Where `max_possible_remaining_capacity` is the largest possible value `bins_remain_cap` can take.\n        \n        # A simpler approach that favors tighter fits:\n        # Assign a score inversely proportional to the remaining capacity.\n        # `priorities[can_fit_mask] = 1.0 / (fitting_bins_capacities + 1e-9)`\n        \n        # Let's try a slightly more nuanced approach, considering the *difference*\n        # from the item size. We want to minimize `bins_remain_cap - item`.\n        # A higher priority for smaller `bins_remain_cap - item`.\n        # So, a score that is `-(bins_remain_cap - item)` would work.\n        # To ensure positive and distinct scores, we can add a large constant.\n        # `priorities[can_fit_mask] = (np.max(fitting_bins_capacities) - fitting_bins_capacities) + item`\n        # This prioritizes bins where `fitting_bins_capacities` is smallest.\n\n        # Let's use a score that is simply the negative of the remaining capacity.\n        # This ensures smaller remaining capacities have less negative, thus higher scores.\n        # `priorities[can_fit_mask] = -fitting_bins_capacities`\n        # To make these scores positive and generally higher than -1, we can add a large offset.\n        # For example, an offset of `max(bins_remain_cap)` plus a margin.\n        # A simple approach: `max_val - fitting_bins_capacities`.\n        \n        # Let's define `max_val` to be larger than any current remaining capacity.\n        # This ensures higher scores for bins with less remaining capacity.\n        # We can pick a value that ensures positive and distinct scores.\n        # Using the maximum possible remaining capacity is a good strategy.\n        # If we don't know the initial bin capacity, we can use a large number.\n        \n        # A good heuristic is to prioritize bins with the smallest remaining capacity.\n        # This means a higher priority for bins where `bins_remain_cap` is smaller.\n        # We can use `max_possible_capacity - bins_remain_cap` to achieve this ordering.\n        # Let `max_possible_capacity` be a value larger than any expected `bins_remain_cap`.\n        # A simple choice is `np.max(bins_remain_cap) + item` or a fixed large number.\n        \n        # Let's use a score that is `1 / (bins_remain_cap - item + epsilon)`\n        # This emphasizes bins where the remaining capacity is just enough.\n        # smaller `bins_remain_cap - item` gives higher score.\n        priorities[can_fit_mask] = 1.0 / (fitting_bins_capacities - item + 1e-9)\n\n    return priorities",
    "response_id": 3,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined First Fit strategy.\n\n    This strategy prioritizes bins that can accommodate the item, favoring\n    those with the least remaining capacity (tightest fit). It uses a scaled\n    difference from the maximum possible remaining capacity to create a graduated\n    priority, ensuring that bins with very little space but still fitting the item\n    receive the highest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority. Bins that cannot fit the\n        item are given a score of -1. Bins that can fit the item are scored\n        based on their remaining capacity, favoring smaller remaining capacities\n        with a graduated scale.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)  # Initialize with low priority (-1)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, assign a priority score.\n    # We want to prioritize bins with *less* remaining capacity first (First Fit logic).\n    # To achieve a graduated priority that emphasizes tighter fits, we can\n    # calculate a score based on how much space is *left over* after packing.\n    # A smaller leftover space means a tighter fit, thus higher priority.\n    # We can express this as (remaining_capacity - item_size).\n    # To ensure higher scores for better fits (smaller leftover space), we can\n    # use a large constant minus this leftover space.\n    # We also add a small epsilon to the leftover space to avoid division by zero\n    # if we were to use inverse, and to ensure a distinct ordering.\n    if np.any(can_fit_mask):\n        fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n        leftover_space = fitting_bins_capacities - item\n        # We want to prioritize smaller leftover_space.\n        # A large number minus leftover_space will achieve this.\n        # Using the maximum possible leftover space as a reference.\n        # The maximum leftover space can be at most the maximum capacity minus item.\n        # To be safe and ensure positive priorities, we can use a value\n        # larger than any potential leftover space.\n        max_potential_leftover = np.max(bins_remain_cap) - item\n        # A common heuristic is to use a large constant like 1000 or a\n        # function of the maximum possible capacity. Let's use a value\n        # that ensures a clear distinction from -1.\n        # A simple approach for graduated priority: a large number minus leftover space.\n        # For example, if capacities are up to 100 and item is 10:\n        # Bin with 15 capacity -> leftover 5 -> priority large - 5\n        # Bin with 20 capacity -> leftover 10 -> priority large - 10\n        # Bin with 10 capacity -> leftover 0 -> priority large - 0 (highest)\n        # Let's use a base value derived from the problem scale to ensure\n        # priorities are distinct and meaningful.\n        base_priority = 1000.0 # A sufficiently large constant\n        priorities[can_fit_mask] = base_priority - leftover_space\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 46.50699332842308,
    "exec_success": true
  }
]