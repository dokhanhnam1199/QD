{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using an Epsilon-Greedy strategy.\n\n    The strategy aims to balance exploration (trying less occupied bins) with exploitation\n    (favoring bins that have a tight fit for the item).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploring a random bin\n\n    # Identify feasible bins where the item can fit\n    feasible_bins_mask = bins_remain_cap >= item\n    \n    # If no bins are feasible, return all zeros (no valid placement)\n    if not np.any(feasible_bins_mask):\n        return np.zeros_like(bins_remain_cap)\n\n    # Initialize priorities for all bins\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Greedy (Exploitation) part: Prioritize bins that are a \"tight fit\"\n    # We want bins where remaining capacity - item size is small.\n    # To avoid division by zero or very small numbers, we can add a small constant.\n    # Also, to make smaller remaining capacities more dominant, we can use the inverse.\n    # However, a simple approach is to prioritize bins with the smallest remaining capacity\n    # that can still fit the item. This is equivalent to prioritizing bins where the\n    # residual capacity (after placing the item) is minimized.\n    \n    # Calculate the residual capacity if the item is placed in a feasible bin\n    residual_capacities = bins_remain_cap[feasible_bins_mask] - item\n    \n    # For feasible bins, calculate a greedy score. Lower residual capacity is better.\n    # We can use the inverse of (residual_capacity + 1) to ensure higher scores for better fits.\n    # Add a small epsilon to avoid division by zero and to make smaller residuals more impactful.\n    greedy_scores = 1.0 / (residual_capacities + 1e-6)\n\n    # Apply the greedy scores to the feasible bins\n    priorities[feasible_bins_mask] = greedy_scores\n\n    # Epsilon-Greedy (Exploration) part: With probability epsilon, choose a random feasible bin\n    # This helps to avoid getting stuck in local optima by sometimes trying bins\n    # that are not the \"best fit\" according to the greedy strategy.\n\n    # Generate random numbers for each bin\n    random_values = np.random.rand(len(bins_remain_cap))\n\n    # For feasible bins, if the random value is less than epsilon, give it a high exploration score.\n    # We can assign a constant high score, or a score based on randomness.\n    # Let's assign a score that makes it competitive but not necessarily dominant.\n    # A simple approach is to assign a score that is slightly better than the \"average\"\n    # greedy score or a random high value.\n    \n    # We want to randomly pick among the *feasible* bins.\n    num_feasible_bins = np.sum(feasible_bins_mask)\n    \n    if num_feasible_bins > 0:\n        # Get indices of feasible bins\n        feasible_bin_indices = np.where(feasible_bins_mask)[0]\n        \n        # Determine how many bins to \"explore\" based on epsilon\n        num_to_explore = int(np.floor(epsilon * num_feasible_bins))\n        \n        if num_to_explore > 0:\n            # Randomly select indices of feasible bins to give an exploration boost\n            exploration_indices = np.random.choice(feasible_bin_indices, num_to_explore, replace=False)\n            \n            # Assign a high exploration score to these bins.\n            # A score that is slightly higher than the current best greedy score\n            # would be reasonable. For simplicity, let's use a constant that ensures\n            # it's considered.\n            exploration_boost = np.max(greedy_scores) * 1.1 if np.any(greedy_scores) else 1.0\n            priorities[exploration_indices] = exploration_boost\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First.\n\n    Exact Fit First prioritizes bins that can fit the item exactly.\n    Among bins that can fit the item exactly, it prioritizes those with less remaining capacity (to minimize wasted space).\n    If no exact fit is available, it will consider bins that can fit the item but might leave some remaining capacity,\n    prioritizing those with the smallest remaining capacity that is still sufficient.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins where the item fits exactly\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n\n    if len(exact_fit_indices) > 0:\n        # Among exact fits, prioritize those with the least remaining capacity (which is 'item' itself in this case)\n        # Since they are exact fits, their remaining capacity is already determined.\n        # We can assign a high priority. Here, we'll give them a value based on their index to ensure\n        # deterministic behavior if multiple exact fits exist (though it doesn't matter for exact fit logic itself).\n        # A higher priority score indicates a better fit.\n        priorities[exact_fit_indices] = 10000 - exact_fit_indices\n    else:\n        # If no exact fit, find bins that can accommodate the item\n        can_fit_indices = np.where(bins_remain_cap >= item)[0]\n\n        if len(can_fit_indices) > 0:\n            # Among bins that can fit, prioritize those with the smallest remaining capacity\n            # that is still sufficient for the item. This is a form of \"best fit\".\n            # We want to maximize the priority for the bin that leaves the least\n            # remaining space after adding the item.\n            # So, we want to minimize (bins_remain_cap - item).\n            # Assigning a priority based on this difference, but inversely (higher priority for smaller difference).\n            # A common way is to use a large number minus the difference.\n            relevant_bins_capacities = bins_remain_cap[can_fit_indices]\n            # Calculate the difference for eligible bins\n            differences = relevant_bins_capacities - item\n            # Assign priorities: Higher values for smaller differences\n            # We can use a large constant minus the difference to make it a \"higher is better\" score.\n            # The constant should be large enough to separate these from non-fitting bins (which have 0 priority).\n            priorities[can_fit_indices] = 1000 - differences\n        else:\n            # No bin can fit the item, priority remains 0 for all.\n            pass # priorities is already initialized to zeros\n\n    return priorities\n\n[Reflection]\nFocus on exact fits and then best fits. Exploration is less critical for BPP.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}