[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility: Only consider bins that can fit the item\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf  # Very low priority for infeasible bins\n\n    # 2. Remaining Capacity Utilization: Prefer bins with tighter fit\n    remaining_after_fit = bins_remain_cap - item\n    priorities[feasible_bins] = 1 / (remaining_after_fit[feasible_bins] + 1e-9)  # Avoid division by zero, prioritize smaller remaining capacity\n\n    # 3. Bonus for almost full bins to fill them up\n    almost_full = (bins_remain_cap > item) & (bins_remain_cap <= 2 * item)  # Check bins remaining capacity is slightly more than item size\n    priorities[almost_full] += 10  # Give these bins a boost, higher than other priority score\n\n    # 4. Add some randomness\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 # Small random number to introduce randomness\n\n    return priorities",
    "response_id": 12,
    "obj": 3.8591942560829726,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 48.43204266092217,
    "mi": 85.89195173073983,
    "token_count": 104.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Feasibility: Only consider bins that can fit the item\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf  # Very low priority for infeasible bins\n\n    # 2. Remaining Capacity Utilization: Prefer bins with tighter fit.  Use a squared term to further penalize larger remaining capacities.\n    remaining_after_fit = bins_remain_cap - item\n    priorities[feasible_bins] = 1 / (remaining_after_fit[feasible_bins]**2 + 1e-9)  # Avoid division by zero, prioritize smaller remaining capacity\n\n    # 3. Bonus for almost full bins to fill them up, and prioritize them even more\n    almost_full = (bins_remain_cap > item) & (bins_remain_cap <= 2 * item)  # Check bins remaining capacity is slightly more than item size\n    priorities[almost_full] += 20  # Give these bins a significant boost, higher than other priority score\n\n    # 4. Add some randomness, scaled to the inverse of the item size (smaller items get more randomness)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * (0.1 / (item + 0.1)) # Small random number to introduce randomness, scaled by item size\n\n    # 5. Prioritize bins that are nearly empty (First-Fit flavor)\n    nearly_empty = bins_remain_cap > (0.9 * np.max(bins_remain_cap)) # Bin is almost empty\n    priorities[nearly_empty & feasible_bins] += 5 # Boost the priority of nearly empty bins if they can fit the item\n\n    return priorities",
    "response_id": 1,
    "obj": 3.6996410051854944,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.16184010614157,
    "mi": 81.61500607917039,
    "token_count": 152.0,
    "exec_success": true
  }
]