{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for TSP based on normalized distance, dynamic degree centrality,\n    and adaptive sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Normalize distances to be between 0 and 1\n    max_dist = np.max(distance_matrix)\n    min_dist = np.min(distance_matrix)\n    normalized_distances = (distance_matrix - min_dist) / (max_dist - min_dist + 1e-9)\n\n    # Initialize heuristic matrix with inverse normalized distances\n    heuristic_matrix = 1 / (normalized_distances + 1e-9)\n\n    # Dynamic degree centrality: penalize connections to nodes with already many near connections\n    degree_centrality = np.sum(1 / (normalized_distances + 1e-9), axis=1)\n    avg_degree = np.mean(degree_centrality)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] *= (degree_centrality[i] + degree_centrality[j]) / (2 * avg_degree + 1e-9) # Normalize by average degree\n\n    # Adaptive sparsification: favor edges shorter than the average, and strongly penalize longer edges.\n\n    avg_distance = np.mean(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            if distance_matrix[i, j] > avg_distance:\n                heuristic_matrix[i, j] *= np.exp(-(distance_matrix[i, j] - avg_distance) / (avg_distance + 1e-9)) # Exponential decay\n            else:\n                heuristic_matrix[i,j] *= 1.0 + 0.5*(1.0 - distance_matrix[i, j] / (avg_distance+1e-9)) #Slight boost for short edges relative to the average\n\n    # Incorporate randomness: add a small random factor to encourage exploration\n    random_matrix = np.random.rand(n, n) * 0.1\n    heuristic_matrix += random_matrix\n\n    # Enforce symmetry (important for some TSP solvers)\n    heuristic_matrix = (heuristic_matrix + heuristic_matrix.T) / 2\n\n    # Normalize the heuristic matrix to a range of 0 to 1\n    max_val = np.max(heuristic_matrix)\n    min_val = np.min(heuristic_matrix)\n\n    if max_val > min_val:\n        heuristic_matrix = (heuristic_matrix - min_val) / (max_val - min_val)\n    else:\n        heuristic_matrix = np.ones_like(heuristic_matrix) * 0.5\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP).\n\n    This version refines the heuristics by incorporating global distance normalization,\n    dynamic sparsification based on percentiles, and a node degree penalty based on\n    neighbor counts, aiming for better exploration and solution quality.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where `distance_matrix[i, j]`\n            represents the distance between node `i` and node `j`.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as `distance_matrix`, where each\n            element indicates the heuristic value (promise) of including the\n            corresponding edge in a TSP solution. Higher values indicate a more\n            promising edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse Distance (primary factor)\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero\n\n    # 2. Node Degree Penalty using Neighbor Counts\n    neighbor_counts = np.sum(heuristic_matrix > 0, axis=0)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] /= (neighbor_counts[i] + neighbor_counts[j] + 1e-9)  # Penalize based on number of existing connections\n\n    # 3. Global Distance Normalization\n    average_distance = np.mean(distance_matrix[distance_matrix != np.inf])\n    heuristic_matrix *= (average_distance / (np.mean(distance_matrix) + 1e-9))  # Scale based on average\n\n    # 4. Dynamic Sparsification based on Percentiles\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 40) # Dynamic Sparsity: consider only top 60%\n    heuristic_matrix[heuristic_matrix < threshold] = 0.0  # Set low-promise edges to zero\n\n    return heuristic_matrix\n\n[Reflection]\nFocus on neighbor-based penalties, global normalization, and percentile-based dynamic sparsification for improved heuristics.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}