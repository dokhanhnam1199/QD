{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP that combines distance, node degree, and randomness.\n    It also sparsifies the matrix by setting low-probability edges to zero.\n\n    Args:\n        distance_matrix (np.ndarray): A numpy array representing the distance matrix.\n\n    Returns:\n        np.ndarray: A numpy array of the same shape as distance_matrix,\n                      representing the probability of including each edge in a solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance: Shorter distances are preferred\n    inverse_distance = 1 / (distance_matrix + 1e-6)  # Add a small constant to avoid division by zero\n\n    # 2. Node degree: Encourage connections to nodes with fewer connections.\n    #    Initialized to ones, and increased when an edge is assigned to a node.\n    node_degrees = np.ones(n)\n\n    # Iterate through the distance matrix\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Combine inverse distance and node degrees\n                heuristic_matrix[i, j] = inverse_distance[i, j] / (node_degrees[i] * node_degrees[j])\n\n    # 3. Add randomness: Introduce some stochasticity to explore different solutions\n    random_matrix = np.random.rand(n, n) * 0.1  # Adjust the scaling factor for randomness\n\n    heuristic_matrix = heuristic_matrix + random_matrix\n\n    # Normalize the heuristic matrix to get probabilities.\n    heuristic_matrix = heuristic_matrix / np.sum(heuristic_matrix)\n\n\n    # 4. Sparsify the matrix: Set low-probability edges to zero to focus on more promising edges.\n    threshold = np.quantile(heuristic_matrix[heuristic_matrix > 0], 0.2)  # Remove bottom 20%\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Re-normalize the matrix\n    if np.sum(heuristic_matrix) > 0: #check for zero sum.\n       heuristic_matrix = heuristic_matrix / np.sum(heuristic_matrix)\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP).\n\n    This version combines several factors to estimate the desirability of including\n    each edge in a potential TSP solution. It considers:\n\n    1. Inverse Distance: Shorter edges are generally more desirable.\n    2. Node Degree Penalty: Penalizes edges connecting to nodes that already have many\n       close neighbors (to encourage exploration and avoid local optima).\n    3. Global Distance Average: Normalizes distances relative to the average.\n    4. Sparsification: Sets elements with low heuristic values to zero to focus search.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where `distance_matrix[i, j]`\n            represents the distance between node `i` and node `j`.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as `distance_matrix`, where each\n            element indicates the heuristic value (promise) of including the\n            corresponding edge in a TSP solution. Higher values indicate a more\n            promising edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse Distance (primary factor)\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero\n\n    # 2. Node Degree Penalty (discourage high-degree nodes early)\n    neighbor_counts = np.sum(heuristic_matrix > 0, axis=0) # how many neighbors does each node have?\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] /= (neighbor_counts[i] + neighbor_counts[j])  # Penalize based on number of existing connections. Add one to each to deal with possible 0 count and avoid division by 0\n\n    # 3. Global Distance Average (normalize distances)\n    average_distance = np.mean(distance_matrix[distance_matrix != np.inf]) # ignores infinite values such as those along the diagonal if they are present\n    heuristic_matrix *= (average_distance / (np.mean(distance_matrix) + 1e-9))  # Scale based on average\n\n    # 4. Sparsification (focus the search)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 40) #Dynamic Sparsity: consider only top 60% promising\n    heuristic_matrix[heuristic_matrix < threshold] = 0.0  # Set low-promise edges to zero\n\n    return heuristic_matrix\n\n[Reflection]\nThe better code normalizes distances globally, dynamically sparsifies, and uses neighbor counts for degree penalty instead of static degrees.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}