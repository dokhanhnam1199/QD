{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP) that\n    combines multiple factors to estimate the suitability of each edge\n    in a potential TSP solution.\n\n    This version incorporates:\n    - Inverse distance: Shorter distances are preferred.\n    - Adaptive Node Preference: Node preferences are updated based on edge selection frequency.\n    - Randomness: Introduces stochasticity to encourage exploration.\n    - Percentile-based sparsification: Removes edges exceeding a distance threshold.\n\n    Args:\n        distance_matrix (np.ndarray): A square, symmetric matrix representing\n                                       the distances between cities.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix,\n                    indicating the prior probability/promise of each edge\n                    being part of a good TSP tour.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # Inverse distance - closer cities are generally better\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # Node degree preference - encourages exploration of less-connected nodes\n    node_preference = np.ones(n)  # Initially, all nodes are equally preferred\n\n    # Edge selection frequency (for adaptive node preference)\n    edge_selection_count = np.zeros((n, n))\n\n    # Initial node preference based on inverse distance sum\n    node_preference = np.sum(inverse_distance, axis=1)\n    node_preference /= np.max(node_preference)  # Normalize\n\n    # Iterate through all possible edges\n    for i in range(n):\n        for j in range(i + 1, n):  # Only consider upper triangle since matrix is symmetric\n            # Combine factors: inverse distance and node preference\n            heuristic_matrix[i, j] = inverse_distance[i, j] * node_preference[i] * node_preference[j]\n\n            # Add some randomness to encourage exploration\n            heuristic_matrix[i, j] += np.random.rand() * 0.05\n\n            # Sparsify the matrix: set unpromising elements to zero based on percentile\n            distance_threshold = np.percentile(distance_matrix, 80)  # Consider top 80%\n            if distance_matrix[i, j] > distance_threshold:\n                heuristic_matrix[i, j] = 0\n\n    # Ensure symmetry\n    heuristic_matrix = heuristic_matrix + heuristic_matrix.T\n\n    # Normalize heuristic values to be between 0 and 1 to avoid numerical issues\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix = heuristic_matrix / max_heuristic\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for TSP based on adaptive sparsification, distance, degree centrality, and geometric mean centrality.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Initialize the heuristic matrix with the inverse of the distance\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # Degree centrality heuristic: favors nodes with high \"connectivity\" (low average distance to others)\n    degree_centrality = np.sum(1 / (distance_matrix + 1e-9), axis=1)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] *= (degree_centrality[i] + degree_centrality[j]) / 2\n\n    #Geometric mean centrality\n    geometric_mean_centrality = np.exp(np.mean(np.log(distance_matrix + 1e-9), axis=1))\n\n    for i in range(n):\n        for j in range(n):\n            if i!=j:\n                 heuristic_matrix[i, j] *= np.sqrt(geometric_mean_centrality[i] * geometric_mean_centrality[j])\n\n    # Adaptive Sparsification based on percentile threshold\n\n    flattened_distances = distance_matrix.flatten()\n    percentile_threshold = np.percentile(flattened_distances, 75) # Adjust percentile to control sparcity; higher value means more edges are kept\n    for i in range(n):\n        for j in range(n):\n            if distance_matrix[i, j] > percentile_threshold:\n                heuristic_matrix[i, j] = 0\n\n    # Local normalization (row means)\n    row_means = np.mean(distance_matrix, axis=1, keepdims=True)\n\n    for i in range(n):\n        for j in range(n):\n          if row_means[i,0] > 0:\n            heuristic_matrix[i, j] /= (row_means[i,0] + 1e-9)\n\n    # Add a small amount of controlled randomness for exploration\n    randomness_factor = 0.01  # Adjust this to control the level of randomness\n    random_matrix = np.random.rand(n, n) * randomness_factor\n    heuristic_matrix += random_matrix\n\n    #Final Distance adjustment\n\n    heuristic_matrix = heuristic_matrix / (distance_matrix**2 + 1e-9)\n\n\n    # Normalize the heuristic matrix to a range of 0 to 1, after all operations.\n    max_val = np.max(heuristic_matrix)\n    min_val = np.min(heuristic_matrix)\n\n    if max_val > min_val:  # To avoid division by zero when all elements are the same\n        heuristic_matrix = (heuristic_matrix - min_val) / (max_val - min_val)\n    else:\n        heuristic_matrix = np.ones_like(heuristic_matrix) * 0.5  # or another default value\n\n    return heuristic_matrix\n\n[Reflection]\nGeometric/harmonic means, degree centrality, adaptive sparsification, local normalization, and final distance adjustment improve TSP heuristics.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}