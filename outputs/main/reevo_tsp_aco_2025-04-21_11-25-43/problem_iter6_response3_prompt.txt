{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for TSP based on adaptive sparsification, distance,\n    node degree, and geometric mean centrality.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Inverse distance as a base\n    heuristic_matrix = 1.0 / (distance_matrix + 1e-9)\n\n    # Node degree centrality (sum of inverse distances)\n    degree_centrality = np.sum(1.0 / (distance_matrix + 1e-9), axis=1)\n\n    # Geometric mean centrality (product of inverse distances)\n    geometric_centrality = np.prod(1.0 / (distance_matrix + 1e-9), axis=1, where=distance_matrix != 0)  # Avoid multiplying by zero\n    geometric_centrality[~np.isfinite(geometric_centrality)] = 0  # Handle potential inf/NaN values\n\n    # Combine degree and geometric centrality\n    combined_centrality = (degree_centrality + geometric_centrality) / 2.0\n\n    # Incorporate centrality into the heuristic\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] *= (combined_centrality[i] + combined_centrality[j]) / 2.0\n\n    # Adaptive sparsification based on percentile threshold\n    distances = distance_matrix[np.triu_indices_from(distance_matrix, k=1)]  # Upper triangle to avoid duplicates\n    threshold_percentile = 75  # Adjust for desired sparsity\n    threshold_distance = np.percentile(distances, threshold_percentile)\n\n    # Apply sparsification\n    heuristic_matrix[distance_matrix > threshold_distance] = 0\n\n    # Local normalization (row-wise mean) - avoids domination by single large values\n    row_means = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    heuristic_matrix = heuristic_matrix / (row_means + 1e-9)\n\n    # Controlled randomness for exploration\n    randomness_factor = 0.01 # Adjust randomness\n    random_matrix = np.random.rand(n, n) * randomness_factor\n    heuristic_matrix += random_matrix\n\n    # Normalize the entire matrix to [0, 1]\n    max_val = np.max(heuristic_matrix)\n    min_val = np.min(heuristic_matrix)\n\n    if max_val > min_val:\n        heuristic_matrix = (heuristic_matrix - min_val) / (max_val - min_val)\n    else:\n        heuristic_matrix = np.ones_like(heuristic_matrix) * 0.5\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for TSP based on distance, degree centrality, geometric mean centrality,\n    adaptive sparsification, local normalization, and controlled randomness.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Initialize the heuristic matrix with the inverse of the distance\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)\n\n    # Degree centrality heuristic: favors nodes with high \"connectivity\"\n    degree_centrality = np.sum(1 / (distance_matrix + 1e-9), axis=1)\n\n    # Geometric mean centrality: favors nodes centrally located in the graph\n    geometric_mean_centrality = np.exp(np.mean(np.log(distance_matrix + 1e-9), axis=1))\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] *= (degree_centrality[i] + degree_centrality[j]) / 2\n                heuristic_matrix[i, j] /= (geometric_mean_centrality[i] * geometric_mean_centrality[j])**0.5 #Penalize edges with nodes far from geometric center.\n\n    # Adaptive sparsification based on dynamic percentile threshold\n    flattened_distances = distance_matrix.flatten()\n    percentile_threshold = np.percentile(flattened_distances, 75)  # Adjust percentile as needed\n\n    for i in range(n):\n        for j in range(n):\n            if distance_matrix[i, j] > percentile_threshold:\n                heuristic_matrix[i, j] = 0\n\n    # Local normalization (row and column means)\n    row_means = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    col_means = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    heuristic_matrix /= (row_means + col_means + 1e-9) / 2  #Combined row and column normalization\n\n    # Controlled randomness for exploration (add small random noise)\n    random_noise = np.random.rand(n, n) * 0.01  # Adjust noise level as needed\n    heuristic_matrix += random_noise\n\n    # Final adjustment based on inverse square of the distance\n    heuristic_matrix = heuristic_matrix / (distance_matrix**2 + 1e-9)\n\n    # Normalize the heuristic matrix to a range of 0 to 1\n    max_val = np.max(heuristic_matrix)\n    min_val = np.min(heuristic_matrix)\n\n    if max_val > min_val:\n        heuristic_matrix = (heuristic_matrix - min_val) / (max_val - min_val)\n    else:\n        heuristic_matrix = np.ones_like(heuristic_matrix) * 0.5\n\n    return heuristic_matrix\n\n[Reflection]\nGeometric centrality penalization, combined row/column normalization, and inverse square distance weighting improve heuristic quality.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}