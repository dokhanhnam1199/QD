```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP).

    This version refines the heuristics_v1 function by incorporating:

    1. Inverse Distance: Shorter edges are generally more desirable.
    2. Node Degree Penalty: Penalizes edges connecting to nodes that already have many
       close neighbors (to encourage exploration and avoid local optima). The penalty
       is adaptively scaled.
    3. Global Distance Average: Normalizes distances relative to the average.
    4. Dynamic Sparsification: Sets elements with low heuristic values to zero to focus search.
       The sparsity level adapts to the problem instance.
    5. Adaptive Degree Penalty: Adjusts the influence of the degree penalty based on the
       problem scale.

    Args:
        distance_matrix (np.ndarray): A square matrix where `distance_matrix[i, j]`
            represents the distance between node `i` and node `j`.

    Returns:
        np.ndarray: A matrix of the same shape as `distance_matrix`, where each
            element indicates the heuristic value (promise) of including the
            corresponding edge in a TSP solution. Higher values indicate a more
            promising edge.
    """

    n = distance_matrix.shape[0]

    # 1. Inverse Distance (primary factor)
    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero

    # 2. Node Degree Penalty (discourage high-degree nodes early)
    neighbor_counts = np.sum(heuristic_matrix > 0, axis=0) # how many neighbors does each node have?
    degree_penalty_strength = np.log(n) #Adaptive scaling to the problem size.

    for i in range(n):
        for j in range(n):
            if i != j:
                heuristic_matrix[i, j] /= (1 + degree_penalty_strength * (neighbor_counts[i] + neighbor_counts[j]))  # Penalize based on number of existing connections.

    # 3. Global Distance Average (normalize distances)
    average_distance = np.mean(distance_matrix[distance_matrix != np.inf]) # ignores infinite values such as those along the diagonal if they are present
    heuristic_matrix *= (average_distance / (np.mean(distance_matrix) + 1e-9))  # Scale based on average

    # 4. Dynamic Sparsification (focus the search)
    sparsity_percentile = max(10, min(50, 50 - int(np.log(n) * 5))) #Adaptive sparsity scaling to the problem size.

    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], sparsity_percentile) #Consider the top values depending on sparsity_percentile
    heuristic_matrix[heuristic_matrix < threshold] = 0.0  # Set low-promise edges to zero

    return heuristic_matrix
```
