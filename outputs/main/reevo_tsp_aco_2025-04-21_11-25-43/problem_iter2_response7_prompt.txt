{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for TSP using stochastic solution sampling principles.\n\n    Combines several factors to determine the desirability of including each edge:\n    1. Inverse Distance:  Shorter distances are generally more desirable.\n    2. Node Degree Preference:  Encourages a relatively balanced degree for each node.\n       Nodes with very few connections are strongly encouraged to connect to closer nodes.\n    3. Sparsification: Sets probabilities of very long edges to zero to reduce the search space.\n\n    Args:\n        distance_matrix (np.ndarray):  A square matrix where [i, j] is the distance\n                                       between node i and node j. Diagonal elements should be 0,\n                                       and the matrix should be symmetric.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, representing\n                    the desirability of including each edge in the TSP tour.\n                    Higher values indicate more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # 2. Node Degree Preference\n    degree_preference = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        # Calculate distances from node i to all other nodes\n        distances = distance_matrix[i, :]\n        \n        # Sort distances in ascending order\n        sorted_indices = np.argsort(distances)\n        \n        # Give higher preference to the closest nodes\n        for j in range(1, min(4,n)): # consider a few closest neighbors\n            degree_preference[i, sorted_indices[j]] = 1.0 #/distances[sorted_indices[j]]\n            degree_preference[sorted_indices[j], i] = 1.0\n\n    # 3. Sparsification\n    max_distance = np.max(distance_matrix)\n    sparsification_threshold = 0.75 * max_distance  # Remove long edges\n\n    # Combine factors\n    heuristic_matrix = inverse_distance + degree_preference\n\n    # Apply sparsification\n    heuristic_matrix[distance_matrix > sparsification_threshold] = 0\n\n    # Normalize to get probabilities between 0 and 1.  Important for stochastic sampling.\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix = heuristic_matrix / max_heuristic\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP) using a combination of factors.\n\n    This function calculates a heuristic matrix where each element indicates how promising\n    it is to include the corresponding edge in a TSP solution. It combines inverse distance,\n    nearest neighbor information, and a random component.  The heuristic matrix is then\n    sparsified by setting less promising values to zero.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances between cities.\n\n    Returns:\n        np.ndarray: A heuristic matrix of the same shape as the distance matrix,\n                      indicating the desirability of including each edge in a TSP solution.\n                      Higher values indicate more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance: shorter distances are generally better\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # 2. Nearest neighbor heuristic: prioritize connecting to nearest neighbors\n    for i in range(n):\n        # Find the indices of the k-nearest neighbors for node i, excluding itself\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:4] #Top 3 nearest neighbors\n\n        # Boost the heuristic value for edges connecting to nearest neighbors\n        for neighbor in nearest_neighbors:\n            heuristic_matrix[i, neighbor] *= 2.0 # boost, but only if the neighbor is not itself\n\n\n    # 3. Random perturbation: Introduce some randomness to avoid getting stuck in local optima\n    random_matrix = np.random.rand(n, n) * 0.1 # small random numbers\n    heuristic_matrix += random_matrix\n\n    # 4. Sparsification: Remove less promising edges to reduce search space\n    threshold = np.quantile(heuristic_matrix[heuristic_matrix > 0], 0.2)  # Keep top 80% edges\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Ensure that diagonal elements are zero, as they represent self-loops\n    np.fill_diagonal(heuristic_matrix, 0)\n\n    return heuristic_matrix\n\n[Reflection]\nPrioritize nearest neighbors, add randomness, and sparsify based on quantiles for better exploration.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}