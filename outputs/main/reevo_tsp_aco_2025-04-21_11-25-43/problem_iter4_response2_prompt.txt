{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristic function for the Traveling Salesman Problem (TSP).\n\n    This version refines the heuristics by incorporating global distance normalization,\n    dynamic sparsification based on percentiles, and a node degree penalty based on\n    neighbor counts, aiming for better exploration and solution quality.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where `distance_matrix[i, j]`\n            represents the distance between node `i` and node `j`.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as `distance_matrix`, where each\n            element indicates the heuristic value (promise) of including the\n            corresponding edge in a TSP solution. Higher values indicate a more\n            promising edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse Distance (primary factor)\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero\n\n    # 2. Node Degree Penalty using Neighbor Counts\n    neighbor_counts = np.sum(heuristic_matrix > 0, axis=0)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] /= (neighbor_counts[i] + neighbor_counts[j] + 1e-9)  # Penalize based on number of existing connections\n\n    # 3. Global Distance Normalization\n    average_distance = np.mean(distance_matrix[distance_matrix != np.inf])\n    heuristic_matrix *= (average_distance / (np.mean(distance_matrix) + 1e-9))  # Scale based on average\n\n    # 4. Dynamic Sparsification based on Percentiles\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 40) # Dynamic Sparsity: consider only top 60%\n    heuristic_matrix[heuristic_matrix < threshold] = 0.0  # Set low-promise edges to zero\n\n    return heuristic_matrix\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics function for the Traveling Salesman Problem (TSP).\n\n    This version combines several factors to estimate the desirability of each edge:\n    - Inverse distance: Shorter edges are generally preferred.\n    - Node degree:  Avoids edges that would lead to high-degree nodes early on.  (Not directly implemented due to lack of intermediate state)\n    - Sparsification: Sets the least promising edges to zero to focus the search.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n\n    # Compute row and column means of distances (proxy for node proximity to others)\n    row_means = np.mean(distance_matrix, axis=1, keepdims=True)\n    col_means = np.mean(distance_matrix, axis=0, keepdims=True)\n\n\n    # Combine factors\n    heuristics = inverse_distance / (row_means + col_means.T + 1e-9)\n\n\n    # Sparsification: Keep only top k edges for each node\n\n    k = max(1, int(np.sqrt(n))) # adaptive k depending on the size of n, no less than 1\n    for i in range(n):\n        row = heuristics[i, :]\n        indices = np.argpartition(row, -k)[-k:] #find indices of k largest\n        mask = np.ones(n, dtype=bool)\n        mask[indices] = False\n        heuristics[i, mask] = 0\n\n    # Normalize rows to create probabilities\n    row_sums = heuristics.sum(axis=1, keepdims=True)\n    heuristics = np.nan_to_num(heuristics / row_sums)  # Handle possible division by zero\n\n    return heuristics\n\n[Reflection]\nThe better code uses local normalization (row/column means) and adaptive sparsification, crucial for TSP heuristic design.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}