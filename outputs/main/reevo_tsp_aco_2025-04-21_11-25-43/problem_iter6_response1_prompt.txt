{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n[Worse code]\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics function for the Traveling Salesman Problem (TSP).\n\n    This version combines several factors to estimate the desirability of each edge:\n    - Inverse distance: Shorter edges are generally preferred.\n    - Node degree: Uses row and column means to discourage edges to already \"central\" nodes.\n    - Adaptive Sparsification: Keeps only the top k edges for each node, where k scales with the problem size.\n    - Probability Normalization: Normalizes heuristic values to create edge selection probabilities.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n\n    # Compute row and column means of distances (proxy for node proximity to others)\n    row_means = np.mean(distance_matrix, axis=1, keepdims=True)\n    col_means = np.mean(distance_matrix, axis=0, keepdims=True)\n\n    # Combine factors: inverse distance, node degree proxy (using row/col means)\n    heuristics = inverse_distance / (row_means + col_means.T + 1e-9)\n\n    # Adaptive Sparsification: Keep only top k edges for each node\n    k = max(1, int(np.sqrt(n)))  # adaptive k depending on the size of n, no less than 1\n    for i in range(n):\n        row = heuristics[i, :]\n        indices = np.argpartition(row, -k)[-k:]  # find indices of k largest\n        mask = np.ones(n, dtype=bool)\n        mask[indices] = False\n        heuristics[i, mask] = 0\n\n    # Probability Normalization: Normalize rows to create probabilities\n    row_sums = heuristics.sum(axis=1, keepdims=True)\n    heuristics = np.nan_to_num(heuristics / row_sums)  # Handle possible division by zero\n\n    return heuristics\n\n[Better code]\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for TSP based on adaptive, dynamic sparsification, degree centrality,\n    and randomness, with refined parameter tuning and normalization.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Initialize heuristic matrix with inverse distance\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)\n\n    # Node degree centrality heuristic\n    degree_centrality = np.sum(1 / (distance_matrix + 1e-9), axis=1)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] *= (degree_centrality[i] + degree_centrality[j]) / 2\n\n    # Adaptive sparsification with dynamic threshold\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                nearest_neighbors_indices = np.argsort(distance_matrix[i, :])[1:6]  # Top 5 nearest neighbors\n                avg_neighbor_distance = np.mean(distance_matrix[i, nearest_neighbors_indices])\n                dynamic_threshold = 2.0 * avg_neighbor_distance  # Tuned multiplier\n\n                if distance_matrix[i, j] > dynamic_threshold:\n                    heuristic_matrix[i, j] *= 0.1  # Reduced penalty compared to v1; encourages exploration\n\n    # Incorporate randomness\n    randomness_factor = 0.05  # Reduced randomness strength for more stable exploitation\n    random_matrix = np.random.rand(n, n) * randomness_factor\n    heuristic_matrix += random_matrix\n\n    # Enhanced normalization and scaling\n    heuristic_matrix = heuristic_matrix / (distance_matrix + 1e-9)**0.5 # Adjusted exponent\n    max_val = np.max(heuristic_matrix)\n    min_val = np.min(heuristic_matrix)\n\n    if max_val > min_val:\n        heuristic_matrix = (heuristic_matrix - min_val) / (max_val - min_val) # Proper normalization\n    else:\n        heuristic_matrix = np.ones_like(heuristic_matrix) * 0.5\n\n    return heuristic_matrix\n\n[Reflection]\nSparsification, dynamic thresholds, degree centrality, and controlled randomness improve TSP heuristics.\n\n\n[Improved code]\nPlease write an improved function `heuristics_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}