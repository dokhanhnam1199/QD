```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Sigmoid Fit Score.

    This heuristic prioritizes bins that can accommodate the item while leaving a
    small remaining capacity, using a sigmoid function to model this preference.
    Bins that can barely fit the item (leaving very little remaining capacity)
    will have a higher priority score.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # Calculate remaining capacity if the item is placed in the bin
    # For bins that cannot fit, set remaining capacity to a very large number
    # so they don't get a high priority from the sigmoid.
    remaining_caps_if_fit = np.where(can_fit_mask, bins_remain_cap - item, np.inf)

    # The Sigmoid Fit Score strategy aims to keep remaining capacity small after packing.
    # We want to prioritize bins where `remaining_caps_if_fit` is small.
    # A sigmoid function is useful here. A common choice is 1 / (1 + exp(-k*(x - x0))),
    # where we want high values for small 'x'.
    # To achieve this, we can use `exp(-k*x)` or `1 / (1 + exp(k*x))`.
    # Let's map the remaining capacity to a score where smaller remaining capacity gets a higher score.
    # A common sigmoid form is to have values closer to 1 for favorable conditions.
    # We can use `1 / (1 + exp(k * (x - x0)))` where x is `remaining_caps_if_fit`.
    # We want smaller `x` (remaining_caps_if_fit) to result in higher scores.
    # Let's tune parameters. A simple approach is to use a negative scaling for remaining capacity.
    # A good candidate for `k` would be related to the typical item sizes or bin capacities.
    # A large positive `k` will make the sigmoid steeper, prioritizing very tight fits more strongly.
    # Let's choose a scaling factor `k` and a center `x0` for the sigmoid.
    # For instance, we might want bins with remaining capacity around 0 to have the highest score.
    # A simplified approach: transform remaining capacity such that smaller values are mapped to larger scores.
    # We can use `exp(-alpha * remaining_caps_if_fit)` for some positive `alpha`.
    # To make it more sigmoid-like and bounded, consider `1 / (1 + exp(alpha * (remaining_caps_if_fit - threshold)))`.
    # If remaining_caps_if_fit is 0, score is 1. If it's large, score approaches 0.
    # A value of `alpha` around 1 or 2, and `threshold` around 5-10 could be reasonable starting points,
    # depending on the typical range of `bins_remain_cap`.

    # Let's use a sigmoid centered around a small positive value to prioritize near-perfect fits.
    # For simplicity and effectiveness in many scenarios, let's use a transformation that
    # gives higher scores to bins with smaller remaining capacity after placing the item.
    # We can use `1 - (remaining_caps_if_fit / max_possible_remaining_capacity)`. This is linear.
    # For a sigmoid approach, let's try `exp(-k * remaining_caps_if_fit)`.
    # This will produce higher scores for smaller remaining capacities.
    # To avoid overflow with large remaining capacities and to bound the scores,
    # we can normalize or use a specific sigmoid formulation.

    # Let's define a sigmoid function where higher score is better for smaller remaining capacity.
    # f(x) = 1 / (1 + exp(k*x)) where x is remaining capacity.
    # This gives a score of 1 for x=0 and approaches 0 for large x.
    # We need to choose `k` appropriately. A larger `k` means a sharper drop-off.
    # Let's set k = 0.5 as a starting point.
    k = 0.5
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Apply sigmoid only to bins that can fit the item
    # For bins that can fit, calculate priority score
    fitting_bins_remaining_caps = remaining_caps_if_fit[can_fit_mask]

    # Calculate sigmoid scores for fitting bins
    # To ensure numerical stability and prevent extremely small values for very large remaining capacities,
    # we can clip the `fitting_bins_remaining_caps` or scale them.
    # A simple approach is `np.exp(-k * fitting_bins_remaining_caps)`.
    # This function decreases as remaining capacity increases.

    # Let's refine the sigmoid idea to be more about "how well it fits"
    # we want to favor bins that leave minimal space, but not negative space.
    # A suitable sigmoid could be related to the proportion of remaining capacity.
    # However, the core idea of Sigmoid Fit Score is to favor bins that leave a small gap.

    # Let's use a Sigmoid centered around a target remaining capacity, e.g., 0.
    # `sigmoid(x) = 1 / (1 + exp(-k * x))`
    # If `x` is the remaining capacity, we want small `x` to have high values.
    # So, `sigmoid(-k * x)` or `1 / (1 + exp(k * x))` where `k > 0`.

    # Let's use `1 / (1 + exp(k * (remaining_capacity)))`.
    # This gives 1 for remaining_capacity=0 and approaches 0 for large remaining_capacity.
    # The parameter `k` controls the steepness of the sigmoid. A larger `k` emphasizes smaller gaps.
    # We can tune `k`. A common heuristic is to relate `k` to the average item size or bin capacity.
    # Let's pick a fixed `k` for this example.

    # Ensure `fitting_bins_remaining_caps` are not excessively large which might cause `exp` overflow if `k` were negative,
    # or underflow to zero if `k` is positive and values are large.
    # Given our choice of `1 / (1 + exp(k * x))`, large positive `x` will lead to scores near 0.
    # This is what we want.

    # Calculate priority scores for bins that can fit the item.
    # `np.exp(k * fitting_bins_remaining_caps)` can become very large if `fitting_bins_remaining_caps` is large,
    # leading to `1 / large_number` which is close to 0. This is okay.
    # If `fitting_bins_remaining_caps` is very small or negative (which shouldn't happen here due to the mask),
    # it could cause issues.

    # Let's calculate priorities for the fitting bins:
    # For numerical stability, especially if remaining_caps_if_fit are small (close to 0),
    # `k * fitting_bins_remaining_caps` will be small.
    # `exp(small_positive)` is slightly > 1. `exp(0)` is 1.
    # `1 / (1 + exp(k * remaining_capacity))` will be close to 0.5 if remaining capacity is around 0.
    # This doesn't seem to prioritize minimal remaining capacity strongly enough with this form directly.

    # Alternative sigmoid formulation:  We want high values for small `remaining_caps_if_fit`.
    # Consider `sigmoid_score = exp(-k * remaining_caps_if_fit)`.
    # This gives values close to 1 for small remaining capacity, and values close to 0 for large remaining capacity.
    # This directly maps smaller remaining capacity to higher scores.
    # We can normalize this or use it as is. A simple `exp(-k * x)` doesn't provide the S-shape benefit of sigmoid directly.

    # Let's try to map `remaining_caps_if_fit` to a score where smaller values get higher scores.
    # A scaled `1 - (remaining_caps_if_fit / MAX_REMAINING)` is linear.
    # For a sigmoid, we can use: `scores = 1 / (1 + np.exp(k * (remaining_caps_if_fit - target)))`
    # Here, `target` would be a small number, e.g., 0.
    # So, `scores = 1 / (1 + np.exp(k * remaining_caps_if_fit))`
    # If `remaining_caps_if_fit` is 0, score is 0.5. If `remaining_caps_if_fit` is large, score is near 0.
    # This also doesn't seem right for prioritizing *minimal* remaining capacity.

    # Let's re-read "Sigmoid Fit Score strategy". It implies favoring bins where the remaining capacity is *just enough*
    # or leaves a small gap.
    # This usually means we want to avoid bins that leave *too much* space.
    # So, a bin with remaining capacity `r` and item `i` -> new remaining capacity `r-i`.
    # We prefer `r-i` to be small, but non-negative.
    # High priority for `r-i` close to 0.
    # This suggests a function that peaks at 0 for `r-i`.

    # A suitable sigmoid formulation: `score = 1 / (1 + exp(k * (remaining_capacity)))`
    # Let's test values:
    # If remaining_capacity = 0, score = 1 / (1 + exp(0)) = 0.5
    # If remaining_capacity = 1, score = 1 / (1 + exp(k))
    # If remaining_capacity = 10, score = 1 / (1 + exp(10k))
    # For large `k`, score drops fast. For small `k`, it drops slow.
    # This means smaller `remaining_capacity` leads to higher scores, as `exp(k*x)` grows with x.

    # Let's try to shift the sigmoid. We want peaks near 0.
    # What if we define the score relative to the item size?
    # `score_component = item / bins_remain_cap` (for bins that fit)
    # This would favor bins where the item takes up a larger proportion of the bin's capacity.
    # Then, we can apply a sigmoid to this proportion.
    # Proportion `p = item / bins_remain_cap`. We want `p` to be close to 1.
    # Sigmoid: `1 / (1 + exp(-k * (p - p0)))`.
    # Here, `p0` would be the target proportion, ideally close to 1. Let `p0=0.9`.
    # `score = 1 / (1 + exp(-k * (item / bins_remain_cap - 0.9)))`

    # Let's stick to the remaining capacity directly.
    # The problem is to select a bin for an item. Higher priority is better.
    # If `r` is remaining capacity, `r-i` is new remaining capacity.
    # We want `r-i` to be small.
    # Let's define a function `f(x)` where `x = r-i`.
    # We want `f(x)` to be high when `x` is small.
    # Sigmoid `g(y) = 1 / (1 + exp(-y))`.
    # We can use `f(x) = g(-k*x) = 1 / (1 + exp(k*x))` with `k>0`.
    # Let's set `k=1`.

    # We need to apply this to bins that can fit.
    # Calculate `remaining_caps_if_fit`.
    # Apply sigmoid: `sigmoid_scores = 1 / (1 + np.exp(k * remaining_caps_if_fit))`

    # To normalize scores or adjust the scale, we can scale `remaining_caps_if_fit`.
    # For example, `scaled_remaining = remaining_caps_if_fit / MAX_REMAINING_POSSIBLE`.
    # Then `sigmoid_scores = 1 / (1 + np.exp(k * scaled_remaining))`.
    # What is `MAX_REMAINING_POSSIBLE`? It could be the bin capacity, or the max of `bins_remain_cap`.
    # A simple heuristic: just use `remaining_caps_if_fit` and tune `k`.

    # Let's define `k` to be a factor that influences how aggressively we seek tight fits.
    # A common approach for "best fit" type heuristics (which this resembles) is to favor the smallest gap.
    # Let's use `k=0.5` as a starting point, and let the scores be computed.
    # For bins that cannot fit, their priority is 0.

    k = 0.5
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Calculate remaining capacities for bins that can fit the item
    remaining_capacities_for_fitting_bins = bins_remain_cap[can_fit_mask] - item

    # Apply the sigmoid function: higher score for smaller remaining capacity
    # We use 1 / (1 + exp(k * x)) where x = remaining_capacity.
    # A small remaining_capacity (close to 0) leads to exp(0) = 1, so score = 0.5.
    # A larger remaining_capacity leads to exp(large positive), so score approaches 0.
    # This formulation actually prioritizes bins that leave *more* space after fitting if k > 0.

    # Let's flip the logic. We want high scores for SMALL remaining capacity.
    # The function `exp(-k * x)` achieves this.
    # Or `1 - sigmoid(x)`? No.
    # The most straightforward "Sigmoid Fit Score" aims for a steep increase in priority
    # as the remaining capacity approaches zero.
    # A function like `1 - (x / MAX_CAP)` is linear best fit.
    # A sigmoid: `1 / (1 + exp(k * (x - target)))`. If `target` is 0, and `k` is positive,
    # then as `x` increases, `exp(k*x)` increases, `1/(1+exp)` decreases.
    # This means bins with HIGHER remaining capacity get higher scores. This is "worst fit".

    # For "best fit" (minimal remaining capacity):
    # We want the function to be high for small `x` (remaining capacity).
    # Let's use `f(x) = exp(-k * x)`.
    # With `k=0.5`:
    # x=0 -> score = 1
    # x=1 -> score = exp(-0.5) ~ 0.606
    # x=5 -> score = exp(-2.5) ~ 0.082
    # This works! High score for low remaining capacity.

    # Calculate priorities using `exp(-k * remaining_capacity)` for fitting bins.
    # We need to ensure `k` is chosen such that the scores are informative.
    # The range of `remaining_capacities_for_fitting_bins` could be large.
    # If `remaining_capacities_for_fitting_bins` can be very large, `exp(-k * large)` can underflow to 0.
    # This is generally acceptable for priority scores.

    priorities[can_fit_mask] = np.exp(-k * remaining_capacities_for_fitting_bins)

    # Ensure no NaNs or Infs if item size is exactly 0 or capacities are negative (though should not happen in BPP)
    # If item is 0, remaining capacity is bin_remain_cap. exp(-k * bin_remain_cap) will be between 0 and 1.
    # `can_fit_mask` handles cases where item is larger than bin capacity.

    return priorities

```
