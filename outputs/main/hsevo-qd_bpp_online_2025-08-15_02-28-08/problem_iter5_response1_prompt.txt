{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\n\n    In First Fit, the item is placed in the first bin that has enough remaining capacity.\n    This heuristic prioritizes bins that can accommodate the item and gives higher\n    priority to bins that have just enough capacity to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    # Assign a high priority to bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = 1.0\n\n    # Among those that can fit, prioritize bins that have just enough capacity.\n    # This is a greedy approach to minimize wasted space in the selected bin.\n    # We can use the inverse of the remaining capacity minus the item size as a measure\n    # of how \"tight\" the fit is. Smaller difference means higher priority.\n    tight_fit_scores = np.where(can_fit_mask, bins_remain_cap - item, np.inf)\n    \n    # Normalize the tight fit scores to avoid overly large or small values.\n    # Add a small epsilon to avoid division by zero if all differences are the same.\n    min_tight_fit = np.min(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 0\n    max_tight_fit = np.max(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 1\n    \n    if max_tight_fit - min_tight_fit > 1e-9: # Avoid division by zero if all are the same\n        normalized_tight_fit = (tight_fit_scores - min_tight_fit) / (max_tight_fit - min_tight_fit)\n    else:\n        normalized_tight_fit = np.zeros_like(tight_fit_scores)\n    \n    # Invert to give higher priority to smaller differences (tighter fits)\n    inverted_normalized_tight_fit = 1.0 - normalized_tight_fit\n    \n    # Combine the \"can fit\" priority with the \"tight fit\" priority.\n    # We want to boost bins that fit and then order them by tightness.\n    # The \"+ 0.1\" ensures that bins that can fit are always prioritized over those that cannot,\n    # even if their tight fit score is very high (which shouldn't happen if they can't fit).\n    priorities = np.where(can_fit_mask, 1.0 + inverted_normalized_tight_fit * 0.1, 0)\n    \n    # Ensure that bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n### Analyze & experience\n- *   **Comparing Heuristic 1 (Priority v2) vs. Heuristic 2 (Priority v2):**\n    *   Heuristic 1 attempts to normalize the \"tightness\" of the fit by calculating `(bins_remain_cap - item)`, finding min/max differences, and then normalizing. It then inverts this normalized score to give higher priority to tighter fits. It also adds a small boost (+ 0.1) to these scores to differentiate them from bins that cannot fit.\n    *   Heuristic 2 calculates `diffs = eligible_capacities - item`, finds the `min_diff`, and then assigns priority as `1.0 / (diffs - min_diff + 1e-9)`. This also aims to prioritize tighter fits by giving higher scores to smaller differences relative to the minimum difference.\n    *   **Observation:** Both heuristics aim to prioritize bins with less excess capacity. Heuristic 1's normalization is more complex, potentially more stable across different scales of differences, but might be overkill. Heuristic 2 is simpler and directly emphasizes the bins closest to the minimum excess.\n\n*   **Comparing Heuristic 3 (Exact Fit First) vs. Heuristic 4 (Priority v2):**\n    *   Heuristic 3 explicitly prioritizes bins that *exactly* fit (`bins_remain_cap == item`) with a score of `1.0`. If no exact fit exists, it falls back to prioritizing bins with the least remaining capacity that *can* fit, using an inverse of the excess capacity, normalized.\n    *   Heuristic 4 is identical to Heuristic 2, focusing solely on inverse difference from minimum excess capacity for all fitting bins, without an explicit \"exact fit\" priority level.\n    *   **Observation:** Heuristic 3 provides a distinct, higher priority for exact fits, which is a common and effective strategy in bin packing. Heuristic 4 treats exact fits the same as other close fits, potentially overlooking the benefit of perfect utilization.\n\n*   **Comparing Heuristic 5 (Inverse Distance) vs. Heuristic 8 (Loop-based Inverse Distance):**\n    *   Heuristic 5 calculates `space_after_placement = bins_remain_cap - item`, assigns `1 / (space_after_placement + epsilon)` for fitting bins, and `-np.inf` for non-fitting bins. This directly favors bins with minimal positive `space_after_placement`.\n    *   Heuristic 8 uses a loop to iterate through bins, achieving the same logic: `1.0 / (bins_remain_cap[i] - item + 1e-9)` for fitting bins, `0.0` otherwise.\n    *   **Observation:** Heuristic 5 is more concise and leverages NumPy's vectorized operations, making it more efficient and Pythonic than the explicit loop in Heuristic 8. Both implement the same core \"inverse distance\" or \"best fit\" logic.\n\n*   **Comparing Heuristic 9 (Exact Fit + Scaled Inverse Distance) vs. Heuristic 14 (Exact Fit + Scaled Inverse Difference):**\n    *   Heuristic 9 assigns `1.0` for exact fits. For non-exact fits, it calculates `inverse_distance_scores = 1.0 / (space_after_placement + epsilon)`, normalizes these scores to a range of `[0.5, 0.99]`, ensuring they are lower than exact fits.\n    *   Heuristic 14 assigns `2.0` for exact fits (even higher priority). For non-exact fits, it calculates `space_after_placement`, normalizes it (`1.0 - normalized_diff`), and adds `0.1`, resulting in scores between `0.1` and `1.1` (before considering the `2.0` for exact fits). The scaling is different: Heuristic 9 scales the inverse of the difference, while Heuristic 14 scales the normalized difference itself (then inverts).\n    *   **Observation:** Both combine exact fits with a \"best fit\" approach. Heuristic 14's use of `2.0` for exact fits creates a clearer hierarchy. Its normalization `1.0 - normalized_diff + 0.1` aims to prioritize smaller differences. Heuristic 9's approach of scaling inverse distance to `[0.5, 0.99]` is also a reasonable way to create a distinct priority band for close fits.\n\n*   **Comparing Heuristic 16/17/18 (Sigmoid Fit Score) vs. Heuristic 19 (Exact Fit + Best Fit):**\n    *   Heuristics 16-18 use a sigmoid function applied to `item / available_caps` with a threshold (`0.7`) and steepness (`10.0`). This aims to favor bins where the item takes up a significant portion of the remaining capacity, but not necessarily the absolute tightest fit. It penalizes bins that are too large.\n    *   Heuristic 19 prioritizes exact fits (`1.0`), then uses normalized inverse of space after placement for non-exact fits, scaled to `[0, 0.9]`. This focuses on minimal excess space for non-exact fits.\n    *   **Observation:** The sigmoid approach (16-18) is more complex and might be trying to find a balance point, not just the absolute closest fit. The prioritization based on `item / available_caps` is an interesting way to avoid bins that are *too* large. Heuristic 19 is a more direct combination of exact and best fit.\n\n*   **Comparing Heuristic 2 (Inverse Distance) vs. Heuristic 8 (Loop-based Inverse Distance):**\n    *   Heuristic 2: `priorities[eligible_bins] = 1.0 / (diffs - min_diff + 1e-9)`\n    *   Heuristic 8: `priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)`\n    *   **Observation:** Heuristic 2 is superior because it normalizes the inverse distance relative to the minimum difference. This prevents bins with extremely large capacities (but still fitting) from getting disproportionately high scores simply because their raw difference `(capacity - item)` is large, even if it's closer to the minimum difference than others. Heuristic 8's scores can be highly skewed by large capacities.\n\n*   **Comparing Heuristic 1 (Normalized Tight Fit) vs. Heuristic 2 (Inverse Difference from Min Diff):**\n    *   Heuristic 1 attempts to normalize the `(capacity - item)` difference to a `[0, 1]` range and then applies `1.0 - normalized_tight_fit`. It also adds `0.1` and a base `1.0` for fitting bins.\n    *   Heuristic 2 uses `1.0 / (diffs - min_diff + 1e-9)`.\n    *   **Observation:** Heuristic 2 is simpler and more direct in prioritizing the *smallest* differences relative to the minimum difference. Heuristic 1's normalization is more involved and the additive `0.1` seems less principled than a multiplicative scaling or direct inverse.\n\n*   **Overall:** Heuristics that explicitly prioritize exact fits (like 3, 9, 14, 19, 20) generally perform better because perfect utilization is a strong objective. Among those that focus on \"best fit\" (minimal excess capacity), prioritizing the inverse of the *difference from the minimum difference* (like Heuristic 2, 4) is more robust than simply taking the inverse of the difference (like Heuristic 8). Vectorized operations (like 1, 2, 5) are preferred over loops (like 8). Complex sigmoid functions (16-18) are less interpretable and may not offer clear advantages over simpler \"best fit\" or \"exact fit\" strategies without empirical validation.\n- \nHere's a redefined \"Current self-reflection\" for designing better heuristics, focusing on actionable improvements:\n\n*   **Keywords:** Robustness, Simplicity, Efficiency, Interpretability.\n*   **Advice:** Develop scoring functions that are robust to capacity variations (e.g., by normalizing differences) and prioritize simple, interpretable metrics. Leverage vectorization for computational efficiency.\n*   **Avoid:** Overly complex, non-linear scoring functions requiring extensive tuning and obscure array manipulations.\n*   **Explanation:** Focusing on robust, simple metrics and efficient implementation leads to more reliable, maintainable, and adaptable heuristics, crucial for dynamic optimization problems.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}