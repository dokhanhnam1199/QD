```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a modified Best Fit Decreasing-like strategy.

    This heuristic prioritizes bins that have just enough space for the item,
    favoring a tighter fit to leave larger capacities in other bins for potentially
    larger future items.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # Calculate the difference between remaining capacity and item size
    diff = bins_remain_cap - item

    # Only consider bins where the item can fit (diff >= 0)
    # For bins where it can fit, the priority is calculated as follows:
    # We want to prioritize bins where the remaining capacity is *closest* to the item size.
    # This is achieved by taking the inverse of the difference, but we want to
    # avoid very small differences getting disproportionately high scores if they are
    # still larger than the item.
    # A common strategy is to use a transformation that amplifies smaller positive differences.
    # We can use a penalty for bins that have much more space than needed.
    # The idea is to reward bins that are "almost full" after packing.
    # We can use a sigmoid-like function or a simple inverse with a shift to control the
    # steepness of the priority change.

    # Let's try a simple approach:
    # Priority is higher for smaller positive differences.
    # We can use exp(-k * diff) where k is a scaling factor. A larger k means
    # the priority drops faster as the difference increases.
    # A good heuristic for k might be related to the average bin capacity or item size.
    # For simplicity and robustness, let's consider a smooth inverse where very
    # small positive differences get high scores, and larger differences get lower scores.
    # The original V1 used 1/(diff + epsilon). We want to modify this.

    # Let's try to give a high score when diff is close to 0.
    # A function like exp(-diff) or 1/(1 + diff) can work.
    # We want to prioritize bins that are *nearly* full after placing the item.
    # So, we want to maximize `bins_remain_cap - item`. No, we want to minimize it while it's non-negative.

    # Consider a function that is high when diff is small and positive.
    # And low when diff is large and positive.
    # An exponential decay: exp(-alpha * diff) could work.
    # Let's choose alpha to be a value that makes the priority drop reasonably fast
    # but still differentiates between similar small positive differences.
    # A heuristic for alpha could be related to the average item size or bin capacity.
    # For this example, let's use a fixed alpha that penalizes larger remaining capacities.
    alpha = 2.0  # This is a tunable parameter. A higher alpha makes the priority drop faster.
    epsilon = 1e-9 # To avoid issues with exactly zero differences.

    # Calculate priorities for bins where the item fits.
    # We use exp(-alpha * diff) for fitting bins.
    # The larger the remaining capacity (diff), the smaller the priority.
    # We use `bins_remain_cap - item` directly, but ensure it's non-negative.
    # Let's use the difference directly as it represents "slack". We want minimum slack.
    priorities = np.where(diff >= 0, np.exp(-alpha * diff), 0)

    # To ensure we don't have division by zero if all diffs are 0,
    # and to also boost scores for bins that are almost perfectly filled,
    # we can add a small constant or use a transformation that ensures
    # non-zero positive values.
    # If diff is 0, exp(0) = 1. If diff is small positive, exp(-small) is slightly less than 1.
    # This is good. We want high priority for bins that are almost full.

    # An alternative: 1 / (1 + diff). This also prioritizes smaller diffs.
    # priorities = np.where(diff >= 0, 1 / (1 + diff), 0)

    # Let's stick with the exponential decay for a smoother penalty for larger remaining capacities.
    # We can add a small constant to the priority to ensure that even bins with large
    # remaining capacity have *some* priority, though very low.
    # This can be useful if we want to ensure a bin is always picked if no other bin is available.
    # However, in this context, we explicitly want to penalize large remaining capacities.

    # Consider a slightly different approach to penalize large remaining capacities more strongly
    # while giving a significant boost to bins that are a near-perfect fit.
    # We can cap the difference or use a threshold.
    # However, sticking to "simplicity" and "interpretability" as per the advice:
    # The exp(-alpha * diff) is interpretable as a decay based on how much "extra" space there is.
    # The smaller the `diff`, the higher `exp(-alpha * diff)`.
    # When `diff` is 0, priority is 1. When `diff` is large, priority is close to 0.

    # Let's refine the priority calculation to ensure that if multiple bins have
    # the same minimal positive difference, they get ranked equally, and if a bin
    # is a perfect fit (diff=0), it gets the highest possible priority.
    # The current `np.exp(-alpha * diff)` does this.

    # If we want to prioritize bins that are closer to a *specific* target capacity,
    # we might normalize `diff`. But here, we want to prioritize the *tightest fit*.

    # A final check on interpretation:
    # `bins_remain_cap - item` is the "slack" or "waste" if we put the item in that bin.
    # We want to minimize slack.
    # `exp(-alpha * slack)` is a good way to do this, prioritizing bins with slack close to 0.

    return priorities
```
