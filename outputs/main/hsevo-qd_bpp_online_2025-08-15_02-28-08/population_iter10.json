[
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins with exact or near-exact fits using a ratio-based score.\n\n    This heuristic favors bins where the remaining capacity is as close as possible to\n    the item size, assigning higher scores to tighter fits.\n    \"\"\"\n    epsilon = 1e-9\n    \n    # Initialize priorities to zero for all bins\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the difference between remaining capacity and item size for fitting bins\n    diff = bins_remain_cap[can_fit_mask] - item\n    \n    # Calculate scores for bins where the item fits.\n    # The score is `bins_remain_cap / (diff + epsilon)`.\n    # This ratio emphasizes bins where `diff` is small (tight fits).\n    # For an exact fit (diff=0), the score becomes `bins_remain_cap / epsilon`, which is very high.\n    # For larger differences, the ratio tends to be smaller.\n    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask] / (diff + epsilon)\n    \n    return priorities",
    "response_id": 9,
    "tryHS": true,
    "obj": 3.9589150378939015,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    fit_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            fit_scores[i] = capacity - item\n        else:\n            fit_scores[i] = -np.inf\n\n    # Softmax-based priority: higher fit_score means lower priority (less remaining space)\n    # We want to favor bins with less remaining space to pack them tightly.\n    # So, we invert the fit_scores to make smaller differences (tighter fits) have higher \"utility\".\n    # A small positive value is added to avoid log(0) or exp(-inf).\n    utility_scores = -fit_scores + 1e-9\n\n    # Applying Softmax\n    exp_scores = np.exp(utility_scores - np.max(utility_scores))\n    probabilities = exp_scores / np.sum(exp_scores)\n\n    # Prioritize bins that can fit the item\n    priorities = np.where(bins_remain_cap >= item, probabilities, 0)\n    \n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    available_bins_mask = bins_remain_cap >= item\n    \n    if np.any(available_bins_mask):\n        available_bins_remain_cap = bins_remain_cap[available_bins_mask]\n        \n        sorted_indices = np.argsort(available_bins_remain_cap)\n        \n        priorities[available_bins_mask] = 1.0 / (available_bins_remain_cap - item + 1e-9)\n        \n        priorities[available_bins_mask] = np.argsort(np.argsort(priorities[available_bins_mask]))\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities",
    "response_id": 17,
    "tryHS": true,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a more sophisticated strategy.\n\n    This heuristic prioritizes bins that have just enough remaining capacity to fit the item,\n    while also considering bins that have significantly more capacity as a secondary factor.\n    It aims to reduce fragmentation by favoring tighter fits.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 1e-9\n    \n    # Calculate the difference between remaining capacity and item size\n    diff = bins_remain_cap - item\n    \n    # Initialize priorities to zero (for bins where the item doesn't fit)\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = diff >= 0\n    \n    # For bins where the item fits, calculate a priority score.\n    # The primary goal is to find bins with a small positive difference (tightest fit).\n    # We use an inverse of (difference + epsilon) for tighter fits to give them higher scores.\n    # We also add a small bonus for bins with much larger remaining capacity to not\n    # completely discard them if no tight fit is available. This bonus is smaller.\n    \n    # Calculate inverse difference for tight fits: higher score for smaller positive difference\n    tight_fit_scores = 1 / (diff[can_fit_mask] + epsilon)\n    \n    # Calculate a secondary score for bins with more remaining capacity than the item size.\n    # This is a simpler inverse of remaining capacity, scaled down.\n    # We want to avoid division by zero for bins with zero remaining capacity if they exist (though item wouldn't fit)\n    # and to give some priority to larger bins if no tight fit is available.\n    # Using the original bins_remain_cap for this secondary scoring.\n    \n    # We can normalize the remaining capacities to get a sense of \"how much space\" is left relative to bin capacity.\n    # However, since we don't have the original bin capacity, we can use a heuristic.\n    # Let's simply use the remaining capacity itself, but scaled.\n    # A simpler approach without original bin capacity is to just use the inverse of difference for those that fit.\n    \n    # Let's refine the logic:\n    # Priority 1: Bins with smallest positive `diff` (tightest fit). This is `1 / (diff + epsilon)`.\n    # Priority 2: Bins with larger `diff`. These are less preferred than tight fits.\n    # A simple way to combine is to give a high score to tight fits and a moderate score to larger fits.\n    \n    # Let's use a piecewise approach for scoring:\n    # For bins that fit:\n    # If diff is very small (e.g., diff < threshold), assign a high priority (e.g., 100 + 1/diff).\n    # If diff is larger, assign a lower priority (e.g., 10 + 1/diff).\n    # This requires tuning `threshold`.\n    \n    # A more robust approach without arbitrary thresholds:\n    # We want to maximize `1/(diff + epsilon)` for tight fits and still assign some score to larger fits.\n    # Consider the ratio of remaining capacity to item size.\n    \n    # Let's try scoring based on inverse difference, and then add a penalty for \"too much\" space.\n    # Or, simply, prioritize bins where `bins_remain_cap` is \"close\" to `item`.\n    \n    # Let's use a score that is high for small positive differences and decreases as the difference grows.\n    # A Gaussian-like function centered around 0 (for `diff`) could work, but it's complex.\n    \n    # Simpler idea: prioritize bins that have *just enough* space.\n    # We can define \"just enough\" as being within a certain percentage of the item size.\n    # For example, if diff is between 0 and `item * tolerance`.\n    \n    # Let's revisit the inverse distance, but modify it to be more sensitive to small differences.\n    # A score that is high for small `diff` and then drops off.\n    # Consider `score = 1 / (diff^2 + epsilon)` or `score = exp(-k * diff)`\n    \n    # Let's try a score that emphasizes the \"tightness\" by squaring the inverse of the difference.\n    # This will amplify the priority for very tight fits.\n    \n    # Calculate the inverse of difference for bins that can fit the item\n    # For bins where it can fit, the priority is proportional to 1 / (difference + epsilon)\n    # We want to boost the priority for smaller differences more significantly.\n    # Let's use (1 / (diff + epsilon))^2 for a stronger emphasis on tightness.\n    \n    # This still might give a very small positive difference a disproportionately high score.\n    \n    # Alternative: Focus on the ratio of remaining capacity to item size.\n    # Bins with `bins_remain_cap / item` close to 1 are good.\n    # Ratio = bins_remain_cap / item. We want ratio ~ 1.\n    # Score could be proportional to `1 / abs(ratio - 1)`.\n    # However, this doesn't account for the absolute amount of space. A bin with 10 capacity\n    # and item 9 (ratio 1.11) is better than bin with 100 capacity and item 9 (ratio 1.01)\n    # if we only consider this ratio. We need to combine it.\n    \n    # Let's stick to the difference but prioritize small positive differences more strongly.\n    # A function like `f(x) = 1/(x+epsilon)` is already good.\n    # What if we add a small bonus for bins that have \"plenty\" of space, but significantly less than tight fits?\n    \n    # Let's try to make it more robust to scale by normalizing.\n    # If we knew the maximum bin capacity, we could normalize. Without it, it's hard.\n    \n    # Back to basics, `priority_v1` favors bins with largest remaining capacity among those that fit.\n    # `1 / (diff + epsilon)` favors bins with smallest `diff`. This is generally good.\n    \n    # How to improve:\n    # 1. Give stronger weight to *very* tight fits.\n    # 2. Ensure that bins that are *almost* full but still fit are prioritized over bins that are nearly empty but fit.\n    \n    # Let's try a compound score:\n    # Score1: Inverse difference (prioritizes tight fits)\n    # Score2: A small bonus for bins that are not too empty, scaled by how much they can fit.\n    \n    # For bins that can fit:\n    # `tight_fit_score = 1 / (diff + epsilon)`\n    \n    # Now, consider the \"emptiness\" of the bin if it fits.\n    # A bin that has `bins_remain_cap` close to `item` is good.\n    # A bin that has `bins_remain_cap` much larger than `item` is less ideal in terms of fragmentation.\n    \n    # Let's define a score that peaks at `diff = 0` (or slightly negative) and decreases.\n    # However, we only consider `diff >= 0`. So we want it to peak at `diff = 0`.\n    \n    # Consider a function that is `1/(diff + epsilon)` for tight fits, and maybe a constant or decaying function for larger fits.\n    \n    # Let's try a score that emphasizes \"just enough\" space more, and \"plenty\" of space less.\n    # If `diff` is small (e.g., < `item / 2`), give it a higher score.\n    # If `diff` is large (e.g., > `item / 2`), give it a lower score.\n    \n    # Let's normalize `diff` relative to the item size.\n    # `normalized_diff = diff / item` (if item > 0)\n    # We want `normalized_diff` close to 0.\n    \n    # Score = `1 / (normalized_diff + epsilon)` for `normalized_diff >= 0`\n    # This is equivalent to `item / (bins_remain_cap - item + epsilon)` which is similar to `priority_v1` but normalized.\n    \n    # Let's try to blend the inverse difference with a penalty for being too \"empty\".\n    # A bin that fits has `bins_remain_cap >= item`.\n    # If `bins_remain_cap` is much larger than `item`, it's \"too empty\".\n    \n    # Let's use a score based on how much of the remaining capacity is *used* by the item.\n    # If `bins_remain_cap` is very close to `item`, then `item / bins_remain_cap` is close to 1.\n    # If `bins_remain_cap` is much larger than `item`, then `item / bins_remain_cap` is close to 0.\n    \n    # So, we want to prioritize bins where `item / bins_remain_cap` is close to 1.\n    # Score = `1 / abs((item / bins_remain_cap) - 1 + epsilon)`\n    # This can be written as `bins_remain_cap / abs(bins_remain_cap - item + epsilon)`.\n    # This is effectively `bins_remain_cap / (diff + epsilon)` for bins that fit.\n    \n    # Let's test this:\n    # item = 5\n    # bins_remain_cap = [10, 6, 20, 5.1]\n    # diff = [5, 1, 15, 0.1]\n    #\n    # priority_v1:\n    # 1/(5+eps) = 0.2\n    # 1/(1+eps) = 1.0\n    # 1/(15+eps) = 0.066\n    # 1/(0.1+eps) = 9.09\n    # Max priority for 5.1 remaining.\n    #\n    # New approach: `bins_remain_cap / (diff + epsilon)`\n    # 10 / (5+eps) = 2.0\n    # 6 / (1+eps) = 6.0\n    # 20 / (15+eps) = 1.33\n    # 5.1 / (0.1+eps) = 51.0\n    # Max priority for 5.1 remaining. This seems to amplify the preference for tight fits.\n    \n    # Let's implement this: `bins_remain_cap / (diff + epsilon)` for bins that fit.\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins where the item fits, calculate the priority score\n    # Prioritize bins where the remaining capacity is closest to the item size.\n    # Score is `bins_remain_cap / (bins_remain_cap - item + epsilon)`\n    # This is equivalent to `bins_remain_cap / (diff + epsilon)`\n    \n    # Add a small epsilon to bins_remain_cap to avoid division by zero if item == bins_remain_cap == 0,\n    # although can_fit_mask should prevent this for item > 0.\n    \n    # Ensure item is not zero to avoid division by zero in potential alternative calculations.\n    # In this case, we are using bins_remain_cap which is always non-negative.\n    \n    # The division `bins_remain_cap / (bins_remain_cap - item + epsilon)` can be large if `bins_remain_cap - item` is small.\n    # This correctly prioritizes tight fits.\n    \n    # Let's make sure the score is well-behaved.\n    # If `bins_remain_cap` is large, and `item` is small, `diff` is large.\n    # `bins_remain_cap / (diff + epsilon)` will be `large / large` -> moderate score.\n    # If `bins_remain_cap` is just slightly larger than `item`, `diff` is small.\n    # `bins_remain_cap / (diff + epsilon)` will be `~item / small` -> high score.\n    \n    # This seems like a good candidate for `priority_v2`.\n    \n    # Avoid division by zero if item is 0, though problem statement implies item > 0.\n    # If item is 0, any bin can fit it with infinite priority if `diff=0`.\n    # For item > 0, `bins_remain_cap` must be >= `item`.\n    \n    # Let's consider `bins_remain_cap - item`. If this is 0, the item perfectly fills the bin.\n    # In that case, `bins_remain_cap / epsilon` would be very large. This is desired.\n    \n    # Calculate the score for bins where the item fits\n    # Score = remaining_capacity / (remaining_capacity - item + epsilon)\n    # This is equivalent to: (item + diff) / (diff + epsilon)\n    # This ratio is maximized when `diff` is minimized (closest to 0).\n    \n    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask] / (diff[can_fit_mask] + epsilon)\n    \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.9589150378939015,
    "cyclomatic_complexity": 1.0,
    "halstead": 82.0447025077789,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    epsilon = 1e-9\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        diff = bins_remain_cap[can_fit_mask] - item\n        \n        # Score: Prioritize bins where the remaining capacity is closest to the item size.\n        # The score is calculated as: remaining_capacity / (remaining_capacity - item + epsilon)\n        # This can be rewritten as: (item + diff) / (diff + epsilon)\n        # This function is maximized when `diff` is minimized (i.e., a tight fit).\n        # For very tight fits (diff close to 0), the score becomes very high.\n        # For larger diffs, the score approaches 1.\n        # This prioritizes bins that are \"just enough\" to fit the item.\n        \n        scores = bins_remain_cap[can_fit_mask] / (diff + epsilon)\n        \n        # A small adjustment to slightly penalize bins that are excessively large if a tight fit exists.\n        # This could be a multiplicative factor or an additive one, but to keep it simple and effective,\n        # let's rely on the primary score's behavior. The current score already implicitly favors smaller available space\n        # when it's just enough.\n        \n        # For bins where the item fits, we want to maximize the ratio `bins_remain_cap / (bins_remain_cap - item)`.\n        # This is equivalent to `(item + diff) / (diff)`.\n        # Let's normalize `diff` by `item` to make the score less dependent on absolute scales.\n        # `normalized_diff = diff / item`\n        # Score = `(item + normalized_diff * item) / (normalized_diff * item + epsilon)`\n        # Score = `(1 + normalized_diff) / (normalized_diff + epsilon / item)`\n        # This makes the score proportional to `1 / normalized_diff` for small `normalized_diff`.\n        \n        # Let's refine the score to focus on the 'goodness' of the fit relative to the item size.\n        # We want bins where `bins_remain_cap` is just slightly larger than `item`.\n        # Consider `bins_remain_cap / item`. We want this ratio to be close to 1.\n        # A score like `1 / abs(bins_remain_cap / item - 1 + epsilon)` is good.\n        # This simplifies to `item / abs(bins_remain_cap - item + epsilon)`.\n        # For bins that fit (`bins_remain_cap >= item`), this is `item / (bins_remain_cap - item + epsilon)`.\n        # This is very similar to `bins_remain_cap / (bins_remain_cap - item + epsilon)` but normalized by item size.\n        \n        # Let's try to create a score that peaks at `diff = 0` and decreases.\n        # A simple approach is to use `1 / (diff + epsilon)`.\n        # To amplify the preference for *very* tight fits, we can use `1 / (diff^2 + epsilon)` or `exp(-k * diff)`.\n        \n        # Let's try a score that is high for tight fits and moderately high for larger fits,\n        # without completely favoring large bins unless no tight fits exist.\n        \n        # A more robust approach:\n        # Prioritize bins with minimal positive difference (`diff`).\n        # Then, among bins with similar small differences, pick the one with less remaining capacity.\n        \n        # Let's score bins based on `1 / (diff + epsilon)`. This gives higher scores to smaller `diff`.\n        # To differentiate further, consider the actual remaining capacity.\n        # If `diff` is small, `bins_remain_cap` is close to `item`.\n        # If `diff` is large, `bins_remain_cap` is much larger than `item`.\n        \n        # Let's try to combine \"tightness\" and \"utilization\".\n        # A good bin is one that fits tightly.\n        # Score = `1 / (diff + epsilon)` is a good start.\n        \n        # To make it more sensitive to *tight* fits and less sensitive to *very large* capacities,\n        # let's use `item / (diff + epsilon)`. This scales the priority by the item size.\n        # This is equivalent to `item / (bins_remain_cap - item + epsilon)`.\n        \n        # If item = 5, bins = [6, 10, 20]\n        # diff = [1, 5, 15]\n        #\n        # Current (v1) `1/(diff+eps)`: [1, 0.2, 0.06] -> Bin with 6 remaining cap wins.\n        # Proposed `item/(diff+eps)`: [5, 1, 0.33] -> Bin with 6 remaining cap wins.\n        \n        # What if we want to penalize bins that are too large?\n        # For example, if `bins_remain_cap` is more than `2 * item`.\n        \n        # Let's try a score that rewards bins that are \"just enough\" and penalizes bins that are \"too much\".\n        # Score = `1 / (diff + epsilon)` gives highest score for smallest `diff`.\n        # We can add a factor that decreases as `bins_remain_cap` increases beyond `item`.\n        \n        # Let's try `score = (1 / (diff + epsilon)) * (item / (bins_remain_cap + epsilon))`\n        # This combines the inverse difference with a factor that reduces score for larger remaining capacities.\n        \n        # If item = 5, bins = [6, 10, 20]\n        # diff = [1, 5, 15]\n        # v1: [1, 0.2, 0.06]\n        #\n        # New score:\n        # Bin 1 (rem=6, diff=1): (1/1) * (5/6) = 0.83\n        # Bin 2 (rem=10, diff=5): (1/5) * (5/10) = 0.1 * 0.5 = 0.05\n        # Bin 3 (rem=20, diff=15): (1/15) * (5/20) = 0.066 * 0.25 = 0.0165\n        \n        # This seems to penalize larger bins too aggressively, making it similar to First Fit Decreasing if items are sorted.\n        \n        # Let's go back to the idea of prioritizing tight fits, but ensure that if there are multiple tight fits,\n        # we prefer the one that leaves less residual space.\n        \n        # Consider a score that is a function of `diff` and `bins_remain_cap`.\n        # A common approach is to use `(bins_remain_cap - item)` as the primary criterion for tightness.\n        # We want to minimize `bins_remain_cap - item`.\n        \n        # Let's try a score that is higher for smaller `diff`, and among equal `diff`s, it doesn't matter much.\n        # The key is to make the score sensitive to small positive `diff`.\n        \n        # A score like `1 / (diff + epsilon)` is already good.\n        # To make it \"better\", we need to ensure it generalizes well.\n        \n        # Let's try to use the reciprocal of the \"waste\" if the item fits perfectly, or a scaled waste.\n        # For a tight fit, `bins_remain_cap` is close to `item`.\n        # Consider `score = bins_remain_cap / (bins_remain_cap - item + epsilon)`.\n        # This was explored before and seemed to amplify tight fits.\n        \n        # Let's try to make the score more focused on the *proportion* of remaining capacity used.\n        # For a bin to be ideal, `item / bins_remain_cap` should be close to 1.\n        # Score = `1 / abs(item / bins_remain_cap - 1 + epsilon)`\n        # Score = `bins_remain_cap / abs(bins_remain_cap - item + epsilon)`\n        # This is `bins_remain_cap / (diff + epsilon)` for bins that fit.\n        \n        # Let's consider a two-stage approach:\n        # 1. Favor bins with `diff` within a small range (e.g., `0 <= diff < threshold`).\n        # 2. Within that range, pick the bin with minimum `diff`.\n        # 3. If no bin is in that range, pick the bin with the minimum `diff` overall.\n        \n        # This can be encoded into a single score.\n        # Let's use a score that is very high for tight fits, and moderately high for larger fits.\n        \n        # A score that is proportional to `1 / (diff + epsilon)` is good for prioritizing tight fits.\n        # To make it \"better\", we can scale it by a factor that is less sensitive to extremely large capacities.\n        \n        # Let's try `score = (1 + item) / (diff + epsilon)`\n        # If item = 5, bins = [6, 10, 20]\n        # diff = [1, 5, 15]\n        #\n        # v1 `1/(diff+eps)`: [1, 0.2, 0.06]\n        # Proposed `(1+item)/(diff+eps)`:\n        # Bin 1 (rem=6, diff=1): (1+5) / 1 = 6\n        # Bin 2 (rem=10, diff=5): (1+5) / 5 = 1.2\n        # Bin 3 (rem=20, diff=15): (1+5) / 15 = 0.4\n        \n        # This seems to amplify the preference for tight fits even more strongly than `item / (diff + epsilon)`.\n        # It's essentially prioritizing bins with smaller `diff` and giving them a boost proportional to `item + 1`.\n        # This can be interpreted as: \"how much value does this bin's remaining space offer for fitting this item tightly?\"\n        \n        # Let's use `(bins_remain_cap + 1) / (diff + epsilon)`. This is slightly different.\n        # If item = 5, bins = [6, 10, 20]\n        # diff = [1, 5, 15]\n        #\n        # Proposed `(bins_remain_cap + 1) / (diff + epsilon)`:\n        # Bin 1 (rem=6, diff=1): (6+1) / 1 = 7\n        # Bin 2 (rem=10, diff=5): (10+1) / 5 = 11 / 5 = 2.2\n        # Bin 3 (rem=20, diff=15): (20+1) / 15 = 21 / 15 = 1.4\n        \n        # This score favors bins that are *closer* to the item size AND have *more* remaining capacity if the difference is the same.\n        # This is not ideal. We want to prioritize tight fits.\n        \n        # Let's stick to prioritizing tight fits. The score `bins_remain_cap / (diff + epsilon)` is a good candidate.\n        # It means we prefer bins where `bins_remain_cap / item` is close to 1.\n        # `bins_remain_cap / (bins_remain_cap - item + epsilon)`\n        # This is `(item + diff) / (diff + epsilon)`\n        \n        # Consider the goal: minimize the number of bins.\n        # This is achieved by packing items as tightly as possible.\n        # So, prioritize bins where `bins_remain_cap - item` is minimized and non-negative.\n        \n        # Let's consider a score that combines the 'tightness' `1/(diff + epsilon)` with a penalty for 'over-filling' if the bin is much larger.\n        # The score `bins_remain_cap / (diff + epsilon)` already tends to favor smaller remaining capacities if the difference is the same.\n        \n        # Final approach: Prioritize bins with the smallest positive difference.\n        # To make this robust, normalize the difference by the item size.\n        # Score = `1 / (diff / item + epsilon)` if `item > 0`.\n        # Score = `item / (diff + epsilon)` for `item > 0`.\n        # This emphasizes tight fits relative to the item's size.\n        \n        scores = item / (diff + epsilon)\n        \n        priorities[can_fit_mask] = scores\n    \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.9589150378939015,
    "cyclomatic_complexity": 2.0,
    "halstead": 64.52932501298082,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a Random Fit strategy for the online Bin Packing Problem.\n    Prioritizes bins that can fit the item. A higher priority is given\n    to bins with less remaining capacity that can still fit the item,\n    encouraging tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Assign priority based on how full the bin would become\n        # Smaller remaining capacity (i.e., larger fraction filled) gets higher priority\n        # We invert the remaining capacity to make smaller values larger priorities\n        inverted_cap = 1.0 / (available_bins_cap + 1e-9) # Add epsilon to avoid division by zero\n        \n        # Normalize priorities to be between 0 and 1\n        min_p = np.min(inverted_cap)\n        max_p = np.max(inverted_cap)\n        \n        if max_p - min_p > 1e-9:\n            normalized_priorities = (inverted_cap - min_p) / (max_p - min_p)\n        else:\n            normalized_priorities = np.ones_like(inverted_cap) * 0.5 # Uniform priority if all capacities are the same\n        \n        priorities[can_fit_mask] = normalized_priorities\n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 116.69205856195879,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic for online Bin Packing Problem.\n    Prioritizes bins that can fit the item exactly. Among those,\n    prioritizes bins with less remaining capacity to minimize wasted space.\n    If no bin fits exactly, it prioritizes bins with the least remaining capacity\n    that can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    exact_fit_bins_mask = (bins_remain_cap == item)\n    close_fit_bins_mask = (bins_remain_cap > item)\n\n    if np.any(exact_fit_bins_mask):\n        # Prioritize exact fits with highest priority (1)\n        priorities[exact_fit_bins_mask] = 1.0\n        # Among exact fits, a subtle bias towards less remaining capacity could be added if needed\n        # For exact fit, remaining capacity is zero, so no further differentiation needed here.\n    elif np.any(close_fit_bins_mask):\n        # If no exact fit, prioritize bins that fit with least remaining capacity\n        valid_bins_cap = bins_remain_cap[close_fit_bins_mask]\n        # Calculate a score inversely proportional to the excess capacity (bins_remain_cap - item)\n        # Adding a small epsilon to the denominator to avoid division by zero if item==0 or bins_remain_cap==item (already handled)\n        excess_capacities = valid_bins_cap - item\n        scores = 1.0 / (excess_capacities + 1e-9)\n\n        # Normalize scores to be between 0 and 1 for bins that can fit the item\n        # The highest score (least excess capacity) will be close to 1\n        max_score = np.max(scores)\n        if max_score > 0:\n            normalized_scores = scores / max_score\n        else:\n            normalized_scores = np.zeros_like(scores) # Should not happen with close_fit_bins_mask\n\n        # Assign these normalized scores to the corresponding bins\n        priorities[close_fit_bins_mask] = normalized_scores\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 82.0447025077789,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 2.0,
    "halstead": 185.75424759098897,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\n\n    In First Fit, the item is placed in the first bin that has enough remaining capacity.\n    This heuristic prioritizes bins that can accommodate the item and gives higher\n    priority to bins that have just enough capacity to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    # Assign a high priority to bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = 1.0\n\n    # Among those that can fit, prioritize bins that have just enough capacity.\n    # This is a greedy approach to minimize wasted space in the selected bin.\n    # We can use the inverse of the remaining capacity minus the item size as a measure\n    # of how \"tight\" the fit is. Smaller difference means higher priority.\n    tight_fit_scores = np.where(can_fit_mask, bins_remain_cap - item, np.inf)\n    \n    # Normalize the tight fit scores to avoid overly large or small values.\n    # Add a small epsilon to avoid division by zero if all differences are the same.\n    min_tight_fit = np.min(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 0\n    max_tight_fit = np.max(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 1\n    \n    if max_tight_fit - min_tight_fit > 1e-9: # Avoid division by zero if all are the same\n        normalized_tight_fit = (tight_fit_scores - min_tight_fit) / (max_tight_fit - min_tight_fit)\n    else:\n        normalized_tight_fit = np.zeros_like(tight_fit_scores)\n    \n    # Invert to give higher priority to smaller differences (tighter fits)\n    inverted_normalized_tight_fit = 1.0 - normalized_tight_fit\n    \n    # Combine the \"can fit\" priority with the \"tight fit\" priority.\n    # We want to boost bins that fit and then order them by tightness.\n    # The \"+ 0.1\" ensures that bins that can fit are always prioritized over those that cannot,\n    # even if their tight fit score is very high (which shouldn't happen if they can't fit).\n    priorities = np.where(can_fit_mask, 1.0 + inverted_normalized_tight_fit * 0.1, 0)\n    \n    # Ensure that bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 201.7383500317309,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by favoring exact fits, then closest fits, using a smooth scoring.\n\n    Combines Exact Fit First and Inverse Distance strategies:\n    1. High priority for bins where remaining_capacity == item.\n    2. Medium priority for bins where remaining_capacity > item, inversely\n       proportional to the difference (remaining_capacity - item).\n    3. Zero priority for bins where remaining_capacity < item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n\n    fitting_bins_cap = bins_remain_cap[can_fit_mask]\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(fitting_bins_cap) > 0:\n        # Prioritize exact fits with a high score\n        exact_fit_mask = fitting_bins_cap == item\n        priorities[fitting_bins_indices[exact_fit_mask]] = 2.0  # Highest priority\n\n        # For bins that are not exact fits, calculate priority based on how close they are\n        non_exact_fitting_bins_cap = fitting_bins_cap[~exact_fit_mask]\n        non_exact_fitting_bins_indices = fitting_bins_indices[~exact_fit_mask]\n\n        if len(non_exact_fitting_bins_cap) > 0:\n            # Calculate the difference (space after placing the item)\n            space_after_placement = non_exact_fitting_bins_cap - item\n\n            # Normalize these differences to a [0, 1] range for scoring.\n            # Smaller difference means higher priority.\n            min_diff = np.min(space_after_placement)\n            max_diff = np.max(space_after_placement)\n\n            if max_diff - min_diff > 1e-9: # Avoid division by zero if all differences are the same\n                normalized_diff = (space_after_placement - min_diff) / (max_diff - min_diff)\n            else:\n                normalized_diff = np.zeros_like(space_after_placement)\n            \n            # Assign priorities: inverse relationship with normalized difference, scaled down.\n            # This gives medium priority, lower than exact fits.\n            # Add a small offset to ensure it's greater than 0 for fitting bins.\n            priorities[non_exact_fitting_bins_indices] = 1.0 - normalized_diff + 0.1\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.208216992421225,
    "cyclomatic_complexity": 4.0,
    "halstead": 188.0175887256437,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Exact Fit First with Inverse Distance for robust bin packing.\n\n    Prioritizes exact fits, then falls back to the closest fit to minimize waste.\n    This hybrid approach balances ideal packing with practical close fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    epsilon = 1e-9\n\n    # Calculate exact fit priority: highest for bins where remaining capacity equals item size.\n    exact_fit_mask = np.abs(bins_remain_cap - item) < epsilon\n    priorities[exact_fit_mask] = 1.0\n\n    # Calculate inverse distance priority for bins that can fit the item and are not exact fits.\n    can_fit_mask = bins_remain_cap >= item\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(non_exact_fit_mask):\n        space_after_placement = bins_remain_cap[non_exact_fit_mask] - item\n        # Prioritize bins with smaller positive difference (less wasted space).\n        # Use a scaled inverse to ensure these priorities are lower than exact fits.\n        inverse_distance_scores = 1.0 / (space_after_placement + epsilon)\n        \n        # Normalize these scores to a range lower than 1.0, e.g., [0.5, 0.99]\n        # This ensures exact fits are still preferred.\n        min_norm = 0.5\n        max_norm = 0.99\n        \n        # Scale scores to [0, 1] based on their distribution, then shift to [0.5, 0.99]\n        if inverse_distance_scores.size > 1:\n            normalized_scores = (inverse_distance_scores - np.min(inverse_distance_scores)) / (np.max(inverse_distance_scores) - np.min(inverse_distance_scores) + epsilon)\n            scaled_scores = min_norm + normalized_scores * (max_norm - min_norm)\n        else:\n            # If only one bin, assign the midpoint of the secondary range\n            scaled_scores = (min_norm + max_norm) / 2.0\n\n        priorities[non_exact_fit_mask] = scaled_scores\n        \n    # Bins that cannot fit the item retain their default priority of 0.\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 271.8519998980832,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins that offer an exact fit or the smallest remaining capacity after placement.\n\n    Combines 'Exact Fit First' and 'Inverse Distance' strategies for a robust approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n        # Strategy 1: Exact Fit (Highest Priority)\n        exact_fit_mask = available_bins_remain_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            # If there are exact fits, we only consider them for ranking (effectively)\n            # but to allow other bins to have non-zero priority if needed, we proceed.\n            # However, for simplicity and clear hierarchy, we could return here if only exact fits are desired as the sole choice.\n            # For a more nuanced approach, we allow other bins to compete if they are \"close\".\n\n        # Strategy 2: Proximity Fit (Inverse of remaining capacity after placement)\n        # Assigns higher priority to bins that leave less space after placing the item.\n        # Avoids division by zero by adding a small epsilon.\n        space_after_placement = available_bins_remain_cap - item\n        \n        # We want to prioritize bins with smaller space_after_placement.\n        # Using 1 / (space_after_placement + epsilon) favors smaller positive differences.\n        # For bins where space_after_placement is 0 (exact fit), this will be 1/epsilon (very high).\n        # To avoid extremely high values for exact fits that might dominate too much,\n        # and to ensure proximity fits are ranked meaningfully, we can cap or scale.\n        # A simple approach is to ensure exact fits get priority 1.0 and then rank others.\n\n        # Let's refine: assign 1.0 to exact fits, and then rank the rest based on inverse remaining capacity.\n        \n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            non_exact_available_caps = available_bins_remain_cap[non_exact_fit_mask]\n            non_exact_space_after_placement = non_exact_available_caps - item\n\n            # Calculate inverse of remaining capacity (higher score for smaller remaining capacity)\n            # Add epsilon to avoid division by zero. The smaller the remaining capacity, the higher the score.\n            proximity_scores = 1.0 / (non_exact_space_after_placement + 1e-9)\n\n            # Normalize these scores to be between 0 and (1 - epsilon) to not overlap with exact fits\n            # if we wanted a strict hierarchy.\n            # For a combined heuristic, we can normalize them relative to each other.\n            if len(proximity_scores) > 0:\n                min_prox_score = np.min(proximity_scores)\n                max_prox_score = np.max(proximity_scores)\n                \n                # Normalize scores to a range that doesn't conflict with exact fit priority (e.g., 0 to 0.99)\n                # or simply use their relative ranking.\n                # Using ranks is often more robust than raw values.\n                \n                # Rank the non-exact fits based on their proximity score (higher score = better rank)\n                # argsort returns indices that would sort the array.\n                # We want higher proximity_scores to have higher ranks.\n                sorted_indices_for_non_exact = np.argsort(proximity_scores)\n                \n                # Assign ranks: the bin with the highest proximity_score gets the highest rank (close to 1).\n                # The indices obtained from argsort are ascending for smaller values.\n                # So, if proximity_scores are [10, 5, 20], argsort gives [1, 0, 2].\n                # We want ranks [0.33, 0.66, 1.0] or similar.\n                # Let's assign ranks such that smaller space_after_placement gets higher priority.\n                \n                # Sort the actual non-exact remaining capacities to get a clear order for prioritization.\n                sorted_non_exact_space_after = non_exact_space_after_placement[sorted_indices_for_non_exact]\n                \n                # Now assign priorities based on these sorted capacities.\n                # The bin with the smallest space_after_placement gets the highest priority (excluding exact fits).\n                # We can assign priorities from 0.0 up to something less than 1.0 (e.g., 0.99).\n                # Let's normalize the ranks to a range like [0.1, 0.9].\n                \n                if len(sorted_non_exact_space_after) > 1:\n                    rank_values = np.linspace(0.1, 0.9, len(sorted_non_exact_space_after))\n                    # The smallest remaining space should get the highest rank (0.9).\n                    # The current sorted_non_exact_space_after is ascending, so the last element is the largest.\n                    # We want to assign highest priority to the smallest values.\n                    assigned_priorities_for_non_exact = rank_values[::-1] # Reverse to give highest to smallest\n                else:\n                    assigned_priorities_for_non_exact = np.array([0.5]) # Default priority for single non-exact fit\n\n                # Map these assigned priorities back to the original indices of the available_bins_array.\n                # `sorted_indices_for_non_exact` are indices within `non_exact_available_caps`\n                # We need to map these back to `can_fit_mask` indices.\n                \n                # Get the original indices within `can_fit_mask` that correspond to non_exact_fit_mask\n                original_indices_of_non_exact_fits = np.where(can_fit_mask)[0][non_exact_fit_mask]\n                \n                # Update priorities for these bins\n                priorities[original_indices_of_non_exact_fits] = assigned_priorities_for_non_exact\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 5.534503390506582,
    "cyclomatic_complexity": 6.0,
    "halstead": 121.01398665684616,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit preference with a Best Fit fallback.\n    Prioritizes bins that exactly fit the item, then bins with minimal excess capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the exact fit score (highest priority)\n        exact_fit_mask = available_bins_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            \n        # Calculate the best fit score for remaining bins (secondary priority)\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            remaining_available_bins_cap = available_bins_cap[non_exact_fit_mask]\n            \n            # Prioritize bins with the least remaining capacity after placing the item\n            # Higher priority for smaller remaining space (closer fit)\n            # We invert (remaining_capacity - item) to make smaller values higher priorities\n            space_after_placement = remaining_available_bins_cap - item\n            \n            # Avoid division by zero and normalize to avoid extreme values\n            inverted_space = 1.0 / (space_after_placement + 1e-9) \n            \n            min_inv_space = np.min(inverted_space)\n            max_inv_space = np.max(inverted_space)\n            \n            if max_inv_space - min_inv_space > 1e-9:\n                normalized_priorities = (inverted_space - min_inv_space) / (max_inv_space - min_inv_space)\n            else:\n                normalized_priorities = np.ones_like(inverted_space) * 0.5 # Uniform if all same\n\n            # Add a small base priority to non-exact fits so they are considered after exact fits\n            # but only if they have higher priority than non-fitting bins (which is always 0)\n            priorities[can_fit_mask][non_exact_fit_mask] = normalized_priorities * 0.9\n            \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 5.0,
    "halstead": 180.68572508221183,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined 'Best Fit' like strategy.\n\n    This heuristic prioritizes bins that leave the least remaining capacity after packing the item,\n    aiming to minimize wasted space. It also favors bins that have sufficient capacity,\n    assigning a lower priority to bins that are too small.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity if the item is placed in each bin\n    remaining_after_packing = bins_remain_cap - item\n\n    # Assign a priority score.\n    # For bins where the item fits (remaining_after_packing >= 0):\n    # Higher priority is given to bins with smaller remaining capacity after packing.\n    # This is achieved by using the negative of the remaining capacity (so smaller positive numbers are prioritized).\n    # We add a small epsilon to ensure that bins with zero remaining capacity after packing\n    # (i.e., perfect fit) have a very high priority (close to 0 when negated and scaled).\n    # For bins where the item does not fit, assign a very low priority (negative infinity conceptually).\n    epsilon = 1e-9\n    priorities = np.where(\n        remaining_after_packing >= 0,\n        -remaining_after_packing,\n        -np.inf\n    )\n\n    # Normalize priorities to be non-negative and to give a higher score to bins that are a better fit.\n    # Shifting by adding the maximum negative value (or minimum positive value) ensures all priorities are >= 0.\n    # The 'best fit' bins (closest to 0 remaining capacity) will have the highest scores.\n    min_priority = np.min(priorities[priorities != -np.inf]) if np.any(priorities != -np.inf) else 0\n    priorities = np.where(\n        priorities == -np.inf,\n        0,  # Bins where item doesn't fit get 0 priority\n        priorities - min_priority + epsilon # Shift to make all priorities non-negative and prioritize smallest remaining capacity\n    )\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 129.26767504471167,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits, then bins with minimal excess capacity using normalized inverse differences.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    eligible_bins_indices = np.where(can_fit_mask)[0]\n    \n    if len(eligible_bins_indices) == 0:\n        return priorities\n\n    eligible_capacities = bins_remain_cap[eligible_bins_indices]\n    \n    # Calculate excess capacity for eligible bins\n    excess_capacity = eligible_capacities - item\n    \n    # --- Strategy: Exact Fit First ---\n    # Assign highest priority to bins that are an exact fit.\n    exact_fit_mask = (excess_capacity == 0)\n    exact_fit_indices = eligible_bins_indices[exact_fit_mask]\n    if len(exact_fit_indices) > 0:\n        priorities[exact_fit_indices] = 2.0 # Highest priority score\n        \n    # --- Strategy: Best Fit (Minimal Excess Capacity) ---\n    # For bins that are not an exact fit, prioritize those with the least excess capacity.\n    # Use a normalized inverse of the excess capacity to give higher scores to tighter fits.\n    non_exact_fit_indices = eligible_bins_indices[~exact_fit_mask]\n    \n    if len(non_exact_fit_indices) > 0:\n        non_exact_excess_capacity = excess_capacity[~exact_fit_mask]\n        \n        # Normalize differences: smaller difference means higher priority.\n        # We use (1.0 - normalized_difference) to map smaller excess to higher score.\n        min_excess = np.min(non_exact_excess_capacity)\n        max_excess = np.max(non_exact_excess_capacity)\n        \n        if max_excess - min_excess > 1e-9: # Avoid division by zero if all are the same\n            normalized_excess = (non_exact_excess_capacity - min_excess) / (max_excess - min_excess)\n            # Higher score for smaller normalized excess\n            best_fit_scores = 1.0 - normalized_excess \n        else:\n            best_fit_scores = np.ones_like(non_exact_excess_capacity) # All are equally good if range is zero\n\n        # Scale scores to a range lower than exact fit (e.g., [0.1, 1.0])\n        # Add a base score and scale to ensure they are distinct from exact fit but ordered.\n        scaled_best_fit_scores = 0.1 + best_fit_scores * 0.9\n        \n        priorities[non_exact_fit_indices] = scaled_best_fit_scores\n    \n    # Ensure bins that don't fit at all have zero priority\n    priorities[~can_fit_mask] = 0.0\n    \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 5.0,
    "halstead": 237.80142289857002,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Exact Fit First with a scaled inverse of remaining space for non-exact fits.\n\n    Prioritizes exact fits, then favors bins with the least space after placement,\n    scaled to ensure they are lower than exact fit scores.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    epsilon = 1e-9\n\n    # Exact fit has the highest priority\n    exact_fit_mask = np.abs(bins_remain_cap - item) < epsilon\n    priorities[exact_fit_mask] = 1.0\n\n    # For bins that can fit but are not exact fits\n    can_fit_mask = bins_remain_cap >= item\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(non_exact_fit_mask):\n        space_after_placement = bins_remain_cap[non_exact_fit_mask] - item\n        \n        # Use inverse of space_after_placement to favor smaller remaining space\n        # Scale these scores to be less than 1.0 to ensure exact fits are always preferred.\n        # A simple inverse without scaling might result in scores higher than 1.0 if the difference is small.\n        # We map the inverse scores to a range [0.5, 0.99]\n        min_secondary_priority = 0.5\n        max_secondary_priority = 0.99\n\n        # Calculate inverse scores for non-exact fits\n        inverse_scores = 1.0 / (space_after_placement + epsilon)\n\n        # Normalize these inverse scores to [0, 1]\n        if inverse_scores.size > 1:\n            normalized_inverse_scores = (inverse_scores - np.min(inverse_scores)) / (np.max(inverse_scores) - np.min(inverse_scores) + epsilon)\n        else:\n            normalized_inverse_scores = np.ones_like(inverse_scores) # If only one non-exact bin, it gets max secondary score\n\n        # Scale normalized scores to the desired secondary priority range\n        scaled_secondary_scores = min_secondary_priority + normalized_inverse_scores * (max_secondary_priority - min_secondary_priority)\n        \n        priorities[non_exact_fit_mask] = scaled_secondary_scores\n        \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 237.08652360984732,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit First with a normalized Best Fit strategy.\n    Prioritizes exact fits, then bins with the least excess capacity\n    relative to the minimum possible excess.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    eligible_bins_cap = bins_remain_cap[can_fit_mask]\n    \n    if eligible_bins_cap.size == 0:\n        return priorities\n\n    # Mask for exact fits\n    exact_fit_mask = (eligible_bins_cap == item)\n    \n    if np.any(exact_fit_mask):\n        # Assign highest priority (1.0) to exact fits\n        priorities[can_fit_mask][exact_fit_mask] = 1.0\n        \n        # For non-exact fits, assign a lower priority band (0.0 to 0.9)\n        non_exact_fit_mask = can_fit_mask.copy()\n        non_exact_fit_mask[can_fit_mask][exact_fit_mask] = False\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_bins_cap = bins_remain_cap[non_exact_fit_mask]\n            # Calculate excess capacity for non-exact fits\n            excess_capacities = non_exact_bins_cap - item\n            \n            # Find the minimum excess capacity among non-exact fits\n            min_excess_capacity = np.min(excess_capacities)\n            \n            # Calculate normalized scores: higher score for smaller excess capacity relative to min\n            # Add epsilon to avoid division by zero and to ensure scores are not infinite\n            normalized_scores = 1.0 / (excess_capacities - min_excess_capacity + 1e-9)\n            \n            # Scale these scores to a lower range (e.g., 0.0 to 0.9)\n            max_normalized_score = np.max(normalized_scores)\n            if max_normalized_score > 0:\n                scaled_scores = 0.9 * (normalized_scores / max_normalized_score)\n            else:\n                scaled_scores = np.zeros_like(normalized_scores) # Should not happen if there are non-exact fits\n\n            priorities[non_exact_fit_mask] = scaled_scores\n            \n    else:\n        # If no exact fit, all fitting bins are non-exact fits\n        # Calculate excess capacity for all eligible bins\n        excess_capacities = eligible_bins_cap - item\n        \n        # Find the minimum excess capacity\n        min_excess_capacity = np.min(excess_capacities)\n        \n        # Calculate normalized scores: higher score for smaller excess capacity relative to min\n        normalized_scores = 1.0 / (excess_capacities - min_excess_capacity + 1e-9)\n        \n        # Scale these scores to a range (e.g., 0.0 to 1.0)\n        max_normalized_score = np.max(normalized_scores)\n        if max_normalized_score > 0:\n            scaled_scores = normalized_scores / max_normalized_score\n        else:\n            scaled_scores = np.zeros_like(normalized_scores) # Should not happen\n\n        priorities[can_fit_mask] = scaled_scores\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 6.0,
    "halstead": 222.90509710918678,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit priority with a normalized Best Fit strategy.\n    Gives highest priority to exact fits, then prioritizes bins with\n    the smallest remaining capacity that can fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # If no bins can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Exact Fit Strategy ---\n    # Prioritize bins that fit the item exactly with a high score\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    \n    # --- Normalized Best Fit Strategy ---\n    # For bins that do not fit exactly, calculate a score based on how close they are\n    # to fitting the item. Prioritize those with minimal excess capacity.\n    close_fit_mask_local = ~exact_fit_mask_local\n    \n    # Calculate excess capacity for close fits\n    excess_capacities = eligible_bins_remain_cap[close_fit_mask_local] - item\n    \n    # Assign high priority to exact fits\n    if np.any(exact_fit_mask_local):\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n        \n    # If there are close fits, calculate their priorities\n    if np.any(close_fit_mask_local):\n        # Normalize excess capacities to be between 0 and 1\n        # A smaller excess capacity should get a higher score.\n        # We use 1 / (normalized_excess + epsilon) to give higher scores to smaller excesses.\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities) # Max excess capacity among close fits\n\n        # Avoid division by zero if all close fits have the same excess capacity\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities) # All close fits have same excess\n        \n        # Calculate scores: higher score for smaller normalized excess capacity\n        # Add a base score to differentiate from bins that don't fit (score 0)\n        # and ensure scores are distinct from exact fits.\n        close_fit_scores = 0.5 + 0.45 * (1.0 / (normalized_excess + 1e-9)) # Scale to [0.5, ~0.95]\n        \n        # Ensure scores are not greater than exact fit priority\n        close_fit_scores = np.minimum(close_fit_scores, 0.99) \n        \n        # Assign scores to the corresponding bins\n        priorities[can_fit_mask][close_fit_mask_local] = close_fit_scores\n\n    # Ensure exact fits have priority over close fits if they overlap in scoring range\n    if np.any(exact_fit_mask_local) and np.any(close_fit_mask_local):\n         priorities[can_fit_mask][exact_fit_mask_local] = 1.0 # Re-assert max priority for exact fits\n\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 7.0,
    "halstead": 198.16785241547504,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a normalized Exact Fit strategy.\n    Prioritizes exact fits and then uses inverse excess capacity for close fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Assign highest priority to exact fits\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    if np.any(exact_fit_mask_local):\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n\n    # For non-exact fits, prioritize based on minimal excess capacity\n    close_fit_mask_local = ~exact_fit_mask_local\n    if np.any(close_fit_mask_local):\n        excess_capacities = eligible_bins_remain_cap[close_fit_mask_local] - item\n        \n        # Normalize excess capacities to differentiate close fits\n        # Smaller excess should have higher priority (closer to 1.0)\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities)\n\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities)\n\n        # Assign priorities between 0.1 and 0.9, inverted for smaller excess\n        # Add a small base to distinguish from 0 priority and ensure separation from exact fits\n        close_fit_scores = 0.1 + 0.8 * (1.0 - normalized_excess)\n        priorities[can_fit_mask][close_fit_mask_local] = close_fit_scores\n\n    # Ensure exact fits (score 1.0) are strictly prioritized over close fits\n    if np.any(exact_fit_mask_local):\n        priorities[can_fit_mask][exact_fit_mask_local] = np.maximum(priorities[can_fit_mask][exact_fit_mask_local], 1.0)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 6.0,
    "halstead": 159.81495041679716,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits, then bins with minimal excess capacity using a scaled inverse difference.\n\n    This heuristic gives the highest priority to bins that exactly fit the item.\n    For bins that don't fit exactly but can accommodate the item, it assigns\n    priority based on the inverse of the excess capacity, scaled to emphasize\n    tighter fits.\n    \"\"\"\n    epsilon = 1e-9\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    # Calculate excess capacity for bins that can fit the item\n    excess_capacity = bins_remain_cap[can_fit_mask] - item\n\n    # Assign highest priority (1.0) to exact fits\n    exact_fit_mask_local = (excess_capacity < epsilon)\n    priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n\n    # For bins that don't fit exactly, calculate priority based on inverse excess capacity\n    close_fit_mask_local = ~exact_fit_mask_local\n    \n    if np.any(close_fit_mask_local):\n        eligible_excess_capacity = excess_capacity[close_fit_mask_local]\n        \n        # Calculate a score proportional to 1 / (excess_capacity + epsilon).\n        # This favors smaller excess capacities (tighter fits).\n        # We normalize this score to be between 0 and 1 to avoid overwhelming exact fits.\n        # A simple normalization: 1 / (1 + scaled_excess_capacity)\n        # Where scaled_excess_capacity is normalized difference.\n        \n        # To ensure scores are distinct from exact fits and rank close fits,\n        # let's use a score that starts below 1.0 and increases as excess capacity decreases.\n        # A simple way is to map the inverse excess capacity to a range like [0.1, 0.9].\n        # The inverse of excess capacity is `1 / (eligible_excess_capacity + epsilon)`.\n        # To bound this, we can consider the maximum inverse excess capacity.\n        \n        # A robust way: Use the inverse of (normalized excess + 1) to get scores in (0, 1].\n        # Let's normalize excess capacity relative to the item size itself,\n        # but ensuring we handle cases where item is very small or zero gracefully if needed.\n        \n        # A simpler score: `1 / (excess_capacity + epsilon)`\n        # Let's scale this to be less than 1.0.\n        # A common approach is `1 / (1 + scaled_value)`.\n        # Let's use `1 / (1 + normalized_excess_capacity)` where normalized is between 0 and some value.\n        \n        # Alternative: score = 0.5 + 0.45 * (1 / (normalized_excess_capacity + epsilon))\n        # This maps normalized excess from 0 to some value into [0.5, ~0.95].\n        \n        # Let's use the remaining capacity itself, but inverted and scaled.\n        # Score = remaining_cap / (remaining_cap - item + epsilon)\n        # This is `(item + excess) / (excess + epsilon)`.\n        # To keep it below 1, we can divide by a factor, e.g., `(item + excess) / (excess + epsilon) / (item/item + epsilon)`\n        \n        # A better approach is to normalize the excess capacity and then use its inverse.\n        # Normalize excess capacity: consider a reasonable upper bound for excess_capacity.\n        # If we assume item size is at most B (max bin capacity), then excess capacity is at most B.\n        # Let's consider `excess_capacity / item` (if item > 0).\n        \n        # A simple and effective score for close fits: `1 / (excess_capacity + epsilon)`\n        # We need to scale this to be less than 1.0.\n        # Find the maximum inverse excess capacity among close fits.\n        max_inv_excess = np.max(1.0 / (eligible_excess_capacity + epsilon))\n        \n        # Scale scores for close fits to be in the range [0.1, 0.9]\n        # Score = 0.1 + 0.8 * (1.0 / (eligible_excess_capacity + epsilon)) / max_inv_excess\n        # This ensures that the tightest fit gets ~0.9 and others scale down.\n        scores_for_close_fits = 0.1 + 0.8 * (1.0 / (eligible_excess_capacity + epsilon)) / (max_inv_excess + epsilon)\n        \n        # Ensure scores are not exactly 1.0 (reserved for exact fits)\n        scores_for_close_fits = np.minimum(scores_for_close_fits, 0.999)\n        \n        priorities[can_fit_mask][close_fit_mask_local] = scores_for_close_fits\n        \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 173.91626957122043,
    "exec_success": true
  }
]