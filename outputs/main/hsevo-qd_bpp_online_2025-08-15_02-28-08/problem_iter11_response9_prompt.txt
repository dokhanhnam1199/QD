{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements a Random Fit strategy for the online Bin Packing Problem.\n    Prioritizes bins that can fit the item. A higher priority is given\n    to bins with less remaining capacity that can still fit the item,\n    encouraging tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Assign priority based on how full the bin would become\n        # Smaller remaining capacity (i.e., larger fraction filled) gets higher priority\n        # We invert the remaining capacity to make smaller values larger priorities\n        inverted_cap = 1.0 / (available_bins_cap + 1e-9) # Add epsilon to avoid division by zero\n        \n        # Normalize priorities to be between 0 and 1\n        min_p = np.min(inverted_cap)\n        max_p = np.max(inverted_cap)\n        \n        if max_p - min_p > 1e-9:\n            normalized_priorities = (inverted_cap - min_p) / (max_p - min_p)\n        else:\n            normalized_priorities = np.ones_like(inverted_cap) * 0.5 # Uniform priority if all capacities are the same\n        \n        priorities[can_fit_mask] = normalized_priorities\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Exact Fit priority with a normalized Best Fit strategy.\n    Gives highest priority to exact fits, then prioritizes bins with\n    the smallest remaining capacity that can fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # If no bins can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Exact Fit Strategy ---\n    # Prioritize bins that fit the item exactly with a high score\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    \n    # --- Normalized Best Fit Strategy ---\n    # For bins that do not fit exactly, calculate a score based on how close they are\n    # to fitting the item. Prioritize those with minimal excess capacity.\n    close_fit_mask_local = ~exact_fit_mask_local\n    \n    # Calculate excess capacity for close fits\n    excess_capacities = eligible_bins_remain_cap[close_fit_mask_local] - item\n    \n    # Assign high priority to exact fits\n    if np.any(exact_fit_mask_local):\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n        \n    # If there are close fits, calculate their priorities\n    if np.any(close_fit_mask_local):\n        # Normalize excess capacities to be between 0 and 1\n        # A smaller excess capacity should get a higher score.\n        # We use 1 / (normalized_excess + epsilon) to give higher scores to smaller excesses.\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities) # Max excess capacity among close fits\n\n        # Avoid division by zero if all close fits have the same excess capacity\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities) # All close fits have same excess\n        \n        # Calculate scores: higher score for smaller normalized excess capacity\n        # Add a base score to differentiate from bins that don't fit (score 0)\n        # and ensure scores are distinct from exact fits.\n        close_fit_scores = 0.5 + 0.45 * (1.0 / (normalized_excess + 1e-9)) # Scale to [0.5, ~0.95]\n        \n        # Ensure scores are not greater than exact fit priority\n        close_fit_scores = np.minimum(close_fit_scores, 0.99) \n        \n        # Assign scores to the corresponding bins\n        priorities[can_fit_mask][close_fit_mask_local] = close_fit_scores\n\n    # Ensure exact fits have priority over close fits if they overlap in scoring range\n    if np.any(exact_fit_mask_local) and np.any(close_fit_mask_local):\n         priorities[can_fit_mask][exact_fit_mask_local] = 1.0 # Re-assert max priority for exact fits\n\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Best) and Heuristic 5 (also the same as 1): Both use `bins_remain_cap / (diff + epsilon)` to prioritize tight fits, favoring bins where `bins_remain_cap` is close to `item`.\n\nComparing Heuristic 2 and Heuristic 4: Both are identical to Heuristic 1, essentially repeating the same logic. The extensive commented-out exploration in Heuristic 2 doesn't translate to a distinct improvement or change in the final implemented logic compared to Heuristic 1.\n\nComparing Heuristic 3 and Heuristic 12/13/14: Heuristic 3 uses `bins_remain_cap / (diff + epsilon)`, similar to Heuristic 1. Heuristics 12, 13, and 14 introduce a tiered approach: highest priority for exact fits (score 2.0), and medium priority for non-exact fits based on normalized differences (scaled to be less than 2.0, e.g., `1.0 - normalized_diff + 0.1`). This tiered approach is more sophisticated than a single scoring function.\n\nComparing Heuristic 6 and Heuristic 7: Heuristic 6 uses a two-tier system: 1.0 for exact fits, and then normalized scores (0.0-0.9) for non-exact fits based on inverse of excess capacity relative to the minimum excess. Heuristic 7 is similar but assigns 2.0 to exact fits and scales non-exact fits to [0.1, 1.0]. The normalization in Heuristic 7 might be more robust if the range of excess capacities is large.\n\nComparing Heuristic 10/11 and Heuristic 16/17/19: Heuristics 10, 11 use a fixed priority of 1.0 for exact fits and scale non-exact fits to a range [0.5, 0.99] based on inverse normalized excess. Heuristics 16, 17, 19 also give 1.0 to exact fits but scale non-exact fits to a range like [0.1, 0.9] using inverse excess capacity relative to the maximum inverse excess capacity. The scaling in 16/17/19 seems more nuanced for ranking close fits.\n\nComparing Heuristic 8 and Heuristic 9: Heuristic 8 sorts available bins by remaining capacity and then assigns ranks based on sorted priorities (which appears to be a form of inverse remaining capacity). Heuristic 9 directly uses the inverse of available capacity (not excess capacity) and normalizes it. Heuristic 8's approach of ranking based on sorted values might be more stable.\n\nComparing Heuristic 15/18 and Heuristic 20: Heuristic 15/18 prioritizes exact fits with 1.0 and scales non-exact fits to [0, 0.9] using normalized inverse of space after placement. Heuristic 20 also prioritizes exact fits with 1.0 but scales non-exact fits to [0.5, 0.99] using inverse of normalized excess capacity. The latter scaling and explicit re-assertion of exact fit priority seem slightly more robust.\n\nOverall: More sophisticated heuristics implement a multi-tiered strategy (exact fit, then best fit based on normalized excess/inverse excess) with carefully chosen scaling factors to differentiate priorities. Simple inverse or ratio-based scoring is less effective than tiered approaches.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Exact Fit, Minimal Excess Capacity, Scaled Difference, Vectorization.\n*   **Advice:** Explicitly separate exact fits with maximum priority. For close fits, score based on a scaled measure of excess capacity, ensuring these scores are always lower than exact fit scores. Leverage vectorized operations for efficiency.\n*   **Avoid:** Complex non-linear transformations on capacity differences, convoluted array manipulations, and overly aggressive normalization that can obscure relative performance.\n*   **Explanation:** This approach clearly prioritizes perfect solutions while providing a predictable and tunable mechanism for selecting the \"best\" imperfect fit, all within an efficient computational framework.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}