```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a more sophisticated strategy.

    This heuristic prioritizes bins that have just enough remaining capacity to fit the item,
    while also considering bins that have significantly more capacity as a secondary factor.
    It aims to reduce fragmentation by favoring tighter fits.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    epsilon = 1e-9
    
    # Calculate the difference between remaining capacity and item size
    diff = bins_remain_cap - item
    
    # Initialize priorities to zero (for bins where the item doesn't fit)
    priorities = np.zeros_like(bins_remain_cap)
    
    # Identify bins where the item can fit
    can_fit_mask = diff >= 0
    
    # For bins where the item fits, calculate a priority score.
    # The primary goal is to find bins with a small positive difference (tightest fit).
    # We use an inverse of (difference + epsilon) for tighter fits to give them higher scores.
    # We also add a small bonus for bins with much larger remaining capacity to not
    # completely discard them if no tight fit is available. This bonus is smaller.
    
    # Calculate inverse difference for tight fits: higher score for smaller positive difference
    tight_fit_scores = 1 / (diff[can_fit_mask] + epsilon)
    
    # Calculate a secondary score for bins with more remaining capacity than the item size.
    # This is a simpler inverse of remaining capacity, scaled down.
    # We want to avoid division by zero for bins with zero remaining capacity if they exist (though item wouldn't fit)
    # and to give some priority to larger bins if no tight fit is available.
    # Using the original bins_remain_cap for this secondary scoring.
    
    # We can normalize the remaining capacities to get a sense of "how much space" is left relative to bin capacity.
    # However, since we don't have the original bin capacity, we can use a heuristic.
    # Let's simply use the remaining capacity itself, but scaled.
    # A simpler approach without original bin capacity is to just use the inverse of difference for those that fit.
    
    # Let's refine the logic:
    # Priority 1: Bins with smallest positive `diff` (tightest fit). This is `1 / (diff + epsilon)`.
    # Priority 2: Bins with larger `diff`. These are less preferred than tight fits.
    # A simple way to combine is to give a high score to tight fits and a moderate score to larger fits.
    
    # Let's use a piecewise approach for scoring:
    # For bins that fit:
    # If diff is very small (e.g., diff < threshold), assign a high priority (e.g., 100 + 1/diff).
    # If diff is larger, assign a lower priority (e.g., 10 + 1/diff).
    # This requires tuning `threshold`.
    
    # A more robust approach without arbitrary thresholds:
    # We want to maximize `1/(diff + epsilon)` for tight fits and still assign some score to larger fits.
    # Consider the ratio of remaining capacity to item size.
    
    # Let's try scoring based on inverse difference, and then add a penalty for "too much" space.
    # Or, simply, prioritize bins where `bins_remain_cap` is "close" to `item`.
    
    # Let's use a score that is high for small positive differences and decreases as the difference grows.
    # A Gaussian-like function centered around 0 (for `diff`) could work, but it's complex.
    
    # Simpler idea: prioritize bins that have *just enough* space.
    # We can define "just enough" as being within a certain percentage of the item size.
    # For example, if diff is between 0 and `item * tolerance`.
    
    # Let's revisit the inverse distance, but modify it to be more sensitive to small differences.
    # A score that is high for small `diff` and then drops off.
    # Consider `score = 1 / (diff^2 + epsilon)` or `score = exp(-k * diff)`
    
    # Let's try a score that emphasizes the "tightness" by squaring the inverse of the difference.
    # This will amplify the priority for very tight fits.
    
    # Calculate the inverse of difference for bins that can fit the item
    # For bins where it can fit, the priority is proportional to 1 / (difference + epsilon)
    # We want to boost the priority for smaller differences more significantly.
    # Let's use (1 / (diff + epsilon))^2 for a stronger emphasis on tightness.
    
    # This still might give a very small positive difference a disproportionately high score.
    
    # Alternative: Focus on the ratio of remaining capacity to item size.
    # Bins with `bins_remain_cap / item` close to 1 are good.
    # Ratio = bins_remain_cap / item. We want ratio ~ 1.
    # Score could be proportional to `1 / abs(ratio - 1)`.
    # However, this doesn't account for the absolute amount of space. A bin with 10 capacity
    # and item 9 (ratio 1.11) is better than bin with 100 capacity and item 9 (ratio 1.01)
    # if we only consider this ratio. We need to combine it.
    
    # Let's stick to the difference but prioritize small positive differences more strongly.
    # A function like `f(x) = 1/(x+epsilon)` is already good.
    # What if we add a small bonus for bins that have "plenty" of space, but significantly less than tight fits?
    
    # Let's try to make it more robust to scale by normalizing.
    # If we knew the maximum bin capacity, we could normalize. Without it, it's hard.
    
    # Back to basics, `priority_v1` favors bins with largest remaining capacity among those that fit.
    # `1 / (diff + epsilon)` favors bins with smallest `diff`. This is generally good.
    
    # How to improve:
    # 1. Give stronger weight to *very* tight fits.
    # 2. Ensure that bins that are *almost* full but still fit are prioritized over bins that are nearly empty but fit.
    
    # Let's try a compound score:
    # Score1: Inverse difference (prioritizes tight fits)
    # Score2: A small bonus for bins that are not too empty, scaled by how much they can fit.
    
    # For bins that can fit:
    # `tight_fit_score = 1 / (diff + epsilon)`
    
    # Now, consider the "emptiness" of the bin if it fits.
    # A bin that has `bins_remain_cap` close to `item` is good.
    # A bin that has `bins_remain_cap` much larger than `item` is less ideal in terms of fragmentation.
    
    # Let's define a score that peaks at `diff = 0` (or slightly negative) and decreases.
    # However, we only consider `diff >= 0`. So we want it to peak at `diff = 0`.
    
    # Consider a function that is `1/(diff + epsilon)` for tight fits, and maybe a constant or decaying function for larger fits.
    
    # Let's try a score that emphasizes "just enough" space more, and "plenty" of space less.
    # If `diff` is small (e.g., < `item / 2`), give it a higher score.
    # If `diff` is large (e.g., > `item / 2`), give it a lower score.
    
    # Let's normalize `diff` relative to the item size.
    # `normalized_diff = diff / item` (if item > 0)
    # We want `normalized_diff` close to 0.
    
    # Score = `1 / (normalized_diff + epsilon)` for `normalized_diff >= 0`
    # This is equivalent to `item / (bins_remain_cap - item + epsilon)` which is similar to `priority_v1` but normalized.
    
    # Let's try to blend the inverse difference with a penalty for being too "empty".
    # A bin that fits has `bins_remain_cap >= item`.
    # If `bins_remain_cap` is much larger than `item`, it's "too empty".
    
    # Let's use a score based on how much of the remaining capacity is *used* by the item.
    # If `bins_remain_cap` is very close to `item`, then `item / bins_remain_cap` is close to 1.
    # If `bins_remain_cap` is much larger than `item`, then `item / bins_remain_cap` is close to 0.
    
    # So, we want to prioritize bins where `item / bins_remain_cap` is close to 1.
    # Score = `1 / abs((item / bins_remain_cap) - 1 + epsilon)`
    # This can be written as `bins_remain_cap / abs(bins_remain_cap - item + epsilon)`.
    # This is effectively `bins_remain_cap / (diff + epsilon)` for bins that fit.
    
    # Let's test this:
    # item = 5
    # bins_remain_cap = [10, 6, 20, 5.1]
    # diff = [5, 1, 15, 0.1]
    #
    # priority_v1:
    # 1/(5+eps) = 0.2
    # 1/(1+eps) = 1.0
    # 1/(15+eps) = 0.066
    # 1/(0.1+eps) = 9.09
    # Max priority for 5.1 remaining.
    #
    # New approach: `bins_remain_cap / (diff + epsilon)`
    # 10 / (5+eps) = 2.0
    # 6 / (1+eps) = 6.0
    # 20 / (15+eps) = 1.33
    # 5.1 / (0.1+eps) = 51.0
    # Max priority for 5.1 remaining. This seems to amplify the preference for tight fits.
    
    # Let's implement this: `bins_remain_cap / (diff + epsilon)` for bins that fit.
    
    priorities = np.zeros_like(bins_remain_cap)
    
    # Identify bins where the item can fit
    can_fit_mask = bins_remain_cap >= item
    
    # For bins where the item fits, calculate the priority score
    # Prioritize bins where the remaining capacity is closest to the item size.
    # Score is `bins_remain_cap / (bins_remain_cap - item + epsilon)`
    # This is equivalent to `bins_remain_cap / (diff + epsilon)`
    
    # Add a small epsilon to bins_remain_cap to avoid division by zero if item == bins_remain_cap == 0,
    # although can_fit_mask should prevent this for item > 0.
    
    # Ensure item is not zero to avoid division by zero in potential alternative calculations.
    # In this case, we are using bins_remain_cap which is always non-negative.
    
    # The division `bins_remain_cap / (bins_remain_cap - item + epsilon)` can be large if `bins_remain_cap - item` is small.
    # This correctly prioritizes tight fits.
    
    # Let's make sure the score is well-behaved.
    # If `bins_remain_cap` is large, and `item` is small, `diff` is large.
    # `bins_remain_cap / (diff + epsilon)` will be `large / large` -> moderate score.
    # If `bins_remain_cap` is just slightly larger than `item`, `diff` is small.
    # `bins_remain_cap / (diff + epsilon)` will be `~item / small` -> high score.
    
    # This seems like a good candidate for `priority_v2`.
    
    # Avoid division by zero if item is 0, though problem statement implies item > 0.
    # If item is 0, any bin can fit it with infinite priority if `diff=0`.
    # For item > 0, `bins_remain_cap` must be >= `item`.
    
    # Let's consider `bins_remain_cap - item`. If this is 0, the item perfectly fills the bin.
    # In that case, `bins_remain_cap / epsilon` would be very large. This is desired.
    
    # Calculate the score for bins where the item fits
    # Score = remaining_capacity / (remaining_capacity - item + epsilon)
    # This is equivalent to: (item + diff) / (diff + epsilon)
    # This ratio is maximized when `diff` is minimized (closest to 0).
    
    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask] / (diff[can_fit_mask] + epsilon)
    
    return priorities

```
