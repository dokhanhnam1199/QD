{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A mutated version of priority_v1 for the online Bin Packing Problem.\n\n    This heuristic prioritizes bins that can exactly fit the item (zero remaining capacity after packing).\n    Among bins that fit, it favors those with the minimal excess capacity (tightest fit).\n    Bins with larger excess capacity are given lower scores, but still positive if they fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 1e-9\n    \n    # Initialize priorities to zero (for bins where the item doesn't fit)\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate the difference between remaining capacity and item size for bins that can fit\n    diff = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign a very high priority to bins that provide an exact fit\n    # These are bins where diff is zero or very close to zero.\n    exact_fit_mask = diff < epsilon\n    \n    # For exact fits, assign the highest possible priority value.\n    # We use a value significantly larger than any possible score from other bins.\n    # The score for non-exact fits will be related to item / diff, which is bounded.\n    # A very large constant or a value based on item size is appropriate.\n    # Let's use a score that ensures it's greater than any other score.\n    # The maximum finite score from the next step would be roughly (item + large_diff) / large_diff ~ 1,\n    # or if diff is tiny, item / epsilon.\n    # So, let's use something like item / epsilon * 2.\n    # A simpler way is to assign a large number, but tying it to item size is better.\n    # Let's assign a score proportional to item, effectively prioritizing exact fits for larger items.\n    \n    # The highest priority will be for bins with `diff` very close to 0.\n    # We can assign a score of `item / epsilon` for these.\n    # For other bins that fit, the score is `bins_remain_cap / diff`.\n    # So, `(item + diff) / diff`\n    \n    # To ensure exact fits are always best, let's give them a score that's guaranteed to be higher.\n    # For bins that fit, the score is item / (bins_remain_cap - item + epsilon) = item / (diff + epsilon)\n    # For exact fits (diff approx 0), this score becomes very large.\n    # Let's ensure a distinct separation.\n    \n    # For bins that fit:\n    # If diff is effectively zero, assign a very high score.\n    # Otherwise, assign a score inversely proportional to the difference.\n    # A good score for non-exact fits is `item / (diff + epsilon)` which is equivalent to `bins_remain_cap / (diff + epsilon)`.\n    \n    # Let's combine these:\n    # If diff < epsilon (exact fit): high score.\n    # If diff >= epsilon (close or loose fit): score based on inverse difference.\n    \n    # Create a temporary array for the scores of bins that can fit\n    fitting_bins_scores = np.zeros_like(diff)\n    \n    # Identify exact fits within the fitting bins\n    exact_fit_in_fitting_mask = diff < epsilon\n    \n    # Assign a very high priority to exact fits. This ensures they are chosen first.\n    # The exact score should be higher than any calculated score for non-exact fits.\n    # The non-exact fit score is `bins_remain_cap / diff`. If diff is small but positive, this can be large.\n    # To make exact fits superior, assign a score that's at least `max(bins_remain_cap / diff)` + a margin.\n    # A simpler, robust approach: assign a score that depends on the item size, making exact fits for larger items\n    # more \"valuable\".\n    \n    # Let's try this:\n    # For exact fits: `item * (1 / epsilon)`\n    # For other fits: `item / (diff + epsilon)` (This is the same as `bins_remain_cap / (diff + epsilon)`)\n    # This makes exact fits have a very high score, proportional to the item size.\n    \n    # For bins that fit:\n    # If `diff` is close to 0: `high_priority = item * 1e10` (or some large multiplier)\n    # If `diff` > 0: `priority = item / (diff + epsilon)`\n    \n    # Let's assign the highest priority to exact fits.\n    # The score for other bins is `bins_remain_cap / (diff + epsilon)`.\n    # If `diff` is small, this value is large. If `diff` is large, this value is closer to 1.\n    # We want exact fits to be strictly better.\n    \n    # Assign a very large number to exact fits to ensure they are always picked.\n    # A value like 1e10 or even larger would work, but making it relative is better.\n    # Let's use a value that's guaranteed to be larger than `bins_remain_cap / diff` for any `diff > epsilon`.\n    # The maximum value of `bins_remain_cap` is not known.\n    # If `diff` is very small (e.g., `epsilon`), score is `item / epsilon`.\n    # So, `item / epsilon * 2` should be safe.\n    \n    # Calculate scores for all bins that can fit.\n    # Score = `bins_remain_cap / (diff + epsilon)`\n    # This inherently gives higher scores to tighter fits.\n    \n    # We want to explicitly boost exact fits.\n    # If `diff < epsilon`: this is an exact fit. Give it a bonus.\n    \n    # Let's use a score that is proportional to `bins_remain_cap / diff` but with a large bonus for exact fits.\n    # `score = bins_remain_cap / (diff + epsilon)`\n    # If `diff < epsilon`, add a large bonus: `score += LargeBonus`\n    \n    # This can be implemented by modifying the `diff` for exact fits.\n    # For exact fits, we want `diff` to be effectively 0.\n    # For non-exact fits, `diff` is positive.\n    \n    # A common strategy is:\n    # 1. Assign a very high fixed priority to exact fits.\n    # 2. For other fits, assign a priority that decreases as `diff` increases.\n    #    The `bins_remain_cap / (diff + epsilon)` is a good candidate.\n    \n    # Let's assign a base score for all fitting bins:\n    # `base_scores = bins_remain_cap[can_fit_mask] / (diff + epsilon)`\n    \n    # Now, identify exact fits among those that can fit.\n    exact_fits_indices = np.where(diff < epsilon)[0]\n    \n    # For these exact fits, assign a significantly higher score.\n    # Let's make their score `item / epsilon * 2` to ensure it's higher than other potential scores.\n    # The scores for non-exact fits are `bins_remain_cap / diff`.\n    # If `diff` is `epsilon`, score is `bins_remain_cap / epsilon`.\n    # So `item / epsilon * 2` is indeed a good choice for exact fits.\n    \n    # Calculate scores for all bins that can fit using the `bins_remain_cap / diff` logic\n    fitting_bins_scores = bins_remain_cap[can_fit_mask] / (diff + epsilon)\n    \n    # Identify exact fits among these:\n    exact_fit_indices_in_fitting = np.where(diff < epsilon)[0]\n    \n    # Boost the priority for exact fits.\n    # Assign a score that is guaranteed to be higher than any calculated score.\n    # A simple approach is to add a large value.\n    # Let's assign a score of `item * 1e10` for exact fits.\n    # For other fits, the score is `bins_remain_cap / diff`.\n    # If `diff` is very small (e.g. `epsilon`), the score is `bins_remain_cap / epsilon`.\n    # Since `bins_remain_cap >= item`, this is at least `item / epsilon`.\n    # So `item * 1e10` is a safe high value.\n    \n    # For indices in `fitting_bins_scores` corresponding to exact fits:\n    # The original `diff` for these was < epsilon.\n    # `fitting_bins_scores[exact_fit_indices_in_fitting]` would be `bins_remain_cap[exact_fit_indices_in_fitting] / diff_values_for_exact_fits`.\n    # If `diff` is tiny, this is large.\n    \n    # Let's re-calculate scores to ensure clarity and separation:\n    scores_for_fitting = np.zeros_like(diff)\n    \n    # Bins with exact fit (diff is effectively 0)\n    exact_fit_mask_for_fitting = diff < epsilon\n    \n    # Assign a very high priority to exact fits.\n    # The score is `item * (1 / epsilon)` ensures it's prioritized.\n    # Using `item * 1e10` for a large multiplier.\n    scores_for_fitting[exact_fit_mask_for_fitting] = item * 1e10\n    \n    # Bins with a positive difference (item fits, but not exactly)\n    non_exact_fit_mask_for_fitting = ~exact_fit_mask_for_fitting\n    \n    # For these, use a score inversely proportional to the difference.\n    # `bins_remain_cap / diff` gives higher scores to smaller differences.\n    # This is `(item + diff) / diff`.\n    scores_for_fitting[non_exact_fit_mask_for_fitting] = bins_remain_cap[non_exact_fit_mask_for_fitting] / diff[non_exact_fit_mask_for_fitting]\n    \n    # Place these scores back into the main priorities array\n    priorities[can_fit_mask] = scores_for_fitting\n    \n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\n\n    In First Fit, the item is placed in the first bin that has enough remaining capacity.\n    This heuristic prioritizes bins that can accommodate the item and gives higher\n    priority to bins that have just enough capacity to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    # Assign a high priority to bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = 1.0\n\n    # Among those that can fit, prioritize bins that have just enough capacity.\n    # This is a greedy approach to minimize wasted space in the selected bin.\n    # We can use the inverse of the remaining capacity minus the item size as a measure\n    # of how \"tight\" the fit is. Smaller difference means higher priority.\n    tight_fit_scores = np.where(can_fit_mask, bins_remain_cap - item, np.inf)\n    \n    # Normalize the tight fit scores to avoid overly large or small values.\n    # Add a small epsilon to avoid division by zero if all differences are the same.\n    min_tight_fit = np.min(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 0\n    max_tight_fit = np.max(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 1\n    \n    if max_tight_fit - min_tight_fit > 1e-9: # Avoid division by zero if all are the same\n        normalized_tight_fit = (tight_fit_scores - min_tight_fit) / (max_tight_fit - min_tight_fit)\n    else:\n        normalized_tight_fit = np.zeros_like(tight_fit_scores)\n    \n    # Invert to give higher priority to smaller differences (tighter fits)\n    inverted_normalized_tight_fit = 1.0 - normalized_tight_fit\n    \n    # Combine the \"can fit\" priority with the \"tight fit\" priority.\n    # We want to boost bins that fit and then order them by tightness.\n    # The \"+ 0.1\" ensures that bins that can fit are always prioritized over those that cannot,\n    # even if their tight fit score is very high (which shouldn't happen if they can't fit).\n    priorities = np.where(can_fit_mask, 1.0 + inverted_normalized_tight_fit * 0.1, 0)\n    \n    # Ensure that bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    available_bins_mask = bins_remain_cap >= item\n    \n    if np.any(available_bins_mask):\n        available_bins_remain_cap = bins_remain_cap[available_bins_mask]\n        \n        sorted_indices = np.argsort(available_bins_remain_cap)\n        \n        priorities[available_bins_mask] = 1.0 / (available_bins_remain_cap - item + 1e-9)\n        \n        priorities[available_bins_mask] = np.argsort(np.argsort(priorities[available_bins_mask]))\n    \n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more sophisticated priority function for online Bin Packing.\n\n    This heuristic prioritizes bins that offer an \"exact fit\" (remaining capacity\n    is very close to the item size) with the highest possible score. For bins\n    that do not offer an exact fit but can accommodate the item, it prioritizes\n    those with minimal excess capacity. It uses a scaled difference to rank these\n    \"close fits\", ensuring they receive a score lower than exact fits.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: A numpy array containing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of priority scores for each bin, with the same shape as bins_remain_cap.\n    \"\"\"\n    epsilon = 1e-9  # Small value to avoid division by zero\n    high_priority_score = 1e9  # Score for exact fits\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Separate bins into exact fits and close fits\n    exact_fit_mask = np.abs(bins_remain_cap - item) < epsilon\n    close_fit_mask = can_fit_mask & ~exact_fit_mask\n\n    # Assign the highest priority to exact fits\n    priorities[exact_fit_mask] = high_priority_score\n\n    # For close fits, calculate a score based on the inverse of the excess capacity.\n    # We want to prioritize bins with less excess capacity (smaller positive difference).\n    # A simple approach is to use `1 / (difference + epsilon)`.\n    # To ensure these scores are always lower than exact fits, we can scale them down,\n    # or ensure the `high_priority_score` is sufficiently large.\n    # Using `bins_remain_cap / (bins_remain_cap - item + epsilon)` as suggested in thought process\n    # is equivalent to `(item + diff) / (diff + epsilon)` which is a good score for close fits.\n    # We will scale this score down to be less than `high_priority_score`.\n\n    if np.any(close_fit_mask):\n        diff_close_fits = bins_remain_cap[close_fit_mask] - item\n        # The score `bins_remain_cap / (diff + epsilon)` is good for ranking close fits,\n        # but we need to ensure it's less than the exact fit score.\n        # A simple scaling or a different functional form can achieve this.\n        # Let's use a score that decays with increasing difference.\n        # A score like `1 / (diff^2 + epsilon)` could amplify small differences.\n        # Let's stick to the robust `bins_remain_cap / (diff + epsilon)` and scale it.\n        \n        # Calculate the raw score for close fits: prioritize smaller positive difference\n        raw_scores = bins_remain_cap[close_fit_mask] / (diff_close_fits + epsilon)\n        \n        # Scale these scores down to be less than high_priority_score.\n        # We can normalize them relative to the maximum possible raw score or\n        # simply divide by a large constant.\n        # A robust way is to map the range of `diff_close_fits` to a range below `high_priority_score`.\n        # Let's use `1 / (diff + epsilon)` and then scale it.\n        # The maximum value of `1/(diff+eps)` occurs at the minimum positive diff.\n        # Let's ensure scores are less than `high_priority_score`.\n        \n        # A simpler approach: assign priority based on `1 / (diff + epsilon)` and then ensure\n        # exact fits are strictly higher.\n        \n        # Let's use the previous v1 logic for close fits, but ensure it's lower than exact fits.\n        # `1 / (diff + epsilon)`\n        \n        # Instead of `1/(diff+eps)`, let's use the `bins_remain_cap / (diff + epsilon)` idea but scale it.\n        # This score `bins_remain_cap / (diff + epsilon)` is `(item + diff) / (diff + epsilon)`.\n        # If diff is small, this is large. If diff is large, this approaches 1.\n        # We want to prioritize small diff.\n        \n        # Let's use a transformed score: `k / (diff + c)` where k and c are tuned.\n        # The goal is to rank them appropriately among themselves, and keep them below exact fits.\n        \n        # Let's refine the scoring for close fits:\n        # We want minimal `diff` for close fits to have higher priority.\n        # A score like `1 / (diff + epsilon)` already does this.\n        # To ensure these scores are lower than `high_priority_score`, we can map the scores\n        # derived from `1 / (diff + epsilon)` into a range below `high_priority_score`.\n        \n        # Calculate the difference for close fits\n        diff_close = bins_remain_cap[close_fit_mask] - item\n        \n        # Calculate a score that prioritizes smaller differences.\n        # Use `1 / (diff_close + epsilon)`. This gives higher scores for smaller positive differences.\n        # To ensure these scores are distinguishable from exact fits, we can scale them,\n        # or use a secondary factor.\n        \n        # Let's consider a different approach:\n        # Prioritize bins that are *most full* among those that fit, but not exact fits.\n        # This means prioritizing bins with the smallest `bins_remain_cap` such that `bins_remain_cap >= item`.\n        # This is equivalent to prioritizing smallest `diff = bins_remain_cap - item`.\n        \n        # Score for close fits: `1 / (diff_close + epsilon)`\n        # This is already what `priority_v1` does for bins that fit.\n        # The improvement can come from how we combine exact fits with close fits.\n        \n        # Let's give a very high score for exact fits, and a decreasing score for close fits.\n        # The scaling of `bins_remain_cap / (diff + epsilon)` is good for ranking close fits.\n        # Let's normalize this to be below `high_priority_score`.\n        \n        # For close fits, calculate `bins_remain_cap / (diff + epsilon)`\n        # Let's cap these values to be less than `high_priority_score`.\n        \n        # A simple heuristic: Use the `bins_remain_cap / (diff + epsilon)` score.\n        # Then, scale all these scores down so they are consistently lower than `high_priority_score`.\n        # For example, find the max `bins_remain_cap / (diff + epsilon)` among close fits,\n        # and then scale all to be within `[0, high_priority_score * 0.9]`.\n        \n        # Let's implement the idea of \"minimal excess capacity\" more directly.\n        # For close fits, the priority should be inversely proportional to the excess capacity (`diff`).\n        # `priority = 1.0 / (diff + epsilon)` gives higher scores to smaller `diff`.\n        \n        # To make it distinct from exact fits, we can add a small constant to the difference\n        # before taking the inverse, or use a different function.\n        \n        # Let's use a score that is inversely related to `diff`, but scaled to be lower than exact fits.\n        # Consider `score = max_possible_close_fit_score - diff` where `max_possible_close_fit_score`\n        # is slightly less than `high_priority_score`.\n        # This is essentially `C - diff`, which would prioritize smaller `diff`.\n        \n        # Let's combine the two ideas:\n        # 1. Exact fits get `high_priority_score`.\n        # 2. Close fits get a score based on `bins_remain_cap / (diff + epsilon)`, scaled.\n        \n        # Calculate the base score for close fits.\n        close_fit_scores_base = bins_remain_cap[close_fit_mask] / (diff_close + epsilon)\n        \n        # Normalize these scores to a range [0, 1] and then scale them.\n        # To avoid issues with division by zero if all close fits have same diff,\n        # or if max_score is very small.\n        \n        # A simpler approach is to add a penalty to `diff` for non-exact fits.\n        # Let's use `1 / (diff + some_constant + epsilon)` where `some_constant` ensures\n        # these scores are lower than exact fits.\n        \n        # `priority = 1 / (bins_remain_cap - item + some_constant + epsilon)`\n        # If `some_constant` is chosen to be large enough, the scores will be smaller.\n        # For example, `some_constant = 1.0` might be enough.\n        \n        # Let's use the idea of `bins_remain_cap / (diff + epsilon)` but add a base penalty for not being an exact fit.\n        # `score = bins_remain_cap[close_fit_mask] / (diff_close + epsilon) - penalty`\n        \n        # The most direct way to implement \"minimal excess capacity\" is to directly use `1/diff`.\n        # Let's try `1 / (diff_close + epsilon)` and ensure it's lower than exact fits.\n        \n        priorities[close_fit_mask] = 1.0 / (diff_close + epsilon)\n        \n        # Now, we need to ensure these are lower than `high_priority_score`.\n        # If there are exact fits, their scores will be `high_priority_score`.\n        # If `1.0 / (diff_close + epsilon)` can become larger than `high_priority_score`\n        # (e.g., if `diff_close` is very close to zero, but not within epsilon of it),\n        # we need to cap it.\n        \n        # Let's adjust the range of scores for close fits to be clearly below exact fits.\n        # We can scale the `1 / (diff + epsilon)` scores.\n        # Find the maximum score among close fits and scale them.\n        \n        if np.any(priorities[close_fit_mask] > 0): # Check if there are any scores for close fits\n            max_close_fit_score = np.max(priorities[close_fit_mask])\n            # Scale these scores to be in a range like [0, `high_priority_score` * 0.9]\n            # If max_close_fit_score is 0 (e.g., all diffs are very large), this scaling might be tricky.\n            # Let's ensure a minimum score of 0 and a maximum score below `high_priority_score`.\n            \n            # A more robust scaling:\n            # If max_close_fit_score is positive, scale to `high_priority_score * 0.9`\n            if max_close_fit_score > epsilon:\n                # Scale the scores for close fits to be in [0, `high_priority_score` * 0.9]\n                # The relative order within close fits is maintained.\n                scaled_close_fit_scores = (priorities[close_fit_mask] / max_close_fit_score) * (high_priority_score * 0.9)\n                priorities[close_fit_mask] = scaled_close_fit_scores\n            else:\n                # If all close fit scores are near zero, assign a small constant score\n                priorities[close_fit_mask] = 1.0 # Or some small value\n\n    # Bins where the item does not fit have a priority of 0, which is already set.\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    available_bins_mask = bins_remain_cap >= item\n    \n    if np.any(available_bins_mask):\n        available_bins_remain_cap = bins_remain_cap[available_bins_mask]\n        \n        sorted_indices = np.argsort(available_bins_remain_cap)\n        \n        priorities[available_bins_mask] = 1.0 / (available_bins_remain_cap - item + 1e-9)\n        \n        priorities[available_bins_mask] = np.argsort(np.argsort(priorities[available_bins_mask]))\n    \n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a Random Fit strategy for the online Bin Packing Problem.\n    Prioritizes bins that can fit the item. A higher priority is given\n    to bins with less remaining capacity that can still fit the item,\n    encouraging tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Assign priority based on how full the bin would become\n        # Smaller remaining capacity (i.e., larger fraction filled) gets higher priority\n        # We invert the remaining capacity to make smaller values larger priorities\n        inverted_cap = 1.0 / (available_bins_cap + 1e-9) # Add epsilon to avoid division by zero\n        \n        # Normalize priorities to be between 0 and 1\n        min_p = np.min(inverted_cap)\n        max_p = np.max(inverted_cap)\n        \n        if max_p - min_p > 1e-9:\n            normalized_priorities = (inverted_cap - min_p) / (max_p - min_p)\n        else:\n            normalized_priorities = np.ones_like(inverted_cap) * 0.5 # Uniform priority if all capacities are the same\n        \n        priorities[can_fit_mask] = normalized_priorities\n    \n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins: exact fits highest, then closest fits based on normalized inverse excess.\n\n    Combines Exact Fit preference with a scaled Best Fit strategy.\n    Exact fits receive the highest priority. Other fitting bins are prioritized\n    based on the inverse of their normalized excess capacity after placement.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        fitting_bins_cap = bins_remain_cap[can_fit_mask]\n        fitting_bins_indices = np.where(can_fit_mask)[0]\n\n        # Highest priority for exact fits\n        exact_fit_mask = fitting_bins_cap == item\n        priorities[fitting_bins_indices[exact_fit_mask]] = 2.0\n\n        # Medium priority for non-exact fits, based on how close they are\n        non_exact_fitting_bins_cap = fitting_bins_cap[~exact_fit_mask]\n        non_exact_fitting_bins_indices = fitting_bins_indices[~exact_fit_mask]\n\n        if len(non_exact_fitting_bins_cap) > 0:\n            space_after_placement = non_exact_fitting_bins_cap - item\n\n            # Normalize differences to [0, 1] range for scoring\n            min_diff = np.min(space_after_placement)\n            max_diff = np.max(space_after_placement)\n\n            if max_diff - min_diff > 1e-9:\n                normalized_diff = (space_after_placement - min_diff) / (max_diff - min_diff)\n            else:\n                normalized_diff = np.zeros_like(space_after_placement) # All are same diff\n\n            # Assign priorities: inverse relationship with normalized difference, scaled\n            # Give higher priority to smaller differences (closer fits)\n            # Scale to be less than exact fit priority (e.g., 0.1 to 1.1)\n            priorities[non_exact_fitting_bins_indices] = 1.1 - normalized_diff\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined 'Best Fit' like strategy.\n\n    This heuristic prioritizes bins that leave the least remaining capacity after packing the item,\n    aiming to minimize wasted space. It also favors bins that have sufficient capacity,\n    assigning a lower priority to bins that are too small.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity if the item is placed in each bin\n    remaining_after_packing = bins_remain_cap - item\n\n    # Assign a priority score.\n    # For bins where the item fits (remaining_after_packing >= 0):\n    # Higher priority is given to bins with smaller remaining capacity after packing.\n    # This is achieved by using the negative of the remaining capacity (so smaller positive numbers are prioritized).\n    # We add a small epsilon to ensure that bins with zero remaining capacity after packing\n    # (i.e., perfect fit) have a very high priority (close to 0 when negated and scaled).\n    # For bins where the item does not fit, assign a very low priority (negative infinity conceptually).\n    epsilon = 1e-9\n    priorities = np.where(\n        remaining_after_packing >= 0,\n        -remaining_after_packing,\n        -np.inf\n    )\n\n    # Normalize priorities to be non-negative and to give a higher score to bins that are a better fit.\n    # Shifting by adding the maximum negative value (or minimum positive value) ensures all priorities are >= 0.\n    # The 'best fit' bins (closest to 0 remaining capacity) will have the highest scores.\n    min_priority = np.min(priorities[priorities != -np.inf]) if np.any(priorities != -np.inf) else 0\n    priorities = np.where(\n        priorities == -np.inf,\n        0,  # Bins where item doesn't fit get 0 priority\n        priorities - min_priority + epsilon # Shift to make all priorities non-negative and prioritize smallest remaining capacity\n    )\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined 'Best Fit' like strategy.\n\n    This heuristic prioritizes bins that leave the least remaining capacity after packing the item,\n    aiming to minimize wasted space. It also favors bins that have sufficient capacity,\n    assigning a lower priority to bins that are too small.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity if the item is placed in each bin\n    remaining_after_packing = bins_remain_cap - item\n\n    # Assign a priority score.\n    # For bins where the item fits (remaining_after_packing >= 0):\n    # Higher priority is given to bins with smaller remaining capacity after packing.\n    # This is achieved by using the negative of the remaining capacity (so smaller positive numbers are prioritized).\n    # We add a small epsilon to ensure that bins with zero remaining capacity after packing\n    # (i.e., perfect fit) have a very high priority (close to 0 when negated and scaled).\n    # For bins where the item does not fit, assign a very low priority (negative infinity conceptually).\n    epsilon = 1e-9\n    priorities = np.where(\n        remaining_after_packing >= 0,\n        -remaining_after_packing,\n        -np.inf\n    )\n\n    # Normalize priorities to be non-negative and to give a higher score to bins that are a better fit.\n    # Shifting by adding the maximum negative value (or minimum positive value) ensures all priorities are >= 0.\n    # The 'best fit' bins (closest to 0 remaining capacity) will have the highest scores.\n    min_priority = np.min(priorities[priorities != -np.inf]) if np.any(priorities != -np.inf) else 0\n    priorities = np.where(\n        priorities == -np.inf,\n        0,  # Bins where item doesn't fit get 0 priority\n        priorities - min_priority + epsilon # Shift to make all priorities non-negative and prioritize smallest remaining capacity\n    )\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Exact Fit First with Inverse Distance for robust bin packing.\n\n    Prioritizes exact fits, then falls back to the closest fit to minimize waste.\n    This hybrid approach balances ideal packing with practical close fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    epsilon = 1e-9\n\n    # Calculate exact fit priority: highest for bins where remaining capacity equals item size.\n    exact_fit_mask = np.abs(bins_remain_cap - item) < epsilon\n    priorities[exact_fit_mask] = 1.0\n\n    # Calculate inverse distance priority for bins that can fit the item and are not exact fits.\n    can_fit_mask = bins_remain_cap >= item\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(non_exact_fit_mask):\n        space_after_placement = bins_remain_cap[non_exact_fit_mask] - item\n        # Prioritize bins with smaller positive difference (less wasted space).\n        # Use a scaled inverse to ensure these priorities are lower than exact fits.\n        inverse_distance_scores = 1.0 / (space_after_placement + epsilon)\n        \n        # Normalize these scores to a range lower than 1.0, e.g., [0.5, 0.99]\n        # This ensures exact fits are still preferred.\n        min_norm = 0.5\n        max_norm = 0.99\n        \n        # Scale scores to [0, 1] based on their distribution, then shift to [0.5, 0.99]\n        if inverse_distance_scores.size > 1:\n            normalized_scores = (inverse_distance_scores - np.min(inverse_distance_scores)) / (np.max(inverse_distance_scores) - np.min(inverse_distance_scores) + epsilon)\n            scaled_scores = min_norm + normalized_scores * (max_norm - min_norm)\n        else:\n            # If only one bin, assign the midpoint of the secondary range\n            scaled_scores = (min_norm + max_norm) / 2.0\n\n        priorities[non_exact_fit_mask] = scaled_scores\n        \n    # Bins that cannot fit the item retain their default priority of 0.\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit priority with a normalized Best Fit strategy.\n    Gives highest priority to exact fits, then prioritizes bins with\n    the smallest remaining capacity that can fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # If no bins can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Exact Fit Strategy ---\n    # Prioritize bins that fit the item exactly with a high score\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    \n    # --- Normalized Best Fit Strategy ---\n    # For bins that do not fit exactly, calculate a score based on how close they are\n    # to fitting the item. Prioritize those with minimal excess capacity.\n    close_fit_mask_local = ~exact_fit_mask_local\n    \n    # Calculate excess capacity for close fits\n    excess_capacities = eligible_bins_remain_cap[close_fit_mask_local] - item\n    \n    # Assign high priority to exact fits\n    if np.any(exact_fit_mask_local):\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n        \n    # If there are close fits, calculate their priorities\n    if np.any(close_fit_mask_local):\n        # Normalize excess capacities to be between 0 and 1\n        # A smaller excess capacity should get a higher score.\n        # We use 1 / (normalized_excess + epsilon) to give higher scores to smaller excesses.\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities) # Max excess capacity among close fits\n\n        # Avoid division by zero if all close fits have the same excess capacity\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities) # All close fits have same excess\n        \n        # Calculate scores: higher score for smaller normalized excess capacity\n        # Add a base score to differentiate from bins that don't fit (score 0)\n        # and ensure scores are distinct from exact fits.\n        close_fit_scores = 0.5 + 0.45 * (1.0 / (normalized_excess + 1e-9)) # Scale to [0.5, ~0.95]\n        \n        # Ensure scores are not greater than exact fit priority\n        close_fit_scores = np.minimum(close_fit_scores, 0.99) \n        \n        # Assign scores to the corresponding bins\n        priorities[can_fit_mask][close_fit_mask_local] = close_fit_scores\n\n    # Ensure exact fits have priority over close fits if they overlap in scoring range\n    if np.any(exact_fit_mask_local) and np.any(close_fit_mask_local):\n         priorities[can_fit_mask][exact_fit_mask_local] = 1.0 # Re-assert max priority for exact fits\n\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit preference with a Best Fit fallback.\n    Prioritizes bins that exactly fit the item, then bins with minimal excess capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the exact fit score (highest priority)\n        exact_fit_mask = available_bins_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            \n        # Calculate the best fit score for remaining bins (secondary priority)\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            remaining_available_bins_cap = available_bins_cap[non_exact_fit_mask]\n            \n            # Prioritize bins with the least remaining capacity after placing the item\n            # Higher priority for smaller remaining space (closer fit)\n            # We invert (remaining_capacity - item) to make smaller values higher priorities\n            space_after_placement = remaining_available_bins_cap - item\n            \n            # Avoid division by zero and normalize to avoid extreme values\n            inverted_space = 1.0 / (space_after_placement + 1e-9) \n            \n            min_inv_space = np.min(inverted_space)\n            max_inv_space = np.max(inverted_space)\n            \n            if max_inv_space - min_inv_space > 1e-9:\n                normalized_priorities = (inverted_space - min_inv_space) / (max_inv_space - min_inv_space)\n            else:\n                normalized_priorities = np.ones_like(inverted_space) * 0.5 # Uniform if all same\n\n            # Add a small base priority to non-exact fits so they are considered after exact fits\n            # but only if they have higher priority than non-fitting bins (which is always 0)\n            priorities[can_fit_mask][non_exact_fit_mask] = normalized_priorities * 0.9\n            \n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit priority with a normalized Best Fit strategy.\n    Gives highest priority to exact fits, then prioritizes bins with\n    the smallest remaining capacity that can fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # If no bins can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Exact Fit Strategy ---\n    # Prioritize bins that fit the item exactly with a high score\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    \n    # --- Normalized Best Fit Strategy ---\n    # For bins that do not fit exactly, calculate a score based on how close they are\n    # to fitting the item. Prioritize those with minimal excess capacity.\n    close_fit_mask_local = ~exact_fit_mask_local\n    \n    # Calculate excess capacity for close fits\n    excess_capacities = eligible_bins_remain_cap[close_fit_mask_local] - item\n    \n    # Assign high priority to exact fits\n    if np.any(exact_fit_mask_local):\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n        \n    # If there are close fits, calculate their priorities\n    if np.any(close_fit_mask_local):\n        # Normalize excess capacities to be between 0 and 1\n        # A smaller excess capacity should get a higher score.\n        # We use 1 / (normalized_excess + epsilon) to give higher scores to smaller excesses.\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities) # Max excess capacity among close fits\n\n        # Avoid division by zero if all close fits have the same excess capacity\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities) # All close fits have same excess\n        \n        # Calculate scores: higher score for smaller normalized excess capacity\n        # Add a base score to differentiate from bins that don't fit (score 0)\n        # and ensure scores are distinct from exact fits.\n        close_fit_scores = 0.5 + 0.45 * (1.0 / (normalized_excess + 1e-9)) # Scale to [0.5, ~0.95]\n        \n        # Ensure scores are not greater than exact fit priority\n        close_fit_scores = np.minimum(close_fit_scores, 0.99) \n        \n        # Assign scores to the corresponding bins\n        priorities[can_fit_mask][close_fit_mask_local] = close_fit_scores\n\n    # Ensure exact fits have priority over close fits if they overlap in scoring range\n    if np.any(exact_fit_mask_local) and np.any(close_fit_mask_local):\n         priorities[can_fit_mask][exact_fit_mask_local] = 1.0 # Re-assert max priority for exact fits\n\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits with highest score, then bins with minimal excess\n    capacity, scaled to differentiate from exact fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Highest priority for exact fits\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    priorities[can_fit_mask][exact_fit_mask_local] = 2.0\n\n    # For non-exact fits, prioritize based on minimal excess capacity\n    non_exact_fit_mask_local = ~exact_fit_mask_local\n    if np.any(non_exact_fit_mask_local):\n        excess_capacities = eligible_bins_remain_cap[non_exact_fit_mask_local] - item\n        \n        # Normalize excess capacities to [0, 1]\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities)\n\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities) # All excess capacities are the same\n\n        # Assign priority: smaller normalized excess means higher priority, scaled to be less than exact fit score\n        # We use (1 - normalized_excess) to give higher score to smaller excess.\n        # Adding a small epsilon to the denominator for robustness, though normalization should handle it.\n        non_exact_priorities = 1.0 - normalized_excess\n        \n        # Scale these priorities to be between 0.1 and 1.0, ensuring they are always less than exact fit priority (2.0)\n        # and higher than the default 0.0\n        min_target_p = 0.1\n        max_target_p = 1.0\n        \n        if np.max(non_exact_priorities) - np.min(non_exact_priorities) > 1e-9:\n             scaled_non_exact_priorities = min_target_p + (non_exact_priorities - np.min(non_exact_priorities)) * (max_target_p - min_target_p) / (np.max(non_exact_priorities) - np.min(non_exact_priorities))\n        else:\n             scaled_non_exact_priorities = np.full_like(non_exact_priorities, (min_target_p + max_target_p) / 2.0)\n\n        priorities[can_fit_mask][non_exact_fit_mask_local] = scaled_non_exact_priorities\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit preference with a Best Fit fallback.\n    Prioritizes bins that exactly fit the item, then bins with minimal excess capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the exact fit score (highest priority)\n        exact_fit_mask = available_bins_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            \n        # Calculate the best fit score for remaining bins (secondary priority)\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            remaining_available_bins_cap = available_bins_cap[non_exact_fit_mask]\n            \n            # Prioritize bins with the least remaining capacity after placing the item\n            # Higher priority for smaller remaining space (closer fit)\n            # We invert (remaining_capacity - item) to make smaller values higher priorities\n            space_after_placement = remaining_available_bins_cap - item\n            \n            # Avoid division by zero and normalize to avoid extreme values\n            inverted_space = 1.0 / (space_after_placement + 1e-9) \n            \n            min_inv_space = np.min(inverted_space)\n            max_inv_space = np.max(inverted_space)\n            \n            if max_inv_space - min_inv_space > 1e-9:\n                normalized_priorities = (inverted_space - min_inv_space) / (max_inv_space - min_inv_space)\n            else:\n                normalized_priorities = np.ones_like(inverted_space) * 0.5 # Uniform if all same\n\n            # Add a small base priority to non-exact fits so they are considered after exact fits\n            # but only if they have higher priority than non-fitting bins (which is always 0)\n            priorities[can_fit_mask][non_exact_fit_mask] = normalized_priorities * 0.9\n            \n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit preference with a Best Fit fallback.\n    Prioritizes bins that exactly fit the item, then bins with minimal excess capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the exact fit score (highest priority)\n        exact_fit_mask = available_bins_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            \n        # Calculate the best fit score for remaining bins (secondary priority)\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            remaining_available_bins_cap = available_bins_cap[non_exact_fit_mask]\n            \n            # Prioritize bins with the least remaining capacity after placing the item\n            # Higher priority for smaller remaining space (closer fit)\n            # We invert (remaining_capacity - item) to make smaller values higher priorities\n            space_after_placement = remaining_available_bins_cap - item\n            \n            # Avoid division by zero and normalize to avoid extreme values\n            inverted_space = 1.0 / (space_after_placement + 1e-9) \n            \n            min_inv_space = np.min(inverted_space)\n            max_inv_space = np.max(inverted_space)\n            \n            if max_inv_space - min_inv_space > 1e-9:\n                normalized_priorities = (inverted_space - min_inv_space) / (max_inv_space - min_inv_space)\n            else:\n                normalized_priorities = np.ones_like(inverted_space) * 0.5 # Uniform if all same\n\n            # Add a small base priority to non-exact fits so they are considered after exact fits\n            # but only if they have higher priority than non-fitting bins (which is always 0)\n            priorities[can_fit_mask][non_exact_fit_mask] = normalized_priorities * 0.9\n            \n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits with highest score, then bins with minimal excess\n    capacity, scaled to differentiate from exact fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Highest priority for exact fits\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    priorities[can_fit_mask][exact_fit_mask_local] = 2.0\n\n    # For non-exact fits, prioritize based on minimal excess capacity\n    non_exact_fit_mask_local = ~exact_fit_mask_local\n    if np.any(non_exact_fit_mask_local):\n        excess_capacities = eligible_bins_remain_cap[non_exact_fit_mask_local] - item\n        \n        # Normalize excess capacities to [0, 1]\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities)\n\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities) # All excess capacities are the same\n\n        # Assign priority: smaller normalized excess means higher priority, scaled to be less than exact fit score\n        # We use (1 - normalized_excess) to give higher score to smaller excess.\n        # Adding a small epsilon to the denominator for robustness, though normalization should handle it.\n        non_exact_priorities = 1.0 - normalized_excess\n        \n        # Scale these priorities to be between 0.1 and 1.0, ensuring they are always less than exact fit priority (2.0)\n        # and higher than the default 0.0\n        min_target_p = 0.1\n        max_target_p = 1.0\n        \n        if np.max(non_exact_priorities) - np.min(non_exact_priorities) > 1e-9:\n             scaled_non_exact_priorities = min_target_p + (non_exact_priorities - np.min(non_exact_priorities)) * (max_target_p - min_target_p) / (np.max(non_exact_priorities) - np.min(non_exact_priorities))\n        else:\n             scaled_non_exact_priorities = np.full_like(non_exact_priorities, (min_target_p + max_target_p) / 2.0)\n\n        priorities[can_fit_mask][non_exact_fit_mask_local] = scaled_non_exact_priorities\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins that offer an exact fit or the smallest remaining capacity after placement.\n\n    Combines 'Exact Fit First' and 'Inverse Distance' strategies for a robust approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n        # Strategy 1: Exact Fit (Highest Priority)\n        exact_fit_mask = available_bins_remain_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            # If there are exact fits, we only consider them for ranking (effectively)\n            # but to allow other bins to have non-zero priority if needed, we proceed.\n            # However, for simplicity and clear hierarchy, we could return here if only exact fits are desired as the sole choice.\n            # For a more nuanced approach, we allow other bins to compete if they are \"close\".\n\n        # Strategy 2: Proximity Fit (Inverse of remaining capacity after placement)\n        # Assigns higher priority to bins that leave less space after placing the item.\n        # Avoids division by zero by adding a small epsilon.\n        space_after_placement = available_bins_remain_cap - item\n        \n        # We want to prioritize bins with smaller space_after_placement.\n        # Using 1 / (space_after_placement + epsilon) favors smaller positive differences.\n        # For bins where space_after_placement is 0 (exact fit), this will be 1/epsilon (very high).\n        # To avoid extremely high values for exact fits that might dominate too much,\n        # and to ensure proximity fits are ranked meaningfully, we can cap or scale.\n        # A simple approach is to ensure exact fits get priority 1.0 and then rank others.\n\n        # Let's refine: assign 1.0 to exact fits, and then rank the rest based on inverse remaining capacity.\n        \n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            non_exact_available_caps = available_bins_remain_cap[non_exact_fit_mask]\n            non_exact_space_after_placement = non_exact_available_caps - item\n\n            # Calculate inverse of remaining capacity (higher score for smaller remaining capacity)\n            # Add epsilon to avoid division by zero. The smaller the remaining capacity, the higher the score.\n            proximity_scores = 1.0 / (non_exact_space_after_placement + 1e-9)\n\n            # Normalize these scores to be between 0 and (1 - epsilon) to not overlap with exact fits\n            # if we wanted a strict hierarchy.\n            # For a combined heuristic, we can normalize them relative to each other.\n            if len(proximity_scores) > 0:\n                min_prox_score = np.min(proximity_scores)\n                max_prox_score = np.max(proximity_scores)\n                \n                # Normalize scores to a range that doesn't conflict with exact fit priority (e.g., 0 to 0.99)\n                # or simply use their relative ranking.\n                # Using ranks is often more robust than raw values.\n                \n                # Rank the non-exact fits based on their proximity score (higher score = better rank)\n                # argsort returns indices that would sort the array.\n                # We want higher proximity_scores to have higher ranks.\n                sorted_indices_for_non_exact = np.argsort(proximity_scores)\n                \n                # Assign ranks: the bin with the highest proximity_score gets the highest rank (close to 1).\n                # The indices obtained from argsort are ascending for smaller values.\n                # So, if proximity_scores are [10, 5, 20], argsort gives [1, 0, 2].\n                # We want ranks [0.33, 0.66, 1.0] or similar.\n                # Let's assign ranks such that smaller space_after_placement gets higher priority.\n                \n                # Sort the actual non-exact remaining capacities to get a clear order for prioritization.\n                sorted_non_exact_space_after = non_exact_space_after_placement[sorted_indices_for_non_exact]\n                \n                # Now assign priorities based on these sorted capacities.\n                # The bin with the smallest space_after_placement gets the highest priority (excluding exact fits).\n                # We can assign priorities from 0.0 up to something less than 1.0 (e.g., 0.99).\n                # Let's normalize the ranks to a range like [0.1, 0.9].\n                \n                if len(sorted_non_exact_space_after) > 1:\n                    rank_values = np.linspace(0.1, 0.9, len(sorted_non_exact_space_after))\n                    # The smallest remaining space should get the highest rank (0.9).\n                    # The current sorted_non_exact_space_after is ascending, so the last element is the largest.\n                    # We want to assign highest priority to the smallest values.\n                    assigned_priorities_for_non_exact = rank_values[::-1] # Reverse to give highest to smallest\n                else:\n                    assigned_priorities_for_non_exact = np.array([0.5]) # Default priority for single non-exact fit\n\n                # Map these assigned priorities back to the original indices of the available_bins_array.\n                # `sorted_indices_for_non_exact` are indices within `non_exact_available_caps`\n                # We need to map these back to `can_fit_mask` indices.\n                \n                # Get the original indices within `can_fit_mask` that correspond to non_exact_fit_mask\n                original_indices_of_non_exact_fits = np.where(can_fit_mask)[0][non_exact_fit_mask]\n                \n                # Update priorities for these bins\n                priorities[original_indices_of_non_exact_fits] = assigned_priorities_for_non_exact\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}