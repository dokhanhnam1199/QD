{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\n\n    In First Fit, the item is placed in the first bin that has enough remaining capacity.\n    This heuristic prioritizes bins that can accommodate the item and gives higher\n    priority to bins that have just enough capacity to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    # Assign a high priority to bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = 1.0\n\n    # Among those that can fit, prioritize bins that have just enough capacity.\n    # This is a greedy approach to minimize wasted space in the selected bin.\n    # We can use the inverse of the remaining capacity minus the item size as a measure\n    # of how \"tight\" the fit is. Smaller difference means higher priority.\n    tight_fit_scores = np.where(can_fit_mask, bins_remain_cap - item, np.inf)\n    \n    # Normalize the tight fit scores to avoid overly large or small values.\n    # Add a small epsilon to avoid division by zero if all differences are the same.\n    min_tight_fit = np.min(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 0\n    max_tight_fit = np.max(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 1\n    \n    if max_tight_fit - min_tight_fit > 1e-9: # Avoid division by zero if all are the same\n        normalized_tight_fit = (tight_fit_scores - min_tight_fit) / (max_tight_fit - min_tight_fit)\n    else:\n        normalized_tight_fit = np.zeros_like(tight_fit_scores)\n    \n    # Invert to give higher priority to smaller differences (tighter fits)\n    inverted_normalized_tight_fit = 1.0 - normalized_tight_fit\n    \n    # Combine the \"can fit\" priority with the \"tight fit\" priority.\n    # We want to boost bins that fit and then order them by tightness.\n    # The \"+ 0.1\" ensures that bins that can fit are always prioritized over those that cannot,\n    # even if their tight fit score is very high (which shouldn't happen if they can't fit).\n    priorities = np.where(can_fit_mask, 1.0 + inverted_normalized_tight_fit * 0.1, 0)\n    \n    # Ensure that bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\n\n    In First Fit, the item is placed in the first bin that has enough remaining capacity.\n    This heuristic prioritizes bins that can accommodate the item and gives higher\n    priority to bins that have just enough capacity to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    # Assign a high priority to bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = 1.0\n\n    # Among those that can fit, prioritize bins that have just enough capacity.\n    # This is a greedy approach to minimize wasted space in the selected bin.\n    # We can use the inverse of the remaining capacity minus the item size as a measure\n    # of how \"tight\" the fit is. Smaller difference means higher priority.\n    tight_fit_scores = np.where(can_fit_mask, bins_remain_cap - item, np.inf)\n    \n    # Normalize the tight fit scores to avoid overly large or small values.\n    # Add a small epsilon to avoid division by zero if all differences are the same.\n    min_tight_fit = np.min(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 0\n    max_tight_fit = np.max(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 1\n    \n    if max_tight_fit - min_tight_fit > 1e-9: # Avoid division by zero if all are the same\n        normalized_tight_fit = (tight_fit_scores - min_tight_fit) / (max_tight_fit - min_tight_fit)\n    else:\n        normalized_tight_fit = np.zeros_like(tight_fit_scores)\n    \n    # Invert to give higher priority to smaller differences (tighter fits)\n    inverted_normalized_tight_fit = 1.0 - normalized_tight_fit\n    \n    # Combine the \"can fit\" priority with the \"tight fit\" priority.\n    # We want to boost bins that fit and then order them by tightness.\n    # The \"+ 0.1\" ensures that bins that can fit are always prioritized over those that cannot,\n    # even if their tight fit score is very high (which shouldn't happen if they can't fit).\n    priorities = np.where(can_fit_mask, 1.0 + inverted_normalized_tight_fit * 0.1, 0)\n    \n    # Ensure that bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Inverse Distance (Proximity Fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between the remaining capacity and the item size\n    # This is the remaining space *after* placing the item.\n    space_after_placement = bins_remain_cap - item\n\n    # We want bins where the remaining capacity is just enough or slightly more than the item.\n    # A smaller positive difference is preferred.\n    # Bins with negative difference (item doesn't fit) should have very low priority.\n    # Inverse distance: smaller difference -> higher priority.\n    # Add a small epsilon to avoid division by zero if space_after_placement is exactly zero.\n    epsilon = 1e-9\n    priorities = 1 / (space_after_placement + epsilon)\n\n    # Set priority to a very low value for bins where the item does not fit\n    priorities[space_after_placement < 0] = -np.inf\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Inverse Distance (Proximity Fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between the remaining capacity and the item size\n    # This is the remaining space *after* placing the item.\n    space_after_placement = bins_remain_cap - item\n\n    # We want bins where the remaining capacity is just enough or slightly more than the item.\n    # A smaller positive difference is preferred.\n    # Bins with negative difference (item doesn't fit) should have very low priority.\n    # Inverse distance: smaller difference -> higher priority.\n    # Add a small epsilon to avoid division by zero if space_after_placement is exactly zero.\n    epsilon = 1e-9\n    priorities = 1 / (space_after_placement + epsilon)\n\n    # Set priority to a very low value for bins where the item does not fit\n    priorities[space_after_placement < 0] = -np.inf\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    available_bins_mask = bins_remain_cap >= item\n    \n    if np.any(available_bins_mask):\n        available_bins_remain_cap = bins_remain_cap[available_bins_mask]\n        \n        sorted_indices = np.argsort(available_bins_remain_cap)\n        \n        priorities[available_bins_mask] = 1.0 / (available_bins_remain_cap - item + 1e-9)\n        \n        priorities[available_bins_mask] = np.argsort(np.argsort(priorities[available_bins_mask]))\n    \n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic for online Bin Packing Problem.\n    Prioritizes bins that can fit the item exactly. Among those,\n    prioritizes bins with less remaining capacity to minimize wasted space.\n    If no bin fits exactly, it prioritizes bins with the least remaining capacity\n    that can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    exact_fit_bins_mask = (bins_remain_cap == item)\n    close_fit_bins_mask = (bins_remain_cap > item)\n\n    if np.any(exact_fit_bins_mask):\n        # Prioritize exact fits with highest priority (1)\n        priorities[exact_fit_bins_mask] = 1.0\n        # Among exact fits, a subtle bias towards less remaining capacity could be added if needed\n        # For exact fit, remaining capacity is zero, so no further differentiation needed here.\n    elif np.any(close_fit_bins_mask):\n        # If no exact fit, prioritize bins that fit with least remaining capacity\n        valid_bins_cap = bins_remain_cap[close_fit_bins_mask]\n        # Calculate a score inversely proportional to the excess capacity (bins_remain_cap - item)\n        # Adding a small epsilon to the denominator to avoid division by zero if item==0 or bins_remain_cap==item (already handled)\n        excess_capacities = valid_bins_cap - item\n        scores = 1.0 / (excess_capacities + 1e-9)\n\n        # Normalize scores to be between 0 and 1 for bins that can fit the item\n        # The highest score (least excess capacity) will be close to 1\n        max_score = np.max(scores)\n        if max_score > 0:\n            normalized_scores = scores / max_score\n        else:\n            normalized_scores = np.zeros_like(scores) # Should not happen with close_fit_bins_mask\n\n        # Assign these normalized scores to the corresponding bins\n        priorities[close_fit_bins_mask] = normalized_scores\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a Random Fit strategy for the online Bin Packing Problem.\n    Prioritizes bins that can fit the item. A higher priority is given\n    to bins with less remaining capacity that can still fit the item,\n    encouraging tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Assign priority based on how full the bin would become\n        # Smaller remaining capacity (i.e., larger fraction filled) gets higher priority\n        # We invert the remaining capacity to make smaller values larger priorities\n        inverted_cap = 1.0 / (available_bins_cap + 1e-9) # Add epsilon to avoid division by zero\n        \n        # Normalize priorities to be between 0 and 1\n        min_p = np.min(inverted_cap)\n        max_p = np.max(inverted_cap)\n        \n        if max_p - min_p > 1e-9:\n            normalized_priorities = (inverted_cap - min_p) / (max_p - min_p)\n        else:\n            normalized_priorities = np.ones_like(inverted_cap) * 0.5 # Uniform priority if all capacities are the same\n        \n        priorities[can_fit_mask] = normalized_priorities\n    \n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    available_bins_mask = bins_remain_cap >= item\n    \n    if np.any(available_bins_mask):\n        available_bins_remain_cap = bins_remain_cap[available_bins_mask]\n        \n        sorted_indices = np.argsort(available_bins_remain_cap)\n        \n        priorities[available_bins_mask] = 1.0 / (available_bins_remain_cap - item + 1e-9)\n        \n        priorities[available_bins_mask] = np.argsort(np.argsort(priorities[available_bins_mask]))\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic for online Bin Packing Problem.\n    Prioritizes bins that can fit the item exactly. Among those,\n    prioritizes bins with less remaining capacity to minimize wasted space.\n    If no bin fits exactly, it prioritizes bins with the least remaining capacity\n    that can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    exact_fit_bins_mask = (bins_remain_cap == item)\n    close_fit_bins_mask = (bins_remain_cap > item)\n\n    if np.any(exact_fit_bins_mask):\n        # Prioritize exact fits with highest priority (1)\n        priorities[exact_fit_bins_mask] = 1.0\n        # Among exact fits, a subtle bias towards less remaining capacity could be added if needed\n        # For exact fit, remaining capacity is zero, so no further differentiation needed here.\n    elif np.any(close_fit_bins_mask):\n        # If no exact fit, prioritize bins that fit with least remaining capacity\n        valid_bins_cap = bins_remain_cap[close_fit_bins_mask]\n        # Calculate a score inversely proportional to the excess capacity (bins_remain_cap - item)\n        # Adding a small epsilon to the denominator to avoid division by zero if item==0 or bins_remain_cap==item (already handled)\n        excess_capacities = valid_bins_cap - item\n        scores = 1.0 / (excess_capacities + 1e-9)\n\n        # Normalize scores to be between 0 and 1 for bins that can fit the item\n        # The highest score (least excess capacity) will be close to 1\n        max_score = np.max(scores)\n        if max_score > 0:\n            normalized_scores = scores / max_score\n        else:\n            normalized_scores = np.zeros_like(scores) # Should not happen with close_fit_bins_mask\n\n        # Assign these normalized scores to the corresponding bins\n        priorities[close_fit_bins_mask] = normalized_scores\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}