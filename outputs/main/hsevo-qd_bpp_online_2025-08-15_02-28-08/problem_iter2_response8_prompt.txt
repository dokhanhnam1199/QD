{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    available_bins_mask = bins_remain_cap >= item\n    \n    if np.any(available_bins_mask):\n        available_bins_remain_cap = bins_remain_cap[available_bins_mask]\n        \n        sorted_indices = np.argsort(available_bins_remain_cap)\n        \n        priorities[available_bins_mask] = 1.0 / (available_bins_remain_cap - item + 1e-9)\n        \n        priorities[available_bins_mask] = np.argsort(np.argsort(priorities[available_bins_mask]))\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1 and 2: These are identical. They implement a \"First Fit\" strategy that prioritizes bins that can fit the item, with a secondary priority given to bins that offer a \"tight fit\" to minimize fragmentation. The normalization of \"tight fit scores\" is a good attempt to make the priorities relative.\n\nComparing Heuristics 3 and 4: These are identical. They use an \"Inverse Distance\" (Proximity Fit) approach, prioritizing bins where the remaining capacity is just enough or slightly more than the item. The use of `1 / (space_after_placement + epsilon)` directly rewards smaller positive differences. Setting priority to `-np.inf` for bins that don't fit is a strong negative signal.\n\nComparing Heuristics 5 and 8: These are identical. They seem to aim for an \"Almost Full Fit\" by sorting available bins and assigning priorities based on their inverse remaining capacity after placing the item, then re-ranking these priorities. The re-ranking with `np.argsort(np.argsort(...))` is unusual and might be intended to assign ranks based on the sorted inverse capacities.\n\nComparing Heuristics 6 and 9: These are identical. They implement an \"Exact Fit First\" heuristic. They give the highest priority to bins where the remaining capacity *exactly* matches the item size. If no exact fit exists, they fall back to prioritizing bins with the least excess capacity (closest to an exact fit) among those that can fit the item. Normalization of scores to [0, 1] is applied in the fallback case.\n\nComparing Heuristics 7 and the others: Heuristic 7 uses a \"Random Fit\" description but its implementation is closer to a \"Best Fit\" variant. It prioritizes bins that can fit the item and assigns priorities based on the inverse of the remaining capacity (after fitting), normalizing these values. This favors bins that will be more full after the item is placed.\n\nComparing Heuristics 10, 11, and 12: These are identical. They represent a basic \"Inverse Fit\" strategy. They iterate through bins, assigning a priority of `1.0 / (bins_remain_cap - item + 1e-9)` if the item fits, and 0 otherwise. This is a straightforward approach to favor tighter fits.\n\nComparing Heuristics 13 through 20: These are all identical and represent a \"Sigmoid Fit Score\" heuristic. They aim to use a sigmoid function to assign priorities. The current implementation calculates `item / available_caps` as a `fit_quality`, intending to favor bins where the item fills a larger portion of the remaining capacity. A sigmoid is then applied to this `fit_quality` with specific `k` and `threshold` parameters. Bins that cannot fit the item receive a priority of 0.\n\nOverall Comparison:\n- **Best:** Heuristics 1 & 2 (\"First Fit\" with tight fit consideration) and Heuristics 3 & 4 (\"Inverse Distance\" / Proximity Fit) seem to be well-reasoned strategies for minimizing waste. Heuristics 6 & 9 (\"Exact Fit First\") are also strong, directly targeting ideal fits.\n- **Middle:** Heuristics 10, 11, 12 (basic \"Inverse Fit\") are simple and effective. Heuristic 7's implementation (normalized inverse capacity) is also reasonable.\n- **Lower:** Heuristics 5 & 8's use of `argsort(argsort())` is unclear in its intent and likely suboptimal.\n- **Worst:** Heuristics 13-20 (\"Sigmoid Fit Score\") have a complex, potentially over-engineered approach. The choice of `item / available_caps` and the specific sigmoid parameters (`k=10`, `threshold=0.7`) might not generalize well and could be sensitive to the distribution of item and bin sizes. The description also seems contradictory, mentioning penalizing large wasted space and then favoring bins where the item fills a \"significant portion\" (which implies less wasted space but also potentially very tight fits).\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Intuitiveness, Measurability, Robustness.\n*   **Advice:** Focus on simple, linear or monotonic relationships that directly address core problem objectives. Ensure your heuristic's behavior is easily understood and its impact on key metrics can be directly measured. Prioritize solutions that are less sensitive to parameter tuning and edge cases.\n*   **Avoid:** Overly complex, non-monotonic, or \"black box\" logic. Unnecessary algorithmic overhead. Heuristics that require extensive data fitting or are brittle to slight input variations.\n*   **Explanation:** Effective heuristics are transparent and predictable. By favoring straightforward logic and clear objectives, you create more robust and maintainable solutions that are easier to debug and improve over time, ultimately leading to better optimization outcomes.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}