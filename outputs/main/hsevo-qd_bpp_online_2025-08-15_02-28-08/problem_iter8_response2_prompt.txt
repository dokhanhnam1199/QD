{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements a Random Fit strategy for the online Bin Packing Problem.\n    Prioritizes bins that can fit the item. A higher priority is given\n    to bins with less remaining capacity that can still fit the item,\n    encouraging tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Assign priority based on how full the bin would become\n        # Smaller remaining capacity (i.e., larger fraction filled) gets higher priority\n        # We invert the remaining capacity to make smaller values larger priorities\n        inverted_cap = 1.0 / (available_bins_cap + 1e-9) # Add epsilon to avoid division by zero\n        \n        # Normalize priorities to be between 0 and 1\n        min_p = np.min(inverted_cap)\n        max_p = np.max(inverted_cap)\n        \n        if max_p - min_p > 1e-9:\n            normalized_priorities = (inverted_cap - min_p) / (max_p - min_p)\n        else:\n            normalized_priorities = np.ones_like(inverted_cap) * 0.5 # Uniform priority if all capacities are the same\n        \n        priorities[can_fit_mask] = normalized_priorities\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Exact Fit priority with a normalized Best Fit strategy.\n    Gives highest priority to exact fits, then prioritizes bins with\n    the smallest remaining capacity that can fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # If no bins can fit the item, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Exact Fit Strategy ---\n    # Prioritize bins that fit the item exactly with a high score\n    exact_fit_mask_local = (eligible_bins_remain_cap == item)\n    \n    # --- Normalized Best Fit Strategy ---\n    # For bins that do not fit exactly, calculate a score based on how close they are\n    # to fitting the item. Prioritize those with minimal excess capacity.\n    close_fit_mask_local = ~exact_fit_mask_local\n    \n    # Calculate excess capacity for close fits\n    excess_capacities = eligible_bins_remain_cap[close_fit_mask_local] - item\n    \n    # Assign high priority to exact fits\n    if np.any(exact_fit_mask_local):\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n        \n    # If there are close fits, calculate their priorities\n    if np.any(close_fit_mask_local):\n        # Normalize excess capacities to be between 0 and 1\n        # A smaller excess capacity should get a higher score.\n        # We use 1 / (normalized_excess + epsilon) to give higher scores to smaller excesses.\n        min_excess = 0.0\n        max_excess = np.max(excess_capacities) # Max excess capacity among close fits\n\n        # Avoid division by zero if all close fits have the same excess capacity\n        if max_excess > min_excess:\n            normalized_excess = (excess_capacities - min_excess) / (max_excess - min_excess)\n        else:\n            normalized_excess = np.zeros_like(excess_capacities) # All close fits have same excess\n        \n        # Calculate scores: higher score for smaller normalized excess capacity\n        # Add a base score to differentiate from bins that don't fit (score 0)\n        # and ensure scores are distinct from exact fits.\n        close_fit_scores = 0.5 + 0.45 * (1.0 / (normalized_excess + 1e-9)) # Scale to [0.5, ~0.95]\n        \n        # Ensure scores are not greater than exact fit priority\n        close_fit_scores = np.minimum(close_fit_scores, 0.99) \n        \n        # Assign scores to the corresponding bins\n        priorities[can_fit_mask][close_fit_mask_local] = close_fit_scores\n\n    # Ensure exact fits have priority over close fits if they overlap in scoring range\n    if np.any(exact_fit_mask_local) and np.any(close_fit_mask_local):\n         priorities[can_fit_mask][exact_fit_mask_local] = 1.0 # Re-assert max priority for exact fits\n\n\n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1st vs. 9th:** The 1st heuristic (`bins_remain_cap / (diff + epsilon)`) directly prioritizes bins where the remaining capacity is closest to the item size. The 9th heuristic attempts a similar goal but uses a more complex normalization and weighting scheme (`1.0 + inverted_normalized_tight_fit * 0.1`) which might overcomplicate the priority assignment without a clear performance gain. The 1st heuristic is more direct and likely more effective for its intended purpose.\n\n*   **Heuristics 2nd vs. 4th:** The 2nd heuristic seems to be a duplicate of the 1st heuristic in terms of its core logic (`bins_remain_cap / (diff + epsilon)`). The 4th heuristic (`1.0 / (available_bins_cap + 1e-9)`) and its normalized version gives higher priority to bins with *less* remaining capacity, which is a valid approach for favoring tighter fits. However, the 1st/2nd heuristic's score is `remaining_capacity / (remaining_capacity - item + epsilon)`, which can be interpreted as `(item + diff) / (diff + epsilon)`. This score is inherently higher when `diff` is smaller, effectively favoring tighter fits more strongly and potentially providing a better distinction between bins.\n\n*   **Heuristics 3rd vs. 11th/12th/14th/15th/16th/17th/18th/19th/20th:** These heuristics focus on an \"Exact Fit First\" strategy, which is a good principle.\n    *   Heuristics 3rd, 11th, 12th, 14th, 17th, 18th, 19th, 20th implement a hybrid approach: exact fits get the highest priority (e.g., 1.0 or 2.0), and then other fitting bins are prioritized based on their \"closeness\" (minimal excess capacity).\n    *   The normalization and scaling in these hybrids vary:\n        *   Heuristics 3rd and 11th/12th/14th use a form of `1 / (excess - min_excess + epsilon)` or similar to rank closer fits higher, scaling them to a specific range (e.g., `[0.5, 0.99]` or `[0.1, 0.9]`).\n        *   Heuristics 15th and 16th use `1.0 - normalized_diff + 0.1` which is a decreasing function of normalized difference, and assign a base priority of 2.0 to exact fits.\n        *   Heuristics 17th, 18th, 19th, 20th combine exact fit (priority 1.0) with a normalized proximity score that attempts to stay below 1.0. Heuristic 20th, for example, uses `1.0 / (space_after_placement + 1e-9)` and then ranks these, mapping them to `[0.1, 0.9]`.\n    *   The primary difference between these hybrid heuristics lies in the specific scoring and scaling of \"close fits\" and how strictly they enforce the hierarchy over exact fits. Heuristics 11th/12th/14th have a clear separation by using `[0.5, 0.99]` for close fits and `1.0` for exact fits. Heuristics 15th/16th assign `2.0` to exact fits, which is a stronger hierarchy. Heuristic 1st/2nd's score `bins_remain_cap / (diff + epsilon)` is a more direct approach to prioritizing close fits without explicit exact-fit separation, potentially making it more adaptable if an exact fit isn't always available.\n\n*   **Heuristics 5th vs. 7th:** These appear to be identical to Heuristic 4th, using a normalized inverse of available capacity.\n\n*   **Heuristics 6th:** This heuristic calculates `1.0 / (available_bins_remain_cap - item + 1e-9)` which is similar to the 1st/2nd heuristic's core idea, but then it applies `np.argsort(np.argsort(...))`. This effectively ranks the bins based on their proximity scores, assigning ranks from 0 to N-1. This means it prioritizes bins with smaller excesses, but the absolute priority values are just ranks, which might be less sensitive to the magnitude of differences compared to direct scores.\n\n*   **Heuristics 9th vs. 13th:** Heuristic 13th is a simple loop-based implementation of `1.0 / (bins_remain_cap[i] - item + 1e-9)` for fitting bins, which is the core logic of the \"inverse difference\" or \"best fit\" strategy. Heuristic 9th attempts a more complex normalization and weighting, which isn't clearly better than the direct inverse difference. Heuristic 13th is simpler but might suffer from non-vectorized operations if the list of bins is very large.\n\n*   **Overall:** The first heuristic (`bins_remain_cap / (diff + epsilon)`) seems to offer a good balance of simplicity and effectiveness by directly prioritizing bins where the remaining capacity is closest to the item size. Hybrid approaches (like 3rd, 11th, 15th) that explicitly handle exact fits first are also strong contenders. The \"normalized inverse remaining capacity\" (4th, 5th, 7th) is a reasonable heuristic for promoting tighter fits but might not distinguish as well between very close fits as the `bins_remain_cap / diff` approach. The ranking-based approach (6th) is also viable but potentially less nuanced.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Interpretability, Vectorization, Hybridization, Simplicity.\n*   **Advice:** Focus on direct, well-scaled scoring functions that clearly represent the heuristic's objective. Combine exact matches with robust \"close fit\" metrics, normalizing differences appropriately. Leverage vectorized operations extensively.\n*   **Avoid:** Overly complex, non-linear scoring functions that demand extensive tuning. Unnecessary array manipulations or obscure code that hinders clarity.\n*   **Explanation:** Prioritizing interpretable scores and vectorization ensures efficiency and maintainability, while a hybrid approach offers robustness by balancing exact solutions with practical approximations, directly informing heuristic design for better performance and adaptability.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}