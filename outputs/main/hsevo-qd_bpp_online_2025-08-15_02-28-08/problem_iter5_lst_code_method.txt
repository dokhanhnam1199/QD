{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\n\n    In First Fit, the item is placed in the first bin that has enough remaining capacity.\n    This heuristic prioritizes bins that can accommodate the item and gives higher\n    priority to bins that have just enough capacity to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    # Assign a high priority to bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = 1.0\n\n    # Among those that can fit, prioritize bins that have just enough capacity.\n    # This is a greedy approach to minimize wasted space in the selected bin.\n    # We can use the inverse of the remaining capacity minus the item size as a measure\n    # of how \"tight\" the fit is. Smaller difference means higher priority.\n    tight_fit_scores = np.where(can_fit_mask, bins_remain_cap - item, np.inf)\n    \n    # Normalize the tight fit scores to avoid overly large or small values.\n    # Add a small epsilon to avoid division by zero if all differences are the same.\n    min_tight_fit = np.min(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 0\n    max_tight_fit = np.max(tight_fit_scores[tight_fit_scores != np.inf]) if np.any(tight_fit_scores != np.inf) else 1\n    \n    if max_tight_fit - min_tight_fit > 1e-9: # Avoid division by zero if all are the same\n        normalized_tight_fit = (tight_fit_scores - min_tight_fit) / (max_tight_fit - min_tight_fit)\n    else:\n        normalized_tight_fit = np.zeros_like(tight_fit_scores)\n    \n    # Invert to give higher priority to smaller differences (tighter fits)\n    inverted_normalized_tight_fit = 1.0 - normalized_tight_fit\n    \n    # Combine the \"can fit\" priority with the \"tight fit\" priority.\n    # We want to boost bins that fit and then order them by tightness.\n    # The \"+ 0.1\" ensures that bins that can fit are always prioritized over those that cannot,\n    # even if their tight fit score is very high (which shouldn't happen if they can't fit).\n    priorities = np.where(can_fit_mask, 1.0 + inverted_normalized_tight_fit * 0.1, 0)\n    \n    # Ensure that bins that cannot fit have a priority of 0\n    priorities[~can_fit_mask] = 0\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    eligible_bins = bins_remain_cap >= item\n    eligible_capacities = bins_remain_cap[eligible_bins]\n\n    if eligible_capacities.size > 0:\n        diffs = eligible_capacities - item\n        min_diff = np.min(diffs)\n        priorities[eligible_bins] = 1.0 / (diffs - min_diff + 1e-9)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic for online Bin Packing Problem.\n    Prioritizes bins that can fit the item exactly. Among those,\n    prioritizes bins with less remaining capacity to minimize wasted space.\n    If no bin fits exactly, it prioritizes bins with the least remaining capacity\n    that can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    exact_fit_bins_mask = (bins_remain_cap == item)\n    close_fit_bins_mask = (bins_remain_cap > item)\n\n    if np.any(exact_fit_bins_mask):\n        # Prioritize exact fits with highest priority (1)\n        priorities[exact_fit_bins_mask] = 1.0\n        # Among exact fits, a subtle bias towards less remaining capacity could be added if needed\n        # For exact fit, remaining capacity is zero, so no further differentiation needed here.\n    elif np.any(close_fit_bins_mask):\n        # If no exact fit, prioritize bins that fit with least remaining capacity\n        valid_bins_cap = bins_remain_cap[close_fit_bins_mask]\n        # Calculate a score inversely proportional to the excess capacity (bins_remain_cap - item)\n        # Adding a small epsilon to the denominator to avoid division by zero if item==0 or bins_remain_cap==item (already handled)\n        excess_capacities = valid_bins_cap - item\n        scores = 1.0 / (excess_capacities + 1e-9)\n\n        # Normalize scores to be between 0 and 1 for bins that can fit the item\n        # The highest score (least excess capacity) will be close to 1\n        max_score = np.max(scores)\n        if max_score > 0:\n            normalized_scores = scores / max_score\n        else:\n            normalized_scores = np.zeros_like(scores) # Should not happen with close_fit_bins_mask\n\n        # Assign these normalized scores to the corresponding bins\n        priorities[close_fit_bins_mask] = normalized_scores\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    eligible_bins = bins_remain_cap >= item\n    eligible_capacities = bins_remain_cap[eligible_bins]\n\n    if eligible_capacities.size > 0:\n        diffs = eligible_capacities - item\n        min_diff = np.min(diffs)\n        priorities[eligible_bins] = 1.0 / (diffs - min_diff + 1e-9)\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Inverse Distance (Proximity Fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between the remaining capacity and the item size\n    # This is the remaining space *after* placing the item.\n    space_after_placement = bins_remain_cap - item\n\n    # We want bins where the remaining capacity is just enough or slightly more than the item.\n    # A smaller positive difference is preferred.\n    # Bins with negative difference (item doesn't fit) should have very low priority.\n    # Inverse distance: smaller difference -> higher priority.\n    # Add a small epsilon to avoid division by zero if space_after_placement is exactly zero.\n    epsilon = 1e-9\n    priorities = 1 / (space_after_placement + epsilon)\n\n    # Set priority to a very low value for bins where the item does not fit\n    priorities[space_after_placement < 0] = -np.inf\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic for online Bin Packing Problem.\n    Prioritizes bins that can fit the item exactly. Among those,\n    prioritizes bins with less remaining capacity to minimize wasted space.\n    If no bin fits exactly, it prioritizes bins with the least remaining capacity\n    that can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    exact_fit_bins_mask = (bins_remain_cap == item)\n    close_fit_bins_mask = (bins_remain_cap > item)\n\n    if np.any(exact_fit_bins_mask):\n        # Prioritize exact fits with highest priority (1)\n        priorities[exact_fit_bins_mask] = 1.0\n        # Among exact fits, a subtle bias towards less remaining capacity could be added if needed\n        # For exact fit, remaining capacity is zero, so no further differentiation needed here.\n    elif np.any(close_fit_bins_mask):\n        # If no exact fit, prioritize bins that fit with least remaining capacity\n        valid_bins_cap = bins_remain_cap[close_fit_bins_mask]\n        # Calculate a score inversely proportional to the excess capacity (bins_remain_cap - item)\n        # Adding a small epsilon to the denominator to avoid division by zero if item==0 or bins_remain_cap==item (already handled)\n        excess_capacities = valid_bins_cap - item\n        scores = 1.0 / (excess_capacities + 1e-9)\n\n        # Normalize scores to be between 0 and 1 for bins that can fit the item\n        # The highest score (least excess capacity) will be close to 1\n        max_score = np.max(scores)\n        if max_score > 0:\n            normalized_scores = scores / max_score\n        else:\n            normalized_scores = np.zeros_like(scores) # Should not happen with close_fit_bins_mask\n\n        # Assign these normalized scores to the corresponding bins\n        priorities[close_fit_bins_mask] = normalized_scores\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic for online Bin Packing Problem.\n    Prioritizes bins that can fit the item exactly. Among those,\n    prioritizes bins with less remaining capacity to minimize wasted space.\n    If no bin fits exactly, it prioritizes bins with the least remaining capacity\n    that can still fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    exact_fit_bins_mask = (bins_remain_cap == item)\n    close_fit_bins_mask = (bins_remain_cap > item)\n\n    if np.any(exact_fit_bins_mask):\n        # Prioritize exact fits with highest priority (1)\n        priorities[exact_fit_bins_mask] = 1.0\n        # Among exact fits, a subtle bias towards less remaining capacity could be added if needed\n        # For exact fit, remaining capacity is zero, so no further differentiation needed here.\n    elif np.any(close_fit_bins_mask):\n        # If no exact fit, prioritize bins that fit with least remaining capacity\n        valid_bins_cap = bins_remain_cap[close_fit_bins_mask]\n        # Calculate a score inversely proportional to the excess capacity (bins_remain_cap - item)\n        # Adding a small epsilon to the denominator to avoid division by zero if item==0 or bins_remain_cap==item (already handled)\n        excess_capacities = valid_bins_cap - item\n        scores = 1.0 / (excess_capacities + 1e-9)\n\n        # Normalize scores to be between 0 and 1 for bins that can fit the item\n        # The highest score (least excess capacity) will be close to 1\n        max_score = np.max(scores)\n        if max_score > 0:\n            normalized_scores = scores / max_score\n        else:\n            normalized_scores = np.zeros_like(scores) # Should not happen with close_fit_bins_mask\n\n        # Assign these normalized scores to the corresponding bins\n        priorities[close_fit_bins_mask] = normalized_scores\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Exact Fit First with Inverse Distance for robust bin packing.\n\n    Prioritizes exact fits, then falls back to the closest fit to minimize waste.\n    This hybrid approach balances ideal packing with practical close fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    epsilon = 1e-9\n\n    # Calculate exact fit priority: highest for bins where remaining capacity equals item size.\n    exact_fit_mask = np.abs(bins_remain_cap - item) < epsilon\n    priorities[exact_fit_mask] = 1.0\n\n    # Calculate inverse distance priority for bins that can fit the item and are not exact fits.\n    can_fit_mask = bins_remain_cap >= item\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(non_exact_fit_mask):\n        space_after_placement = bins_remain_cap[non_exact_fit_mask] - item\n        # Prioritize bins with smaller positive difference (less wasted space).\n        # Use a scaled inverse to ensure these priorities are lower than exact fits.\n        inverse_distance_scores = 1.0 / (space_after_placement + epsilon)\n        \n        # Normalize these scores to a range lower than 1.0, e.g., [0.5, 0.99]\n        # This ensures exact fits are still preferred.\n        min_norm = 0.5\n        max_norm = 0.99\n        \n        # Scale scores to [0, 1] based on their distribution, then shift to [0.5, 0.99]\n        if inverse_distance_scores.size > 1:\n            normalized_scores = (inverse_distance_scores - np.min(inverse_distance_scores)) / (np.max(inverse_distance_scores) - np.min(inverse_distance_scores) + epsilon)\n            scaled_scores = min_norm + normalized_scores * (max_norm - min_norm)\n        else:\n            # If only one bin, assign the midpoint of the secondary range\n            scaled_scores = (min_norm + max_norm) / 2.0\n\n        priorities[non_exact_fit_mask] = scaled_scores\n        \n    # Bins that cannot fit the item retain their default priority of 0.\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by favoring exact fits, then closest fits, using a smooth scoring.\n\n    Combines Exact Fit First and Inverse Distance strategies:\n    1. High priority for bins where remaining_capacity == item.\n    2. Medium priority for bins where remaining_capacity > item, inversely\n       proportional to the difference (remaining_capacity - item).\n    3. Zero priority for bins where remaining_capacity < item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n\n    fitting_bins_cap = bins_remain_cap[can_fit_mask]\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(fitting_bins_cap) > 0:\n        # Prioritize exact fits with a high score\n        exact_fit_mask = fitting_bins_cap == item\n        priorities[fitting_bins_indices[exact_fit_mask]] = 2.0  # Highest priority\n\n        # For bins that are not exact fits, calculate priority based on how close they are\n        non_exact_fitting_bins_cap = fitting_bins_cap[~exact_fit_mask]\n        non_exact_fitting_bins_indices = fitting_bins_indices[~exact_fit_mask]\n\n        if len(non_exact_fitting_bins_cap) > 0:\n            # Calculate the difference (space after placing the item)\n            space_after_placement = non_exact_fitting_bins_cap - item\n\n            # Normalize these differences to a [0, 1] range for scoring.\n            # Smaller difference means higher priority.\n            min_diff = np.min(space_after_placement)\n            max_diff = np.max(space_after_placement)\n\n            if max_diff - min_diff > 1e-9: # Avoid division by zero if all differences are the same\n                normalized_diff = (space_after_placement - min_diff) / (max_diff - min_diff)\n            else:\n                normalized_diff = np.zeros_like(space_after_placement)\n            \n            # Assign priorities: inverse relationship with normalized difference, scaled down.\n            # This gives medium priority, lower than exact fits.\n            # Add a small offset to ensure it's greater than 0 for fitting bins.\n            priorities[non_exact_fitting_bins_indices] = 1.0 - normalized_diff + 0.1\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by favoring exact fits, then closest fits, using a smooth scoring.\n\n    Combines Exact Fit First and Inverse Distance strategies:\n    1. High priority for bins where remaining_capacity == item.\n    2. Medium priority for bins where remaining_capacity > item, inversely\n       proportional to the difference (remaining_capacity - item).\n    3. Zero priority for bins where remaining_capacity < item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n\n    fitting_bins_cap = bins_remain_cap[can_fit_mask]\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(fitting_bins_cap) > 0:\n        # Prioritize exact fits with a high score\n        exact_fit_mask = fitting_bins_cap == item\n        priorities[fitting_bins_indices[exact_fit_mask]] = 2.0  # Highest priority\n\n        # For bins that are not exact fits, calculate priority based on how close they are\n        non_exact_fitting_bins_cap = fitting_bins_cap[~exact_fit_mask]\n        non_exact_fitting_bins_indices = fitting_bins_indices[~exact_fit_mask]\n\n        if len(non_exact_fitting_bins_cap) > 0:\n            # Calculate the difference (space after placing the item)\n            space_after_placement = non_exact_fitting_bins_cap - item\n\n            # Normalize these differences to a [0, 1] range for scoring.\n            # Smaller difference means higher priority.\n            min_diff = np.min(space_after_placement)\n            max_diff = np.max(space_after_placement)\n\n            if max_diff - min_diff > 1e-9: # Avoid division by zero if all differences are the same\n                normalized_diff = (space_after_placement - min_diff) / (max_diff - min_diff)\n            else:\n                normalized_diff = np.zeros_like(space_after_placement)\n            \n            # Assign priorities: inverse relationship with normalized difference, scaled down.\n            # This gives medium priority, lower than exact fits.\n            # Add a small offset to ensure it's greater than 0 for fitting bins.\n            priorities[non_exact_fitting_bins_indices] = 1.0 - normalized_diff + 0.1\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.any(can_fit_mask):\n        available_caps = bins_remain_cap[can_fit_mask]\n        \n        # Sigmoid-like function: higher priority for bins that are \"closer\" to fitting the item\n        # but not too close to waste significant space.\n        # We want to favor bins where item fills a significant portion of remaining capacity\n        # but leaves a reasonable amount.\n        \n        # Normalized remaining capacity relative to bin size if we were to fit the item\n        # Higher value means more wasted space if item is put in this bin\n        wasted_space_ratio = (available_caps - item) / available_caps\n        \n        # Apply sigmoid to map the ratio to a [0, 1] range, then invert it.\n        # We want to penalize large wasted_space_ratio, so we use 1 - sigmoid(x).\n        # A small positive constant 'k' is used to control the steepness of the sigmoid.\n        k = 5.0 \n        sigmoid_values = 1 / (1 + np.exp(-k * (wasted_space_ratio - 0.5)))\n        \n        # Invert the sigmoid: prioritize bins with lower wasted space ratio (closer fit)\n        # but avoid extremely tight fits by not making the priority too close to 1.\n        # A simple inversion (1 - sigmoid) might over-prioritize near-perfect fits.\n        # Let's try to emphasize the middle ground.\n        \n        # A different approach: penalize bins that are too large and too small for the item\n        # We want to find a bin that is \"just right\"\n        \n        # Let's define \"goodness\" of fit as how close the remaining capacity is to the item size.\n        # Normalize this difference.\n        \n        # Score: inversely proportional to the difference between remaining capacity and item size.\n        # But also, if remaining capacity is much larger than item size, it's not good.\n        \n        # Let's use the negative of the wasted space ratio as a base, which favors tighter fits.\n        # Then apply a sigmoid-like transform that peaks when wasted_space_ratio is around 0.\n        \n        # For each bin that can fit the item, calculate a score.\n        # Score = sigmoid( k * ( (available_caps - item) / AVAILABLE_CAP_SUM - 0.5) )\n        # Where AVAILABLE_CAP_SUM is the sum of capacities of bins that can fit the item.\n        # This might still be tricky.\n        \n        # Let's stick to a simple approach:\n        # Prioritize bins where the remaining capacity is just enough or slightly more than the item.\n        # A good heuristic: the inverse of the squared difference between remaining capacity and item size.\n        # However, this doesn't account for the \"too much space\" problem.\n        \n        # Let's try a sigmoid centered around the ideal fit (remaining_cap = item).\n        # The closer remaining_cap is to item, the higher the score.\n        \n        # Calculate a 'fit_quality' score for each bin that can fit the item.\n        # We want to penalize bins where `available_caps` is much larger than `item`.\n        # A possible metric: `item / available_caps`. This favors bins that are closer to being full if the item is added.\n        # Values are between 0 and 1. Higher means better fit (less wasted space).\n        fit_quality = item / available_caps\n        \n        # Apply a sigmoid to the fit_quality.\n        # Higher fit_quality means the bin is \"more full\" if the item is added.\n        # We want to map high fit_quality to high priority.\n        # Sigmoid(k * (fit_quality - threshold))\n        # Threshold can be around 0.5 for example, meaning we prefer bins where item takes up ~50% of remaining cap.\n        # A steeper sigmoid will favor very close fits.\n        \n        k_sigmoid = 10.0\n        threshold = 0.7 # Favor bins where item takes up more than 70% of remaining capacity\n        \n        scores_for_fitting_bins = 1 / (1 + np.exp(-k_sigmoid * (fit_quality - threshold)))\n        \n        priorities[can_fit_mask] = scores_for_fitting_bins\n        \n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit preference with a Best Fit fallback.\n    Prioritizes bins that exactly fit the item, then bins with minimal excess capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the exact fit score (highest priority)\n        exact_fit_mask = available_bins_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            \n        # Calculate the best fit score for remaining bins (secondary priority)\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            remaining_available_bins_cap = available_bins_cap[non_exact_fit_mask]\n            \n            # Prioritize bins with the least remaining capacity after placing the item\n            # Higher priority for smaller remaining space (closer fit)\n            # We invert (remaining_capacity - item) to make smaller values higher priorities\n            space_after_placement = remaining_available_bins_cap - item\n            \n            # Avoid division by zero and normalize to avoid extreme values\n            inverted_space = 1.0 / (space_after_placement + 1e-9) \n            \n            min_inv_space = np.min(inverted_space)\n            max_inv_space = np.max(inverted_space)\n            \n            if max_inv_space - min_inv_space > 1e-9:\n                normalized_priorities = (inverted_space - min_inv_space) / (max_inv_space - min_inv_space)\n            else:\n                normalized_priorities = np.ones_like(inverted_space) * 0.5 # Uniform if all same\n\n            # Add a small base priority to non-exact fits so they are considered after exact fits\n            # but only if they have higher priority than non-fitting bins (which is always 0)\n            priorities[can_fit_mask][non_exact_fit_mask] = normalized_priorities * 0.9\n            \n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins that offer an exact fit or the smallest remaining capacity after placement.\n\n    Combines 'Exact Fit First' and 'Inverse Distance' strategies for a robust approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n        # Strategy 1: Exact Fit (Highest Priority)\n        exact_fit_mask = available_bins_remain_cap == item\n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            # If there are exact fits, we only consider them for ranking (effectively)\n            # but to allow other bins to have non-zero priority if needed, we proceed.\n            # However, for simplicity and clear hierarchy, we could return here if only exact fits are desired as the sole choice.\n            # For a more nuanced approach, we allow other bins to compete if they are \"close\".\n\n        # Strategy 2: Proximity Fit (Inverse of remaining capacity after placement)\n        # Assigns higher priority to bins that leave less space after placing the item.\n        # Avoids division by zero by adding a small epsilon.\n        space_after_placement = available_bins_remain_cap - item\n        \n        # We want to prioritize bins with smaller space_after_placement.\n        # Using 1 / (space_after_placement + epsilon) favors smaller positive differences.\n        # For bins where space_after_placement is 0 (exact fit), this will be 1/epsilon (very high).\n        # To avoid extremely high values for exact fits that might dominate too much,\n        # and to ensure proximity fits are ranked meaningfully, we can cap or scale.\n        # A simple approach is to ensure exact fits get priority 1.0 and then rank others.\n\n        # Let's refine: assign 1.0 to exact fits, and then rank the rest based on inverse remaining capacity.\n        \n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            non_exact_available_caps = available_bins_remain_cap[non_exact_fit_mask]\n            non_exact_space_after_placement = non_exact_available_caps - item\n\n            # Calculate inverse of remaining capacity (higher score for smaller remaining capacity)\n            # Add epsilon to avoid division by zero. The smaller the remaining capacity, the higher the score.\n            proximity_scores = 1.0 / (non_exact_space_after_placement + 1e-9)\n\n            # Normalize these scores to be between 0 and (1 - epsilon) to not overlap with exact fits\n            # if we wanted a strict hierarchy.\n            # For a combined heuristic, we can normalize them relative to each other.\n            if len(proximity_scores) > 0:\n                min_prox_score = np.min(proximity_scores)\n                max_prox_score = np.max(proximity_scores)\n                \n                # Normalize scores to a range that doesn't conflict with exact fit priority (e.g., 0 to 0.99)\n                # or simply use their relative ranking.\n                # Using ranks is often more robust than raw values.\n                \n                # Rank the non-exact fits based on their proximity score (higher score = better rank)\n                # argsort returns indices that would sort the array.\n                # We want higher proximity_scores to have higher ranks.\n                sorted_indices_for_non_exact = np.argsort(proximity_scores)\n                \n                # Assign ranks: the bin with the highest proximity_score gets the highest rank (close to 1).\n                # The indices obtained from argsort are ascending for smaller values.\n                # So, if proximity_scores are [10, 5, 20], argsort gives [1, 0, 2].\n                # We want ranks [0.33, 0.66, 1.0] or similar.\n                # Let's assign ranks such that smaller space_after_placement gets higher priority.\n                \n                # Sort the actual non-exact remaining capacities to get a clear order for prioritization.\n                sorted_non_exact_space_after = non_exact_space_after_placement[sorted_indices_for_non_exact]\n                \n                # Now assign priorities based on these sorted capacities.\n                # The bin with the smallest space_after_placement gets the highest priority (excluding exact fits).\n                # We can assign priorities from 0.0 up to something less than 1.0 (e.g., 0.99).\n                # Let's normalize the ranks to a range like [0.1, 0.9].\n                \n                if len(sorted_non_exact_space_after) > 1:\n                    rank_values = np.linspace(0.1, 0.9, len(sorted_non_exact_space_after))\n                    # The smallest remaining space should get the highest rank (0.9).\n                    # The current sorted_non_exact_space_after is ascending, so the last element is the largest.\n                    # We want to assign highest priority to the smallest values.\n                    assigned_priorities_for_non_exact = rank_values[::-1] # Reverse to give highest to smallest\n                else:\n                    assigned_priorities_for_non_exact = np.array([0.5]) # Default priority for single non-exact fit\n\n                # Map these assigned priorities back to the original indices of the available_bins_array.\n                # `sorted_indices_for_non_exact` are indices within `non_exact_available_caps`\n                # We need to map these back to `can_fit_mask` indices.\n                \n                # Get the original indices within `can_fit_mask` that correspond to non_exact_fit_mask\n                original_indices_of_non_exact_fits = np.where(can_fit_mask)[0][non_exact_fit_mask]\n                \n                # Update priorities for these bins\n                priorities[original_indices_of_non_exact_fits] = assigned_priorities_for_non_exact\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}