import numpy as np

def heuristics_v2(distance_matrix):
    """{This algorithm refines the heuristic matrix by combining edge frequencies from 2-opt improved tours with a reinforcement learning approach that favors edges used in successful tours.}"""
    n = distance_matrix.shape[0]
    num_samples = 100
    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)
    reward_matrix = np.zeros_like(distance_matrix, dtype=float)
    alpha = 0.1  # Learning rate

    for _ in range(num_samples):
        # Generate a random tour
        tour = np.random.permutation(n)
        tour = np.append(tour, tour[0])  # Return to start

        # Improve the tour using 2-opt swaps
        improved_tour = tour.copy()
        best_cost = sum(distance_matrix[improved_tour[k], improved_tour[k+1]] for k in range(n))
        
        for i in range(n):
            for j in range(i + 2, n + 1):
                new_tour = np.concatenate((improved_tour[:i], improved_tour[i:j][::-1], improved_tour[j:]))
                
                new_cost = sum(distance_matrix[new_tour[k], new_tour[k+1]] for k in range(n))
                
                if new_cost < best_cost:
                    improved_tour = new_tour
                    best_cost = new_cost
                    
        # Update heuristics matrix and reward matrix
        for i in range(n):
            node1 = improved_tour[i]
            node2 = improved_tour[i+1]
            heuristics_matrix[node1, node2] += 1
            heuristics_matrix[node2, node1] += 1

            # Reward edges used in the improved tour
            reward_matrix[node1, node2] += alpha * (1 - reward_matrix[node1, node2])
            reward_matrix[node2, node1] += alpha * (1 - reward_matrix[node2, node1])

        # Penalize other edges (optional, but can improve performance)
        #for i in range(n):
        #    for j in range(i+1, n):
        #        if (improved_tour[:-1] != i).any() or (improved_tour[:-1] != j).any():
        #            reward_matrix[i, j] -= alpha * reward_matrix[i, j]
        #            reward_matrix[j, i] -= alpha * reward_matrix[j, i]



    heuristics_matrix /= num_samples
    heuristics_matrix = heuristics_matrix + reward_matrix # Combine frequency and reward

    return heuristics_matrix
