{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    bin_capacity: float = 1.0,\n    avg_future_item: float = None,\n) -> np.ndarray:\n    \"\"\"\n    Advanced priority function for online Bin Packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of the currently opened bins.\n    bin_capacity : float, optional\n        Fixed capacity of each bin (default = 1.0).\n    avg_future_item : float, optional\n        Expected size of a typical future item; used for a one\u2011step look\u2011ahead boost.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; higher values indicate more desirable bins.\n        Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n    feasible = waste >= 0\n\n    # Initialise priorities with -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        return priorities\n\n    # ---------- Parameter settings ----------\n    alpha = 5.0          # exponential slack penalty steepness\n    beta = 4.0           # scaling with current bin fullness\n    exact_fit_reward = 1e6\n    lookahead_boost = 0.2\n    epsilon = 1e-12\n    tol = 1e-9\n    # ----------------------------------------\n\n    # Fullness before placement (0 = empty, 1 = full)\n    fullness_before = (bin_capacity - bins_remain_cap) / bin_capacity\n    # Penalty steepness factor grows with bin fullness\n    factor = 1.0 + beta * fullness_before\n\n    # Normalized slack (waste) after placing the item\n    normalized_slack = waste / bin_capacity\n\n    # Exponential penalty: larger slack \u2192 more negative priority\n    penalty = -np.exp(alpha * normalized_slack * factor)\n\n    # Apply penalty to feasible bins\n    priorities[feasible] = penalty[feasible]\n\n    # Massive reward for an exact fit (waste \u2248 0)\n    exact_fit_mask = feasible & np.isclose(waste, 0.0, atol=tol)\n    priorities[exact_fit_mask] = exact_fit_reward\n\n    # One\u2011step look\u2011ahead boost if we have an estimate of future item size\n    if avg_future_item is not None:\n        boost_mask = feasible & (waste >= avg_future_item)\n        if np.any(boost_mask):\n            # Boost proportional to the surplus capacity beyond the expected future item\n            boost = lookahead_boost * ((waste[boost_mask] - avg_future_item) / bin_capacity)\n            priorities[boost_mask] += boost\n\n    # Tiny tie\u2011breaker: deterministic component (index) plus minuscule random noise\n    N = bins_remain_cap.size\n    det_eps = -np.arange(N) * epsilon\n    rand_eps = (np.random.rand(N) - 0.5) * epsilon * 0.1  # \u00b10.05\u00b7\u03b5\n    tie_breaker = det_eps + rand_eps\n    priorities += tie_breaker\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n\n    item: float,\n    bins_remain_cap: Union[np.ndarray, Sequence[float]],\n    *,\n    bin_capacity: Optional[float] = None,\n    lookahead_items: Optional[Union[np.ndarray, Sequence[float]]] = None,\n    k_base: float = 8.0,\n    alpha: float = 0.2,\n    jitter: float = 1e-7,\n    exact_fit_bonus: float = 0.15,\n    random_state: Optional[Union[int, np.random.Generator]] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins in an online Bin Packing problem.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : array\u2011like of float\n        Remaining capacity of each currently opened bin.\n    bin_capacity : float, optional\n        Fixed capacity of a bin.  If ``None`` a small estimate is derived\n        from the data (max remaining capacity + the incoming item).\n    lookahead_items : array\u2011like of float, optional\n        Sizes of future items.  Bins that can also accommodate more of these\n        items after the current placement receive a multiplicative boost.\n    k_base : float, default 8.0\n        Base steepness for the sigmoid.  Scaled by bin fullness.\n    alpha : float, default 0.2\n        Strength of the look\u2011ahead boost (0\u202f\u2264\u202falpha\u202f\u2264\u202f1).\n    jitter : float, default 1e-7\n        Amplitude of the random tie\u2011breaker noise.\n    exact_fit_bonus : float, default 0.15\n        Small additive bonus for bins that fit the item exactly.\n    random_state : int or np.random.Generator, optional\n        Seed or generator for the random tie\u2011breaker.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (same shape as ``bins_remain_cap``).  Infeasible bins\n        (remaining capacity < ``item``) receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Prepare input\n    # ------------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = bins.size\n\n    if n_bins == 0:\n        return np.empty(0, dtype=float)\n\n    # ------------------------------------------------------------------\n    # 2. Infer bin capacity if not provided\n    # ------------------------------------------------------------------\n    if bin_capacity is None:\n        # Use the largest observed remaining capacity plus the current item.\n        # Adding a tiny epsilon guards against division\u2011by\u2011zero.\n        bin_capacity = float(np.max(bins) + item + 1e-9)\n    else:\n        bin_capacity = float(bin_capacity)\n\n    if bin_capacity <= 0.0:\n        raise ValueError(\"Bin capacity must be positive.\")\n\n    # ------------------------------------------------------------------\n    # 3. Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No bin can host the item.\n        return np.full_like(bins, -np.inf, dtype=float)\n\n    # ------------------------------------------------------------------\n    # 4. Slack (remaining capacity after placing the item)\n    # ------------------------------------------------------------------\n    slack = bins - item                       # may be negative for infeasible bins\n\n    # ------------------------------------------------------------------\n    # 5. Normalised slack (gap) and bin fullness (used fraction)\n    # ------------------------------------------------------------------\n    # Normalise slack to [0, 1] using the (estimated) bin capacity.\n    norm_gap = np.clip(slack / bin_capacity, 0.0, 1.0)\n\n    # Fullness = used capacity / total capacity\n    fullness = np.clip((bin_capacity - bins) / bin_capacity, 0.0, 1.0)\n\n    # ------------------------------------------------------------------\n    # 6. Dynamic sigmoid steepness based on bin fullness\n    # ------------------------------------------------------------------\n    # Bins that are already more full get a steeper curve, rewarding\n    # tight fits even more strongly.\n    k = k_base * (1.0 + fullness)               # shape (n_bins,)\n\n    # ------------------------------------------------------------------\n    # 7. Sigmoid score favouring tighter fits\n    # ------------------------------------------------------------------\n    # We want a monotone decreasing function of the normalised gap.\n    # Using shift = 1 - norm_gap makes a perfect fit (gap=0) give the\n    # largest exponent, hence the highest sigmoid value.\n    shift = 1.0 - norm_gap                       # larger -> tighter fit\n    exponent = k * shift                        # shape (n_bins,)\n\n    # feasible bins only\n    # Clip exponent to avoid overflow in exp()\n    exponent = np.clip(exponent, -700.0, 700.0)\n\n    # Logistic sigmoid in (0, 1)\n    scores = 1.0 / (1.0 + np.exp(-exponent))\n\n    # ------------------------------------------------------------------\n    # 8. Exact\u2011fit bonus (small additive bump)\n    # ------------------------------------------------------------------\n    exact_fit_mask = feasible & np.isclose(slack, 0.0, atol=1e-12)\n    scores[exact_fit_mask] += exact_fit_bonus\n\n    # ------------------------------------------------------------------\n    # 9. Look\u2011ahead boost (optional)\n    # ------------------------------------------------------------------\n    if lookahead_items is not None:\n        lookahead = np.asarray(lookahead_items, dtype=float).ravel()\n        if lookahead.size > 0:\n            # Capacity left after the current placement for each feasible bin.\n            remaining_after = slack[feasible]                      # >= 0\n            # Count how many look\u2011ahead items each bin could still accommodate.\n            fits = (remaining_after[:, None] >= lookahead[None, :]).sum(axis=1)\n            fit_ratio = fits.astype(float) / float(lookahead.size)                                   # in [0, 1]\n            boost = 1.0 + np.clip(alpha, 0.0, 1.0) * fit_ratio\n            scores[feasible] *= boost\n\n    # ------------------------------------------------------------------\n    # 10. Tiny random tie\u2011breaker\n    # ------------------------------------------------------------------\n    rng = np.random.default_rng(random_state)\n    scores[feasible] += rng.uniform(0.0, jitter, size=np.count_nonzero(feasible))\n\n    # ------------------------------------------------------------------\n    # 11. Assemble final priority vector\n    # ------------------------------------------------------------------\n    priority = np.full_like(bins, -np.inf, dtype=float)\n    priority[feasible] = scores[feasible]\n\n    return priority\n\n[Reflection]\nUse sigmoid scoring, dynamic steepness, small exact\u2011fit bonus, lookahead multiplier, normalize slack, avoid extreme penalties, add tiny jitter.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}