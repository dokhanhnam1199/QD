```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Adaptive priority for online bin packing.

    - Scores only feasible bins (remaining capacity >= item).
    - Uses a sharp sigmoid centred at a small residual threshold to
      boost exact or near‑exact fits.
    - Penalises waste exponentially based on the normalised leftover.
    - Adds a decaying epsilon random perturbation for exploration.
    - Deterministic tie‑breaker via a tiny bias favouring lower indices.
    - Infeasible bins receive -inf.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.

    Returns
    -------
    np.ndarray
        Priority scores (higher = more desirable). Shape matches
        `bins_remain_cap`.
    """
    caps = np.asarray(bins_remain_cap, dtype=float)
    if caps.size == 0:
        return np.array([], dtype=float)

    # Residual capacity after placing the item in each bin.
    residual = caps - item
    feasible = residual >= 0

    # If nothing fits, penalise all bins.
    if not np.any(feasible):
        return np.full_like(caps, -np.inf, dtype=float)

    # Estimate bin capacity (assume at least one empty bin exists).
    bin_capacity = np.max(caps)
    if bin_capacity <= 0:
        # Fallback: use the largest possible capacity inferred from residuals.
        bin_capacity = np.max(caps + residual)
    if bin_capacity <= 0:
        bin_capacity = 1.0  # safety fallback

    # Normalised residual (relative waste).
    norm_res = residual / bin_capacity

    # Adaptive sigmoid steepness based on spread of feasible residuals.
    feasible_res = residual[feasible]
    spread = np.std(feasible_res)
    if spread <= 0.0:
        spread = np.ptp(feasible_res)  # range as fallback
    if spread <= 0.0:
        spread = 1.0

    base_steepness = 10.0  # tunable: larger → sharper transition
    slope = base_steepness / spread

    # Threshold for a “tight” fit (e.g., 5 % of bin capacity).
    tight_threshold = 0.05 * bin_capacity

    # Sharp sigmoid: high score for residual << tight_threshold, low otherwise.
    # sigmoid(x) = 1 / (1 + exp(slope * (x - tight_threshold)))
    exp_arg = slope * (residual - tight_threshold)
    exp_arg = np.clip(exp_arg, -700, 700)  # avoid overflow
    sigmoid_score = 1.0 / (1.0 + np.exp(exp_arg))

    # Exponential waste penalty: larger residual → stronger penalty.
    alpha = 5.0  # tunable
    waste_penalty = np.exp(alpha * norm_res)  # >= 1
    base_score = sigmoid_score / waste_penalty

    # Infeasible bins get -inf.
    scores = np.where(feasible, base_score, -np.inf)

    # --- Decaying epsilon exploration ---
    # Initialise static call counter.
    if not hasattr(priority_v2, "_call_count"):
        priority_v2._call_count = 0
    priority_v2._call_count += 1

    # Epsilon decays as 1/sqrt(call_count) (adjustable schedule).
    epsilon0 = 0.01
    epsilon = epsilon0 / np.sqrt(priority_v2._call_count)

    # Add small random perturbation to feasible scores.
    noise = np.random.rand(caps.shape[0]) * epsilon
    scores = np.where(feasible, scores + noise, scores)

    # --- Deterministic tie‑breaker (tiny bias for lower index) ---
    tie_bias = -np.arange(caps.shape[0]) * 1e-12
    scores = np.where(scores > -np.inf, scores + tie_bias, scores)

    return scores
```
