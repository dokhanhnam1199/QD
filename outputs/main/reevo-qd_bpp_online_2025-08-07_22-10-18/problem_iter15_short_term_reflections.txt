Prefer MAD‑based spread, logistic scaling, deterministic tie‑breakers, minimal parameters, skip normalisation.
Prefer simple adaptive scoring; calibrate sigmoid steepness by residual variance; avoid global state; favor exact fits.
Prioritize simple deterministic scores; penalize waste proportionally; avoid complex sigmoids, random noise, and elaborate tie‑breakers.
Adapt steepness via median leftover, cap exponentials, reward exact fits, normalise, avoid per‑call randomness, deterministic tie‑break.
Adapt steepness via robust spread (MAD), use smooth sigmoid, enforce numeric stability, deterministic tie‑breaker, avoid division by zero.
Prefer deterministic best‑fit, boost exact fits, avoid complex sigmoids and noise; keep scores simple, monotonic.
Prefer exact‑fit boost, deterministic best‑fit, avoid random noise, keep tie‑breaking minimal.
Use MAD for scaling; smooth sigmoid; deterministic tie‑breakers; clip exponents; handle zero spread.
Make epsilon adaptive, smooth scoring rather than discrete boost, incorporate bin utilization and waste, use sigmoid, jitter.
Use adaptive epsilon, normalize waste, dynamic sigmoid, avoid per‑call counters, use vectorized ops, tiny random tie‑breaker.
