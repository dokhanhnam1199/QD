{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global state for adaptive behavior\n_call_counter: int = 0\n_total_item_size: float = 0.0\n\n# Exploration parameters (epsilon\u2011greedy)\n_EPSILON0: float = 0.2          # Initial exploration probability\n_MIN_EPSILON: float = 0.01      # Minimum exploration probability\n_DECAY_RATE: float = 0.001      # Exponential decay rate of epsilon\n\n# Penalty weight for waste compared to average item size\n_ALPHA: float = 0.5\n\n    \"\"\"\n    Priority function for online Bin Packing that combines:\n\n      * Exact\u2011fit first: bins that fit the item exactly get infinite priority.\n      * Best\u2011fit: for other feasible bins, priority is inversely proportional to\n        the waste (remaining capacity after placing the item).\n      * Adaptive epsilon\u2011greedy exploration: with a decaying probability\n        the algorithm selects a random feasible bin.\n      * Waste penalty weighted by the average item size: bins whose waste\n        is significantly larger than the observed average item size are\n        penalised.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more preferred).  Bins that\n        cannot accommodate the item receive -inf.\n    \"\"\"\n    global _call_counter, _total_item_size\n\n    # Ensure a NumPy array of floats\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Update online statistics\n    _call_counter += 1\n    _total_item_size += item\n    avg_item_size = _total_item_size / _call_counter\n\n    # Dynamic epsilon (decays exponentially, never below _MIN_EPSILON)\n    epsilon = max(_MIN_EPSILON, _EPSILON0 * np.exp(-_DECAY_RATE * _call_counter))\n\n    rng = np.random.default_rng()\n\n    # Exploration branch: random feasible bin with probability epsilon\n    if rng.random() < epsilon:\n        feasible = bins_remain_cap >= item\n        random_scores = rng.random(bins_remain_cap.shape[0])\n        return np.where(feasible, random_scores, -np.inf)\n\n    # Deterministic scoring branch\n    waste = bins_remain_cap - item\n\n    # Masks\n    atol = 1e-9\n    exact_fit_mask = np.isclose(waste, 0.0, atol=atol)\n    feasible_mask = waste >= -atol  # allow slight negative due to tolerance\n\n    # Initialize priorities to -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Exact fits get infinite priority\n    priorities[exact_fit_mask] = np.inf\n\n    # Non\u2011exact but feasible bins get priority inversely proportional to waste\n    non_exact_mask = feasible_mask & ~exact_fit_mask\n    if np.any(non_exact_mask):\n        eps = 1e-12\n        base_score = 1.0 / (waste[non_exact_mask] + eps)\n        # Penalty for waste larger than the average item size\n        excess = np.maximum(0.0, waste[non_exact_mask] - avg_item_size)\n        penalty = _ALPHA * excess\n        priorities[non_exact_mask] = base_score - penalty\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Adaptive sigmoid priority for online bin packing.\n\n    The function returns a score for each bin; higher scores indicate more\n    desirable bins for placing the incoming ``item``. The scoring uses a smooth\n    sigmoid that adapts its steepness to the dispersion of feasible residual\n    capacities, avoiding hard thresholds. Infeasible bins receive ``-inf``.\n    A tiny deterministic tie\u2011breaker favours lower\u2011index bins when scores are\n    otherwise equal.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores (same shape as ``bins_remain_cap``).\n    \"\"\"\n    # Ensure a 1\u2011D float array.\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.shape[0]\n\n    # Empty case.\n    if n_bins == 0:\n        return np.empty(0, dtype=float)\n\n    # Residual capacity after packing the item.\n    residual = caps - item\n\n    # Feasibility mask.\n    feasible = residual >= 0\n\n    # Initialise all scores to -inf (infeasible).\n    scores = np.full(n_bins, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return the -inf vector.\n    if not np.any(feasible):\n        return scores\n\n    # Residual capacities of feasible bins.\n    feas_res = residual[feasible]\n\n    # --- Adaptive steepness -------------------------------------------------\n    # Robust spread estimator: Median Absolute Deviation (MAD).\n    median_res = np.median(feas_res)\n    mad = np.median(np.abs(feas_res - median_res))\n    # Convert MAD to an estimate of standard deviation (for normal data).\n    spread = mad * 1.4826\n\n    # Fallback strategies if MAD is zero.\n    if spread <= 0.0:\n        std = np.std(feas_res)\n        if std > 0.0:\n            spread = std\n        else:\n            # Use range as last resort.\n            rng = np.max(feas_res) - np.min(feas_res)\n            spread = rng if rng > 0.0 else 1.0\n\n    # Base steepness factor (tunable). Larger spread \u2192 softer sigmoid.\n    base_steepness = 5.0\n    slope = base_steepness / spread\n\n    # --- Sigmoid scoring ----------------------------------------------------\n    # Logistic function decreasing with residual.\n    # score = 1 / (1 + exp(slope * residual))\n    # Clip exponent to avoid overflow/underflow.\n    exp_arg = np.clip(slope * residual[feasible], -700, 700)\n    scores_feas = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Assign scores to feasible bins.\n    scores[feasible] = scores_feas\n\n    # --- Deterministic tie\u2011breaker -----------------------------------------\n    # Tiny decreasing bias with index ensures stable ordering when scores tie.\n    epsilon = 1e-12\n    tie_bias = -np.arange(n_bins, dtype=float) * epsilon\n    scores = np.where(scores > -np.inf, scores + tie_bias, scores)\n\n    return scores\n\n[Reflection]\nPrefer smooth adaptive scores, use dispersion\u2011based steepness, tie\u2011break deterministically, limit randomness, avoid hard cutoffs.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}