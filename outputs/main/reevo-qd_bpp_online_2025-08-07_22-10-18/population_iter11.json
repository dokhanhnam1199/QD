[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    return priorities",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 3.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Best\u2011Fit priority for online Bin Packing.\n\n    The bin that leaves the smallest remaining capacity after receiving the\n    *item* gets the highest priority. Bins that cannot accommodate the item\n    receive a very low (\u2011inf) priority and will never be selected.\n\n    Args:\n        item: Size of the incoming item.\n        bins_remain_cap: 1\u2011D array of remaining capacities for each existing bin.\n\n    Returns:\n        NumPy array with a priority score for each bin (higher means more\n        preferred). The shape matches ``bins_remain_cap``.\n    \"\"\"\n    # Work in floating point to safely use -inf for infeasible bins.\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Remaining space after the item would be placed.\n    leftover = caps - item\n\n    # Assign priority: bins that can fit the item get -leftover (higher for\n    # smaller leftover). Infeasible bins get -inf.\n    priorities = np.where(leftover >= 0, -leftover, -np.inf)\n\n    # Tiny tie\u2011breaker: favor lower\u2011index bins when leftover is identical.\n    # This epsilon is far smaller than any realistic leftover value.\n    epsilon = 1e-9\n    tie_break = -epsilon * np.arange(priorities.size)\n    priorities = priorities + tie_break\n\n    return priorities",
    "response_id": 21,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Best\u2011Fit priority for online Bin Packing.\n\n    For each bin the function evaluates the remaining space that would be left\n    after placing ``item``.  Bins that can accommodate the item receive a\n    priority proportional to the negative of this leftover \u2013 i.e. a smaller\n    leftover yields a larger priority.  Bins that cannot fit the item are\n    assigned ``-np.inf`` so they are never selected.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacity of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``). The\n        caller should select the bin with the highest priority.\n    \"\"\"\n    # Compute the prospective leftover space after adding the item.\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask: only bins with non\u2011negative leftover can hold the item.\n    feasible = leftover >= 0\n\n    # Base priority: -leftover (smaller leftover \u2192 larger priority).\n    # Infeasible bins receive -inf.\n    priorities = np.where(feasible, -leftover, -np.inf)\n\n    # ----------------------------------------------------------------------\n    # OPTIONAL tie\u2011breaker: prefer earlier bins (lower index) when priorities\n    # are otherwise identical.  This adds a negligible offset that does not\n    # alter the main ordering.\n    # ----------------------------------------------------------------------\n    if priorities.size:\n        # Machine epsilon for the array's dtype (or float64 if integer).\n        eps = np.finfo(priorities.dtype).eps if np.issubdtype(priorities.dtype, np.floating) else np.finfo(np.float64).eps\n        tie_break = np.arange(priorities.size, dtype=priorities.dtype) * eps\n        priorities = priorities - tie_break\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\n# Exploration probability for the epsilon\u2011greedy strategy\nEPSILON = 0.1\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Epsilon\u2011greedy priority function for online Bin Packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Array of the remaining capacities of the open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin. The bin with the highest score\n        will be selected. Bins that cannot accommodate the item are\n        assigned a very low priority (-\u221e).\n    \"\"\"\n    rng = np.random.default_rng()\n\n    # Exploration phase with probability EPSILON\n    if rng.random() < EPSILON:\n        # Generate uniform random scores for a purely random pick\n        return rng.random(bins_remain_cap.shape[0])\n\n    # Exploitation phase: best\u2011fit measure\n    leftover = bins_remain_cap - item\n    # Only bins that can hold the item are considered; others get -\u221e\n    priorities = np.where(leftover >= 0, leftover, -np.inf)\n    return priorities",
    "response_id": 8,
    "obj": 137.9537295572397,
    "SLOC": 7.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Return priority scores for placing an incoming item into existing bins\n    based on the Exact\u2011Fit\u2011First heuristic.\n\n    Parameters\n    ----------\n    item : float\n        Size of the new item that needs to be packed.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for all currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Same shape as *bins_remain_cap*; each entry is the priority score\n        for placing *item* into the corresponding bin.  The bin with the\n        maximum score will be selected by the scheduler.\n    \"\"\"\n    # Initialise with a very low score to effectively drop bins that\n    # cannot accommodate the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Mask for bins that can hold the item\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        # No bin can contain the item \u2013 all scores remain -inf\n        return priorities\n\n    # Space that would be left after the placement\n    leftovers = bins_remain_cap[fit_mask] - item\n\n    # Detect bins that would result in an exact fit\n    exact_mask = np.isclose(leftovers, 0.0, atol=1e-9)\n\n    # Base score prefers smaller leftover (best\u2011fit principle):\n    # larger (less negative) values correspond to better fit.\n    base_score = -leftovers\n    # Boost the score for exact fits so they outrank all non\u2011exact ones.\n    boost = 10.0  # arbitrary large constant\n\n    # Compute final scores\n    priorities[fit_mask] = base_score + (exact_mask * boost)\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Inverse Distance (Proximity Fit) priority for online Bin Packing.\n\n    For each bin that can accommodate the item, compute the leftover capacity\n    after placing the item and assign a priority equal to the inverse of that\n    leftover (plus a tiny epsilon to avoid division by zero).  \n    Bins that cannot hold the item receive a very large negative priority,\n    ensuring they are never chosen.  \n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacity of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher is better).\n    \"\"\"\n    # Compute available space after packing `item`\n    space_left = bins_remain_cap - item\n\n    # Only consider bins that can hold the item\n    valid = space_left >= 0\n\n    # Avoid division by zero with a very small epsilon\n    eps = 1e-12\n\n    # Inverse distance priority: the closer the remaining space to zero,\n    # the higher the priority. Use -np.inf for invalid bins.\n    priorities = np.where(\n        valid,\n        1.0 / (space_left + eps),  # Inverse of leftover space\n        -np.inf                    # Completely invalid bins\n    )\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for each bin using a Sigmoid Fit Score strategy.\n    Bins that cannot accommodate the item receive a very low priority (-inf).\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to be packed.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores for each bin.  The bin with the highest\n        priority score will be chosen to store the item.\n    \"\"\"\n    # Ensure numeric types for accurate arithmetic\n    rem = bins_remain_cap.astype(float, copy=False)\n\n    # Mask of bins that can actually fit the item\n    fit_mask = rem >= item\n\n    # Initialize all priorities with negative infinity (bins that cannot fit)\n    priorities = np.full_like(rem, -np.inf, dtype=float)\n\n    if not np.any(fit_mask):\n        return priorities  # no bin can fit the item\n\n    # Compute the difference between remaining capacity and the item size\n    diff = rem[fit_mask] - item\n\n    # The fill ratio after placing the item: value in (0, 1]\n    fill_ratio = 1.0 - diff / rem[fit_mask]\n\n    # Logistic (sigmoid) transformation to obtain a smooth prioritization\n    # Good fit (fill_ratio close to 1) \u2192 score close to 1\n    # Poor fit (small fill_ratio)   \u2192 score close to 0\n    k = 12.0  # Steepness of the sigmoid\n    sigmoid = 1.0 / (1.0 + np.exp(-k * (fill_ratio - 0.5)))\n\n    priorities[fit_mask] = sigmoid\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Almost\u2011Full\u2011Fit priority for online Bin Packing.\n    Bins that become \"almost full\" after adding the item get higher priority.\n    An item is considered a fit for a bin if the remaining capacity is non\u2011negative.\n    Bins that do not fit receive a priority of -np.inf.\n    \n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining capacity of each bin.\n    \n    Returns\n    -------\n    np.ndarray\n        Array of priority scores (same shape as bins_remain_cap).\n    \"\"\"\n    # Ensure we work with a NumPy array and avoid datatype surprises\n    rem_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Allocate priority vector\n    priorities = np.full_like(rem_cap, -np.inf, dtype=np.float64)\n\n    # Identify bins that can accommodate the item\n    fit_mask = rem_cap >= item\n    if not np.any(fit_mask):\n        # Nothing fits \u2013 return all -inf priorities\n        return priorities\n\n    # Remaining capacity after packing the item\n    remaining = rem_cap[fit_mask] - item\n    capacity   = rem_cap[fit_mask]\n\n    # Normalized slack: 0 means perfect fill, 1 means bin is empty\n    slack_ratio = remaining / capacity\n\n    # Heuristic: the smaller the slack_ratio, the higher the priority\n    # For \"almost full\" bins (slack_ratio <= THRESHOLD) we use a steeper penalty\n    THRESHOLD = 0.2  # <20% unused capacity is considered almost full\n    priorities[fit_mask] = np.where(\n        slack_ratio <= THRESHOLD,\n        1.0 / (slack_ratio + 1e-9),   # strongly favor very low slack\n        1.0 / (1.0 + slack_ratio)     # mild penalty for larger slack\n    )\n\n    return priorities",
    "response_id": 13,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact\u2011Fit\u2011First priority function for online Bin Packing.\n    \n    Bins where the item fits exactly receive the highest priority (infinite).\n    Among the remaining bins that can accommodate the item, those that leave the\n    smallest waste (i.e., smallest remaining capacity after insertion) receive\n    higher priority, proportional to 1 / waste.\n    Bins that cannot accommodate the item get a very low (\u2212inf) priority.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more preferred).\n    \"\"\"\n    # Ensure a NumPy array of floats\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute the waste that would remain after placing the item\n    waste = bins_remain_cap - item\n\n    # Floating\u2011point tolerance for equality checks\n    atol = 1e-9\n\n    # Masks\n    exact_fit_mask = np.isclose(waste, 0.0, atol=atol)      # exact fits\n    can_fit_mask   = waste >= -atol                         # fits (including exact)\n\n    # Initialize all priorities to \u2212inf (cannot fit)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Exact fits get the highest possible priority\n    priorities[exact_fit_mask] = np.inf\n\n    # Non\u2011exact but feasible bins get priority inversely proportional to waste\n    # (smaller waste \u2192 larger priority). Small epsilon avoids division by zero.\n    epsilon = 1e-12\n    non_exact_mask = can_fit_mask & ~exact_fit_mask\n    priorities[non_exact_mask] = 1.0 / (waste[non_exact_mask] + epsilon)\n\n    return priorities",
    "response_id": 14,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Sigmoid Fit Score priority for online bin packing.\n\n    This function assigns a higher priority to bins where the item fits tightly.\n    Bins that cannot accommodate the item receive a very low (\u2011inf) priority.\n    For feasible bins the remaining capacity after placement is fed through a\n    sigmoid: the smaller the leftover space, the larger the score.\n\n    Args:\n        item: Size of the incoming item.\n        bins_remain_cap: 1\u2011D array with the remaining capacity of each bin.\n\n    Returns:\n        np.ndarray of the same shape as `bins_remain_cap` with priority scores.\n        Higher values indicate more desirable bins.\n    \"\"\"\n    # Ensure input is a NumPy array of floats.\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Residual capacity if we placed the item in each bin.\n    residual = bins_remain_cap - item\n\n    # Identify infeasible bins (item does not fit).\n    infeasible = residual < 0\n\n    # Feasible residuals for slope calibration.\n    feasible_res = residual[~infeasible]\n\n    # If there are no feasible bins, return an array of -inf.\n    if feasible_res.size == 0:\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Adaptive sigmoid steepness:\n    # Larger spread of feasible residuals \u2192 softer sigmoid.\n    std = np.std(feasible_res)\n    # Guard against zero std (all residuals identical).\n    std = std if std > 0 else 1.0\n    slope = 5.0 / std  # 5.0 is a tunable base steepness.\n\n    # Compute sigmoid of negative residual: tighter fit \u2192 higher score.\n    # score = 1 / (1 + exp(slope * residual))\n    # Clip exponent to avoid overflow in np.exp.\n    exp_arg = np.clip(slope * residual, -700, 700)\n    scores = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Force infeasible bins to the lowest possible priority.\n    scores = np.where(infeasible, -np.inf, scores)\n\n    return scores",
    "response_id": 16,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Softmax\u2011Based Fit priority for online Bin Packing.\n\n    For each bin we compute the amount of *wasted* space that would remain\n    after inserting the item (if the item fits).  The priority is then an\n    exponential (softmax) decay of this waste \u2013 bins that leave little or no\n    waste get the highest scores.  A temperature parameter controls the\n    greediness: lower values behave like a Best\u2011Fit heuristic, higher values\n    produce a softer distribution (more exploration).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Array containing the remaining capacity of each existing bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores (summing to 1 over feasible bins).  Bins that\n        cannot accommodate the item receive a priority of 0.\n    a new bin will be opened when all priorities are zero.\n    \"\"\"\n    # ---------------------- hyper\u2011parameters ----------------------\n    temperature: float = 0.3          # <1 \u2192 greedier (best\u2011fit), >1 \u2192 softer\n    waste_exponent: float = 1.0       # linear waste penalty (2.0 \u2192 quadratic)\n    # ----------------------------------------------------------------\n\n    # Compute how much space would remain if the item were placed.\n    waste = bins_remain_cap - item            # positive = leftover space, negative = cannot fit\n    feasible = waste >= 0                     # boolean mask of bins that can hold the item\n\n    # Raw scores: negative (penalised) waste. Infeasible bins get -inf \u2192 zero after exp.\n    raw_scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    raw_scores[feasible] = -np.power(waste[feasible], waste_exponent)\n\n    # If no bin can accommodate the item, return a zero vector (caller may open a new bin).\n    if not feasible.any():\n        return np.zeros_like(bins_remain_cap, dtype=np.float64)\n\n    # Numerically stable softmax:\n    #   softmax(x) = exp((x - max(x)) / temperature) / sum(exp(...))\n    max_raw = raw_scores[feasible].max()\n    shifted = (raw_scores - max_raw) / temperature\n    exp_vals = np.exp(shifted)               # exp(-inf) -> 0 for infeasible bins\n\n    total = exp_vals.sum()\n    if total > 0:\n        priorities = exp_vals / total\n    else:\n        priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n\n    return priorities",
    "response_id": 19,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Deterministic best\u2011fit with exact\u2011fit boost for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  The bin with the highest score\n        will be selected for placement.  Bins that cannot accommodate\n        the item receive a priority of -np.inf.\n    \"\"\"\n    # Ensure the input is a NumPy array of floats\n    bins = np.asarray(bins_remain_cap, dtype=float)\n\n    # Early exit for empty bin list\n    if bins.size == 0:\n        return np.array([], dtype=float)\n\n    # Initialize all priorities to -inf (infeasible bins)\n    priorities = np.full(bins.shape, -np.inf, dtype=float)\n\n    # Find bins that can hold the item\n    fit_mask = bins >= item\n    if not np.any(fit_mask):\n        # No bin can accommodate the item\n        return priorities\n\n    # Compute leftover capacity if the item were placed in each feasible bin\n    leftovers = bins[fit_mask] - item\n\n    # Base score: prefer bins with the smallest leftover (best\u2011fit principle)\n    base_score = -leftovers\n\n    # Identify exact fits within a small tolerance\n    exact_mask = np.isclose(leftovers, 0.0, atol=1e-9)\n\n    # Boost factor for exact fits\n    BOOST = 1e6  # large constant to guarantee exact fits outrank others\n\n    # Apply boost to exact fit bins\n    final_score = base_score.copy()\n    final_score[exact_mask] += BOOST\n\n    # Assign computed scores back to the corresponding bins\n    priorities[fit_mask] = final_score\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority function for online Bin Packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin. Bins that cannot accommodate the item\n        receive -inf. The bin with the highest score should be selected.\n    \"\"\"\n    # Ensure input is a NumPy array of floats\n    rem = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = rem.shape[0]  # number of currently open bins\n\n    # No bins open \u2013 caller should open a new bin\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    # Feasibility mask: bins that can hold the item\n    fit_mask = rem >= item\n\n    # If no bin can accommodate the item, return -inf for all (open new bin)\n    if not np.any(fit_mask):\n        return np.full(n_bins, -np.inf, dtype=float)\n\n    # Adaptive epsilon\u2011greedy exploration\n    base_eps = 0.1\n    fit_frac = np.count_nonzero(fit_mask) / n_bins\n    epsilon = base_eps * (1.0 - fit_frac)  # more exploration when few bins fit\n\n    rng = np.random.default_rng()\n    if rng.random() < epsilon:\n        # Random scores for feasible bins\n        scores = rng.random(n_bins)\n        scores[~fit_mask] = -np.inf\n        return scores\n\n    # Estimate bin capacity (use the maximum observed remaining capacity)\n    bin_capacity = np.max(rem)\n    if bin_capacity <= 0:\n        # Fallback to a positive reference (item size)\n        # This situation occurs only if all bins are full, which we already handled\n        bin_capacity = item\n\n    # Average utilization of the current bins (used capacity / total capacity)\n    avg_util = 1.0 - np.mean(rem) / bin_capacity  # roughly in [0, 1]\n\n    # Dynamic sigmoid steepness: steeper when utilization is high\n    base_k = 12.0\n    k = base_k * (1.0 + avg_util)\n\n    # Fill ratio for feasible bins (item size / remaining capacity)\n    fill_ratio = np.zeros_like(rem)\n    fill_ratio[fit_mask] = item / rem[fit_mask]  # values in (0, 1]\n\n    # Logistic (sigmoid) transformation centered at 0.5 fill ratio\n    arg = -k * (fill_ratio[fit_mask] - 0.5)\n    arg = np.clip(arg, -700, 700)  # avoid overflow in exp\n    sigmoid = 1.0 / (1.0 + np.exp(arg))\n\n    # Waste fraction after placing the item (leftover capacity / original remaining)\n    waste_frac = np.zeros_like(rem)\n    waste_frac[fit_mask] = (rem[fit_mask] - item) / rem[fit_mask]  # = 1 - fill_ratio\n\n    # Weight for waste penalty\n    beta = 0.5\n\n    # Combine sigmoid score with waste penalty\n    priority = np.full_like(rem, -np.inf, dtype=float)\n    priority[fit_mask] = sigmoid - beta * waste_frac[fit_mask]\n\n    # Tiny random jitter for tie\u2011breaking\n    jitter = rng.random(n_bins) * 1e-9\n    priority[fit_mask] += jitter[fit_mask]\n\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 35.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a normalized priority score for each bin in an online Bin Packing\n    scenario.\n\n    The priority reflects the *Best\u2011Fit* rule: a bin that leaves the smallest\n    remaining capacity after accommodating the item receives the highest\n    priority.  The score is normalised to the range [0,\u202f1] for the feasible\n    bins, and infeasible bins receive ``-np.inf`` so they are never chosen.\n    A tiny tie\u2011breaker favours lower\u2011index bins when priorities are equal.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining capacity of each existing bin.\n\n    Returns\n    -------\n    np.ndarray\n        1\u2011D array of the same shape as ``bins_remain_cap`` containing the\n        priority score for each bin (higher means more preferred).\n    \"\"\"\n    # Ensure a floating\u2011point array for safe arithmetic\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Remaining space if the item were to be added\n    leftover = caps - item\n    feasible = leftover >= 0\n\n    # Compute leftover ratio safely (avoid division by zero)\n    leftover_ratio = np.empty_like(caps)\n    if np.any(feasible):\n        valid = feasible & (caps > 0)\n        leftover_ratio[valid] = leftover[valid] / caps[valid]\n\n        zero_cap = feasible & (caps == 0)\n        # When capacity is zero and item fits (i.e., item==0), the ratio is 0\n        leftover_ratio[zero_cap] = 0.0\n\n    # Raw priority: negative leftover ratio (higher when leftover is smaller)\n    raw_priority = np.full_like(caps, -np.inf, dtype=float)\n    if np.any(feasible):\n        raw_priority[feasible] = -leftover_ratio[feasible]\n\n    # Normalise feasible priorities to [0,\u202f1], keep infeasible as -inf\n    if np.any(feasible):\n        min_f = np.min(raw_priority[feasible])\n        max_f = np.max(raw_priority[feasible])\n        norm_range = max_f - min_f\n        if norm_range > 0:\n            norm_priority = (raw_priority - min_f) / norm_range\n        else:\n            # All feasible priorities are equal \u2192 keep them all 0\n            norm_priority = raw_priority - min_f\n    else:\n        norm_priority = raw_priority\n\n    # Tie\u2011breaker: slightly favour lower\u2011index bins\n    epsilon = 1e-9\n    tie_breaker = -epsilon * np.arange(len(norm_priority))\n    priorities = norm_priority + tie_breaker\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 27.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\n\n# Global state for adaptive behavior (maintained across calls)\n_call_counter: int = 0          # Number of items processed so far\n_total_item_size: float = 0.0   # Cumulative size of all processed items\n\n# Adaptive parameters\n_ALPHA0: float = 0.3            # Base penalty weight for large leftovers\n_ALPHA_DECAY: float = 500.0     # Controls how fast the penalty weight grows\n_K0: float = 8.0                # Base steepness of the sigmoid\n_K_DECAY: float = 500.0         # Controls how fast the sigmoid steepness grows\n\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute deterministic priority scores for each bin using an adaptive\n    sigmoid fit strategy with a penalty for large leftovers.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores for each bin.  Bins that cannot accommodate\n        the item receive -np.inf and are never selected.\n    \"\"\"\n    global _call_counter, _total_item_size\n\n    # ------------------------------------------------------------------\n    # Update online statistics\n    # ------------------------------------------------------------------\n    _call_counter += 1\n    _total_item_size += item\n    avg_item_size = _total_item_size / _call_counter\n\n    # Ensure numeric types for accurate arithmetic\n    rem = bins_remain_cap.astype(float, copy=False)\n\n    # Mask of bins that can actually fit the item\n    fit_mask = rem >= item\n\n    # Initialize all priorities with negative infinity (bins that cannot fit)\n    priorities = np.full_like(rem, -np.inf, dtype=float)\n\n    if not np.any(fit_mask):\n        return priorities  # no bin can fit the item\n\n    # Compute leftover after placing the item\n    leftover = rem - item\n\n    # Fit ratio after placing the item (fraction of bin that is filled)\n    fit_ratio = 1.0 - leftover / rem\n\n    # Adaptive sigmoid parameters (increase over time)\n    k = _K0 * (_call_counter / (_call_counter + _K_DECAY))\n    alpha = _ALPHA0 * (_call_counter / (_call_counter + _ALPHA_DECAY))\n\n    # Logistic (sigmoid) transformation to obtain a smooth prioritization\n    # Good fit (fit_ratio close to 1) \u2192 score close to 1\n    # Poor fit (fit_ratio close to 0)   \u2192 score close to 0\n    sigmoid = 1.0 / (1.0 + np.exp(-k * (fit_ratio - 0.5)))\n\n    # Penalty for large leftover relative to bin capacity\n    penalty = alpha * (leftover / rem)\n\n    # Final priority: high sigmoid minus penalty\n    scores = sigmoid - penalty\n\n    # Assign scores to the corresponding bins\n    priorities[fit_mask] = scores[fit_mask]\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online Bin Packing.\n\n    Returns a score for each bin; higher score means more preferred.\n    Infeasible bins receive -inf.\n    The scoring combines a sigmoid bias towards tight fits, an exponential\n    penalty for waste, a boost for exact fits, and a tiny tie\u2011breaker.\n    Scores are min\u2011max normalised to [0, 1] for comparability.\n    \"\"\"\n    # Ensure a NumPy array of floats\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Remaining capacity after placing the item\n    leftover = caps - item\n\n    # Feasibility mask: only bins that can accommodate the item\n    feasible = leftover >= 0\n\n    # Initialise all scores to -inf (infeasible)\n    scores = np.full_like(caps, -np.inf, dtype=float)\n\n    # If no feasible bins exist, return early\n    if not np.any(feasible):\n        return scores\n\n    # ----------------------------------------------------------------------\n    # Adaptive steepness based on current leftover distribution\n    # ----------------------------------------------------------------------\n    median_leftover = np.median(leftover[feasible])\n    base_alpha = 5.0            # base steepness for the sigmoid\n    eps = 1e-12\n    # Larger steepness when median leftover is small (tight\u2011fit regime)\n    alpha = base_alpha / (median_leftover + eps)\n    # Clamp to avoid extreme exponentials\n    alpha = np.clip(alpha, 0.1, 100.0)\n\n    # Use the same parameter for the exponential waste penalty\n    beta = alpha\n\n    # ----------------------------------------------------------------------\n    # Sigmoid component (tight\u2011fit bias)\n    # ----------------------------------------------------------------------\n    max_exp = 50.0  # clip exponent to keep np.exp stable\n    exp_arg = np.clip(alpha * leftover[feasible], 0.0, max_exp)\n    # 2/(1+exp(alpha * leftover)) yields 1 at leftover=0 and decays smoothly\n    sigmoid = 2.0 / (1.0 + np.exp(exp_arg))\n\n    # ----------------------------------------------------------------------\n    # Exponential waste penalty\n    # ----------------------------------------------------------------------\n    pen_exp_arg = np.clip(beta * leftover[feasible], 0.0, max_exp)\n    penalty = np.exp(pen_exp_arg)\n\n    # Combine components; lambda balances penalty strength (set to 1.0)\n    lam = 1.0\n    raw = sigmoid - lam * penalty\n\n    # ----------------------------------------------------------------------\n    # Boost exact fits\n    # ----------------------------------------------------------------------\n    exact_fit_tol = 1e-9\n    exact_fit_bonus = 10.0\n    exact_fit_mask = leftover[feasible] <= exact_fit_tol\n    raw[exact_fit_mask] += exact_fit_bonus\n\n    # ----------------------------------------------------------------------\n    # Normalise to [0, 1]\n    # ----------------------------------------------------------------------\n    min_raw = raw.min()\n    max_raw = raw.max()\n    if max_raw > min_raw:\n        norm_raw = (raw - min_raw) / (max_raw - min_raw)\n    else:\n        # All values equal (e.g., all exact fits); give them zero before tie\u2011break\n        norm_raw = np.zeros_like(raw)\n\n    # ----------------------------------------------------------------------\n    # Tiny tie\u2011breaker preferring lower\u2011index bins\n    # ----------------------------------------------------------------------\n    epsilon = 1e-12\n    feasible_indices = np.nonzero(feasible)[0]  # original indices of feasible bins\n    norm_raw = norm_raw - epsilon * feasible_indices.astype(float)\n\n    # Populate the final scores array\n    scores[feasible] = norm_raw\n\n    return scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 35.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Compute priority scores for bins in online bin packing.\n    \n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of existing bins.\n    \n    Returns\n    -------\n    np.ndarray\n        Priority scores, one per bin. Higher values indicate higher preference.\n        Feasible bins are normalised to [0, 1]; infeasible bins get -np.inf.\n    \"\"\"\n    # Early exit for empty input\n    if bins_remain_cap.size == 0:\n        return np.empty(0, dtype=float)\n\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    leftover = caps - item\n    feasible = leftover >= 0\n\n    # Compute leftover ratio safely, handling zero capacities\n    ratio = np.where(feasible & (caps > 0), leftover / caps, 0.0)\n\n    # Assign a raw priority: higher when leftover ratio is smaller\n    raw_priority = np.full_like(caps, -np.inf, dtype=float)\n    raw_priority[feasible] = -ratio[feasible]\n\n    # Normalise feasible priorities to [0, 1]\n    if np.any(feasible):\n        min_f = raw_priority[feasible].min()\n        max_f = raw_priority[feasible].max()\n        span = max_f - min_f\n        if span > 0:\n            norm_priority = (raw_priority - min_f) / span\n        else:\n            norm_priority = raw_priority - min_f  # all zeros\n    else:\n        norm_priority = raw_priority\n\n    # Tie\u2011breaker: slightly favour lower\u2011index bins\n    epsilon = 1e-9\n    tie_breaker = -epsilon * np.arange(len(norm_priority))\n    priorities = norm_priority + tie_breaker\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 23.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\n\n# Global state for adaptive behavior\n_call_counter: int = 0\n_total_item_size: float = 0.0\n\n# Exploration parameters (epsilon\u2011greedy)\n_EPSILON0: float = 0.2          # Initial exploration probability\n_MIN_EPSILON: float = 0.01      # Minimum exploration probability\n_DECAY_RATE: float = 0.001      # Exponential decay rate of epsilon\n\n# Penalty weight for waste compared to average item size\n_ALPHA: float = 0.5\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online Bin Packing that combines:\n\n      * Exact\u2011fit first: bins that fit the item exactly get infinite priority.\n      * Best\u2011fit: for other feasible bins, priority is inversely proportional to\n        the waste (remaining capacity after placing the item).\n      * Adaptive epsilon\u2011greedy exploration: with a decaying probability\n        the algorithm selects a random feasible bin.\n      * Waste penalty weighted by the average item size: bins whose waste\n        is significantly larger than the observed average item size are\n        penalised.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more preferred).  Bins that\n        cannot accommodate the item receive -inf.\n    \"\"\"\n    global _call_counter, _total_item_size\n\n    # Ensure a NumPy array of floats\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Update online statistics\n    _call_counter += 1\n    _total_item_size += item\n    avg_item_size = _total_item_size / _call_counter\n\n    # Dynamic epsilon (decays exponentially, never below _MIN_EPSILON)\n    epsilon = max(_MIN_EPSILON, _EPSILON0 * np.exp(-_DECAY_RATE * _call_counter))\n\n    rng = np.random.default_rng()\n\n    # Exploration branch: random feasible bin with probability epsilon\n    if rng.random() < epsilon:\n        feasible = bins_remain_cap >= item\n        random_scores = rng.random(bins_remain_cap.shape[0])\n        return np.where(feasible, random_scores, -np.inf)\n\n    # Deterministic scoring branch\n    waste = bins_remain_cap - item\n\n    # Masks\n    atol = 1e-9\n    exact_fit_mask = np.isclose(waste, 0.0, atol=atol)\n    feasible_mask = waste >= -atol  # allow slight negative due to tolerance\n\n    # Initialize priorities to -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Exact fits get infinite priority\n    priorities[exact_fit_mask] = np.inf\n\n    # Non\u2011exact but feasible bins get priority inversely proportional to waste\n    non_exact_mask = feasible_mask & ~exact_fit_mask\n    if np.any(non_exact_mask):\n        eps = 1e-12\n        base_score = 1.0 / (waste[non_exact_mask] + eps)\n        # Penalty for waste larger than the average item size\n        excess = np.maximum(0.0, waste[non_exact_mask] - avg_item_size)\n        penalty = _ALPHA * excess\n        priorities[non_exact_mask] = base_score - penalty\n\n    return priorities",
    "response_id": 6,
    "obj": 4.01874750698045,
    "SLOC": 26.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive sigmoid priority for online bin packing.\n\n    Gives higher priority to bins that accommodate the item tightly.\n    The steepness of the sigmoid is calibrated to the spread of feasible\n    residual capacities, ensuring a balanced exploitation of tight fits\n    across different instance scales. Infeasible bins receive -inf.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as `bins_remain_cap`).\n        Higher values indicate more desirable bins; infeasible bins are\n        penalised with -inf.\n    \"\"\"\n    # Ensure a NumPy float array.\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    if caps.size == 0:\n        return np.array([], dtype=float)\n\n    # Residual capacity after placing the item in each bin.\n    residual = caps - item\n\n    # Feasibility mask.\n    feasible = residual >= 0\n\n    # If nothing fits, return -inf for every bin.\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Residuals of feasible bins.\n    feasible_res = residual[feasible]\n\n    # Adaptive steepness: based on the more robust spread of feasible residuals.\n    # Use standard deviation; fall back to range if std is zero.\n    std = np.std(feasible_res)\n    if std <= 0.0:\n        spread = np.max(feasible_res) - np.min(feasible_res)\n        std = spread if spread > 0.0 else 1.0\n\n    # Base steepness factor (tunable). Larger std \u2192 softer sigmoid.\n    base_steepness = 5.0\n    slope = base_steepness / std\n\n    # Sigmoid of negative residual: tighter fit \u2192 larger score.\n    # score = 1 / (1 + exp(slope * residual))\n    # Clip exponent to avoid overflow/underflow.\n    exp_arg = np.clip(slope * residual, -700, 700)\n    scores = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Penalise infeasible bins.\n    scores = np.where(feasible, scores, -np.inf)\n\n    # Deterministic tie\u2011breaker: tiny bias favouring lower indices.\n    # This does not affect ordering unless scores are exactly equal.\n    tie_bias = -np.arange(caps.shape[0]) * 1e-12\n    scores = np.where(scores > -np.inf, scores + tie_bias, scores)\n\n    return scores",
    "response_id": 8,
    "obj": 3.9888312724371757,
    "SLOC": 21.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive, exploration\u2011aware priority scoring for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item <= bin capacity).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacities of currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority score for each bin (same shape as ``bins_remain_cap``).\n        Infeasible bins receive ``-np.inf``.  The bin with the highest\n        score should be selected for the item.  If there are no open bins,\n        an empty array is returned (caller should open a new bin).\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Pre\u2011process input\n    # ------------------------------------------------------------------\n    rem = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = rem.size\n\n    # No open bins \u2013 caller must create a new one\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    # Feasibility mask: bins that can accommodate the item\n    fit_mask = rem >= item\n\n    # If nothing fits, return -inf for all bins (force new bin creation)\n    if not np.any(fit_mask):\n        return np.full(n_bins, -np.inf, dtype=float)\n\n    # ------------------------------------------------------------------\n    # Adaptive epsilon\u2011greedy exploration\n    # ------------------------------------------------------------------\n    base_eps = 0.10                     # baseline exploration prob.\n    fit_frac = np.count_nonzero(fit_mask) / n_bins\n\n    # Estimate bin capacity (all bins have the same fixed capacity)\n    bin_capacity = np.max(rem)\n    if bin_capacity <= 0.0:\n        bin_capacity = item   # fallback, should not happen for valid data\n\n    # Current utilization of each bin (higher = more filled)\n    utilization = 1.0 - rem / bin_capacity\n    avg_util = np.mean(utilization)\n\n    # Exploration probability rises when few bins fit or utilization is low\n    epsilon = base_eps * (1.0 - fit_frac) * (1.0 + (1.0 - avg_util))\n\n    rng = np.random.default_rng()\n    if rng.random() < epsilon:\n        # Purely random scores for feasible bins, -inf otherwise\n        scores = rng.random(n_bins)\n        scores[~fit_mask] = -np.inf\n        return scores\n\n    # ------------------------------------------------------------------\n    # Deterministic scoring for exploitation\n    # ------------------------------------------------------------------\n    # Leftover capacity after placing the item (only for feasible bins)\n    leftover = np.empty_like(rem)\n    leftover.fill(np.nan)\n    leftover[fit_mask] = rem[fit_mask] - item\n\n    # Fill ratio: fraction of a bin's remaining capacity that the item occupies\n    fill_ratio = np.empty_like(rem)\n    fill_ratio.fill(np.nan)\n    fill_ratio[fit_mask] = item / rem[fit_mask]          # in (0, 1]\n\n    # Waste fraction after placement (same as leftover / original remaining)\n    waste_frac = np.empty_like(rem)\n    waste_frac.fill(np.nan)\n    waste_frac[fit_mask] = leftover[fit_mask] / rem[fit_mask]   # = 1 - fill_ratio\n\n    # Sigmoid scoring that favours fill ratios > 0.5.\n    # Steepness grows with average utilization (more aggressive when bins are tight).\n    base_k = 12.0\n    k = base_k * (1.0 + avg_util)          # k \u2208 [base_k, 2*base_k]\n\n    # Compute sigmoid: \u03c3(x) = 1 / (1 + exp(-k*(x - 0.5)))\n    arg = -k * (fill_ratio[fit_mask] - 0.5)   # negative for fill>0.5 \u2192 large \u03c3\n    # Clip to avoid overflow in exp\n    arg = np.clip(arg, -700.0, 700.0)\n    sigmoid = 1.0 / (1.0 + np.exp(arg))\n\n    # ------------------------------------------------------------------\n    # Combine components into a single priority value\n    # ------------------------------------------------------------------\n    # Weight parameters (tunable)\n    beta = 0.5      # waste penalty weight\n    delta = 0.30    # utilization reward weight\n\n    priority = np.full(n_bins, -np.inf, dtype=float)\n\n    # Base score: sigmoid (higher for larger fill ratios)\n    # Penalise waste and reward already\u2011used bins (higher utilization)\n    priority[fit_mask] = (\n        sigmoid\n        - beta * waste_frac[fit_mask]\n        + delta * utilization[fit_mask]\n    )\n\n    # Tiny random jitter to break ties in a reproducible way\n    jitter = rng.random(n_bins) * 1e-9\n    priority[fit_mask] += jitter[fit_mask]\n\n    return priority",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 46.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive sigmoid\u2011based priority for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as `bins_remain_cap`).\n        Higher values indicate more desirable bins; infeasible bins are\n        represented by ``-inf``.\n    \"\"\"\n    # Ensure a NumPy float array.\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = caps.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    # Residual capacity after placing the item in each bin.\n    residual = caps - item\n    feasible = residual >= 0\n\n    # If nothing fits, return -inf for every bin.\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Ratio of leftover after placement to the capacity before placement.\n    # Use np.where to avoid division by zero for caps == 0 (though infeasible).\n    ratio = np.where(caps > 0, residual / caps, 0.0)\n\n    # Median of feasible residuals to adapt steepness.\n    median_res = np.median(residual[feasible])\n    if median_res <= 0.0:\n        median_res = 1.0\n\n    # Steepness parameter.\n    base_slope = 10.0\n    slope = base_slope / median_res\n\n    # Sigmoid-like score that prefers small leftover ratio.\n    exp_arg = slope * ratio\n    exp_arg = np.clip(exp_arg, -700, 700)  # avoid overflow\n    sigmoid_score = 2.0 / (1.0 + np.exp(exp_arg))\n\n    # Exponential penalty for waste relative to item size.\n    eps_item = 1e-12\n    waste_ratio = residual / (item + eps_item)\n    penalty = np.exp(-5.0 * waste_ratio)\n\n    # Size weight (fraction of bin capacity taken by the item).\n    size_weight = np.where(caps > 0, item / caps, 0.0)\n\n    # Raw score.\n    raw_score = sigmoid_score * penalty * size_weight\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # Deterministic tie\u2011breaker: tiny negative bias favouring lower indices.\n    tie_bias = -np.arange(n_bins) * 1e-12\n    raw_score = np.where(raw_score > -np.inf, raw_score + tie_bias, raw_score)\n\n    return raw_score",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 27.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    epsilon: float = 0.1,\n    boost: float = 10.0,\n    rng: np.random.Generator | None = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for placing an incoming item into existing bins.\n\n    The function implements an epsilon\u2011greedy strategy combined with an\n    Exact\u2011Fit\u2011First (best\u2011fit) heuristic and random tie\u2011breaking.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining capacity of each open bin.\n    epsilon : float, optional\n        Exploration probability for epsilon\u2011greedy. With probability ``epsilon``\n        a random feasible bin is favoured. Default is 0.1.\n    boost : float, optional\n        Additive bonus for bins that achieve an exact fit (remaining capacity\n        ~0). Must be larger than the typical range of the base scores to\n        guarantee precedence. Default is 10.0.\n    rng : np.random.Generator, optional\n        Random number generator. If ``None`` a new default generator is created.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores (same shape as ``bins_remain_cap``). Bins that\n        cannot accommodate the item receive ``-np.inf``. The bin with the highest\n        score should be selected.\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # Feasibility mask: bins that can hold the item\n    feasible_mask = bins_remain_cap >= item\n\n    # If no bin can accommodate the item, return all -inf\n    if not np.any(feasible_mask):\n        return np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n\n    # Exploration phase: random scores for feasible bins\n    if rng.random() < epsilon:\n        random_scores = rng.random(bins_remain_cap.shape)\n        random_scores[~feasible_mask] = -np.inf\n        return random_scores\n\n    # Exploitation phase: best\u2011fit with exact\u2011fit boost\n    # Compute leftover capacity for feasible bins\n    leftovers = bins_remain_cap[feasible_mask] - item\n\n    # Base score prefers smaller leftover (best\u2011fit). Use negative leftover\n    # so that larger scores correspond to tighter fits.\n    base_score = -leftovers\n\n    # Detect exact fits (within numerical tolerance)\n    exact_fit_mask = np.isclose(leftovers, 0.0, atol=1e-9)\n\n    # Apply boost to exact fits\n    scores = base_score + boost * exact_fit_mask.astype(float)\n\n    # Random tie\u2011breaking: add a tiny noise term to avoid deterministic ties\n    tie_noise = 1e-6 * rng.random(scores.shape)\n    scores += tie_noise\n\n    # Assemble full priority array\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    priorities[feasible_mask] = scores\n\n    return priorities",
    "response_id": 0,
    "obj": 4.15835660151576,
    "SLOC": 25.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive sigmoid priority for online bin packing.\n\n    The function returns a score for each bin; higher scores indicate more\n    desirable bins for placing the incoming ``item``. The scoring uses a smooth\n    sigmoid that adapts its steepness to the dispersion of feasible residual\n    capacities, avoiding hard thresholds. Infeasible bins receive ``-inf``.\n    A tiny deterministic tie\u2011breaker favours lower\u2011index bins when scores are\n    otherwise equal.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores (same shape as ``bins_remain_cap``).\n    \"\"\"\n    # Ensure a 1\u2011D float array.\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.shape[0]\n\n    # Empty case.\n    if n_bins == 0:\n        return np.empty(0, dtype=float)\n\n    # Residual capacity after packing the item.\n    residual = caps - item\n\n    # Feasibility mask.\n    feasible = residual >= 0\n\n    # Initialise all scores to -inf (infeasible).\n    scores = np.full(n_bins, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return the -inf vector.\n    if not np.any(feasible):\n        return scores\n\n    # Residual capacities of feasible bins.\n    feas_res = residual[feasible]\n\n    # --- Adaptive steepness -------------------------------------------------\n    # Robust spread estimator: Median Absolute Deviation (MAD).\n    median_res = np.median(feas_res)\n    mad = np.median(np.abs(feas_res - median_res))\n    # Convert MAD to an estimate of standard deviation (for normal data).\n    spread = mad * 1.4826\n\n    # Fallback strategies if MAD is zero.\n    if spread <= 0.0:\n        std = np.std(feas_res)\n        if std > 0.0:\n            spread = std\n        else:\n            # Use range as last resort.\n            rng = np.max(feas_res) - np.min(feas_res)\n            spread = rng if rng > 0.0 else 1.0\n\n    # Base steepness factor (tunable). Larger spread \u2192 softer sigmoid.\n    base_steepness = 5.0\n    slope = base_steepness / spread\n\n    # --- Sigmoid scoring ----------------------------------------------------\n    # Logistic function decreasing with residual.\n    # score = 1 / (1 + exp(slope * residual))\n    # Clip exponent to avoid overflow/underflow.\n    exp_arg = np.clip(slope * residual[feasible], -700, 700)\n    scores_feas = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Assign scores to feasible bins.\n    scores[feasible] = scores_feas\n\n    # --- Deterministic tie\u2011breaker -----------------------------------------\n    # Tiny decreasing bias with index ensures stable ordering when scores tie.\n    epsilon = 1e-12\n    tie_bias = -np.arange(n_bins, dtype=float) * epsilon\n    scores = np.where(scores > -np.inf, scores + tie_bias, scores)\n\n    return scores",
    "response_id": 4,
    "obj": 3.9888312724371757,
    "SLOC": 30.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response5.txt_stdout.txt",
    "code_path": "problem_iter6_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    epsilon: float = 0.05,\n    base_slope: float = 12.0,\n    waste_alpha: float = 5.0,\n    random_state=None,\n) -> np.ndarray:\n    \"\"\"\n    Adaptive sigmoid\u2011based priority for online bin packing with\n    epsilon\u2011greedy exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    epsilon : float, optional\n        Exploration probability (default 0.05).\n    base_slope : float, optional\n        Base steepness for the sigmoid scaling (default 12.0).\n    waste_alpha : float, optional\n        Penalty factor for waste relative to the item size (default 5.0).\n    random_state : int or np.random.Generator, optional\n        Seed or generator for reproducible randomness.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; infeasible bins receive -inf.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = caps.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    # RNG handling\n    if isinstance(random_state, np.random.Generator):\n        rng = random_state\n    else:\n        rng = np.random.default_rng(random_state)\n\n    # ---------- Exploration ----------\n    if rng.random() < epsilon:\n        # Uniform random scores for feasible bins, -inf for infeasible.\n        rand_scores = rng.random(n_bins)\n        feasible = caps >= item\n        rand_scores[~feasible] = -np.inf\n        # Tiny deterministic bias to break ties by index.\n        rand_scores += -np.arange(n_bins) * 1e-12\n        return rand_scores\n\n    # ---------- Exploitation ----------\n    residual = caps - item\n    feasible = residual >= 0\n\n    # No bin can accommodate the item.\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Residual ratio (leftover / capacity). Smaller = better fit.\n    ratio = np.where(caps > 0, residual / caps, 0.0)\n\n    # Adaptive sigmoid steepness based on median feasible residual.\n    median_res = np.median(residual[feasible])\n    median_res = median_res if median_res > 0 else 1.0\n    slope = base_slope / median_res\n\n    # Sigmoid\u2011like score that prefers small leftover ratios.\n    exp_arg = slope * ratio\n    exp_arg = np.clip(exp_arg, -700, 700)           # avoid overflow\n    sigmoid_score = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Exponential penalty for waste relative to the item size.\n    eps = 1e-12\n    waste_ratio = residual / (item + eps)\n    waste_penalty = np.exp(-waste_alpha * waste_ratio)\n\n    # Utilization weight: fraction of bin capacity taken by the item.\n    utilization = np.where(caps > 0, item / caps, 0.0)\n\n    # Combine components multiplicatively (all in [0,1]).\n    raw_score = sigmoid_score * waste_penalty * utilization\n\n    # Mask infeasible bins.\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # Deterministic tie\u2011breaker: tiny decreasing bias with index.\n    raw_score += -np.arange(n_bins) * 1e-12\n\n    return raw_score",
    "response_id": 5,
    "obj": 4.0885520542481055,
    "SLOC": 41.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for online bin packing.\n\n    - Scores only feasible bins (remaining capacity >= item).\n    - Uses a sharp sigmoid centred at a small residual threshold to\n      boost exact or near\u2011exact fits.\n    - Penalises waste exponentially based on the normalised leftover.\n    - Adds a decaying epsilon random perturbation for exploration.\n    - Deterministic tie\u2011breaker via a tiny bias favouring lower indices.\n    - Infeasible bins receive -inf.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = more desirable). Shape matches\n        `bins_remain_cap`.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    if caps.size == 0:\n        return np.array([], dtype=float)\n\n    # Residual capacity after placing the item in each bin.\n    residual = caps - item\n    feasible = residual >= 0\n\n    # If nothing fits, penalise all bins.\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Estimate bin capacity (assume at least one empty bin exists).\n    bin_capacity = np.max(caps)\n    if bin_capacity <= 0:\n        # Fallback: use the largest possible capacity inferred from residuals.\n        bin_capacity = np.max(caps + residual)\n    if bin_capacity <= 0:\n        bin_capacity = 1.0  # safety fallback\n\n    # Normalised residual (relative waste).\n    norm_res = residual / bin_capacity\n\n    # Adaptive sigmoid steepness based on spread of feasible residuals.\n    feasible_res = residual[feasible]\n    spread = np.std(feasible_res)\n    if spread <= 0.0:\n        spread = np.ptp(feasible_res)  # range as fallback\n    if spread <= 0.0:\n        spread = 1.0\n\n    base_steepness = 10.0  # tunable: larger \u2192 sharper transition\n    slope = base_steepness / spread\n\n    # Threshold for a \u201ctight\u201d fit (e.g., 5\u202f% of bin capacity).\n    tight_threshold = 0.05 * bin_capacity\n\n    # Sharp sigmoid: high score for residual << tight_threshold, low otherwise.\n    # sigmoid(x) = 1 / (1 + exp(slope * (x - tight_threshold)))\n    exp_arg = slope * (residual - tight_threshold)\n    exp_arg = np.clip(exp_arg, -700, 700)  # avoid overflow\n    sigmoid_score = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Exponential waste penalty: larger residual \u2192 stronger penalty.\n    alpha = 5.0  # tunable\n    waste_penalty = np.exp(alpha * norm_res)  # >= 1\n    base_score = sigmoid_score / waste_penalty\n\n    # Infeasible bins get -inf.\n    scores = np.where(feasible, base_score, -np.inf)\n\n    # --- Decaying epsilon exploration ---\n    # Initialise static call counter.\n    if not hasattr(priority_v2, \"_call_count\"):\n        priority_v2._call_count = 0\n    priority_v2._call_count += 1\n\n    # Epsilon decays as 1/sqrt(call_count) (adjustable schedule).\n    epsilon0 = 0.01\n    epsilon = epsilon0 / np.sqrt(priority_v2._call_count)\n\n    # Add small random perturbation to feasible scores.\n    noise = np.random.rand(caps.shape[0]) * epsilon\n    scores = np.where(feasible, scores + noise, scores)\n\n    # --- Deterministic tie\u2011breaker (tiny bias for lower index) ---\n    tie_bias = -np.arange(caps.shape[0]) * 1e-12\n    scores = np.where(scores > -np.inf, scores + tie_bias, scores)\n\n    return scores",
    "response_id": 0,
    "obj": 27.742321499800564,
    "SLOC": 40.0,
    "cyclomatic_complexity": 8.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    rng: Optional[np.random.Generator] = None,\n    base_eps: float = 0.10,\n    base_k: float = 12.0,\n    beta: float = 0.5,\n    delta: float = 0.30,\n    boost: float = 5.0,\n    exact_fit_tol: float = 1e-9,\n) -> np.ndarray:\n    \"\"\"\n    Adaptive priority scoring for the online bin packing problem.\n\n    The function combines an epsilon\u2011greedy exploration scheme with a smooth\n    sigmoid fill\u2011ratio scoring, penalises waste, rewards already\u2011utilised bins\n    and gives a small boost to exact\u2011fit placements.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item <= bin capacity).\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining capacities of the currently open bins.\n    rng : np.random.Generator, optional\n        Random generator for exploration decisions and jitter.\n        If ``None`` a default generator is created.\n    base_eps : float, optional\n        Base exploration probability (default 0.10).\n    base_k : float, optional\n        Base steepness of the sigmoid used for fill\u2011ratio scoring (default 12.0).\n    beta : float, optional\n        Weight of the waste\u2011penalty term (default 0.5).\n    delta : float, optional\n        Weight of the utilization\u2011reward term (default 0.30).\n    boost : float, optional\n        Additive boost given to bins that achieve an (almost) exact fit\n        (default 5.0).\n    exact_fit_tol : float, optional\n        Numerical tolerance for detecting an exact fit (default 1e-9).\n\n    Returns\n    -------\n    np.ndarray\n        Priority score for each bin (same shape as ``bins_remain_cap``).\n        Infeasible bins receive ``-np.inf``.  The caller should select the bin\n        with the highest score; if all scores are ``-np.inf`` a new bin must be\n        opened.  An empty array is returned when ``bins_remain_cap`` is empty.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Input preparation\n    # ------------------------------------------------------------------\n    rem = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = rem.size\n\n    # No open bins \u2192 caller must open a new bin\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    # Feasibility mask: bins that can accommodate the item\n    fit_mask = rem >= item\n\n    # If no bin can hold the item, return -inf for all bins\n    if not np.any(fit_mask):\n        return np.full(n_bins, -np.inf, dtype=float)\n\n    # ------------------------------------------------------------------\n    # Random number generator\n    # ------------------------------------------------------------------\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Adaptive epsilon\u2011greedy exploration probability\n    # ------------------------------------------------------------------\n    # Fraction of bins that can fit the item\n    fit_frac = np.count_nonzero(fit_mask) / n_bins\n\n    # Estimate bin capacity (all bins share the same fixed capacity)\n    # Using the maximum remaining capacity is safe because no bin can have\n    # more remaining capacity than its total capacity.\n    bin_capacity = np.max(rem)\n    if bin_capacity <= 0.0:\n        # Defensive fallback \u2013 should not happen for valid data\n        bin_capacity = item\n\n    # Utilisation of each bin (higher = more filled)\n    utilization = 1.0 - rem / bin_capacity\n    avg_util = np.mean(utilization)\n\n    # Exploration probability grows when few bins fit or utilization is low\n    epsilon = base_eps * (1.0 - fit_frac) * (1.0 + (1.0 - avg_util))\n    epsilon = np.clip(epsilon, 0.0, 1.0)\n\n    # Exploration: random feasible scores\n    if rng.random() < epsilon:\n        scores = rng.random(n_bins)\n        scores[~fit_mask] = -np.inf\n        return scores\n\n    # ------------------------------------------------------------------\n    # Deterministic exploitation scoring\n    # ------------------------------------------------------------------\n    # Leftover capacity after placing the item (only defined for feasible bins)\n    leftover = np.empty_like(rem)\n    leftover.fill(np.nan)\n    leftover[fit_mask] = rem[fit_mask] - item\n\n    # ensure leftover for infeasible bins stays NaN (won't be used)\n\n    # Fill ratio: portion of the bin's remaining capacity taken by the item\n    fill_ratio = np.empty_like(rem)\n    fill_ratio.fill(np.nan)\n    fill_ratio[fit_mask] = item / rem[fit_mask]  # in (0, 1]\n\n    # Waste fraction after placement (same as leftover / original remaining)\n    waste_frac = np.empty_like(rem)\n    waste_frac.fill(np.nan)\n    waste_frac[fit_mask] = leftover[fit_mask] / rem[fit_mask]  # = 1 - fill_ratio\n\n    # Sigmoid scoring that favours fill ratios > 0.5.\n    # Steepness grows with average utilisation (more aggressive when bins are tight).\n    k = base_k * (1.0 + avg_util)          # k \u2208 [base_k, 2*base_k]\n    arg = -k * (fill_ratio[fit_mask] - 0.5)   # negative for fill>0.5 \u2192 larger sigmoid\n    # Clip to avoid overflow in exp\n    arg = np.clip(arg, -700.0, 700.0)\n    sigmoid = 1.0 / (1.0 + np.exp(arg))\n\n    # Exact\u2011fit boost (detect near\u2011zero leftover)\n    exact_fit = np.isclose(leftover[fit_mask], 0.0, atol=exact_fit_tol)\n    exact_boost = boost * exact_fit.astype(float)\n\n    # Combine components\n    priority = np.full(n_bins, -np.inf, dtype=float)\n    priority[fit_mask] = (\n        sigmoid                                 # base sigmoid (higher = better)\n        - beta * waste_frac[fit_mask]           # penalise waste\n        + delta * utilization[fit_mask]         # reward already used bins\n        + exact_boost                           # reward exact fits\n    )\n\n    # Tiny random jitter to break ties reproducibly\n    jitter = rng.random(n_bins) * 1e-9\n    priority[fit_mask] += jitter[fit_mask]\n\n    return priority",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 58.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\n# ----------------------------------------------------------------------\n# Global state (persisted across calls) \u2013 used for adaptive behaviour.\n# ----------------------------------------------------------------------\n_call_counter: int = 0               # Number of items processed so far\n_total_item_size: float = 0.0        # Cumulative size of all items seen\n_ema_item_size: float = 0.0          # Exponential moving average of item size\n_ema_alpha: float = 0.2              # Smoothing factor for EMA (0 < \u03b1 \u2264 1)\n\n# Exploration (epsilon\u2011greedy) schedule\n_EPSILON0: float = 0.15              # Initial exploration probability\n_MIN_EPSILON: float = 0.02           # Floor for exploration probability\n_DECAY_RATE: float = 5e-4           # Exponential decay rate (slower decay)\n\n# Waste\u2011penalty configuration\n_WASTE_PENALTY_WEIGHT: float = 0.35  # Relative importance of waste excess\n_EPS: float = 1e-12                  # Tiny epsilon to avoid division by zero\n\n# Random number generator (single instance for reproducibility)\n_rng = np.random.default_rng()\n\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority function for online Bin Packing.\n\n    Blends several heuristics:\n      \u2022 Exact\u2011fit bins (zero waste) get infinite priority.\n      \u2022 Best\u2011fit: for feasible non\u2011exact bins, priority \u221d 1 / waste.\n      \u2022 Waste penalty: bins whose waste exceeds the EMA of observed item\n        sizes are penalised proportionally.\n      \u2022 Adaptive epsilon\u2011greedy exploration: with a decaying probability a\n        random feasible bin is chosen to encourage diversification.\n      \u2022 Small random jitter is added to break ties deterministically.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be non\u2011negative).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more preferred).  Infeasible\n        bins receive -inf.\n    \"\"\"\n    global _call_counter, _total_item_size, _ema_item_size\n\n    # ------------------------------------------------------------------\n    # 1) Normalise input and update online statistics.\n    # ------------------------------------------------------------------\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    _call_counter += 1\n    _total_item_size += item\n\n    # Update exponential moving average of item size.\n    if _call_counter and _call_counter == 1:\n        _ema_item_size = item\n    else:\n        _ema_item_size = _ema_alpha * item + (1.0 - _ema_alpha) * _ema_item_size\n\n    # ------------------------------------------------------------------\n    # 2) Compute adaptive epsilon.\n    # ------------------------------------------------------------------\n    epsilon = max(_MIN_EPSILON, _EPSILON0 * np.exp(-_DECAY_RATE * _call_counter))\n\n    # ------------------------------------------------------------------\n    # 3) Exploration branch \u2013 random feasible bin with probability epsilon.\n    # ------------------------------------------------------------------\n    if _rng.random() < epsilon:\n        feasible = bins_remain_cap >= item\n        random_scores = _rng.random(bins_remain_cap.shape[0])\n        return np.where(feasible, random_scores, -np.inf)\n\n    # ------------------------------------------------------------------\n    # 4) Deterministic scoring branch.\n    # ------------------------------------------------------------------\n    waste = bins_remain_cap - item                      # Positive = leftover space\n    feasible_mask = waste >= -_EPS                       # Allow tiny negative tolerance\n\n    # Initialise all priorities to -inf (infeasible by default).\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Exact\u2011fit detection \u2013 give them a \"perfect\" priority.\n    atol = 1e-9\n    exact_fit_mask = np.isclose(waste, 0.0, atol=atol) & feasible_mask\n    priorities[exact_fit_mask] = np.inf\n\n    # Non\u2011exact but feasible bins.\n    non_exact_mask = feasible_mask & ~exact_fit_mask\n    if np.any(non_exact_mask):\n        # Base best\u2011fit score: inverse of leftover space.\n        base_score = 1.0 / (waste[non_exact_mask] + _EPS)\n\n        # Penalty for waste that exceeds the EMA of observed item sizes.\n        waste_excess = np.maximum(0.0, waste[non_exact_mask] - _ema_item_size)\n        penalty = _WASTE_PENALTY_WEIGHT * waste_excess\n\n        # Combine base score and penalty.\n        score = base_score - penalty\n\n        # Ensure scores stay positive (still better than -inf).\n        score = np.maximum(score, _EPS)\n        priorities[non_exact_mask] = score\n\n    # ------------------------------------------------------------------\n    # 5) Tie\u2011breaking jitter \u2013 very small random perturbation.\n    # ------------------------------------------------------------------\n    jitter = _rng.random(bins_remain_cap.shape[0]) * 1e-8\n    priorities += jitter\n\n    return priorities",
    "response_id": 4,
    "obj": 3.8891104906262464,
    "SLOC": 31.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority scoring for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item <= bin capacity).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority score for each bin (higher is better). Infeasible bins receive\n        ``-np.inf``. If no bins are open, an empty array is returned.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Normalise input\n    # ------------------------------------------------------------------\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.size\n\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    # Feasibility mask: bins that can accommodate the item\n    fit_mask = caps >= item\n\n    # If nothing fits, force creation of a new bin\n    if not np.any(fit_mask):\n        return np.full(n_bins, -np.inf, dtype=float)\n\n    # ------------------------------------------------------------------\n    # Estimate fixed bin capacity and utilisation\n    # ------------------------------------------------------------------\n    # All bins share the same (unknown) capacity; infer it from the max\n    bin_capacity = caps.max()\n    if bin_capacity <= 0.0:               # safety fallback\n        bin_capacity = item\n\n    # Utilisation = fraction of capacity already used (higher = more filled)\n    utilisation = 1.0 - caps / bin_capacity\n    avg_util = utilisation.mean()\n\n    # Fraction of bins that can fit the item\n    fit_frac = np.mean(fit_mask)\n\n    # ------------------------------------------------------------------\n    # Exploration (epsilon\u2011greedy) scaled by fit fraction and utilisation\n    # ------------------------------------------------------------------\n    base_eps = 0.10                       # baseline exploration probability\n    epsilon = base_eps * (1.0 - fit_frac) * (1.0 + (1.0 - avg_util))\n\n    rng = np.random.default_rng()\n    if rng.random() < epsilon:\n        # Random scores for feasible bins; infeasible remain -inf\n        scores = rng.random(n_bins)\n        scores[~fit_mask] = -np.inf\n        return scores\n\n    # ------------------------------------------------------------------\n    # Deterministic exploitation scoring\n    # ------------------------------------------------------------------\n    # Fill ratio: proportion of the bin's remaining capacity taken by the item\n    fill_ratio = np.empty(n_bins, dtype=float)\n    fill_ratio.fill(np.nan)\n    fill_ratio[fit_mask] = item / caps[fit_mask]\n\n    # Waste fraction after placement (1 - fill_ratio)\n    waste_frac = np.empty(n_bins, dtype=float)\n    waste_frac.fill(np.nan)\n    waste_frac[fit_mask] = 1.0 - fill_ratio[fit_mask]\n\n    # Sigmoid that favours fill ratios > 0.  Steepness grows with avg utilisation.\n    base_k = 12.0\n    k = base_k * (1.0 + avg_util)          # more loaded bins \u2192 sharper sigmoid\n    arg = -k * (fill_ratio[fit_mask] - 0.5)   # negative for fill>0.5 \u2192 larger \u03c3\n    arg = np.clip(arg, -700.0, 700.0)         # protect against overflow\n    sigmoid = 1.0 / (1.0 + np.exp(arg))\n\n    # ------------------------------------------------------------------\n    # Combine components\n    # ------------------------------------------------------------------\n    beta = 0.5   # weight of waste penalty\n    delta = 0.30  # weight of utilisation reward\n\n    priority = np.full(n_bins, -np.inf, dtype=float)\n    priority[fit_mask] = (\n        sigmoid\n        - beta * waste_frac[fit_mask]\n        + delta * utilisation[fit_mask]\n    )\n\n    # Tiny random jitter to break ties reproducibly\n    jitter = rng.random(n_bins) * 1e-9\n    priority[fit_mask] += jitter[fit_mask]\n\n    return priority",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 43.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\n\n# Global state\n_call_counter = 0\n_total_item_size = 0.0\n_ema_item_size = 0.0\n_ema_alpha = 0.2\n_WASTE_PENALTY_WEIGHT = 0.35\n_EPS = 1e-12\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority function for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher is more preferable).\n        Infeasible bins receive -inf.\n    \"\"\"\n    global _call_counter, _total_item_size, _ema_item_size\n\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Update statistics\n    _call_counter += 1\n    _total_item_size += item\n    if _call_counter == 1:\n        _ema_item_size = item\n    else:\n        _ema_item_size = _ema_alpha * item + (1.0 - _ema_alpha) * _ema_item_size\n\n    # Feasible mask\n    feasible_mask = bins_remain_cap >= item\n\n    # Leftover space\n    leftover = bins_remain_cap - item\n\n    # Detect exact\u2011fit bins (zero leftover within tolerance)\n    atol = 1e-9\n    exact_fit_mask = np.isclose(leftover, 0.0, atol=atol) & feasible_mask\n\n    # Prepare priority array with -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Handle exact\u2011fit bins: highest priority (inf)\n    priorities[exact_fit_mask] = np.inf\n\n    # Non\u2011exact feasible bins\n    non_exact_mask = feasible_mask & ~exact_fit_mask\n    if np.any(non_exact_mask):\n        # Base score: inverse of leftover (larger for tighter fit)\n        base_score = 1.0 / (leftover[non_exact_mask] + _EPS)\n\n        # Penalty for waste exceeding EMA of item sizes\n        waste_excess = np.maximum(0.0, leftover[non_exact_mask] - _ema_item_size)\n\n        # Adapt penalty weight by fraction of feasible bins\n        fit_fraction = np.count_nonzero(feasible_mask) / bins_remain_cap.size\n        penalty_weight = _WASTE_PENALTY_WEIGHT * (1.0 - fit_fraction)\n\n        penalty = penalty_weight * waste_excess\n\n        # Raw score before normalization\n        score = base_score - penalty\n\n        # Standardize scores: mean and MAD\n        mean_score = np.mean(score)\n        mad_score = np.median(np.abs(score - mean_score))\n        mad = mad_score if mad_score > _EPS else _EPS\n\n        std_score = (score - mean_score) / mad\n\n        # Clip exponents to avoid overflow\n        clip_val = 50.0\n        std_score = np.clip(std_score, -clip_val, clip_val)\n\n        # Monotonic sigmoid\n        sigmoid_scores = 1.0 / (1.0 + np.exp(-std_score))\n\n        # Assign priorities\n        priorities[non_exact_mask] = sigmoid_scores\n\n    # Tiny deterministic tie\u2011breaker based on bin index\n    indices = np.arange(bins_remain_cap.size)\n    priorities += indices * 1e-8\n\n    return priorities",
    "response_id": 0,
    "obj": 4.188272836059035,
    "SLOC": 34.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response1.txt_stdout.txt",
    "code_path": "problem_iter10_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive epsilon\u2011greedy priority function for online Bin Packing.\n\n    Returns a priority score for each bin (higher = more desirable). Infeasible\n    bins receive ``-np.inf``. The scoring combines:\n      * Exponential decay of the exploration probability (epsilon\u2011greedy);\n      * A weighted leftover term (best\u2011fit style);\n      * A usage bias that favors bins already partially filled;\n      * A penalty for bins that would become too tight relative to the\n        predicted next\u2011item size (estimated via an exponential moving average).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Static state (initialized once)\n    # ------------------------------------------------------------------\n    if not hasattr(priority_v2, \"initialized\"):\n        # Exploration parameters\n        priority_v2.epsilon0 = 0.2          # initial exploration probability\n        priority_v2.min_epsilon = 0.01     # lower bound for epsilon\n        priority_v2.decay_rate = 0.001    # exponential decay rate\n\n        # EMA for predicting the size of the next item\n        priority_v2.alpha = 0.2            # smoothing factor (0 < alpha <= 1)\n        priority_v2.ema_item = None        # will hold the EMA after first item\n\n        # Counters\n        priority_v2.item_count = 0\n\n        # Scoring weights\n        priority_v2.leftover_weight = 1.0   # weight for the leftover term\n        priority_v2.usage_weight = 0.2     # bias for already used bins\n        priority_v2.penalty_factor = 2.0   # strength of the tight\u2011bin penalty\n\n        # Random generator for exploration\n        priority_v2.rng = np.random.default_rng()\n\n        priority_v2.initialized = True\n\n    # ------------------------------------------------------------------\n    # Per\u2011item updates\n    # ------------------------------------------------------------------\n    priority_v2.item_count += 1\n\n    # Update EMA of item size (prediction of next\u2011item size)\n    if priority_v2.ema_item is None:\n        priority_v2.ema_item = item\n    else:\n        priority_v2.ema_item = (priority_v2.alpha * item +\n                               (1 - priority_v2.alpha) * priority_v2.ema_item)\n\n    # Compute decayed epsilon\n    epsilon = max(priority_v2.min_epsilon,\n                  priority_v2.epsilon0 *\n                  np.exp(-priority_v2.decay_rate * priority_v2.item_count))\n\n    # Feasibility mask (bins that can accommodate the item)\n    feasible = bins_remain_cap >= item\n\n    # ------------------------------------------------------------------\n    # Exploration: pick a random feasible bin with probability epsilon\n    # ------------------------------------------------------------------\n    if priority_v2.rng.random() < epsilon:\n        rand_scores = priority_v2.rng.random(bins_remain_cap.shape[0])\n        # Infeasible bins must never be selected\n        rand_scores[~feasible] = -np.inf\n        return rand_scores\n\n    # ------------------------------------------------------------------\n    # Exploitation: compute a deterministic priority for each bin\n    # ------------------------------------------------------------------\n    leftover = bins_remain_cap - item\n    feasible = leftover >= 0  # recompute for clarity\n\n    # 1) Weighted leftover (best\u2011fit): smaller leftover \u2192 higher score\n    base_score = -priority_v2.leftover_weight * leftover\n\n    # 2) Usage bias: encourage packing into bins that already contain items\n    if bins_remain_cap.size > 0:\n        total_capacity = bins_remain_cap.max()   # all bins share the same capacity\n        if total_capacity > 0:\n            fill_ratio = (total_capacity - bins_remain_cap) / total_capacity\n        else:\n            fill_ratio = np.zeros_like(bins_remain_cap)\n    else:\n        fill_ratio = np.zeros_like(bins_remain_cap)\n    usage_bonus = priority_v2.usage_weight * fill_ratio\n\n    # 3) Penalty for creating a bin that is too tight for the predicted next item\n    tight_mask = feasible & (leftover < priority_v2.ema_item)\n    penalty = np.zeros_like(bins_remain_cap)\n    penalty[tight_mask] = (priority_v2.penalty_factor *\n                           (priority_v2.ema_item - leftover[tight_mask]))\n\n    # Combine all components\n    scores = base_score + usage_bonus - penalty\n    scores[~feasible] = -np.inf if hasattr(np, 'inf') else -np.inf  # ensure infeasible bins are worst\n\n    return scores",
    "response_id": 1,
    "obj": 38.133226964499414,
    "SLOC": 46.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response3.txt_stdout.txt",
    "code_path": "problem_iter10_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive sigmoid priority function for online bin packing.\n\n    For each currently open bin the function returns a score; higher scores\n    indicate a more desirable bin for placing ``item``. Bins that cannot\n    accommodate the item receive ``-inf`` so they are never selected. The\n    scoring uses a sigmoid whose steepness adapts to the dispersion of the\n    feasible residual capacities, employing a robust spread estimate (MAD).\n    A deterministic tiny bias breaks ties in favour of lower\u2011index bins.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores (same shape as ``bins_remain_cap``).\n    \"\"\"\n    # Ensure a 1\u2011D float array.\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.shape[0]\n\n    # No bins open \u2013 return empty array.\n    if n_bins == 0:\n        return np.empty(0, dtype=float)\n\n    # Residual capacity after hypothetically placing the item.\n    residual = caps - item\n\n    # Feasibility mask: only bins with enough remaining capacity.\n    feasible = residual >= 0\n\n    # Initialise all scores to -inf (infeasible).\n    scores = np.full(n_bins= n_bins, fill_value=-np.inf, dtype=float) if False else np.full(n_bins, -np.inf, dtype=float)\n    # Actually, the above line is erroneous; correct implementation follows.\n    scores = np.full(n_bins, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return the -inf vector.\n    if not np.any(feasible):\n        return scores\n\n    # Residual capacities of feasible bins.\n    feas_res = residual[feasible]\n\n    # --- Robust spread estimation (MAD) ------------------------------------\n    median_res = np.median(feas_res)\n    mad = np.median(np.abs(feas_res - median_res))\n    # Convert MAD to an estimate of standard deviation for normal data.\n    spread = mad * 1.4826\n\n    # Fallback strategies if MAD is zero.\n    if spread <= 0.0:\n        std = np.std(feas_res)\n        if std > 0.0:\n            spread = std\n        else:\n            # Use range as last resort.\n            rng = np.max(feas_res) - np.min(feas_res)\n            spread = rng if rng > 0.0 else 1.0\n\n    # --- Adaptive sigmoid ----------------------------------------------------\n    # Base steepness factor (tunable). Larger spread \u2192 softer sigmoid.\n    base_steepness = 5.0\n    slope = base_steepness / spread\n\n    # Logistic function decreasing with residual capacity.\n    # score = 1 / (1 + exp(slope * residual))\n    exp_arg = np.clip(slope * residual[feasible], -700, 700)  # avoid overflow\n    scores_feas = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Assign scores to feasible bins.\n    scores[feasible] = scores_feas\n\n    # --- Deterministic tie\u2011breaker -----------------------------------------\n    # Tiny decreasing bias with index ensures stable ordering when scores tie.\n    epsilon = 1e-12\n    tie_bias = -np.arange(n_bins, dtype=float) * epsilon\n    scores = np.where(scores > -np.inf, scores + tie_bias, scores)\n\n    return scores",
    "response_id": 3,
    "obj": 3.9888312724371757,
    "SLOC": 31.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response7.txt_stdout.txt",
    "code_path": "problem_iter10_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Deterministic priority scores for online bin packing.\n\n    The function evaluates each currently open bin and returns a score;\n    higher scores indicate a more desirable bin for placing the incoming\n    ``item``. Infeasible bins (those that cannot accommodate the item) are\n    assigned ``-np.inf``. The score is based on an adaptive sigmoid that\n    depends on the distribution of the residual capacities of feasible bins.\n    A tiny deterministic tie\u2011breaker (decreasing bias with bin index) ensures\n    a stable ordering when scores tie.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be non\u2011negative).\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining capacity of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores, same shape as ``bins_remain_cap``.\n    \"\"\"\n    # Ensure a 1\u2011D float array.\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.shape[0]\n\n    # Empty input \u2192 nothing to score.\n    if n_bins == 0:\n        return np.empty(0, dtype=float)\n\n    # Residual capacity after (hypothetically) placing the item.\n    residual = caps - item\n\n    # Feasibility mask: bins that can hold the item.\n    feasible = residual >= 0.0\n\n    # Initialise all scores to -inf (infeasible).\n    scores = np.full(n_bins, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return the -inf vector.\n    if not np.any(feasible):\n        return scores\n\n    # Residual capacities of feasible bins.\n    feas_res = residual[feasible]\n\n    # --- Adaptive steepness using MAD (median absolute deviation) ---\n    median_res = np.median(feas_res)\n    mad = np.median(np.abs(feas_res - median_res))\n    # Convert MAD to an estimate of standard deviation (for normal data).\n    spread = mad * 1.4826\n\n    # Fallback strategies if MAD is zero or extremely small.\n    if spread <= 0.0:\n        std = np.std(feas_res)\n        if std > 0.0:\n            spread = std\n        else:\n            # Use range as a last resort.\n            r = np.max(feas_res) - np.min(feas_res)\n            spread = r if r > 0.0 else 1.0\n\n    # Base steepness factor (tunable). Larger spread \u2192 softer sigmoid.\n    base_steepness = 5.0\n    slope = base_steepness / spread\n\n    # --- Sigmoid scoring -------------------------------------------------\n    # Logistic function decreasing with residual.\n    # score = 1 / (1 + exp(slope * residual))\n    # Clip exponent to avoid overflow/underflow.\n    exp_arg = np.clip(slope * feas_res, -700.0, 700.0)\n    scores_feas = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Assign scores to feasible bins.\n    scores[feasible] = scores_feas\n\n    # --- Deterministic tie\u2011breaker ---------------------------------------\n    # Tiny decreasing bias with bin index ensures stable ordering when scores tie.\n    tie_bias = -np.arange(n_bins, dtype=float) * 1e-12\n    scores = np.where(scores > -np.inf, scores + tie_bias, scores)\n\n    return scores",
    "response_id": 7,
    "obj": 3.9888312724371757,
    "SLOC": 29.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response9.txt_stdout.txt",
    "code_path": "problem_iter10_code9.py",
    "code": "import numpy as np\n\n# ----------------------------------------------------------------------\n# Global online statistics and exploration parameters\n# ----------------------------------------------------------------------\n_call_counter: int = 0                # Number of items processed so far\n_total_item_size: float = 0.0         # Cumulative sum of item sizes\n\n# Epsilon\u2011greedy exploration schedule\n_EPSILON_START: float = 0.2          # Initial exploration probability\n_EPSILON_MIN: float = 0.01           # Minimum exploration probability\n_EPSILON_DECAY: float = 0.001        # Exponential decay (per item)\n\n# Penalty weights for waste\n_ALPHA: float = 0.5   # Penalty weight for waste > average item size\n_BETA: float = 0.3    # Penalty weight for waste > relative capacity threshold\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority function for the online Bin Packing Problem.\n\n    This function blends several heuristics:\n      * Exact\u2011fit bins receive infinite priority.\n      * Best\u2011fit (inverse of residual waste) is the base score.\n      * Bins that would leave waste larger than the running average item size\n        are penalised (weight _ALPHA).\n      * Bins that would leave waste larger than a configurable fraction of the\n        bin capacity are further penalised (weight _BETA).\n      * An epsilon\u2011greedy exploration component decays over time, allowing\n        occasional random feasible choices.\n      * A deterministic tie\u2011breaker prefers lower\u2011index bins when scores are\n        otherwise equal.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more desirable).  Infeasible\n        bins receive ``-np.inf``.\n    \"\"\"\n    global _call_counter, _total_item_size\n\n    # Convert to NumPy array of floats\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Update online statistics\n    _call_counter += 1\n    _total_item_size += item\n    avg_item_size = _total_item_size / _call_counter\n\n    # Compute dynamic epsilon for exploration\n    epsilon = max(_EPSILON_MIN,\n                  _EPSILON_START * np.exp(-_EPSILON_DECAY * _call_counter))\n\n    rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Exploration branch: with probability epsilon pick a random feasible bin\n    # ------------------------------------------------------------------\n    if rng.random() < epsilon:\n        feasible = caps >= item - 1e-12\n        random_scores = rng.random(caps.shape[0])\n        return np.where(feasible, random_scores, -np.inf)\n\n    # ------------------------------------------------------------------\n    # Deterministic scoring branch\n    # ------------------------------------------------------------------\n    waste = caps - item\n\n    atol = 1e-9  # tolerance for floating\u2011point comparisons\n\n    # Feasibility mask (allow tiny negative due to rounding)\n    feasible_mask = waste >= -atol\n    # Exact\u2011fit mask\n    exact_fit_mask = np.isclose(waste, 0.0, atol=atol)\n\n    # Initialise priorities: -inf for infeasible bins\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    # Exact fits get infinite priority\n    priorities[exact_fit_mask] = np.inf\n\n    # Non\u2011exact feasible bins\n    non_exact_mask = feasible_mask & ~exact_fit_mask\n    if np.any(non_exact_mask):\n        tiny = 1e-12  # avoid division by zero\n        # Base score: inverse of waste (smaller waste \u2192 larger score)\n        base_score = 1.0 / (waste[non_exact_mask] + tiny)\n\n        # Penalty for waste exceeding the running average item size\n        excess_over_avg = np.maximum(0.0, waste[non_exact_mask] - avg_item_size)\n        penalty_avg = _ALPHA * excess_over_avg\n\n        # Penalty for waste that is large relative to bin capacity\n        # Threshold: 30% of the bin capacity\n        rel_waste = waste[non_exact_mask] / caps[non_exact_mask]\n        excess_rel = np.maximum(0.0, rel_waste - 1.0 * 0.30)\n        penalty_rel = _BETA * excess_rel * caps[non_exact_mask]  # scaled to absolute waste\n\n        # Combine components\n        score = base_score - penalty_avg - penalty_rel\n\n        priorities[non_exact_mask] = score\n\n    # ------------------------------------------------------------------\n    # Deterministic tie\u2011breaker: prefer lower\u2011index bins when scores tie\n    # ------------------------------------------------------------------\n    if priorities.size:\n        if np.issubdtype(priorities.dtype, np.floating):\n            eps_machine = np.finfo(priorities.dtype).eps\n        else:\n            eps_machine = np.finfo(np.float64).eps\n        tie_break = np.arange(priorities.size, dtype=priorities.dtype) * eps_machine\n        priorities = priorities - tie_break\n\n    return priorities",
    "response_id": 9,
    "obj": 4.098524132429212,
    "SLOC": 38.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  }
]