{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Softmax\u2011Based Fit priority for online Bin Packing.\n\n    For each bin we compute the amount of *wasted* space that would remain\n    after inserting the item (if the item fits).  The priority is then an\n    exponential (softmax) decay of this waste \u2013 bins that leave little or no\n    waste get the highest scores.  A temperature parameter controls the\n    greediness: lower values behave like a Best\u2011Fit heuristic, higher values\n    produce a softer distribution (more exploration).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Array containing the remaining capacity of each existing bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores (summing to 1 over feasible bins).  Bins that\n        cannot accommodate the item receive a priority of 0.\n    a new bin will be opened when all priorities are zero.\n    \"\"\"\n    # ---------------------- hyper\u2011parameters ----------------------\n    temperature: float = 0.3          # <1 \u2192 greedier (best\u2011fit), >1 \u2192 softer\n    waste_exponent: float = 1.0       # linear waste penalty (2.0 \u2192 quadratic)\n    # ----------------------------------------------------------------\n\n    # Compute how much space would remain if the item were placed.\n    waste = bins_remain_cap - item            # positive = leftover space, negative = cannot fit\n    feasible = waste >= 0                     # boolean mask of bins that can hold the item\n\n    # Raw scores: negative (penalised) waste. Infeasible bins get -inf \u2192 zero after exp.\n    raw_scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    raw_scores[feasible] = -np.power(waste[feasible], waste_exponent)\n\n    # If no bin can accommodate the item, return a zero vector (caller may open a new bin).\n    if not feasible.any():\n        return np.zeros_like(bins_remain_cap, dtype=np.float64)\n\n    # Numerically stable softmax:\n    #   softmax(x) = exp((x - max(x)) / temperature) / sum(exp(...))\n    max_raw = raw_scores[feasible].max()\n    shifted = (raw_scores - max_raw) / temperature\n    exp_vals = np.exp(shifted)               # exp(-inf) -> 0 for infeasible bins\n\n    total = exp_vals.sum()\n    if total > 0:\n        priorities = exp_vals / total\n    else:\n        priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Adaptive sigmoid priority for online bin packing.\n\n    Gives higher priority to bins that accommodate the item tightly.\n    The steepness of the sigmoid is calibrated to the spread of feasible\n    residual capacities, ensuring a balanced exploitation of tight fits\n    across different instance scales. Infeasible bins receive -inf.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as `bins_remain_cap`).\n        Higher values indicate more desirable bins; infeasible bins are\n        penalised with -inf.\n    \"\"\"\n    # Ensure a NumPy float array.\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    if caps.size == 0:\n        return np.array([], dtype=float)\n\n    # Residual capacity after placing the item in each bin.\n    residual = caps - item\n\n    # Feasibility mask.\n    feasible = residual >= 0\n\n    # If nothing fits, return -inf for every bin.\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Residuals of feasible bins.\n    feasible_res = residual[feasible]\n\n    # Adaptive steepness: based on the more robust spread of feasible residuals.\n    # Use standard deviation; fall back to range if std is zero.\n    std = np.std(feasible_res)\n    if std <= 0.0:\n        spread = np.max(feasible_res) - np.min(feasible_res)\n        std = spread if spread > 0.0 else 1.0\n\n    # Base steepness factor (tunable). Larger std \u2192 softer sigmoid.\n    base_steepness = 5.0\n    slope = base_steepness / std\n\n    # Sigmoid of negative residual: tighter fit \u2192 larger score.\n    # score = 1 / (1 + exp(slope * residual))\n    # Clip exponent to avoid overflow/underflow.\n    exp_arg = np.clip(slope * residual, -700, 700)\n    scores = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Penalise infeasible bins.\n    scores = np.where(feasible, scores, -np.inf)\n\n    # Deterministic tie\u2011breaker: tiny bias favouring lower indices.\n    # This does not affect ordering unless scores are exactly equal.\n    tie_bias = -np.arange(caps.shape[0]) * 1e-12\n    scores = np.where(scores > -np.inf, scores + tie_bias, scores)\n\n    return scores\n\n[Reflection]\nScale scores by residual spread, use adaptive sigmoid or softmax, heavily penalize infeasible bins, add deterministic tie bias.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}