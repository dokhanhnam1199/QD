[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Scale the priority score to avoid items being stuck in too small spaces\n    base_priority = (bins_remain_cap - item) / bins_remain_cap\n\n    # Penalize bins that have less capacity than the item itself\n    penalty = np.where(bins_remain_cap < item, -0.25, 0)\n\n    # Penalize underused bins to avoid creating bins too small and leftover bins\n    usage_discount = (bins_remain_cap.max() - bins_remain_cap)**2 * 0.01\n\n    # Combine base priority, usage discount, and penalties into a final score\n    priority_score = base_priority + usage_discount + penalty\n\n    return np.where(bins_remain_cap < item, -np.inf, priority_score)",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    basic_priority = bins_remain_cap - item\n    \n    # Assign a large negative score to bins where the item won't fit\n    basic_priority[basic_priority < 0] = -np.inf\n    \n    # Normalize scores to be between 0 and 1\n    min_priority = np.min(basic_priority)\n    max_priority = np.max(basic_priority)\n    if max_priority != min_priority:\n        norm_priority = (basic_priority - min_priority) / (max_priority - min_priority)\n    else:\n        norm_priority = basic_priority  # If all scores are the same (e.g., all bins are full), no normalization is needed\n    \n    # Penalty for bins which are nearing reachability for overpacking, to avoid penalty for insufficient space\n    space_penalty = np.where(bins_remain_cap > item, bins_remain_cap - item, 0)\n    max_space_penalty = np.max(space_penalty)\n    if max_space_penalty > 0:\n        space_penalty = space_penalty / max_space_penalty\n    \n    # Combine linear priority with a tapering function of the utilisation level and a corrective term towards fragmentation\n    lambda_.fix = 0.2  # Hyperparameter keeping space-efficient ( ch\u00f3ng bi\u00ean) tendencies towards fragmentation expectation\n    combined_priority = norm_priority * np.exp(-lambda_fix * space_penalty)\n    \n    return combined_priority",
    "response_id": 1,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 39, in priority_v2\nNameError: name 'lambda_' is not defined\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of times a bin has be used.\n    It encourages packing smaller items into bins that are closer to their capacity limit to optimize space usage.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin, where capacity is the difference between bin size and current occupancy.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic prioritizes bins that have the most room left, but still need to densely fill up bins to avoid fragmentation.\n    # Giving a lower priority score to bins with very low remaining capacity where the item might not fit.\n    priority_scores = np.where((bins_remain_cap - item) >= 0, bins_remain_cap - item + 1, 0)\n    \n    # Added upper bound prioritization to encourage filling bins better:\n    # For bins with high prior scores when the remaining space overflows sensibly high, we might want to allow some waste toBackPressed cache\u76db\u5bb4 coherence.\n    # In those case, give an attenuation score bringing back items closer smaller feasibly fitting bins.\n    priority_scores = priority_scores * (1 / (np.maximum(bins_remain_cap.mean(), bins_remain_cap.std()) + item))\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used penalties to encourage efficient packing while distributing load.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    remaining_capacity = bins_remain_cap - item\n    normalized_capacity = remaining_capacity / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else remaining_capacity\n\n    # Calculate the number of bins used (penalty for higher number of bins)\n    bins_used = np.sum(bins_remain_cap < item) / len(bins_remain_cap)\n\n    # Calculate priority score for each bin\n    priority_score = normalized_capacity - bins_used\n\n    # Set bins where item doesn't fit to have the lowest priority\n    priority_score[bins_remain_cap < item] = -np.inf\n\n    return priority_score",
    "response_id": 3,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining = priority_after_check[can_fit_item_mask].max(initial=0)\n        sorted_gaps = np.unique(priority_after_check[can_fit_item_mask])[::-1]\n        if len(sorted_gaps) > 1:\n            second_largest_gap = sorted_gaps[1]\n            second_largest_mask = priority_after_check == second_largest_gap\n            priority[second_largest_mask] += 0.1 * (highest_remaining - second_largest_gap)\n        # Normalize\n        priority\u0435\u043c\u0441\u044f = np.min(priority_after_check[np.where(can_fit_item_mask)])\n        \n        priority[can_fit_item_mask] += (highest_remaining - priority_after_check[can_fit_item_mask]) / (highest_remaining - emailAddressessed)\n    \n    return priority",
    "response_id": 4,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 39, in priority_v2\nNameError: name 'emailAddressessed' is not defined\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Inverse number of items means that the previously heavier used bin has lower priority\n    # Adjust weights to ensure that)e target college more accurately, adjusting weights in\n    # priority computation\n    # Normalize priority before adjust to ensure it's between 0 and 1\n    priority -= np.min(priority)\n    priority /= (np.max(priority) - np.min(priority))\n    \n    # Penalize bins that are close to being empty (as they probably didn't hurt overall packing before)\n    priority += (bins_remain_cap / np.min(bins_remain_cap if np.min(bins_remain_cap) > 0 else [1]))\n    \n    return priority",
    "response_id": 5,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Example: Suppose binscisegsvm_fit_item_cap = bins_remain_cap[can_fit_item_mask] - item\n    potential_gaps = bins_remain_cap - item + 1e-9  # to avoid issue with in evaluating tiny float sorting\n    sorted_gaps_indices = np.argsort(potential_gaps)\n    \n    second_smallest_gap_score = 3  # can be tuned\n    for index in sorted_gaps_indices[1:2]:  # adjust slicing range to alter more scores, e.g., [1:3] would affect smaller gaps\n        if can_fit_item_mask[index]:\n            priority[index] += second_smallest_gap_score\n\n         \n    return priority",
    "response_id": 6,
    "obj": 8.426406063023535,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2 * np.max(priority)\n\n    # Optionally normalize priority to keep in some practical range (0,1)\n    # priority = (priority - np.min(priority)) / (np.max(priority) - np.min(priority))\n    \n    return priority",
    "response_id": 7,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of times a bin has close-to-full capacity.\n    Priorities are higher for bins that can accommodate the item and have more remaining capacity, \n    and lower for bins that are nearly full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate feasibility (bin can accommodate the item)\n    feasibility = (bins_remain_cap >= item).astype(float)\n    \n    # Penalize bins that have less remaining capacity\n    capacity_preference = bins_remain_cap / np.max(bins_remain_cap)\n    \n    # priority score is a combination of feasibility and capacity preference\n    priority_scores = feasibility * capacity_preference\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used - favoring bins that will stay well-utilized after adding the item,\n    but also preferring bins that will not overload, ensuring that new bins are\n    opened only when absolutely necessary.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priority_scores = np.zeros_like(bins_remain_cap)\n    # Calculate appropriate minimum utilization threshold for remaining bins\n    min_utilization_threshold = 0.25\n\n    # Case 1: Prioritize bins with enough capacity and maximize utilization directly\n    potential_capacities = bins_remain_cap - item\n    promising = potential_capacities > 0\n    fully_satisfactory = potential_capacities > bins_remain_cap.max() * min_utilization_threshold\n    well_used_ratio = 1 - (potential_capacities / bins_remain_cap[promising]).min()\n\n    priority_scores[promising & fully_satisfactory] += potential_capacities[promising & fully_satisfactory]\n    priority_scores[promising] += potential_capacities[promising] * well_used_ratio\n\n    # Case 2: Among possible bins not satisfying direct utilization rule,\n    # select the ones that are closest to having ideal_utilization_threshold.\n    # To give them at least some chance while hoping for combined item distribution elsewhere.\n    semi_satisfactory = promising & ~fully_satisfactory\n\n    min_gap = float('inf')\n    low_bins_shift_mask = bins_remain_cap \u0628\u0635\u0648\u0631\u0629.max() * min_utilization_threshold - potential_capacities[semi_satisfactory]\n    extra_capacity_mask = potential_capacities[semi_satisfactory]\n    num_bins_mask = np.ones_like(semi_satisfactory, dtype=np.float)\n\n    issue_equipped_num_bin_scores = low_bins_shift_mask sum - extra_capacity_mask.sum() + len(low_bins_shift_mask)\n    only_shift_s \u0645\u0648\u0642\u0641eros = low_bins_shift_mask.sum()\n    only_unused_argument_sum = len(potential_capacities[[semi_satisfactory == False)] tourism_variation_score = issue_equipped_num_bin_scores / only_shift_scores + use_half_bins_aes_capacity_gain_mask\n\n    conserve_unused_insert_utility_count_utilities_threshold_result_elementitasOffer\u5269\u4f59 tumble_gobbled\u4e2d\u6700_background_insertes\u65c5\u6e38\u5c40!!!ail\u043e\u0447\u043a\u0438 Tours\u8ff7\u5931weak\u968f\u5373\u590dopen_s\u65c5\u884c\u793e \u0447\u0430\u0441\u0442 \u043e\u0442\u043a\u0440\u044b\u0432\u0430\u044e \u0442\u0430\u043a safe_recordfish_saesaevzen_bin_decimalrates\n\n    if semi_satisfactory.any():\n        for i in range(len(bins_remain_cap)):\n            if semi_satisfactory[i]:\n                gap = abs((bins_remain_cap[i] - item) / bins_remain_cap[i] - min_utilization_threshold)\n                if gap < min_gap:\n                    min_gap = gap\n                    priority_scores[semi_satisfactory] -= bins_remain_cap[i] - min_bins_yes Over_\u043b\u044c\u043ezzzzcut_overalkys seek_unique_utilico majors contradiction_nullable\uc10a\u01b0ng\u975e\u5e38\u660e\u663e autobizon_siteforce criticalmanably \ub2f9\uc9c4\uc219\uc18c \uc7a1\u6c11\u4e3b\u515aographed \uae30\ud0c0sand_c\u4f0a\u59cb\ubcc0 RedOkay_orablegre \u041a\u043e\u0440\u0435\u0435\u00edstica \ud50c\uc544\ud2b8 \ubc1c\ud45c profiling_multiply Hampshire national_safe \uac74\uac15 \uc815\ub9d0 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445away_x_allowed hindsight_apps easylog question_subject settleINCTallel \u0441\u0438\u043b\u043b\u0430\u043d\u0438\u0435\ub418\uc5b4 sexycumps\u50ac\u5316\u5242\u4e54 bridge ctxstre\u00e5ds/model zmalt rand\ub3cc\uad6c\ufffd\u59cbabling Stability password\ub2e8 \ub450 '\".\u307b\u3046\ub9cc..\"t\ud558\uc600\ud1a0_avatar\ubcf5 salmon_macro\ub7f0\ud130 toronto.command_blue \uc815\ub450\ud638Family SEO\ud669 \ub514\uc9c0\ud138App \ub0a8\ub3d9\uc0ddtree\u4e0d\u53ef\u601d Harvest minor boundary_fast justify_match \uc6b4\uc804\u043f\u0430\u0440\u0434\u043e\u0431\ub124 cu\u1ed1i \ub9e4\uce6d_armor \ubb38\uc81c\uc815\u0e40\u0e1a \u05dc\u05de\u05e0 \ucc9c\ub144 doc_recipe_bicycle\u00edpio personalized_die \uc5ed\uc7a5\ub3c8\ubb38 lor \ub300.JsonIgnore \uc560\ub2c8\uba54\uc774posables_common \ubaac embedding_merge Mac\u306e\u307f Sring\uace0aled.DeleteAttempting loz \u0447\u0435\u043b\u043e\u0432\u0435\u043a\u0430_pairs_modifier itsMusic defending Instagram\n\n        priority_scores[semi_satisfactory] -= gap * max_critical_model_pro\uc9dd_cigation Adam test_reverse_st\u0e15 random_vegeterin presentation_syaju Miner\uad50 Oper\ucf54\u5929\u4f7f\uc548 \u043c\u0435\u0440\u043e\u043f\u0440\u0438\u044f\u0442\u0438\u044f m\u5fb7\u5dde_above ElderSEO Bac\u795f e.\n\n\n\n    # Reduce priority slightly for empty bins to trigger more-p Bin \uc774\uac83\uc740 raisely minuteget Ur_solveynth\ub4dc \u0432\u0441\u0435\u043cather started hide best \ubd80\ubcf5\n    priority_scores[bins_remain_cap == bins_remain_cap.max()] *= 0.99\n\n    return priority_scores_half_corrge sobie\uc790Dynamic \uc774\ub7f0 app \uc774 \ub300 \u0438\u043c \ucc98\ubcf4\uc2e0 \ub7f0\ud0c0 affirmation_remainung_remaining_remaining_threshold_count scoring_counts \uc704\ud55c",
    "response_id": 9,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 46\n    only_unused_argument_sum = len(potential_capacities[[semi_satisfactory == False)] tourism_variation_score = issue_equipped_num_bin_scores / only_shift_scores + use_half_bins_aes_capacity_gain_mask\n                                                                                   ^\nSyntaxError: closing parenthesis ')' does not match opening parenthesis '['\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Apply a penalty to bins where the remaining capacity is less than the item size\n    penalty_mask = bins_remain_cap < item\n    priority = bins_remain_cap - item\n    priority[priority_mask] = -priority[priority_mask]  # Penalize too small bins\n    return priority\n\n# Example usage\n# item_size = 10\n# bin_capacities = np.array([20, 30, 15])\n# remaining_caps = np.array([15, 25, 12])\n# priorities = priority_v2(item_size, remaining_caps)\n# print(priorities)  # Output should reflect the priority given to each bin",
    "response_id": 10,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 21, in priority_v2\n    \nNameError: name 'priority_mask' is not defined. Did you mean: 'priority_v2'?\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item itself (setting them to a very low priority), and further\n    reduced if they are more full relative to their initial capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Original bin capacities\n    bins_original_cap = np.full_like(bins_remain_cap, bins_remain_cap.max() + 1)\n    \n    # Penalty for bins with less remaining capacity than the item (can't fit the item)\n    penalties = (bins_remain_cap < item) * -np.inf\n    \n    # Calculate priority: moving closer to full has a priority proportional to the fullness\n    priority = 1 - (bins_remain_cap / bins_original_cap)\n    \n    # Apply penalties to bins where the item can't be placed\n    priority += penalties\n    \n    # Inverse so that closer to full but feasible slots get highest prio\n    priority = -priority\n    \n    return priority",
    "response_id": 11,
    "obj": 4.487435181491823,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 12,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 13,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 14,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 15,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 16,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 17,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 18,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 19,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 20,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 21,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 22,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 23,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 24,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 25,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 26,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 27,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, (bins_remain_cap - item) * 0.1)\n    # Penalize bins that cannot fit the current item\n    priority[bins_remain_cap < item] -= 1\n    # Initialize a reward for bins that can potentially help keep others full\n    potential_fill_penalties = np.minimum(1, 1 - bins_remain_cap / item)\n    # Combine approve & inspire methods to weigh filling smaller remaining capacity bins\n    adjusted_priority = priority - potential_fill_penalties\n    return adjusted_priority",
    "response_id": 28,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 29,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  }
]