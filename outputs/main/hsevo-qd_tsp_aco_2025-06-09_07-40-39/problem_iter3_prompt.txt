{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\nCurrent heuristics:\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines inverse distance and node degree penalty for TSP.\n    Normalizes heuristic scores to represent edge promisingness.\n    \"\"\"\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n\n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\nNow, think outside the box write a mutated function `heuristics_v2` better than current version.\nYou can use some hints below:\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's redefine \"Current Self-Reflection\" for designing better heuristics, steering clear of ineffective practices:\n\n*   **Keywords:** Comprehensive analysis, robustification, edge-case handling, multi-faceted evaluation.\n*   **Advice:** Actively question initial assumptions. Explore diverse heuristic parameters and combinations. Stress-test heuristics with varied datasets. Quantify improvements systematically.\n*   **Avoid:** Premature optimization on limited datasets. Over-reliance on intuition without empirical validation. Ignoring potential failure modes or boundary conditions.\n*   **Explanation:** Current self-reflection should involve broad exploration, rigorous testing, and awareness of limitations, ensuring robustness across diverse scenarios.\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}