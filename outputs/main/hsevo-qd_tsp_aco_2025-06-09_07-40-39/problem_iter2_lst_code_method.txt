{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 4th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 5th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 6th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 7th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 8th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 9th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 10th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n[Heuristics 11th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 13th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}