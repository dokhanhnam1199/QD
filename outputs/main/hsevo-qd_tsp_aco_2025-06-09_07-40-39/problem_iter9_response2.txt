```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Combines inverse distance, degree penalty, clustering coefficient, and adaptive sparsification.
    Also uses a pheromone-inspired persistence mechanism.
    """
    zero_replacement_value = 1e-9
    std_replacement_value = 1e-6
    nan_replacement_value = 0.0
    sharpening_factor = 1.1  # Reduced sharpening to be less aggressive
    pheromone_weight = 0.1  # Weight for the pheromone influence
    degree_penalty_exponent = 0.5 #tuneable parameter
    clustering_weight = 0.1 #tuneable parameter

    # Avoid division by zero
    distance_matrix = np.where(distance_matrix == 0, zero_replacement_value, distance_matrix)

    # 1. Inverse distance
    heuristic_matrix = 1 / distance_matrix

    # 2. Node degree penalty
    num_nodes = distance_matrix.shape[0]
    degree_penalty = np.zeros_like(distance_matrix)
    node_strengths = np.sum(heuristic_matrix, axis=0)

    for i in range(num_nodes):
        for j in range(num_nodes):
            if i != j:
                degree_penalty[i, j] = 1 / (node_strengths[i] * node_strengths[j])**degree_penalty_exponent

    # Combine inverse distance and node degree penalty
    heuristic_matrix = heuristic_matrix * degree_penalty

    # 3. Clustering Coefficient Approximation (using shared neighbors)
    clustering_coefficients = np.zeros_like(distance_matrix)
    for i in range(num_nodes):
        for j in range(num_nodes):
            if i != j:
                # Approximate number of common neighbors
                common_neighbors = np.sum((distance_matrix[i, :] > 0) & (distance_matrix[j, :] > 0))
                #Heuristic approximation.  Could improve this.
                clustering_coefficients[i, j] = common_neighbors / (num_nodes - 2 + zero_replacement_value)

    heuristic_matrix = heuristic_matrix + clustering_weight * clustering_coefficients

    # 4. Adaptive Sparsification and Edge Sharpening
    node_mean_heuristic = np.mean(heuristic_matrix, axis=1, keepdims=True)
    sharpened_heuristic = np.where(heuristic_matrix > sharpening_factor * node_mean_heuristic,
                                  heuristic_matrix,
                                  0.0)  # Sparsify by setting others to zero

    # 5. Variance Normalization - more stable normalization

    row_mean = np.mean(sharpened_heuristic, axis=1, keepdims=True)
    row_std = np.std(sharpened_heuristic, axis=1, keepdims=True)
    col_mean = np.mean(sharpened_heuristic, axis=0, keepdims=True)
    col_std = np.std(sharpened_heuristic, axis=0, keepdims=True)

    row_std = np.where(row_std == 0, std_replacement_value, row_std)
    col_std = np.where(col_std == 0, std_replacement_value, col_std)

    row_normalized = (sharpened_heuristic - row_mean) / row_std
    col_normalized = (sharpened_heuristic - col_mean) / col_std

    final_heuristic_matrix = row_normalized + col_normalized #Simplified combination

    #6. Pheromone Persistence - removed due to complexities of passing external pheromone info. Could be added back
    #if external pheromone info exists, the formula could be:
    #final_heuristic_matrix = (1 - pheromone_weight) * final_heuristic_matrix + pheromone_weight * pheromone_matrix #need to pass pheromone matrix

    #Zero out diagonals (no self-loops)
    np.fill_diagonal(final_heuristic_matrix, 0)

    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=nan_replacement_value, posinf=nan_replacement_value, neginf=nan_replacement_value)

    return final_heuristic_matrix
```
