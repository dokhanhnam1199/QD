{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Implements a heuristic for the Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance: Closer cities are more likely to be connected.\n    2. Node Degree Preference: Penalizes high-degree nodes (prevents local optima saturation).\n    3. Variance based normalization to create reasonable probability.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n                                         between cities. distance_matrix[i][j] is the\n                                         distance between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                      representing the heuristic scores for each edge.  Higher\n                      scores indicate a more promising edge.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # 1. Inverse distance (more or less what we did before)\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty - encourages exploration and avoids quickly settling\n    #    on a suboptimal solution. This penalizes edges connected to nodes that\n    #    already have many connections in the current (incomplete) tour.\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n\n    #Calculate sum of values associated to node. \n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                # Penalize connections to nodes with high \"strength\" from all connections\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Normalization using variance across each edges\n    # Standardize each row and column to values between 0 and 1.\n    # To do this, take exponential. Scale exp by deviation from the mean.\n    row_mean = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    row_std = np.std(heuristic_matrix, axis=1, keepdims=True)\n\n    col_mean = np.mean(heuristic_matrix, axis=0, keepdims=True)\n    col_std = np.std(heuristic_matrix, axis=0, keepdims=True)\n\n    # Avoid division by zero standard deviation\n    row_std = np.where(row_std == 0, 1e-6, row_std)\n    col_std = np.where(col_std == 0, 1e-6, col_std)\n    \n    row_normalized = np.exp((heuristic_matrix - row_mean) / row_std)\n    col_normalized = np.exp((heuristic_matrix - col_mean) / col_std)\n    \n    #Scale by product of standard deviations to normalize.\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    #Make sure to set any nan or inf values to a reasonable number.\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n\n\n    return final_heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the top heuristic incorporates inverse distance, node degree penalty, and variance-based normalization, while the worst only uses inverse distance. Comparing (2nd) vs (19th), we see that all heuristics from 1st to 10th have the complete implementation, while from 11th to 20th, they only return inverse distance. Comparing (1st) vs (2nd), (3rd) vs (4th), etc., we see that they are identical, suggesting no performance difference among the top 10. Comparing (11th) vs (20th), they are also identical, implying no performance difference among the bottom 10. Comparing (second worst) vs (worst), we see no difference, as both return 1/distance_matrix. Overall: The best heuristic uses inverse distance, node degree penalty and normalization, while the worst only uses inverse distance.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's redefine \"Current Self-Reflection\" for designing better heuristics, steering clear of ineffective practices:\n\n*   **Keywords:** Comprehensive analysis, robustification, edge-case handling, multi-faceted evaluation.\n*   **Advice:** Actively question initial assumptions. Explore diverse heuristic parameters and combinations. Stress-test heuristics with varied datasets. Quantify improvements systematically.\n*   **Avoid:** Premature optimization on limited datasets. Over-reliance on intuition without empirical validation. Ignoring potential failure modes or boundary conditions.\n*   **Explanation:** Current self-reflection should involve broad exploration, rigorous testing, and awareness of limitations, ensuring robustness across diverse scenarios.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}