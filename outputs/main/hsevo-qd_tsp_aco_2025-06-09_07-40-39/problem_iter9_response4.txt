```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Combines inverse distance, node popularity, and a novel cycle-breaking mechanism.
    Further sparsifies edges and normalizes using robust statistics.
    """
    zero_replacement_value = 1e-9
    std_replacement_value = 1e-6
    nan_replacement_value = 0.0
    sharpening_factor = 1.3  # Increased sparsification
    popularity_exponent = 0.5
    cycle_breaker_factor = 0.7  # Adjust to balance cycle breaking

    # Avoid division by zero
    distance_matrix = np.where(distance_matrix == 0, zero_replacement_value, distance_matrix)

    # 1. Inverse distance
    heuristic_matrix = 1 / distance_matrix

    # 2. Node Popularity (combination of degree and inverse distance)
    node_degree = np.sum(heuristic_matrix, axis=0)
    node_inverse_distance_sum = np.sum(1 / distance_matrix, axis=0)
    node_popularity = (node_degree * node_inverse_distance_sum)**popularity_exponent

    num_nodes = distance_matrix.shape[0]
    popularity_matrix = np.zeros_like(distance_matrix)
    for i in range(num_nodes):
        for j in range(num_nodes):
            if i != j:
                popularity_matrix[i, j] = node_popularity[i] + node_popularity[j]

    heuristic_matrix = heuristic_matrix * popularity_matrix

    # 3. Cycle Breaking (penalize edges between nodes with many common neighbors)
    cycle_breaker = np.zeros_like(distance_matrix)
    for i in range(num_nodes):
        for j in range(num_nodes):
            if i != j:
                common_neighbors = np.sum((distance_matrix[i, :] > 0) & (distance_matrix[j, :] > 0))
                cycle_breaker[i, j] = 1 / (1 + common_neighbors) ** cycle_breaker_factor # Adjusted to range from 0 to 1

    heuristic_matrix = heuristic_matrix * cycle_breaker

    # 4. Sparsification and Edge Sharpening
    node_mean_heuristic = np.mean(heuristic_matrix, axis=1, keepdims=True)
    sharpened_heuristic = np.where(heuristic_matrix > sharpening_factor * node_mean_heuristic,
                                  heuristic_matrix,
                                  0.0)  # Sparsify more aggressively

    # 5. Robust Normalization (using median and IQR)
    q1 = np.percentile(sharpened_heuristic, 25, axis=1, keepdims=True)
    q3 = np.percentile(sharpened_heuristic, 75, axis=1, keepdims=True)
    iqr = q3 - q1
    iqr = np.where(iqr == 0, std_replacement_value, iqr)  # Avoid division by zero

    median = np.median(sharpened_heuristic, axis=1, keepdims=True)
    normalized_heuristic = (sharpened_heuristic - median) / iqr

    q1_col = np.percentile(sharpened_heuristic, 25, axis=0, keepdims=True)
    q3_col = np.percentile(sharpened_heuristic, 75, axis=0, keepdims=True)
    iqr_col = q3_col - q1_col
    iqr_col = np.where(iqr_col == 0, std_replacement_value, iqr_col)  # Avoid division by zero

    median_col = np.median(sharpened_heuristic, axis=0, keepdims=True)
    normalized_heuristic_col = (sharpened_heuristic - median_col) / iqr_col

    final_heuristic_matrix = normalized_heuristic * normalized_heuristic_col
    final_heuristic_matrix = np.exp(final_heuristic_matrix)
    #Zero out diagonals (no self-loops)
    np.fill_diagonal(final_heuristic_matrix, 0)

    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=nan_replacement_value, posinf=nan_replacement_value, neginf=nan_replacement_value)

    return final_heuristic_matrix
```
