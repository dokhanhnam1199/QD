{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\nCurrent heuristics:\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines inverse distance, degree penalty, and variance normalization.\n    Sparsifies edges to enhance promisingness.\n    \"\"\"\n    zero_replacement_value = 1e-9\n    std_replacement_value = 1e-6\n    nan_replacement_value = 0.0\n    sharpening_factor = 1.2\n    zero_replacement = 1e-9\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, zero_replacement_value, distance_matrix)\n\n    # 1. Inverse distance\n    heuristic_matrix = 1 / distance_matrix\n\n    # 2. Node degree penalty\n    num_nodes = distance_matrix.shape[0]\n    degree_penalty = np.zeros_like(distance_matrix)\n    node_strengths = np.sum(heuristic_matrix, axis=0)\n\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                degree_penalty[i, j] = 1 / (node_strengths[i] + node_strengths[j])\n\n    # Combine inverse distance and node degree penalty\n    heuristic_matrix = heuristic_matrix * degree_penalty\n\n    # 3. Sparsification and Edge Sharpening\n    node_mean_heuristic = np.mean(heuristic_matrix, axis=1, keepdims=True)\n    sharpened_heuristic = np.where(heuristic_matrix > sharpening_factor * node_mean_heuristic,\n                                  heuristic_matrix,\n                                  0.0)  # Sparsify by setting others to zero\n    # 4. Normalization using variance across each edges\n    row_mean = np.mean(sharpened_heuristic, axis=1, keepdims=True)\n    row_std = np.std(sharpened_heuristic, axis=1, keepdims=True)\n\n    col_mean = np.mean(sharpened_heuristic, axis=0, keepdims=True)\n    col_std = np.std(sharpened_heuristic, axis=0, keepdims=True)\n\n    row_std = np.where(row_std == 0, std_replacement_value, row_std)\n    col_std = np.where(col_std == 0, std_replacement_value, col_std)\n\n    row_normalized = np.exp((sharpened_heuristic - row_mean) / row_std)\n    col_normalized = np.exp((sharpened_heuristic - col_mean) / col_std)\n\n    final_heuristic_matrix = row_normalized * col_normalized\n\n    #Zero out diagonals (no self-loops)\n    np.fill_diagonal(final_heuristic_matrix, 0)\n\n    final_heuristic_matrix = np.nan_to_num(final_heuristic_matrix, nan=nan_replacement_value, posinf=nan_replacement_value, neginf=nan_replacement_value)\n\n    return final_heuristic_matrix\n\nNow, think outside the box write a mutated function `heuristics_v2` better than current version.\nYou can use some hints below:\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine our self-reflection to design better heuristics, aiming for actionable insights:\n\n*   **Keywords:** Iterative refinement, multi-factor integration, robustness, computational efficiency, parameter tuning, search space focusing.\n\n*   **Advice:** Systematically experiment with combining diverse features (distance, degree, etc.). Quantify the impact of each addition on both solution quality and runtime. Explicitly design for edge cases and numerical stability.\n\n*   **Avoid:** Premature optimization, relying solely on intuition, neglecting computational cost analysis.\n\n*   **Explanation:** This approach encourages data-driven design, balancing complexity and efficiency, while ensuring generalizability through parameter tuning and careful consideration of edge cases.\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}