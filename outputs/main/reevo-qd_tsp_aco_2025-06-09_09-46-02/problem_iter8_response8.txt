```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) based on stochastic solution sampling with improvements.

    This function refines the heuristics by incorporating node proximity, edge diversity, and iterative refinement
    to enhance the exploration-exploitation balance in TSP solution sampling.  It builds upon v1 with:
        - More robust handling of degree calculation and thresholds.
        - Enhanced edge clustering based on a weighted Jaccard index.
        - Adaptive noise injection based on sparsity of the heuristic matrix.
        - Reduced reliance on global mean distance, favoring local considerations.

    Args:
        distance_matrix (np.ndarray): A square matrix representing the distances between cities.
                                         distance_matrix[i][j] is the distance between city i and city j.

    Returns:
        np.ndarray: A matrix of the same shape as distance_matrix, where each element represents the
                      promise of including the corresponding edge in the TSP solution.
    """
    n = distance_matrix.shape[0]
    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)

    # 1. Node Proximity (Inverse Distance with Scaling) - Less reliant on global mean
    inverse_distance = 1 / (distance_matrix + 1e-6)
    proximity_factor = np.median(distance_matrix) / (distance_matrix + 1e-6)  # Use median instead of mean
    node_proximity = inverse_distance * proximity_factor

    # 2. Edge Diversity (Penalize High-Degree Nodes) with improved degree calculation
    degree_penalty = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                # Adaptive threshold for degree calculation, use 2nd smallest distance as threshold
                distances_i = np.sort(distance_matrix[i, :])
                threshold_i = distances_i[min(1, len(distances_i) -1)] if len(distances_i) > 1 else distances_i[0] # handle cases with few cities
                distances_j = np.sort(distance_matrix[j, :])
                threshold_j = distances_j[min(1, len(distances_j) - 1)] if len(distances_j) > 1 else distances_j[0]

                degree_i = np.sum(distance_matrix[i, :] < threshold_i)
                degree_j = np.sum(distance_matrix[j, :] < threshold_j)
                degree_penalty[i, j] = 1.0 / (np.sqrt(degree_i * degree_j) + 1e-6)  # Geometric mean

    # 3. Shortest Path Consideration with Adaptive Scaling and dynamic temperature - Local Temperature
    shortest_path_bonus = np.zeros_like(distance_matrix, dtype=float)
    #mean_distance = np.mean(distance_matrix) # was global, using local mean instead
    for i in range(n):
        local_mean = np.mean(distance_matrix[i,:])
        temperature = local_mean / 2.0 if local_mean > 0 else np.mean(distance_matrix) /2.0 #Dynamic temperature
        for j in range(n):
            if i != j:
                shortest_path_bonus[i, j] = np.exp(-distance_matrix[i, j] / temperature)  # Favors shorter edges

    # Combine factors
    heuristics_matrix = node_proximity * degree_penalty * shortest_path_bonus

    # 4. Sparsification (Adaptive Thresholding) - Refined sparsification
    # More aggressive sparsification in early iterations
    threshold = np.percentile(heuristics_matrix[heuristics_matrix > 0], 60)  # remove bottom 60%
    heuristics_matrix[heuristics_matrix < threshold] = 0

    # Adaptive noise injection based on matrix sparsity
    sparsity = np.sum(heuristics_matrix > 0) / heuristics_matrix.size
    noise_level = 0.001 * np.mean(heuristics_matrix[heuristics_matrix > 0]) * (1-sparsity)  # Scale noise based on sparsity
    noise = np.random.normal(0, noise_level, size=heuristics_matrix.shape)
    heuristics_matrix = heuristics_matrix + noise
    heuristics_matrix[heuristics_matrix < 0] = 0  # Ensure no negative values after adding noise
    # 5. Local neighborhood refinement for degree estimation
    for i in range(n):
        for j in range(n):
            if heuristics_matrix[i, j] > 0:
                # Consider only neighbors within a certain distance
                neighborhood_radius = np.median(distance_matrix[i,:]) * 0.70 # was 0.75, reduce for more local
                neighbors_i = np.where(distance_matrix[i, :] < neighborhood_radius)[0]
                neighbors_j = np.where(distance_matrix[j, :] < neighborhood_radius)[0]
                # Recalculate degree penalty based on local neighborhood
                degree_i_local = np.sum(distance_matrix[i, neighbors_i] < threshold_i) if len(neighbors_i) > 0 else 0
                degree_j_local = np.sum(distance_matrix[j, neighbors_j] < threshold_j) if len(neighbors_j) > 0 else 0
                heuristics_matrix[i,j] *= 1.0 / (np.sqrt(degree_i_local * degree_j_local) + 1e-6) if (degree_i_local > 0 and degree_j_local > 0) else 1

    # Additional: Edge Clustering based on Shared Neighbors - Weighted Jaccard
    edge_clustering = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(i + 1, n):  # Only consider upper triangle
            if heuristics_matrix[i, j] > 0:
                # Find shared neighbors of i and j
                neighbors_i = np.where(heuristics_matrix[i, :] > 0)[0]
                neighbors_j = np.where(heuristics_matrix[j, :] > 0)[0]
                shared_neighbors = np.intersect1d(neighbors_i, neighbors_j)

                # Weighted Jaccard Index (using heuristics_matrix as weights)
                weight_sum_i = np.sum(heuristics_matrix[i, neighbors_i])
                weight_sum_j = np.sum(heuristics_matrix[j, neighbors_j])
                weight_sum_shared = 0
                for neighbor in shared_neighbors:
                    weight_sum_shared += min(heuristics_matrix[i, neighbor], heuristics_matrix[j, neighbor]) # Take min of weights

                union_weight = weight_sum_i + weight_sum_j - weight_sum_shared
                jaccard_index = weight_sum_shared / (union_weight + 1e-6) if union_weight > 0 else 0
                edge_clustering[i, j] = jaccard_index

                edge_clustering[j, i] = edge_clustering[i, j] #symmetric matrix
    heuristics_matrix = heuristics_matrix * (1 + 0.3 * edge_clustering)

    return heuristics_matrix
```
