```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) based on stochastic solution sampling with significant improvements.

    This function builds upon heuristics_v1 by incorporating more refined adaptive scaling, localized degree estimation,
    enhanced edge clustering, dynamic noise injection, and a probabilistic edge selection bias to improve exploration,
    exploitation, and overall solution quality in TSP solution sampling.

    Args:
        distance_matrix (np.ndarray): A square matrix representing the distances between cities.
                                         distance_matrix[i][j] is the distance between city i and city j.

    Returns:
        np.ndarray: A matrix of the same shape as distance_matrix, where each element represents the
                      promise of including the corresponding edge in the TSP solution.
    """
    n = distance_matrix.shape[0]
    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)

    # 1. Node Proximity (Inverse Distance with Adaptive Scaling)
    inverse_distance = 1 / (distance_matrix + 1e-6)
    median_distance = np.median(distance_matrix[distance_matrix > 0])
    proximity_factor = median_distance / (distance_matrix + 1e-6)
    node_proximity = inverse_distance * proximity_factor

    # 2. Edge Diversity (Penalize High-Degree Nodes) with localized and adaptive degree calculation
    degree_penalty = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                # Adaptive threshold for degree calculation (average distance to k-nearest neighbors)
                k = min(5, n - 1)  # Consider up to 5 nearest neighbors
                distances_i = np.sort(distance_matrix[i, :])[1:k+1]  # Exclude self and take k nearest
                threshold_i = np.mean(distances_i) if len(distances_i) > 0 else np.inf
                distances_j = np.sort(distance_matrix[j, :])[1:k+1]
                threshold_j = np.mean(distances_j) if len(distances_j) > 0 else np.inf

                # Localized degree calculation within a radius
                neighborhood_radius = median_distance * 1.25  # Adapt radius based on median
                neighbors_i = np.where(distance_matrix[i, :] < neighborhood_radius)[0]
                neighbors_j = np.where(distance_matrix[j, :] < neighborhood_radius)[0]

                degree_i_local = np.sum(distance_matrix[i, neighbors_i] < threshold_i) if len(neighbors_i) > 0 else 0
                degree_j_local = np.sum(distance_matrix[j, neighbors_j] < threshold_j) if len(neighbors_j) > 0 else 0
                degree_penalty[i, j] = 1.0 / (np.sqrt(degree_i_local * degree_j_local) + 1e-6)

    # 3. Shortest Path Consideration with Adaptive Temperature Scaling
    shortest_path_bonus = np.zeros_like(distance_matrix, dtype=float)
    temperature = median_distance / 1.5  # Dynamic temperature based on median
    for i in range(n):
        for j in range(n):
            if i != j:
                shortest_path_bonus[i, j] = np.exp(-distance_matrix[i, j] / temperature)

    # Combine factors
    heuristics_matrix = node_proximity * degree_penalty * shortest_path_bonus

    # 4. Sparsification (Adaptive Thresholding with Dynamic Adjustment)
    sparsification_percentile = 70  # Start with higher sparsification
    threshold = np.percentile(heuristics_matrix[heuristics_matrix > 0], sparsification_percentile)
    heuristics_matrix[heuristics_matrix < threshold] = 0

    # 5. Dynamic Noise Injection with Probabilistic Edge Selection Bias
    positive_heuristics = heuristics_matrix[heuristics_matrix > 0]
    if positive_heuristics.size > 0:
        noise_level = 0.001 * np.mean(positive_heuristics)  # Reduce noise further
    else:
        noise_level = 0.0001
    noise = np.random.normal(0, noise_level, size=heuristics_matrix.shape)
    heuristics_matrix = heuristics_matrix + noise
    heuristics_matrix[heuristics_matrix < 0] = 0

    # Probabilistic Edge Selection Bias
    for i in range(n):
        for j in range(n):
            if heuristics_matrix[i, j] > 0:
                # Bias towards shorter edges, but allow some longer ones with lower probability
                probability = np.exp(-distance_matrix[i, j] / median_distance)  # Prob based on scaled distance
                if np.random.rand() > probability:  #Flip if random number is greater than prob
                    heuristics_matrix[i, j] *= 0.75  # Reduce the value probabilistically

    # 6. Enhanced Edge Clustering Based on Shared Neighbors and Connection Strength
    edge_clustering = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(i + 1, n):
            if heuristics_matrix[i, j] > 0:
                neighbors_i = np.where(heuristics_matrix[i, :] > 0)[0]
                neighbors_j = np.where(heuristics_matrix[j, :] > 0)[0]
                shared_neighbors = np.intersect1d(neighbors_i, neighbors_j)
                # Weighted Jaccard index using heuristic values as weights
                weight_sum_i = np.sum(heuristics_matrix[i, neighbors_i])
                weight_sum_j = np.sum(heuristics_matrix[j, neighbors_j])
                weight_sum_shared = 0
                for neighbor in shared_neighbors:
                    weight_sum_shared += min(heuristics_matrix[i,neighbor], heuristics_matrix[j,neighbor]) #Take minimum edge strength
                jaccard_index = weight_sum_shared / (weight_sum_i + weight_sum_j - weight_sum_shared + 1e-6)
                edge_clustering[i, j] = jaccard_index
                edge_clustering[j, i] = edge_clustering[i, j]
    heuristics_matrix = heuristics_matrix * (1 + 0.3 * edge_clustering)  # Increase edge clustering effect

    return heuristics_matrix
```
