```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) based on stochastic solution sampling.

    This function combines multiple factors to determine the promise of including each edge in a solution.
    It considers:
        1. Inverse distance: Shorter distances are preferred.
        2. Node degree: Edges connected to nodes with fewer connections are favored (encourages exploration).
        3. Global shortest path consideration: An approximation of whether the edge lies on several shortest paths.
        4. Sparsification: Sets less promising edges to zero.
        5. Normalization: Normalize different heurisitcs to the same scale.

    Args:
        distance_matrix (np.ndarray): A square matrix representing the distances between cities.
                                         distance_matrix[i][j] is the distance between city i and city j.

    Returns:
        np.ndarray: A matrix of the same shape as distance_matrix, where each element represents the
                      promise of including the corresponding edge in the TSP solution.
    """
    n = distance_matrix.shape[0]
    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)

    # 1. Inverse distance (basic desirability)
    inverse_distance = 1 / (distance_matrix + 1e-6)  # Adding a small constant to avoid division by zero
    inverse_distance = inverse_distance / np.max(inverse_distance)


    # 2. Node degree (encourage exploration from sparsely connected nodes)
    degree_penalty = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                degree_i = np.sum(distance_matrix[i, :] > 0)  #number of adjacent nodes for node i.
                degree_j = np.sum(distance_matrix[j, :] > 0)  #number of adjacent nodes for node j.
                degree_penalty[i, j] = 1.0 / (degree_i * degree_j + 1e-6)
    degree_penalty = degree_penalty / np.max(degree_penalty)


    # 3. Shortest Path Consideration
    shortest_path_bonus = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                # Approximate shortest path consideration by using Dijkstra (or Floyd-Warshall for a complete graph)
                # In this case, use a basic heuristic.

                shortest_path_bonus[i, j] = np.exp(-distance_matrix[i,j]/np.mean(distance_matrix))  # Favors edges with shorter distances
    shortest_path_bonus = shortest_path_bonus / np.max(shortest_path_bonus)


    # Combine the factors
    heuristics_matrix = inverse_distance * degree_penalty * shortest_path_bonus

    # 4. Sparsification (set less promising edges to zero)
    threshold = np.percentile(heuristics_matrix[heuristics_matrix > 0], 25) # remove 25% lowest scored edges
    heuristics_matrix[heuristics_matrix < threshold] = 0

    return heuristics_matrix
```
