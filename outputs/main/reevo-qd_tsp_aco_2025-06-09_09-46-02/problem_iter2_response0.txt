```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for the Traveling Salesman Problem (TSP) based on stochastic solution sampling.

    This function combines multiple factors to determine the promise of including each edge in a solution.
    It considers:
        1. Inverse distance: Shorter distances are preferred.
        2. Node degree: Edges connected to nodes with fewer connections are favored (encourages exploration).
        3. Global shortest path consideration: An approximation of whether the edge lies on several shortest paths,
           using a more refined calculation involving intermediate nodes.
        4. Sparsification: Sets less promising edges to zero based on a dynamically adjusted threshold.
        5. Adaptive Weighting: Adjusts the influence of each factor based on problem characteristics.

    Args:
        distance_matrix (np.ndarray): A square matrix representing the distances between cities.
                                         distance_matrix[i][j] is the distance between city i and city j.

    Returns:
        np.ndarray: A matrix of the same shape as distance_matrix, where each element represents the
                      promise of including the corresponding edge in the TSP solution.
    """
    n = distance_matrix.shape[0]
    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)

    # 1. Inverse distance (basic desirability)
    inverse_distance = 1 / (distance_matrix + 1e-6)  # Adding a small constant to avoid division by zero

    # 2. Node degree (encourage exploration from sparsely connected nodes)
    degree_penalty = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                degree_i = np.sum(distance_matrix[i, :] > 0)  #number of adjacent nodes for node i.
                degree_j = np.sum(distance_matrix[j, :] > 0)  #number of adjacent nodes for node j.
                degree_penalty[i, j] = 1.0 / (degree_i * degree_j + 1e-6)

    # 3. Shortest Path Consideration (Refined)
    shortest_path_bonus = np.zeros_like(distance_matrix, dtype=float)
    for i in range(n):
        for j in range(n):
            if i != j:
                # Check for shorter paths via intermediate nodes
                shortest_path = distance_matrix[i, j]
                for k in range(n):
                    if k != i and k != j:
                        potential_path = distance_matrix[i, k] + distance_matrix[k, j]
                        shortest_path = min(shortest_path, potential_path)

                shortest_path_bonus[i, j] = np.exp(-distance_matrix[i,j]/shortest_path) if shortest_path > 0 else 0 # Favors edges that contribute to shorter paths


    # 4. Adaptive Weighting (adjust influence of factors based on problem characteristics)
    avg_distance = np.mean(distance_matrix[distance_matrix > 0])  #avoid using zero distance
    distance_importance = np.exp(-avg_distance / (np.std(distance_matrix[distance_matrix > 0]) + 1e-6))  # Higher std => Less important direct distance

    degree_importance = 1.0 - distance_importance  # Inverse relationship


    # Combine the factors with adaptive weights
    heuristics_matrix = (distance_importance * inverse_distance +
                         degree_importance * degree_penalty) * shortest_path_bonus

    # 5. Sparsification (set less promising edges to zero)
    threshold = np.percentile(heuristics_matrix[heuristics_matrix > 0], 30)  # Adjust percentile dynamically to control sparsity
    heuristics_matrix[heuristics_matrix < threshold] = 0

    return heuristics_matrix
```
