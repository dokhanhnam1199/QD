{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, utilization, and close fit for bin selection.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) + 1e-9\n    waste = bins_remain_cap - item\n    \n    priorities[waste < 0] = -np.inf\n\n    valid_bins = waste >= 0\n    priorities[valid_bins] = 1.0 / (waste[valid_bins] + 1e-9)\n    \n    utilization = 1.0 - bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else np.zeros_like(bins_remain_cap)\n\n    priorities[valid_bins] *= (1 + utilization[valid_bins])\n\n    close_fit_threshold = 0.1 * item\n    close_fit = (waste >= 0) & (waste <= close_fit_threshold)\n    priorities[close_fit] += 10\n\n    # Add a penalty for bins that are becoming too full, but only if the item fits\n    almost_full_threshold = 0.9\n    almost_full = (bins_remain_cap / np.max(bins_remain_cap) < (1-almost_full_threshold)) & (waste >=0)\n    priorities[almost_full] *= 0.5 # Reduce priority if bin is almost full\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins based on a combination of factors:\n    - Closeness of item size to remaining capacity.\n    - Remaining capacity relative to the item size.\n    - A \"best fit\" bonus.\n    - A penalty for bins significantly larger than the item.\n    - A small random factor to break ties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bins_remain_cap = np.array(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n\n    if np.any(valid_bins):\n        valid_remain_cap = bins_remain_cap[valid_bins]\n\n        # Closeness factor: Favor bins with remaining capacity close to the item size.\n        closeness = np.exp(-np.abs(valid_remain_cap - item) / (0.1 * item + 1e-9))  # Scale by item to be relative\n        # Capacity factor: Favor bins with enough capacity, penalize bins that are much larger.\n        capacity_ratio = item / valid_remain_cap\n        capacity_factor = np.clip(capacity_ratio, 0, 1) # changed from previous valid_remain_cap / np.max(valid_remain_cap)\n\n        # \"Best fit\" bonus: If the item fits perfectly or almost perfectly, give a significant bonus.\n        best_fit_threshold = 0.05 * item  # Define what \"almost perfect\" means\n        best_fit_bonus = np.where(np.abs(valid_remain_cap - item) <= best_fit_threshold, 2.0, 1.0)\n\n        # Large bin penalty: Penalize bins that are much larger than the item.\n        large_bin_penalty = np.where(valid_remain_cap > 2.5 * item, 0.6, 1.0) # modified penalty & thresh\n\n        # Combine factors\n        priorities[valid_bins] = closeness * capacity_factor * best_fit_bonus * large_bin_penalty\n\n        # Small random factor to break ties.\n        priorities[valid_bins] += np.random.rand(len(valid_remain_cap)) * 0.001\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), the first uses simpler calculations for waste, capacity, and fit, while the 20th uses a best-fit bonus, large bin penalty, and capacity factor. The 1st includes a small boost and a large negative value for infeasible bins, while 20th normalizes priorities.\n\nComparing (2nd) vs (3rd), the 2nd is a more parameterized version with weights and exponent, while the 3rd version focuses on utilization and close fit, adding a penalty for almost full bins.\n\nComparing (3rd) vs (4th), the 3rd version combines waste minimization, utilization, and close fit, while the 4th version uses best-fit, fullness bonus, and infeasibility handling. The 4th version uses sigmoid for bonus, while the 3rd version uses direct penalties and rewards.\n\nComparing (4th) vs (5th), the 4th emphasizes fullness bonus and infeasibility, whereas the 5th prioritizes fill ratio and fragmentation avoidance, with penalties for nearly full bins.\n\nComparing (2nd worst) vs (worst), both are similar with the same functionality. This indicates potential redundancy or the heuristic is not improving.\n\nComparing (1st) vs (2nd), the first uses hardcoded weights, and the second is parameterized, suggesting the first is a simplified version.\n\nOverall: the best heuristics tend to be simpler and more direct in their approach, while the worst are either redundant or introduce complex calculations that don't necessarily improve performance. Good heuristics balance several factors (fit, capacity, fragmentation), handle infeasible bins appropriately, and avoid overly complex calculations that add noise.\n- \nOkay, let's refine \"Current self-reflection\" to be more effective for heuristic design, steering clear of the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a revised perspective:\n\n*   **Keywords:** Parsimony, Evidence-based, Core Factors, Adaptive Complexity.\n*   **Advice:** Begin with a minimal viable heuristic, focusing on essential factors. Rigorously test and validate each added layer of complexity based on performance gains.\n*   **Avoid:** Premature optimization, complex scoring functions without justification, and parameter proliferation without empirical evidence.\n*   **Explanation:** Prioritize creating a simple, understandable baseline. Only introduce complexity or parameterization if it demonstrably and significantly improves performance, avoiding unnecessary computational overhead. Focus on *why* additional factors are needed.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}