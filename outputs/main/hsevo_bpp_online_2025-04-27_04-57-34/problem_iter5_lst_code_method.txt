{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities considering waste, capacity, and fit.\"\"\"\n\n    eligible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(eligible_bins):\n        waste = bins_remain_cap - item\n        waste[~eligible_bins] = np.inf\n        priorities[eligible_bins] = -np.abs(waste[eligible_bins])\n\n        priorities[eligible_bins] += bins_remain_cap[eligible_bins] / np.max(bins_remain_cap)\n        \n        fit_ratios = item / bins_remain_cap\n        scaled_fit = (1 - np.clip(fit_ratios, 0, 1)) ** (1/3)\n        priorities[eligible_bins] += scaled_fit[eligible_bins]\n        \n        priorities[eligible_bins] += 0.001\n\n    else:\n        priorities[:] = -1e9\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, waste_penalty_weight: float = 1.4337767566018633, capacity_reward_weight: float = 0.6351441211300948, fit_reward_weight: float = 0.6148956244348253, fit_exponent: float = 0.376774087268522, min_priority_boost: float = 0.0011171410227250645, ineligible_priority: float = -3580892971.4245377) -> np.ndarray:\n    \"\"\"Calculate bin priorities considering waste, capacity, and fit.\"\"\"\n\n    eligible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(eligible_bins):\n        waste = bins_remain_cap - item\n        waste[~eligible_bins] = np.inf\n        priorities[eligible_bins] = -waste_penalty_weight * np.abs(waste[eligible_bins])\n\n        priorities[eligible_bins] += capacity_reward_weight * bins_remain_cap[eligible_bins] / np.max(bins_remain_cap)\n        \n        fit_ratios = item / bins_remain_cap\n        scaled_fit = (1 - np.clip(fit_ratios, 0, 1)) ** fit_exponent\n        priorities[eligible_bins] += fit_reward_weight * scaled_fit[eligible_bins]\n        \n        priorities[eligible_bins] += min_priority_boost\n\n    else:\n        priorities[:] = ineligible_priority\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, utilization, and close fit for bin selection.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) + 1e-9\n    waste = bins_remain_cap - item\n    \n    priorities[waste < 0] = -np.inf\n\n    valid_bins = waste >= 0\n    priorities[valid_bins] = 1.0 / (waste[valid_bins] + 1e-9)\n    \n    utilization = 1.0 - bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else np.zeros_like(bins_remain_cap)\n\n    priorities[valid_bins] *= (1 + utilization[valid_bins])\n\n    close_fit_threshold = 0.1 * item\n    close_fit = (waste >= 0) & (waste <= close_fit_threshold)\n    priorities[close_fit] += 10\n\n    # Add a penalty for bins that are becoming too full, but only if the item fits\n    almost_full_threshold = 0.9\n    almost_full = (bins_remain_cap / np.max(bins_remain_cap) < (1-almost_full_threshold)) & (waste >=0)\n    priorities[almost_full] *= 0.5 # Reduce priority if bin is almost full\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fullness bonus, and infeasibility handling for bin selection.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    feasible_mask = ~infeasible_mask\n    if not np.any(feasible_mask):\n        return priorities\n\n    remaining_capacities_after_fit = bins_remain_cap[feasible_mask] - item\n    space_score = -np.abs(remaining_capacities_after_fit)\n\n    bins_used_ratio = (bins_remain_cap.max() - bins_remain_cap[feasible_mask]) / bins_remain_cap.max()\n    bonus = 1 / (1 + np.exp(-10 * (bins_used_ratio - 0.7)))\n\n    priorities[feasible_mask] = space_score + bonus\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Assigns bin priorities considering fit, fill ratio, and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n\n    if np.any(fits):\n        remaining_space = bins_remain_cap[fits] - item\n        priorities[fits] = (item / bins_remain_cap[fits]) + (1 / (1 + remaining_space))\n        nearly_full = remaining_space < 0.1\n        priorities[fits][nearly_full] *= 0.9\n    else:\n        priorities = -bins_remain_cap\n        priorities = priorities - np.min(priorities) + 1e-9\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Assigns bin priorities considering fit, fill ratio, and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n\n    if np.any(fits):\n        remaining_space = bins_remain_cap[fits] - item\n        priorities[fits] = (item / bins_remain_cap[fits]) + (1 / (1 + remaining_space))\n        nearly_full = remaining_space < 0.1\n        priorities[fits][nearly_full] *= 0.9\n    else:\n        priorities = -bins_remain_cap\n        priorities = priorities - np.min(priorities) + 1e-9\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, utilization, and close fit for bin selection.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) + 1e-9\n    waste = bins_remain_cap - item\n    \n    priorities[waste < 0] = -np.inf\n\n    valid_bins = waste >= 0\n    priorities[valid_bins] = 1.0 / (waste[valid_bins] + 1e-9)\n    \n    utilization = 1.0 - bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else np.zeros_like(bins_remain_cap)\n\n    priorities[valid_bins] *= (1 + utilization[valid_bins])\n\n    close_fit_threshold = 0.1 * item\n    close_fit = (waste >= 0) & (waste <= close_fit_threshold)\n    priorities[close_fit] += 10\n\n    # Add a penalty for bins that are becoming too full, but only if the item fits\n    almost_full_threshold = 0.9\n    almost_full = (bins_remain_cap / np.max(bins_remain_cap) < (1-almost_full_threshold)) & (waste >=0)\n    priorities[almost_full] *= 0.5 # Reduce priority if bin is almost full\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Assigns bin priorities considering fit, fill ratio, and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n\n    if np.any(fits):\n        remaining_space = bins_remain_cap[fits] - item\n        priorities[fits] = (item / bins_remain_cap[fits]) + (1 / (1 + remaining_space))\n        nearly_full = remaining_space < 0.1\n        priorities[fits][nearly_full] *= 0.9\n    else:\n        priorities = -bins_remain_cap\n        priorities = priorities - np.min(priorities) + 1e-9\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Assigns bin priorities considering fit, fill ratio, and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n\n    if np.any(fits):\n        remaining_space = bins_remain_cap[fits] - item\n        priorities[fits] = (item / bins_remain_cap[fits]) + (1 / (1 + remaining_space))\n        nearly_full = remaining_space < 0.1\n        priorities[fits][nearly_full] *= 0.9\n    else:\n        priorities = -bins_remain_cap\n        priorities = priorities - np.min(priorities) + 1e-9\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities considering waste, capacity, and fit.\"\"\"\n\n    eligible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(eligible_bins):\n        waste = bins_remain_cap - item\n        waste[~eligible_bins] = np.inf\n        priorities[eligible_bins] = -np.abs(waste[eligible_bins])\n\n        priorities[eligible_bins] += bins_remain_cap[eligible_bins] / np.max(bins_remain_cap)\n        \n        fit_ratios = item / bins_remain_cap\n        scaled_fit = (1 - np.clip(fit_ratios, 0, 1)) ** (1/3)\n        priorities[eligible_bins] += scaled_fit[eligible_bins]\n        \n        priorities[eligible_bins] += 0.001\n\n    else:\n        priorities[:] = -1e9\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, remaining capacity, and fragmentation avoidance.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities\n\n    # Utilization score\n    space_utilization = item / bins_remain_cap[eligible_bins]\n    packing_density_score = space_utilization / (1 + space_utilization**2 + 0.001)\n\n    # Remaining capacity\n    remaining_capacity_after_fit = bins_remain_cap[eligible_bins] - item\n    remaining_capacity_score = np.exp(-remaining_capacity_after_fit)\n\n    # Fragmentation avoidance (penalty for almost full)\n    nearly_full_threshold = 0.1\n    nearly_full_mask = (bins_remain_cap[eligible_bins] > 0) & (bins_remain_cap[eligible_bins] < nearly_full_threshold)\n    fragmentation_penalty = np.zeros_like(packing_density_score)\n    fragmentation_penalty[nearly_full_mask] = -0.5\n\n    priorities[eligible_bins] = packing_density_score + remaining_capacity_score + fragmentation_penalty + np.random.normal(0, 0.01, size=np.sum(eligible_bins))\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, remaining capacity, and fragmentation avoidance.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities\n\n    # Utilization score\n    space_utilization = item / bins_remain_cap[eligible_bins]\n    packing_density_score = space_utilization / (1 + space_utilization**2 + 0.001)\n\n    # Remaining capacity\n    remaining_capacity_after_fit = bins_remain_cap[eligible_bins] - item\n    remaining_capacity_score = np.exp(-remaining_capacity_after_fit)\n\n    # Fragmentation avoidance (penalty for almost full)\n    nearly_full_threshold = 0.1\n    nearly_full_mask = (bins_remain_cap[eligible_bins] > 0) & (bins_remain_cap[eligible_bins] < nearly_full_threshold)\n    fragmentation_penalty = np.zeros_like(packing_density_score)\n    fragmentation_penalty[nearly_full_mask] = -0.5\n\n    priorities[eligible_bins] = packing_density_score + remaining_capacity_score + fragmentation_penalty + np.random.normal(0, 0.01, size=np.sum(eligible_bins))\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins based on a combination of factors:\n    - Closeness of item size to remaining capacity.\n    - Remaining capacity relative to the item size.\n    - A \"best fit\" bonus.\n    - A penalty for bins significantly larger than the item.\n    - A small random factor to break ties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bins_remain_cap = np.array(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n\n    if np.any(valid_bins):\n        valid_remain_cap = bins_remain_cap[valid_bins]\n\n        # Closeness factor: Favor bins with remaining capacity close to the item size.\n        closeness = np.exp(-np.abs(valid_remain_cap - item) / (0.1 * item + 1e-9))  # Scale by item to be relative\n        # Capacity factor: Favor bins with enough capacity, penalize bins that are much larger.\n        capacity_ratio = item / valid_remain_cap\n        capacity_factor = np.clip(capacity_ratio, 0, 1) # changed from previous valid_remain_cap / np.max(valid_remain_cap)\n\n        # \"Best fit\" bonus: If the item fits perfectly or almost perfectly, give a significant bonus.\n        best_fit_threshold = 0.05 * item  # Define what \"almost perfect\" means\n        best_fit_bonus = np.where(np.abs(valid_remain_cap - item) <= best_fit_threshold, 2.0, 1.0)\n\n        # Large bin penalty: Penalize bins that are much larger than the item.\n        large_bin_penalty = np.where(valid_remain_cap > 2.5 * item, 0.6, 1.0) # modified penalty & thresh\n\n        # Combine factors\n        priorities[valid_bins] = closeness * capacity_factor * best_fit_bonus * large_bin_penalty\n\n        # Small random factor to break ties.\n        priorities[valid_bins] += np.random.rand(len(valid_remain_cap)) * 0.001\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins based on a combination of factors:\n    - Closeness of item size to remaining capacity.\n    - Remaining capacity relative to the item size.\n    - A \"best fit\" bonus.\n    - A penalty for bins significantly larger than the item.\n    - A small random factor to break ties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bins_remain_cap = np.array(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n\n    if np.any(valid_bins):\n        valid_remain_cap = bins_remain_cap[valid_bins]\n\n        # Closeness factor: Favor bins with remaining capacity close to the item size.\n        closeness = np.exp(-np.abs(valid_remain_cap - item) / (0.1 * item + 1e-9))  # Scale by item to be relative\n        # Capacity factor: Favor bins with enough capacity, penalize bins that are much larger.\n        capacity_ratio = item / valid_remain_cap\n        capacity_factor = np.clip(capacity_ratio, 0, 1) # changed from previous valid_remain_cap / np.max(valid_remain_cap)\n\n        # \"Best fit\" bonus: If the item fits perfectly or almost perfectly, give a significant bonus.\n        best_fit_threshold = 0.05 * item  # Define what \"almost perfect\" means\n        best_fit_bonus = np.where(np.abs(valid_remain_cap - item) <= best_fit_threshold, 2.0, 1.0)\n\n        # Large bin penalty: Penalize bins that are much larger than the item.\n        large_bin_penalty = np.where(valid_remain_cap > 2.5 * item, 0.6, 1.0) # modified penalty & thresh\n\n        # Combine factors\n        priorities[valid_bins] = closeness * capacity_factor * best_fit_bonus * large_bin_penalty\n\n        # Small random factor to break ties.\n        priorities[valid_bins] += np.random.rand(len(valid_remain_cap)) * 0.001\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of v0 and v1, balancing fit and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get a very low priority\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -1e9\n\n    # Perfect fit gets highest priority\n    perfect_fit = np.isclose(bins_remain_cap, item)\n    priorities[perfect_fit] = 1e9\n\n    # Prioritize bins with smaller remaining space, but avoid near-full\n    feasible_bins = ~infeasible_bins & ~perfect_fit\n    remaining_space = bins_remain_cap[feasible_bins] - item\n    scaled_remaining_space = remaining_space / item\n    priorities[feasible_bins] = 1 / (1 + np.exp(5 - 10*scaled_remaining_space)) - 0.5*np.exp(10*scaled_remaining_space-5)\n\n    # Penalize bins with large leftover space\n    large_leftover = (bins_remain_cap > item) & (bins_remain_cap - item > np.mean(bins_remain_cap))\n    priorities[large_leftover] = -50\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of v0 and v1, balancing fit and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get a very low priority\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -1e9\n\n    # Perfect fit gets highest priority\n    perfect_fit = np.isclose(bins_remain_cap, item)\n    priorities[perfect_fit] = 1e9\n\n    # Prioritize bins with smaller remaining space, but avoid near-full\n    feasible_bins = ~infeasible_bins & ~perfect_fit\n    remaining_space = bins_remain_cap[feasible_bins] - item\n    scaled_remaining_space = remaining_space / item\n    priorities[feasible_bins] = 1 / (1 + np.exp(5 - 10*scaled_remaining_space)) - 0.5*np.exp(10*scaled_remaining_space-5)\n\n    # Penalize bins with large leftover space\n    large_leftover = (bins_remain_cap > item) & (bins_remain_cap - item > np.mean(bins_remain_cap))\n    priorities[large_leftover] = -50\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best aspects of v0 and v1, balancing fit and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get a very low priority\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -1e9\n\n    # Perfect fit gets highest priority\n    perfect_fit = np.isclose(bins_remain_cap, item)\n    priorities[perfect_fit] = 1e9\n\n    # Prioritize bins with smaller remaining space, but avoid near-full\n    feasible_bins = ~infeasible_bins & ~perfect_fit\n    remaining_space = bins_remain_cap[feasible_bins] - item\n    scaled_remaining_space = remaining_space / item\n    priorities[feasible_bins] = 1 / (1 + np.exp(5 - 10*scaled_remaining_space)) - 0.5*np.exp(10*scaled_remaining_space-5)\n\n    # Penalize bins with large leftover space\n    large_leftover = (bins_remain_cap > item) & (bins_remain_cap - item > np.mean(bins_remain_cap))\n    priorities[large_leftover] = -50\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version refines the priority calculation by:\n    1. Adding a \"best fit\" bonus to prioritize bins that closely match the item size.\n    2. Introducing a penalty for bins that are significantly larger than the item,\n       but making this penalty adaptive to the item size.\n    3. Incorporating a small random factor to encourage exploration and break ties.\n    4. Handles edge cases with very small remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bins_remain_cap = np.array(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    valid_remain_cap = bins_remain_cap[valid_bins]\n\n    # 1. Best Fit Bonus: Prioritize bins with capacity close to item size.\n    # Smaller absolute difference gets a higher bonus.\n    best_fit_bonus = np.exp(-np.abs(valid_remain_cap - item) / (0.1 * item + 1e-6))  # Added small constant to avoid division by zero\n\n    # 2. Large Bin Penalty: Penalize bins that are much larger than the item.\n    # The penalty is scaled relative to the item size.\n    large_bin_threshold = 1.5 * item  # Example: Penalize bins > 1.5x item size\n    large_bin_penalty = np.where(valid_remain_cap > large_bin_threshold,\n                                 0.5 * (1 - np.exp(-(valid_remain_cap - large_bin_threshold) / (0.5 * item + 1e-6))), # added small constant to denominator\n                                 1.0)\n\n    # 3. Capacity Factor: Favor bins with higher (but not too high) remaining capacity.\n    capacity_factor = valid_remain_cap / np.max(valid_remain_cap)\n\n\n    # 4. Small Random Factor: Break ties and encourage exploration.\n    random_factor = 0.01 * np.random.rand(len(valid_remain_cap))\n\n    # Combine all factors:\n    priorities[valid_bins] = best_fit_bonus * large_bin_penalty * capacity_factor + random_factor\n\n    # Normalize priorities to be between 0 and 1 (optional, but can be helpful)\n    if np.sum(priorities) > 0 :\n        priorities = priorities / np.max(priorities)\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version refines the priority calculation by:\n    1. Adding a \"best fit\" bonus to prioritize bins that closely match the item size.\n    2. Introducing a penalty for bins that are significantly larger than the item,\n       but making this penalty adaptive to the item size.\n    3. Incorporating a small random factor to encourage exploration and break ties.\n    4. Handles edge cases with very small remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bins_remain_cap = np.array(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    valid_remain_cap = bins_remain_cap[valid_bins]\n\n    # 1. Best Fit Bonus: Prioritize bins with capacity close to item size.\n    # Smaller absolute difference gets a higher bonus.\n    best_fit_bonus = np.exp(-np.abs(valid_remain_cap - item) / (0.1 * item + 1e-6))  # Added small constant to avoid division by zero\n\n    # 2. Large Bin Penalty: Penalize bins that are much larger than the item.\n    # The penalty is scaled relative to the item size.\n    large_bin_threshold = 1.5 * item  # Example: Penalize bins > 1.5x item size\n    large_bin_penalty = np.where(valid_remain_cap > large_bin_threshold,\n                                 0.5 * (1 - np.exp(-(valid_remain_cap - large_bin_threshold) / (0.5 * item + 1e-6))), # added small constant to denominator\n                                 1.0)\n\n    # 3. Capacity Factor: Favor bins with higher (but not too high) remaining capacity.\n    capacity_factor = valid_remain_cap / np.max(valid_remain_cap)\n\n\n    # 4. Small Random Factor: Break ties and encourage exploration.\n    random_factor = 0.01 * np.random.rand(len(valid_remain_cap))\n\n    # Combine all factors:\n    priorities[valid_bins] = best_fit_bonus * large_bin_penalty * capacity_factor + random_factor\n\n    # Normalize priorities to be between 0 and 1 (optional, but can be helpful)\n    if np.sum(priorities) > 0 :\n        priorities = priorities / np.max(priorities)\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version refines the priority calculation by:\n    1. Adding a \"best fit\" bonus to prioritize bins that closely match the item size.\n    2. Introducing a penalty for bins that are significantly larger than the item,\n       but making this penalty adaptive to the item size.\n    3. Incorporating a small random factor to encourage exploration and break ties.\n    4. Handles edge cases with very small remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    bins_remain_cap = np.array(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    valid_bins = bins_remain_cap > 0\n    if not np.any(valid_bins):\n        return priorities\n\n    valid_remain_cap = bins_remain_cap[valid_bins]\n\n    # 1. Best Fit Bonus: Prioritize bins with capacity close to item size.\n    # Smaller absolute difference gets a higher bonus.\n    best_fit_bonus = np.exp(-np.abs(valid_remain_cap - item) / (0.1 * item + 1e-6))  # Added small constant to avoid division by zero\n\n    # 2. Large Bin Penalty: Penalize bins that are much larger than the item.\n    # The penalty is scaled relative to the item size.\n    large_bin_threshold = 1.5 * item  # Example: Penalize bins > 1.5x item size\n    large_bin_penalty = np.where(valid_remain_cap > large_bin_threshold,\n                                 0.5 * (1 - np.exp(-(valid_remain_cap - large_bin_threshold) / (0.5 * item + 1e-6))), # added small constant to denominator\n                                 1.0)\n\n    # 3. Capacity Factor: Favor bins with higher (but not too high) remaining capacity.\n    capacity_factor = valid_remain_cap / np.max(valid_remain_cap)\n\n\n    # 4. Small Random Factor: Break ties and encourage exploration.\n    random_factor = 0.01 * np.random.rand(len(valid_remain_cap))\n\n    # Combine all factors:\n    priorities[valid_bins] = best_fit_bonus * large_bin_penalty * capacity_factor + random_factor\n\n    # Normalize priorities to be between 0 and 1 (optional, but can be helpful)\n    if np.sum(priorities) > 0 :\n        priorities = priorities / np.max(priorities)\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}