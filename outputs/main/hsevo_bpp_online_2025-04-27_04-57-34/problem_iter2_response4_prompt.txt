{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by the cosmos, where larger bodies attract smaller ones. This heuristic\n    prioritizes bins that can accommodate the item with minimal remaining space (gravity)\n    while also discouraging fragmentation of nearly full bins (stellar wind).\n    Further considerations include a probabilistic element (quantum uncertainty) to allow\n    for exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Ensure capacities are positive.\n    bins_remain_cap = np.maximum(bins_remain_cap, 0)\n\n    # Initialize priorities with a base score of zero.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item.\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        # No bin can fit the item. Assign a small, random priority to all bins.\n        priorities = np.random.rand(len(bins_remain_cap)) * 0.0001\n        return priorities\n    # Gravity: Higher priority for bins with smaller remaining space AFTER packing, IF they can contain item.\n    remaining_after_pack = bins_remain_cap - item\n    remaining_after_pack[remaining_after_pack < 0] = np.inf #make very undesirable\n    priorities[fit_mask] += np.max(bins_remain_cap) / (remaining_after_pack[fit_mask] + 0.0001) #Add a small epsilon to avoid divide by zero.\n    # Stellar Wind: Discourage placing the item in nearly full bins to avoid creating tiny fragments.\n    nearly_full_threshold = 0.1 #consider bins with <10% capacity almost full\n    nearly_full_mask = (bins_remain_cap > 0) & (bins_remain_cap < nearly_full_threshold)\n    priorities[nearly_full_mask] -= np.max(bins_remain_cap) * 0.5 # Reduce Priority significantly\n\n    # Quantum Uncertainty: Introduce a small degree of randomness for exploration.\n    priorities[fit_mask] += np.random.rand(np.sum(fit_mask)) * np.std(priorities[fit_mask]) * 0.01\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Consider only bins that can accommodate the item.\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # No bin can fit the item. Give minimum priority to all existing bins to signal a new bin is needed.\n        return priorities\n\n    # Calculate space utilization: how much of the bin will be filled if the item is added.\n    space_utilization = item / bins_remain_cap[eligible_bins]\n\n    # Encourage tighter packing by prioritizing bins with higher utilization. However, we don't want it to\n    # always choose the absolute tightest pack, as that can be greedy. So we introduce a non-linear term.\n    # A small value such as 0.001 is added to aviod numerical unstability when the bin is exactly same size as the item.\n    packing_density_score = space_utilization / (1 + space_utilization**2 + 0.001)  # Non-linear to avoid being *too* greedy.\n\n    # Consider the remaining capacity *after* the item is added. Bins with lower *remaining* capacity\n    # should be preferred to avoid leaving large, unusable gaps. Introduce noise to escape local optima.\n    remaining_capacity_after_fit = bins_remain_cap[eligible_bins] - item\n    remaining_capacity_score = np.exp(-remaining_capacity_after_fit)  # Exponential decay\n\n    # Combine the two scores, with some added randomness.\n    priorities[eligible_bins] = packing_density_score + remaining_capacity_score + np.random.normal(0, 0.01, size=np.sum(eligible_bins)) # Introduce some randomness\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic uses a combination of fill ratio, perfect fit, and fragmentation avoidance, while the worst only considers fill ratio and perfect fit. (2nd best) vs (second worst), the heuristic emphasizes waste minimization and remaining capacity scaling, whereas its counterpart focuses solely on space usage and original fullness. Comparing (1st) vs (2nd), we see that the best heuristic explicitly calculates priorities for each bin using a for loop to apply conditions, while the second best leverages numpy vectorization for eligible bins and waste calculation. (3rd) vs (4th), the third heuristic incorporates bin utilization and close fit bonuses, while the fourth focuses on fill ratio and tightness, with a penalty for near-full bins. Comparing (second worst) vs (worst), we see that they are identical copies. Overall: The better heuristics combine multiple factors (waste, utilization, fragmentation) and use numpy efficiently. They often include bonuses/penalties to fine-tune the selection process and avoid extremes (overfilling, leaving large gaps).\n- \nOkay, let's redefine \"Current self-reflection\" for better heuristic design, actively avoiding common pitfalls.\n\nHere's a refined approach:\n\n*   **Keywords:** Iterative refinement, multi-objective, computational cost, edge-case mitigation.\n\n*   **Advice:** Structure self-reflection around iterative refinement. Evaluate computational cost and trade-offs when combining factors. Design penalties/bonuses based on *data-driven* edge-case analysis, not intuition alone.\n\n*   **Avoid:** Premature optimization, relying solely on intuition, neglecting computational cost analysis during iterative stages.\n\n*   **Explanation:** Refine heuristics iteratively by tracking performance metrics (e.g., solution quality, runtime). A good approach involves a tight feedback loop: (1) design, (2) implement, (3) test, (4) analyze, (5) refine.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}