```python
import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                waste_penalty_factor: float = 0.8575834075161552,
                bin_fraction_penalty: float = 0.4693634879473551,
                item_size_weight: float = 2.0884148461764993,
                random_perturbation_scale: float = 0.06717097613120268,
                capacity_usage_factor: float = 1.5,
                large_item_threshold: float = 0.7,
                waste_threshold: float = 0.1) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.
    Employs a combination of heuristics with adaptive and interaction considerations:

        1.  Waste Minimization: Prioritizes bins where the remaining space after
            packing the item is minimal.  A near-perfect fit is highly valued.
        2.  Capacity Threshold: Avoids bins with extremely small remaining
            capacity to reduce fragmentation. Bins that cannot fit are penalized.
        3.  Bin Level Awareness : Considers the initial capacity of the bins for a
            more balanced distribution
        4.  Balancing Bin Utilization:  Slight preference for bins that are not
            completely empty or completely full to maintain flexibility.
        5.  Random Perturbation: Introduces small randomness to avoid getting stuck
            in local optima and explore slightly different packing arrangements.
        6.  Item size awareness : Larger Items should fill bins as much as possible
        7. Capacity Usage: More emphasis on using bins with higher capacity
        8. Interaction effects between waste and item size.
        9. Adaptive Scaling based on Item Size: Dynamically scales the influence of
            different factors based on whether the item is considered "large" or not.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.
        waste_penalty_factor: Factor to adjust the impact of waste minimization.
        bin_fraction_penalty: Factor to adjust the balancing of bin utilization.
        item_size_weight: Weight of item size awareness.
        random_perturbation_scale: Scale of random noise.
        capacity_usage_factor: weight to original capacity.
        large_item_threshold: threshold to determine if item is considered large.
        waste_threshold: threshold to determine if waste is significant.
    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    original_capacity = np.max(bins_remain_cap)

    # Waste Minimization & Capacity Threshold
    waste = bins_remain_cap - item
    too_small = waste < 0
    priorities[too_small] = -np.inf  # Never put item in bins that are too small.
    waste[too_small] = np.inf

    # Near-perfect fit bonus (minimize waste)
    priorities += waste_penalty_factor * np.exp(-waste)  # Exponential decay for increasing waste.

    # Bin utilization balancing - slightly prefers bins that aren't empty or full.  avoids extremities.  Parabolic preference
    bin_fraction = bins_remain_cap / original_capacity
    priorities += bin_fraction_penalty * -(bin_fraction - 0.5)**2  # Adds a parabolic preference curve.

    # Item Size Awareness.  Larger items fill bins up
    priorities += item_size_weight * item / original_capacity
    
    # Capacity Usage: Preferentially use bins with higher remaining capacity
    priorities += capacity_usage_factor * bins_remain_cap/original_capacity

    # Interaction effects: If waste is small and item is large, prioritize more
    is_large_item = item > large_item_threshold * original_capacity
    is_small_waste = waste < waste_threshold * original_capacity
    
    if is_large_item:
      priorities += 2*waste_penalty_factor * np.exp(-waste)
    
    # Adaptive Scaling: Adjust weights based on item size
    if is_large_item:
        # For large items, emphasize packing efficiency and capacity usage
        waste_penalty_factor *= 1.2  # Increase importance of minimizing waste
        capacity_usage_factor *= 1.1  # Slight increase in using available space
        bin_fraction_penalty *= 0.8  # Reduce importance of bin balancing
    else:
        # For smaller items, emphasize bin balancing and waste
        bin_fraction_penalty *= 1.2
        waste_penalty_factor *= 0.9
        capacity_usage_factor *= 0.9

    # Random Perturbation (introduces some "quantum" fluctuation). Very small value for numerical stability
    priorities += np.random.normal(0, random_perturbation_scale, size=bins_remain_cap.shape)

    return priorities
```
