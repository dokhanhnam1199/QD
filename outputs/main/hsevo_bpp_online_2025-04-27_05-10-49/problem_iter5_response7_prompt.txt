{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines utilization, waste minimization, near-perfect fit, small bin preference, and randomness.\"\"\"\n    epsilon = 1e-9\n    available_space = bins_remain_cap + epsilon\n\n    utilization = item / available_space\n    waste = available_space - item\n    normalized_waste = waste / available_space\n    near_perfect_fit = np.exp(-np.abs(waste))\n    small_bins_priority = 1.0 / (available_space + epsilon)\n    temperature = 0.1\n    random_fluctuation = np.random.normal(0, temperature, size=bins_remain_cap.shape)\n\n    # Prioritize feasible bins and scale the waste\n    feasible_bins = bins_remain_cap >= item\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n\n    priority[feasible_bins] = (\n        1.0 * utilization[feasible_bins]\n        -0.5 * normalized_waste[feasible_bins]\n        + 1.0 * near_perfect_fit[feasible_bins]\n        + 0.5 * small_bins_priority[feasible_bins]\n        + 0.1 * random_fluctuation[feasible_bins]\n    )\n\n    return priority\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, capacity considerations, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Waste Minimization & Infeasibility\n    waste = bins_remain_cap - item\n    infeasible = waste < 0\n    priorities[infeasible] = -np.inf\n    waste[infeasible] = np.inf\n\n    # Capacity considerations - like v1, but refined\n    capacity_diff = np.abs(bins_remain_cap - item)\n    priorities += 1.0 / (1e-6 + capacity_diff)\n\n    # Near-perfect fit bonus with waste\n    priorities += np.exp(-waste)\n\n    # Random Perturbation\n    priorities += np.random.normal(0, 0.01, size=bins_remain_cap.shape)\n\n    priorities = np.nan_to_num(priorities, neginf=-np.inf)\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see 1st uses waste minimization, capacity threshold, bin utilization balancing, item size awareness, and random perturbation with parameter tuning while the 20th use gravity/velocity with capacity and a buffer, lacking parameter tuning and random perturbation.\nComparing (2nd best) vs (second worst), we see 2nd uses waste minimization, capacity threshold, bin utilization balancing, item size awareness, and random perturbation with parameter tuning while the 19th use gravity/velocity with capacity and a buffer, lacking parameter tuning and random perturbation. Comparing (1st) vs (2nd), we see the two are identical, likely a copy-paste error. (3rd) vs (4th) also shows identical code, likely a copy-paste error. Comparing (second worst) vs (worst), we see the two are identical, likely a copy-paste error. Overall: The best heuristics include multiple factors (waste, capacity, utilization, item size, randomness), use parameter tuning and more sophisticated equations (exponential, sigmoid). Poorer heuristics focus on fewer factors and simpler equations, without parameter tuning. Specifically, the better heuristics prioritize a combination of waste minimization, bin utilization balancing, item size considerations, and random perturbation, often employing techniques like sigmoid scaling and adaptive adjustments. They also include mechanisms to avoid fragmentation. The worse heuristics tend to focus on a smaller subset of these factors, use simpler mathematical formulations, and lack adaptive or dynamic adjustments based on problem characteristics. The penalty terms for infeasible bins are also better handled in the top-ranked functions.\n- \nOkay, let's refine \"Current Self-Reflection\" for designing better heuristics.\n\n*   **Keywords:** Multifactorial Analysis, Adaptive Weights, Exploration, Granularity.\n*   **Advice:** Go beyond simple combinations. Explore interaction effects between factors (e.g., waste & item size). Employ adaptive weight adjustments based on real-time performance feedback.\n*   **Avoid:** Static, linear factor combinations; premature convergence.\n*   **Explanation:** Adaptive learning, fine-grained factor integration, and diversification help us to design better heuristics.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}