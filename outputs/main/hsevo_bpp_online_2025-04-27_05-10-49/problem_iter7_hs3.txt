import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                waste_weight: float = 0.0021137078106597817,
                utilization_weight: float = 0.3454551461331815,
                item_weight: float = 0.5720884582890235,
                gravity_weight: float = 0.8008558906947232,
                random_perturbation_scale: float = 0.025966681950800145,
                bin_fraction_midpoint: float = 0.5800905414911527) -> np.ndarray:
    """Combines waste minimization, bin utilization, item size, and randomness."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    original_capacity = np.max(bins_remain_cap)

    # Waste Minimization & Infeasibility
    waste = bins_remain_cap - item
    infeasible_mask = waste < 0
    priorities[infeasible_mask] = -np.inf
    waste[infeasible_mask] = np.inf

    # Waste Minimization Score
    waste_score = np.exp(-waste)

    # Bin Utilization Score
    bin_fraction = bins_remain_cap / original_capacity
    utilization_score = -(bin_fraction - bin_fraction_midpoint)**2

    # Item Size Awareness Score
    item_size_score = item / original_capacity

    # Gravitational component from the second heuristic, but adapted
    fit_mask = bins_remain_cap >= item
    fill_ratios = np.where(fit_mask, item / bins_remain_cap, 0)  # Avoid division by zero
    gravity_score = np.where(fit_mask, (1 - np.abs(1 - fill_ratios)), 0)  # Only add for feasible bins

    # Combine scores with potentially adaptive weights (using placeholder values for now, consider later adaptations).

    priorities += waste_weight * waste_score + utilization_weight * utilization_score + item_weight * item_size_score + gravity_weight * gravity_score

    # Small random perturbation
    priorities += np.random.normal(0, random_perturbation_scale, size=bins_remain_cap.shape)

    return priorities
