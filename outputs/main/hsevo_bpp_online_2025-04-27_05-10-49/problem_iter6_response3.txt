```python
import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                waste_penalty_factor: float = 0.8575834075161552,
                bin_fraction_penalty: float = 0.4693634879473551,
                item_size_weight: float = 2.0884148461764993,
                random_perturbation_scale: float = 0.06717097613120268,
                large_item_threshold: float = 0.7,
                waste_threshold: float = 0.1) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.
    Employs a combination of heuristics with adaptive considerations:
        1. Waste Minimization: Prioritizes bins where the remaining space after
           packing the item is minimal.  A near-perfect fit is highly valued.
        2. Capacity Threshold: Avoids bins with extremely small remaining
           capacity to reduce fragmentation. Bins that cannot fit are penalized.
        3. Bin Level Awareness : Considers the initial capacity of the bins for a more balanced distribution
        4. Balancing Bin Utilization:  Slight preference for bins that are not
           completely empty or completely full to maintain flexibility.
        5. Random Perturbation: Introduces small randomness to avoid getting stuck
           in local optima and explore slightly different packing arrangements.
        6. Item size awareness : Larger Items should fill bins as much as possible
        7. Adaptive Waste Penalty: Increase waste penalty for large items to prefer tighter fits.
        8. Waste Thresholding: Strongly penalize bins that will have very little remaining capacity.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.
        waste_penalty_factor: Factor to adjust the impact of waste minimization.
        bin_fraction_penalty: Factor to adjust the balancing of bin utilization.
        item_size_weight: Weight of item size awareness.
        random_perturbation_scale: Scale of random noise.
        large_item_threshold: Threshold to consider an item as large, relative to bin capacity.
        waste_threshold: The minimum waste tolerance.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    original_capacity = np.max(bins_remain_cap)

    # Waste Minimization & Capacity Threshold
    waste = bins_remain_cap - item
    too_small = waste < 0
    priorities[too_small] = -np.inf  # Never put item in bins that are too small.
    waste[too_small] = np.inf
    
    # Adaptive Waste Penalty.  If item is large, prefer very tight fits.
    if item / original_capacity > large_item_threshold:
        adaptive_waste_penalty = waste_penalty_factor * 2  # Increase penalty for large items
    else:
        adaptive_waste_penalty = waste_penalty_factor
    
    # Near-perfect fit bonus (minimize waste)
    priorities += adaptive_waste_penalty * np.exp(-waste)  # Exponential decay for increasing waste.
    
    # Waste Threshold penalty
    too_much_waste = waste > original_capacity * waste_threshold
    priorities[too_much_waste] -= 0.5 * waste[too_much_waste]
    

    # Bin utilization balancing - slightly prefers bins that aren't empty or full.  avoids extremities.  Parabolic preference
    bin_fraction = bins_remain_cap / original_capacity
    priorities += bin_fraction_penalty * -(bin_fraction - 0.5)**2  # Adds a parabolic preference curve.
    
    # Item Size Awareness.  Larger items fill bins up
    priorities += item_size_weight * item/original_capacity

    # Random Perturbation (introduces some "quantum" fluctuation). Very small value for numerical stability
    priorities += np.random.normal(0, random_perturbation_scale, size=bins_remain_cap.shape)

    return priorities
```
