{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, utilization balancing, item size, and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    avg_cap = np.mean(bins_remain_cap)\n\n    # Waste Minimization with Sigmoid\n    waste = bins_remain_cap - item\n    too_small = waste < 0\n    priorities[too_small] = -np.inf\n    waste[too_small] = np.inf\n    sigmoid_scale = 5\n    priorities += 1 / (1 + np.exp(sigmoid_scale * waste))\n\n    # Bin Utilization Balancing with Adaptive Center\n    bin_fraction = bins_remain_cap / np.max(bins_remain_cap)\n    utilization_center = 0.5 + 0.2 * np.clip(item / avg_cap, 0, 1)\n    priorities += -((bin_fraction - utilization_center) ** 2)\n\n    # Item Size Consideration\n    priorities += item / avg_cap\n\n    # Adaptive Random Perturbation\n    noise_scale = 0.01 + 0.05 * np.clip(item / avg_cap, 0, 1)\n    priorities += np.random.normal(0, noise_scale, size=bins_remain_cap.shape)\n    \n    # Fragmentation Avoidance\n    remaining_fraction = waste / np.max(bins_remain_cap)\n    too_fragmented = (waste > 0) & (remaining_fraction < 0.1)\n    priorities[too_fragmented] -= 0.5\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, target utilization, and adaptive scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    wasted_space = bins_remain_cap - item\n    fit_mask = wasted_space >= 0\n\n    if np.any(fit_mask):\n        # Adaptive scaling based on item size and remaining capacity distribution.\n        item_fraction = item / np.max(bins_remain_cap)\n        scaling_factor = 1.0 + 2.0 * item_fraction # Increase scaling if item is a significant fraction of bin size\n        priorities[fit_mask] = np.exp(-scaling_factor * wasted_space[fit_mask]**2 / (bins_remain_cap[fit_mask].mean() + 1e-9))\n\n        desirable_remaining_space = 0.2 * np.max(bins_remain_cap)\n        priority_values = np.exp(-((wasted_space[fit_mask] ) ** 2) / (2 * (desirable_remaining_space/2)** 2)) # Target utilization\n        priorities[fit_mask] = 0.6*priorities[fit_mask]+ 0.4*priority_values #Combine with weight\n        \n        # Introduce a small bias to prefer bins with larger remaining capacity if waste is similar. Mitigates fragmentation.\n        capacity_bias = 0.1 * bins_remain_cap[fit_mask] / np.max(bins_remain_cap)\n        priorities[fit_mask] += capacity_bias\n\n        # Small random perturbation for exploration\n        priorities[fit_mask] += np.random.normal(0, 0.01, size=np.sum(fit_mask))\n\n    priorities[~fit_mask] = -1e9 # Penalize infeasible bins severely\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st has fewer adaptive components and simpler logic. The 20th has more parameters and conditional adjustments based on item size, making it more complex but not necessarily better.\n\nComparing (2nd) vs (19th), we observe that the 2nd and the 19th are nearly identical. This implies code duplication, and a possible lack of significant experimentation between these versions.\n\nComparing (3rd) vs (4th), the 3rd includes weighted scores for waste, utilization, item size, and a \"gravity\" component, while the 4th simplifies to waste minimization, bin utilization, item size awareness, and adaptive randomness. The 3rd's use of separate weights for each component may offer finer control, but also more parameters to tune.\n\nComparing (second worst) vs (worst), the 19th and 20th focus on adaptive scaling, conditional logic based on item size, and capacity usage. The 20th introduces capacity usage factor, emphasizes interaction effects between waste and item size and adaptive scaling based on item size.\n\nOverall: The better heuristics tend to be simpler and rely on a core set of principles (waste minimization, bin utilization balancing, item size awareness, and randomness), while the worse heuristics try to introduce more complex adaptive mechanisms which is not necessary. Also, duplication might reveal lack of diversity in experiments. Simplicity and core concepts appears more robust.\n- \nOkay, let's refine \"Current Self-Reflection\" to design better heuristics, focusing on actionable advice and avoiding common pitfalls.\n\nHere's a breakdown:\n\n*   **Keywords:** Parsimony, Adaptive Complexity, Diverse Experimentation, Code Reuse Analysis.\n*   **Advice:** Begin with minimal heuristics; incrementally add complexity only when demonstrably beneficial through rigorous testing. Prioritize simple, adaptive mechanisms over complex, heavily parameterized ones.\n*   **Avoid:** Premature complexity, over-parameterization, neglecting code duplication as a sign of limited exploration.\n*   **Explanation:** Start lean, adapt intelligently, test thoroughly, and actively seek out unexplored avenues (indicated by code redundancies).\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}