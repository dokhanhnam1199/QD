```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.
    Employs a combination of heuristics with refined strategies:
        1.  Waste Minimization with Sigmoid Scaling: Prioritizes near-perfect
            fits, but uses a sigmoid function to provide a more gradual and
            context-aware scaling of priorities.  This avoids overly aggressive
            assignment to bins with tiny waste.
        2.  Capacity Threshold with Dynamic Adjustment:  Penalizes bins that
            cannot fit, but dynamically adjusts the penalty based on the
            item size relative to the average remaining bin capacity.  If the
            item is large, the penalty is reduced to encourage filling nearly-full
            bins and reduce fragmentation.
        3.  Bin Utilization Balancing with Adaptive Range:  Prefers bins that
            are neither too full nor too empty, but adaptively adjusts the
            preferred utilization range based on the item size.  Large items
            shift the preference towards fuller bins.
        4.  Fragmentation Avoidance: Explicitly discourages creating bins with
            very small remaining capacity *after* placing the item, further
            reducing fragmentation.
        5.  Adaptive Random Perturbation: Adds random noise, but scales the
            magnitude of the noise based on the item size.  Larger items
            justify a larger perturbation to explore more diverse packing
            arrangements.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    avg_cap = np.mean(bins_remain_cap)

    # Waste Minimization & Capacity Threshold (Sigmoid Scaling & Dynamic Adjustment)
    waste = bins_remain_cap - item
    too_small = waste < 0
    penalty_scale = np.clip(item / avg_cap, 0.1, 1.0)  # Dynamic penalty scaling
    priorities[too_small] = -1e9 * penalty_scale  # Scaled penalty
    waste[too_small] = np.inf

    # Near-perfect fit bonus (minimize waste) with sigmoid
    sigmoid_scale = 10  # Controls steepness of sigmoid
    priorities += 1 / (1 + np.exp(sigmoid_scale * waste)) # Sigmoid scaling

    # Bin utilization balancing (Adaptive Range)
    bin_fraction = bins_remain_cap / np.max(bins_remain_cap)
    utilization_center = 0.5 + 0.2 * np.clip(item / avg_cap, 0, 1) # Shifts center
    priorities += -((bin_fraction - utilization_center) ** 2)

    # Fragmentation Avoidance
    remaining_fraction = waste / np.max(bins_remain_cap)
    too_fragmented = (waste > 0) & (remaining_fraction < 0.1)  # Avoid tiny wastes
    priorities[too_fragmented] -= 0.5  # Discourage fragmented bins, but less aggressive than infeasibility

    # Adaptive Random Perturbation
    noise_scale = 0.01 + 0.05 * np.clip(item / avg_cap, 0, 1)  # Scale noise
    priorities += np.random.normal(0, noise_scale, size=bins_remain_cap.shape)

    return priorities
```
