[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    return priorities",
    "response_id": 0,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 1.0,
    "halstead": 0.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    The First Fit strategy prioritizes bins that have just enough capacity\n    to fit the item, aiming to leave larger remaining capacities in other bins\n    for potentially larger future items.\n    A higher priority score indicates a better fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n    \n    # Calculate the difference between remaining capacity and item size for fitting bins\n    # A smaller difference means a \"tighter\" fit, which is preferred by First Fit.\n    # We use the inverse of the difference to make it a maximization problem.\n    # Add a small epsilon to avoid division by zero for exact fits.\n    priorities[fit_mask] = 1.0 / (bins_remain_cap[fit_mask] - item + 1e-9)\n    \n    # Bins where the item does not fit get a priority of 0\n    # This is already handled by np.zeros_like, but explicitly for clarity in logic\n    priorities[~fit_mask] = 0.0\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 51.80615605397529,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    if np.any(suitable_bins_mask):\n        remaining_capacities = bins_remain_cap[suitable_bins_mask] - item\n        min_remaining_capacity = np.min(remaining_capacities)\n        best_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap - item == min_remaining_capacity)\n        priorities[best_fit_mask] = 1.0\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 62.26976913547136,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    if valid_bins_remain_cap.size > 0:\n        gaps = valid_bins_remain_cap - item\n        priorities[can_fit_mask] = -gaps\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 36.541209043760986,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic: Prioritize bins where the item fits exactly.\n    If no exact fit, then prioritize the bin with the smallest remaining capacity\n    that can still accommodate the item (Best Fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    \n    if len(exact_fit_indices) > 0:\n        priorities[exact_fit_indices] = 1.0\n    else:\n        possible_bins = np.where(bins_remain_cap >= item)[0]\n        if len(possible_bins) > 0:\n            relevant_capacities = bins_remain_cap[possible_bins]\n            best_fit_index_in_possible = np.argmin(relevant_capacities)\n            best_fit_original_index = possible_bins[best_fit_index_in_possible]\n            priorities[best_fit_original_index] = 1.0\n    \n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 36.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = 1.0  # Give priority to bins that can fit the item\n        else:\n            priorities[i] = 0.0  # No priority for bins that cannot fit the item\n    \n    # In First Fit, we iterate through bins in order and pick the first one that fits.\n    # To simulate this priority, we want to give higher priority to earlier bins if they fit.\n    # We can achieve this by making the priority score dependent on the bin's index.\n    # A simple way is to add a small decreasing value based on the index.\n    # However, the standard First Fit doesn't explicitly use priority scores in this way;\n    # it's more of a sequential search. For the purpose of this function signature,\n    # we'll just mark bins that can fit. If multiple can fit, the selection logic\n    # outside this function would need to pick the first one.\n    #\n    # A true \"priority\" that mimics FF selection might be complex within this\n    # function signature if it's meant to return scores to be maxed.\n    # If the intention is for this function to directly return which bin to pick,\n    # a different approach would be needed.\n    #\n    # Given the structure, the simplest interpretation that *hints* at FF is\n    # to give a higher score to the *first* available bin.\n    \n    first_available_index = -1\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            first_available_index = i\n            break\n            \n    if first_available_index != -1:\n        priorities[first_available_index] = 1.0 + (len(bins_remain_cap) - 1 - first_available_index) * 0.001 # Slightly higher priority for earlier bins\n        \n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 6.0,
    "halstead": 100.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_capacity = bins_remain_cap[i]\n            if remaining_capacity - item == 0:\n                priorities[i] = 1.0 / (remaining_capacity - item + 1e-9)\n            else:\n                priorities[i] = 1.0 / (remaining_capacity - item)\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 93.76537429460444,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate how well each bin can fit the item\n    # A smaller remaining capacity relative to the item size is better\n    # We want to penalize bins that are too large, as they might be inefficient for this item\n    # We want to favor bins that are just right for the item, or slightly larger\n    \n    # Calculate the difference between remaining capacity and item size\n    diff = bins_remain_cap - item\n    \n    # Apply a sigmoid function to the difference.\n    # The sigmoid function will map values to a range between 0 and 1.\n    # We want higher scores for bins that have a 'good' fit.\n    # A good fit means the remaining capacity is slightly larger than the item,\n    # or just enough to fit the item.\n    # Let's map 'diff' such that values close to 0 (perfect fit) or slightly positive\n    # (a bit of slack) get higher scores.\n    # We can adjust the steepness of the sigmoid using a scaling factor.\n    # A larger scaling factor will make the sigmoid steeper, resulting in more\n    # distinct priorities for small differences.\n    \n    scaling_factor = 2.0 # Heuristic parameter to tune the steepness\n    \n    # We want to avoid negative arguments to the sigmoid for values where the item doesn't fit\n    # so we clip the values to be at least 0 before division.\n    # This means bins where remaining_cap < item will be treated similarly regarding their\n    # \"unsuitability\" from this metric, all getting very low priority.\n    \n    # Consider bins where the item *can* fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit, we want to prioritize those where the remaining capacity is\n    # close to the item size.\n    # A value of diff=0 (perfect fit) should ideally be near the center of the sigmoid's steep part.\n    # We can shift the input to the sigmoid by a small amount if needed, but let's start simply.\n    \n    # Let's use a logistic sigmoid function: L / (1 + exp(-k*(x-x0)))\n    # Where L is the maximum value (1), k is the steepness (scaling_factor),\n    # x is the input (diff), and x0 is the midpoint.\n    # If we set x0=0, then perfect fit (diff=0) will result in 1 / (1 + exp(0)) = 1/2.\n    # We want the highest score when diff is small and positive.\n    # Let's modify the function to center around 0 difference being optimal.\n    # Consider a transformation: -diff.\n    # Now a perfect fit (diff=0) becomes 0. A slight excess capacity (diff=1) becomes -1.\n    # A slight deficit (diff=-1) becomes 1. This is not quite right.\n    \n    # Let's consider the *relative* remaining capacity after fitting the item.\n    # If remaining_cap - item = 0, this is a perfect fit.\n    # If remaining_cap - item = positive, there's slack.\n    # If remaining_cap - item = negative, it doesn't fit.\n    \n    # We want to maximize the priority for `remaining_cap - item` being close to 0.\n    # Let's use a function that is symmetric around 0 and peaks at 0.\n    # A Gaussian-like shape could work, but sigmoid is requested.\n    \n    # Alternative interpretation for Sigmoid Fit Score:\n    # We want bins that are \"almost full\" but can still fit the item.\n    # This means `bins_remain_cap - item` should be small.\n    \n    # Let's try a sigmoid that maps small positive differences to high values,\n    # and larger positive differences to lower values.\n    # Also, bins that cannot fit the item should have very low priority.\n    \n    # We can use a sigmoid on a scaled version of `item / bins_remain_cap`.\n    # If `bins_remain_cap` is very large, `item / bins_remain_cap` is small.\n    # If `bins_remain_cap` is just slightly larger than `item`, `item / bins_remain_cap` is close to 1.\n    # If `bins_remain_cap` equals `item`, `item / bins_remain_cap` is 1.\n    \n    # Let's define a score that is high when `bins_remain_cap` is close to `item`.\n    # We can consider the inverse of the \"slack\": `item / bins_remain_cap`\n    # However, if `bins_remain_cap < item`, this ratio is > 1.\n    \n    # Let's stick to the idea of `bins_remain_cap - item`.\n    # We want a function f(x) where x = bins_remain_cap - item,\n    # such that f(0) is high, f(small_positive) is slightly lower,\n    # f(large_positive) is very low, and f(negative) is very low.\n    \n    # The sigmoid function `1 / (1 + exp(-k*x))` maps `x` to `(0, 1)`.\n    # If `x` is large positive, result is close to 1.\n    # If `x` is large negative, result is close to 0.\n    # If `x` is 0, result is 0.5.\n    \n    # We want a peak at `x=0`.\n    # Consider `1 / (1 + exp(-k * |x|))` - this peaks at 1 for x=0 but is symmetric.\n    # Consider `exp(-k * x^2)` - Gaussian.\n    \n    # Let's try to use sigmoid in a way that penalizes large remaining capacities.\n    # For bins where `bins_remain_cap >= item`:\n    # We want to maximize the priority as `bins_remain_cap` gets closer to `item`.\n    # Let's map `bins_remain_cap` to a value that is small when it's much larger than `item`.\n    # Consider `bins_remain_cap / (item + epsilon)`.\n    # If `bins_remain_cap = item`, this is 1.\n    # If `bins_remain_cap = 2*item`, this is 2.\n    # If `bins_remain_cap = 0.5*item`, this is 0.5 (but this case is invalid as item won't fit).\n    \n    # Let's consider `1 - sigmoid(k * (bins_remain_cap - item))` for bins where item fits.\n    # If `bins_remain_cap = item`, `diff = 0`, `sigmoid(0) = 0.5`, `1 - 0.5 = 0.5`.\n    # If `bins_remain_cap = item + delta` (delta small positive), `diff = delta`.\n    # `sigmoid(k * delta)` > 0.5, so `1 - sigmoid(...)` < 0.5. This is not what we want.\n    \n    # Let's use a sigmoid to represent \"goodness of fit\" as being close to 1.\n    # Let's scale `item` to be within some range and then use sigmoid.\n    \n    # Consider a transformation on the *unused space*: `unused_space = bins_remain_cap - item`\n    # We want to maximize priority when `unused_space` is small and non-negative.\n    # Let's map `unused_space` to a score.\n    # A small non-negative `unused_space` should yield a high score.\n    # A large positive `unused_space` should yield a low score.\n    # A negative `unused_space` (item doesn't fit) should yield a very low score.\n    \n    # Let's try `sigmoid(scaling_factor * (item - bins_remain_cap))`.\n    # If `item = bins_remain_cap` (diff=0), `sigmoid(0) = 0.5`.\n    # If `item = bins_remain_cap - delta` (slack=delta), `sigmoid(-delta * k)` < 0.5. We want high.\n    # If `item = bins_remain_cap + delta` (deficit=delta), `sigmoid(delta * k)` > 0.5. We want low.\n    \n    # The inverse of the previous idea: `sigmoid(scaling_factor * (bins_remain_cap - item))`\n    # If `bins_remain_cap = item` (diff=0), `sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta` (slack=delta), `sigmoid(delta * k)` > 0.5. High is good.\n    # If `bins_remain_cap = item - delta` (deficit=delta), `sigmoid(-delta * k)` < 0.5. Low is good.\n    \n    # This seems to be the most promising approach: higher scores for more remaining capacity,\n    # but we need to make it so that it penalizes *excessive* remaining capacity.\n    \n    # Let's scale the remaining capacity relative to the bin size if we knew it, or relative to item.\n    # If `bins_remain_cap` is much larger than `item`, we might want a lower score.\n    \n    # Consider the quantity `bins_remain_cap / item`.\n    # If `bins_remain_cap = item`, ratio = 1.\n    # If `bins_remain_cap = 2 * item`, ratio = 2.\n    # If `bins_remain_cap < item`, ratio < 1.\n    \n    # We want a peak when `bins_remain_cap` is slightly larger than `item`.\n    # Let's define `score = bins_remain_cap - item`. We want to maximize score near 0.\n    \n    # We can use a sigmoid applied to a scaled version of `item - bins_remain_cap`.\n    # This is equivalent to `1 - sigmoid(scaling_factor * (bins_remain_cap - item))`.\n    # `1 - sigmoid(x)` is `1 / (1 + exp(-x))`. This is a sigmoid shifted and inverted.\n    # Let `y = bins_remain_cap - item`.\n    # If `y=0`, `1 - sigmoid(0) = 0.5`.\n    # If `y` is small positive (slack), `1 - sigmoid(positive_k*y)` < 0.5. Not good.\n    \n    # Let's use `sigmoid(k * (item - bins_remain_cap))`\n    # If `item == bins_remain_cap`: score is 0.5\n    # If `item < bins_remain_cap`: item - bin_rem_cap < 0. sigmoid(<0) < 0.5. Score is lower.\n    # If `item > bins_remain_cap`: item - bin_rem_cap > 0. sigmoid(>0) > 0.5. Score is higher.\n    # This means we prefer bins that are too small. Not correct.\n    \n    # The common \"sigmoid fit\" for bin packing often refers to prioritizing bins that are \"tight fits\".\n    # A tight fit means the remaining capacity is close to the item size.\n    \n    # Let's try to create a score that is high when `bins_remain_cap` is approximately equal to `item`.\n    # Consider `sigmoid(k * (1 - bins_remain_cap / item))` if item is not zero.\n    # This is undefined if item is zero. Also division by zero if bins_remain_cap is zero.\n    \n    # Let's use the absolute difference and invert it.\n    # `score = -abs(bins_remain_cap - item)`\n    # Then apply sigmoid to this negated difference.\n    # `sigmoid(k * -abs(bins_remain_cap - item))`\n    # This peaks at 0.5 when `abs(bins_remain_cap - item) = 0`.\n    # It goes down to 0 as `abs(...)` increases.\n    # This looks like a good candidate for \"tight fit\".\n    \n    # However, we must ensure the item fits.\n    # We can set priorities to a very low value (e.g., 0) for bins where `bins_remain_cap < item`.\n    \n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit, calculate the priority using the sigmoid of the negated absolute difference\n    # between remaining capacity and item size.\n    # We scale the difference to control the steepness of the priority curve.\n    # A larger `steepness` means we strongly favor bins that are closer fits.\n    steepness = 5.0  # Tune this parameter. Higher means more sensitive to small differences.\n    \n    # Calculate `bins_remain_cap - item`. If this is very large, we want low priority.\n    # Let's apply sigmoid to `item - bins_remain_cap` and ensure it's capped for non-fitting bins.\n    \n    # Consider the ratio of remaining capacity to the item size.\n    # `ratio = bins_remain_cap / item`\n    # If ratio is 1 (perfect fit), we want high priority.\n    # If ratio is slightly > 1 (slack), priority should be slightly lower.\n    # If ratio is much > 1 (large slack), priority should be much lower.\n    # If ratio is < 1 (item doesn't fit), priority should be minimal.\n    \n    # Let's use `1 / (1 + exp(-k * (1 - bins_remain_cap / item)))`. This peaks when `bins_remain_cap / item = 1`.\n    # When `bins_remain_cap / item = 1`: `1 / (1 + exp(0)) = 0.5`.\n    # When `bins_remain_cap / item = 2`: `1 / (1 + exp(-k))`. Lower than 0.5 if k>0.\n    # When `bins_remain_cap / item = 0.5`: `1 / (1 + exp(k/2))`. Lower than 0.5.\n    # This seems to correctly penalize bins that are too small or too large, peaking at a perfect fit.\n    \n    # Handle division by zero if item is 0. Assume item size is always positive.\n    # Handle cases where `bins_remain_cap` might be zero or very small for the ratio.\n    \n    # Let's use a robust calculation for the ratio, ensuring we don't divide by zero\n    # and handle cases where bins_remain_cap is very small or zero.\n    \n    # `fit_metric = bins_remain_cap - item`\n    # We want to maximize `f(fit_metric)` where `f(0)` is max, `f(positive)` decreases, `f(negative)` is minimal.\n    \n    # Let's scale `item` and `bins_remain_cap` relative to each other in a sigmoid.\n    # Consider `sigmoid(k * (item - bins_remain_cap))`.\n    # If `bins_remain_cap` is large, `item - bins_remain_cap` is large negative. Sigmoid is near 0.\n    # If `bins_remain_cap` is small (but >= item), `item - bins_remain_cap` is small positive. Sigmoid is near 0.5 to 1.\n    # If `bins_remain_cap == item`, `item - bins_remain_cap = 0`. Sigmoid is 0.5.\n    \n    # This means `sigmoid(k * (bins_remain_cap - item))` is better.\n    # `bins_remain_cap = item` => 0.5\n    # `bins_remain_cap = item + delta` => sigmoid(k*delta) > 0.5\n    # `bins_remain_cap = item - delta` => sigmoid(-k*delta) < 0.5\n    \n    # This favors bins that are larger. To favor tighter fits, we need to penalize large remaining capacities.\n    \n    # Let's try sigmoid on the \"emptiness ratio\": `(bins_remain_cap - item) / bin_capacity` is not possible.\n    # Let's scale `bins_remain_cap` relative to `item` but ensure the output makes sense.\n    \n    # If `bins_remain_cap` is slightly larger than `item`, we want high priority.\n    # If `bins_remain_cap` is much larger than `item`, we want lower priority.\n    # If `bins_remain_cap` is exactly `item`, we want high priority.\n    \n    # Consider `1 - sigmoid(k * (bins_remain_cap - item))`.\n    # `bins_remain_cap = item`: 1 - 0.5 = 0.5\n    # `bins_remain_cap = item + delta`: 1 - sigmoid(k*delta) < 0.5\n    # `bins_remain_cap = item - delta`: 1 - sigmoid(-k*delta) > 0.5\n    \n    # This seems to favor bins that are just fitting or slightly undersized. Still not right.\n    \n    # Let's try a reversed sigmoid on the \"excess capacity\".\n    # `excess_capacity = bins_remain_cap - item`\n    # We want to minimize `excess_capacity` for `excess_capacity >= 0`.\n    # Apply `1 - sigmoid(k * excess_capacity)`\n    # If `excess_capacity = 0`: 1 - 0.5 = 0.5\n    # If `excess_capacity = delta` (small positive): 1 - sigmoid(k*delta) < 0.5\n    # If `excess_capacity = D` (large positive): 1 - sigmoid(k*D) -> 1 - 1 = 0.\n    # If `excess_capacity = -delta` (item doesn't fit): 1 - sigmoid(-k*delta) > 0.5. This is problematic.\n    \n    # We must ensure `bins_remain_cap >= item` for non-zero priorities.\n    \n    # Final attempt strategy:\n    # Calculate a score representing how close `bins_remain_cap` is to `item`,\n    # penalizing bins that have too much excess capacity.\n    # Use `sigmoid(k * (item - (bins_remain_cap - epsilon)))`\n    # Where epsilon is a small value to slightly prefer bins with some remaining capacity over exact fits.\n    # This is still tricky to get the exact desired behavior with a simple sigmoid.\n    \n    # A common \"sigmoid fit\" heuristic: prioritize bins where `bins_remain_cap` is closest to `item`.\n    # This can be modeled by `sigmoid(-k * abs(bins_remain_cap - item))`.\n    # This is symmetric around `bins_remain_cap = item`, peaking at 0.5.\n    \n    # Let's combine the \"can fit\" condition with this.\n    \n    # Calculate priorities for bins that can fit the item\n    diff_from_ideal = bins_remain_cap[can_fit_mask] - item\n    \n    # Use sigmoid on the negative of the absolute difference.\n    # This gives highest priority (close to 1) for diff = 0, and decreases as diff grows.\n    # We want to penalize large remaining capacity.\n    # Let's consider the inverse of the remaining capacity ratio: `item / bins_remain_cap`.\n    # For bins that fit:\n    # if `bins_remain_cap` is `item`, ratio is 1.\n    # if `bins_remain_cap` is `item + delta`, ratio is `item / (item + delta) < 1`.\n    # if `bins_remain_cap` is `2*item`, ratio is `0.5`.\n    \n    # We want high priority when `bins_remain_cap` is just slightly larger than `item`.\n    # So, when `item / bins_remain_cap` is close to 1 but slightly less than 1.\n    \n    # Let's use `sigmoid(k * (1 - bins_remain_cap / item))`.\n    # This implies `bins_remain_cap / item < 1`.\n    \n    # A more direct approach for Sigmoid Fit:\n    # Prioritize bins where the remaining capacity `R` satisfies `item <= R < some_threshold`.\n    # And within that, prefer smaller `R`.\n    \n    # Let's try `sigmoid(k * (item - (bins_remain_cap - small_buffer)))`\n    # If `bins_remain_cap = item`, `sigmoid(k * (item - (item))) = sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta` (small positive slack), `sigmoid(k * (item - (item + delta))) = sigmoid(-k*delta) < 0.5`.\n    # This is not what we want.\n    \n    # How about: `sigmoid(k * (bins_remain_cap / item))` for bins that fit?\n    # If `bins_remain_cap = item`, sigmoid(k).\n    # If `bins_remain_cap = 2*item`, sigmoid(2k). Higher priority for larger bins. Wrong.\n    \n    # Let's try the inverted ratio, scaled:\n    # `sigmoid(k * (item - bins_remain_cap))`\n    # `bins_remain_cap = item`: sigmoid(0) = 0.5\n    # `bins_remain_cap = item + delta`: sigmoid(-k*delta) < 0.5\n    # `bins_remain_cap = item - delta`: sigmoid(k*delta) > 0.5\n    # This prioritizes bins that are undersized.\n    \n    # It seems the core idea for \"Sigmoid Fit\" should capture \"tightness\".\n    # The `sigmoid(k * (item - residual_capacity))` where `residual_capacity` is the capacity *after* placing the item,\n    # i.e., `bins_remain_cap - item`.\n    # Let `residual = bins_remain_cap - item`.\n    # We want to maximize `sigmoid(k * (item - residual))` or `sigmoid(k * (item - (bins_remain_cap - item)))`.\n    # This is `sigmoid(k * (2*item - bins_remain_cap))`.\n    \n    # Let's test `sigmoid(k * (2*item - bins_remain_cap))` for fitting bins.\n    # If `bins_remain_cap = item`: `sigmoid(k * (2*item - item)) = sigmoid(k*item)`. High if k*item is large.\n    # If `bins_remain_cap = item + delta`: `sigmoid(k * (2*item - (item + delta))) = sigmoid(k * (item - delta))`. Lower than previous.\n    # If `bins_remain_cap = 2*item`: `sigmoid(k * (2*item - 2*item)) = sigmoid(0) = 0.5`.\n    \n    # This means higher priority for bins that are smaller than 2*item and closer to item.\n    # But it penalizes bins that are exactly item size if item is small.\n    \n    # A simpler form of Sigmoid Fit could be focusing on the ratio of item size to remaining capacity.\n    # We want this ratio to be close to 1.\n    # Let's consider `item / bins_remain_cap` for bins that fit.\n    # If `bins_remain_cap = item`: ratio = 1.\n    # If `bins_remain_cap = item + delta`: ratio = `item / (item + delta) < 1`.\n    # If `bins_remain_cap = 2*item`: ratio = 0.5.\n    \n    # We want high priority when `item / bins_remain_cap` is close to 1.\n    # Use `sigmoid(k * (1 - item / bins_remain_cap))`\n    # If `item / bins_remain_cap = 1`: sigmoid(0) = 0.5.\n    # If `item / bins_remain_cap = 0.9`: sigmoid(k * 0.1) > 0.5. High priority.\n    # If `item / bins_remain_cap = 0.5`: sigmoid(k * 0.5) >> 0.5. Very high priority.\n    # This seems to prefer bins where the item fills a large proportion of the bin, even if `bins_remain_cap` is large.\n    \n    # Let's try this: prioritize bins where `bins_remain_cap` is close to `item`.\n    # Use `sigmoid(k * (item - abs(bins_remain_cap - item)))`. This is problematic.\n    \n    # Focus on `bins_remain_cap - item`. We want this to be small and positive.\n    # Let `slack = bins_remain_cap - item`.\n    # Prioritize bins where `slack` is small.\n    # `sigmoid(k * (1 - slack))` ?\n    # If slack=0, sigmoid(k).\n    # If slack=small_positive, sigmoid(k * (1-small)) < sigmoid(k). Lower priority. This is not desired.\n    \n    # Let's use a negative exponential on slack. `exp(-k * slack)`.\n    # If slack=0, exp(0)=1.\n    # If slack=small_positive, exp(-k*small_positive) < 1. Lower priority.\n    # If slack=large_positive, exp(-k*large_positive) -> 0.\n    # This is good for prioritizing tight fits.\n    \n    # Let's wrap `exp(-k * slack)` with a sigmoid to keep values in (0, 1) or to control the curve.\n    # This would be `sigmoid(k_outer * (exp(-k_inner * slack) - midpoint))`.\n    \n    # A more direct approach from literature on Sigmoid Fit:\n    # Prioritize bins where `bins_remain_cap` is just enough to fit the item.\n    # This means `bins_remain_cap` is NOT much larger than `item`.\n    \n    # Let's define priority based on `item / bins_remain_cap` for bins that can fit.\n    # `bins_remain_cap >= item`\n    # If `bins_remain_cap = item`, ratio = 1.\n    # If `bins_remain_cap = 2*item`, ratio = 0.5.\n    # If `bins_remain_cap = 1.1*item`, ratio = `item / (1.1*item) = 1/1.1 approx 0.909`.\n    \n    # We want to favor ratios close to 1.\n    # Consider `sigmoid(k * (bins_remain_cap / item - 1))`\n    # If `bins_remain_cap = item`: sigmoid(0) = 0.5.\n    # If `bins_remain_cap = item + delta`: sigmoid(k * (delta/item)) > 0.5. Higher priority for larger remaining bins.\n    \n    # Let's try the inverse: `sigmoid(k * (1 - bins_remain_cap / item))`\n    # If `bins_remain_cap = item`: sigmoid(0) = 0.5.\n    # If `bins_remain_cap = item + delta`: sigmoid(k * (1 - (item+delta)/item)) = sigmoid(k * (1 - (1 + delta/item))) = sigmoid(-k * delta/item) < 0.5. Lower priority for larger remaining bins.\n    # If `bins_remain_cap = item - delta` (item doesn't fit properly, so we should exclude these): This ratio is > 1.\n    \n    # So, the formula `sigmoid(k * (1 - bins_remain_cap / item))` correctly prioritizes bins that are closer to the item size, penalizing larger bins.\n    \n    # Handle `item == 0` and `bins_remain_cap == 0`. Assume item > 0.\n    # Need to be careful with division by `item` if `item` is zero, or very small.\n    # Also careful if `bins_remain_cap` is zero or very small.\n    \n    # Let's define a small epsilon for numerical stability and to avoid division by zero.\n    epsilon = 1e-9\n    \n    # Calculate priorities for bins that can fit the item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Compute the 'tightness' metric: item size divided by remaining capacity.\n    # Higher value means a tighter fit.\n    # Add epsilon to denominator to prevent division by zero.\n    tightness_ratio = item / (fitting_bins_remain_cap + epsilon)\n    \n    # Apply sigmoid to a transformed tightness ratio.\n    # We want highest priority when `item / bins_remain_cap` is close to 1.\n    # Let's use `sigmoid(k * (1 - tightness_ratio))`.\n    # If `item == bins_remain_cap`: tightness_ratio = 1. `sigmoid(k * (1 - 1)) = sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta` (small positive slack): tightness_ratio < 1. `1 - tightness_ratio` is small positive. `sigmoid(k * small_positive) > 0.5`.\n    # This is penalizing tight fits and favoring larger bins. Incorrect.\n    \n    # Let's try `sigmoid(k * (tightness_ratio - 1))`.\n    # If `item == bins_remain_cap`: `sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta`: `tightness_ratio < 1`. `tightness_ratio - 1` is negative. `sigmoid(k * negative) < 0.5`. This penalizes larger bins. CORRECT.\n    # If `bins_remain_cap = item - delta`: `tightness_ratio > 1`. `tightness_ratio - 1` is positive. `sigmoid(k * positive) > 0.5`. High priority for undersized bins. This is still problematic if not handled.\n    \n    # The `can_fit_mask` already handles the undersized bins by setting their priority to 0.\n    \n    # So, for fitting bins: `sigmoid(k * (item / (bins_remain_cap + epsilon) - 1))`\n    # With `k = steepness`.\n    \n    k = steepness # Use steepness as the scaling factor\n    \n    # Calculate the priority for fitting bins\n    priorities[can_fit_mask] = 1 / (1 + np.exp(-k * (item / (fitting_bins_remain_cap + epsilon) - 1)))\n    \n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 164.2332676057198,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priorities for placing an item into bins using a Softmax-Based Fit strategy.\n\n    The priority is higher for bins that have a remaining capacity greater than or equal to the item's size,\n    and among those, bins that have less remaining capacity (tighter fit) are preferred.\n    A small penalty is added to bins that cannot accommodate the item to ensure they receive a non-zero\n    but still lower priority.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array representing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element represents\n        the priority score for placing the item into the corresponding bin.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    unsuitable_bins_mask = ~suitable_bins_mask\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(suitable_bins_mask):\n        suitable_capacities = bins_remain_cap[suitable_bins_mask]\n        \n        inverted_capacities = 1.0 / (suitable_capacities - item + 1e-9)\n        \n        max_inverted_capacity = np.max(inverted_capacities)\n        \n        normalized_priorities = inverted_capacities / max_inverted_capacity\n        \n        priorities[suitable_bins_mask] = normalized_priorities\n\n    if np.any(unsuitable_bins_mask):\n        priorities[unsuitable_bins_mask] = 1e-6\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = capacity - item\n        else:\n            priorities[i] = -np.inf\n    \n    min_diff = np.min(priorities[priorities != -np.inf]) if np.any(priorities != -np.inf) else np.inf\n    \n    priorities[priorities != -np.inf] = min_diff - priorities[priorities != -np.inf]\n    \n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 118.02800258378572,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    possible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    available_capacities = bins_remain_cap[possible_bins]\n    \n    if available_capacities.size > 0:\n        \n        fitted_capacities = available_capacities - item\n        \n        \n        scaled_capacities = fitted_capacities / np.max(available_capacities)\n        \n        \n        priorities[possible_bins] = 1 / (1 + np.exp(-5 * (scaled_capacities - 0.5)))\n        \n        \n        if np.any(fitted_capacities == 0):\n            priorities[possible_bins][fitted_capacities == 0] = 1.0\n            \n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 144.75398259382442,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priorities for placing an item into bins using a hybrid Best Fit and Softmax strategy.\n\n    Prioritizes bins with exact fits, then bins with the tightest fit.\n    Unsuitable bins receive a minimal priority.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    unsuitable_bins_mask = ~suitable_bins_mask\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(suitable_bins_mask):\n        suitable_capacities = bins_remain_cap[suitable_bins_mask]\n        \n        # Prioritize exact fits with highest score\n        exact_fit_mask = suitable_capacities == item\n        if np.any(exact_fit_mask):\n            priorities[suitable_bins_mask][exact_fit_mask] = 1.0\n        \n        # For other suitable bins, use inverted remaining capacity for tightest fit\n        non_exact_suitable_mask = suitable_bins_mask.copy()\n        non_exact_suitable_mask[suitable_bins_mask] = ~exact_fit_mask\n        \n        if np.any(non_exact_suitable_mask):\n            non_exact_capacities = bins_remain_cap[non_exact_suitable_mask]\n            \n            # Inverse of (capacity - item) for tightest fit, normalized\n            inverted_gaps = 1.0 / (non_exact_capacities - item + 1e-9)\n            \n            # Scale priorities to be between 0 and 1, favoring larger inverse_gaps (tighter fits)\n            max_inverted_gap = np.max(inverted_gaps)\n            normalized_priorities = inverted_gaps / max_inverted_gap\n            \n            # Assign scaled priorities to non-exact fitting bins\n            priorities[non_exact_suitable_mask] = normalized_priorities\n    \n    # Assign a very low priority to bins that cannot fit the item\n    if np.any(unsuitable_bins_mask):\n        priorities[unsuitable_bins_mask] = 1e-6\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 5.195452732349436,
    "cyclomatic_complexity": 5.0,
    "halstead": 91.73835003173087,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit First and Best Fit.\n    Prioritizes exact fits, then bins with minimal remaining capacity,\n    using a penalty for bins that cannot fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n\n    # Exact fit: highest priority\n    exact_fit_mask = (bins_remain_cap == item) & fit_mask\n    priorities[exact_fit_mask] = 1.0\n\n    # Best fit for remaining bins (those that fit but not exactly)\n    non_exact_fit_mask = fit_mask & ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        fitting_capacities = bins_remain_cap[non_exact_fit_mask]\n        gaps = fitting_capacities - item\n        min_gap = np.min(gaps)\n        \n        # Assign priorities based on the gap, higher for smaller gaps.\n        # Add a small offset to distinguish from exact fits and ensure positive.\n        best_fit_priorities = 0.9 - (gaps - min_gap) / (np.max(gaps) - min_gap + 1e-9)\n        \n        # Apply these priorities only to the bins that are non-exact fits\n        priorities[non_exact_fit_mask] = best_fit_priorities\n\n    # Penalize bins that cannot fit the item\n    no_fit_mask = ~fit_mask\n    priorities[no_fit_mask] = -1.0 # Effectively exclude them from selection\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 167.17882283189007,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on tight fit, favoring exact fits then closest fits.\n\n    Combines exact fit (priority 1.0) with a tight fit metric using sigmoid\n    on the inverse of remaining capacity relative to item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If there are no bins that can fit the item, return all zeros\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Prioritize exact fits with the highest score\n    exact_fit_mask_for_fitting = np.abs(fitting_bins_remain_cap - item) < epsilon\n    priorities[can_fit_mask][exact_fit_mask_for_fitting] = 1.0\n\n    # For bins that can fit but are not exact fits, use a sigmoid score\n    # that favors bins with less remaining capacity (tighter fit).\n    # The metric is `item / remaining_capacity`. Closer to 1 is better.\n    # We use `sigmoid(k * (item / remaining_capacity - 1))`\n    # k controls the steepness. We choose a moderate k.\n    # We need to apply this only to bins that are not exact fits.\n    non_exact_fit_mask_for_fitting = ~exact_fit_mask_for_fitting\n\n    if np.any(non_exact_fit_mask_for_fitting):\n        non_exact_fitting_capacities = fitting_bins_remain_cap[non_exact_fit_mask_for_fitting]\n        \n        # Calculate the tightness ratio: item size / remaining capacity.\n        # A higher ratio indicates a tighter fit.\n        tightness_ratio = item / (non_exact_fitting_capacities + epsilon)\n\n        # Sigmoid function to map the tightness ratio to a priority score between 0 and 1.\n        # The formula `1 / (1 + exp(-k * (ratio - 1)))` peaks around ratio=1.\n        # A k=5.0 makes the sigmoid relatively steep, favoring capacities closer to item size.\n        k = 5.0\n        sigmoid_priorities = 1 / (1 + np.exp(-k * (tightness_ratio - 1)))\n        \n        # Assign these priorities to the corresponding original bins\n        priorities[can_fit_mask][non_exact_fit_mask_for_fitting] = sigmoid_priorities\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 159.81495041679716,
    "exec_success": true
  }
]