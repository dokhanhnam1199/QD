{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a modified Best Fit strategy.\n    This version prioritizes bins that have just enough space for the item, and among those,\n    prefers bins that will have the least remaining capacity after packing.\n    It also introduces a slight preference for bins that have been used less (i.e., higher remaining capacity)\n    if no \"perfect fit\" is found, to encourage better space utilization over time.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    remaining_capacities_after_packing = suitable_bins_caps - item\n\n    # Identify bins that are a \"perfect fit\" or very close\n    # A small tolerance is introduced to capture bins that are \"almost\" a perfect fit\n    tolerance = 1e-6\n    perfect_fit_mask = np.abs(remaining_capacities_after_packing) < tolerance\n\n    if np.any(perfect_fit_mask):\n        # Among perfect fits, prefer those with the absolute minimum remaining capacity (which is close to zero)\n        # This is essentially Best Fit for perfect fits.\n        min_remaining_cap_among_perfect = np.min(remaining_capacities_after_packing[perfect_fit_mask])\n        best_fit_perfect_mask = (suitable_bins_caps - item == min_remaining_cap_among_perfect)\n\n        # Map back to original indices\n        original_indices_perfect = np.where(suitable_bins_mask)[0][best_fit_perfect_mask]\n        priorities[original_indices_perfect] = 2.0 # Highest priority\n\n    else:\n        # If no perfect fit, fall back to a modified Best Fit strategy.\n        # Prioritize bins that leave the least remaining capacity, but not too much.\n        # We'll give a higher score to bins that have a small remaining capacity after packing,\n        # but not so small that it's completely unusable for future small items.\n        # The score is inversely related to the remaining capacity after packing.\n        # To avoid extreme values, we use a scaled inverse.\n        min_remaining_cap_overall = np.min(remaining_capacities_after_packing)\n        \n        # Assign scores based on how close the remaining capacity is to the minimum\n        # Higher score for bins that are closer to the minimum remaining capacity\n        scores_for_suitable = 1.0 / (1.0 + remaining_capacities_after_packing - min_remaining_cap_overall)\n        \n        # Normalize scores to be between 0 and 1\n        max_score = np.max(scores_for_suitable)\n        min_score = np.min(scores_for_suitable)\n        if max_score > min_score:\n            normalized_scores = (scores_for_suitable - min_score) / (max_score - min_score)\n        else:\n            normalized_scores = np.ones_like(scores_for_suitable) * 0.5 # Assign a neutral score if all are equal\n\n        # Map back to original indices\n        original_indices_suitable = np.where(suitable_bins_mask)[0]\n        priorities[original_indices_suitable] = normalized_scores\n        \n        # Ensure perfect fits (if any were missed by tolerance) still get top priority\n        if np.any(np.abs(remaining_capacities_after_packing) < tolerance):\n            min_remaining_cap_close_to_zero = np.min(remaining_capacities_after_packing[np.abs(remaining_capacities_after_packing) < tolerance])\n            best_fit_close_mask = (suitable_bins_caps - item == min_remaining_cap_close_to_zero)\n            original_indices_close = np.where(suitable_bins_mask)[0][best_fit_close_mask]\n            priorities[original_indices_close] = np.maximum(priorities[original_indices_close], 1.5) # Boost priority\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a\n    modified Best Fit strategy that also considers the \"tightness\" of the fit\n    and the potential for future packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Calculate the remaining capacity after placing the item\n    remaining_after_fit = suitable_bins_remain_cap - item\n    \n    # Heuristic 1: Prioritize bins where the item fits snugly (minimizing waste in this bin)\n    # We use a value that is inversely proportional to the remaining capacity after fitting.\n    # Add a small epsilon to avoid division by zero if remaining_after_fit is 0.\n    snug_fit_scores = 1.0 / (remaining_after_fit + 1e-9)\n\n    # Heuristic 2: Prioritize bins that will have more remaining capacity AFTER the item is placed.\n    # This can be useful if we anticipate packing larger items later and want to reserve\n    # larger bins, or if we want to keep bins with moderate remaining capacity.\n    # Let's give a slight bonus to bins that will have a medium amount of remaining capacity.\n    # A simple way is to give a higher score to bins whose remaining capacity is closer to the median.\n    # Or, a simpler approach: prioritize bins that leave a \"good amount\" of space, but not too much.\n    # Let's try to penalize bins that become nearly empty or still very large.\n    # We can use a Gaussian-like function centered around a 'desirable' remaining capacity.\n    # For simplicity here, let's consider leaving a moderate amount of space as good.\n    # We can map remaining_after_fit to a score where middle values are higher.\n    # A simple approach: score = 1 - (x - target)^2 / range^2.\n    # Let's assume a target remaining capacity is around half of the bin's original capacity,\n    # but this is complex as we don't know original capacity.\n    # A simpler heuristic: prioritize bins that leave a moderate amount of space,\n    # e.g., not too close to 0 and not too close to the original capacity.\n    # Let's consider bins that leave remaining capacity between 10% and 50% of the *item size* as moderately good.\n    # This is a bit ad-hoc but aims to keep bins that are neither too full nor too empty for the current item.\n    moderate_space_scores = np.zeros_like(suitable_bins_remain_cap)\n    lower_bound = item * 0.1\n    upper_bound = item * 0.5\n    \n    valid_moderate_mask = (remaining_after_fit >= lower_bound) & (remaining_after_fit <= upper_bound)\n    moderate_space_scores[valid_moderate_mask] = 1.0\n    \n    # Combine scores: A weighted sum or a simple addition might work.\n    # Let's try a weighted sum. The snug fit is often the primary goal in BPP.\n    # We can add the moderate space score as a secondary factor.\n    combined_scores = snug_fit_scores + 0.2 * moderate_space_scores # Weighting snug fit more\n\n    # Normalize scores to be between 0 and 1 (optional, but good for consistent priority interpretation)\n    if np.max(combined_scores) > 0:\n        normalized_scores = combined_scores / np.max(combined_scores)\n    else:\n        normalized_scores = combined_scores\n\n    # Assign priorities to the original array\n    priorities[suitable_bins_mask] = normalized_scores\n\n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 vs 8 (and 2, 4, 10, 14, 17, 18, 20):** Heuristic 1 (Exact Fit, then Best Fit with penalty) is more direct and explicit about its prioritization. Heuristics 2, 4, 8, 10, 14, 17, 20 use sigmoid or exponential functions to model \"tightness\" or \"moderate fit\". While potentially more nuanced, they are less interpretable and rely on tuned parameters (`scaling_factor`, `steepness`, `k`). Heuristic 1's clear hierarchy of Exact Fit > Best Fit is generally a strong and understandable strategy.\n*   **Heuristics 1 vs 3:** Heuristic 1 uses a distinct highest priority (1.0) for exact fits and then scales other fits. Heuristic 3 uses a higher priority (2.0) for exact fits, which is a clearer way to denote absolute preference. However, Heuristic 1's approach of using 1.0 for exact fits and then scaling others below that is also valid. Heuristic 3's score for non-exact fits (`1.0 / (difference + 1e-9)`) can lead to very high priorities for very small differences, potentially more volatile than Heuristic 1's approach.\n*   **Heuristics 1 vs 5 & 6 (and 9):** Heuristics 5, 6, and 9 introduce a secondary criterion (favoring bins that are less empty). Heuristic 1 prioritizes tightest fits after exact fits. The introduction of secondary criteria adds complexity and tunable parameters (like the scaling for non-best-fit bins) that might not always be beneficial. Heuristic 1's focused approach is simpler.\n*   **Heuristics 1 vs 7 & 9:** Heuristics 7 and 9 attempt to refine Best Fit by penalizing \"too full\" bins or by favoring a peak at a moderate remaining capacity (`r_after * exp(-k*r_after)`). While these are interesting \"outside the box\" ideas, they introduce more parameters (`tolerance`, `k`, `weights`, `tightness_threshold_factor`) and are less straightforward than Heuristic 1's clear Best Fit logic.\n*   **Heuristics 1 vs 13 (First Fit):** Heuristic 1 (Best Fit) is generally considered better than First Fit for minimizing the number of bins, as it makes more informed local decisions. Heuristic 13 is a basic implementation of First Fit and doesn't use priority scores in a way that allows for selection among multiple fitting bins.\n*   **Heuristics 1 vs 15 & 17:** Heuristics 15 and 17 combine exact fit (1.0) with a sigmoid score for tight fits. The sigmoid approach (`1 / (1 + exp(-k * (ratio - 1)))`) aims to penalize larger bins. Heuristic 1's approach is simpler: exact fits first, then pure Best Fit (implicitly, by penalizing bins that cannot fit). The sigmoid adds complexity with the `k` parameter.\n*   **Heuristics 1 vs 16 & 20:** Heuristics 16 and 20 use a multi-component scoring system (tightness, anti-tightness, fullness preference) with weights. This is significantly more complex and parameter-dependent than Heuristic 1.\n*   **Heuristics 1 vs 18:** Heuristic 18 combines exact fit (1.0) with inverse remaining capacity, scaled. It also assigns a low priority to unsuitable bins. Heuristic 1's explicit penalty for unsuitable bins (implicitly by assigning 0 priority) and its clear two-tier Best Fit logic make it more understandable.\n*   **Overall:** Heuristic 1 stands out for its clarity, simplicity, and effective combination of two strong strategies (Exact Fit First and Best Fit). It avoids complex, tunable functions or multi-component scores, making it a robust and easy-to-understand heuristic. The other heuristics introduce complexity (sigmoid, multi-factor scoring, peak functions) often tied to specific tunable parameters or less direct logic.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Robustness, Interpretability, Explicit Penalties, Logical Hierarchy.\n*   **Advice:** Focus on intuitive, rule-based strategies. Define a clear, prioritized sequence of simple objectives. Implement explicit checks and penalties for invalid or suboptimal choices.\n*   **Avoid:** Complex, opaque mathematical functions without empirical validation. Arbitrary weighting or blending of criteria. Mimicking sequential logic through static scores.\n*   **Explanation:** Simpler heuristics are easier to debug, adapt, and understand, leading to more reliable performance across diverse problem instances. Explicitly addressing constraints and undesirable states through penalties makes the heuristic's behavior predictable.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}