[
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits, then bins with least remaining capacity using a graded scale.\n\n    Combines the explicit prioritization of exact fits (score 2.0) from priority_v0\n    with a graded penalty for non-exact fits based on the difference, aiming for\n    a balanced Best Fit approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Bins where the item can fit exactly\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 2.0  # Highest priority for exact fits\n\n    # Bins where the item can fit but not exactly\n    fit_mask = bins_remain_cap > item\n    \n    # Calculate priority for bins that can fit but not exactly.\n    # Prioritize bins with smaller remaining capacity (tighter fit).\n    # A higher score indicates a better (tighter) fit.\n    # The score is inversely proportional to the remaining capacity after fitting.\n    # Add epsilon to avoid division by zero.\n    difference = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (difference + 1e-9)\n\n    # Ensure exact fits still have the highest priority if they also satisfy fit_mask\n    priorities[exact_fit_mask] = np.maximum(priorities[exact_fit_mask], 2.0)\n    \n    return priorities",
    "response_id": 2,
    "tryHS": true,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    The First Fit strategy prioritizes bins that have just enough capacity\n    to fit the item, aiming to leave larger remaining capacities in other bins\n    for potentially larger future items.\n    A higher priority score indicates a better fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Bins where the item can fit\n    fit_mask = bins_remain_cap >= item\n    \n    # Calculate the difference between remaining capacity and item size for fitting bins\n    # A smaller difference means a \"tighter\" fit, which is preferred by First Fit.\n    # We use the inverse of the difference to make it a maximization problem.\n    # Add a small epsilon to avoid division by zero for exact fits.\n    priorities[fit_mask] = 1.0 / (bins_remain_cap[fit_mask] - item + 1e-9)\n    \n    # Bins where the item does not fit get a priority of 0\n    # This is already handled by np.zeros_like, but explicitly for clarity in logic\n    priorities[~fit_mask] = 0.0\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 51.80615605397529,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    if np.any(suitable_bins_mask):\n        remaining_capacities = bins_remain_cap[suitable_bins_mask] - item\n        min_remaining_capacity = np.min(remaining_capacities)\n        best_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap - item == min_remaining_capacity)\n        priorities[best_fit_mask] = 1.0\n    return priorities",
    "response_id": 1,
    "tryHS": true,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 62.26976913547136,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    if valid_bins_remain_cap.size > 0:\n        gaps = valid_bins_remain_cap - item\n        priorities[can_fit_mask] = -gaps\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 36.541209043760986,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic: Prioritize bins where the item fits exactly.\n    If no exact fit, then prioritize the bin with the smallest remaining capacity\n    that can still accommodate the item (Best Fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    \n    if len(exact_fit_indices) > 0:\n        priorities[exact_fit_indices] = 1.0\n    else:\n        possible_bins = np.where(bins_remain_cap >= item)[0]\n        if len(possible_bins) > 0:\n            relevant_capacities = bins_remain_cap[possible_bins]\n            best_fit_index_in_possible = np.argmin(relevant_capacities)\n            best_fit_original_index = possible_bins[best_fit_index_in_possible]\n            priorities[best_fit_original_index] = 1.0\n    \n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 36.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = 1.0  # Give priority to bins that can fit the item\n        else:\n            priorities[i] = 0.0  # No priority for bins that cannot fit the item\n    \n    # In First Fit, we iterate through bins in order and pick the first one that fits.\n    # To simulate this priority, we want to give higher priority to earlier bins if they fit.\n    # We can achieve this by making the priority score dependent on the bin's index.\n    # A simple way is to add a small decreasing value based on the index.\n    # However, the standard First Fit doesn't explicitly use priority scores in this way;\n    # it's more of a sequential search. For the purpose of this function signature,\n    # we'll just mark bins that can fit. If multiple can fit, the selection logic\n    # outside this function would need to pick the first one.\n    #\n    # A true \"priority\" that mimics FF selection might be complex within this\n    # function signature if it's meant to return scores to be maxed.\n    # If the intention is for this function to directly return which bin to pick,\n    # a different approach would be needed.\n    #\n    # Given the structure, the simplest interpretation that *hints* at FF is\n    # to give a higher score to the *first* available bin.\n    \n    first_available_index = -1\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            first_available_index = i\n            break\n            \n    if first_available_index != -1:\n        priorities[first_available_index] = 1.0 + (len(bins_remain_cap) - 1 - first_available_index) * 0.001 # Slightly higher priority for earlier bins\n        \n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 6.0,
    "halstead": 100.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_capacity = bins_remain_cap[i]\n            if remaining_capacity - item == 0:\n                priorities[i] = 1.0 / (remaining_capacity - item + 1e-9)\n            else:\n                priorities[i] = 1.0 / (remaining_capacity - item)\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 93.76537429460444,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate how well each bin can fit the item\n    # A smaller remaining capacity relative to the item size is better\n    # We want to penalize bins that are too large, as they might be inefficient for this item\n    # We want to favor bins that are just right for the item, or slightly larger\n    \n    # Calculate the difference between remaining capacity and item size\n    diff = bins_remain_cap - item\n    \n    # Apply a sigmoid function to the difference.\n    # The sigmoid function will map values to a range between 0 and 1.\n    # We want higher scores for bins that have a 'good' fit.\n    # A good fit means the remaining capacity is slightly larger than the item,\n    # or just enough to fit the item.\n    # Let's map 'diff' such that values close to 0 (perfect fit) or slightly positive\n    # (a bit of slack) get higher scores.\n    # We can adjust the steepness of the sigmoid using a scaling factor.\n    # A larger scaling factor will make the sigmoid steeper, resulting in more\n    # distinct priorities for small differences.\n    \n    scaling_factor = 2.0 # Heuristic parameter to tune the steepness\n    \n    # We want to avoid negative arguments to the sigmoid for values where the item doesn't fit\n    # so we clip the values to be at least 0 before division.\n    # This means bins where remaining_cap < item will be treated similarly regarding their\n    # \"unsuitability\" from this metric, all getting very low priority.\n    \n    # Consider bins where the item *can* fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit, we want to prioritize those where the remaining capacity is\n    # close to the item size.\n    # A value of diff=0 (perfect fit) should ideally be near the center of the sigmoid's steep part.\n    # We can shift the input to the sigmoid by a small amount if needed, but let's start simply.\n    \n    # Let's use a logistic sigmoid function: L / (1 + exp(-k*(x-x0)))\n    # Where L is the maximum value (1), k is the steepness (scaling_factor),\n    # x is the input (diff), and x0 is the midpoint.\n    # If we set x0=0, then perfect fit (diff=0) will result in 1 / (1 + exp(0)) = 1/2.\n    # We want the highest score when diff is small and positive.\n    # Let's modify the function to center around 0 difference being optimal.\n    # Consider a transformation: -diff.\n    # Now a perfect fit (diff=0) becomes 0. A slight excess capacity (diff=1) becomes -1.\n    # A slight deficit (diff=-1) becomes 1. This is not quite right.\n    \n    # Let's consider the *relative* remaining capacity after fitting the item.\n    # If remaining_cap - item = 0, this is a perfect fit.\n    # If remaining_cap - item = positive, there's slack.\n    # If remaining_cap - item = negative, it doesn't fit.\n    \n    # We want to maximize the priority for `remaining_cap - item` being close to 0.\n    # Let's use a function that is symmetric around 0 and peaks at 0.\n    # A Gaussian-like shape could work, but sigmoid is requested.\n    \n    # Alternative interpretation for Sigmoid Fit Score:\n    # We want bins that are \"almost full\" but can still fit the item.\n    # This means `bins_remain_cap - item` should be small.\n    \n    # Let's try a sigmoid that maps small positive differences to high values,\n    # and larger positive differences to lower values.\n    # Also, bins that cannot fit the item should have very low priority.\n    \n    # We can use a sigmoid on a scaled version of `item / bins_remain_cap`.\n    # If `bins_remain_cap` is very large, `item / bins_remain_cap` is small.\n    # If `bins_remain_cap` is just slightly larger than `item`, `item / bins_remain_cap` is close to 1.\n    # If `bins_remain_cap` equals `item`, `item / bins_remain_cap` is 1.\n    \n    # Let's define a score that is high when `bins_remain_cap` is close to `item`.\n    # We can consider the inverse of the \"slack\": `item / bins_remain_cap`\n    # However, if `bins_remain_cap < item`, this ratio is > 1.\n    \n    # Let's stick to the idea of `bins_remain_cap - item`.\n    # We want a function f(x) where x = bins_remain_cap - item,\n    # such that f(0) is high, f(small_positive) is slightly lower,\n    # f(large_positive) is very low, and f(negative) is very low.\n    \n    # The sigmoid function `1 / (1 + exp(-k*x))` maps `x` to `(0, 1)`.\n    # If `x` is large positive, result is close to 1.\n    # If `x` is large negative, result is close to 0.\n    # If `x` is 0, result is 0.5.\n    \n    # We want a peak at `x=0`.\n    # Consider `1 / (1 + exp(-k * |x|))` - this peaks at 1 for x=0 but is symmetric.\n    # Consider `exp(-k * x^2)` - Gaussian.\n    \n    # Let's try to use sigmoid in a way that penalizes large remaining capacities.\n    # For bins where `bins_remain_cap >= item`:\n    # We want to maximize the priority as `bins_remain_cap` gets closer to `item`.\n    # Let's map `bins_remain_cap` to a value that is small when it's much larger than `item`.\n    # Consider `bins_remain_cap / (item + epsilon)`.\n    # If `bins_remain_cap = item`, this is 1.\n    # If `bins_remain_cap = 2*item`, this is 2.\n    # If `bins_remain_cap = 0.5*item`, this is 0.5 (but this case is invalid as item won't fit).\n    \n    # Let's consider `1 - sigmoid(k * (bins_remain_cap - item))` for bins where item fits.\n    # If `bins_remain_cap = item`, `diff = 0`, `sigmoid(0) = 0.5`, `1 - 0.5 = 0.5`.\n    # If `bins_remain_cap = item + delta` (delta small positive), `diff = delta`.\n    # `sigmoid(k * delta)` > 0.5, so `1 - sigmoid(...)` < 0.5. This is not what we want.\n    \n    # Let's use a sigmoid to represent \"goodness of fit\" as being close to 1.\n    # Let's scale `item` to be within some range and then use sigmoid.\n    \n    # Consider a transformation on the *unused space*: `unused_space = bins_remain_cap - item`\n    # We want to maximize priority when `unused_space` is small and non-negative.\n    # Let's map `unused_space` to a score.\n    # A small non-negative `unused_space` should yield a high score.\n    # A large positive `unused_space` should yield a low score.\n    # A negative `unused_space` (item doesn't fit) should yield a very low score.\n    \n    # Let's try `sigmoid(scaling_factor * (item - bins_remain_cap))`.\n    # If `item = bins_remain_cap` (diff=0), `sigmoid(0) = 0.5`.\n    # If `item = bins_remain_cap - delta` (slack=delta), `sigmoid(-delta * k)` < 0.5. We want high.\n    # If `item = bins_remain_cap + delta` (deficit=delta), `sigmoid(delta * k)` > 0.5. We want low.\n    \n    # The inverse of the previous idea: `sigmoid(scaling_factor * (bins_remain_cap - item))`\n    # If `bins_remain_cap = item` (diff=0), `sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta` (slack=delta), `sigmoid(delta * k)` > 0.5. High is good.\n    # If `bins_remain_cap = item - delta` (deficit=delta), `sigmoid(-delta * k)` < 0.5. Low is good.\n    \n    # This seems to be the most promising approach: higher scores for more remaining capacity,\n    # but we need to make it so that it penalizes *excessive* remaining capacity.\n    \n    # Let's scale the remaining capacity relative to the bin size if we knew it, or relative to item.\n    # If `bins_remain_cap` is much larger than `item`, we might want a lower score.\n    \n    # Consider the quantity `bins_remain_cap / item`.\n    # If `bins_remain_cap = item`, ratio = 1.\n    # If `bins_remain_cap = 2 * item`, ratio = 2.\n    # If `bins_remain_cap < item`, ratio < 1.\n    \n    # We want a peak when `bins_remain_cap` is slightly larger than `item`.\n    # Let's define `score = bins_remain_cap - item`. We want to maximize score near 0.\n    \n    # We can use a sigmoid applied to a scaled version of `item - bins_remain_cap`.\n    # This is equivalent to `1 - sigmoid(scaling_factor * (bins_remain_cap - item))`.\n    # `1 - sigmoid(x)` is `1 / (1 + exp(-x))`. This is a sigmoid shifted and inverted.\n    # Let `y = bins_remain_cap - item`.\n    # If `y=0`, `1 - sigmoid(0) = 0.5`.\n    # If `y` is small positive (slack), `1 - sigmoid(positive_k*y)` < 0.5. Not good.\n    \n    # Let's use `sigmoid(k * (item - bins_remain_cap))`\n    # If `item == bins_remain_cap`: score is 0.5\n    # If `item < bins_remain_cap`: item - bin_rem_cap < 0. sigmoid(<0) < 0.5. Score is lower.\n    # If `item > bins_remain_cap`: item - bin_rem_cap > 0. sigmoid(>0) > 0.5. Score is higher.\n    # This means we prefer bins that are too small. Not correct.\n    \n    # The common \"sigmoid fit\" for bin packing often refers to prioritizing bins that are \"tight fits\".\n    # A tight fit means the remaining capacity is close to the item size.\n    \n    # Let's try to create a score that is high when `bins_remain_cap` is approximately equal to `item`.\n    # Consider `sigmoid(k * (1 - bins_remain_cap / item))` if item is not zero.\n    # This is undefined if item is zero. Also division by zero if bins_remain_cap is zero.\n    \n    # Let's use the absolute difference and invert it.\n    # `score = -abs(bins_remain_cap - item)`\n    # Then apply sigmoid to this negated difference.\n    # `sigmoid(k * -abs(bins_remain_cap - item))`\n    # This peaks at 0.5 when `abs(bins_remain_cap - item) = 0`.\n    # It goes down to 0 as `abs(...)` increases.\n    # This looks like a good candidate for \"tight fit\".\n    \n    # However, we must ensure the item fits.\n    # We can set priorities to a very low value (e.g., 0) for bins where `bins_remain_cap < item`.\n    \n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit, calculate the priority using the sigmoid of the negated absolute difference\n    # between remaining capacity and item size.\n    # We scale the difference to control the steepness of the priority curve.\n    # A larger `steepness` means we strongly favor bins that are closer fits.\n    steepness = 5.0  # Tune this parameter. Higher means more sensitive to small differences.\n    \n    # Calculate `bins_remain_cap - item`. If this is very large, we want low priority.\n    # Let's apply sigmoid to `item - bins_remain_cap` and ensure it's capped for non-fitting bins.\n    \n    # Consider the ratio of remaining capacity to the item size.\n    # `ratio = bins_remain_cap / item`\n    # If ratio is 1 (perfect fit), we want high priority.\n    # If ratio is slightly > 1 (slack), priority should be slightly lower.\n    # If ratio is much > 1 (large slack), priority should be much lower.\n    # If ratio is < 1 (item doesn't fit), priority should be minimal.\n    \n    # Let's use `1 / (1 + exp(-k * (1 - bins_remain_cap / item)))`. This peaks when `bins_remain_cap / item = 1`.\n    # When `bins_remain_cap / item = 1`: `1 / (1 + exp(0)) = 0.5`.\n    # When `bins_remain_cap / item = 2`: `1 / (1 + exp(-k))`. Lower than 0.5 if k>0.\n    # When `bins_remain_cap / item = 0.5`: `1 / (1 + exp(k/2))`. Lower than 0.5.\n    # This seems to correctly penalize bins that are too small or too large, peaking at a perfect fit.\n    \n    # Handle division by zero if item is 0. Assume item size is always positive.\n    # Handle cases where `bins_remain_cap` might be zero or very small for the ratio.\n    \n    # Let's use a robust calculation for the ratio, ensuring we don't divide by zero\n    # and handle cases where bins_remain_cap is very small or zero.\n    \n    # `fit_metric = bins_remain_cap - item`\n    # We want to maximize `f(fit_metric)` where `f(0)` is max, `f(positive)` decreases, `f(negative)` is minimal.\n    \n    # Let's scale `item` and `bins_remain_cap` relative to each other in a sigmoid.\n    # Consider `sigmoid(k * (item - bins_remain_cap))`.\n    # If `bins_remain_cap` is large, `item - bins_remain_cap` is large negative. Sigmoid is near 0.\n    # If `bins_remain_cap` is small (but >= item), `item - bins_remain_cap` is small positive. Sigmoid is near 0.5 to 1.\n    # If `bins_remain_cap == item`, `item - bins_remain_cap = 0`. Sigmoid is 0.5.\n    \n    # This means `sigmoid(k * (bins_remain_cap - item))` is better.\n    # `bins_remain_cap = item` => 0.5\n    # `bins_remain_cap = item + delta` => sigmoid(k*delta) > 0.5\n    # `bins_remain_cap = item - delta` => sigmoid(-k*delta) < 0.5\n    \n    # This favors bins that are larger. To favor tighter fits, we need to penalize large remaining capacities.\n    \n    # Let's try sigmoid on the \"emptiness ratio\": `(bins_remain_cap - item) / bin_capacity` is not possible.\n    # Let's scale `bins_remain_cap` relative to `item` but ensure the output makes sense.\n    \n    # If `bins_remain_cap` is slightly larger than `item`, we want high priority.\n    # If `bins_remain_cap` is much larger than `item`, we want lower priority.\n    # If `bins_remain_cap` is exactly `item`, we want high priority.\n    \n    # Consider `1 - sigmoid(k * (bins_remain_cap - item))`.\n    # `bins_remain_cap = item`: 1 - 0.5 = 0.5\n    # `bins_remain_cap = item + delta`: 1 - sigmoid(k*delta) < 0.5\n    # `bins_remain_cap = item - delta`: 1 - sigmoid(-k*delta) > 0.5\n    \n    # This seems to favor bins that are just fitting or slightly undersized. Still not right.\n    \n    # Let's try a reversed sigmoid on the \"excess capacity\".\n    # `excess_capacity = bins_remain_cap - item`\n    # We want to minimize `excess_capacity` for `excess_capacity >= 0`.\n    # Apply `1 - sigmoid(k * excess_capacity)`\n    # If `excess_capacity = 0`: 1 - 0.5 = 0.5\n    # If `excess_capacity = delta` (small positive): 1 - sigmoid(k*delta) < 0.5\n    # If `excess_capacity = D` (large positive): 1 - sigmoid(k*D) -> 1 - 1 = 0.\n    # If `excess_capacity = -delta` (item doesn't fit): 1 - sigmoid(-k*delta) > 0.5. This is problematic.\n    \n    # We must ensure `bins_remain_cap >= item` for non-zero priorities.\n    \n    # Final attempt strategy:\n    # Calculate a score representing how close `bins_remain_cap` is to `item`,\n    # penalizing bins that have too much excess capacity.\n    # Use `sigmoid(k * (item - (bins_remain_cap - epsilon)))`\n    # Where epsilon is a small value to slightly prefer bins with some remaining capacity over exact fits.\n    # This is still tricky to get the exact desired behavior with a simple sigmoid.\n    \n    # A common \"sigmoid fit\" heuristic: prioritize bins where `bins_remain_cap` is closest to `item`.\n    # This can be modeled by `sigmoid(-k * abs(bins_remain_cap - item))`.\n    # This is symmetric around `bins_remain_cap = item`, peaking at 0.5.\n    \n    # Let's combine the \"can fit\" condition with this.\n    \n    # Calculate priorities for bins that can fit the item\n    diff_from_ideal = bins_remain_cap[can_fit_mask] - item\n    \n    # Use sigmoid on the negative of the absolute difference.\n    # This gives highest priority (close to 1) for diff = 0, and decreases as diff grows.\n    # We want to penalize large remaining capacity.\n    # Let's consider the inverse of the remaining capacity ratio: `item / bins_remain_cap`.\n    # For bins that fit:\n    # if `bins_remain_cap` is `item`, ratio is 1.\n    # if `bins_remain_cap` is `item + delta`, ratio is `item / (item + delta) < 1`.\n    # if `bins_remain_cap` is `2*item`, ratio is `0.5`.\n    \n    # We want high priority when `bins_remain_cap` is just slightly larger than `item`.\n    # So, when `item / bins_remain_cap` is close to 1 but slightly less than 1.\n    \n    # Let's use `sigmoid(k * (1 - bins_remain_cap / item))`.\n    # This implies `bins_remain_cap / item < 1`.\n    \n    # A more direct approach for Sigmoid Fit:\n    # Prioritize bins where the remaining capacity `R` satisfies `item <= R < some_threshold`.\n    # And within that, prefer smaller `R`.\n    \n    # Let's try `sigmoid(k * (item - (bins_remain_cap - small_buffer)))`\n    # If `bins_remain_cap = item`, `sigmoid(k * (item - (item))) = sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta` (small positive slack), `sigmoid(k * (item - (item + delta))) = sigmoid(-k*delta) < 0.5`.\n    # This is not what we want.\n    \n    # How about: `sigmoid(k * (bins_remain_cap / item))` for bins that fit?\n    # If `bins_remain_cap = item`, sigmoid(k).\n    # If `bins_remain_cap = 2*item`, sigmoid(2k). Higher priority for larger bins. Wrong.\n    \n    # Let's try the inverted ratio, scaled:\n    # `sigmoid(k * (item - bins_remain_cap))`\n    # `bins_remain_cap = item`: sigmoid(0) = 0.5\n    # `bins_remain_cap = item + delta`: sigmoid(-k*delta) < 0.5\n    # `bins_remain_cap = item - delta`: sigmoid(k*delta) > 0.5\n    # This prioritizes bins that are undersized.\n    \n    # It seems the core idea for \"Sigmoid Fit\" should capture \"tightness\".\n    # The `sigmoid(k * (item - residual_capacity))` where `residual_capacity` is the capacity *after* placing the item,\n    # i.e., `bins_remain_cap - item`.\n    # Let `residual = bins_remain_cap - item`.\n    # We want to maximize `sigmoid(k * (item - residual))` or `sigmoid(k * (item - (bins_remain_cap - item)))`.\n    # This is `sigmoid(k * (2*item - bins_remain_cap))`.\n    \n    # Let's test `sigmoid(k * (2*item - bins_remain_cap))` for fitting bins.\n    # If `bins_remain_cap = item`: `sigmoid(k * (2*item - item)) = sigmoid(k*item)`. High if k*item is large.\n    # If `bins_remain_cap = item + delta`: `sigmoid(k * (2*item - (item + delta))) = sigmoid(k * (item - delta))`. Lower than previous.\n    # If `bins_remain_cap = 2*item`: `sigmoid(k * (2*item - 2*item)) = sigmoid(0) = 0.5`.\n    \n    # This means higher priority for bins that are smaller than 2*item and closer to item.\n    # But it penalizes bins that are exactly item size if item is small.\n    \n    # A simpler form of Sigmoid Fit could be focusing on the ratio of item size to remaining capacity.\n    # We want this ratio to be close to 1.\n    # Let's consider `item / bins_remain_cap` for bins that fit.\n    # If `bins_remain_cap = item`: ratio = 1.\n    # If `bins_remain_cap = item + delta`: ratio = `item / (item + delta) < 1`.\n    # If `bins_remain_cap = 2*item`: ratio = 0.5.\n    \n    # We want high priority when `item / bins_remain_cap` is close to 1.\n    # Use `sigmoid(k * (1 - item / bins_remain_cap))`\n    # If `item / bins_remain_cap = 1`: sigmoid(0) = 0.5.\n    # If `item / bins_remain_cap = 0.9`: sigmoid(k * 0.1) > 0.5. High priority.\n    # If `item / bins_remain_cap = 0.5`: sigmoid(k * 0.5) >> 0.5. Very high priority.\n    # This seems to prefer bins where the item fills a large proportion of the bin, even if `bins_remain_cap` is large.\n    \n    # Let's try this: prioritize bins where `bins_remain_cap` is close to `item`.\n    # Use `sigmoid(k * (item - abs(bins_remain_cap - item)))`. This is problematic.\n    \n    # Focus on `bins_remain_cap - item`. We want this to be small and positive.\n    # Let `slack = bins_remain_cap - item`.\n    # Prioritize bins where `slack` is small.\n    # `sigmoid(k * (1 - slack))` ?\n    # If slack=0, sigmoid(k).\n    # If slack=small_positive, sigmoid(k * (1-small)) < sigmoid(k). Lower priority. This is not desired.\n    \n    # Let's use a negative exponential on slack. `exp(-k * slack)`.\n    # If slack=0, exp(0)=1.\n    # If slack=small_positive, exp(-k*small_positive) < 1. Lower priority.\n    # If slack=large_positive, exp(-k*large_positive) -> 0.\n    # This is good for prioritizing tight fits.\n    \n    # Let's wrap `exp(-k * slack)` with a sigmoid to keep values in (0, 1) or to control the curve.\n    # This would be `sigmoid(k_outer * (exp(-k_inner * slack) - midpoint))`.\n    \n    # A more direct approach from literature on Sigmoid Fit:\n    # Prioritize bins where `bins_remain_cap` is just enough to fit the item.\n    # This means `bins_remain_cap` is NOT much larger than `item`.\n    \n    # Let's define priority based on `item / bins_remain_cap` for bins that can fit.\n    # `bins_remain_cap >= item`\n    # If `bins_remain_cap = item`, ratio = 1.\n    # If `bins_remain_cap = 2*item`, ratio = 0.5.\n    # If `bins_remain_cap = 1.1*item`, ratio = `item / (1.1*item) = 1/1.1 approx 0.909`.\n    \n    # We want to favor ratios close to 1.\n    # Consider `sigmoid(k * (bins_remain_cap / item - 1))`\n    # If `bins_remain_cap = item`: sigmoid(0) = 0.5.\n    # If `bins_remain_cap = item + delta`: sigmoid(k * (delta/item)) > 0.5. Higher priority for larger remaining bins.\n    \n    # Let's try the inverse: `sigmoid(k * (1 - bins_remain_cap / item))`\n    # If `bins_remain_cap = item`: sigmoid(0) = 0.5.\n    # If `bins_remain_cap = item + delta`: sigmoid(k * (1 - (item+delta)/item)) = sigmoid(k * (1 - (1 + delta/item))) = sigmoid(-k * delta/item) < 0.5. Lower priority for larger remaining bins.\n    # If `bins_remain_cap = item - delta` (item doesn't fit properly, so we should exclude these): This ratio is > 1.\n    \n    # So, the formula `sigmoid(k * (1 - bins_remain_cap / item))` correctly prioritizes bins that are closer to the item size, penalizing larger bins.\n    \n    # Handle `item == 0` and `bins_remain_cap == 0`. Assume item > 0.\n    # Need to be careful with division by `item` if `item` is zero, or very small.\n    # Also careful if `bins_remain_cap` is zero or very small.\n    \n    # Let's define a small epsilon for numerical stability and to avoid division by zero.\n    epsilon = 1e-9\n    \n    # Calculate priorities for bins that can fit the item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Compute the 'tightness' metric: item size divided by remaining capacity.\n    # Higher value means a tighter fit.\n    # Add epsilon to denominator to prevent division by zero.\n    tightness_ratio = item / (fitting_bins_remain_cap + epsilon)\n    \n    # Apply sigmoid to a transformed tightness ratio.\n    # We want highest priority when `item / bins_remain_cap` is close to 1.\n    # Let's use `sigmoid(k * (1 - tightness_ratio))`.\n    # If `item == bins_remain_cap`: tightness_ratio = 1. `sigmoid(k * (1 - 1)) = sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta` (small positive slack): tightness_ratio < 1. `1 - tightness_ratio` is small positive. `sigmoid(k * small_positive) > 0.5`.\n    # This is penalizing tight fits and favoring larger bins. Incorrect.\n    \n    # Let's try `sigmoid(k * (tightness_ratio - 1))`.\n    # If `item == bins_remain_cap`: `sigmoid(0) = 0.5`.\n    # If `bins_remain_cap = item + delta`: `tightness_ratio < 1`. `tightness_ratio - 1` is negative. `sigmoid(k * negative) < 0.5`. This penalizes larger bins. CORRECT.\n    # If `bins_remain_cap = item - delta`: `tightness_ratio > 1`. `tightness_ratio - 1` is positive. `sigmoid(k * positive) > 0.5`. High priority for undersized bins. This is still problematic if not handled.\n    \n    # The `can_fit_mask` already handles the undersized bins by setting their priority to 0.\n    \n    # So, for fitting bins: `sigmoid(k * (item / (bins_remain_cap + epsilon) - 1))`\n    # With `k = steepness`.\n    \n    k = steepness # Use steepness as the scaling factor\n    \n    # Calculate the priority for fitting bins\n    priorities[can_fit_mask] = 1 / (1 + np.exp(-k * (item / (fitting_bins_remain_cap + epsilon) - 1)))\n    \n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 164.2332676057198,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priorities for placing an item into bins using a Softmax-Based Fit strategy.\n\n    The priority is higher for bins that have a remaining capacity greater than or equal to the item's size,\n    and among those, bins that have less remaining capacity (tighter fit) are preferred.\n    A small penalty is added to bins that cannot accommodate the item to ensure they receive a non-zero\n    but still lower priority.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array representing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element represents\n        the priority score for placing the item into the corresponding bin.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    unsuitable_bins_mask = ~suitable_bins_mask\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(suitable_bins_mask):\n        suitable_capacities = bins_remain_cap[suitable_bins_mask]\n        \n        inverted_capacities = 1.0 / (suitable_capacities - item + 1e-9)\n        \n        max_inverted_capacity = np.max(inverted_capacities)\n        \n        normalized_priorities = inverted_capacities / max_inverted_capacity\n        \n        priorities[suitable_bins_mask] = normalized_priorities\n\n    if np.any(unsuitable_bins_mask):\n        priorities[unsuitable_bins_mask] = 1e-6\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = capacity - item\n        else:\n            priorities[i] = -np.inf\n    \n    min_diff = np.min(priorities[priorities != -np.inf]) if np.any(priorities != -np.inf) else np.inf\n    \n    priorities[priorities != -np.inf] = min_diff - priorities[priorities != -np.inf]\n    \n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 118.02800258378572,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit prioritization with a scaled inverse of remaining capacity.\n    Prioritizes bins that perfectly fit the item. For other bins, it prioritizes\n    those with less remaining capacity, using an inverse relationship.\n    This aims to fill bins as tightly as possible, preferring exact fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Find bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity for bins that can fit\n    remaining_caps_for_fit = bins_remain_cap[can_fit_mask]\n    \n    # Calculate the difference for bins that can fit\n    diffs = remaining_caps_for_fit - item\n    \n    # Assign priorities:\n    # Highest priority for exact fits (difference is 0)\n    # For non-exact fits, use inverse of difference (smaller difference = higher priority)\n    # Add a small epsilon to avoid division by zero if exact fit logic fails\n    \n    # Calculate base priorities for bins that can fit\n    base_priorities = np.zeros_like(remaining_caps_for_fit, dtype=float)\n    \n    # Prioritize exact fits\n    exact_fit_mask = (diffs == 0)\n    base_priorities[exact_fit_mask] = 2.0  # High priority for exact fits\n    \n    # Prioritize bins with smallest remaining capacity among non-exact fits\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        # Use inverse of difference, scale it to avoid extremely large numbers\n        # Add epsilon for numerical stability and to differentiate from exact fits\n        priorities_for_non_exact = 1.0 / (diffs[non_exact_fit_mask] + 1e-9)\n        # Scale these priorities to be less than the exact fit priority\n        # A simple scaling could be to divide by the max of these non-exact priorities\n        max_non_exact_priority = np.max(priorities_for_non_exact)\n        if max_non_exact_priority > 0:\n            scaled_priorities = 1.0 + 0.5 * (priorities_for_non_exact / max_non_exact_priority)\n            base_priorities[non_exact_fit_mask] = scaled_priorities\n        else: # If all remaining are exact fits, this branch won't be hit but for completeness\n             base_priorities[non_exact_fit_mask] = 1.0\n\n    # Assign these calculated priorities back to the original priorities array\n    priorities[can_fit_mask] = base_priorities\n    \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 131.18329672565338,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priorities for placing an item into bins using a hybrid Best Fit and Softmax strategy.\n\n    Prioritizes bins with exact fits, then bins with the tightest fit.\n    Unsuitable bins receive a minimal priority.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    unsuitable_bins_mask = ~suitable_bins_mask\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(suitable_bins_mask):\n        suitable_capacities = bins_remain_cap[suitable_bins_mask]\n        \n        # Prioritize exact fits with highest score\n        exact_fit_mask = suitable_capacities == item\n        if np.any(exact_fit_mask):\n            priorities[suitable_bins_mask][exact_fit_mask] = 1.0\n        \n        # For other suitable bins, use inverted remaining capacity for tightest fit\n        non_exact_suitable_mask = suitable_bins_mask.copy()\n        non_exact_suitable_mask[suitable_bins_mask] = ~exact_fit_mask\n        \n        if np.any(non_exact_suitable_mask):\n            non_exact_capacities = bins_remain_cap[non_exact_suitable_mask]\n            \n            # Inverse of (capacity - item) for tightest fit, normalized\n            inverted_gaps = 1.0 / (non_exact_capacities - item + 1e-9)\n            \n            # Scale priorities to be between 0 and 1, favoring larger inverse_gaps (tighter fits)\n            max_inverted_gap = np.max(inverted_gaps)\n            normalized_priorities = inverted_gaps / max_inverted_gap\n            \n            # Assign scaled priorities to non-exact fitting bins\n            priorities[non_exact_suitable_mask] = normalized_priorities\n    \n    # Assign a very low priority to bins that cannot fit the item\n    if np.any(unsuitable_bins_mask):\n        priorities[unsuitable_bins_mask] = 1e-6\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 5.195452732349436,
    "cyclomatic_complexity": 5.0,
    "halstead": 91.73835003173087,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit First and Best Fit.\n    Prioritizes exact fits, then bins with minimal remaining capacity,\n    using a penalty for bins that cannot fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n\n    # Exact fit: highest priority\n    exact_fit_mask = (bins_remain_cap == item) & fit_mask\n    priorities[exact_fit_mask] = 1.0\n\n    # Best fit for remaining bins (those that fit but not exactly)\n    non_exact_fit_mask = fit_mask & ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        fitting_capacities = bins_remain_cap[non_exact_fit_mask]\n        gaps = fitting_capacities - item\n        min_gap = np.min(gaps)\n        \n        # Assign priorities based on the gap, higher for smaller gaps.\n        # Add a small offset to distinguish from exact fits and ensure positive.\n        best_fit_priorities = 0.9 - (gaps - min_gap) / (np.max(gaps) - min_gap + 1e-9)\n        \n        # Apply these priorities only to the bins that are non-exact fits\n        priorities[non_exact_fit_mask] = best_fit_priorities\n\n    # Penalize bins that cannot fit the item\n    no_fit_mask = ~fit_mask\n    priorities[no_fit_mask] = -1.0 # Effectively exclude them from selection\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 167.17882283189007,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on tight fit, favoring exact fits then closest fits.\n\n    Combines exact fit (priority 1.0) with a tight fit metric using sigmoid\n    on the inverse of remaining capacity relative to item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If there are no bins that can fit the item, return all zeros\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Prioritize exact fits with the highest score\n    exact_fit_mask_for_fitting = np.abs(fitting_bins_remain_cap - item) < epsilon\n    priorities[can_fit_mask][exact_fit_mask_for_fitting] = 1.0\n\n    # For bins that can fit but are not exact fits, use a sigmoid score\n    # that favors bins with less remaining capacity (tighter fit).\n    # The metric is `item / remaining_capacity`. Closer to 1 is better.\n    # We use `sigmoid(k * (item / remaining_capacity - 1))`\n    # k controls the steepness. We choose a moderate k.\n    # We need to apply this only to bins that are not exact fits.\n    non_exact_fit_mask_for_fitting = ~exact_fit_mask_for_fitting\n\n    if np.any(non_exact_fit_mask_for_fitting):\n        non_exact_fitting_capacities = fitting_bins_remain_cap[non_exact_fit_mask_for_fitting]\n        \n        # Calculate the tightness ratio: item size / remaining capacity.\n        # A higher ratio indicates a tighter fit.\n        tightness_ratio = item / (non_exact_fitting_capacities + epsilon)\n\n        # Sigmoid function to map the tightness ratio to a priority score between 0 and 1.\n        # The formula `1 / (1 + exp(-k * (ratio - 1)))` peaks around ratio=1.\n        # A k=5.0 makes the sigmoid relatively steep, favoring capacities closer to item size.\n        k = 5.0\n        sigmoid_priorities = 1 / (1 + np.exp(-k * (tightness_ratio - 1)))\n        \n        # Assign these priorities to the corresponding original bins\n        priorities[can_fit_mask][non_exact_fit_mask_for_fitting] = sigmoid_priorities\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 159.81495041679716,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a modified Best Fit strategy.\n    This version prioritizes bins that have just enough space for the item, and among those,\n    prefers bins that will have the least remaining capacity after packing.\n    It also introduces a slight preference for bins that have been used less (i.e., higher remaining capacity)\n    if no \"perfect fit\" is found, to encourage better space utilization over time.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    remaining_capacities_after_packing = suitable_bins_caps - item\n\n    # Identify bins that are a \"perfect fit\" or very close\n    # A small tolerance is introduced to capture bins that are \"almost\" a perfect fit\n    tolerance = 1e-6\n    perfect_fit_mask = np.abs(remaining_capacities_after_packing) < tolerance\n\n    if np.any(perfect_fit_mask):\n        # Among perfect fits, prefer those with the absolute minimum remaining capacity (which is close to zero)\n        # This is essentially Best Fit for perfect fits.\n        min_remaining_cap_among_perfect = np.min(remaining_capacities_after_packing[perfect_fit_mask])\n        best_fit_perfect_mask = (suitable_bins_caps - item == min_remaining_cap_among_perfect)\n\n        # Map back to original indices\n        original_indices_perfect = np.where(suitable_bins_mask)[0][best_fit_perfect_mask]\n        priorities[original_indices_perfect] = 2.0 # Highest priority\n\n    else:\n        # If no perfect fit, fall back to a modified Best Fit strategy.\n        # Prioritize bins that leave the least remaining capacity, but not too much.\n        # We'll give a higher score to bins that have a small remaining capacity after packing,\n        # but not so small that it's completely unusable for future small items.\n        # The score is inversely related to the remaining capacity after packing.\n        # To avoid extreme values, we use a scaled inverse.\n        min_remaining_cap_overall = np.min(remaining_capacities_after_packing)\n        \n        # Assign scores based on how close the remaining capacity is to the minimum\n        # Higher score for bins that are closer to the minimum remaining capacity\n        scores_for_suitable = 1.0 / (1.0 + remaining_capacities_after_packing - min_remaining_cap_overall)\n        \n        # Normalize scores to be between 0 and 1\n        max_score = np.max(scores_for_suitable)\n        min_score = np.min(scores_for_suitable)\n        if max_score > min_score:\n            normalized_scores = (scores_for_suitable - min_score) / (max_score - min_score)\n        else:\n            normalized_scores = np.ones_like(scores_for_suitable) * 0.5 # Assign a neutral score if all are equal\n\n        # Map back to original indices\n        original_indices_suitable = np.where(suitable_bins_mask)[0]\n        priorities[original_indices_suitable] = normalized_scores\n        \n        # Ensure perfect fits (if any were missed by tolerance) still get top priority\n        if np.any(np.abs(remaining_capacities_after_packing) < tolerance):\n            min_remaining_cap_close_to_zero = np.min(remaining_capacities_after_packing[np.abs(remaining_capacities_after_packing) < tolerance])\n            best_fit_close_mask = (suitable_bins_caps - item == min_remaining_cap_close_to_zero)\n            original_indices_close = np.where(suitable_bins_mask)[0][best_fit_close_mask]\n            priorities[original_indices_close] = np.maximum(priorities[original_indices_close], 1.5) # Boost priority\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 5.0,
    "halstead": 267.35288832599804,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a hybrid strategy:\n    Prioritize bins that are a \"tight fit\" (minimizing waste), but also consider\n    bins that have a moderate amount of remaining capacity to potentially accommodate\n    future larger items or to avoid creating many small, unusable spaces.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_capacities = bins_remain_cap[suitable_bins_mask]\n\n    # Strategy 1: Tight fit (Best Fit)\n    # Calculate remaining capacity if item is placed\n    remaining_after_fit = suitable_bins_capacities - item\n    min_remaining = np.min(remaining_after_fit)\n    tight_fit_mask_local = (suitable_bins_capacities - item) == min_remaining\n\n    # Strategy 2: Moderate capacity (to potentially fit larger items later)\n    # This is a bit heuristic, let's consider bins that have capacity\n    # roughly between the item size and the bin capacity, avoiding extreme\n    # both very full and very empty bins for this secondary score.\n    # We can normalize remaining capacities and assign a score.\n    # Let's define a \"good enough\" fit as having remaining capacity that is\n    # not too small (but not necessarily the absolute smallest) and not too large.\n    # A simple approach is to give higher priority to bins with remaining capacity\n    # that is closer to the item size, but not exactly the tightest fit.\n\n    # Calculate a \"wastefulness\" score for each suitable bin. Lower is better.\n    # We want to minimize (bin_capacity - item).\n    waste_score = suitable_bins_capacities - item\n\n    # Normalize waste score to be between 0 and 1 (where 0 is best).\n    # Avoid division by zero if all suitable bins have exactly item size capacity.\n    if np.max(waste_score) > 0:\n        normalized_waste_score = waste_score / np.max(waste_score)\n    else:\n        normalized_waste_score = np.zeros_like(waste_score)\n\n    # Create a composite score: prioritize tight fits, but give some boost\n    # to bins that are not excessively empty.\n    # We can use a function that gives higher values to smaller waste.\n    # For example, 1 / (1 + waste_score) or exp(-waste_score).\n    # Let's try a simpler approach: a weighted sum.\n    # High score for tightest fits, moderate score for other suitable bins.\n\n    # Assign a base score to all suitable bins.\n    base_priority = 0.1 # Small baseline for being suitable\n\n    # Boost the tightest fits.\n    priorities[suitable_bins_mask][tight_fit_mask_local] = 1.0\n\n    # For other suitable bins, assign a priority based on how much space is left.\n    # We want to prefer bins that leave less space, but not *too* little (which is the tight fit).\n    # A score that increases as remaining capacity decreases, but capped.\n    # Let's assign a score that is inversely proportional to the remaining capacity AFTER packing.\n    # We'll scale this to avoid overpowering the 'best fit' score.\n    other_suitable_indices = np.where(suitable_bins_mask)[0][~tight_fit_mask_local]\n    if other_suitable_indices.size > 0:\n        other_capacities = bins_remain_cap[other_suitable_indices] - item\n        # Assign priority based on inverse of remaining capacity (smaller remaining is better)\n        # Add a small epsilon to avoid division by zero if a bin is perfectly filled\n        inverse_capacity_score = 1.0 / (other_capacities + 1e-6)\n        # Normalize this score so it doesn't dominate the '1.0' from tight fit\n        max_inverse_score = np.max(inverse_capacity_score)\n        if max_inverse_score > 0:\n            normalized_inverse_score = inverse_capacity_score / max_inverse_score\n        else:\n            normalized_inverse_score = np.zeros_like(inverse_capacity_score)\n\n        # Combine baseline, tight fit boost, and moderate fit score.\n        # The tightest fit gets 1.0. Other suitable bins get a score based on inverse capacity.\n        # We need to ensure that the 'best fit' priority (1.0) is respected.\n        # If a bin is the tightest fit, its priority is 1.0.\n        # For others, it's a scaled inverse capacity.\n\n        # Recalculate priorities for 'other' suitable bins\n        priorities[other_suitable_indices] = 0.5 * normalized_inverse_score # Scale it down to be less than 1.0\n\n    # Ensure that the best fits truly have the highest priority and that other suitable bins\n    # have a priority higher than 0 but lower than the best fit.\n    # If any bin was marked as a tight fit, its priority is 1.0.\n    # Other suitable bins get their calculated score, which should be < 1.0.\n    # If a bin is suitable but not a tight fit, and not in 'other_suitable_indices' (which shouldn't happen if logic is correct),\n    # it will remain 0.\n    # The logic above correctly assigns 1.0 to tight fits and <1.0 to other suitable bins.\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 5.0,
    "halstead": 225.71696739799185,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a\n    modified Best Fit strategy that also considers the \"tightness\" of the fit\n    and the potential for future packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Calculate the remaining capacity after placing the item\n    remaining_after_fit = suitable_bins_remain_cap - item\n    \n    # Heuristic 1: Prioritize bins where the item fits snugly (minimizing waste in this bin)\n    # We use a value that is inversely proportional to the remaining capacity after fitting.\n    # Add a small epsilon to avoid division by zero if remaining_after_fit is 0.\n    snug_fit_scores = 1.0 / (remaining_after_fit + 1e-9)\n\n    # Heuristic 2: Prioritize bins that will have more remaining capacity AFTER the item is placed.\n    # This can be useful if we anticipate packing larger items later and want to reserve\n    # larger bins, or if we want to keep bins with moderate remaining capacity.\n    # Let's give a slight bonus to bins that will have a medium amount of remaining capacity.\n    # A simple way is to give a higher score to bins whose remaining capacity is closer to the median.\n    # Or, a simpler approach: prioritize bins that leave a \"good amount\" of space, but not too much.\n    # Let's try to penalize bins that become nearly empty or still very large.\n    # We can use a Gaussian-like function centered around a 'desirable' remaining capacity.\n    # For simplicity here, let's consider leaving a moderate amount of space as good.\n    # We can map remaining_after_fit to a score where middle values are higher.\n    # A simple approach: score = 1 - (x - target)^2 / range^2.\n    # Let's assume a target remaining capacity is around half of the bin's original capacity,\n    # but this is complex as we don't know original capacity.\n    # A simpler heuristic: prioritize bins that leave a moderate amount of space,\n    # e.g., not too close to 0 and not too close to the original capacity.\n    # Let's consider bins that leave remaining capacity between 10% and 50% of the *item size* as moderately good.\n    # This is a bit ad-hoc but aims to keep bins that are neither too full nor too empty for the current item.\n    moderate_space_scores = np.zeros_like(suitable_bins_remain_cap)\n    lower_bound = item * 0.1\n    upper_bound = item * 0.5\n    \n    valid_moderate_mask = (remaining_after_fit >= lower_bound) & (remaining_after_fit <= upper_bound)\n    moderate_space_scores[valid_moderate_mask] = 1.0\n    \n    # Combine scores: A weighted sum or a simple addition might work.\n    # Let's try a weighted sum. The snug fit is often the primary goal in BPP.\n    # We can add the moderate space score as a secondary factor.\n    combined_scores = snug_fit_scores + 0.2 * moderate_space_scores # Weighting snug fit more\n\n    # Normalize scores to be between 0 and 1 (optional, but good for consistent priority interpretation)\n    if np.max(combined_scores) > 0:\n        normalized_scores = combined_scores / np.max(combined_scores)\n    else:\n        normalized_scores = combined_scores\n\n    # Assign priorities to the original array\n    priorities[suitable_bins_mask] = normalized_scores\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.058635819704831,
    "cyclomatic_complexity": 3.0,
    "halstead": 203.1220487258619,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a modified Best Fit strategy\n    that also considers the initial size of the bin.\n    Bins that are almost full but can still accommodate the item are prioritized slightly higher\n    than bins that have a lot of remaining space, to encourage tighter packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate remaining capacities for suitable bins\n    remaining_capacities_after_fit = bins_remain_cap[suitable_bins_mask] - item\n\n    # Find the minimum remaining capacity among suitable bins (this is the Best Fit criterion)\n    min_remaining_capacity = np.min(remaining_capacities_after_fit)\n\n    # Identify bins that achieve the minimum remaining capacity\n    best_fit_bins_mask = suitable_bins_mask.copy()\n    best_fit_bins_mask[suitable_bins_mask] = (remaining_capacities_after_fit == min_remaining_capacity)\n\n    # Assign a base priority of 1.0 to best-fit bins\n    priorities[best_fit_bins_mask] = 1.0\n\n    # Introduce a secondary consideration: prefer bins that are already \"closer\" to full.\n    # This is to avoid leaving many small gaps in bins that are mostly empty.\n    # We can achieve this by giving a slight boost to bins that have less remaining capacity *before* the item is added,\n    # among those that can fit the item.\n\n    # Get remaining capacities of all suitable bins\n    suitable_bins_remaining_cap = bins_remain_cap[suitable_bins_mask]\n\n    # Calculate a \"fill ratio\" - how full the bin is before adding the item. Higher is better.\n    # Add a small epsilon to avoid division by zero if a bin had 0 initial capacity (though unlikely in BPP)\n    epsilon = 1e-9\n    initial_bin_capacity_for_suitable_bins = suitable_bins_remaining_cap + item\n    fill_ratios = (initial_bin_capacity_for_suitable_bins - suitable_bins_remaining_cap) / (initial_bin_capacity_for_suitable_bins + epsilon)\n\n    # Scale these fill ratios to create a secondary priority boost.\n    # We want to slightly prefer fuller bins. A simple scaling could be based on the maximum fill ratio.\n    # A small additive boost is generally safer than multiplicative to avoid huge numbers.\n    # Let's try a small positive boost for bins that are \"more filled\" than the average.\n    \n    # Calculate a threshold based on the mean fill ratio of suitable bins\n    mean_fill_ratio = np.mean(fill_ratios)\n    \n    # Apply a smaller boost to bins that are more filled than the average,\n    # but only if they are not already a \"best fit\" bin (to avoid double counting the primary priority).\n    # The boost should be less than the primary priority (1.0).\n    secondary_boost_amount = 0.1\n\n    # For bins that are suitable but *not* best-fit, and are more filled than average, give a small boost.\n    non_best_fit_suitable_mask = suitable_bins_mask.copy()\n    non_best_fit_suitable_mask[suitable_bins_mask] = ~best_fit_bins_mask[suitable_bins_mask]\n    \n    combined_mask_for_boost = non_best_fit_suitable_mask & suitable_bins_mask\n    \n    if np.any(combined_mask_for_boost):\n        # Filter fill ratios for these bins\n        fill_ratios_for_boost = fill_ratios[np.isin(np.where(suitable_bins_mask)[0], np.where(combined_mask_for_boost)[0])]\n        \n        # Apply boost to those with fill ratio > mean fill ratio\n        boost_condition_mask = fill_ratios_for_boost > mean_fill_ratio\n        \n        if np.any(boost_condition_mask):\n            # Get the indices in the original bins_remain_cap array\n            indices_to_boost = np.where(suitable_bins_mask)[0][np.isin(np.where(suitable_bins_mask)[0], np.where(combined_mask_for_boost)[0])][boost_condition_mask]\n            priorities[indices_to_boost] += secondary_boost_amount\n\n    # Ensure best-fit bins still have the highest priority (1.0)\n    # If a best-fit bin also qualified for the secondary boost, its priority will be 1.0 + 0.1,\n    # which might be undesireable if we want best-fit to be strictly highest.\n    # Let's refine this: Best Fit gets 1.0. Other suitable bins get a smaller priority\n    # based on how \"full\" they are.\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    remaining_capacities_after_fit = bins_remain_cap[suitable_bins_mask] - item\n    min_remaining_capacity = np.min(remaining_capacities_after_fit)\n\n    # Assign priority based on how close they are to best-fit, and then by fill ratio.\n    # The highest priority will be for best-fit bins.\n    # For non-best-fit bins, priority will be lower and based on their fill level.\n\n    # Calculate a \"closeness\" to best-fit metric for all suitable bins.\n    # Lower remaining capacity after fit is better (closer to best-fit).\n    # We can normalize this.\n    \n    # Normalize remaining capacities to a [0, 1] range, where 0 is best.\n    # Avoid division by zero if all suitable bins have the same remaining capacity.\n    if np.all(remaining_capacities_after_fit == min_remaining_capacity):\n        closeness_to_best_fit = np.zeros_like(remaining_capacities_after_fit)\n    else:\n        max_remaining_capacity_after_fit = np.max(remaining_capacities_after_fit)\n        closeness_to_best_fit = (remaining_capacities_after_fit - min_remaining_capacity) / (max_remaining_capacity_after_fit - min_remaining_capacity + epsilon)\n\n    # Now, use fill ratio for secondary sorting among bins with similar \"closeness to best-fit\".\n    # Or, combine them. A simple way is to prioritize Best Fit (closeness = 0) with a high score,\n    # and then use fill ratio for others.\n\n    # Let's assign priorities:\n    # Best-fit bins get a high priority (e.g., 1.0)\n    # Other suitable bins get a priority based on their fill ratio, scaled down.\n    \n    # Priority for best-fit bins\n    best_fit_bins_mask_final = suitable_bins_mask.copy()\n    best_fit_bins_mask_final[suitable_bins_mask] = (remaining_capacities_after_fit == min_remaining_capacity)\n    priorities[best_fit_bins_mask_final] = 1.0\n    \n    # Priority for non-best-fit suitable bins\n    non_best_fit_suitable_mask_final = suitable_bins_mask.copy()\n    non_best_fit_suitable_mask_final[suitable_bins_mask] = ~best_fit_bins_mask_final[suitable_bins_mask]\n    \n    # Calculate fill ratios for these bins again\n    suitable_bins_remaining_cap_non_bf = bins_remain_cap[non_best_fit_suitable_mask_final]\n    initial_bin_capacity_for_suitable_bins_non_bf = suitable_bins_remaining_cap_non_bf + item\n    fill_ratios_non_bf = (initial_bin_capacity_for_suitable_bins_non_bf - suitable_bins_remaining_cap_non_bf) / (initial_bin_capacity_for_suitable_bins_non_bf + epsilon)\n\n    # Scale these fill ratios to a lower range, e.g., [0.1, 0.5]\n    # This ensures they are less prioritized than best-fit bins (1.0).\n    if np.any(non_best_fit_suitable_mask_final):\n        if np.all(fill_ratios_non_bf == fill_ratios_non_bf[0]): # Handle case where all fill ratios are same\n             scaled_priorities = 0.3 # Assign a mid-range priority\n        else:\n            min_fill_ratio = np.min(fill_ratios_non_bf)\n            max_fill_ratio = np.max(fill_ratios_non_bf)\n            # Scale fill ratios from [min_fill_ratio, max_fill_ratio] to [0.1, 0.5]\n            scaled_priorities = 0.1 + 0.4 * (fill_ratios_non_bf - min_fill_ratio) / (max_fill_ratio - min_fill_ratio + epsilon)\n        \n        priorities[non_best_fit_suitable_mask_final] = scaled_priorities\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 8.0,
    "halstead": 536.1663380285988,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines exact fit prioritization with a refined Best Fit approach for remaining capacity.\n\n    This heuristic prioritizes exact fits and then favors bins that minimize remaining\n    space, using a scaled inverse to avoid extreme values, similar to the best-performing\n    strategies.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    remaining_capacities_after_packing = suitable_bins_caps - item\n\n    # Prioritize exact fits with a high score\n    tolerance = 1e-6\n    exact_fit_mask = np.abs(remaining_capacities_after_packing) < tolerance\n\n    if np.any(exact_fit_mask):\n        # Among exact fits, pick the one with least remaining capacity (already zero)\n        # Assign highest priority to these\n        original_indices_exact = np.where(suitable_bins_mask)[0][exact_fit_mask]\n        priorities[original_indices_exact] = 2.0\n        \n        # If there are exact fits, we primarily focus on them.\n        # For any remaining suitable bins that are *not* exact fits, give them a lower\n        # but still significant priority based on how 'best-fit' they are.\n        non_exact_mask_for_suitable = ~exact_fit_mask\n        if np.any(non_exact_mask_for_suitable):\n            non_exact_suitable_caps = suitable_bins_caps[non_exact_mask_for_suitable]\n            non_exact_remaining_after = non_exact_suitable_caps - item\n            \n            # Score based on minimizing remaining capacity after packing.\n            # Use a scaled inverse to avoid extreme values and favor tighter fits.\n            min_remaining_non_exact = np.min(non_exact_remaining_after)\n            scores_non_exact = 1.0 / (1.0 + non_exact_remaining_after - min_remaining_non_exact)\n            \n            # Normalize scores for these non-exact fits\n            max_score_non_exact = np.max(scores_non_exact)\n            min_score_non_exact = np.min(scores_non_exact)\n            if max_score_non_exact > min_score_non_exact:\n                normalized_scores_non_exact = (scores_non_exact - min_score_non_exact) / (max_score_non_exact - min_score_non_exact)\n            else:\n                normalized_scores_non_exact = np.ones_like(scores_non_exact) * 0.5\n\n            # Assign a priority lower than exact fits but higher than default (e.g., 1.0 to 1.9)\n            priorities[suitable_bins_mask][non_exact_mask_for_suitable] = 1.0 + normalized_scores_non_exact * 0.9\n\n    else:\n        # If no exact fits, fall back to a refined Best Fit strategy for all suitable bins.\n        # Prioritize bins that leave the least remaining capacity after packing.\n        # Score is inversely related to the remaining capacity, scaled to avoid extremes.\n        min_remaining_overall = np.min(remaining_capacities_after_packing)\n        \n        # Higher score for bins closer to the minimum remaining capacity.\n        scores_all_suitable = 1.0 / (1.0 + remaining_capacities_after_packing - min_remaining_overall)\n        \n        # Normalize scores to be between 0 and 1\n        max_score_all_suitable = np.max(scores_all_suitable)\n        min_score_all_suitable = np.min(scores_all_suitable)\n        if max_score_all_suitable > min_score_all_suitable:\n            normalized_scores_all_suitable = (scores_all_suitable - min_score_all_suitable) / (max_score_all_suitable - min_score_all_suitable)\n        else:\n            normalized_scores_all_suitable = np.ones_like(scores_all_suitable) * 0.5 # Neutral score if all are equal\n\n        # Assign priorities between 1.0 and 1.9, reflecting a strong Best Fit preference.\n        priorities[suitable_bins_mask] = 1.0 + normalized_scores_all_suitable * 0.9\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 6.0,
    "halstead": 414.9168030164346,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit (tightest fit) with a penalty for wasted space\n    on other suitable bins, prioritizing exact fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_capacities = bins_remain_cap[suitable_bins_mask]\n    \n    # Calculate remaining capacity if item is placed\n    remaining_capacities_after_fit = suitable_capacities - item\n    \n    # Find the minimum remaining capacity among suitable bins\n    min_remaining_capacity = np.min(remaining_capacities_after_fit)\n    \n    # Identify bins that achieve the minimum remaining capacity (tightest fits)\n    tight_fit_indices_local = np.where(remaining_capacities_after_fit == min_remaining_capacity)[0]\n    \n    # Get the global indices of these tightest fitting bins\n    tight_fit_global_indices = np.where(suitable_bins_mask)[0][tight_fit_indices_local]\n    \n    # Assign the highest priority to exact fits (where remaining capacity is 0)\n    exact_fit_mask = (remaining_capacities_after_fit == 0)\n    exact_fit_indices_local = np.where(exact_fit_mask)[0]\n    exact_fit_global_indices = np.where(suitable_bins_mask)[0][exact_fit_indices_local]\n    priorities[exact_fit_global_indices] = 2.0  # Highest priority for exact fits\n\n    # For other tightest fits (but not exact), assign a high priority\n    other_tight_fit_indices_local = tight_fit_indices_local[~exact_fit_mask[tight_fit_indices_local]]\n    other_tight_fit_global_indices = np.where(suitable_bins_mask)[0][other_tight_fit_indices_local]\n    priorities[other_tight_fit_global_indices] = 1.5\n\n    # For remaining suitable bins (not among the tightest fits), assign a priority\n    # inversely proportional to the remaining capacity (smaller is better).\n    # This rewards bins that leave less, but not the absolute least, space.\n    other_suitable_mask_local = ~np.isin(np.arange(len(suitable_capacities)), np.concatenate([tight_fit_indices_local, exact_fit_indices_local]))\n    other_suitable_indices_local = np.where(other_suitable_mask_local)[0]\n    \n    if other_suitable_indices_local.size > 0:\n        other_suitable_global_indices = np.where(suitable_bins_mask)[0][other_suitable_indices_local]\n        \n        # Calculate remaining capacities for these bins\n        other_remaining_capacities = suitable_capacities[other_suitable_indices_local] - item\n        \n        # Assign priority inversely proportional to remaining capacity, scaled down.\n        # Add a small epsilon to avoid division by zero.\n        # Scale it to be between 0 and 1, ensuring it's less than the tightest fits.\n        inverse_priority_scores = 1.0 / (other_remaining_capacities + 1e-6)\n        \n        # Normalize scores so the max is 1.0 for this group\n        max_inv_score = np.max(inverse_priority_scores)\n        if max_inv_score > 0:\n            normalized_scores = inverse_priority_scores / max_inv_score\n        else:\n            normalized_scores = np.zeros_like(inverse_priority_scores)\n        \n        # Assign a score that is high but less than tight fits\n        priorities[other_suitable_global_indices] = 0.5 + 0.4 * normalized_scores # Ranging from 0.5 to 0.9\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 206.0894050155578,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic aims to fill bins more evenly while still prioritizing fitting.\n    It assigns higher priority to bins that are \"closer\" to being full after\n    packing the item, but not so close that they become unusable for smaller items.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    # Calculate the remaining capacity after placing the item\n    remaining_after_fit = bins_remain_cap[suitable_bins_mask] - item\n\n    # We want to prioritize bins that leave a \"good\" amount of space.\n    # Too little space is bad (might not fit other items), too much is also less ideal\n    # as it suggests the bin is not being efficiently used relative to others.\n    # A common strategy is to aim for a moderate remaining capacity.\n    # Let's consider the *inverse* of the remaining capacity as a measure of fullness.\n    # However, we need to avoid division by zero if a bin becomes exactly full.\n    # We also want to penalize bins that become *too* full (leaving very little space).\n\n    # To avoid division by zero and to handle bins that become full, we can add a small epsilon\n    # or use a strategy that caps the \"fullness\" contribution.\n    # Let's try a strategy that rewards bins that are mostly filled but not completely,\n    # and disincentivizes bins that remain largely empty.\n\n    # Option 1: Prioritize bins that leave a small, non-zero remaining capacity (closest to Best Fit)\n    # This is similar to Best Fit, but let's refine the scoring.\n    # We can score based on how \"tight\" the fit is, but not perfectly tight.\n    # A penalty for being too empty.\n\n    # Let's define a \"desirability\" score for the remaining capacity.\n    # A bin that leaves capacity `c` could be scored.\n    # We want to avoid `c` being too large or too small (near zero).\n\n    # A simple approach: maximize `remaining_after_fit` but with a penalty if it's too close to zero.\n    # Or, minimize `remaining_after_fit` (Best Fit), but add a small bonus for bins\n    # that have a substantial amount of space *before* fitting the item.\n\n    # Let's try to incentivize bins that are relatively full *before* placing the item,\n    # among the suitable bins. This aims to consolidate items.\n    # Among suitable bins, we can score them by their original remaining capacity,\n    # but perhaps inversely. Or, score by how much space is *left* after fitting,\n    # favoring smaller remaining space but with a floor to avoid over-filling.\n\n    # Let's try a \"Worst Fit Decreasing\"-like idea but for online.\n    # Prioritize bins that are \"least full\" among those that can fit the item.\n    # This is similar to First Fit, but instead of picking the first, we pick the one\n    # that has the most space *remaining* after fitting. This might leave more options\n    # for subsequent items. This is more like \"Worst Fit\".\n\n    # Let's refine Best Fit. Best Fit minimizes `bins_remain_cap - item`.\n    # What if we introduce a secondary criterion?\n    # Consider the variance of remaining capacities. We want to reduce variance.\n    # Or, we want to keep remaining capacities distributed.\n\n    # Let's focus on the *impact* on the bin's remaining capacity.\n    # We want to fill bins as much as possible, but not to the point where\n    # the bin becomes unusable for future small items.\n    # A bin with remaining capacity `R` becomes `R - item`.\n    # If `R - item` is very small, the bin is \"almost full\".\n    # If `R - item` is large, the bin is \"not very full\".\n\n    # Heuristic idea: Prioritize bins that are already relatively full (good candidates for Best Fit)\n    # BUT, also consider that leaving *some* reasonable space is good.\n    # So, we want bins that are \"almost full\" but not \"too empty\".\n\n    # Let's try scoring based on the \"tightness of fit\" but with a bias against leaving\n    # *very* little space.\n    # For a suitable bin `i` with remaining capacity `R_i`:\n    # The remaining capacity after fitting is `R_i - item`.\n    # If `R_i - item` is close to 0, it's a good fit (BF).\n    # If `R_i - item` is large, it's a \"waste\" of space in that bin.\n\n    # Consider a score that is high when `R_i - item` is small, but not zero.\n    # Let's use `1 / (R_i - item + epsilon)` where epsilon is small, to reward small remaining capacity.\n    # However, this can be unstable if `R_i - item` is tiny.\n    # A better approach might be to invert the \"gap\" and penalize bins that leave too much gap.\n\n    # Let's try a \"Best Fit with a bias towards not leaving too little space\".\n    # The difference `bins_remain_cap[suitable_bins_mask] - item`\n    # We want to minimize this difference.\n    # Let `diffs = bins_remain_cap[suitable_bins_mask] - item`.\n    # We want to pick the bin with the minimum `diff`.\n\n    # To \"think outside the box\" and improve upon Best Fit:\n    # Best Fit aims to minimize `R - item`. This can lead to many bins with small remaining capacities.\n    # A more robust approach might be to keep capacities more uniform, or to avoid\n    # creating too many \"nearly full\" bins.\n\n    # Let's consider a heuristic that aims to leave a moderate amount of space,\n    # effectively trying to keep bins from becoming \"too full\" too quickly,\n    # while still ensuring the item fits.\n\n    # Consider the \"gap\" `bins_remain_cap[suitable_bins_mask] - item`.\n    # We want this gap to be small, but not necessarily minimal.\n    # Let's assign a priority that is high for small gaps, but decreases as the gap gets very small.\n\n    # We can use a function like `exp(-k * gap)` or a piecewise function.\n    # A simpler approach: penalize bins that have a very small remaining capacity *after* fitting.\n    # For example, if `R_i - item < threshold`, reduce its priority.\n\n    # Let's try a heuristic that aims for a compromise:\n    # 1. Prioritize bins that can fit the item.\n    # 2. Among those, prioritize bins that leave a reasonably small remaining capacity,\n    #    but penalize those that leave extremely little space.\n\n    # Calculate the remaining capacities after placing the item for suitable bins.\n    remaining_capacities_after_fit = bins_remain_cap[suitable_bins_mask] - item\n\n    # A potential heuristic: assign priority based on the inverse of the remaining capacity,\n    # but cap it to avoid extreme values for very tight fits.\n    # Also, add a small penalty if the remaining capacity is very small, to discourage\n    # bins that are *too* full.\n\n    # Let's try this: the priority is inversely proportional to the remaining capacity,\n    # but we want to avoid bins that become *too* full.\n    # We can define a \"desirability\" of the remaining capacity.\n    # A bin that leaves `c` capacity is \"good\" if `c` is small but not zero.\n\n    # Consider the remaining capacity `r_after = bins_remain_cap[suitable_bins_mask] - item`.\n    # We want to maximize `f(r_after)` where `f` is a function that is high for small `r_after`.\n    # Let's use a function that is high for `r_after` in a \"sweet spot\".\n\n    # A robust approach could be to penalize bins that become \"too full\" (e.g., `r_after < threshold`).\n    # And still prioritize the smallest `r_after` otherwise.\n\n    # Let's try to balance Best Fit with avoiding \"too full\" bins.\n    # Best Fit would assign a high priority to the bin with minimum `remaining_capacities_after_fit`.\n    # Let's modify this.\n\n    # For suitable bins, calculate the remaining capacity after fitting.\n    # `remaining_after_fit = bins_remain_cap[suitable_bins_mask] - item`\n    # We want to pick the bin that minimizes `remaining_after_fit`.\n\n    # To improve: consider how \"full\" the bin was *before* placing the item.\n    # If a bin was already very full, fitting an item might not be ideal if it leaves very little space.\n    # If a bin was mostly empty, fitting an item might not be ideal if it leaves a lot of space.\n\n    # Let's try a heuristic that:\n    # 1. Prioritizes bins that can fit the item.\n    # 2. Among suitable bins, it prioritizes those that result in a smaller remaining capacity,\n    #    but with a penalty if this remaining capacity is excessively small (e.g., less than 10% of bin capacity).\n    #    This is to avoid creating many bins that are almost full and might not fit subsequent small items.\n\n    # Let's assume a default bin capacity (e.g., 1.0, if not provided).\n    # For this problem, the bin capacity is implicitly defined by the maximum possible item size\n    # or by a global parameter. Assuming a unit capacity for normalization if needed,\n    # but the problem states fixed-size bins, so the `bins_remain_cap` already reflects this.\n\n    # Let's re-evaluate the objective: \"smallest number of bins\".\n    # This means we want to pack items as tightly as possible. Best Fit is generally good for this.\n    # The \"outside the box\" improvement could be about *robustness* or *avoiding bad states*.\n\n    # Consider the \"waste\" generated by a choice. Waste is `bins_remain_cap[i] - item` for the chosen bin.\n    # Best Fit minimizes this waste for the chosen bin.\n\n    # What if we want to keep the remaining capacities of all bins \"spread out\" or \"balanced\"?\n    # This could involve considering the variance of `bins_remain_cap`.\n\n    # Let's try a hybrid approach:\n    # 1. Primary goal: fit the item (mask `suitable_bins_mask`).\n    # 2. Secondary goal: minimize the remaining capacity *after* fitting (`r_after`).\n    # 3. Tertiary goal (tie-breaker or refinement): Avoid bins that were already very full *before* fitting,\n    #    if they result in a very tight fit. Or, prefer bins that were less full but still provide a good fit.\n\n    # Let's consider the \"gap\" for suitable bins: `gaps = bins_remain_cap[suitable_bins_mask] - item`.\n    # Best Fit selects the bin with minimum `gaps`.\n    # To improve: We might want to avoid bins where `gaps` is *too* small.\n    # Let's define a penalty for small gaps.\n\n    # Priority for suitable bins can be defined as:\n    # `priority = (max_possible_gap - current_gap) + penalty_for_very_small_gap`\n    # Where `max_possible_gap` ensures larger gaps get lower scores.\n    # A simple inverse relation: `1 / (gap + epsilon)`.\n\n    # Let's try `priority = 1 / (remaining_capacities_after_fit + epsilon)` for small values.\n    # This rewards smaller remaining capacities.\n    # But we need to penalize if `remaining_capacities_after_fit` is too close to zero.\n\n    # Consider the following score:\n    # For a suitable bin `i`, let `r_after = bins_remain_cap[i] - item`.\n    # Score_i = `1 / (r_after + epsilon)`  # Encourages small `r_after`\n    # We want to avoid cases where `r_after` is very small.\n    # So, if `r_after < some_threshold`, we can reduce its score.\n\n    # Let's try a score that is monotonically decreasing with `remaining_capacities_after_fit`,\n    # but with an added component that penalizes very small remaining capacities.\n    # Score = `f(r_after)`. We want `f` to be high for small `r_after`.\n    # Let's try `f(r) = 1/(r + alpha) - beta * exp(-gamma * r)`\n    # where alpha, beta, gamma are tuning parameters.\n    # `1/(r + alpha)` rewards small `r`.\n    # `-beta * exp(-gamma * r)` penalizes small `r` as `exp(-gamma * r)` is large for small `r`.\n\n    # A simpler, more interpretable approach:\n    # For suitable bins, calculate `remaining_after_fit`.\n    # We want to minimize `remaining_after_fit`.\n    # Let's assign priority based on the \"tightness\" of the fit, but with a twist.\n    # High priority for bins that fit tightly, but a slight reduction in priority\n    # if the bin becomes *too* full.\n\n    # For suitable bins, the remaining capacities are `remaining_capacities_after_fit`.\n    # Let's compute priorities as `1 / (remaining_capacities_after_fit + epsilon)`.\n    # This naturally favors smaller remaining capacities.\n    # Now, how to penalize \"too full\"?\n    # We can reduce the priority if `remaining_capacities_after_fit` is below a certain threshold.\n    # Threshold could be a small fraction of the bin capacity (e.g., 0.1).\n\n    # Let's try `priority = 1.0 / (remaining_capacities_after_fit + 1e-9)`\n    # and then apply a penalty if `remaining_capacities_after_fit` is too small.\n    # Penalty function: if `remaining_capacities_after_fit < penalty_threshold`, reduce priority.\n\n    # Let's simplify: assign priority based on the *inverse* of the remaining capacity *after* fitting,\n    # effectively favoring bins that become \"more full\". This is Best Fit.\n    # To improve \"outside the box\", we can consider the *original* remaining capacity.\n    # If two bins offer the same `remaining_after_fit`, which one should be preferred?\n    # Perhaps the one that was originally less full, to keep more options open?\n    # Or perhaps the one that was originally *more* full, to consolidate better?\n\n    # Let's try to keep the distribution of remaining capacities more even.\n    # This means avoiding too many bins with very small remaining capacities.\n\n    # Heuristic:\n    # 1. Identify suitable bins.\n    # 2. For each suitable bin, calculate the remaining capacity after fitting.\n    # 3. Assign priority: a higher score for smaller remaining capacity, but\n    #    introduce a damping or penalty for very small remaining capacities.\n\n    # Let's use the score: `score = 1 / (remaining_capacities_after_fit + epsilon)`\n    # This is similar to Best Fit.\n    # To be \"outside the box\" and potentially better:\n    # Consider the \"waste\" `w = bins_remain_cap[i] - item`.\n    # We want to minimize `w`.\n    # What if we prioritize bins that have a \"good\" remaining capacity `w`?\n    # A \"good\" `w` is small, but not zero.\n\n    # Let's try a strategy that encourages bins to be filled \"similarly\".\n    # Among suitable bins, calculate `remaining_after_fit`.\n    # We want small `remaining_after_fit`.\n    # Let's assign a priority that is high for small `remaining_after_fit`.\n    # `priority = 1.0 / (remaining_after_fit + epsilon)`\n\n    # To be \"better than current version\" (Best Fit), we need to think about\n    # why Best Fit might not be optimal in all online scenarios.\n    # BF can create many bins with very small remaining capacities, making it hard\n    # to fit subsequent small items.\n\n    # Consider a heuristic that prefers bins that are \"almost full\", but not \"too empty\" after fitting.\n    # Let `r_after = bins_remain_cap[suitable_bins_mask] - item`.\n    # We want to pick the bin with minimum `r_after`.\n    # To avoid bins that become too full, we can penalize small `r_after` values.\n    # Let's use a score that decreases with `r_after`, but caps the maximum priority.\n    # `score = max(0, 1.0 - k * r_after)` where `k` is a scaling factor.\n    # This would favor smaller `r_after`, but linearly.\n\n    # Let's try a score that is inversely proportional to the remaining capacity,\n    # but with a slight boost for bins that were more full to begin with (as a tie-breaker\n    # for Best Fit, or as a primary driver if they lead to similar remaining capacities).\n\n    # Let's go with a refined Best Fit:\n    # For suitable bins:\n    # `remaining_after_fit = bins_remain_cap[suitable_bins_mask] - item`\n    # We want to minimize `remaining_after_fit`.\n    # Let's assign priorities that are higher for smaller `remaining_after_fit`.\n    # To avoid \"too full\" bins, we can cap the priority or introduce a penalty.\n\n    # A simple approach: score based on the inverse of the remaining capacity,\n    # but limit the score to avoid extreme values.\n    # `score = 1.0 / (remaining_capacities_after_fit + epsilon)`\n    # If `remaining_capacities_after_fit` is very small, this score becomes large.\n    # Let's cap the score to prevent over-emphasis on extremely tight fits.\n    # `capped_score = min(score, max_priority_value)`\n\n    # Or, a more direct approach to penalize \"too full\" bins:\n    # Let `r_after = remaining_capacities_after_fit`.\n    # Score = `r_after` (to minimize)\n    # But if `r_after < threshold`, then `score = threshold + penalty_factor * (threshold - r_after)`\n    # This makes very small `r_after` worse than `threshold`.\n\n    # Let's try a heuristic that encourages a more uniform distribution of remaining capacities,\n    # by slightly disincentivizing the absolute best fit if it leaves very little space.\n\n    # Calculate remaining capacities for suitable bins.\n    remaining_after_fit = bins_remain_cap[suitable_bins_mask] - item\n\n    # We want to pick the bin with the minimum `remaining_after_fit`.\n    # To avoid bins becoming too full, we can penalize very small values.\n    # Let's assign priority inversely proportional to `remaining_after_fit`, but with a cap\n    # on how \"good\" a fit can be.\n\n    # Let's consider the \"opportunity cost\" of leaving space.\n    # A bin that leaves `c` capacity has `c` space \"wasted\" or \"available\".\n    # We want to minimize `c`.\n\n    # Consider a score that is high for small `c`.\n    # Let `score = 1.0 / (remaining_after_fit + epsilon)`\n    # This is essentially Best Fit.\n\n    # To be \"better\", let's consider a small penalty for the absolute best fit if it's *too* good.\n    # Suppose the smallest remaining capacity is `min_rem`.\n    # If `min_rem < very_small_threshold`, we want to slightly reduce its priority.\n    # We can do this by adding a small value to the `min_rem` before taking the inverse.\n\n    # Let's define a \"sweet spot\" for remaining capacity.\n    # For example, if bin capacity is C, maybe remaining capacity between 0.2C and 0.5C is ideal.\n    # This is hard to do without knowing bin capacity.\n\n    # Let's focus on the relative remaining capacity.\n    # `relative_remaining = remaining_after_fit / bins_remain_cap[suitable_bins_mask]`\n    # This is not good if `bins_remain_cap[suitable_bins_mask]` is small.\n\n    # Let's refine Best Fit: prioritize minimum `remaining_after_fit`.\n    # As a tie-breaker or secondary criterion, consider the original remaining capacity.\n    # If two bins result in the same `remaining_after_fit`, which one to choose?\n    # Option A: Choose the one that was originally more full. (Consolidation)\n    # Option B: Choose the one that was originally less full. (Keeps more options open)\n\n    # Let's try Option A for tie-breaking: If `remaining_after_fit` are equal,\n    # prefer the bin that had a larger original `bins_remain_cap`.\n\n    # To implement this:\n    # Calculate `remaining_after_fit`.\n    # Find the minimum `remaining_after_fit`.\n    # Identify all bins that achieve this minimum.\n    # Among these, select the one with the maximum original `bins_remain_cap`.\n\n    # This is still essentially Best Fit with a deterministic tie-breaker.\n    # To be \"outside the box\" and potentially \"better\", we need a more fundamental change.\n\n    # Let's consider the impact on *all* bins.\n    # BF greedily optimizes for one bin. What if we consider the overall \"state\" of the bins?\n    # This is moving towards metaheuristics, which is likely too complex for a simple priority function.\n\n    # Let's stick to refining the selection criteria for a single item.\n    # Heuristic idea:\n    # The item needs to fit (`bins_remain_cap >= item`).\n    # We want to find a bin `i` such that `bins_remain_cap[i] - item` is minimized (Best Fit).\n    # Improvement: Avoid bins that become \"too full\".\n    # Define \"too full\" as having `bins_remain_cap[i] - item < threshold`.\n    # If `bins_remain_cap[i] - item` is very small, reduce its priority.\n\n    # Let's quantify this:\n    # For suitable bins, calculate `r_after = bins_remain_cap[suitable_bins_mask] - item`.\n    # If `r_after` is small, it's good (BF).\n    # If `r_after` is *very* small, it might be bad.\n    # Let `priority = 1.0 / (r_after + epsilon)` as a base score (favors small `r_after`).\n    # Add a penalty if `r_after` is too small.\n    # Penalty can be `max(0, 1 - r_after / penalty_threshold)`.\n    # So, `total_priority = (1.0 / (r_after + epsilon)) * max(1.0, 1 - r_after / penalty_threshold)`.\n    # This seems complex.\n\n    # Simpler approach:\n    # Calculate `remaining_after_fit` for suitable bins.\n    # We want to minimize `remaining_after_fit`.\n    # Consider the \"gap\" `g = remaining_after_fit`.\n    # We assign priority based on `g`. Higher priority for smaller `g`.\n    # Let's cap the priority to avoid extremely good fits dominating.\n    # `priority = min(BIG_NUMBER, 1.0 / (g + epsilon))`\n\n    # The \"outside the box\" aspect might be to consider the *original* capacity as well.\n    # If `bins_remain_cap[i]` is large, and `bins_remain_cap[i] - item` is also relatively large,\n    # this is a \"wasteful\" fit.\n    # If `bins_remain_cap[i]` is small, and `bins_remain_cap[i] - item` is very small, this is a \"good\" fit.\n\n    # Let's try a score that is inversely proportional to the \"wasted space\" but also penalizes\n    # bins that were already very full if the fit is tight.\n\n    # Consider the following score for suitable bins:\n    # `score = (bins_remain_cap[suitable_bins_mask] - item)`. We want to minimize this.\n    # Let's transform this into a priority.\n    # Priority = `1.0 / (bins_remain_cap[suitable_bins_mask] - item + epsilon)`\n    # This is Best Fit.\n\n    # To improve:\n    # Let's consider the original capacity.\n    # `original_cap = bins_remain_cap[suitable_bins_mask]`\n    # `remaining_after_fit = original_cap - item`\n    # We want small `remaining_after_fit`.\n    # Let's try to balance minimizing `remaining_after_fit` with not making bins *too* full.\n\n    # Heuristic:\n    # For suitable bins, calculate `r_after = bins_remain_cap[suitable_bins_mask] - item`.\n    # Assign priority as `1.0 / (r_after + epsilon)`.\n    # Now, slightly reduce the priority for bins where `r_after` is very small.\n    # If `r_after < penalty_threshold`: `priority -= penalty_amount`.\n\n    # A more elegant way to penalize small `r_after`:\n    # Let `score = 1.0 / (r_after + epsilon)`.\n    # Let's try to invert this logic.\n    # The \"badness\" of a bin is `r_after`. We want small `r_after`.\n    # If `r_after` is very small, it's \"extra bad\" or \"extra good\" depending on perspective.\n    # Let's treat \"very small\" `r_after` as slightly less desirable than \"small but not tiny\".\n\n    # Let's try a score that is high for small `r_after`, but this score saturates.\n    # `priority = min(MAX_PRIORITY, 1.0 / (r_after + epsilon))`\n    # This effectively makes all very tight fits equally good.\n\n    # Consider a different approach:\n    # The goal is to minimize the number of bins.\n    # Best Fit tries to minimize the gap for the current item.\n    # What if we prioritize bins that have a \"good amount of space remaining\" after fitting?\n    # This is the opposite of Best Fit. This is like Worst Fit.\n    # Worst Fit selects the bin with the largest remaining capacity.\n    # This might leave larger gaps, potentially fitting future items better.\n\n    # Let's try a heuristic that is a compromise between Best Fit and Worst Fit.\n    # Consider the remaining capacities after fitting: `remaining_after_fit`.\n    # Let the smallest be `min_r` and the largest be `max_r`.\n    # BF picks bin with `min_r`. WF picks bin with `max_r`.\n    # We could pick a bin with `r_after` that is close to the median of `remaining_after_fit`.\n    # Or pick a bin that minimizes `(r_after - median_r)^2`.\n\n    # Let's try a simpler modification of Best Fit to make it \"outside the box\".\n    # Best Fit: minimize `bins_remain_cap - item`.\n    # Let `gap = bins_remain_cap[suitable_bins_mask] - item`.\n    # We want to minimize `gap`.\n    # Let's prioritize bins where `gap` is small, but not zero.\n    # We can assign priority based on `1.0 / (gap + epsilon)`.\n\n    # To be \"better\":\n    # Consider the \"slack\" in the bin.\n    # High slack: `bins_remain_cap[i]` is large.\n    # Low slack: `bins_remain_cap[i]` is small.\n\n    # Heuristic: Prioritize bins that, after fitting the item, leave a moderate amount of remaining capacity.\n    # This means we don't want the remaining capacity to be too small, nor too large.\n    # For suitable bins, calculate `r_after = bins_remain_cap[suitable_bins_mask] - item`.\n    # We want `r_after` to be in a \"sweet spot\".\n    # Let's assign priority based on `1 / (r_after + epsilon)`, but penalize extremely small `r_after`.\n\n    # Let's define a function `f(r_after)` that is high for small `r_after`,\n    # but decreases if `r_after` gets extremely small.\n    # For example, `f(r) = 1.0 / (r + epsilon)`.\n    # Now, penalize small `r`.\n    # `penalty = max(0, 1.0 - r_after / penalty_threshold)`\n    # `priority = (1.0 / (r_after + epsilon)) * penalty`\n    # This is problematic because the penalty reduces the priority. We want to REWARD small `r_after`.\n\n    # Let's try to make the priority function smooth and peaked for a small, non-zero remaining capacity.\n    # `priority = exp(-k * r_after)`. This is minimized at infinity, maximized at 0.\n    # Let's try `priority = exp(-k * r_after)`.\n    # To penalize very small `r_after`, we need a function that has a peak at some `r_after > 0`.\n    # For example, `priority = r_after * exp(-k * r_after)`.\n    # This function peaks when `1 - k * r_after = 0`, so `r_after = 1/k`.\n    # This prioritizes bins that leave `1/k` remaining capacity.\n\n    # Let's try this approach: Prioritize bins that leave a remaining capacity that is\n    # small, but not excessively small.\n    # For each suitable bin, calculate `r_after = bins_remain_cap[suitable_bins_mask] - item`.\n    # We want to maximize `score = r_after * exp(-k * r_after)`.\n    # A smaller `k` will favor larger remaining capacities. A larger `k` will favor smaller.\n    # Let's choose `k` such that the peak is at a small, non-zero value.\n\n    # This is a form of \"Balanced Fit\" or trying to keep capacities distributed.\n    # Let's test this.\n    # Example: items [0.3, 0.3, 0.3, 0.3], bin capacity 1.0.\n    # BF:\n    # Item 0.3: Bin 1 [0.7]. Priority: 1/(0.7) = 1.42\n    # Item 0.3: Bin 1 [0.4]. Priority: 1/(0.4) = 2.5\n    # Item 0.3: Bin 1 [0.1]. Priority: 1/(0.1) = 10\n    # Item 0.3: Bin 2 [0.7]. Priority: 1/(0.7) = 1.42\n    # Total: 2 bins.\n\n    # Proposed heuristic: `score = r_after * exp(-k * r_after)`.\n    # Let's pick `k = 5.0` (arbitrary, tuneable). Peak at `r_after = 1/5 = 0.2`.\n    # Item 0.3:\n    # Bin 1 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.7 * exp(-5 * 0.7) = 0.7 * exp(-3.5) approx 0.02`.\n    # Bin 2 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.7 * exp(-5 * 0.7) approx 0.02`.\n    # Bin 3 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.7 * exp(-5 * 0.7) approx 0.02`.\n    # Bin 4 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.7 * exp(-5 * 0.7) approx 0.02`.\n    # All scores are equal. Let's say we pick the first one.\n    # Bin 1: [0.7] -> [0.4]\n\n    # Item 0.3:\n    # Bin 1 (cap 0.4): Suitable. `r_after = 0.1`. Score = `0.1 * exp(-5 * 0.1) = 0.1 * exp(-0.5) approx 0.06`.\n    # Bin 2 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # Bin 3 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # Bin 4 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # Bin 1 has highest score.\n    # Bin 1: [0.4] -> [0.1]\n\n    # Item 0.3:\n    # Bin 1 (cap 0.1): NOT SUITABLE.\n    # Bin 2 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # Bin 3 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # Bin 4 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # All scores equal. Pick Bin 2.\n    # Bin 2: [1.0] -> [0.7]\n\n    # Item 0.3:\n    # Bin 1 (cap 0.1): NOT SUITABLE.\n    # Bin 2 (cap 0.7): Suitable. `r_after = 0.4`. Score = `0.4 * exp(-5 * 0.4) = 0.4 * exp(-2) approx 0.054`.\n    # Bin 3 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # Bin 4 (cap 1.0): Suitable. `r_after = 0.7`. Score = `0.02`.\n    # Bin 2 has highest score.\n    # Bin 2: [0.7] -> [0.4]\n    # Total: 2 bins.\n\n    # This heuristic `r_after * exp(-k * r_after)` seems to achieve a similar result for this simple case,\n    # but its behavior might differ for more complex item sizes.\n    # It aims to avoid leaving *too* little space.\n\n    # Let's implement this as `priority_v2`.\n    # We need to choose a value for `k`. This `k` tunes how aggressively we penalize small remaining capacities.\n    # A larger `k` means we penalize small `r_after` more heavily, thus favoring larger `r_after` (closer to WF).\n    # A smaller `k` means we penalize small `r_after` less, thus favoring smaller `r_after` (closer to BF).\n    # For \"outside the box\" and potentially \"better\", let's choose a `k` that is not too extreme.\n    # The peak is at `1/k`. If `k=5`, peak at 0.2. If `k=2`, peak at 0.5.\n    # Let's try `k=3.0`. Peak at `r_after = 1/3 approx 0.33`.\n    # This suggests we want to leave around 33% of bin capacity.\n\n    # The priorities should be non-negative. `r_after` is non-negative. `exp(-k * r_after)` is positive.\n    # So the scores are positive.\n\n    # Calculate the remaining capacities after placing the item for suitable bins.\n    remaining_after_fit = bins_remain_cap[suitable_bins_mask] - item\n\n    # Parameter for the heuristic: k controls the peak of the score function.\n    # A higher k means we prefer smaller remaining capacities more strongly.\n    # Let's set k to a value that aims to avoid extremely tight fits but still\n    # encourages filling. k=3.0 aims for a peak around 0.33 remaining capacity.\n    k = 3.0\n    epsilon = 1e-9  # To avoid division by zero if using inverse\n\n    # Calculate scores using the formula: score = r_after * exp(-k * r_after)\n    # This score function is maximized when r_after = 1/k.\n    # For r_after close to 0, score is close to 0.\n    # For r_after large, score decreases exponentially.\n    # This prioritizes bins that leave a moderate amount of space.\n    scores = remaining_after_fit * np.exp(-k * remaining_after_fit)\n\n    # We want to maximize this score.\n    # So, the priorities should be these scores.\n    priorities[suitable_bins_mask] = scores\n\n    # A simple interpretation of this heuristic:\n    # It's a compromise. It doesn't strictly minimize the remaining capacity (like BF),\n    # nor does it maximize it (like WF). It tries to find a middle ground.\n    # The goal is to avoid creating too many \"nearly full\" bins, which can happen with BF.\n    # By peaking at `1/k`, it suggests a preference for leaving a certain amount of space.\n    # This might lead to better packing overall by keeping more options open.\n\n    # Let's refine the score slightly. What if remaining_after_fit is zero?\n    # score = 0 * exp(0) = 0. This is fine.\n    # What if remaining_after_fit is very small, say 1e-5.\n    # score = 1e-5 * exp(-k * 1e-5) approx 1e-5. Very low priority.\n    # This is desirable, as we want to avoid making bins *too* full.\n\n    # So, this heuristic `r_after * exp(-k * r_after)` prioritizes bins\n    # that leave a moderate amount of space after fitting the item.\n    # This is a deviation from Best Fit, aiming for better overall bin utilization by avoiding\n    # the creation of too many bins with very little remaining capacity.\n\n    # Final check on the logic:\n    # Input: item, bins_remain_cap\n    # Output: priorities array\n\n    # 1. Identify bins that can fit the item (`suitable_bins_mask`).\n    # 2. For these suitable bins, calculate the remaining capacity after fitting (`remaining_after_fit`).\n    # 3. Calculate a score for each of these `remaining_after_fit` values.\n    #    The score function `f(r) = r * exp(-k*r)` is used, where `k` is a parameter.\n    #    This function peaks at `r = 1/k`.\n    # 4. Assign these scores as priorities to the corresponding suitable bins.\n    # 5. Unsuitable bins retain their initial priority of 0.\n\n    # This heuristic attempts to balance filling bins tightly with leaving enough space for future items.\n    # It deviates from pure Best Fit by not always picking the bin with the absolute minimum remaining capacity,\n    # especially if that minimum is very close to zero.\n\n    # The choice of `k` is crucial and would typically be determined by empirical testing.\n    # For the purpose of this exercise, `k=3.0` is chosen as a reasonable starting point.\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 2.0,
    "halstead": 100.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that are a \"tight fit\" (minimize leftover space)\n    but also considers bins with more remaining capacity as a secondary factor to\n    avoid prematurely filling bins with very little space left, thus promoting\n    better overall packing density and potentially fewer bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities  # No bin can fit the item\n\n    # Calculate leftover capacity for suitable bins\n    leftover_capacities = bins_remain_cap[suitable_bins_mask] - item\n    \n    # Primary objective: Minimize leftover capacity (Best Fit aspect)\n    min_leftover = np.min(leftover_capacities)\n    \n    # Create a primary priority score based on how close to the minimum leftover capacity\n    # Bins with leftover_capacity == min_leftover get a high score.\n    # Normalize by the maximum possible leftover to scale scores.\n    # If all suitable bins have the same leftover, this will result in zeros.\n    # To handle this, we add a small epsilon to the denominator or ensure it's not zero.\n    max_possible_leftover = np.max(bins_remain_cap[suitable_bins_mask]) - item if np.max(bins_remain_cap[suitable_bins_mask]) > item else 0\n    if max_possible_leftover == 0: max_possible_leftover = 1e-9 # Avoid division by zero if all bins are perfectly filled\n    \n    primary_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    primary_scores[suitable_bins_mask] = 1.0 - (leftover_capacities - min_leftover) / max_possible_leftover\n\n    # Secondary objective: Maximize remaining capacity among bins with minimal leftover\n    # This is a tie-breaker. If multiple bins have the same minimal leftover,\n    # we prefer the one that has more remaining capacity *before* packing the item.\n    # This can help in spreading items more evenly and potentially leaving larger gaps\n    # for future larger items.\n    \n    # Find the maximum remaining capacity among the bins that have the minimum leftover\n    min_leftover_bins_mask = suitable_bins_mask & (bins_remain_cap - item == min_leftover)\n    \n    if np.any(min_leftover_bins_mask):\n        max_remaining_among_min_leftover = np.max(bins_remain_cap[min_leftover_bins_mask])\n        \n        # Assign a high score to bins that are both best fit AND have the most remaining capacity among best fits\n        secondary_scores = np.zeros_like(bins_remain_cap, dtype=float)\n        secondary_scores[min_leftover_bins_mask] = (bins_remain_cap[min_leftover_bins_mask] == max_remaining_among_min_leftover).astype(float)\n        \n        # Combine primary and secondary scores.\n        # The primary score encourages best fit.\n        # The secondary score acts as a strong tie-breaker for best fit bins.\n        # We can weight them. Here, the secondary score is a strong boost.\n        priorities = primary_scores + secondary_scores * 0.5 # Give secondary a significant weight but not overriding primary completely\n    else:\n        # If for some reason min_leftover_bins_mask is empty (should not happen if suitable_bins_mask is not empty),\n        # just use primary scores.\n        priorities = primary_scores\n\n    # Ensure that only suitable bins get a non-zero priority\n    priorities[~suitable_bins_mask] = 0.0\n\n    # Normalize priorities so the maximum is 1.0 (optional but good practice for some solvers)\n    if np.max(priorities) > 0:\n        priorities /= np.max(priorities)\n        \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 6.0,
    "halstead": 266.72271688113824,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that result in less wasted space after packing,\n    while also favoring bins that are a \"closer fit\" without being too tight.\n    It also introduces a penalty for bins that are nearly full to encourage\n    using bins with more remaining capacity when possible, especially for smaller items.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    # Calculate remaining capacity after packing\n    potential_remaining_caps = bins_remain_cap[suitable_bins_mask] - item\n\n    # Heuristic component 1: Minimize wasted space (similar to Best Fit)\n    # We want bins with smaller potential_remaining_caps to have higher priority.\n    # Normalize this to avoid extreme values.\n    min_potential_remaining = np.min(potential_remaining_caps)\n    max_potential_remaining = np.max(potential_remaining_caps)\n\n    if max_potential_remaining == min_potential_remaining:\n        # If all suitable bins have the same remaining capacity after packing,\n        # assign equal priority to them.\n        score1 = np.ones_like(potential_remaining_caps)\n    else:\n        # Higher priority for bins with smaller remaining capacity after packing\n        score1 = 1.0 - (potential_remaining_caps - min_potential_remaining) / (max_potential_remaining - min_potential_remaining)\n\n    # Heuristic component 2: Favor \"good enough\" fits over very tight fits\n    # We want to avoid situations where a very small item fills a bin almost completely,\n    # leaving little room for future, potentially larger items.\n    # If the remaining capacity after packing is very small (e.g., close to 0),\n    # we might want to slightly reduce its priority.\n    # This is a form of \"anti-tightness\" penalty.\n    # We use a sigmoid-like function or a simple threshold for this.\n    # Let's consider bins where remaining_cap - item is small.\n    # A small positive remaining capacity is good, but very small might be bad.\n    # Let's define a \"tightness threshold\" relative to the bin's original capacity.\n    # For simplicity, let's consider a threshold relative to the item size itself.\n    # If remaining_cap - item < epsilon * item, it's a tight fit.\n    # We want to penalize these.\n    tightness_threshold_factor = 0.1 # This factor can be tuned\n    tight_fit_mask = potential_remaining_caps < tightness_threshold_factor * item\n    score2 = np.ones_like(potential_remaining_caps)\n    # Reduce priority for tight fits\n    score2[tight_fit_mask] *= 0.7 # Reduce priority by 30% for tight fits\n\n    # Heuristic component 3: Encourage fuller bins when it doesn't hurt too much\n    # This is to try and consolidate items. If multiple bins have similar 'waste',\n    # prefer the one that is more full (i.e., has less initial remaining capacity).\n    # This is a tie-breaker for score1.\n    # Higher initial remaining capacity is worse in this component.\n    initial_remaining_caps_suitable = bins_remain_cap[suitable_bins_mask]\n    min_initial_rem = np.min(initial_remaining_caps_suitable)\n    max_initial_rem = np.max(initial_remaining_caps_suitable)\n\n    if max_initial_rem == min_initial_rem:\n        score3 = np.ones_like(potential_remaining_caps)\n    else:\n        # Higher priority for bins with less initial remaining capacity\n        score3 = 1.0 - (initial_remaining_caps_suitable - min_initial_rem) / (max_initial_rem - min_initial_rem)\n\n\n    # Combine scores. Weights can be tuned.\n    # score1 (minimize waste) is primary.\n    # score2 (avoid tightness) is secondary.\n    # score3 (encourage fullness) is a tie-breaker.\n    weights = {'score1': 0.6, 'score2': 0.3, 'score3': 0.1}\n\n    combined_score = (weights['score1'] * score1 +\n                      weights['score2'] * score2 +\n                      weights['score3'] * score3)\n\n    # Assign combined scores to the original priority array\n    priorities[suitable_bins_mask] = combined_score\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 5.434782608695652,
    "cyclomatic_complexity": 4.0,
    "halstead": 327.6949375694594,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that can fit the item and, among those,\n    favors bins that would leave the least remaining capacity after packing (Best Fit).\n    Additionally, it assigns a higher priority to bins that are \"closer\" to being full,\n    as this might encourage packing smaller items into less utilized bins first,\n    potentially leaving larger capacities for larger items later.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if np.any(suitable_bins_mask):\n        # Calculate the remaining capacity for suitable bins after packing the item\n        remaining_capacities_after_packing = bins_remain_cap[suitable_bins_mask] - item\n\n        # Find the minimum remaining capacity (Best Fit criterion)\n        min_remaining_capacity = np.min(remaining_capacities_after_packing)\n\n        # Create a mask for bins that achieve the best fit\n        best_fit_mask = suitable_bins_mask & (bins_remain_cap - item == min_remaining_capacity)\n\n        # Assign a base priority to bins that are a best fit\n        priorities[best_fit_mask] = 1.0\n\n        # Introduce a secondary priority: favor bins that are less empty (closer to full)\n        # This can be done by inverting the remaining capacity (before packing) or using the original capacity.\n        # Let's use the original remaining capacity, higher values mean more available space.\n        # We want to prioritize bins that have *less* remaining capacity, so we can invert this.\n        # However, simply inverting might lead to negative priorities if we normalize.\n        # A better approach is to use a value that increases as capacity decreases.\n        # Let's consider bins that are *not* the absolute best fit, but still suitable.\n        # For these bins, we can assign a priority based on how \"tight\" the fit is,\n        # or how much remaining capacity they have.\n        # Let's refine: For bins that are not the absolute best fit, assign a score\n        # proportional to how much *less* remaining capacity they have compared to\n        # the largest available capacity among suitable bins. This encourages using\n        # bins that are already somewhat full.\n\n        suitable_bins_original_capacities = bins_remain_cap[suitable_bins_mask]\n        max_suitable_capacity = np.max(suitable_bins_original_capacities)\n\n        # For bins that are suitable but not the best fit:\n        # Assign a priority inversely proportional to their remaining capacity.\n        # Higher priority for bins with less remaining capacity.\n        # We can scale this to avoid overlapping with the '1.0' priority of best-fit bins.\n        # A simple approach is to assign a priority value between 0 and 1,\n        # where 0.5 might be a good intermediate value.\n        # The priority should be higher for smaller remaining_capacities_after_packing.\n        # Let's map remaining_capacities_after_packing to a value from 0 to 0.5.\n        # Higher priority for smaller remaining_capacities_after_packing.\n\n        non_best_fit_suitable_mask = suitable_bins_mask & ~best_fit_mask\n\n        if np.any(non_best_fit_suitable_mask):\n            non_best_fit_remaining_caps_after = bins_remain_cap[non_best_fit_suitable_mask] - item\n            # Normalize these remaining capacities to be between 0 and 0.5\n            # A simple linear scaling:\n            # If there's only one non-best-fit bin, it gets 0.5.\n            # If there are multiple, map the smallest remaining capacity to 0.5 and largest to 0.\n            min_non_best_fit_rem_cap = np.min(non_best_fit_remaining_caps_after)\n            max_non_best_fit_rem_cap = np.max(non_best_fit_remaining_caps_after)\n\n            if max_non_best_fit_rem_cap == min_non_best_fit_rem_cap:\n                # All non-best-fit bins have the same remaining capacity\n                priorities[non_best_fit_suitable_mask] = 0.5\n            else:\n                # Scale remaining capacities to the range [0, 0.5)\n                scaled_priorities = 0.5 * (1 - (non_best_fit_remaining_caps_after - min_non_best_fit_rem_cap) / (max_non_best_fit_rem_cap - min_non_best_fit_rem_cap))\n                priorities[non_best_fit_suitable_mask] = scaled_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 192.7180284437848,
    "exec_success": true
  }
]