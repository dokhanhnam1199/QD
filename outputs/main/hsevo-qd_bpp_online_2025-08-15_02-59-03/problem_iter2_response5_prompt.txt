{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Exact Fit First heuristic: Prioritize bins where the item fits exactly.\n    If no exact fit, then prioritize the bin with the smallest remaining capacity\n    that can still accommodate the item (Best Fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    \n    if len(exact_fit_indices) > 0:\n        priorities[exact_fit_indices] = 1.0\n    else:\n        possible_bins = np.where(bins_remain_cap >= item)[0]\n        if len(possible_bins) > 0:\n            relevant_capacities = bins_remain_cap[possible_bins]\n            best_fit_index_in_possible = np.argmin(relevant_capacities)\n            best_fit_original_index = possible_bins[best_fit_index_in_possible]\n            priorities[best_fit_original_index] = 1.0\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = 1.0  # Give priority to bins that can fit the item\n        else:\n            priorities[i] = 0.0  # No priority for bins that cannot fit the item\n    \n    # In First Fit, we iterate through bins in order and pick the first one that fits.\n    # To simulate this priority, we want to give higher priority to earlier bins if they fit.\n    # We can achieve this by making the priority score dependent on the bin's index.\n    # A simple way is to add a small decreasing value based on the index.\n    # However, the standard First Fit doesn't explicitly use priority scores in this way;\n    # it's more of a sequential search. For the purpose of this function signature,\n    # we'll just mark bins that can fit. If multiple can fit, the selection logic\n    # outside this function would need to pick the first one.\n    #\n    # A true \"priority\" that mimics FF selection might be complex within this\n    # function signature if it's meant to return scores to be maxed.\n    # If the intention is for this function to directly return which bin to pick,\n    # a different approach would be needed.\n    #\n    # Given the structure, the simplest interpretation that *hints* at FF is\n    # to give a higher score to the *first* available bin.\n    \n    first_available_index = -1\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            first_available_index = i\n            break\n            \n    if first_available_index != -1:\n        priorities[first_available_index] = 1.0 + (len(bins_remain_cap) - 1 - first_available_index) * 0.001 # Slightly higher priority for earlier bins\n        \n    return priorities\n\n### Analyze & experience\n- *   **Comparing (1st) vs (2nd/4th/9th):** Heuristic 1st implements a strategy where it prioritizes bins with the smallest positive difference between remaining capacity and item size (closest fit). It achieves this by calculating `capacity - item`, finding the minimum positive difference, and then transforming priorities. Heuristics 2nd, 4th, and 9th calculate priority as `1.0 / (remaining_capacity - item + epsilon)`, which also favors tighter fits. However, 1st's explicit handling of the minimum positive difference and transformation is slightly more robust in creating distinct priorities. The use of `-np.inf` for unsuitable bins in 1st is a clear way to exclude them.\n\n*   **Comparing (2nd/4th/9th) vs (11th/12th/13th/14th):** Heuristics 11th through 14th use `1.0 / (bins_remain_cap[fit_mask] - item + 1e-9)`, which is identical to 2nd, 4th, and 9th. The docstrings in 11th-14th mention \"First Fit strategy,\" but the code itself implements a \"Best Fit\" or \"Tight Fit\" by prioritizing the smallest positive gap. This discrepancy makes them functionally similar to the Best Fit-like heuristics.\n\n*   **Comparing (3rd) vs (8th):** Heuristic 3rd implements a \"Softmax-Based Fit\" where it normalizes priorities for suitable bins based on `1.0 / (suitable_capacities - item + 1e-9)` divided by the max of these values. It also assigns a small penalty to unsuitable bins. Heuristic 8th attempts a \"Sigmoid Fit Score\" using `1 / (1 + np.exp(-k * (item / (fitting_bins_remain_cap + epsilon) - 1)))`, aiming to prioritize tighter fits. Heuristic 3rd's approach of normalizing by the maximum suitable priority is a more direct way to achieve relative prioritization among suitable bins, while 8th's sigmoid function might be more complex to tune and interpret. The explicit handling of unsuitable bins in 3rd (assigning `1e-6`) is also clearer than the implicit handling in 8th (where the sigmoid might not perform as intended for non-fitting bins if not masked).\n\n*   **Comparing (5th/7th) vs (6th):** Heuristics 5th and 7th are identical and implement a \"Best Fit\" strategy by setting priority to 1.0 for bins that achieve the minimum `remaining_capacity - item` among suitable bins. Heuristic 6th implements an \"Exact Fit First\" strategy: it gives priority 1.0 to exact fits and then falls back to Best Fit if no exact fit exists. Heuristic 6th is more sophisticated as it explicitly handles the \"exact fit\" condition, which is often a desirable outcome, before resorting to a \"best fit.\"\n\n*   **Comparing (15th/16th) vs others:** Heuristics 15th and 16th are identical and use a sigmoid function `1 / (1 + np.exp(-5 * (scaled_capacities - 0.5)))` on scaled differences, with a special case for exact fits (`priorities = 1.0`). The scaling is done by dividing `fitted_capacities` by `np.max(available_capacities)`. This approach is less intuitive for prioritization compared to direct gap minimization or inverse gap. The peak of the sigmoid is at `scaled_capacities = 0.5`, meaning bins where the remaining capacity is half of the maximum available capacity among suitable bins would get the highest score, which isn't a standard \"fit\" heuristic. The explicit setting of 1.0 for exact fits is good, but the general sigmoid logic is less clear.\n\n*   **Comparing (17th/20th) vs (18th/19th):** Heuristics 17th and 20th (identical) attempt to mimic \"First Fit\" by marking the *first* bin that fits with a slightly higher priority. Heuristics 18th and 19th (identical) return all zeros, making them the worst as they provide no prioritization. The approach in 17th/20th is a reasonable interpretation of how to represent \"First Fit\" within a priority score framework, although it's not a direct implementation of the sequential search.\n\n*   **Overall:** The best heuristics (1st, 5th, 6th, 7th, 11th-14th, 3rd, 8th) focus on \"tightest fit\" or \"best fit,\" prioritizing bins where the remaining capacity is just enough or slightly more than the item. Heuristic 6th is superior for explicitly handling exact fits first. Heuristics 17th/20th attempt to capture \"First Fit\" logic, which is a different strategy. Heuristics 15th/16th have a less standard sigmoid application. Heuristics 18th/19th are completely non-functional. The slight variations in implementing \"tightest fit\" (e.g., inverse of gap vs. negative gap, normalization) lead to minor ranking differences.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Objective Alignment, Robustness, Simplicity, Empirical Validation.\n*   **Advice:** Focus on how your heuristic directly addresses the *specific objective* (e.g., minimizing wasted space, maximizing item packing). Build in mechanisms to gracefully handle boundary conditions and data irregularities.\n*   **Avoid:** Over-engineering with complex, unjustified mathematical transformations or blindly copying existing heuristics without understanding their underlying rationale in your context.\n*   **Explanation:** True self-reflection means ensuring your heuristic's design choices are *purposeful*, testable, and contribute directly to solving the problem, rather than adding unnecessary complexity or relying on unverified assumptions.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}