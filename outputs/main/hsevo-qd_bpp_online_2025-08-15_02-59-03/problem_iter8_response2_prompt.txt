{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes exact fits, then bins with least remaining capacity using a graded scale.\n\n    Combines the explicit prioritization of exact fits (score 2.0) from priority_v0\n    with a graded penalty for non-exact fits based on the difference, aiming for\n    a balanced Best Fit approach.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Bins where the item can fit exactly\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 2.0  # Highest priority for exact fits\n\n    # Bins where the item can fit but not exactly\n    fit_mask = bins_remain_cap > item\n    \n    # Calculate priority for bins that can fit but not exactly.\n    # Prioritize bins with smaller remaining capacity (tighter fit).\n    # A higher score indicates a better (tighter) fit.\n    # The score is inversely proportional to the remaining capacity after fitting.\n    # Add epsilon to avoid division by zero.\n    difference = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (difference + 1e-9)\n\n    # Ensure exact fits still have the highest priority if they also satisfy fit_mask\n    priorities[exact_fit_mask] = np.maximum(priorities[exact_fit_mask], 2.0)\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit strategy.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            priorities[i] = 1.0  # Give priority to bins that can fit the item\n        else:\n            priorities[i] = 0.0  # No priority for bins that cannot fit the item\n    \n    # In First Fit, we iterate through bins in order and pick the first one that fits.\n    # To simulate this priority, we want to give higher priority to earlier bins if they fit.\n    # We can achieve this by making the priority score dependent on the bin's index.\n    # A simple way is to add a small decreasing value based on the index.\n    # However, the standard First Fit doesn't explicitly use priority scores in this way;\n    # it's more of a sequential search. For the purpose of this function signature,\n    # we'll just mark bins that can fit. If multiple can fit, the selection logic\n    # outside this function would need to pick the first one.\n    #\n    # A true \"priority\" that mimics FF selection might be complex within this\n    # function signature if it's meant to return scores to be maxed.\n    # If the intention is for this function to directly return which bin to pick,\n    # a different approach would be needed.\n    #\n    # Given the structure, the simplest interpretation that *hints* at FF is\n    # to give a higher score to the *first* available bin.\n    \n    first_available_index = -1\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            first_available_index = i\n            break\n            \n    if first_available_index != -1:\n        priorities[first_available_index] = 1.0 + (len(bins_remain_cap) - 1 - first_available_index) * 0.001 # Slightly higher priority for earlier bins\n        \n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 vs 8 (and 2, 4, 10, 14, 17, 18, 20):** Heuristic 1 (Exact Fit, then Best Fit with penalty) is more direct and explicit about its prioritization. Heuristics 2, 4, 8, 10, 14, 17, 20 use sigmoid or exponential functions to model \"tightness\" or \"moderate fit\". While potentially more nuanced, they are less interpretable and rely on tuned parameters (`scaling_factor`, `steepness`, `k`). Heuristic 1's clear hierarchy of Exact Fit > Best Fit is generally a strong and understandable strategy.\n*   **Heuristics 1 vs 3:** Heuristic 1 uses a distinct highest priority (1.0) for exact fits and then scales other fits. Heuristic 3 uses a higher priority (2.0) for exact fits, which is a clearer way to denote absolute preference. However, Heuristic 1's approach of using 1.0 for exact fits and then scaling others below that is also valid. Heuristic 3's score for non-exact fits (`1.0 / (difference + 1e-9)`) can lead to very high priorities for very small differences, potentially more volatile than Heuristic 1's approach.\n*   **Heuristics 1 vs 5 & 6 (and 9):** Heuristics 5, 6, and 9 introduce a secondary criterion (favoring bins that are less empty). Heuristic 1 prioritizes tightest fits after exact fits. The introduction of secondary criteria adds complexity and tunable parameters (like the scaling for non-best-fit bins) that might not always be beneficial. Heuristic 1's focused approach is simpler.\n*   **Heuristics 1 vs 7 & 9:** Heuristics 7 and 9 attempt to refine Best Fit by penalizing \"too full\" bins or by favoring a peak at a moderate remaining capacity (`r_after * exp(-k*r_after)`). While these are interesting \"outside the box\" ideas, they introduce more parameters (`tolerance`, `k`, `weights`, `tightness_threshold_factor`) and are less straightforward than Heuristic 1's clear Best Fit logic.\n*   **Heuristics 1 vs 13 (First Fit):** Heuristic 1 (Best Fit) is generally considered better than First Fit for minimizing the number of bins, as it makes more informed local decisions. Heuristic 13 is a basic implementation of First Fit and doesn't use priority scores in a way that allows for selection among multiple fitting bins.\n*   **Heuristics 1 vs 15 & 17:** Heuristics 15 and 17 combine exact fit (1.0) with a sigmoid score for tight fits. The sigmoid approach (`1 / (1 + exp(-k * (ratio - 1)))`) aims to penalize larger bins. Heuristic 1's approach is simpler: exact fits first, then pure Best Fit (implicitly, by penalizing bins that cannot fit). The sigmoid adds complexity with the `k` parameter.\n*   **Heuristics 1 vs 16 & 20:** Heuristics 16 and 20 use a multi-component scoring system (tightness, anti-tightness, fullness preference) with weights. This is significantly more complex and parameter-dependent than Heuristic 1.\n*   **Heuristics 1 vs 18:** Heuristic 18 combines exact fit (1.0) with inverse remaining capacity, scaled. It also assigns a low priority to unsuitable bins. Heuristic 1's explicit penalty for unsuitable bins (implicitly by assigning 0 priority) and its clear two-tier Best Fit logic make it more understandable.\n*   **Overall:** Heuristic 1 stands out for its clarity, simplicity, and effective combination of two strong strategies (Exact Fit First and Best Fit). It avoids complex, tunable functions or multi-component scores, making it a robust and easy-to-understand heuristic. The other heuristics introduce complexity (sigmoid, multi-factor scoring, peak functions) often tied to specific tunable parameters or less direct logic.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Robustness, Interpretability, Explicit Penalties, Logical Hierarchy.\n*   **Advice:** Focus on intuitive, rule-based strategies. Define a clear, prioritized sequence of simple objectives. Implement explicit checks and penalties for invalid or suboptimal choices.\n*   **Avoid:** Complex, opaque mathematical functions without empirical validation. Arbitrary weighting or blending of criteria. Mimicking sequential logic through static scores.\n*   **Explanation:** Simpler heuristics are easier to debug, adapt, and understand, leading to more reliable performance across diverse problem instances. Explicitly addressing constraints and undesirable states through penalties makes the heuristic's behavior predictable.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}