{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a modified Best Fit strategy.\n    This version prioritizes bins that have just enough space for the item, and among those,\n    prefers bins that will have the least remaining capacity after packing.\n    It also introduces a slight preference for bins that have been used less (i.e., higher remaining capacity)\n    if no \"perfect fit\" is found, to encourage better space utilization over time.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    remaining_capacities_after_packing = suitable_bins_caps - item\n\n    # Identify bins that are a \"perfect fit\" or very close\n    # A small tolerance is introduced to capture bins that are \"almost\" a perfect fit\n    tolerance = 1e-6\n    perfect_fit_mask = np.abs(remaining_capacities_after_packing) < tolerance\n\n    if np.any(perfect_fit_mask):\n        # Among perfect fits, prefer those with the absolute minimum remaining capacity (which is close to zero)\n        # This is essentially Best Fit for perfect fits.\n        min_remaining_cap_among_perfect = np.min(remaining_capacities_after_packing[perfect_fit_mask])\n        best_fit_perfect_mask = (suitable_bins_caps - item == min_remaining_cap_among_perfect)\n\n        # Map back to original indices\n        original_indices_perfect = np.where(suitable_bins_mask)[0][best_fit_perfect_mask]\n        priorities[original_indices_perfect] = 2.0 # Highest priority\n\n    else:\n        # If no perfect fit, fall back to a modified Best Fit strategy.\n        # Prioritize bins that leave the least remaining capacity, but not too much.\n        # We'll give a higher score to bins that have a small remaining capacity after packing,\n        # but not so small that it's completely unusable for future small items.\n        # The score is inversely related to the remaining capacity after packing.\n        # To avoid extreme values, we use a scaled inverse.\n        min_remaining_cap_overall = np.min(remaining_capacities_after_packing)\n        \n        # Assign scores based on how close the remaining capacity is to the minimum\n        # Higher score for bins that are closer to the minimum remaining capacity\n        scores_for_suitable = 1.0 / (1.0 + remaining_capacities_after_packing - min_remaining_cap_overall)\n        \n        # Normalize scores to be between 0 and 1\n        max_score = np.max(scores_for_suitable)\n        min_score = np.min(scores_for_suitable)\n        if max_score > min_score:\n            normalized_scores = (scores_for_suitable - min_score) / (max_score - min_score)\n        else:\n            normalized_scores = np.ones_like(scores_for_suitable) * 0.5 # Assign a neutral score if all are equal\n\n        # Map back to original indices\n        original_indices_suitable = np.where(suitable_bins_mask)[0]\n        priorities[original_indices_suitable] = normalized_scores\n        \n        # Ensure perfect fits (if any were missed by tolerance) still get top priority\n        if np.any(np.abs(remaining_capacities_after_packing) < tolerance):\n            min_remaining_cap_close_to_zero = np.min(remaining_capacities_after_packing[np.abs(remaining_capacities_after_packing) < tolerance])\n            best_fit_close_mask = (suitable_bins_caps - item == min_remaining_cap_close_to_zero)\n            original_indices_close = np.where(suitable_bins_mask)[0][best_fit_close_mask]\n            priorities[original_indices_close] = np.maximum(priorities[original_indices_close], 1.5) # Boost priority\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that result in less wasted space after packing,\n    while also favoring bins that are a \"closer fit\" without being too tight.\n    It also introduces a penalty for bins that are nearly full to encourage\n    using bins with more remaining capacity when possible, especially for smaller items.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    # Calculate remaining capacity after packing\n    potential_remaining_caps = bins_remain_cap[suitable_bins_mask] - item\n\n    # Heuristic component 1: Minimize wasted space (similar to Best Fit)\n    # We want bins with smaller potential_remaining_caps to have higher priority.\n    # Normalize this to avoid extreme values.\n    min_potential_remaining = np.min(potential_remaining_caps)\n    max_potential_remaining = np.max(potential_remaining_caps)\n\n    if max_potential_remaining == min_potential_remaining:\n        # If all suitable bins have the same remaining capacity after packing,\n        # assign equal priority to them.\n        score1 = np.ones_like(potential_remaining_caps)\n    else:\n        # Higher priority for bins with smaller remaining capacity after packing\n        score1 = 1.0 - (potential_remaining_caps - min_potential_remaining) / (max_potential_remaining - min_potential_remaining)\n\n    # Heuristic component 2: Favor \"good enough\" fits over very tight fits\n    # We want to avoid situations where a very small item fills a bin almost completely,\n    # leaving little room for future, potentially larger items.\n    # If the remaining capacity after packing is very small (e.g., close to 0),\n    # we might want to slightly reduce its priority.\n    # This is a form of \"anti-tightness\" penalty.\n    # We use a sigmoid-like function or a simple threshold for this.\n    # Let's consider bins where remaining_cap - item is small.\n    # A small positive remaining capacity is good, but very small might be bad.\n    # Let's define a \"tightness threshold\" relative to the bin's original capacity.\n    # For simplicity, let's consider a threshold relative to the item size itself.\n    # If remaining_cap - item < epsilon * item, it's a tight fit.\n    # We want to penalize these.\n    tightness_threshold_factor = 0.1 # This factor can be tuned\n    tight_fit_mask = potential_remaining_caps < tightness_threshold_factor * item\n    score2 = np.ones_like(potential_remaining_caps)\n    # Reduce priority for tight fits\n    score2[tight_fit_mask] *= 0.7 # Reduce priority by 30% for tight fits\n\n    # Heuristic component 3: Encourage fuller bins when it doesn't hurt too much\n    # This is to try and consolidate items. If multiple bins have similar 'waste',\n    # prefer the one that is more full (i.e., has less initial remaining capacity).\n    # This is a tie-breaker for score1.\n    # Higher initial remaining capacity is worse in this component.\n    initial_remaining_caps_suitable = bins_remain_cap[suitable_bins_mask]\n    min_initial_rem = np.min(initial_remaining_caps_suitable)\n    max_initial_rem = np.max(initial_remaining_caps_suitable)\n\n    if max_initial_rem == min_initial_rem:\n        score3 = np.ones_like(potential_remaining_caps)\n    else:\n        # Higher priority for bins with less initial remaining capacity\n        score3 = 1.0 - (initial_remaining_caps_suitable - min_initial_rem) / (max_initial_rem - min_initial_rem)\n\n\n    # Combine scores. Weights can be tuned.\n    # score1 (minimize waste) is primary.\n    # score2 (avoid tightness) is secondary.\n    # score3 (encourage fullness) is a tie-breaker.\n    weights = {'score1': 0.6, 'score2': 0.3, 'score3': 0.1}\n\n    combined_score = (weights['score1'] * score1 +\n                      weights['score2'] * score2 +\n                      weights['score3'] * score3)\n\n    # Assign combined scores to the original priority array\n    priorities[suitable_bins_mask] = combined_score\n\n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 vs 8 (and 2, 4, 10, 14, 17, 18, 20):** Heuristic 1 (Exact Fit, then Best Fit with penalty) is more direct and explicit about its prioritization. Heuristics 2, 4, 8, 10, 14, 17, 20 use sigmoid or exponential functions to model \"tightness\" or \"moderate fit\". While potentially more nuanced, they are less interpretable and rely on tuned parameters (`scaling_factor`, `steepness`, `k`). Heuristic 1's clear hierarchy of Exact Fit > Best Fit is generally a strong and understandable strategy.\n*   **Heuristics 1 vs 3:** Heuristic 1 uses a distinct highest priority (1.0) for exact fits and then scales other fits. Heuristic 3 uses a higher priority (2.0) for exact fits, which is a clearer way to denote absolute preference. However, Heuristic 1's approach of using 1.0 for exact fits and then scaling others below that is also valid. Heuristic 3's score for non-exact fits (`1.0 / (difference + 1e-9)`) can lead to very high priorities for very small differences, potentially more volatile than Heuristic 1's approach.\n*   **Heuristics 1 vs 5 & 6 (and 9):** Heuristics 5, 6, and 9 introduce a secondary criterion (favoring bins that are less empty). Heuristic 1 prioritizes tightest fits after exact fits. The introduction of secondary criteria adds complexity and tunable parameters (like the scaling for non-best-fit bins) that might not always be beneficial. Heuristic 1's focused approach is simpler.\n*   **Heuristics 1 vs 7 & 9:** Heuristics 7 and 9 attempt to refine Best Fit by penalizing \"too full\" bins or by favoring a peak at a moderate remaining capacity (`r_after * exp(-k*r_after)`). While these are interesting \"outside the box\" ideas, they introduce more parameters (`tolerance`, `k`, `weights`, `tightness_threshold_factor`) and are less straightforward than Heuristic 1's clear Best Fit logic.\n*   **Heuristics 1 vs 13 (First Fit):** Heuristic 1 (Best Fit) is generally considered better than First Fit for minimizing the number of bins, as it makes more informed local decisions. Heuristic 13 is a basic implementation of First Fit and doesn't use priority scores in a way that allows for selection among multiple fitting bins.\n*   **Heuristics 1 vs 15 & 17:** Heuristics 15 and 17 combine exact fit (1.0) with a sigmoid score for tight fits. The sigmoid approach (`1 / (1 + exp(-k * (ratio - 1)))`) aims to penalize larger bins. Heuristic 1's approach is simpler: exact fits first, then pure Best Fit (implicitly, by penalizing bins that cannot fit). The sigmoid adds complexity with the `k` parameter.\n*   **Heuristics 1 vs 16 & 20:** Heuristics 16 and 20 use a multi-component scoring system (tightness, anti-tightness, fullness preference) with weights. This is significantly more complex and parameter-dependent than Heuristic 1.\n*   **Heuristics 1 vs 18:** Heuristic 18 combines exact fit (1.0) with inverse remaining capacity, scaled. It also assigns a low priority to unsuitable bins. Heuristic 1's explicit penalty for unsuitable bins (implicitly by assigning 0 priority) and its clear two-tier Best Fit logic make it more understandable.\n*   **Overall:** Heuristic 1 stands out for its clarity, simplicity, and effective combination of two strong strategies (Exact Fit First and Best Fit). It avoids complex, tunable functions or multi-component scores, making it a robust and easy-to-understand heuristic. The other heuristics introduce complexity (sigmoid, multi-factor scoring, peak functions) often tied to specific tunable parameters or less direct logic.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Robustness, Interpretability, Explicit Penalties, Logical Hierarchy.\n*   **Advice:** Focus on intuitive, rule-based strategies. Define a clear, prioritized sequence of simple objectives. Implement explicit checks and penalties for invalid or suboptimal choices.\n*   **Avoid:** Complex, opaque mathematical functions without empirical validation. Arbitrary weighting or blending of criteria. Mimicking sequential logic through static scores.\n*   **Explanation:** Simpler heuristics are easier to debug, adapt, and understand, leading to more reliable performance across diverse problem instances. Explicitly addressing constraints and undesirable states through penalties makes the heuristic's behavior predictable.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}