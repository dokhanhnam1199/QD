{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Exact Fit First and Best Fit.\n    Prioritizes exact fits, then bins with minimal remaining capacity,\n    using a penalty for bins that cannot fit the item.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n\n    # Exact fit: highest priority\n    exact_fit_mask = (bins_remain_cap == item) & fit_mask\n    priorities[exact_fit_mask] = 1.0\n\n    # Best fit for remaining bins (those that fit but not exactly)\n    non_exact_fit_mask = fit_mask & ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        fitting_capacities = bins_remain_cap[non_exact_fit_mask]\n        gaps = fitting_capacities - item\n        min_gap = np.min(gaps)\n        \n        # Assign priorities based on the gap, higher for smaller gaps.\n        # Add a small offset to distinguish from exact fits and ensure positive.\n        best_fit_priorities = 0.9 - (gaps - min_gap) / (np.max(gaps) - min_gap + 1e-9)\n        \n        # Apply these priorities only to the bins that are non-exact fits\n        priorities[non_exact_fit_mask] = best_fit_priorities\n\n    # Penalize bins that cannot fit the item\n    no_fit_mask = ~fit_mask\n    priorities[no_fit_mask] = -1.0 # Effectively exclude them from selection\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Exact Fit with a refined Best Fit, prioritizing snug fits\n    and then bins that minimize remaining capacity, ensuring clarity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    remaining_capacities_after_packing = suitable_bins_caps - item\n\n    # Assign highest priority to exact fits (tolerance for floating point issues)\n    tolerance = 1e-9\n    exact_fit_mask = np.abs(remaining_capacities_after_packing) < tolerance\n    \n    if np.any(exact_fit_mask):\n        priorities[suitable_bins_mask][exact_fit_mask] = 1.0\n\n    # For non-exact fits, prioritize based on Best Fit principle:\n    # minimize remaining capacity after packing.\n    # Use a score that is inversely proportional to the remaining capacity.\n    # Add a small epsilon to avoid division by zero if remaining_after_fit is 0 (though covered by exact fit).\n    non_exact_fit_mask = ~exact_fit_mask\n    \n    if np.any(non_exact_fit_mask):\n        non_exact_remain_caps = remaining_capacities_after_packing[non_exact_fit_mask]\n        \n        # Higher score for smaller remaining capacity after packing\n        # Use a scaled inverse to keep scores in a reasonable range and prioritize tighter fits.\n        # We scale by the minimum remaining capacity among these non-exact fits.\n        min_remaining_among_non_exact = np.min(non_exact_remain_caps)\n        scaled_scores = 1.0 / (1.0 + (non_exact_remain_caps - min_remaining_among_non_exact))\n\n        # Normalize scores for non-exact fits to be between 0 and 0.9\n        # This ensures exact fits (score 1.0) are always preferred.\n        max_score = np.max(scaled_scores)\n        min_score = np.min(scaled_scores)\n        if max_score > min_score:\n            normalized_scores = 0.9 * (scaled_scores - min_score) / (max_score - min_score)\n        else:\n            normalized_scores = np.full_like(scaled_scores, 0.45) # Neutral score if all are equal\n\n        # Assign these scores to the appropriate bins\n        priorities[suitable_bins_mask][non_exact_fit_mask] = normalized_scores\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Exact fit + graded Best Fit) vs. Heuristic 10 (Basic inverse of remaining capacity without handling exact fits or suitability): Heuristic 1 is superior due to its explicit handling of exact fits and its more nuanced scoring for non-exact fits, leading to more predictable and often better packing.\n\nComparing Heuristic 1 vs. Heuristic 12 (Simple inverse of remaining capacity for fitting bins): Heuristic 1's explicit high priority for exact fits (score 2.0) and graded scoring for non-exact fits (1.0 / diff) provides a more robust \"Best Fit\" approach than Heuristic 12's simple inverse, which might not distinguish between exact fits and other close fits as effectively.\n\nComparing Heuristic 2 (Modified Best Fit with perfect fit prioritization) vs. Heuristic 11 (Balanced Fit, prioritizing moderate remaining capacity): Heuristic 2's explicit prioritization of perfect fits (score 2.0) and then a graded \"least remaining capacity\" for others is a clear hierarchy. Heuristic 11's approach of peaking at a moderate remaining capacity (using `r * exp(-k*r)`) is a different strategy that might perform better in some scenarios by avoiding overly full bins, but lacks the clear initial preference for exact fits that Heuristic 2 provides.\n\nComparing Heuristic 18/19 (Exact fit + scaled Best Fit) vs. Heuristic 1 (Exact fit + graded Best Fit): Heuristics 18/19 use a scaled inverse of the difference for non-exact fits, normalized to a range below the exact fit priority. Heuristic 1 uses a simpler inverse. Heuristics 18/19 offer a more controlled prioritization for non-exact fits, ensuring they are clearly secondary to exact fits.\n\nComparing Heuristic 16 (First Fit simulation) vs. Heuristic 20 (First Fit simulation with minor index bias): Both are attempts to mimic First Fit (FF). Heuristic 16 and 20 assign a high priority to the *first* bin that fits. The minor bias in Heuristic 20 is an artificial way to favor earlier bins, which is inherent in FF's sequential nature. However, a true FF implementation typically involves sequential iteration, not just scoring. These are less sophisticated than \"Best Fit\" variations.\n\nOverall: Heuristics that explicitly prioritize exact fits and then use a graded approach for \"Best Fit\" (like 1, 18, 19) or combine exact fits with a well-defined secondary strategy (like 2, 9) tend to be better. Simple \"Best Fit\" (12, 13) or variations that aim for moderate fill (11, 14, 15) are also reasonable. Heuristics simulating First Fit (16, 20) or basic inverse scoring without refinement (10) are generally less robust.\n- \nHere's a redefinition of self-reflection for designing better heuristics:\n\n*   **Keywords:** Objective-driven, measurable improvement, adaptive strategies, principled design.\n*   **Advice:** Focus on *why* a strategy works. Does it directly address a quantifiable objective (e.g., minimizing waste)? Explore how to *adapt* to different problem characteristics, rather than just mimicking existing ones.\n*   **Avoid:** Overly complex, arbitrary mathematical functions (like `r * exp(-k*r)`) without a clear theoretical or empirical justification for their specific form. Avoid \"simulating\" known heuristics if a more direct, objective-driven approach is possible.\n*   **Explanation:** The goal is to build heuristics that are understood through their objective alignment and demonstrable performance improvements, not through the intricacy of their mathematical formulation or a blind imitation of prior methods.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}