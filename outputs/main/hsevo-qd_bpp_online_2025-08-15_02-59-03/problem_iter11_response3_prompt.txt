{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Calculates priorities for placing an item into bins using a Softmax-Based Fit strategy.\n\n    The priority is higher for bins that have a remaining capacity greater than or equal to the item's size,\n    and among those, bins that have less remaining capacity (tighter fit) are preferred.\n    A small penalty is added to bins that cannot accommodate the item to ensure they receive a non-zero\n    but still lower priority.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A numpy array representing the remaining capacity of each bin.\n\n    Returns:\n        A numpy array of the same size as bins_remain_cap, where each element represents\n        the priority score for placing the item into the corresponding bin.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    unsuitable_bins_mask = ~suitable_bins_mask\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(suitable_bins_mask):\n        suitable_capacities = bins_remain_cap[suitable_bins_mask]\n        \n        inverted_capacities = 1.0 / (suitable_capacities - item + 1e-9)\n        \n        max_inverted_capacity = np.max(inverted_capacities)\n        \n        normalized_priorities = inverted_capacities / max_inverted_capacity\n        \n        priorities[suitable_bins_mask] = normalized_priorities\n\n    if np.any(unsuitable_bins_mask):\n        priorities[unsuitable_bins_mask] = 1e-6\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Exact Fit First with a penalty for bins that would become too full.\n    Prioritizes exact fits, then bins that leave a moderate remaining capacity,\n    penalizing those that leave very little space.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    # If no bins can fit the item, return all zeros.\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    # Separate suitable bins from unsuitable ones.\n    suitable_capacities = bins_remain_cap[suitable_bins_mask]\n\n    # --- Strategy: Exact Fit First ---\n    # Bins that perfectly fit the item get the highest priority.\n    exact_fit_mask = (suitable_capacities == item)\n    if np.any(exact_fit_mask):\n        priorities[suitable_bins_mask][exact_fit_mask] = 1.0\n\n    # --- Strategy: Moderate Fit (Avoid \"too full\" bins) ---\n    # For bins that do not provide an exact fit, calculate remaining capacity after placing the item.\n    # Use a score that peaks for a moderate remaining capacity, avoiding near-zero values.\n    # The score function r * exp(-k*r) peaks at r = 1/k.\n    # We choose k to encourage leaving a reasonable amount of space.\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_capacities = suitable_capacities[non_exact_fit_mask]\n        remaining_after_fit = non_exact_capacities - item\n\n        # Parameter 'k' tunes the peak of the scoring function.\n        # A higher 'k' favors smaller remaining capacities.\n        # k=3.0 suggests a preference for leaving around 1/3 of capacity.\n        k = 3.0 \n        \n        # Calculate scores: score = remaining_capacity * exp(-k * remaining_capacity)\n        # This function gives low scores for very small or very large remaining capacities,\n        # and peaks for intermediate values. This helps avoid creating too many \"nearly full\" bins.\n        scores = remaining_after_fit * np.exp(-k * remaining_after_fit)\n\n        # Normalize scores to be between 0 and 1 for consistency, and add a small base.\n        # This ensures these priorities are lower than exact fits (1.0) but still positive.\n        # We scale by a factor < 1.0 to ensure they are less than exact fit priority.\n        # Adding a small base (e.g., 0.01) ensures they have some priority even if scores are very low.\n        max_score = np.max(scores) if np.any(scores) else 1.0\n        if max_score > 0:\n            scaled_scores = 0.9 * (scores / max_score) + 0.01\n        else: # Handle case where all remaining capacities are 0 (highly unlikely for non-exact fits)\n            scaled_scores = np.full_like(scores, 0.01)\n\n        # Assign these calculated priorities to the non-exact fit bins.\n        priorities[suitable_bins_mask][non_exact_fit_mask] = scaled_scores\n\n    # Bins that cannot fit the item (already handled by initialization to 0).\n    \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Exact fit + graded Best Fit) vs. Heuristic 10 (Basic inverse of remaining capacity without handling exact fits or suitability): Heuristic 1 is superior due to its explicit handling of exact fits and its more nuanced scoring for non-exact fits, leading to more predictable and often better packing.\n\nComparing Heuristic 1 vs. Heuristic 12 (Simple inverse of remaining capacity for fitting bins): Heuristic 1's explicit high priority for exact fits (score 2.0) and graded scoring for non-exact fits (1.0 / diff) provides a more robust \"Best Fit\" approach than Heuristic 12's simple inverse, which might not distinguish between exact fits and other close fits as effectively.\n\nComparing Heuristic 2 (Modified Best Fit with perfect fit prioritization) vs. Heuristic 11 (Balanced Fit, prioritizing moderate remaining capacity): Heuristic 2's explicit prioritization of perfect fits (score 2.0) and then a graded \"least remaining capacity\" for others is a clear hierarchy. Heuristic 11's approach of peaking at a moderate remaining capacity (using `r * exp(-k*r)`) is a different strategy that might perform better in some scenarios by avoiding overly full bins, but lacks the clear initial preference for exact fits that Heuristic 2 provides.\n\nComparing Heuristic 18/19 (Exact fit + scaled Best Fit) vs. Heuristic 1 (Exact fit + graded Best Fit): Heuristics 18/19 use a scaled inverse of the difference for non-exact fits, normalized to a range below the exact fit priority. Heuristic 1 uses a simpler inverse. Heuristics 18/19 offer a more controlled prioritization for non-exact fits, ensuring they are clearly secondary to exact fits.\n\nComparing Heuristic 16 (First Fit simulation) vs. Heuristic 20 (First Fit simulation with minor index bias): Both are attempts to mimic First Fit (FF). Heuristic 16 and 20 assign a high priority to the *first* bin that fits. The minor bias in Heuristic 20 is an artificial way to favor earlier bins, which is inherent in FF's sequential nature. However, a true FF implementation typically involves sequential iteration, not just scoring. These are less sophisticated than \"Best Fit\" variations.\n\nOverall: Heuristics that explicitly prioritize exact fits and then use a graded approach for \"Best Fit\" (like 1, 18, 19) or combine exact fits with a well-defined secondary strategy (like 2, 9) tend to be better. Simple \"Best Fit\" (12, 13) or variations that aim for moderate fill (11, 14, 15) are also reasonable. Heuristics simulating First Fit (16, 20) or basic inverse scoring without refinement (10) are generally less robust.\n- \nHere's a redefinition of self-reflection for designing better heuristics:\n\n*   **Keywords:** Objective-driven, measurable improvement, adaptive strategies, principled design.\n*   **Advice:** Focus on *why* a strategy works. Does it directly address a quantifiable objective (e.g., minimizing waste)? Explore how to *adapt* to different problem characteristics, rather than just mimicking existing ones.\n*   **Avoid:** Overly complex, arbitrary mathematical functions (like `r * exp(-k*r)`) without a clear theoretical or empirical justification for their specific form. Avoid \"simulating\" known heuristics if a more direct, objective-driven approach is possible.\n*   **Explanation:** The goal is to build heuristics that are understood through their objective alignment and demonstrable performance improvements, not through the intricacy of their mathematical formulation or a blind imitation of prior methods.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}