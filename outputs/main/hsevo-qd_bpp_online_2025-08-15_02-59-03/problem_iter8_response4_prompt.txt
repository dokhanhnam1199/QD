{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on tight fit, favoring exact fits then closest fits.\n\n    Combines exact fit (priority 1.0) with a tight fit metric using sigmoid\n    on the inverse of remaining capacity relative to item size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # If there are no bins that can fit the item, return all zeros\n    if fitting_bins_remain_cap.size == 0:\n        return priorities\n\n    # Prioritize exact fits with the highest score\n    exact_fit_mask_for_fitting = np.abs(fitting_bins_remain_cap - item) < epsilon\n    priorities[can_fit_mask][exact_fit_mask_for_fitting] = 1.0\n\n    # For bins that can fit but are not exact fits, use a sigmoid score\n    # that favors bins with less remaining capacity (tighter fit).\n    # The metric is `item / remaining_capacity`. Closer to 1 is better.\n    # We use `sigmoid(k * (item / remaining_capacity - 1))`\n    # k controls the steepness. We choose a moderate k.\n    # We need to apply this only to bins that are not exact fits.\n    non_exact_fit_mask_for_fitting = ~exact_fit_mask_for_fitting\n\n    if np.any(non_exact_fit_mask_for_fitting):\n        non_exact_fitting_capacities = fitting_bins_remain_cap[non_exact_fit_mask_for_fitting]\n        \n        # Calculate the tightness ratio: item size / remaining capacity.\n        # A higher ratio indicates a tighter fit.\n        tightness_ratio = item / (non_exact_fitting_capacities + epsilon)\n\n        # Sigmoid function to map the tightness ratio to a priority score between 0 and 1.\n        # The formula `1 / (1 + exp(-k * (ratio - 1)))` peaks around ratio=1.\n        # A k=5.0 makes the sigmoid relatively steep, favoring capacities closer to item size.\n        k = 5.0\n        sigmoid_priorities = 1 / (1 + np.exp(-k * (tightness_ratio - 1)))\n        \n        # Assign these priorities to the corresponding original bins\n        priorities[can_fit_mask][non_exact_fit_mask_for_fitting] = sigmoid_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Calculates priorities for placing an item into bins using a hybrid Best Fit and Softmax strategy.\n\n    Prioritizes bins with exact fits, then bins with the tightest fit.\n    Unsuitable bins receive a minimal priority.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    unsuitable_bins_mask = ~suitable_bins_mask\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(suitable_bins_mask):\n        suitable_capacities = bins_remain_cap[suitable_bins_mask]\n        \n        # Prioritize exact fits with highest score\n        exact_fit_mask = suitable_capacities == item\n        if np.any(exact_fit_mask):\n            priorities[suitable_bins_mask][exact_fit_mask] = 1.0\n        \n        # For other suitable bins, use inverted remaining capacity for tightest fit\n        non_exact_suitable_mask = suitable_bins_mask.copy()\n        non_exact_suitable_mask[suitable_bins_mask] = ~exact_fit_mask\n        \n        if np.any(non_exact_suitable_mask):\n            non_exact_capacities = bins_remain_cap[non_exact_suitable_mask]\n            \n            # Inverse of (capacity - item) for tightest fit, normalized\n            inverted_gaps = 1.0 / (non_exact_capacities - item + 1e-9)\n            \n            # Scale priorities to be between 0 and 1, favoring larger inverse_gaps (tighter fits)\n            max_inverted_gap = np.max(inverted_gaps)\n            normalized_priorities = inverted_gaps / max_inverted_gap\n            \n            # Assign scaled priorities to non-exact fitting bins\n            priorities[non_exact_suitable_mask] = normalized_priorities\n    \n    # Assign a very low priority to bins that cannot fit the item\n    if np.any(unsuitable_bins_mask):\n        priorities[unsuitable_bins_mask] = 1e-6\n\n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 vs 8 (and 2, 4, 10, 14, 17, 18, 20):** Heuristic 1 (Exact Fit, then Best Fit with penalty) is more direct and explicit about its prioritization. Heuristics 2, 4, 8, 10, 14, 17, 20 use sigmoid or exponential functions to model \"tightness\" or \"moderate fit\". While potentially more nuanced, they are less interpretable and rely on tuned parameters (`scaling_factor`, `steepness`, `k`). Heuristic 1's clear hierarchy of Exact Fit > Best Fit is generally a strong and understandable strategy.\n*   **Heuristics 1 vs 3:** Heuristic 1 uses a distinct highest priority (1.0) for exact fits and then scales other fits. Heuristic 3 uses a higher priority (2.0) for exact fits, which is a clearer way to denote absolute preference. However, Heuristic 1's approach of using 1.0 for exact fits and then scaling others below that is also valid. Heuristic 3's score for non-exact fits (`1.0 / (difference + 1e-9)`) can lead to very high priorities for very small differences, potentially more volatile than Heuristic 1's approach.\n*   **Heuristics 1 vs 5 & 6 (and 9):** Heuristics 5, 6, and 9 introduce a secondary criterion (favoring bins that are less empty). Heuristic 1 prioritizes tightest fits after exact fits. The introduction of secondary criteria adds complexity and tunable parameters (like the scaling for non-best-fit bins) that might not always be beneficial. Heuristic 1's focused approach is simpler.\n*   **Heuristics 1 vs 7 & 9:** Heuristics 7 and 9 attempt to refine Best Fit by penalizing \"too full\" bins or by favoring a peak at a moderate remaining capacity (`r_after * exp(-k*r_after)`). While these are interesting \"outside the box\" ideas, they introduce more parameters (`tolerance`, `k`, `weights`, `tightness_threshold_factor`) and are less straightforward than Heuristic 1's clear Best Fit logic.\n*   **Heuristics 1 vs 13 (First Fit):** Heuristic 1 (Best Fit) is generally considered better than First Fit for minimizing the number of bins, as it makes more informed local decisions. Heuristic 13 is a basic implementation of First Fit and doesn't use priority scores in a way that allows for selection among multiple fitting bins.\n*   **Heuristics 1 vs 15 & 17:** Heuristics 15 and 17 combine exact fit (1.0) with a sigmoid score for tight fits. The sigmoid approach (`1 / (1 + exp(-k * (ratio - 1)))`) aims to penalize larger bins. Heuristic 1's approach is simpler: exact fits first, then pure Best Fit (implicitly, by penalizing bins that cannot fit). The sigmoid adds complexity with the `k` parameter.\n*   **Heuristics 1 vs 16 & 20:** Heuristics 16 and 20 use a multi-component scoring system (tightness, anti-tightness, fullness preference) with weights. This is significantly more complex and parameter-dependent than Heuristic 1.\n*   **Heuristics 1 vs 18:** Heuristic 18 combines exact fit (1.0) with inverse remaining capacity, scaled. It also assigns a low priority to unsuitable bins. Heuristic 1's explicit penalty for unsuitable bins (implicitly by assigning 0 priority) and its clear two-tier Best Fit logic make it more understandable.\n*   **Overall:** Heuristic 1 stands out for its clarity, simplicity, and effective combination of two strong strategies (Exact Fit First and Best Fit). It avoids complex, tunable functions or multi-component scores, making it a robust and easy-to-understand heuristic. The other heuristics introduce complexity (sigmoid, multi-factor scoring, peak functions) often tied to specific tunable parameters or less direct logic.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Simplicity, Robustness, Interpretability, Explicit Penalties, Logical Hierarchy.\n*   **Advice:** Focus on intuitive, rule-based strategies. Define a clear, prioritized sequence of simple objectives. Implement explicit checks and penalties for invalid or suboptimal choices.\n*   **Avoid:** Complex, opaque mathematical functions without empirical validation. Arbitrary weighting or blending of criteria. Mimicking sequential logic through static scores.\n*   **Explanation:** Simpler heuristics are easier to debug, adapt, and understand, leading to more reliable performance across diverse problem instances. Explicitly addressing constraints and undesirable states through penalties makes the heuristic's behavior predictable.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}