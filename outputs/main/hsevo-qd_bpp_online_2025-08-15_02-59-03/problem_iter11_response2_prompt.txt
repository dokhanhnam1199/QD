{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    This heuristic prioritizes bins that can fit the item and, among those,\n    favors bins that would leave the least remaining capacity after packing (Best Fit).\n    Additionally, it assigns a higher priority to bins that are \"closer\" to being full,\n    as this might encourage packing smaller items into less utilized bins first,\n    potentially leaving larger capacities for larger items later.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if np.any(suitable_bins_mask):\n        # Calculate the remaining capacity for suitable bins after packing the item\n        remaining_capacities_after_packing = bins_remain_cap[suitable_bins_mask] - item\n\n        # Find the minimum remaining capacity (Best Fit criterion)\n        min_remaining_capacity = np.min(remaining_capacities_after_packing)\n\n        # Create a mask for bins that achieve the best fit\n        best_fit_mask = suitable_bins_mask & (bins_remain_cap - item == min_remaining_capacity)\n\n        # Assign a base priority to bins that are a best fit\n        priorities[best_fit_mask] = 1.0\n\n        # Introduce a secondary priority: favor bins that are less empty (closer to full)\n        # This can be done by inverting the remaining capacity (before packing) or using the original capacity.\n        # Let's use the original remaining capacity, higher values mean more available space.\n        # We want to prioritize bins that have *less* remaining capacity, so we can invert this.\n        # However, simply inverting might lead to negative priorities if we normalize.\n        # A better approach is to use a value that increases as capacity decreases.\n        # Let's consider bins that are *not* the absolute best fit, but still suitable.\n        # For these bins, we can assign a priority based on how \"tight\" the fit is,\n        # or how much remaining capacity they have.\n        # Let's refine: For bins that are not the absolute best fit, assign a score\n        # proportional to how much *less* remaining capacity they have compared to\n        # the largest available capacity among suitable bins. This encourages using\n        # bins that are already somewhat full.\n\n        suitable_bins_original_capacities = bins_remain_cap[suitable_bins_mask]\n        max_suitable_capacity = np.max(suitable_bins_original_capacities)\n\n        # For bins that are suitable but not the best fit:\n        # Assign a priority inversely proportional to their remaining capacity.\n        # Higher priority for bins with less remaining capacity.\n        # We can scale this to avoid overlapping with the '1.0' priority of best-fit bins.\n        # A simple approach is to assign a priority value between 0 and 1,\n        # where 0.5 might be a good intermediate value.\n        # The priority should be higher for smaller remaining_capacities_after_packing.\n        # Let's map remaining_capacities_after_packing to a value from 0 to 0.5.\n        # Higher priority for smaller remaining_capacities_after_packing.\n\n        non_best_fit_suitable_mask = suitable_bins_mask & ~best_fit_mask\n\n        if np.any(non_best_fit_suitable_mask):\n            non_best_fit_remaining_caps_after = bins_remain_cap[non_best_fit_suitable_mask] - item\n            # Normalize these remaining capacities to be between 0 and 0.5\n            # A simple linear scaling:\n            # If there's only one non-best-fit bin, it gets 0.5.\n            # If there are multiple, map the smallest remaining capacity to 0.5 and largest to 0.\n            min_non_best_fit_rem_cap = np.min(non_best_fit_remaining_caps_after)\n            max_non_best_fit_rem_cap = np.max(non_best_fit_remaining_caps_after)\n\n            if max_non_best_fit_rem_cap == min_non_best_fit_rem_cap:\n                # All non-best-fit bins have the same remaining capacity\n                priorities[non_best_fit_suitable_mask] = 0.5\n            else:\n                # Scale remaining capacities to the range [0, 0.5)\n                scaled_priorities = 0.5 * (1 - (non_best_fit_remaining_caps_after - min_non_best_fit_rem_cap) / (max_non_best_fit_rem_cap - min_non_best_fit_rem_cap))\n                priorities[non_best_fit_suitable_mask] = scaled_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a\n    modified Best Fit strategy that also considers the \"tightness\" of the fit\n    and the potential for future packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if not np.any(suitable_bins_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    # Calculate the remaining capacity after placing the item\n    remaining_after_fit = suitable_bins_remain_cap - item\n    \n    # Heuristic 1: Prioritize bins where the item fits snugly (minimizing waste in this bin)\n    # We use a value that is inversely proportional to the remaining capacity after fitting.\n    # Add a small epsilon to avoid division by zero if remaining_after_fit is 0.\n    snug_fit_scores = 1.0 / (remaining_after_fit + 1e-9)\n\n    # Heuristic 2: Prioritize bins that will have more remaining capacity AFTER the item is placed.\n    # This can be useful if we anticipate packing larger items later and want to reserve\n    # larger bins, or if we want to keep bins with moderate remaining capacity.\n    # Let's give a slight bonus to bins that will have a medium amount of remaining capacity.\n    # A simple way is to give a higher score to bins whose remaining capacity is closer to the median.\n    # Or, a simpler approach: prioritize bins that leave a \"good amount\" of space, but not too much.\n    # Let's try to penalize bins that become nearly empty or still very large.\n    # We can use a Gaussian-like function centered around a 'desirable' remaining capacity.\n    # For simplicity here, let's consider leaving a moderate amount of space as good.\n    # We can map remaining_after_fit to a score where middle values are higher.\n    # A simple approach: score = 1 - (x - target)^2 / range^2.\n    # Let's assume a target remaining capacity is around half of the bin's original capacity,\n    # but this is complex as we don't know original capacity.\n    # A simpler heuristic: prioritize bins that leave a moderate amount of space,\n    # e.g., not too close to 0 and not too close to the original capacity.\n    # Let's consider bins that leave remaining capacity between 10% and 50% of the *item size* as moderately good.\n    # This is a bit ad-hoc but aims to keep bins that are neither too full nor too empty for the current item.\n    moderate_space_scores = np.zeros_like(suitable_bins_remain_cap)\n    lower_bound = item * 0.1\n    upper_bound = item * 0.5\n    \n    valid_moderate_mask = (remaining_after_fit >= lower_bound) & (remaining_after_fit <= upper_bound)\n    moderate_space_scores[valid_moderate_mask] = 1.0\n    \n    # Combine scores: A weighted sum or a simple addition might work.\n    # Let's try a weighted sum. The snug fit is often the primary goal in BPP.\n    # We can add the moderate space score as a secondary factor.\n    combined_scores = snug_fit_scores + 0.2 * moderate_space_scores # Weighting snug fit more\n\n    # Normalize scores to be between 0 and 1 (optional, but good for consistent priority interpretation)\n    if np.max(combined_scores) > 0:\n        normalized_scores = combined_scores / np.max(combined_scores)\n    else:\n        normalized_scores = combined_scores\n\n    # Assign priorities to the original array\n    priorities[suitable_bins_mask] = normalized_scores\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Exact fit + graded Best Fit) vs. Heuristic 10 (Basic inverse of remaining capacity without handling exact fits or suitability): Heuristic 1 is superior due to its explicit handling of exact fits and its more nuanced scoring for non-exact fits, leading to more predictable and often better packing.\n\nComparing Heuristic 1 vs. Heuristic 12 (Simple inverse of remaining capacity for fitting bins): Heuristic 1's explicit high priority for exact fits (score 2.0) and graded scoring for non-exact fits (1.0 / diff) provides a more robust \"Best Fit\" approach than Heuristic 12's simple inverse, which might not distinguish between exact fits and other close fits as effectively.\n\nComparing Heuristic 2 (Modified Best Fit with perfect fit prioritization) vs. Heuristic 11 (Balanced Fit, prioritizing moderate remaining capacity): Heuristic 2's explicit prioritization of perfect fits (score 2.0) and then a graded \"least remaining capacity\" for others is a clear hierarchy. Heuristic 11's approach of peaking at a moderate remaining capacity (using `r * exp(-k*r)`) is a different strategy that might perform better in some scenarios by avoiding overly full bins, but lacks the clear initial preference for exact fits that Heuristic 2 provides.\n\nComparing Heuristic 18/19 (Exact fit + scaled Best Fit) vs. Heuristic 1 (Exact fit + graded Best Fit): Heuristics 18/19 use a scaled inverse of the difference for non-exact fits, normalized to a range below the exact fit priority. Heuristic 1 uses a simpler inverse. Heuristics 18/19 offer a more controlled prioritization for non-exact fits, ensuring they are clearly secondary to exact fits.\n\nComparing Heuristic 16 (First Fit simulation) vs. Heuristic 20 (First Fit simulation with minor index bias): Both are attempts to mimic First Fit (FF). Heuristic 16 and 20 assign a high priority to the *first* bin that fits. The minor bias in Heuristic 20 is an artificial way to favor earlier bins, which is inherent in FF's sequential nature. However, a true FF implementation typically involves sequential iteration, not just scoring. These are less sophisticated than \"Best Fit\" variations.\n\nOverall: Heuristics that explicitly prioritize exact fits and then use a graded approach for \"Best Fit\" (like 1, 18, 19) or combine exact fits with a well-defined secondary strategy (like 2, 9) tend to be better. Simple \"Best Fit\" (12, 13) or variations that aim for moderate fill (11, 14, 15) are also reasonable. Heuristics simulating First Fit (16, 20) or basic inverse scoring without refinement (10) are generally less robust.\n- \nHere's a redefinition of self-reflection for designing better heuristics:\n\n*   **Keywords:** Objective-driven, measurable improvement, adaptive strategies, principled design.\n*   **Advice:** Focus on *why* a strategy works. Does it directly address a quantifiable objective (e.g., minimizing waste)? Explore how to *adapt* to different problem characteristics, rather than just mimicking existing ones.\n*   **Avoid:** Overly complex, arbitrary mathematical functions (like `r * exp(-k*r)`) without a clear theoretical or empirical justification for their specific form. Avoid \"simulating\" known heuristics if a more direct, objective-driven approach is possible.\n*   **Explanation:** The goal is to build heuristics that are understood through their objective alignment and demonstrable performance improvements, not through the intricacy of their mathematical formulation or a blind imitation of prior methods.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}