```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """
    Heuristic function for TSP using a combination of factors and sparsification,
    with improved nearest neighbor consideration, centrality, and normalization.

    Args:
        distance_matrix (np.ndarray): A 2D numpy array representing the distance matrix.

    Returns:
        np.ndarray: A 2D numpy array of the same shape as distance_matrix,
                    representing the heuristic values (prior indicators) for each edge.
    """

    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Calculate nearest neighbors for each node
    nearest_neighbors = np.argsort(distance_matrix, axis=1)

    # Calculate node centrality (degree centrality approximation using inverse distance sum)
    node_centrality = np.zeros(n)
    for i in range(n):
        node_centrality[i] = np.sum(1 / (distance_matrix[i, :] + 1e-6))  # Adding a small constant to avoid division by zero

    # Normalize node centrality
    node_centrality = (node_centrality - np.min(node_centrality)) / (np.max(node_centrality) - np.min(node_centrality) + 1e-6)


    for i in range(n):
        for j in range(n):
            if i != j:
                distance = distance_matrix[i, j]

                # Heuristic factor 1: Inverse distance
                heuristic_factor_1 = 1 / distance if distance > 0 else 0  # Avoid division by zero

                # Heuristic factor 2: Nearest neighbor rank (sharper decay)
                nn_rank = np.where(nearest_neighbors[i] == j)[0][0] + 1
                heuristic_factor_2 = np.exp(-nn_rank / 2)

                # Heuristic factor 3: Average distance of nodes involved
                avg_dist_i = np.mean(distance_matrix[i, :])
                avg_dist_j = np.mean(distance_matrix[j, :])
                heuristic_factor_3 = 1 / (avg_dist_i + avg_dist_j) if (avg_dist_i + avg_dist_j) > 0 else 0

                # Heuristic factor 4: Node Centrality.  Higher centrality implies higher likelihood of importance
                heuristic_factor_4 = (node_centrality[i] + node_centrality[j]) / 2 #Use the average centrality of both nodes.


                # Combine the factors. Experiment with different weights.
                heuristic_matrix[i, j] = (0.4 * heuristic_factor_1 +
                                          0.3 * heuristic_factor_2 +
                                          0.2 * heuristic_factor_3 +
                                          0.1 * heuristic_factor_4)

    # Sparsify the matrix: keep only top K edges for each node (or edges below a certain threshold)
    k = int(np.sqrt(n))  # Keep sqrt(n) nearest edges to each node (parameter can be tuned)
    for i in range(n):
        row = heuristic_matrix[i, :]
        indices = np.argsort(row)[::-1]  # Indices of the highest values in descending order
        keep_indices = indices[:k]       #Indices to retain

        mask = np.ones(n, dtype=bool)
        mask[keep_indices] = True
        heuristic_matrix[i, ~mask] = 0  # Set other entries to zero, to allow efficient sampling later

    # Normalize the heuristic values for better sampling behavior
    max_heuristic = np.max(heuristic_matrix)
    if max_heuristic > 0:
        heuristic_matrix = heuristic_matrix / max_heuristic
    else:
        # If all heuristic values are zero, set them to a small uniform value to allow for some exploration
        heuristic_matrix = np.ones_like(heuristic_matrix) * 1e-9

    return heuristic_matrix
```
