[
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic with waste, fill ratio, randomization, and bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with cubic penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, significant for larger items, boosted by bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness)\n\n    # Dynamic randomization, inversely proportional to bin fill, scales with item size & capacity variance\n    cap_variance = np.var(bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 + cap_variance)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scales with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement. Scale with occupancy\n    fill_ratio_after_simple = (1 - wasted_space[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after_simple * 0.2 * average_occupancy\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Incentivize placing large items in emptier bins\n    if item > bins_remain_cap.max() / 2:\n        priorities[feasible_bins] += (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * 0.05\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response1.txt_stdout.txt",
    "code_path": "problem_iter20_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with dynamic non-linear penalty. Larger waste penalized more\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n    priorities[feasible_bins] -= waste_penalty\n\n    # Fill ratio bonus, scaled by item size and bin fullness.  Emphasis on nearly-full bins.\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2) # Non-linear fullness boost\n\n    # Dynamic randomization, proportional to item size and remaining capacity variance\n    capacity_std = np.std(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.sum(feasible_bins) > 1 else 0.0\n    randomization_strength = 0.03 * item_scale * (1 + capacity_std) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Penalty for leaving bins mostly empty, adjusted by average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())**2 * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.05 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Significant bonus for bins becoming almost full, scaled by how close they are\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = 0.2 * (1 - wasted_space_after[almost_full] / (0.05 * bins_remain_cap.max())) if np.any(almost_full) else 0.0\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Smaller items have a higher chance to explore (fit in emptier bins)\n    if item < 0.2 * bins_remain_cap.max():\n        exploration_bonus = 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += exploration_bonus\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins.\n    if item > 0.7 * bins_remain_cap.max():\n        large_item_bonus = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += large_item_bonus\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response2.txt_stdout.txt",
    "code_path": "problem_iter20_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio and randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste Minimization\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= wasted_space[feasible_bins]\n\n    # Fill Ratio Bonus\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] += fill_ratio_after * 0.2\n\n    # Adaptive Randomization\n    randomization_strength = 0.05 * item * (1 - wasted_space[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Empty bin penalty\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response3.txt_stdout.txt",
    "code_path": "problem_iter20_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, controlled randomization, and emptiness penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with scaled penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, scaled by item size and bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness)\n\n    # Controlled randomization, inversely proportional to bin fill\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response4.txt_stdout.txt",
    "code_path": "problem_iter20_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, landscape and dynamic exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with dynamic non-linear penalty.\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n    priorities[feasible_bins] -= waste_penalty\n\n    # Fill ratio bonus, scaled by item size and bin fullness.\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2)\n\n    # Dynamic randomization, proportional to item size and remaining capacity variance\n    capacity_std = np.std(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.sum(feasible_bins) > 1 else 0.0\n    randomization_strength = 0.03 * item_scale * (1 + capacity_std) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Penalty for leaving bins mostly empty, adjusted by average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())**2 * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.05 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Significant bonus for bins becoming almost full, scaled by how close they are\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = 0.2 * (1 - wasted_space_after[almost_full] / (0.05 * bins_remain_cap.max())) if np.any(almost_full) else 0.0\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Smaller items have a higher chance to explore (fit in emptier bins)\n    if item < 0.2 * bins_remain_cap.max():\n        exploration_bonus = 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += exploration_bonus\n\n    # Large Item Consideration (New): Incentivize placing large items in emptier bins\n    if item > 0.8 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response5.txt_stdout.txt",
    "code_path": "problem_iter20_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, fill ratio, and dynamic exploration based on bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    avg_bin_cap = np.mean(bins_remain_cap)\n\n    # 1. Waste Minimization (Non-linear)\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space / max_bin_cap)**2\n    priorities[feasible_bins] -= waste_penalty[feasible_bins] * 0.1\n\n    # 2. Adaptive Fill Ratio Bonus\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] += fill_ratio_after * 0.2\n\n    # 3. Dynamic Exploration\n    exploration_strength = 0.05 * item * (1 - avg_bin_cap / max_bin_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_strength\n\n    # 4. Dynamic empty bin penalty, adjusting to the overall bin landscape\n    average_bin_usage = np.mean(bins_remain_cap) / max_bin_cap\n    empty_bin_penalty = (bins_remain_cap / max_bin_cap) * (1 - average_bin_usage)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1\n\n    # 5. Almost Full Bonus\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full_threshold = 0.04 * max_bin_cap\n    almost_full = wasted_space_after <= almost_full_threshold\n    priorities[feasible_bins][almost_full] += 0.15\n\n    # 6. Large Item Consideration\n    if item > 0.5 * max_bin_cap:\n        empty_bin_bonus = (bins_remain_cap[feasible_bins] / max_bin_cap) * 0.05\n        priorities[feasible_bins] += empty_bin_bonus\n    \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response6.txt_stdout.txt",
    "code_path": "problem_iter20_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, randomization, emptiness penalty, near-full reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # No feasible bins\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0  # Ensure non-negative waste\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / np.max(bins_remain_cap)\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Adaptive Randomization\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins\n    almost_full_threshold = 0.1\n    almost_full_bins = (wasted_space[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    # Empty Bin Penalty\n    average_fill = np.mean(1 - bins_remain_cap / np.max(bins_remain_cap))\n    empty_bin_penalty = (bins_remain_cap / np.max(bins_remain_cap))\n    penalty_scale = 0.05 * (1 - average_fill)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Bonus for current fill ratio\n    current_fill_ratio = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    priorities[feasible_bins] += current_fill_ratio[feasible_bins] * 0.05\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.547267650578394,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response7.txt_stdout.txt",
    "code_path": "problem_iter20_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic. Combines waste minimization, fill ratio, exploration and bin landscape awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    avg_bin_cap = np.mean(bins_remain_cap)\n    std_bin_cap = np.std(bins_remain_cap)\n\n    # 1. Dynamic Waste Minimization (Non-linear penalty)\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space / max_bin_cap)**3  # Cubic penalty for larger waste\n    priorities[feasible_bins] -= waste_penalty[feasible_bins] * (item / max_bin_cap)\n\n    # 2. Adaptive Fill Ratio Bonus\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / max_bin_cap\n\n    # Adjust fill ratio bonus based on item size and bin fullness\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / max_bin_cap\n    fill_bonus = fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2) # Non-linear fullness boost\n    priorities[feasible_bins] += fill_bonus\n\n    # 3. Dynamic Exploration (Randomization)\n    # More exploration for smaller items and fuller bins\n    exploration_strength = 0.03 * (item / max_bin_cap) * (1 - avg_bin_cap / max_bin_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_strength\n\n    # 4. Empty Bin Penalty (Adaptive)\n    # Scales with both item size and average remaining capacity\n    empty_bin_penalty = (bins_remain_cap / max_bin_cap) * (item / max_bin_cap)\n    empty_bin_weight = 0.01 + 0.04 * (1 - avg_bin_cap / max_bin_cap) # Scales with occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_weight\n\n    # 5. \"Almost Full\" Bonus (Enhanced)\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full_threshold = 0.04 * max_bin_cap\n    almost_full = wasted_space_after <= almost_full_threshold\n    priorities[feasible_bins][almost_full] += 0.15  # Increased bonus\n\n    # 6. Large Item Consideration\n    if item > 0.5 * max_bin_cap:\n        empty_bin_bonus = (bins_remain_cap[feasible_bins] / max_bin_cap) * 0.05\n        priorities[feasible_bins] += empty_bin_bonus\n\n    # 7. Bin Capacity Variance Penalty (New - Encourages balancing)\n    capacity_variance_penalty = (std_bin_cap / max_bin_cap) * 0.02\n    priorities[feasible_bins] -= capacity_variance_penalty\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response8.txt_stdout.txt",
    "code_path": "problem_iter20_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, controlled randomization,\n    empty bin penalty, and almost full reward. Adapts to bin landscape.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0\n\n    # Prioritize based on wasted space, normalized\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / np.max(bins_remain_cap)\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.05 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins\n    almost_full_threshold = 0.1\n    almost_full_bins = (bins_remain_cap[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    # Empty Bin Penalty: Penalize bins that are too empty, adjust based on average fill.\n    average_fill = np.mean(1 - bins_remain_cap / np.max(bins_remain_cap))\n    empty_bin_penalty = (bins_remain_cap / np.max(bins_remain_cap))\n    penalty_scale = 0.05 * (1 - average_fill)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Reward bins close to full before insertion, non-linear bonus\n    current_fill_ratio = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    priorities[feasible_bins] += current_fill_ratio[feasible_bins]**2 * 0.1 # Non-linear bonus\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.736737136019147,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response9.txt_stdout.txt",
    "code_path": "problem_iter20_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, controlled randomization, emptiness penalty and almost full reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by bin cap variance\n    wasted_space = bins_remain_cap - item\n    waste_penalty_scale = np.var(bins_remain_cap) if np.var(bins_remain_cap) > 0 else bins_remain_cap.max()\n    priorities[feasible_bins] -= (wasted_space[feasible_bins]**2) / (waste_penalty_scale + 1e-9)\n\n    # Adaptive fill ratio bonus, scaled by item size and bin capacity. Non-linear fullness boost\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    fill_bonus_weight = 0.2 + 0.3 * item_scale * (1 + fill_ratio_after)\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization scaled by remaining capacity and item size\n    randomization_strength = 0.05 * (1 - item_scale) * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item_scale)\n    empty_bin_penalty_weight = 0.03 * (1 - fill_ratio_after)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Near full bonus\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response0.txt_stdout.txt",
    "code_path": "problem_iter21_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio,\n    bin landscape awareness, and dynamic parameter adjustment.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Scale item size to bin capacity range\n    item_scale = item / bins_remain_cap.max()\n\n    # Dynamic waste minimization penalty, adjusted by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = 0.5 + 0.5 * item_scale  # Adjust penalty based on item size\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Fill ratio bonus with dynamic weighting based on bin occupancy\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_ratio_weight = 0.2 + 0.6 * bin_fullness  # Weight fill ratio by current bin fullness\n    priorities[feasible_bins] += fill_ratio_after * fill_ratio_weight * item_scale\n\n    # Controlled randomization, stronger for smaller items and emptier bins\n    randomization_strength = 0.1 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with average occupancy & inverse item size\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.05 + 0.05 * average_occupancy * (1 - item_scale)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Strong bonus for bins becoming very full after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.03  # Tighter threshold\n    almost_full_bonus = 0.2 + 0.3 * item_scale  # Bonus scales with item size, incentivizing final placements\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Encourage even distribution by penalizing bins close to the average remaining capacity\n    capacity_difference = np.abs(bins_remain_cap[feasible_bins] - np.mean(bins_remain_cap)) / bins_remain_cap.max()\n    distribution_penalty = 0.02 * capacity_difference * item_scale\n    priorities[feasible_bins] -= distribution_penalty\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.068607897885915,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response1.txt_stdout.txt",
    "code_path": "problem_iter21_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced adaptive heuristic for online bin packing.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # Punish infeasible solutions harshly\n\n    # 1. Waste Minimization with Adaptive Scaling:\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_ratio = wasted_space[feasible_bins] / bins_remain_cap.max()\n    item_importance = item / bins_remain_cap.max()  # Scale by item size\n    priorities[feasible_bins] -= (waste_ratio**2) * item_importance * (1 + np.mean(bins_remain_cap / bins_remain_cap.max()))  # Adjust penalty based on average occupancy\n\n    # 2. Fill Ratio Bonus with Dynamic Adjustment:\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_bonus = fill_ratio_after * 0.3 * item_importance * (1 + bin_fullness**2)  # Non-linear bonus for near-full bins\n    priorities[feasible_bins] += fill_bonus\n\n    # 3. Controlled Exploration based on Item Size and Bin Landscape:\n    remaining_capacity_ratio = bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    randomization_strength = 0.05 * item_importance * remaining_capacity_ratio # More randomness for emptier bins and smaller items.\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # 4. Dynamic Empty Bin Penalty:\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (remaining_capacity_ratio) * (1 - item_importance) # Scales with remaining capacity and item size\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy # Increase penalty weight if bins are generally full.\n    priorities[feasible_bins] -= empty_bin_penalty * empty_bin_penalty_weight\n\n    # 5. Aggressive Bonus for Almost Full Bins:\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.2  # Substantially reward filling bins completely\n\n    # 6. Penalize highly fragmented bins:\n    fragmentation_penalty = np.zeros_like(bins_remain_cap[feasible_bins])\n    for i in range(len(bins_remain_cap[feasible_bins])):\n        if bins_remain_cap[feasible_bins][i] > item and bins_remain_cap[feasible_bins][i] < 2 * item:\n            fragmentation_penalty[i] = 0.05 * item_importance\n    priorities[feasible_bins] -= fragmentation_penalty\n            \n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997540000004 seconds"
  },
  {
    "stdout_filepath": "problem_iter21_response2.txt_stdout.txt",
    "code_path": "problem_iter21_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and bin landscape awareness with dynamic adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with adaptive scaling based on item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = (item / bins_remain_cap.max())**0.5  # Smaller items penalize waste less\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Adaptive fill ratio bonus, scaled by remaining capacity and occupancy variance\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    capacity_scale = (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    occupancy_variance = np.var(1 - bins_remain_cap / bins_remain_cap.max()) # Variance as landscape awareness\n    fill_bonus_weight = 0.2 + 0.3 * (1 - occupancy_variance) # Reduce fill bonus if bins are similarly full\n    priorities[feasible_bins] += fill_ratio_after * fill_bonus_weight * capacity_scale\n\n    # Controlled randomization, inversely proportional to bin fullness and item size\n    randomization_strength = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.04 * average_occupancy  # Reduced penalty, more subtle\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Stronger bonus for almost full bins after insertion, scaled non-linearly\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = (1 - wasted_space_after[almost_full] / bins_remain_cap.max())**2 # Non-linear bonus\n    priorities[feasible_bins][almost_full] += 0.15 * almost_full_bonus\n\n    # Penalty for placing small items into almost empty bins (delayed commitment)\n    almost_empty = bins_remain_cap[feasible_bins] / bins_remain_cap.max() > 0.8\n    small_item = item / bins_remain_cap.max() < 0.2\n    if np.any(almost_empty) and small_item:\n        priorities[feasible_bins][almost_empty] -= 0.05 * small_item  # Slight discouragement\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 6.082967690466694,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response3.txt_stdout.txt",
    "code_path": "problem_iter21_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Advanced heuristic combining waste minimization, fill ratio, bin landscape awareness, and dynamic exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with adaptive scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = np.clip(item / bins_remain_cap.max(), 0.1, 0.5)  # Scale based on item size\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Fill ratio bonus, scaled by item size and bin fullness (non-linear reward)\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after**1.5 * 0.4 * item_scale * (1 + bin_fullness**2) # non-linear fill ratio\n\n    # Controlled randomization, inversely proportional to bin fullness (adaptive exploration)\n    randomization_strength = 0.1 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())**2 # less full means more random\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy (dynamic)\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.1 * average_occupancy # dynamic update based on average\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Strong bonus for almost full bins after insertion (exploitation)\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.2  # stronger bonus\n\n    # Penalty for creating nearly empty bins (bin landscape awareness)\n    nearly_empty = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap.max() > 0.9\n    priorities[feasible_bins][nearly_empty] -= 0.15 * item_scale # small penalty\n\n    # Encourage utilizing bins around the median fullness to promote even distribution.\n    median_fullness = np.median(1 - bins_remain_cap / bins_remain_cap.max())\n    fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    distance_from_median = np.abs(fullness - median_fullness)\n    priorities[feasible_bins] -= 0.05 * item_scale * distance_from_median\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response4.txt_stdout.txt",
    "code_path": "problem_iter21_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and bin landscape awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with scaled penalty, more aggressively penalized for larger items\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())**1.5\n\n    # Adaptive fill ratio bonus, scaled by item size, bin fullness, and a sigmoid function for gradual reward\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    sigmoid_fullness = 1 / (1 + np.exp(-10 * (bin_fullness - 0.5)))  # Sigmoid around 0.5 fullness\n    priorities[feasible_bins] += fill_ratio_after * 0.35 * item_scale * (1 + sigmoid_fullness)\n\n    # Controlled randomization, inversely proportional to bin fill and item size, increased exploration for small items\n    randomization_strength = 0.05 * (1 - item_scale)**2 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item, average occupancy, and bin's relative capacity.  Avoid overfilling slightly filled bins\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())**0.5 * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.09 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Stronger bonus for almost full bins after insertion, sigmoid to smoothen the transition.\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    sigmoid_almost_full = 1 / (1 + np.exp(50 * (wasted_space_after / bins_remain_cap.max() - 0.05)))\n    priorities[feasible_bins][almost_full] += 0.15 * sigmoid_almost_full[almost_full] #scaled by the sigmoid.\n\n    # Extra bonus for filling almost empty bins with large item\n    almost_empty = bins_remain_cap[feasible_bins] > 0.9 * bins_remain_cap.max()\n    if item > 0.6 * bins_remain_cap.max():\n        priorities[feasible_bins][almost_empty] += 0.07\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.068607897885915,
    "exec_success": true
  }
]