import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray,
                 waste_penalty_min_scale: float = 0.22399617347566247,
                 waste_penalty_max_scale: float = 0.8634045059809357,
                 fill_ratio_weight: float = 0.995872819634127,
                 randomization_strength_scale: float = 0.9307567619757817,
                 almost_full_bonus: float = 0.16607962209522742,
                 empty_bin_penalty_scale: float = 0.5718414192252098,
                 nearly_empty_penalty: float = 0.1624271330290037,
                 almost_full_threshold: float = 0.5337930599723525,
                 nearly_empty_threshold: float = 0.3744362422074502) -> np.ndarray:
    """Combines waste minimization, adaptive fill ratio, controlled randomization, almost full reward, and empty bin penalty with landscape awareness."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if not np.any(feasible_bins):
        return priorities - np.inf

    # Waste minimization with adaptive scaling
    wasted_space = bins_remain_cap - item
    wasted_space[~feasible_bins] = np.inf
    waste_penalty_scale = np.clip(item / bins_remain_cap.max(), waste_penalty_min_scale, waste_penalty_max_scale)
    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale

    # Adaptive fill ratio bonus, scaled by item size
    fill_ratio_after = item / bins_remain_cap[feasible_bins]
    item_scale = item / bins_remain_cap.max()
    priorities[feasible_bins] += fill_ratio_after * fill_ratio_weight * item_scale

    # Controlled randomization, inversely proportional to bin fullness.
    randomization_strength = randomization_strength_scale * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())**2
    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength

    # Strong bonus for almost full bins after insertion
    wasted_space_after = bins_remain_cap[feasible_bins] - item
    almost_full = wasted_space_after / bins_remain_cap.max() < almost_full_threshold
    priorities[feasible_bins][almost_full] += almost_full_bonus

    # Empty Bin Penalty: Penalize bins that are too empty, adjust based on average fill.
    average_fill = np.mean(1 - bins_remain_cap / bins_remain_cap.max())
    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())
    penalty_scale = empty_bin_penalty_scale * (1 - average_fill)
    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale

    # Landscape aware penalty for creating nearly empty bins
    nearly_empty = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap.max() > nearly_empty_threshold
    priorities[feasible_bins][nearly_empty] -= nearly_empty_penalty * item_scale

    return priorities
