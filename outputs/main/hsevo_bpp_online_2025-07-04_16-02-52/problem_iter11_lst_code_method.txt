{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization, and adaptive penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 #non-linear penalty\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Controlled randomization, scaled by (1 - item_scale)\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n    \n    #Adaptive bin-emptiness penalty\n    empty_penalty = (bins_remain_cap / bins_remain_cap.max())[feasible_bins]\n    priorities[feasible_bins] -= empty_penalty * 0.01 # scale down\n\n    # Bonus for bins nearing full capacity, reduced magnitude\n    almost_full = (wasted_space[feasible_bins] / bins_remain_cap.max()) < 0.05\n    priorities[feasible_bins][almost_full] += 0.01 # smaller bonus.\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization, and adaptive penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 #non-linear penalty\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Controlled randomization, scaled by (1 - item_scale)\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n    \n    #Adaptive bin-emptiness penalty\n    empty_penalty = (bins_remain_cap / bins_remain_cap.max())[feasible_bins]\n    priorities[feasible_bins] -= empty_penalty * 0.01 # scale down\n\n    # Bonus for bins nearing full capacity, reduced magnitude\n    almost_full = (wasted_space[feasible_bins] / bins_remain_cap.max()) < 0.05\n    priorities[feasible_bins][almost_full] += 0.01 # smaller bonus.\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization, and adaptive penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 #non-linear penalty\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Controlled randomization, scaled by (1 - item_scale)\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n    \n    #Adaptive bin-emptiness penalty\n    empty_penalty = (bins_remain_cap / bins_remain_cap.max())[feasible_bins]\n    priorities[feasible_bins] -= empty_penalty * 0.01 # scale down\n\n    # Bonus for bins nearing full capacity, reduced magnitude\n    almost_full = (wasted_space[feasible_bins] / bins_remain_cap.max()) < 0.05\n    priorities[feasible_bins][almost_full] += 0.01 # smaller bonus.\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization, and adaptive penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 #non-linear penalty\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Controlled randomization, scaled by (1 - item_scale)\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n    \n    #Adaptive bin-emptiness penalty\n    empty_penalty = (bins_remain_cap / bins_remain_cap.max())[feasible_bins]\n    priorities[feasible_bins] -= empty_penalty * 0.01 # scale down\n\n    # Bonus for bins nearing full capacity, reduced magnitude\n    almost_full = (wasted_space[feasible_bins] / bins_remain_cap.max()) < 0.05\n    priorities[feasible_bins][almost_full] += 0.01 # smaller bonus.\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, fill ratio, adaptive randomization, and bin diversity\n    for bin prioritization, with an emphasis on exploration and preventing\n    premature bin commitment.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Fill ratio bonus, adaptive to the item size and bin capacity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    \n    # Adaptive fill ratio bonus, scaled by item size and remaining capacity\n    adaptive_fill_bonus = fill_ratio_after * (0.2 + 0.1 * (item / bins_remain_cap.max()))\n    priorities[feasible_bins] += adaptive_fill_bonus[feasible_bins]\n    \n    # Adaptive Randomization: More randomization for smaller items and fuller bins\n    randomization_strength = 0.05 * item * (1 + bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n    \n    # Bin Diversity Bonus: Encourage using bins with diverse fill levels.\n    # This is done by giving a bonus to bins whose remaining capacity is \n    # furthest from the average remaining capacity of all feasible bins.\n    if np.sum(feasible_bins) > 1:\n        avg_remaining_cap = np.mean(bins_remain_cap[feasible_bins])\n        diversity_bonus = np.abs(bins_remain_cap - avg_remaining_cap) / bins_remain_cap.max()\n        priorities[feasible_bins] += diversity_bonus[feasible_bins] * 0.05\n\n    # Prevent early commitment to bins that are almost full. Penalize bins with very small remaining capacity\n    almost_full_penalty = np.where(bins_remain_cap < 1.1*item, (1-(bins_remain_cap/ (1.1*item))),0) #apply the penalty only if the bin is almost full\n    \n    \n    priorities[feasible_bins] -= almost_full_penalty[feasible_bins] * 0.1 # scaled by a factor of 0.1 for balance.\n    \n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, controlled randomization, and bin-emptiness discouragement.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Adaptive fill ratio bonus, scale by item size relative to bin size\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap)\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.2 * item_scale\n\n    # Controlled randomization, scale randomization by (1 - item_scale)\n    randomization_factor = 0.05 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n\n    # Adaptive bin-emptiness penalty, heavier penalty for emptier bins\n    empty_bin_penalty = (1 - bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, adaptive randomization, and dynamic penalty for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.3  # Increased fill ratio weight\n\n    # Adaptive Randomization: Scale randomization based on the variance of remaining capacities.\n    # Higher variance suggests more diverse bin states, thus increased exploration\n    capacity_variance = np.var(bins_remain_cap[feasible_bins]) if np.any(feasible_bins) else 0.0\n    randomization_strength = 0.01 + 0.04 * (capacity_variance / bins_remain_cap.max()) # Scale randomization\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength * item\n    \n    # Dynamic Empty Bin Penalty:  Penalize near-empty bins, but adjust penalty strength dynamically.\n    # Stronger penalty if average bin occupancy is high (to avoid creating too many almost-empty bins).\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty_strength = 0.02 + 0.08 * average_occupancy # Dynamically adjust penalty\n\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_strength\n\n    # Bonus for bins with remaining capacity close to the item size. Prevents fragmentation\n    closeness = np.abs(bins_remain_cap[feasible_bins] - item)\n    closeness_bonus = np.exp(-closeness / (0.2 * bins_remain_cap.max())) # Gaussian-like bonus\n    priorities[feasible_bins] += closeness_bonus * 0.1\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, and adaptive penalties for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if the item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.3  # Increased fill ratio importance\n    \n    # Adaptive randomization: Smaller items get more randomization\n    randomization_scale = 0.1 * (1 - item / bins_remain_cap.max())  # Scale based on item size\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_scale\n    \n    # Adaptive empty bin penalty: Penalize near-empty bins more strongly when items are large\n    empty_bin_ratio = bins_remain_cap / bins_remain_cap.max()\n    empty_bin_penalty = empty_bin_ratio * (item / bins_remain_cap.max())  # Penalty scales with item size\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1\n    \n    # Bin balancing: Slightly prioritize bins with lower fill levels overall\n    average_fill_level = np.mean(bins_remain_cap)\n    bin_balance_bonus = (average_fill_level - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += bin_balance_bonus[feasible_bins] * 0.05\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, controlled randomization, \n    and dynamic bin-emptiness penalty for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n    \n    # Adaptive fill ratio bonus based on item size relative to bin size\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    fill_ratio_bonus = fill_ratio_after * (0.2 + 0.3 * item_scale)  # Adaptive bonus\n    priorities[feasible_bins] += fill_ratio_bonus[feasible_bins]\n    \n    # Controlled randomization, scale randomization by (1 - item_scale)\n    randomization_factor = 0.05 * (1 - item_scale) # Favor exploration for smaller items\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n    \n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * (0.02 + 0.03 * (1 - bins_remain_cap / bins_remain_cap.max()))[feasible_bins] #Dynamic penalty\n    \n    # Bonus for bins nearing full capacity\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins #Threshold tuning\n    priorities[almost_full] += 0.1\n    \n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, controlled randomization, \n    and dynamic bin-emptiness penalty for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n    \n    # Adaptive fill ratio bonus based on item size relative to bin size\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    fill_ratio_bonus = fill_ratio_after * (0.2 + 0.3 * item_scale)  # Adaptive bonus\n    priorities[feasible_bins] += fill_ratio_bonus[feasible_bins]\n    \n    # Controlled randomization, scale randomization by (1 - item_scale)\n    randomization_factor = 0.05 * (1 - item_scale) # Favor exploration for smaller items\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n    \n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * (0.02 + 0.03 * (1 - bins_remain_cap / bins_remain_cap.max()))[feasible_bins] #Dynamic penalty\n    \n    # Bonus for bins nearing full capacity\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins #Threshold tuning\n    priorities[almost_full] += 0.1\n    \n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using best-fit, fill ratio, adaptive randomization, and emptiness penalty.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    # Primary best-fit\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.3 * item_scale\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.03\n    priorities[bins_remain_cap >= item] -= empty_bin_penalty[bins_remain_cap >= item] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-wasted_space[bins_remain_cap >= item] * 5 / item)\n    priorities[bins_remain_cap >= item] += almost_perfect_fit * 0.1\n    \n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using best-fit, fill ratio, adaptive randomization, and emptiness penalty.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    # Primary best-fit\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.3 * item_scale\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.03\n    priorities[bins_remain_cap >= item] -= empty_bin_penalty[bins_remain_cap >= item] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-wasted_space[bins_remain_cap >= item] * 5 / item)\n    priorities[bins_remain_cap >= item] += almost_perfect_fit * 0.1\n    \n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using best-fit, fill ratio, adaptive randomization, and emptiness penalty.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    # Primary best-fit\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.3 * item_scale\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.03\n    priorities[bins_remain_cap >= item] -= empty_bin_penalty[bins_remain_cap >= item] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-wasted_space[bins_remain_cap >= item] * 5 / item)\n    priorities[bins_remain_cap >= item] += almost_perfect_fit * 0.1\n    \n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, fill_ratio_weight: float = 0.14186947394776347,\n                 randomization_scale: float = 0.027543638469598338, empty_penalty_scale: float = 0.01028656195916193,\n                 almost_full_threshold: float = 0.07250345035700985, almost_full_bonus: float = 0.01859654179121566) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization, and adaptive penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, fill_ratio_weight: float = 0.14186947394776347,\n                 randomization_scale: float = 0.027543638469598338, empty_penalty_scale: float = 0.01028656195916193,\n                 almost_full_threshold: float = 0.07250345035700985, almost_full_bonus: float = 0.01859654179121566) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization, and adaptive penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering waste, fill ratio, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if the item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item] / bins_remain_cap.max()\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.3\n    \n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n    \n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering waste, fill ratio, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if the item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item] / bins_remain_cap.max()\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.3\n    \n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n    \n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering waste, fill ratio, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if the item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item] / bins_remain_cap.max()\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.3\n    \n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n    \n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering waste, fill ratio, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if the item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item] / bins_remain_cap.max()\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.3\n    \n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n    \n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering waste, fill ratio, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if the item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item] / bins_remain_cap.max()\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.3\n    \n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength[bins_remain_cap >= item]\n    \n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}