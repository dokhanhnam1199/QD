[
  {
    "stdout_filepath": "problem_iter23_response0.txt_stdout.txt",
    "code_path": "problem_iter23_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, emptiness penalty, near-full reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization, scaled by item size and bin capacity\n    wasted_space = bins_remain_cap - item\n    waste_penalty_scale = np.mean(bins_remain_cap)\n    priorities[feasible_bins] -= (wasted_space[feasible_bins]**2) / (waste_penalty_scale + 1e-9) * (item / np.max(bins_remain_cap))\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (bins_remain_cap - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after[feasible_bins]) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Controlled Randomization, scaled to remaining capacity\n    randomization_strength = 0.05 * (np.max(bins_remain_cap) - bins_remain_cap) / np.max(bins_remain_cap) * item\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Emptiness Penalty, more severe for smaller items\n    empty_bin_penalty = (bins_remain_cap / np.max(bins_remain_cap))\n    penalty_scale = 0.03 * (1 - np.mean(1 - bins_remain_cap / np.max(bins_remain_cap))) * (1 - item / np.max(bins_remain_cap))\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Near full bonus\n    almost_full_threshold = 0.1\n    almost_full_bins = (wasted_space[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.617072197846027,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response1.txt_stdout.txt",
    "code_path": "problem_iter23_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and item-aware randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste Minimization with non-linear scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Fill Ratio Bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] += fill_ratio_after * 0.2 * (item / bins_remain_cap.max())\n\n    # Item-aware Randomization\n    randomization_strength = 0.05 * (1-item / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Empty bin penalty, scaled to bin fullness\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.457518946948548,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response2.txt_stdout.txt",
    "code_path": "problem_iter23_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, and bin landscape.\n    Combines adaptive scaling and bonuses for near-full bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with item size scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = (item / bins_remain_cap.max())**0.5\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Fill ratio bonus with capacity awareness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    capacity_scale = (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    occupancy_variance = np.var(1 - bins_remain_cap / bins_remain_cap.max())\n    fill_bonus_weight = 0.2 + 0.3 * (1 - occupancy_variance)\n    priorities[feasible_bins] += fill_ratio_after * fill_bonus_weight * capacity_scale\n\n    # Controlled randomization\n    randomization_strength = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.04 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Strong bonus for almost full bins, non-linear scaling\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = (1 - wasted_space_after[almost_full] / bins_remain_cap.max())**2\n    priorities[feasible_bins][almost_full] += 0.15 * almost_full_bonus\n\n    # Delayed commitment penalty\n    almost_empty = bins_remain_cap[feasible_bins] / bins_remain_cap.max() > 0.8\n    small_item = item / bins_remain_cap.max() < 0.2\n    if np.any(almost_empty) and small_item:\n        priorities[feasible_bins][almost_empty] -= 0.05 * small_item\n\n    # Incentivize placing large items in emptier bins\n    if item > bins_remain_cap.max() / 2:\n        priorities[feasible_bins] += (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * 0.05\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 6.023135221380145,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response3.txt_stdout.txt",
    "code_path": "problem_iter23_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, bin awareness, and controlled randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = (item / bins_remain_cap.max())**0.5 #Scale based on item size\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    capacity_scale = (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    occupancy_variance = np.var(1 - bins_remain_cap / bins_remain_cap.max())\n    fill_bonus_weight = 0.2 + 0.3 * (1 - occupancy_variance)\n    priorities[feasible_bins] += fill_ratio_after * fill_bonus_weight * capacity_scale\n\n    # Controlled randomization\n    randomization_strength = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bin-emptiness penalty\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.04 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Almost full bonus\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = (1 - wasted_space_after[almost_full] / bins_remain_cap.max())**2\n    priorities[feasible_bins][almost_full] += 0.15 * almost_full_bonus\n\n    # Small item penalty in almost empty bins\n    almost_empty = bins_remain_cap[feasible_bins] / bins_remain_cap.max() > 0.8\n    small_item = item / bins_remain_cap.max() < 0.2\n    if np.any(almost_empty) and small_item:\n        priorities[feasible_bins][almost_empty] -= 0.05 * small_item\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 6.122856003191075,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response4.txt_stdout.txt",
    "code_path": "problem_iter23_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, fill ratio, almost full reward, and controlled randomization.\n    Adapts to bin fullness and item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Wasted space priority (minimize waste)\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Fill ratio bonus, scaling with current bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_ratio_weight = 0.2 + 0.6 * bin_fullness\n    priorities[feasible_bins] += fill_ratio_after * fill_ratio_weight\n\n    # Controlled randomization, reduce for larger items and fuller bins\n    randomization_strength = 0.05 * (1 - item / bins_remain_cap.max()) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins after placement\n    almost_full_threshold = 0.05 * bins_remain_cap.max()  # Adaptive threshold\n    remaining_after_placement = bins_remain_cap[feasible_bins] - item\n    almost_full_bins = remaining_after_placement <= almost_full_threshold\n    priorities[feasible_bins][almost_full_bins] += 0.3 + 0.2*(1-item/bins_remain_cap.max())\n\n    #Adaptive penalty for placing the item in almost empty bins.\n    average_occupancy = np.mean(1 - bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    penalty_scale = 0.05 * (1 - average_occupancy) * (item / bins_remain_cap.max()) # Scale penalty by item size\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response5.txt_stdout.txt",
    "code_path": "problem_iter23_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and bin landscape awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with cubic penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, significant for larger items, boosted by bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness)\n\n    # Dynamic randomization, inversely proportional to bin fill, scales with item size & capacity variance\n    cap_variance = np.var(bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 + cap_variance)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scales with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.068607897885915,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response6.txt_stdout.txt",
    "code_path": "problem_iter23_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, controlled randomization, almost full reward, and empty bin penalty with landscape awareness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with adaptive scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = np.clip(item / bins_remain_cap.max(), 0.1, 0.5)\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fullness.\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())**2\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Strong bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.1\n    priorities[feasible_bins][almost_full] += 0.2\n\n    # Empty Bin Penalty: Penalize bins that are too empty, adjust based on average fill.\n    average_fill = np.mean(1 - bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    penalty_scale = 0.05 * (1 - average_fill)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Landscape aware penalty for creating nearly empty bins\n    nearly_empty = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap.max() > 0.9\n    priorities[feasible_bins][nearly_empty] -= 0.1 * item_scale\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.01874750698045,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response7.txt_stdout.txt",
    "code_path": "problem_iter23_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic combining waste, fill ratio, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with cubic penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n    priorities[feasible_bins] -= waste_penalty\n\n    # Fill ratio bonus, scaled by item size and bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2)\n\n    # Dynamic randomization, proportional to item size and remaining capacity variance\n    capacity_std = np.std(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.sum(feasible_bins) > 1 else 0.0\n    randomization_strength = 0.03 * item_scale * (1 + capacity_std) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Penalty for leaving bins mostly empty, adjusted by average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())**2 * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.05 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Significant bonus for bins becoming almost full, scaled by how close they are\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = 0.2 * (1 - wasted_space_after[almost_full] / (0.05 * bins_remain_cap.max())) if np.any(almost_full) else 0.0\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Smaller items have a higher chance to explore (fit in emptier bins)\n    if item < 0.2 * bins_remain_cap.max():\n        exploration_bonus = 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += exploration_bonus\n\n    # Dynamically adjust large item threshold based on remaining capacities\n    large_item_threshold = 0.7 + 0.1 * (np.mean(bins_remain_cap) / bins_remain_cap.max())\n    large_item_threshold = min(0.9, large_item_threshold)  # Cap the threshold\n\n    if item > large_item_threshold * bins_remain_cap.max():\n        large_item_bonus = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += large_item_bonus\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response8.txt_stdout.txt",
    "code_path": "problem_iter23_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic: waste minimization, fill ratio, landscape, item-aware adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    avg_bin_cap = np.mean(bins_remain_cap)\n    std_bin_cap = np.std(bins_remain_cap)\n\n    # 1. Waste Minimization (Scaled)\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / max_bin_cap)**2 * (item / max_bin_cap)\n\n    # 2. Adaptive Fill Ratio Bonus (Item-aware)\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / max_bin_cap\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / max_bin_cap\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness**2)\n\n    # 3. Controlled Randomization (Bin-aware)\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / max_bin_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # 4. Adaptive Empty Bin Penalty (Landscape-aware)\n    empty_bin_penalty = (bins_remain_cap / max_bin_cap) * (1 - item / max_bin_cap)\n    empty_bin_weight = 0.02 + 0.08 * (1 - avg_bin_cap / max_bin_cap)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_weight\n\n    # 5. Almost Full Bonus (Enhanced)\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / max_bin_cap < 0.04\n    priorities[feasible_bins][almost_full] += 0.15\n\n    # 6. Large Item Consideration (Threshold)\n    if item > 0.5 * max_bin_cap:\n        empty_bin_bonus = (bins_remain_cap[feasible_bins] / max_bin_cap) * 0.05\n        priorities[feasible_bins] += empty_bin_bonus\n\n    # 7. Bin Capacity Variance Penalty (Balance)\n    capacity_variance_penalty = (std_bin_cap / max_bin_cap) * 0.02\n    priorities[feasible_bins] -= capacity_variance_penalty\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response9.txt_stdout.txt",
    "code_path": "problem_iter23_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic: Waste minimization, fill ratio, bin landscape, dynamic params.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    item_scale = item / bins_remain_cap.max()\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = 0.5 + 0.5 * item_scale\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_ratio_weight = 0.2 + 0.6 * bin_fullness\n    priorities[feasible_bins] += fill_ratio_after * fill_ratio_weight * item_scale\n\n    randomization_strength = 0.1 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.05 + 0.05 * average_occupancy * (1 - item_scale)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.03\n    almost_full_bonus = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    capacity_difference = np.abs(bins_remain_cap[feasible_bins] - np.mean(bins_remain_cap)) / bins_remain_cap.max()\n    distribution_penalty = 0.02 * capacity_difference * item_scale\n    priorities[feasible_bins] -= distribution_penalty\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  }
]