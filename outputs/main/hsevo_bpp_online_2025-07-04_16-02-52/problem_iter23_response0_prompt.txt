{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, adaptive fill ratio, controlled randomization, emptiness penalty and almost full reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by bin cap variance\n    wasted_space = bins_remain_cap - item\n    waste_penalty_scale = np.var(bins_remain_cap) if np.var(bins_remain_cap) > 0 else bins_remain_cap.max()\n    priorities[feasible_bins] -= (wasted_space[feasible_bins]**2) / (waste_penalty_scale + 1e-9)\n\n    # Adaptive fill ratio bonus, scaled by item size and bin capacity. Non-linear fullness boost\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    fill_bonus_weight = 0.2 + 0.3 * item_scale * (1 + fill_ratio_after)\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization scaled by remaining capacity and item size\n    randomization_strength = 0.05 * (1 - item_scale) * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item_scale)\n    empty_bin_penalty_weight = 0.03 * (1 - fill_ratio_after)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Near full bonus\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, adaptive fill ratio, randomization, emptiness penalty, near-full reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # No feasible bins\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0  # Ensure non-negative waste\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / np.max(bins_remain_cap)\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Adaptive Randomization\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins\n    almost_full_threshold = 0.1\n    almost_full_bins = (wasted_space[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    # Empty Bin Penalty\n    average_fill = np.mean(1 - bins_remain_cap / np.max(bins_remain_cap))\n    empty_bin_penalty = (bins_remain_cap / np.max(bins_remain_cap))\n    penalty_scale = 0.05 * (1 - average_fill)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Bonus for current fill ratio\n    current_fill_ratio = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    priorities[feasible_bins] += current_fill_ratio[feasible_bins] * 0.05\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic includes a bonus for almost full bins and a penalty for placing small items in almost empty bins, which are absent in the worst. (2nd best) vs (19th) reveals that (2nd) does not penalize placing small items in almost empty bins. Comparing (1st) vs (2nd), they are identical, suggesting other factors influence ranking. (3rd) vs (4th) are identical. Comparing (second worst) vs (worst), they are identical. Overall: Top heuristics have nuanced adjustments based on item size and bin fullness, promoting efficient space use and preventing premature commitment to empty bins with small items. They demonstrate better landscape awareness.\n- \nOkay, I understand the task. Let's redefine \"Current self-reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective self-reflection\" and focusing on actionable advice.\n\nHere's a breakdown to guide the process:\n\n*   **Keywords:** Adaptive parameters, non-linear scaling, controlled randomness, bin landscape, item size, bin capacity, state-dependent adjustments, balanced exploration/exploitation.\n\n*   **Advice:** Design heuristics with parameters that dynamically adapt to the current state of the bins and items. Use non-linear scaling for rewards and penalties to fine-tune behavior. Balance exploration (trying different placements) with exploitation (placing items where they fit best based on current knowledge).\n\n*   **Avoid:** Overly simplistic, direct heuristics based solely on remaining capacity. Relying on complex analogies without empirical validation. Undifferentiated, global randomness.\n\n*   **Explanation:** Effective heuristics should \"sense\" the overall packing situation and adjust their behavior accordingly. Adaptive parameters, state-dependent adjustments, non-linear scaling and balanced exploration/exploitation are key.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}