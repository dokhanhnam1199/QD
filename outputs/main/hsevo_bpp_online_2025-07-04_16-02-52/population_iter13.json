[
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, and emptiness discouragement.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / bins_remain_cap.max()\n\n    # Fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.3\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller, scaled by item size.\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    #Adaptive bin-emptiness penalty.\n    empty_bin_penalty = (1 - bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.786597526924611,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, adaptive randomization, and dynamic emptiness penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear waste penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.517351416035098,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, adaptive randomization, and bin diversity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization (best-fit) with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.2 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill\n    randomization_strength = 0.05 * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, more for larger items\n    empty_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * item_scale\n    priorities[feasible_bins] -= empty_penalty * 0.02\n\n    # Bonus for bins nearing full capacity (almost perfect fit)\n    almost_perfect_fit = np.exp(-wasted_space[feasible_bins] * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.05\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.098524132429212,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using waste, fill ratio, controlled randomization, adaptive penalties, and near-full bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus, increased magnitude\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.3\n\n    # Controlled randomization, scaled by item size and remaining capacity\n    item_scale = item / bins_remain_cap.max()\n    randomization_strength = 0.1 * item_scale * (bins_remain_cap.max() - bins_remain_cap[feasible_bins]) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n    \n    # Adaptive bin-emptiness penalty\n    empty_penalty = (bins_remain_cap / bins_remain_cap.max())[feasible_bins]\n    priorities[feasible_bins] -= empty_penalty * 0.01\n\n    # Bonus for bins nearing full capacity, reduced magnitude\n    almost_full = (wasted_space[feasible_bins] / bins_remain_cap.max()) < 0.05\n    priorities[feasible_bins][almost_full] += 0.01\n\n    return priorities",
    "response_id": 3,
    "tryHS": true,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Controlled randomization, scaled by (1 - item_scale)\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after_all = (bins_remain_cap - wasted_space) / bins_remain_cap.max() #using scaled version\n    priorities[feasible_bins] += fill_ratio_after_all[feasible_bins] * 0.2 #reduce scaling to 0.2\n\n    # Slightly penalize bins that are already very full.\n    almost_full = (wasted_space < 0.1*bins_remain_cap.max()) & feasible_bins\n    priorities[almost_full] -= 0.01\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.0885520542481055,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, and adaptive randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0  # Ensure no negative waste\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / np.max(bins_remain_cap)\n\n    # Fill ratio bonus after placing the item\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1-fill_ratio_after) * 0.3\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller, scale by item size.\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Encourage bins that are almost full (but only if feasible)\n    almost_full_threshold = 0.1  # e.g., within 10% of being full\n    almost_full_bins = (bins_remain_cap[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2 # bonus for almost full\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.716792979656956,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, randomization, bin-emptiness penalty, and near-full bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n    \n    empty_penalty = (bins_remain_cap / bins_remain_cap.max())[feasible_bins]\n    priorities[feasible_bins] -= empty_penalty * 0.01\n\n    almost_full = (wasted_space[feasible_bins] / bins_remain_cap.max()) < 0.05\n    priorities[feasible_bins][almost_full] += 0.01\n\n    # Bin balancing from v1, slightly modified scaling\n    average_fill_level = np.mean(bins_remain_cap)\n    bin_balance_bonus = (average_fill_level - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += bin_balance_bonus[feasible_bins] * 0.02 # Reduce magnitude.\n    \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.1284403669724865,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response7.txt_stdout.txt",
    "code_path": "problem_iter11_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, and emptiness penalty.\n    Scales randomization and bonuses based on item size and bin capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization - scaled by item and bin capacity\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item_scale)\n    empty_bin_penalty_weight = 0.03\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n    \n    # Near full bonus\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, randomization and dynamic penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Adaptive fill ratio bonus\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - wasted_space[feasible_bins]) / bins_remain_cap[feasible_bins] #fill rate\n    fill_ratio_bonus = fill_ratio_after * (0.2 + 0.3 * item_scale) # Adaptive bonus\n    priorities[feasible_bins] += fill_ratio_bonus\n\n    # Controlled randomization\n    randomization_factor = 0.05 * (1 - item_scale)  # Favor exploration for smaller items\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] -= empty_bin_penalty * (0.02 + 0.03 * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()))\n\n    # Bonus for bins nearing full capacity\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins  # Threshold tuning\n    priorities[almost_full] += 0.1\n    # Diversify bin selection (penalize bins that are already nearly full).\n    # This term will prevent the algorithm from sticking to bins which\n    # could potentially result in worse packing in future steps\n    bins_almost_full = (bins_remain_cap / bins_remain_cap.max() < 0.1) & feasible_bins\n    priorities[bins_almost_full] -= 0.02 * (bins_remain_cap[bins_almost_full] / bins_remain_cap.max())\n\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines wasted space, fill ratio, randomization, diversity and prevents early commitment.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / bins_remain_cap.max()\n    \n    # Fill ratio bonus, adaptive to the item size and bin capacity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    adaptive_fill_bonus = fill_ratio_after * (0.2 + 0.1 * (item / bins_remain_cap.max()))\n    priorities[feasible_bins] += adaptive_fill_bonus[feasible_bins]\n\n    # Adaptive Randomization: More randomization for smaller items and fuller bins\n    randomization_strength = 0.05 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Bin Diversity Bonus: Encourage using bins with diverse fill levels.\n    if np.sum(feasible_bins) > 1:\n        avg_remaining_cap = np.mean(bins_remain_cap[feasible_bins])\n        diversity_bonus = np.abs(bins_remain_cap - avg_remaining_cap) / bins_remain_cap.max()\n        priorities[feasible_bins] += diversity_bonus[feasible_bins] * 0.05\n        \n    # Prevent early commitment to bins that are almost full. Penalize bins with very small remaining capacity\n    almost_full_penalty = np.where(bins_remain_cap < 1.1*item, (1-(bins_remain_cap/ (1.1*item))),0) #apply the penalty only if the bin is almost full\n    \n    \n    priorities[feasible_bins] -= almost_full_penalty[feasible_bins] * 0.1 # scaled by a factor of 0.1 for balance.\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.726765057838063,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, bin utilization, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mark infeasible bins with negative infinity\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate remaining space after placing the item in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize bins with minimal wasted space (Best-Fit component)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]\n\n    # Fill ratio bonus, scaled by remaining capacity.  Emphasizes filling nearly full bins.\n    fill_ratio_after = (bins_remain_cap - wasted_space) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.3\n\n    # Adaptive Randomization: Smaller items get more randomization.\n    randomization_strength = 0.1 / (1 + item) # Inverse relationship\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength\n\n    # Bin Utilization Penalty: Penalize bins with very low fill levels to encourage using partially filled bins.\n    utilization_ratio = bins_remain_cap / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] -= (1 - utilization_ratio[bins_remain_cap >= item]) * 0.1\n\n    # Bonus for bins that would become nearly full after placing the item\n    nearly_full_threshold = 0.9\n    nearly_full_bonus = np.where((bins_remain_cap >= item) & (fill_ratio_after >= nearly_full_threshold), 0.2, 0)\n    priorities[bins_remain_cap >= item] += nearly_full_bonus[bins_remain_cap >= item]\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines best-fit, fill ratio, controlled randomization, bin diversity, and adaptive penalties\n    for bin prioritization, aiming for better performance than v1.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (bins_remain_cap - wasted_space) / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.3  # Increased fill ratio weight\n\n    # Adaptive Randomization: Smaller items get more randomness\n    randomization_factor = 0.1 / (item + 0.01)  # Inverse relationship with item size\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n\n    # Bin Diversity: Slightly favor bins with different remaining capacities\n    unique_capacities = np.unique(bins_remain_cap[feasible_bins])\n    if len(unique_capacities) < len(bins_remain_cap[feasible_bins]):\n         capacity_counts = {}\n         for cap in bins_remain_cap[feasible_bins]:\n             capacity_counts[cap] = capacity_counts.get(cap,0)+1\n         for i in np.where(feasible_bins)[0]:\n            priorities[i] += 0.01 / capacity_counts[bins_remain_cap[i]]\n\n    # Adaptive Empty Bin Penalty: Larger items penalize empty bins more\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * item\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1 # Increased penalty weight\n\n    # Prioritize bins that have already been used somewhat\n    bin_usage_penalty = np.where(bins_remain_cap < bins_remain_cap.max(), 0.02, 0)\n    priorities[feasible_bins] += bin_usage_penalty[feasible_bins]\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997989999997 seconds"
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced priority function combining best-fit, fill ratio, bin diversity, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    \n    # Feasible bins only\n    feasible_mask = bins_remain_cap >= item\n    feasible_bins_cap = bins_remain_cap[feasible_mask]\n\n    if feasible_bins_cap.size == 0:\n        return priorities\n    \n    # Waste-based prioritization (smaller waste is better)\n    wasted_space = feasible_bins_cap - item\n    priorities[feasible_mask] = -wasted_space\n    \n    # Fill ratio bonus, tuned for better sensitivity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += fill_ratio_after * 0.3  # Slightly increased fill ratio weight\n    \n    # Bin diversity incentive: Reward bins with remaining capacity close to the item size\n    diversity_score = np.exp(-np.abs(wasted_space - item) / (0.1 * bins_remain_cap.max()))\n    priorities[feasible_mask] += diversity_score * 0.15\n    \n    # Adaptive randomization, scaling with both item and available capacity\n    randomization_strength = 0.05 * item * (1 - wasted_space / bins_remain_cap.max()) # Reduced Randomization strength when the wasted space is large\n    priorities[feasible_mask] += np.random.rand(feasible_bins_cap.size) * randomization_strength\n    \n    # Dynamic empty bin penalty, adjusting to the current bin landscape\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage) #Increase penalty when the average bin usage is low\n    priorities[feasible_mask] -= empty_bin_penalty[feasible_mask] * 0.1\n    \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.068607897885915,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response3.txt_stdout.txt",
    "code_path": "problem_iter12_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, bin utilization, and adaptive randomization for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.3  # Slightly increased fill ratio importance\n\n    # Adaptive Randomization: Scale randomness based on item size AND remaining capacity variance.\n    # Larger items and more uniform bin capacities promote more exploration.\n    capacity_std = np.std(bins_remain_cap[bins_remain_cap > 0]) # Only consider non-empty bins when computing the std\n    randomization_scale = 0.05 * item * (1 + capacity_std) #Increased scaling factor and consider variance\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_scale\n\n    # Bin Utilization Penalty: Penalize bins that are significantly underutilized.  The penalty\n    # increases non-linearly as the bin becomes emptier.\n    bin_utilization = bins_remain_cap / bins_remain_cap.max()\n    empty_bin_penalty = (1 - bin_utilization)**2  # Squared to penalize very empty bins more\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1 #Increased penalty\n\n    # Moderate the effect of extremely small items: Add a small bonus to bins with higher remaining capacity\n    # to avoid overfilling small bins with tiny items at the end.\n    small_item_threshold = bins_remain_cap.max() * 0.1 #If item is smaller than 10% of bins_remain_cap.max()\n    if item <= small_item_threshold:\n        priorities[feasible_bins] += bin_utilization[feasible_bins] * 0.02 #Slight bonus to bins that have more space left\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.13841244515357,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, bin diversity, and adaptive randomization for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    valid_bins = bins_remain_cap >= item\n    priorities[valid_bins] = -wasted_space[valid_bins]\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement, adaptive weight\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    fill_ratio_weight = min(item, 0.5)  # Weight fill ratio more for smaller items\n    priorities[valid_bins] += fill_ratio_after[valid_bins] * fill_ratio_weight\n    \n    # Adaptive randomization, scaled by item size and bin fill level, for exploration\n    randomization_strength = 0.05 * item * (1 - bins_remain_cap / bins_remain_cap.max())\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * randomization_strength[valid_bins]\n    \n    # Penalize bins that are too empty or too full, adaptive penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    full_bin_penalty = (wasted_space / bins_remain_cap.max())\n    penalty_weight = max(0, item - 0.3) # Apply penalty stronger for larger items\n    priorities[valid_bins] -= empty_bin_penalty[valid_bins] * 0.05 * penalty_weight\n    priorities[valid_bins] -= full_bin_penalty[valid_bins] * 0.02 * penalty_weight # Slightly penalize nearly full bins\n\n    # Bin Diversity: Encourage using bins with different fill levels\n    bin_diversity_bonus = np.std(bins_remain_cap) / bins_remain_cap.max()\n    priorities[valid_bins] += bin_diversity_bonus * 0.03\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response0.txt_stdout.txt",
    "code_path": "problem_iter13_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, \n                bins_remain_cap: np.ndarray,\n                fill_ratio_weight: float = 0.4998508278429229,\n                randomization_strength_base: float = 0.4185316887301156,\n                empty_penalty_weight: float = 0.07094071477100863,\n                almost_full_threshold: float = 0.05891004041856748,\n                almost_full_bonus: float = 0.01883537661369473) -> np.ndarray:\n    \"\"\"Prioritizes bins using waste, fill ratio, controlled randomization, adaptive penalties, and near-full bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "exec_success": true
  }
]