{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, more significant for larger items\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill and scaled by item size\n    randomization_strength = 0.05 * item_scale * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptively combines best-fit, fill ratio, diversity, and penalizes nearly full bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Fill ratio bonus, adaptive to item size and bin utilization.\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    adaptive_fill_bonus = fill_ratio_after * (0.2 + 0.1 * (item / bins_remain_cap.max()))\n    priorities[feasible_bins] += adaptive_fill_bonus[feasible_bins]\n\n    # Encourage using bins with diverse fill levels.\n    if np.sum(feasible_bins) > 1:\n        avg_remaining_cap = np.mean(bins_remain_cap[feasible_bins])\n        diversity_bonus = np.abs(bins_remain_cap - avg_remaining_cap) / bins_remain_cap.max()\n        priorities[feasible_bins] += diversity_bonus[feasible_bins] * 0.05\n\n    # Penalize bins with very small remaining capacity\n    almost_full_penalty = np.where(bins_remain_cap < 1.1*item, (1-(bins_remain_cap/ (1.1*item))),0)\n    priorities[feasible_bins] -= almost_full_penalty[feasible_bins] * 0.1\n\n    # Adaptive randomization based on item size and bin capacity.\n    randomization_strength = 0.05 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic includes an \"empty bin penalty\" and \"reward for bins close to full,\" while the worst focuses on waste minimization, fill ratio, and randomization. The best heuristic also uses average fill to scale its \"empty bin penalty,\" while the worst doesn't consider the overall bin landscape.\n\nComparing (2nd best) vs (second worst), we see (2nd) includes an \"empty bin penalty,\" while (second worst) gives diversity bonus. The second best focuses wastespace and fillratio bonuses. The adaptive randomization strategies differ. Second best use  `item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()` for randomization strength, while (second worst) use `0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)`.\n\nComparing (1st) vs (2nd), we see (1st) includes `Reward bins close to full before insertion` to encourage packing, whereas the (2nd) does not.\n\nComparing (3rd) vs (4th), we see that (3rd) use non-linear wasted space and adaptive fill ratio bonus, whereas (4th) use waste-based prioritization (smaller waste is better) for prioritizing.\n\nComparing (second worst) vs (worst), we see that both include adaptive randomization to some extent. (second worst) gives diversity bonus, and the (worst) gives bonus for almost full bins.\n\nOverall:\nThe better-performing heuristics incorporate a wider range of factors beyond just waste minimization and fill ratio. They include elements like penalties for using almost-empty bins, rewards for using almost-full bins, diversity incentives, and adaptive randomization. Scaling factors based on item size, remaining bin capacity, and overall bin landscape (average fill level) seem to improve performance. Non-linear penalties for wasted space also appear beneficial.\n- \nOkay, I'm ready to help design better heuristics, focusing on avoiding the pitfalls of ineffective self-reflection and aiming for that $999K improvement! Here's a redefined approach to \"current self-reflection\":\n\n*   **Keywords:** Adaptive, Dynamic, Exploration/Exploitation Balance, Non-linear Penalties.\n*   **Advice:** Design heuristics that dynamically adapt to the state of the problem, emphasizing exploration with small items and exploitation of nearly full bins. Use non-linear penalties for wasted space.\n*   **Avoid:** Overly simplistic, static heuristics, complex and inefficient calculations, and relying solely on remaining capacity.\n*   **Explanation:** Effective heuristics should be state-aware, balancing exploration and exploitation by dynamically adjusting parameters based on item characteristics and bin states, while avoiding premature commitment and overly simplistic or computationally expensive strategies.\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}