{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, adaptive fill ratio, controlled randomization, and emptiness penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with scaled penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, scaled by item size and bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness)\n\n    # Controlled randomization, inversely proportional to bin fill\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic with waste, fill ratio, randomization, and bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with cubic penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, significant for larger items, boosted by bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness)\n\n    # Dynamic randomization, inversely proportional to bin fill, scales with item size & capacity variance\n    cap_variance = np.var(bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 + cap_variance)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scales with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement. Scale with occupancy\n    fill_ratio_after_simple = (1 - wasted_space[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after_simple * 0.2 * average_occupancy\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Incentivize placing large items in emptier bins\n    if item > bins_remain_cap.max() / 2:\n        priorities[feasible_bins] += (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * 0.05\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic includes a bonus for almost full bins and a penalty for placing small items in almost empty bins, which are absent in the worst. (2nd best) vs (19th) reveals that (2nd) does not penalize placing small items in almost empty bins. Comparing (1st) vs (2nd), they are identical, suggesting other factors influence ranking. (3rd) vs (4th) are identical. Comparing (second worst) vs (worst), they are identical. Overall: Top heuristics have nuanced adjustments based on item size and bin fullness, promoting efficient space use and preventing premature commitment to empty bins with small items. They demonstrate better landscape awareness.\n- \nOkay, I understand the task. Let's redefine \"Current self-reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective self-reflection\" and focusing on actionable advice.\n\nHere's a breakdown to guide the process:\n\n*   **Keywords:** Adaptive parameters, non-linear scaling, controlled randomness, bin landscape, item size, bin capacity, state-dependent adjustments, balanced exploration/exploitation.\n\n*   **Advice:** Design heuristics with parameters that dynamically adapt to the current state of the bins and items. Use non-linear scaling for rewards and penalties to fine-tune behavior. Balance exploration (trying different placements) with exploitation (placing items where they fit best based on current knowledge).\n\n*   **Avoid:** Overly simplistic, direct heuristics based solely on remaining capacity. Relying on complex analogies without empirical validation. Undifferentiated, global randomness.\n\n*   **Explanation:** Effective heuristics should \"sense\" the overall packing situation and adjust their behavior accordingly. Adaptive parameters, state-dependent adjustments, non-linear scaling and balanced exploration/exploitation are key.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}