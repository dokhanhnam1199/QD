{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Advanced adaptive heuristic with dynamic exploration/exploitation and non-linear waste penalties.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    avg_bin_cap = np.mean(bins_remain_cap)\n\n    # 1. Dynamic Waste Minimization (Non-linear penalty)\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space / max_bin_cap)**3  # Cubic penalty for larger waste\n    priorities[feasible_bins] -= waste_penalty[feasible_bins] * (item / max_bin_cap)\n\n    # 2. Adaptive Fill Ratio Bonus\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / max_bin_cap\n\n    # Adjust fill ratio bonus based on item size and bin fullness\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / max_bin_cap\n    fill_bonus = fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2) # Non-linear fullness boost\n    priorities[feasible_bins] += fill_bonus\n\n    # 3. Dynamic Exploration (Randomization)\n    # More exploration for smaller items and fuller bins\n    exploration_strength = 0.03 * (item / max_bin_cap) * (1 - avg_bin_cap / max_bin_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_strength\n\n    # 4. Empty Bin Penalty (Adaptive)\n    # Scales with both item size and average remaining capacity\n    empty_bin_penalty = (bins_remain_cap / max_bin_cap) * (item / max_bin_cap)\n    empty_bin_weight = 0.01 + 0.04 * (1 - avg_bin_cap / max_bin_cap) # Scales with occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_weight\n\n    # 5. \"Almost Full\" Bonus (Enhanced)\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full_threshold = 0.04 * max_bin_cap\n    almost_full = wasted_space_after <= almost_full_threshold\n    priorities[feasible_bins][almost_full] += 0.15  # Increased bonus\n\n    # 6. Large Item Consideration (New)\n    # Incentivize placing large items in emptier bins\n    if item > 0.5 * max_bin_cap:\n        empty_bin_bonus = (bins_remain_cap[feasible_bins] / max_bin_cap) * 0.05\n        priorities[feasible_bins] += empty_bin_bonus\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, adaptive randomization, and dynamic empty bin penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mark infeasible bins with the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Focus only on feasible bins\n    feasible_mask = bins_remain_cap >= item\n    feasible_bins_cap = bins_remain_cap[feasible_mask]\n\n    if feasible_bins_cap.size == 0:\n        return priorities\n\n    # Waste-based prioritization (smaller waste is better)\n    wasted_space = feasible_bins_cap - item\n    priorities[feasible_mask] = -wasted_space\n\n    # Adaptive randomization, scaling with item size and bin capacity\n    randomization_strength = 0.05 * item * (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += np.random.rand(feasible_bins_cap.size) * randomization_strength\n\n    # Dynamic empty bin penalty, adjusting to the overall bin landscape\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage)\n    priorities[feasible_mask] -= empty_bin_penalty[feasible_mask] * 0.1\n\n    # Encourage filling bins, with bonus based on fill ratio AFTER insertion\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += fill_ratio_after * 0.2\n\n    # Non-linear wasted space penalty\n    priorities[feasible_mask] -= (wasted_space / bins_remain_cap.max())**2 * 0.1\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (2nd), (2nd) vs (3rd), we see that all three heuristics are identical. This suggests the ranking is based on some external factor, not code differences.\n*   Comparing (4th) vs (6th), (4th) has more advanced features: dynamic waste minimization using a cubic penalty, fill ratio bonus with non-linear fullness boost, dynamic randomization based on item size and capacity variance, emptiness penalty adjusted by occupancy, bonus for almost full bins, and an exploration bonus for smaller items. Heuristic (6th) combines waste minimization (non-linear), fill ratio, empty bin penalty and almost full bin. Overall, (4th) seems like a better approach due to its dynamic, non-linear nature and more features.\n*   Comparing (5th) vs (7th), both have same structure with adaptive heuristic combining waste minimization, fill ratio, bin landscape awareness, and dynamic exploration.\n*   Comparing (8th) vs (10th), (8th) has Large Item Consideration (New): Incentivize placing large items in emptier bins.\n*   Comparing (19th) vs (20th), these two heuristics are identical. It highlights a focus on waste minimization, adaptive fill ratio, controlled randomization, an empty bin penalty, and an almost full reward.\n*   Comparing (1st) vs (20th), the initial heuristics have a simpler, more fundamental structure focusing on waste minimization and fill ratio. As the ranking goes down, the heuristics get more complex, incorporating adaptive parameters, non-linear penalties, and randomization strategies.\n*   Comparing (17th) vs (18th), heuristic (17th) utilizes hardcoded coefficients and (18th) uses hardcoded variable as arguments.\n\nOverall: The better heuristics incorporate dynamic elements, non-linear scaling, item-size awareness, and exploration/exploitation strategies, while lower-ranked heuristics tend to be simpler and less adaptive.\n- \nOkay, let's refine \"Current self-reflection\" to create more effective heuristics, keeping your (hypothetical) generous tip in mind! Here's a redefinition focused on actionable insights, avoiding common pitfalls:\n\n*   **Keywords:** Adaptive scaling, dynamic penalties/bonuses, controlled exploration, bin landscape.\n*   **Advice:** Prioritize adaptive parameter adjustments based on item size, bin capacity, and occupancy *distribution*. Favor exploration with small items and exploitation with nearly full bins, delaying commitment on early, suboptimal placements.\n*   **Avoid:** Rigid, pre-defined parameters; over-reliance on single metrics; premature commitment.\n*   **Explanation:** Robust heuristics consider the overall \"bin landscape\" (distribution of occupancies) to dynamically adjust parameters. Non-linear rewards encourage diverse bin usage and discourage waste more effectively than linear approaches.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}