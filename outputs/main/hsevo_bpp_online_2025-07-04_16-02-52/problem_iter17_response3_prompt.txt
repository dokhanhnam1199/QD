{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, and adaptive penalties\n    for bin prioritization.  Adapts randomization based on item size relative to bin size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.2\n\n    # Adaptive Randomization: Scale randomization based on item size relative to bin size.\n    # Smaller items in larger bins get more exploration, larger items get less.\n    relative_size = item / bins_remain_cap[feasible_bins]\n    randomization_scale = 0.1 * (1 - relative_size)  # range from 0 to 0.1\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_scale * item\n\n    # Adaptive Empty Bin Penalty: Penalize bins that are too empty, adjust the penalty\n    # based on the average fill level of all bins.  If bins are generally full,\n    # be more lenient with nearly empty bins.\n    average_fill = np.mean(1 - bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    penalty_scale = 0.05 * (1 - average_fill)  # Reduce penalty if bins are mostly full.\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Reward bins close to full before insertion\n    current_fill_ratio = 1 - bins_remain_cap / bins_remain_cap.max()\n    priorities[feasible_bins] += current_fill_ratio[feasible_bins] * 0.05\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, adaptive fill ratio, and controlled randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0\n\n    # Prioritize based on wasted space, normalized\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / np.max(bins_remain_cap)\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins\n    almost_full_threshold = 0.1\n    almost_full_bins = (bins_remain_cap[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic includes an \"empty bin penalty\" and \"reward for bins close to full,\" while the worst focuses on waste minimization, fill ratio, and randomization. The best heuristic also uses average fill to scale its \"empty bin penalty,\" while the worst doesn't consider the overall bin landscape.\n\nComparing (2nd best) vs (second worst), we see (2nd) includes an \"empty bin penalty,\" while (second worst) gives diversity bonus. The second best focuses wastespace and fillratio bonuses. The adaptive randomization strategies differ. Second best use  `item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()` for randomization strength, while (second worst) use `0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)`.\n\nComparing (1st) vs (2nd), we see (1st) includes `Reward bins close to full before insertion` to encourage packing, whereas the (2nd) does not.\n\nComparing (3rd) vs (4th), we see that (3rd) use non-linear wasted space and adaptive fill ratio bonus, whereas (4th) use waste-based prioritization (smaller waste is better) for prioritizing.\n\nComparing (second worst) vs (worst), we see that both include adaptive randomization to some extent. (second worst) gives diversity bonus, and the (worst) gives bonus for almost full bins.\n\nOverall:\nThe better-performing heuristics incorporate a wider range of factors beyond just waste minimization and fill ratio. They include elements like penalties for using almost-empty bins, rewards for using almost-full bins, diversity incentives, and adaptive randomization. Scaling factors based on item size, remaining bin capacity, and overall bin landscape (average fill level) seem to improve performance. Non-linear penalties for wasted space also appear beneficial.\n- \nOkay, I'm ready to help design better heuristics, focusing on avoiding the pitfalls of ineffective self-reflection and aiming for that $999K improvement! Here's a redefined approach to \"current self-reflection\":\n\n*   **Keywords:** Adaptive, Dynamic, Exploration/Exploitation Balance, Non-linear Penalties.\n*   **Advice:** Design heuristics that dynamically adapt to the state of the problem, emphasizing exploration with small items and exploitation of nearly full bins. Use non-linear penalties for wasted space.\n*   **Avoid:** Overly simplistic, static heuristics, complex and inefficient calculations, and relying solely on remaining capacity.\n*   **Explanation:** Effective heuristics should be state-aware, balancing exploration and exploitation by dynamically adjusting parameters based on item characteristics and bin states, while avoiding premature commitment and overly simplistic or computationally expensive strategies.\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}