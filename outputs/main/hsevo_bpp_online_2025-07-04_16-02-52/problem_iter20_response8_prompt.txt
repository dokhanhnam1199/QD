{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, adaptive randomization, and dynamic empty bin penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mark infeasible bins with the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Focus only on feasible bins\n    feasible_mask = bins_remain_cap >= item\n    feasible_bins_cap = bins_remain_cap[feasible_mask]\n\n    if feasible_bins_cap.size == 0:\n        return priorities\n\n    # Waste-based prioritization (smaller waste is better)\n    wasted_space = feasible_bins_cap - item\n    priorities[feasible_mask] = -wasted_space\n\n    # Adaptive randomization, scaling with item size and bin capacity\n    randomization_strength = 0.05 * item * (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += np.random.rand(feasible_bins_cap.size) * randomization_strength\n\n    # Dynamic empty bin penalty, adjusting to the overall bin landscape\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage)\n    priorities[feasible_mask] -= empty_bin_penalty[feasible_mask] * 0.1\n\n    # Encourage filling bins, with bonus based on fill ratio AFTER insertion\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += fill_ratio_after * 0.2\n\n    # Non-linear wasted space penalty\n    priorities[feasible_mask] -= (wasted_space / bins_remain_cap.max())**2 * 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, adaptive fill ratio, controlled randomization,\n    empty bin penalty, and almost full reward. Adapts to bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0\n\n    # Prioritize based on wasted space, normalized\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / np.max(bins_remain_cap)\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins\n    almost_full_threshold = 0.1\n    almost_full_bins = (bins_remain_cap[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    # Empty Bin Penalty: Penalize bins that are too empty, adjust based on average fill.\n    average_fill = np.mean(1 - bins_remain_cap / np.max(bins_remain_cap))\n    empty_bin_penalty = (bins_remain_cap / np.max(bins_remain_cap))\n    penalty_scale = 0.05 * (1 - average_fill)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Reward bins close to full before insertion\n    current_fill_ratio = 1 - bins_remain_cap / np.max(bins_remain_cap)\n    priorities[feasible_bins] += current_fill_ratio[feasible_bins] * 0.05\n\n\n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (2nd), (2nd) vs (3rd), we see that all three heuristics are identical. This suggests the ranking is based on some external factor, not code differences.\n*   Comparing (4th) vs (6th), (4th) has more advanced features: dynamic waste minimization using a cubic penalty, fill ratio bonus with non-linear fullness boost, dynamic randomization based on item size and capacity variance, emptiness penalty adjusted by occupancy, bonus for almost full bins, and an exploration bonus for smaller items. Heuristic (6th) combines waste minimization (non-linear), fill ratio, empty bin penalty and almost full bin. Overall, (4th) seems like a better approach due to its dynamic, non-linear nature and more features.\n*   Comparing (5th) vs (7th), both have same structure with adaptive heuristic combining waste minimization, fill ratio, bin landscape awareness, and dynamic exploration.\n*   Comparing (8th) vs (10th), (8th) has Large Item Consideration (New): Incentivize placing large items in emptier bins.\n*   Comparing (19th) vs (20th), these two heuristics are identical. It highlights a focus on waste minimization, adaptive fill ratio, controlled randomization, an empty bin penalty, and an almost full reward.\n*   Comparing (1st) vs (20th), the initial heuristics have a simpler, more fundamental structure focusing on waste minimization and fill ratio. As the ranking goes down, the heuristics get more complex, incorporating adaptive parameters, non-linear penalties, and randomization strategies.\n*   Comparing (17th) vs (18th), heuristic (17th) utilizes hardcoded coefficients and (18th) uses hardcoded variable as arguments.\n\nOverall: The better heuristics incorporate dynamic elements, non-linear scaling, item-size awareness, and exploration/exploitation strategies, while lower-ranked heuristics tend to be simpler and less adaptive.\n- \nOkay, let's refine \"Current self-reflection\" to create more effective heuristics, keeping your (hypothetical) generous tip in mind! Here's a redefinition focused on actionable insights, avoiding common pitfalls:\n\n*   **Keywords:** Adaptive scaling, dynamic penalties/bonuses, controlled exploration, bin landscape.\n*   **Advice:** Prioritize adaptive parameter adjustments based on item size, bin capacity, and occupancy *distribution*. Favor exploration with small items and exploitation with nearly full bins, delaying commitment on early, suboptimal placements.\n*   **Avoid:** Rigid, pre-defined parameters; over-reliance on single metrics; premature commitment.\n*   **Explanation:** Robust heuristics consider the overall \"bin landscape\" (distribution of occupancies) to dynamically adjust parameters. Non-linear rewards encourage diverse bin usage and discourage waste more effectively than linear approaches.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}