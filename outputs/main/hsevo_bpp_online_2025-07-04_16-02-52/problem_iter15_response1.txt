```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines best-fit, fill ratio, adaptive randomization, and bin usage awareness."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Infeasible bins get lowest priority
    priorities[bins_remain_cap < item] = -np.inf

    # Calculate wasted space if item is placed in each bin
    wasted_space = bins_remain_cap - item

    # Prioritize based on wasted space (smaller waste is better)
    valid_bins = bins_remain_cap >= item
    priorities[valid_bins] = -wasted_space[valid_bins]

    # Encourage filling bins, bonus based on fill ratio AFTER placement
    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())
    priorities[valid_bins] += fill_ratio_after[valid_bins] * 0.3

    # Adaptive Randomization: Scale randomization based on item size AND remaining bin capacity
    randomization_strength = 0.05 * item * (bins_remain_cap[valid_bins] / bins_remain_cap.max())
    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * randomization_strength

    # Bin Usage Awareness: Prefer bins that are neither too empty nor almost full.  This encourages a more balanced bin utilization
    bin_utilization_ratio = bins_remain_cap / bins_remain_cap.max()
    utilization_penalty = np.abs(bin_utilization_ratio - 0.5)  # Penalty increases as bin is closer to empty or full
    priorities[valid_bins] -= utilization_penalty[valid_bins] * 0.1

    # Dynamic Adjustment:  Boost priority for bins that result in a "significant" fill level, preventing excessive fragmentation.
    significant_fill_threshold = 0.75 * bins_remain_cap.max() #Consider 75% to be a good target
    is_significantly_filled = (bins_remain_cap - item) <= (bins_remain_cap.max() - significant_fill_threshold)
    priorities[valid_bins & is_significantly_filled] += 0.15 #Slightly boost the filled bins

    return priorities
```
