{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, and controlled randomization for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.2\n    \n    # Add a small amount of randomization, scaled by item size, for exploration\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * 0.05 * item\n    \n    # Penalize bins that are too empty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] -= empty_bin_penalty[bins_remain_cap >= item] * 0.05\n    \n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, and controlled randomization for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.2\n    \n    # Add a small amount of randomization, scaled by item size, for exploration\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * 0.05 * item\n    \n    # Penalize bins that are too empty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] -= empty_bin_penalty[bins_remain_cap >= item] * 0.05\n    \n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, more significant for larger items\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill and scaled by item size\n    randomization_strength = 0.05 * item_scale * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, diversity, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Feasible bins only\n    feasible_mask = bins_remain_cap >= item\n    feasible_bins_cap = bins_remain_cap[feasible_mask]\n\n    if feasible_bins_cap.size == 0:\n        return priorities\n\n    # Waste-based prioritization (smaller waste is better)\n    wasted_space = feasible_bins_cap - item\n    priorities[feasible_mask] = -wasted_space\n\n    # Fill ratio bonus, tuned for better sensitivity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += fill_ratio_after * 0.3\n\n    # Bin diversity incentive: Reward bins with remaining capacity close to the item size\n    diversity_score = np.exp(-np.abs(wasted_space - item) / (0.1 * bins_remain_cap.max()))\n    priorities[feasible_mask] += diversity_score * 0.15\n\n    # Adaptive randomization, scaling with both item and available capacity\n    randomization_strength = 0.05 * item * (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += np.random.rand(feasible_bins_cap.size) * randomization_strength\n\n    # Dynamic empty bin penalty, adjusting to the current bin landscape\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage)\n    priorities[feasible_mask] -= empty_bin_penalty[feasible_mask] * 0.1\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += fill_ratio_after * 0.2\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, more significant for larger items\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill and scaled by item size\n    randomization_strength = 0.05 * item_scale * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, more significant for larger items\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill and scaled by item size\n    randomization_strength = 0.05 * item_scale * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, more significant for larger items\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill and scaled by item size\n    randomization_strength = 0.05 * item_scale * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, adaptive randomization, and bin diversity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization (best-fit) with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.2 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill, and item size\n    randomization_strength = 0.05 * item_scale * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, more for larger items\n    empty_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * item_scale\n    priorities[feasible_bins] -= empty_penalty * 0.02\n\n    # Bonus for bins nearing full capacity (almost perfect fit)\n    almost_perfect_fit = np.exp(-wasted_space[feasible_bins] * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.05\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, randomization, and emptiness penalty.\n    Adaptive scaling based on item size and bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, and adaptive penalties\n    for bin prioritization.  Adapts randomization based on item size relative to bin size.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * 0.2\n\n    # Adaptive Randomization: Scale randomization based on item size relative to bin size.\n    # Smaller items in larger bins get more exploration, larger items get less.\n    relative_size = item / bins_remain_cap[feasible_bins]\n    randomization_scale = 0.1 * (1 - relative_size)  # range from 0 to 0.1\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_scale * item\n\n    # Adaptive Empty Bin Penalty: Penalize bins that are too empty, adjust the penalty\n    # based on the average fill level of all bins.  If bins are generally full,\n    # be more lenient with nearly empty bins.\n    average_fill = np.mean(1 - bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    penalty_scale = 0.05 * (1 - average_fill)  # Reduce penalty if bins are mostly full.\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Reward bins close to full before insertion\n    current_fill_ratio = 1 - bins_remain_cap / bins_remain_cap.max()\n    priorities[feasible_bins] += current_fill_ratio[feasible_bins] * 0.05\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, randomization, and emptiness handling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by max bin cap.\n    wasted_space = bins_remain_cap - item\n    priorities[feasible_bins] -= (wasted_space[feasible_bins]**2) / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size and bin capacity\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    fill_bonus_weight = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization scaled by remaining capacity, less for bigger items\n    randomization_strength = 0.05 * (1 - item_scale) * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, avoid filling almost empty bins early\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item_scale)\n    empty_bin_penalty_weight = 0.03\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Near full bonus\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, randomization, and emptiness penalty.\n    Adaptive scaling based on item size and bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, randomization, and emptiness penalty.\n    Adaptive scaling based on item size and bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptively combines best-fit, fill ratio, diversity, and penalizes nearly full bins.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Fill ratio bonus, adaptive to item size and bin utilization.\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    adaptive_fill_bonus = fill_ratio_after * (0.2 + 0.1 * (item / bins_remain_cap.max()))\n    priorities[feasible_bins] += adaptive_fill_bonus[feasible_bins]\n\n    # Encourage using bins with diverse fill levels.\n    if np.sum(feasible_bins) > 1:\n        avg_remaining_cap = np.mean(bins_remain_cap[feasible_bins])\n        diversity_bonus = np.abs(bins_remain_cap - avg_remaining_cap) / bins_remain_cap.max()\n        priorities[feasible_bins] += diversity_bonus[feasible_bins] * 0.05\n\n    # Penalize bins with very small remaining capacity\n    almost_full_penalty = np.where(bins_remain_cap < 1.1*item, (1-(bins_remain_cap/ (1.1*item))),0)\n    priorities[feasible_bins] -= almost_full_penalty[feasible_bins] * 0.1\n\n    # Adaptive randomization based on item size and bin capacity.\n    randomization_strength = 0.05 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight: float = 0.8056242630372064,\n                randomization_strength_base: float = 0.06711721301957442,\n                empty_bin_penalty_weight_base: float = 0.05954891384078274,\n                empty_bin_penalty_weight_occupancy_factor: float = 0.1461073097991506,\n                almost_perfect_fit_scale: float = 6.032531043023081,\n                almost_perfect_fit_weight: float = 0.26548219489652797) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight: float = 0.8056242630372064,\n                randomization_strength_base: float = 0.06711721301957442,\n                empty_bin_penalty_weight_base: float = 0.05954891384078274,\n                empty_bin_penalty_weight_occupancy_factor: float = 0.1461073097991506,\n                almost_perfect_fit_scale: float = 6.032531043023081,\n                almost_perfect_fit_weight: float = 0.26548219489652797) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight: float = 0.8056242630372064,\n                randomization_strength_base: float = 0.06711721301957442,\n                empty_bin_penalty_weight_base: float = 0.05954891384078274,\n                empty_bin_penalty_weight_occupancy_factor: float = 0.1461073097991506,\n                almost_perfect_fit_scale: float = 6.032531043023081,\n                almost_perfect_fit_weight: float = 0.26548219489652797) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, waste minimization, and controlled randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Adaptive Randomization: Smaller items get more randomization.\n    item_scale = item / bins_remain_cap.max()\n    randomization_strength = 0.1 / (1 + item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after_all = (bins_remain_cap - wasted_space) / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after_all[feasible_bins] * 0.2\n\n    # Bonus for bins that would become nearly full after placing the item\n    nearly_full_threshold = 0.9\n    nearly_full_bonus = np.where((bins_remain_cap >= item) & (fill_ratio_after_all >= nearly_full_threshold), 0.2, 0)\n    priorities[bins_remain_cap >= item] += nearly_full_bonus[bins_remain_cap >= item]\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste, fill ratio, randomization, and near-full penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    wasted_space = bins_remain_cap - item\n    priorities[feasible_bins] = -wasted_space / np.max(bins_remain_cap)\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / np.max(bins_remain_cap))\n    adaptive_fill_bonus = fill_ratio_after * (0.2 + 0.1 * (item / np.max(bins_remain_cap)))\n    priorities[feasible_bins] += adaptive_fill_bonus[feasible_bins]\n\n    # Adaptive Randomization: More randomization for fuller bins\n    randomization_strength = 0.05 * item * (np.max(bins_remain_cap) - bins_remain_cap) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Near-full penalty\n    almost_full_penalty = np.where(bins_remain_cap < 1.1*item, (1-(bins_remain_cap/ (1.1*item))),0)\n    priorities[feasible_bins] -= almost_full_penalty[feasible_bins] * 0.1\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, and controlled randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0\n\n    # Prioritize based on wasted space, normalized\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / np.max(bins_remain_cap)\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller.\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins\n    almost_full_threshold = 0.1\n    almost_full_bins = (bins_remain_cap[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}