{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, and controlled randomization for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.2\n    \n    # Add a small amount of randomization, scaled by item size, for exploration\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * 0.05 * item\n    \n    # Penalize bins that are too empty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] -= empty_bin_penalty[bins_remain_cap >= item] * 0.05\n    \n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, and controlled randomization for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.2\n    \n    # Add a small amount of randomization, scaled by item size, for exploration\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * 0.05 * item\n    \n    # Penalize bins that are too empty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    priorities[bins_remain_cap >= item] -= empty_bin_penalty[bins_remain_cap >= item] * 0.05\n    \n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, randomization and dynamic penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins]\n\n    # Adaptive fill ratio bonus\n    item_scale = item / bins_remain_cap.max()\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - wasted_space[feasible_bins]) / bins_remain_cap[feasible_bins] #fill rate\n    fill_ratio_bonus = fill_ratio_after * (0.2 + 0.3 * item_scale) # Adaptive bonus\n    priorities[feasible_bins] += fill_ratio_bonus\n\n    # Controlled randomization\n    randomization_factor = 0.05 * (1 - item_scale)  # Favor exploration for smaller items\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] -= empty_bin_penalty * (0.02 + 0.03 * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()))\n\n    # Bonus for bins nearing full capacity\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins  # Threshold tuning\n    priorities[almost_full] += 0.1\n    # Diversify bin selection (penalize bins that are already nearly full).\n    # This term will prevent the algorithm from sticking to bins which\n    # could potentially result in worse packing in future steps\n    bins_almost_full = (bins_remain_cap / bins_remain_cap.max() < 0.1) & feasible_bins\n    priorities[bins_almost_full] -= 0.02 * (bins_remain_cap[bins_almost_full] / bins_remain_cap.max())\n\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, and emptiness penalty.\n    Scales randomization and bonuses based on item size and bin capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization - scaled by item and bin capacity\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item_scale)\n    empty_bin_penalty_weight = 0.03\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n    \n    # Near full bonus\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, bin diversity, and adaptive randomization for bin prioritization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # Infeasible bins get lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize based on wasted space (smaller waste is better)\n    valid_bins = bins_remain_cap >= item\n    priorities[valid_bins] = -wasted_space[valid_bins]\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement, adaptive weight\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    fill_ratio_weight = min(item, 0.5)  # Weight fill ratio more for smaller items\n    priorities[valid_bins] += fill_ratio_after[valid_bins] * fill_ratio_weight\n    \n    # Adaptive randomization, scaled by item size and bin fill level, for exploration\n    randomization_strength = 0.05 * item * (1 - bins_remain_cap / bins_remain_cap.max())\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * randomization_strength[valid_bins]\n    \n    # Penalize bins that are too empty or too full, adaptive penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    full_bin_penalty = (wasted_space / bins_remain_cap.max())\n    penalty_weight = max(0, item - 0.3) # Apply penalty stronger for larger items\n    priorities[valid_bins] -= empty_bin_penalty[valid_bins] * 0.05 * penalty_weight\n    priorities[valid_bins] -= full_bin_penalty[valid_bins] * 0.02 * penalty_weight # Slightly penalize nearly full bins\n\n    # Bin Diversity: Encourage using bins with different fill levels\n    bin_diversity_bonus = np.std(bins_remain_cap) / bins_remain_cap.max()\n    priorities[valid_bins] += bin_diversity_bonus * 0.03\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, and emptiness penalty.\n    Scales randomization and bonuses based on item size and bin capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization - scaled by item and bin capacity\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item_scale)\n    empty_bin_penalty_weight = 0.03\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n    \n    # Near full bonus\n    almost_full = (wasted_space / bins_remain_cap.max() < 0.05) & feasible_bins\n    priorities[almost_full] += 0.1\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, bin utilization, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mark infeasible bins with negative infinity\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate remaining space after placing the item in each bin\n    wasted_space = bins_remain_cap - item\n    \n    # Prioritize bins with minimal wasted space (Best-Fit component)\n    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]\n\n    # Fill ratio bonus, scaled by remaining capacity.  Emphasizes filling nearly full bins.\n    fill_ratio_after = (bins_remain_cap - wasted_space) / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] += fill_ratio_after[bins_remain_cap >= item] * 0.3\n\n    # Adaptive Randomization: Smaller items get more randomization.\n    randomization_strength = 0.1 / (1 + item) # Inverse relationship\n    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * randomization_strength\n\n    # Bin Utilization Penalty: Penalize bins with very low fill levels to encourage using partially filled bins.\n    utilization_ratio = bins_remain_cap / bins_remain_cap.max()\n    priorities[bins_remain_cap >= item] -= (1 - utilization_ratio[bins_remain_cap >= item]) * 0.1\n\n    # Bonus for bins that would become nearly full after placing the item\n    nearly_full_threshold = 0.9\n    nearly_full_bonus = np.where((bins_remain_cap >= item) & (fill_ratio_after >= nearly_full_threshold), 0.2, 0)\n    priorities[bins_remain_cap >= item] += nearly_full_bonus[bins_remain_cap >= item]\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced priority function combining best-fit, fill ratio, bin diversity, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    \n    # Feasible bins only\n    feasible_mask = bins_remain_cap >= item\n    feasible_bins_cap = bins_remain_cap[feasible_mask]\n\n    if feasible_bins_cap.size == 0:\n        return priorities\n    \n    # Waste-based prioritization (smaller waste is better)\n    wasted_space = feasible_bins_cap - item\n    priorities[feasible_mask] = -wasted_space\n    \n    # Fill ratio bonus, tuned for better sensitivity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += fill_ratio_after * 0.3  # Slightly increased fill ratio weight\n    \n    # Bin diversity incentive: Reward bins with remaining capacity close to the item size\n    diversity_score = np.exp(-np.abs(wasted_space - item) / (0.1 * bins_remain_cap.max()))\n    priorities[feasible_mask] += diversity_score * 0.15\n    \n    # Adaptive randomization, scaling with both item and available capacity\n    randomization_strength = 0.05 * item * (1 - wasted_space / bins_remain_cap.max()) # Reduced Randomization strength when the wasted space is large\n    priorities[feasible_mask] += np.random.rand(feasible_bins_cap.size) * randomization_strength\n    \n    # Dynamic empty bin penalty, adjusting to the current bin landscape\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage) #Increase penalty when the average bin usage is low\n    priorities[feasible_mask] -= empty_bin_penalty[feasible_mask] * 0.1\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced priority function combining best-fit, fill ratio, bin diversity, and adaptive randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Infeasible bins get the lowest priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    \n    # Feasible bins only\n    feasible_mask = bins_remain_cap >= item\n    feasible_bins_cap = bins_remain_cap[feasible_mask]\n\n    if feasible_bins_cap.size == 0:\n        return priorities\n    \n    # Waste-based prioritization (smaller waste is better)\n    wasted_space = feasible_bins_cap - item\n    priorities[feasible_mask] = -wasted_space\n    \n    # Fill ratio bonus, tuned for better sensitivity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_mask] += fill_ratio_after * 0.3  # Slightly increased fill ratio weight\n    \n    # Bin diversity incentive: Reward bins with remaining capacity close to the item size\n    diversity_score = np.exp(-np.abs(wasted_space - item) / (0.1 * bins_remain_cap.max()))\n    priorities[feasible_mask] += diversity_score * 0.15\n    \n    # Adaptive randomization, scaling with both item and available capacity\n    randomization_strength = 0.05 * item * (1 - wasted_space / bins_remain_cap.max()) # Reduced Randomization strength when the wasted space is large\n    priorities[feasible_mask] += np.random.rand(feasible_bins_cap.size) * randomization_strength\n    \n    # Dynamic empty bin penalty, adjusting to the current bin landscape\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage) #Increase penalty when the average bin usage is low\n    priorities[feasible_mask] -= empty_bin_penalty[feasible_mask] * 0.1\n    \n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Controlled randomization, scaled by (1 - item_scale)\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after_all = (bins_remain_cap - wasted_space) / bins_remain_cap.max() #using scaled version\n    priorities[feasible_bins] += fill_ratio_after_all[feasible_bins] * 0.2 #reduce scaling to 0.2\n\n    # Slightly penalize bins that are already very full.\n    almost_full = (wasted_space < 0.1*bins_remain_cap.max()) & feasible_bins\n    priorities[almost_full] -= 0.01\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, controlled randomization and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / (bins_remain_cap[feasible_bins])\n    priorities[feasible_bins] += fill_ratio_after * 0.1\n\n    # Controlled randomization, scaled by (1 - item_scale)\n    item_scale = item / bins_remain_cap.max()\n    randomization_factor = 0.02 * (1 - item_scale)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_factor\n\n    # Encourage filling bins, bonus based on fill ratio AFTER placement\n    fill_ratio_after_all = (bins_remain_cap - wasted_space) / bins_remain_cap.max() #using scaled version\n    priorities[feasible_bins] += fill_ratio_after_all[feasible_bins] * 0.2 #reduce scaling to 0.2\n\n    # Slightly penalize bins that are already very full.\n    almost_full = (wasted_space < 0.1*bins_remain_cap.max()) & feasible_bins\n    priorities[almost_full] -= 0.01\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, adaptive randomization, and bin diversity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization (best-fit) with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.2 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill\n    randomization_strength = 0.05 * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, more for larger items\n    empty_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * item_scale\n    priorities[feasible_bins] -= empty_penalty * 0.02\n\n    # Bonus for bins nearing full capacity (almost perfect fit)\n    almost_perfect_fit = np.exp(-wasted_space[feasible_bins] * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.05\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, adaptive randomization, and bin diversity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization (best-fit) with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.2 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill\n    randomization_strength = 0.05 * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, more for larger items\n    empty_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * item_scale\n    priorities[feasible_bins] -= empty_penalty * 0.02\n\n    # Bonus for bins nearing full capacity (almost perfect fit)\n    almost_perfect_fit = np.exp(-wasted_space[feasible_bins] * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.05\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, \n                bins_remain_cap: np.ndarray,\n                fill_ratio_weight: float = 0.4998508278429229,\n                randomization_strength_base: float = 0.4185316887301156,\n                empty_penalty_weight: float = 0.07094071477100863,\n                almost_full_threshold: float = 0.05891004041856748,\n                almost_full_bonus: float = 0.01883537661369473) -> np.ndarray:\n    \"\"\"Prioritizes bins using waste, fill ratio, controlled randomization, adaptive penalties, and near-full bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, adaptive randomization, and dynamic emptiness penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear waste penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive fill ratio, adaptive randomization, and dynamic emptiness penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear waste penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, and adaptive randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0  # Ensure no negative waste\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / np.max(bins_remain_cap)\n\n    # Fill ratio bonus after placing the item\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1-fill_ratio_after) * 0.3\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller, scale by item size.\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Encourage bins that are almost full (but only if feasible)\n    almost_full_threshold = 0.1  # e.g., within 10% of being full\n    almost_full_bins = (bins_remain_cap[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2 # bonus for almost full\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, and adaptive randomization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n    wasted_space[wasted_space < 0] = 0  # Ensure no negative waste\n\n    # Prioritize based on wasted space (smaller waste is better)\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / np.max(bins_remain_cap)\n\n    # Fill ratio bonus after placing the item\n    fill_ratio_after = (bins_remain_cap[feasible_bins] - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1-fill_ratio_after) * 0.3\n\n    # Adaptive Randomization: Reduce randomization as bins become fuller, scale by item size.\n    randomization_strength = 0.1 * item * (np.max(bins_remain_cap) - bins_remain_cap[feasible_bins]) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Encourage bins that are almost full (but only if feasible)\n    almost_full_threshold = 0.1  # e.g., within 10% of being full\n    almost_full_bins = (bins_remain_cap[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2 # bonus for almost full\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines wasted space, fill ratio, randomization, diversity and prevents early commitment.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / bins_remain_cap.max()\n    \n    # Fill ratio bonus, adaptive to the item size and bin capacity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    adaptive_fill_bonus = fill_ratio_after * (0.2 + 0.1 * (item / bins_remain_cap.max()))\n    priorities[feasible_bins] += adaptive_fill_bonus[feasible_bins]\n\n    # Adaptive Randomization: More randomization for smaller items and fuller bins\n    randomization_strength = 0.05 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Bin Diversity Bonus: Encourage using bins with diverse fill levels.\n    if np.sum(feasible_bins) > 1:\n        avg_remaining_cap = np.mean(bins_remain_cap[feasible_bins])\n        diversity_bonus = np.abs(bins_remain_cap - avg_remaining_cap) / bins_remain_cap.max()\n        priorities[feasible_bins] += diversity_bonus[feasible_bins] * 0.05\n        \n    # Prevent early commitment to bins that are almost full. Penalize bins with very small remaining capacity\n    almost_full_penalty = np.where(bins_remain_cap < 1.1*item, (1-(bins_remain_cap/ (1.1*item))),0) #apply the penalty only if the bin is almost full\n    \n    \n    priorities[feasible_bins] -= almost_full_penalty[feasible_bins] * 0.1 # scaled by a factor of 0.1 for balance.\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines wasted space, fill ratio, randomization, diversity and prevents early commitment.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Infeasible bins get the lowest priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate wasted space\n    wasted_space = bins_remain_cap - item\n\n    # Prioritize based on wasted space (smaller waste is better)\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] = -wasted_space[feasible_bins] / bins_remain_cap.max()\n    \n    # Fill ratio bonus, adaptive to the item size and bin capacity\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    adaptive_fill_bonus = fill_ratio_after * (0.2 + 0.1 * (item / bins_remain_cap.max()))\n    priorities[feasible_bins] += adaptive_fill_bonus[feasible_bins]\n\n    # Adaptive Randomization: More randomization for smaller items and fuller bins\n    randomization_strength = 0.05 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Bin Diversity Bonus: Encourage using bins with diverse fill levels.\n    if np.sum(feasible_bins) > 1:\n        avg_remaining_cap = np.mean(bins_remain_cap[feasible_bins])\n        diversity_bonus = np.abs(bins_remain_cap - avg_remaining_cap) / bins_remain_cap.max()\n        priorities[feasible_bins] += diversity_bonus[feasible_bins] * 0.05\n        \n    # Prevent early commitment to bins that are almost full. Penalize bins with very small remaining capacity\n    almost_full_penalty = np.where(bins_remain_cap < 1.1*item, (1-(bins_remain_cap/ (1.1*item))),0) #apply the penalty only if the bin is almost full\n    \n    \n    priorities[feasible_bins] -= almost_full_penalty[feasible_bins] * 0.1 # scaled by a factor of 0.1 for balance.\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}