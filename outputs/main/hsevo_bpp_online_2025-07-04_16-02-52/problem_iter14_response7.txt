```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines best-fit, fill ratio, diversity, and adaptive randomization."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Infeasible bins get the lowest priority
    infeasible_mask = bins_remain_cap < item
    priorities[infeasible_mask] = -np.inf

    # Feasible bins only
    feasible_mask = bins_remain_cap >= item
    feasible_bins_cap = bins_remain_cap[feasible_mask]

    if feasible_bins_cap.size == 0:
        return priorities

    # Waste-based prioritization (smaller waste is better)
    wasted_space = feasible_bins_cap - item
    priorities[feasible_mask] = -wasted_space

    # Fill ratio bonus, tuned for better sensitivity
    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())
    priorities[feasible_mask] += fill_ratio_after * 0.3

    # Bin diversity incentive: Reward bins with remaining capacity close to the item size
    diversity_score = np.exp(-np.abs(wasted_space - item) / (0.1 * bins_remain_cap.max()))
    priorities[feasible_mask] += diversity_score * 0.15

    # Adaptive randomization, scaling with both item and available capacity
    randomization_strength = 0.05 * item * (1 - wasted_space / bins_remain_cap.max())
    priorities[feasible_mask] += np.random.rand(feasible_bins_cap.size) * randomization_strength

    # Dynamic empty bin penalty, adjusting to the current bin landscape
    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()
    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage)
    priorities[feasible_mask] -= empty_bin_penalty[feasible_mask] * 0.1
    
    # Encourage filling bins, bonus based on fill ratio AFTER placement
    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())
    priorities[feasible_mask] += fill_ratio_after * 0.2

    return priorities
```
