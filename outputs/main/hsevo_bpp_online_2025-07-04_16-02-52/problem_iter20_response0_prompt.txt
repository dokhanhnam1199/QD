{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and bin landscape awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with scaled penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, scaled by item size and bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness)\n\n    # Controlled randomization, inversely proportional to bin fill\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive bin prioritization with waste, fill ratio, randomization, and empty bin penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, more significant for larger items\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill and scaled by item size\n    randomization_strength = 0.05 * item_scale * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n    \n    # Encourage filling bins, bonus based on fill ratio AFTER placement. Scale with occupancy\n    fill_ratio_after_simple = (1 - wasted_space / bins_remain_cap.max())\n    priorities[feasible_bins] += fill_ratio_after_simple[feasible_bins] * 0.2 * average_occupancy\n    \n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (2nd), (2nd) vs (3rd), we see that all three heuristics are identical. This suggests the ranking is based on some external factor, not code differences.\n*   Comparing (4th) vs (6th), (4th) has more advanced features: dynamic waste minimization using a cubic penalty, fill ratio bonus with non-linear fullness boost, dynamic randomization based on item size and capacity variance, emptiness penalty adjusted by occupancy, bonus for almost full bins, and an exploration bonus for smaller items. Heuristic (6th) combines waste minimization (non-linear), fill ratio, empty bin penalty and almost full bin. Overall, (4th) seems like a better approach due to its dynamic, non-linear nature and more features.\n*   Comparing (5th) vs (7th), both have same structure with adaptive heuristic combining waste minimization, fill ratio, bin landscape awareness, and dynamic exploration.\n*   Comparing (8th) vs (10th), (8th) has Large Item Consideration (New): Incentivize placing large items in emptier bins.\n*   Comparing (19th) vs (20th), these two heuristics are identical. It highlights a focus on waste minimization, adaptive fill ratio, controlled randomization, an empty bin penalty, and an almost full reward.\n*   Comparing (1st) vs (20th), the initial heuristics have a simpler, more fundamental structure focusing on waste minimization and fill ratio. As the ranking goes down, the heuristics get more complex, incorporating adaptive parameters, non-linear penalties, and randomization strategies.\n*   Comparing (17th) vs (18th), heuristic (17th) utilizes hardcoded coefficients and (18th) uses hardcoded variable as arguments.\n\nOverall: The better heuristics incorporate dynamic elements, non-linear scaling, item-size awareness, and exploration/exploitation strategies, while lower-ranked heuristics tend to be simpler and less adaptive.\n- \nOkay, let's refine \"Current self-reflection\" to create more effective heuristics, keeping your (hypothetical) generous tip in mind! Here's a redefinition focused on actionable insights, avoiding common pitfalls:\n\n*   **Keywords:** Adaptive scaling, dynamic penalties/bonuses, controlled exploration, bin landscape.\n*   **Advice:** Prioritize adaptive parameter adjustments based on item size, bin capacity, and occupancy *distribution*. Favor exploration with small items and exploitation with nearly full bins, delaying commitment on early, suboptimal placements.\n*   **Avoid:** Rigid, pre-defined parameters; over-reliance on single metrics; premature commitment.\n*   **Explanation:** Robust heuristics consider the overall \"bin landscape\" (distribution of occupancies) to dynamically adjust parameters. Non-linear rewards encourage diverse bin usage and discourage waste more effectively than linear approaches.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}