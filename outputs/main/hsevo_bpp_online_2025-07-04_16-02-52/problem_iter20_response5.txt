```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines waste minimization, fill ratio, and dynamic exploration based on bin landscape."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if not np.any(feasible_bins):
        return priorities - np.inf

    max_bin_cap = np.max(bins_remain_cap)
    avg_bin_cap = np.mean(bins_remain_cap)

    # 1. Waste Minimization (Non-linear)
    wasted_space = bins_remain_cap - item
    wasted_space[~feasible_bins] = np.inf
    waste_penalty = (wasted_space / max_bin_cap)**2
    priorities[feasible_bins] -= waste_penalty[feasible_bins] * 0.1

    # 2. Adaptive Fill Ratio Bonus
    fill_ratio_after = item / bins_remain_cap[feasible_bins]
    priorities[feasible_bins] += fill_ratio_after * 0.2

    # 3. Dynamic Exploration
    exploration_strength = 0.05 * item * (1 - avg_bin_cap / max_bin_cap)
    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_strength

    # 4. Dynamic empty bin penalty, adjusting to the overall bin landscape
    average_bin_usage = np.mean(bins_remain_cap) / max_bin_cap
    empty_bin_penalty = (bins_remain_cap / max_bin_cap) * (1 - average_bin_usage)
    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1

    # 5. Almost Full Bonus
    wasted_space_after = bins_remain_cap[feasible_bins] - item
    almost_full_threshold = 0.04 * max_bin_cap
    almost_full = wasted_space_after <= almost_full_threshold
    priorities[feasible_bins][almost_full] += 0.15

    # 6. Large Item Consideration
    if item > 0.5 * max_bin_cap:
        empty_bin_bonus = (bins_remain_cap[feasible_bins] / max_bin_cap) * 0.05
        priorities[feasible_bins] += empty_bin_bonus
    
    return priorities
```
