{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and bin landscape.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with dynamic non-linear penalty. Larger waste penalized more\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n    priorities[feasible_bins] -= waste_penalty\n\n    # Fill ratio bonus, scaled by item size and bin fullness.  Emphasis on nearly-full bins.\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2) # Non-linear fullness boost\n\n    # Dynamic randomization, proportional to item size and remaining capacity variance\n    capacity_std = np.std(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.sum(feasible_bins) > 1 else 0.0\n    randomization_strength = 0.03 * item_scale * (1 + capacity_std) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Penalty for leaving bins mostly empty, adjusted by average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())**2 * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.05 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Significant bonus for bins becoming almost full, scaled by how close they are\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = 0.2 * (1 - wasted_space_after[almost_full] / (0.05 * bins_remain_cap.max())) if np.any(almost_full) else 0.0\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Smaller items have a higher chance to explore (fit in emptier bins)\n    if item < 0.2 * bins_remain_cap.max():\n        exploration_bonus = 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += exploration_bonus\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins.\n    if item > 0.7 * bins_remain_cap.max():\n        large_item_bonus = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += large_item_bonus\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, landscape and dynamic exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with dynamic non-linear penalty.\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n    priorities[feasible_bins] -= waste_penalty\n\n    # Fill ratio bonus, scaled by item size and bin fullness.\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2)\n\n    # Dynamic randomization, proportional to item size and remaining capacity variance\n    capacity_std = np.std(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.sum(feasible_bins) > 1 else 0.0\n    randomization_strength = 0.03 * item_scale * (1 + capacity_std) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Penalty for leaving bins mostly empty, adjusted by average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())**2 * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.05 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Significant bonus for bins becoming almost full, scaled by how close they are\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = 0.2 * (1 - wasted_space_after[almost_full] / (0.05 * bins_remain_cap.max())) if np.any(almost_full) else 0.0\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Smaller items have a higher chance to explore (fit in emptier bins)\n    if item < 0.2 * bins_remain_cap.max():\n        exploration_bonus = 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += exploration_bonus\n\n    # Large Item Consideration (New): Incentivize placing large items in emptier bins\n    if item > 0.8 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic includes a bonus for almost full bins and a penalty for placing small items in almost empty bins, which are absent in the worst. (2nd best) vs (19th) reveals that (2nd) does not penalize placing small items in almost empty bins. Comparing (1st) vs (2nd), they are identical, suggesting other factors influence ranking. (3rd) vs (4th) are identical. Comparing (second worst) vs (worst), they are identical. Overall: Top heuristics have nuanced adjustments based on item size and bin fullness, promoting efficient space use and preventing premature commitment to empty bins with small items. They demonstrate better landscape awareness.\n- \nOkay, I understand the task. Let's redefine \"Current self-reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective self-reflection\" and focusing on actionable advice.\n\nHere's a breakdown to guide the process:\n\n*   **Keywords:** Adaptive parameters, non-linear scaling, controlled randomness, bin landscape, item size, bin capacity, state-dependent adjustments, balanced exploration/exploitation.\n\n*   **Advice:** Design heuristics with parameters that dynamically adapt to the current state of the bins and items. Use non-linear scaling for rewards and penalties to fine-tune behavior. Balance exploration (trying different placements) with exploitation (placing items where they fit best based on current knowledge).\n\n*   **Avoid:** Overly simplistic, direct heuristics based solely on remaining capacity. Relying on complex analogies without empirical validation. Undifferentiated, global randomness.\n\n*   **Explanation:** Effective heuristics should \"sense\" the overall packing situation and adjust their behavior accordingly. Adaptive parameters, state-dependent adjustments, non-linear scaling and balanced exploration/exploitation are key.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}