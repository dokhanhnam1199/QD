```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Infeasible bins get lowest priority
    priorities[bins_remain_cap < item] = -np.inf

    # Wasted space is still important
    wasted_space = bins_remain_cap - item
    priorities[bins_remain_cap >= item] = -wasted_space[bins_remain_cap >= item]

    # Bonus for bins that are relatively full, but scaled.  We want this to be a
    # secondary effect, not the primary driver.  Adjust scale as needed.
    priorities[bins_remain_cap >= item] += (1 - bins_remain_cap[bins_remain_cap >= item]) * 0.2

    # Add a small random component to encourage exploration. The scale here is also important.
    # Too large and it overrides the other heuristics. Too small and it does nothing.
    priorities[bins_remain_cap >= item] += np.random.rand(np.sum(bins_remain_cap >= item)) * 0.05

    # Prioritize bins with remaining capacity closest to a multiple of item size.
    # This encourages filling bins with similar-sized items. This can potentially
    # reduce fragmentation and make it easier to pack future items.
    
    for i in np.where(bins_remain_cap >= item)[0]:
        remainder = bins_remain_cap[i] % item
        priorities[i] += -abs(remainder - item/2) * 0.01  # small penalty, tuned.
    

    return priorities
```
