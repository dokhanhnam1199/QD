```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive heuristic combining waste minimization, fill ratio, bin landscape awareness,
    and dynamic exploration/exploitation balance.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if not np.any(feasible_bins):
        return priorities - np.inf

    # Waste minimization with non-linear penalty, scaled by item size and remaining capacity
    wasted_space = bins_remain_cap - item
    wasted_space[~feasible_bins] = np.inf
    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())
    priorities[feasible_bins] -= waste_penalty

    # Adaptive fill ratio bonus, scaled by item size and bin fullness, with sigmoid scaling
    fill_ratio_after = item / bins_remain_cap[feasible_bins]
    item_scale = item / bins_remain_cap.max()
    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()
    sigmoid_scale = 1 / (1 + np.exp(-5 * (bin_fullness - 0.5))) # Sigmoid centered at 0.5 fullness
    priorities[feasible_bins] += fill_ratio_after * 0.5 * item_scale * sigmoid_scale

    # Dynamic exploration/exploitation: stronger randomization for smaller items and emptier bins
    randomization_strength = 0.1 * (item / bins_remain_cap.max()) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())
    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength

    # Bin balance encouragement: penalize under-utilized bins with a dynamically adjusted weight
    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())
    bin_utilization_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (item / bins_remain_cap.max())
    utilization_penalty_weight = 0.01 + 0.09 * average_occupancy # Weight adjusted based on average bin utilization
    priorities[feasible_bins] -= bin_utilization_penalty * utilization_penalty_weight

    # Encourage nearly full bins, with a bonus scaled by how much space is left and how large the item is
    remaining_space_after = bins_remain_cap[feasible_bins] - item
    almost_full = remaining_space_after / bins_remain_cap.max() < 0.05
    almost_full_bonus = (1 - remaining_space_after[almost_full] / bins_remain_cap.max()) * (item / bins_remain_cap.max()) * 0.2
    priorities[feasible_bins][almost_full] += almost_full_bonus

    # Large item placement incentive.  Place large items into the fullest feasible bin, to avoid stranding them.
    large_item_threshold = 0.7 * bins_remain_cap.max()
    if item > large_item_threshold:
        priorities[feasible_bins] += bin_fullness * 0.1

    return priorities
```
