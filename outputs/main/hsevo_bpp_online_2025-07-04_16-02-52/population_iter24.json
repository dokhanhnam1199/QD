[
  {
    "stdout_filepath": "problem_iter23_response0.txt_stdout.txt",
    "code_path": "problem_iter23_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fill ratio, controlled randomization, emptiness penalty, near-full reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization, scaled by item size and bin capacity\n    wasted_space = bins_remain_cap - item\n    waste_penalty_scale = np.mean(bins_remain_cap)\n    priorities[feasible_bins] -= (wasted_space[feasible_bins]**2) / (waste_penalty_scale + 1e-9) * (item / np.max(bins_remain_cap))\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = (bins_remain_cap - item) / np.max(bins_remain_cap)\n    priorities[feasible_bins] += (1 - fill_ratio_after[feasible_bins]) * 0.3 * (1 - item / np.max(bins_remain_cap))\n\n    # Controlled Randomization, scaled to remaining capacity\n    randomization_strength = 0.05 * (np.max(bins_remain_cap) - bins_remain_cap) / np.max(bins_remain_cap) * item\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Emptiness Penalty, more severe for smaller items\n    empty_bin_penalty = (bins_remain_cap / np.max(bins_remain_cap))\n    penalty_scale = 0.03 * (1 - np.mean(1 - bins_remain_cap / np.max(bins_remain_cap))) * (1 - item / np.max(bins_remain_cap))\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Near full bonus\n    almost_full_threshold = 0.1\n    almost_full_bins = (wasted_space[feasible_bins] <= almost_full_threshold * np.max(bins_remain_cap))\n    priorities[feasible_bins][almost_full_bins] += 0.2\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.617072197846027,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response1.txt_stdout.txt",
    "code_path": "problem_iter23_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and item-aware randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste Minimization with non-linear scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Fill Ratio Bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] += fill_ratio_after * 0.2 * (item / bins_remain_cap.max())\n\n    # Item-aware Randomization\n    randomization_strength = 0.05 * (1-item / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Empty bin penalty, scaled to bin fullness\n    average_bin_usage = np.mean(bins_remain_cap) / bins_remain_cap.max()\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - average_bin_usage)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * 0.1\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.457518946948548,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response2.txt_stdout.txt",
    "code_path": "problem_iter23_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on waste, fill ratio, and bin landscape.\n    Combines adaptive scaling and bonuses for near-full bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with item size scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = (item / bins_remain_cap.max())**0.5\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Fill ratio bonus with capacity awareness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    capacity_scale = (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    occupancy_variance = np.var(1 - bins_remain_cap / bins_remain_cap.max())\n    fill_bonus_weight = 0.2 + 0.3 * (1 - occupancy_variance)\n    priorities[feasible_bins] += fill_ratio_after * fill_bonus_weight * capacity_scale\n\n    # Controlled randomization\n    randomization_strength = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.04 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Strong bonus for almost full bins, non-linear scaling\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = (1 - wasted_space_after[almost_full] / bins_remain_cap.max())**2\n    priorities[feasible_bins][almost_full] += 0.15 * almost_full_bonus\n\n    # Delayed commitment penalty\n    almost_empty = bins_remain_cap[feasible_bins] / bins_remain_cap.max() > 0.8\n    small_item = item / bins_remain_cap.max() < 0.2\n    if np.any(almost_empty) and small_item:\n        priorities[feasible_bins][almost_empty] -= 0.05 * small_item\n\n    # Incentivize placing large items in emptier bins\n    if item > bins_remain_cap.max() / 2:\n        priorities[feasible_bins] += (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * 0.05\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 6.023135221380145,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response3.txt_stdout.txt",
    "code_path": "problem_iter23_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, bin awareness, and controlled randomization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = (item / bins_remain_cap.max())**0.5 #Scale based on item size\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Adaptive fill ratio bonus\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    capacity_scale = (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    occupancy_variance = np.var(1 - bins_remain_cap / bins_remain_cap.max())\n    fill_bonus_weight = 0.2 + 0.3 * (1 - occupancy_variance)\n    priorities[feasible_bins] += fill_ratio_after * fill_bonus_weight * capacity_scale\n\n    # Controlled randomization\n    randomization_strength = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bin-emptiness penalty\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.04 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Almost full bonus\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = (1 - wasted_space_after[almost_full] / bins_remain_cap.max())**2\n    priorities[feasible_bins][almost_full] += 0.15 * almost_full_bonus\n\n    # Small item penalty in almost empty bins\n    almost_empty = bins_remain_cap[feasible_bins] / bins_remain_cap.max() > 0.8\n    small_item = item / bins_remain_cap.max() < 0.2\n    if np.any(almost_empty) and small_item:\n        priorities[feasible_bins][almost_empty] -= 0.05 * small_item\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 6.122856003191075,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response4.txt_stdout.txt",
    "code_path": "problem_iter23_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, fill ratio, almost full reward, and controlled randomization.\n    Adapts to bin fullness and item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Wasted space priority (minimize waste)\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Fill ratio bonus, scaling with current bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_ratio_weight = 0.2 + 0.6 * bin_fullness\n    priorities[feasible_bins] += fill_ratio_after * fill_ratio_weight\n\n    # Controlled randomization, reduce for larger items and fuller bins\n    randomization_strength = 0.05 * (1 - item / bins_remain_cap.max()) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bonus for almost full bins after placement\n    almost_full_threshold = 0.05 * bins_remain_cap.max()  # Adaptive threshold\n    remaining_after_placement = bins_remain_cap[feasible_bins] - item\n    almost_full_bins = remaining_after_placement <= almost_full_threshold\n    priorities[feasible_bins][almost_full_bins] += 0.3 + 0.2*(1-item/bins_remain_cap.max())\n\n    #Adaptive penalty for placing the item in almost empty bins.\n    average_occupancy = np.mean(1 - bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())\n    penalty_scale = 0.05 * (1 - average_occupancy) * (item / bins_remain_cap.max()) # Scale penalty by item size\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response5.txt_stdout.txt",
    "code_path": "problem_iter23_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, and bin landscape awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with cubic penalty, scaled by item size\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n\n    # Adaptive fill ratio bonus, significant for larger items, boosted by bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness)\n\n    # Dynamic randomization, inversely proportional to bin fill, scales with item size & capacity variance\n    cap_variance = np.var(bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 + cap_variance)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scales with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    priorities[feasible_bins][almost_full] += 0.1\n\n    # Large Item Consideration: Incentivize placing large items in emptier bins\n    if item > 0.5 * bins_remain_cap.max():\n        priorities[feasible_bins] += 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.068607897885915,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response6.txt_stdout.txt",
    "code_path": "problem_iter23_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive fill ratio, controlled randomization, almost full reward, and empty bin penalty with landscape awareness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with adaptive scaling\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = np.clip(item / bins_remain_cap.max(), 0.1, 0.5)\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fullness.\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())**2\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Strong bonus for almost full bins after insertion\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.1\n    priorities[feasible_bins][almost_full] += 0.2\n\n    # Empty Bin Penalty: Penalize bins that are too empty, adjust based on average fill.\n    average_fill = np.mean(1 - bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    penalty_scale = 0.05 * (1 - average_fill)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * penalty_scale\n\n    # Landscape aware penalty for creating nearly empty bins\n    nearly_empty = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap.max() > 0.9\n    priorities[feasible_bins][nearly_empty] -= 0.1 * item_scale\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.01874750698045,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response7.txt_stdout.txt",
    "code_path": "problem_iter23_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic combining waste, fill ratio, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with cubic penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**3 * (item / bins_remain_cap.max())\n    priorities[feasible_bins] -= waste_penalty\n\n    # Fill ratio bonus, scaled by item size and bin fullness\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2)\n\n    # Dynamic randomization, proportional to item size and remaining capacity variance\n    capacity_std = np.std(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.sum(feasible_bins) > 1 else 0.0\n    randomization_strength = 0.03 * item_scale * (1 + capacity_std) * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Penalty for leaving bins mostly empty, adjusted by average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max())**2 * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.05 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Significant bonus for bins becoming almost full, scaled by how close they are\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.05\n    almost_full_bonus = 0.2 * (1 - wasted_space_after[almost_full] / (0.05 * bins_remain_cap.max())) if np.any(almost_full) else 0.0\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Smaller items have a higher chance to explore (fit in emptier bins)\n    if item < 0.2 * bins_remain_cap.max():\n        exploration_bonus = 0.05 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += exploration_bonus\n\n    # Dynamically adjust large item threshold based on remaining capacities\n    large_item_threshold = 0.7 + 0.1 * (np.mean(bins_remain_cap) / bins_remain_cap.max())\n    large_item_threshold = min(0.9, large_item_threshold)  # Cap the threshold\n\n    if item > large_item_threshold * bins_remain_cap.max():\n        large_item_bonus = 0.1 * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n        priorities[feasible_bins] += large_item_bonus\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response8.txt_stdout.txt",
    "code_path": "problem_iter23_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic: waste minimization, fill ratio, landscape, item-aware adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    max_bin_cap = np.max(bins_remain_cap)\n    avg_bin_cap = np.mean(bins_remain_cap)\n    std_bin_cap = np.std(bins_remain_cap)\n\n    # 1. Waste Minimization (Scaled)\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / max_bin_cap)**2 * (item / max_bin_cap)\n\n    # 2. Adaptive Fill Ratio Bonus (Item-aware)\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / max_bin_cap\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / max_bin_cap\n    priorities[feasible_bins] += fill_ratio_after * 0.3 * item_scale * (1 + bin_fullness**2)\n\n    # 3. Controlled Randomization (Bin-aware)\n    randomization_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / max_bin_cap)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # 4. Adaptive Empty Bin Penalty (Landscape-aware)\n    empty_bin_penalty = (bins_remain_cap / max_bin_cap) * (1 - item / max_bin_cap)\n    empty_bin_weight = 0.02 + 0.08 * (1 - avg_bin_cap / max_bin_cap)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_weight\n\n    # 5. Almost Full Bonus (Enhanced)\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / max_bin_cap < 0.04\n    priorities[feasible_bins][almost_full] += 0.15\n\n    # 6. Large Item Consideration (Threshold)\n    if item > 0.5 * max_bin_cap:\n        empty_bin_bonus = (bins_remain_cap[feasible_bins] / max_bin_cap) * 0.05\n        priorities[feasible_bins] += empty_bin_bonus\n\n    # 7. Bin Capacity Variance Penalty (Balance)\n    capacity_variance_penalty = (std_bin_cap / max_bin_cap) * 0.02\n    priorities[feasible_bins] -= capacity_variance_penalty\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response9.txt_stdout.txt",
    "code_path": "problem_iter23_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic: Waste minimization, fill ratio, bin landscape, dynamic params.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    item_scale = item / bins_remain_cap.max()\n\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = 0.5 + 0.5 * item_scale\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_ratio_weight = 0.2 + 0.6 * bin_fullness\n    priorities[feasible_bins] += fill_ratio_after * fill_ratio_weight * item_scale\n\n    randomization_strength = 0.1 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.05 + 0.05 * average_occupancy * (1 - item_scale)\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.03\n    almost_full_bonus = 0.2 + 0.3 * item_scale\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    capacity_difference = np.abs(bins_remain_cap[feasible_bins] - np.mean(bins_remain_cap)) / bins_remain_cap.max()\n    distribution_penalty = 0.02 * capacity_difference * item_scale\n    priorities[feasible_bins] -= distribution_penalty\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.038691663342641,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response0.txt_stdout.txt",
    "code_path": "problem_iter24_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced adaptive heuristic for online bin packing.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # 1. Waste Minimization with Dynamic Scaling:\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    \n    # Scale the penalty based on item size and remaining capacity.  Smaller remaining capacity\n    # and larger items result in a higher penalty.\n    waste_penalty_scale = (item / bins_remain_cap.max()) * (1 / (bins_remain_cap[feasible_bins] / bins_remain_cap.max() + 0.1))  # Add small value to avoid division by zero\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # 2. Adaptive Fill Ratio Bonus with Non-Linear Scaling:\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    \n    # Apply non-linear scaling to the fill ratio bonus.  Higher fill ratios get a larger bonus,\n    # encouraging efficient packing.\n    fill_ratio_bonus_scale = fill_ratio_after**1.5  # Experiment with different powers\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_bonus_scale * 0.3 * item_scale * (1 + bin_fullness)\n\n    # 3. Controlled Randomization Based on Bin Utilization:\n    # Reduce randomness as bins become fuller.\n    randomness_strength = 0.05 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max())**2\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomness_strength\n\n    # 4. Bin Emptiness Penalty Adjusted by Overall Bin Occupancy:\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    \n    # The penalty for using almost empty bins increases more significantly as average occupancy rises.\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy**2  # Non-linear scaling\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # 5. \"Almost Full\" Bin Bonus with Tolerance Adjustment:\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    \n    # Dynamically adjust the \"almost full\" tolerance based on item size.  Smaller items require\n    # a tighter tolerance.\n    almost_full_tolerance = 0.05 + 0.05 * (item / bins_remain_cap.max())\n    almost_full = wasted_space_after / bins_remain_cap.max() < almost_full_tolerance\n    priorities[feasible_bins][almost_full] += 0.15 #Increased bonus for almost full.\n\n    # 6. Prioritize bins that are close to the item size (best fit)\n    item_difference = np.abs(bins_remain_cap[feasible_bins] - item)\n    priorities[feasible_bins] -= 0.05 * (item_difference / bins_remain_cap.max())\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response1.txt_stdout.txt",
    "code_path": "problem_iter24_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced adaptive heuristic for online bin packing.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with dynamic scaling based on item size and average fill\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    avg_fill = np.mean(1 - bins_remain_cap / np.max(bins_remain_cap))\n    waste_penalty_scale = (item / np.max(bins_remain_cap)) * (1 + avg_fill)\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / np.max(bins_remain_cap))**2 * waste_penalty_scale\n\n    # Fill ratio bonus with saturation and item-size dependent boost\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_boost = 1 + np.tanh(item / np.max(bins_remain_cap))  # Saturating boost for larger items\n    fill_ratio_bonus = fill_ratio_after * item_boost\n    priorities[feasible_bins] += 0.4 * fill_ratio_bonus / (1 + fill_ratio_bonus)  # Scaled and saturated\n\n    # Context-aware randomization, favoring emptier bins initially, then diminishing\n    global_fill = 1 - np.mean(bins_remain_cap) / np.max(bins_remain_cap)\n    randomization_strength = 0.1 * (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap)) * (1 - global_fill)**2  # Reduced randomness as bins fill\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Bin fullness incentive with non-linear scaling\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / np.max(bins_remain_cap)\n    fullness_incentive = bin_fullness**1.5 # Non-linear scaling to prioritize nearly full bins\n    priorities[feasible_bins] += 0.2 * fullness_incentive\n\n    # Strong bonus for bins that become nearly full after insertion\n    remaining_after = bins_remain_cap[feasible_bins] - item\n    nearly_full = remaining_after / np.max(bins_remain_cap) < 0.05\n    priorities[feasible_bins][nearly_full] += 0.5\n\n    # Moderate penalty for creating very small remaining space.\n    too_small_space = (remaining_after > 0) & (remaining_after / np.max(bins_remain_cap) > 0.01) & (remaining_after / np.max(bins_remain_cap) < 0.1)\n\n    priorities[feasible_bins][too_small_space] -= 0.1 * (remaining_after[too_small_space]/np.max(bins_remain_cap))\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.11846828879138,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response2.txt_stdout.txt",
    "code_path": "problem_iter24_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Advanced adaptive heuristic for online bin packing, emphasizing balanced optimization.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # 1. Waste Minimization with Dynamic Scaling:\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_ratio = wasted_space[feasible_bins] / bins_remain_cap[feasible_bins]\n    priorities[feasible_bins] -= (waste_ratio**1.5) * (item / np.max(bins_remain_cap))  # Non-linear penalty\n\n    # 2. Fill Ratio Optimization with State Awareness:\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / np.max(bins_remain_cap)\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / np.max(bins_remain_cap)\n\n    # Adaptive scaling based on average bin occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / np.max(bins_remain_cap))\n    fill_ratio_bonus_weight = 0.2 + 0.4 * average_occupancy  # More weight when bins are full\n    priorities[feasible_bins] += fill_ratio_after * fill_ratio_bonus_weight * item_scale * (1 + bin_fullness)\n\n    # 3. Controlled Randomization with Temperature:\n    temperature = 1 - average_occupancy # Higher temperature when bins are empty (more exploration)\n    randomization_strength = 0.03 * item_scale * temperature * (bins_remain_cap[feasible_bins] / np.max(bins_remain_cap))\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # 4. Empty Bin Strategy: Discourage if bins are mostly full\n    empty_bin_penalty = (bins_remain_cap / np.max(bins_remain_cap)) * (1 - item / np.max(bins_remain_cap))\n    empty_bin_penalty_weight = 0.01 + 0.04 * average_occupancy #Increase penalty as bins fill.\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # 5. \"Almost Full\" Bin Incentive:\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full_threshold = 0.03 * np.max(bins_remain_cap)\n    almost_full = wasted_space_after <= almost_full_threshold\n    priorities[feasible_bins][almost_full] += 0.15  # Stronger incentive\n\n    #6. Item Size Sensitive Adjustment\n    large_item_threshold = 0.7 * np.max(bins_remain_cap)\n    if item > large_item_threshold:\n        #For large items, prioritize bins with more space and less fill\n        space_priority = bins_remain_cap[feasible_bins] / np.max(bins_remain_cap)\n        fill_priority = 1 - bin_fullness\n        priorities[feasible_bins] += 0.1 * (space_priority + fill_priority)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response3.txt_stdout.txt",
    "code_path": "problem_iter24_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, fill ratio, bin landscape awareness, and item characteristics.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with adaptive scaling based on item size and bin fullness\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty_scale = (item / bins_remain_cap.max()) * (1 - np.mean(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.any(feasible_bins) else 1.0)  # Scale by item size and avg bin occupancy\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2 * waste_penalty_scale\n\n    # Fill ratio bonus, non-linear scaling, enhanced by item size and bin state\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_ratio_bonus_scale = 0.4 * item_scale * (1 + bin_fullness**2)  # Non-linear scaling of bin fullness\n    priorities[feasible_bins] += fill_ratio_after**1.5 * fill_ratio_bonus_scale  # Non-linear fill ratio bonus\n\n    # Controlled randomness, adaptive to item size and remaining capacity variance\n    capacity_variance = np.var(bins_remain_cap[feasible_bins] / bins_remain_cap.max()) if np.any(feasible_bins) else 0.0\n    randomization_strength = 0.03 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 + capacity_variance)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Empty bin penalty, scaled by item size, average occupancy, and number of empty bins\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_count = np.sum(bins_remain_cap == bins_remain_cap.max()) #Count completely empty bins.\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.01 + 0.06 * average_occupancy + 0.03 * (empty_bin_count / len(bins_remain_cap))\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for almost full bins, enhanced scaling based on item size\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = (wasted_space_after / bins_remain_cap.max()) < 0.05\n    almost_full_bonus = 0.07 + 0.05 * item_scale # Scale almost full bonus by item_scale\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n    # Prioritize bins that will become completely full after insertion\n    becomes_full = wasted_space_after == 0\n    priorities[feasible_bins][becomes_full] += 0.15\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response4.txt_stdout.txt",
    "code_path": "problem_iter24_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced adaptive heuristic for online bin packing, balancing waste minimization,\n    fill ratio, bin landscape awareness, and dynamic exploration.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf\n\n    # Waste minimization with non-linear penalty, focusing on small waste\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    waste_penalty = (wasted_space[feasible_bins] / bins_remain_cap.max())**1.5 * (item / bins_remain_cap.max())\n    priorities[feasible_bins] -= waste_penalty\n\n    # Adaptive fill ratio bonus, scaled by item size and bin fullness, emphasis on almost full\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    bin_fullness = 1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max()\n    fill_bonus = fill_ratio_after * 0.4 * item_scale * (1 + bin_fullness**2)  # Increased impact of fullness\n    priorities[feasible_bins] += fill_bonus\n\n    # Controlled randomization, dynamically adjusted to bin diversity and item size\n    bin_diversity = np.std(bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    randomization_strength = 0.03 * item_scale * (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 + bin_diversity)\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, scaling with item, average occupancy, and bin proximity to full\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())**0.5\n    empty_bin_penalty_weight = 0.01 + 0.09 * average_occupancy # Tuned weights\n    priorities[feasible_bins] -= empty_bin_penalty * empty_bin_penalty_weight\n\n    # Substantial bonus for almost full bins after insertion, highly sensitive\n    wasted_space_after = bins_remain_cap[feasible_bins] - item\n    almost_full = wasted_space_after / bins_remain_cap.max() < 0.03 # More sensitive threshold\n    almost_full_bonus = 0.2 + 0.3 * (1-wasted_space_after[almost_full]/ bins_remain_cap.max()) # Magnitude scales with wasted space\n    priorities[feasible_bins][almost_full] += almost_full_bonus\n\n\n    # Encourage balanced bin usage: penalize bins far from the mean remaining capacity.\n    mean_remaining = np.mean(bins_remain_cap[feasible_bins])\n    capacity_deviation_penalty = 0.01 * np.abs(bins_remain_cap[feasible_bins] - mean_remaining) / bins_remain_cap.max()\n    priorities[feasible_bins] -= capacity_deviation_penalty\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  }
]