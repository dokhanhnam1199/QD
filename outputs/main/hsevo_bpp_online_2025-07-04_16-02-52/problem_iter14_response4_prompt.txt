{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, fill ratio, adaptive randomization, and bin diversity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities - np.inf  # All bins are infeasible\n\n    # Waste minimization (best-fit) with non-linear penalty\n    wasted_space = bins_remain_cap - item\n    wasted_space[~feasible_bins] = np.inf\n    priorities[feasible_bins] -= (wasted_space[feasible_bins] / bins_remain_cap.max())**2\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = item / bins_remain_cap[feasible_bins]\n    item_scale = item / bins_remain_cap.max()\n    priorities[feasible_bins] += fill_ratio_after * 0.2 * item_scale\n\n    # Controlled randomization, inversely proportional to bin fill\n    randomization_strength = 0.05 * (1 - bins_remain_cap[feasible_bins] / bins_remain_cap.max())\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength\n\n    # Adaptive bin-emptiness penalty, more for larger items\n    empty_penalty = (bins_remain_cap[feasible_bins] / bins_remain_cap.max()) * item_scale\n    priorities[feasible_bins] -= empty_penalty * 0.02\n\n    # Bonus for bins nearing full capacity (almost perfect fit)\n    almost_perfect_fit = np.exp(-wasted_space[feasible_bins] * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.05\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, adaptive fill ratio, adaptive randomization, and dynamic emptiness penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap < item] = -np.inf\n\n    wasted_space = bins_remain_cap - item\n    feasible_bins = bins_remain_cap >= item\n\n    # Best-fit with non-linear waste penalty\n    priorities[feasible_bins] = -wasted_space[feasible_bins]**2 / bins_remain_cap.max()\n\n    # Adaptive fill ratio bonus, scaled by item size\n    fill_ratio_after = (1 - wasted_space / bins_remain_cap.max())\n    item_scale = item / bins_remain_cap.max()\n    fill_bonus_weight = 0.3 * item_scale\n    priorities[feasible_bins] += fill_ratio_after[feasible_bins] * fill_bonus_weight\n\n    # Adaptive Randomization, less when fuller\n    randomization_strength = 0.1 * item * (bins_remain_cap.max() - bins_remain_cap) / bins_remain_cap.max()\n    priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * randomization_strength[feasible_bins]\n\n    # Adaptive bin-emptiness penalty, scaling with item and average occupancy\n    average_occupancy = 1 - np.mean(bins_remain_cap / bins_remain_cap.max())\n    empty_bin_penalty = (bins_remain_cap / bins_remain_cap.max()) * (1 - item / bins_remain_cap.max())\n    empty_bin_penalty_weight = 0.02 + 0.08 * average_occupancy\n    priorities[feasible_bins] -= empty_bin_penalty[feasible_bins] * empty_bin_penalty_weight\n\n    # Bonus for bins that fit the item almost perfectly\n    almost_perfect_fit = np.exp(-np.abs(wasted_space[feasible_bins]) * 5 / item)\n    priorities[feasible_bins] += almost_perfect_fit * 0.1\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see that both heuristics are identical.\nComparing (3rd) vs (4th), (5th) vs (6th), (9th) vs (10th), (11th) vs (12th), (13th) vs (14th), (15th) vs (16th), (17th) vs (18th), (19th) vs (20th), we also see that both heuristics are identical.\n\nComparing (1st) vs (3rd), we observe several key differences. Heuristic 3 introduces the concept of adaptive scaling and bonus/penalty mechanisms based on item size and bin capacity. These adaptive approaches, specifically the adaptive fill ratio bonus, randomization factor, and bin-emptiness penalty, are not present in Heuristic 1. Additionally, Heuristic 3 includes a bonus for bins nearing full capacity and penalizes bins that are nearly full to encourage diversity.\n\nComparing (3rd) vs (4th), Heuristic 4 introduces a non-linear penalty for wasted space, scaling it by the maximum bin capacity, whereas Heuristic 3 uses a linear penalty and normalizes by the max bin capacity. Also, Heuristic 4 scales randomization by the item and bin capacity, whereas Heuristic 3 scales only by item size.\n\nComparing (4th) vs (5th), Heuristic 5 introduces `bin_diversity_bonus` based on the standard deviation of the remaining bin capacities to prioritize bins with more diverse fill levels. Also, the fill ratio weight and the empty/full bin penalties are made adaptive in H5, depending on item size. H4 only uses item scale to adapt the fill bonus weight and uses fixed weights for penalty.\n\nComparing (5th) vs (7th), Heuristic 7 simplifies the randomization strength and uses inverse relationship to the item size. It also introduces a nearly full bonus with fixed threshold.\n\nComparing (7th) vs (8th), Heuristic 8 adds diversity score based on how close the wasted space is to the item size. It also incorporates a dynamic empty bin penalty adjusting to the current bin landscape.\n\nComparing (8th) vs (10th), Heuristic 10 removes diversity score and dynamic empty bin penalty. It simplifies adaptive randomization and near full penalty, using less parameters.\n\nOverall: The better heuristics introduce adaptive scaling of bonuses/penalties, considering item size and bin capacity. They promote bin diversity and prevent early commitment to bins that are almost full, while adaptive randomization scales based on bin fullness to diversify selection.\n- \nOkay, let's refine \"Current Self-Reflection\" for better heuristic design, avoiding the pitfalls of \"Ineffective Self-Reflection.\" Here's a breakdown:\n\n*   **Keywords:** Adaptive parameters, balanced approach, multiple factors (waste, fill ratio, exploration), dynamic adjustment, overall landscape.\n\n*   **Advice:** Design heuristics that dynamically adapt based on item/bin states, balancing waste minimization with exploration. Prioritize heuristics that consider the interplay between parameters and their impact on solution quality.\n\n*   **Avoid:** Overly simplistic heuristics focused solely on remaining capacity, complex analogies, relying solely on random factors without a clear strategy.\n\n*   **Explanation:** Move beyond simple rules. Focus on creating a system that reacts intelligently to the current packing state, leveraging diverse factors in a coordinated manner for robust performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}