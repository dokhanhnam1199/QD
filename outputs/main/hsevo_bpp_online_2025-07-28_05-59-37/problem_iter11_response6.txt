```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines variance-weighted Z-score synergy with decaying entropy-aware penalty fields. 
    Features hybrid BF/WF behavior through adaptive item classification, predictive fragility control, 
    and dynamic multi-metric balance preservation.
    """
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    if item <= 1e-9:
        return np.where(
            bins_remain_cap >= 0,
            1e-4 * bins_remain_cap - 1e-7 * bins_remain_cap**2,
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    if not np.any(eligible):
        return np.full_like(bins_remain_cap, -np.inf)
    
    # State-aware metric basis
    leftover = bins_remain_cap - item
    tightness = item / (bins_remain_cap + 1e-9)
    C_est = bins_remain_cap.max() if bins_remain_cap.max() > 0 else item * 5
    
    # Z-score framework with variance sensitivity
    def z_metric(metric):
        subset = metric[eligible]
        return (metric - subset.mean()) / (subset.std() + 1e-9)
    
    tight_z = z_metric(tightness)
    fit_z = z_metric(1.0 / (leftover + 1e-9))
    var_ratio = (fit_z.var() + 1e-9) / (fit_z.var() + tight_z.var() + 2e-9)
    base_priority = var_ratio * fit_z + (1 - var_ratio) * tight_z
    
    # Granular item classification macros
    sys_avg = bins_remain_cap.mean()
    sys_std = bins_remain_cap.std()
    is_large = item > 0.75 * C_est  # Hard threshold for guaranteed-waste scenarios
    is_typical = item < 1.25 * sys_avg  # Empirically derived normality threshold
    
    # Nonlinear climb modulation
    grad_factor = 1.25 if is_large else 0.85
    utilization = 1 - bins_remain_cap / C_est
    climb_envelope = grad_factor * np.exp(0.3 * (tightness + utilization))
    
    # Fragmentation hazard containment
    frag_penalty_powers = 0.2 * np.exp(-leftover / (0.3 * C_est + 1e-9))
    bin_normalization = bins_remain_cap / (C_est + 1e-9)
    frag_penalty_modes = (1 + 0.25 * bin_normalization) * abs(leftover - 0.5 * sys_avg)
    
    # Landscape stability maintenance
    median_cap = np.median(bins_remain_cap[eligible])
    median_proximity = np.abs(bins_remain_cap - median_cap) / (C_est + 1e-9)
    volatility_term = 0.1 * sys_std * np.abs(tight_z) * median_proximity
    
    # Final priority composition
    priority = base_priority * climb_envelope
    priority -= frag_penalty_powers
    priority -= frag_penalty_modes
    priority += volatility_term
    priority *= np.exp(-0.05 * left_over / C_est if (left_over := bins_remain_cap - item).max() > 0 else 1.0)
    
    # Frailty resilience micro-perturbation
    priority += 1e-7 * np.random.randn(*bins_remain_cap.shape)
    
    return np.where(eligible, priority, -np.inf)
```
