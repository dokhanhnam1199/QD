```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines z-score-normalized fit/cap metrics with exponential utilization enhancer 
    and entropy-aware tie-breaking via leftover volatility damping.
    """
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            1.0 / (bins_remain_cap - item + 1e-9),
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    if not eligible.any():
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    leftover = bins_remain_cap - item
    utilization = (orig_cap - bins_remain_cap) / orig_cap
    tightness = item / (bins_remain_cap + 1e-9)
    
    # Z-score normalization of fit and capacity
    fit_quality = 1.0 / (leftover + 1e-9)
    elig_fit = fit_quality[eligible]
    elig_cap = bins_remain_cap[eligible]
    
    mean_fit, std_fit = np.mean(elig_fit), np.std(elig_fit)
    z_fit = (fit_quality - mean_fit) / (std_fit + 1e-9)
    
    mean_cap, std_cap = np.mean(elig_cap), np.std(elig_cap)
    z_cap = (bins_remain_cap - mean_cap) / (std_cap + 1e-9)
    
    # Dynamic hybrid weighting and exponential enhancement
    primary_score = tightness * z_fit + (1.0 - tightness) * z_cap
    enhancer = np.exp(utilization * tightness)
    
    # Entropy-aware tie-breaking: small term to penalize fragmentation volatility
    tie_breaker = 0.05 * np.exp(-leftover)  # Weak exponential damping of leftover space
    
    # Final layered prioritization with perturbed thresholds
    return np.where(
        eligible, 
        (primary_score * enhancer) + tie_breaker, 
        -np.inf
    )
```
