{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive normalization with variance impact modeling. Uses item-size-aware dynamic weights and reinforcement-inspired usability boosting. Balances tight packing, variance reduction, and system stability through hybrid scoring.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # System metrics\n    system_avg = np.mean(bins_remain_cap)\n    system_std = np.std(bins_remain_cap)\n    system_cv = system_std / (system_avg + 1e-9)\n    n = bins_remain_cap.size\n    \n    # Item classification\n    large_item_threshold = system_avg * (0.75 * (1 + 0.3 * system_cv))\n    large_item = item > large_item_threshold\n    \n    # Metrics for eligible bins\n    bin_remain = bins_remain_cap[eligible]\n    tightness = item / (bin_remain + 1e-9)\n    leftover = bin_remain - item\n    proximity = np.abs(leftover - system_avg)\n    usability = (system_avg - leftover) / (system_std + 1e-9)\n    \n    # Variance impact calculation\n    sum_remain = bins_remain_cap.sum()\n    sum_remain_sq = (bins_remain_cap ** 2).sum()\n    sum_remain_new = sum_remain - item\n    sum_remain_sq_new = sum_remain_sq - bins_remain_cap**2 + (bins_remain_cap - item)**2\n    var_new = (sum_remain_sq_new / n) - (sum_remain_new / n)**2\n    \n    # Normalization of metrics\n    var_score = np.zeros_like(var_new)\n    eligible_var = var_new[eligible]\n    var_min, var_max = eligible_var.min(), eligible_var.max()\n    if var_max > var_min:\n        var_score[eligible] = (var_max - var_new[eligible]) / (var_max - var_min + 1e-9)\n    else:\n        var_score[eligible] = 0.5\n    \n    tight_norm = np.zeros_like(tightness)\n    tight_min, tight_max = tightness.min(), tightness.max()\n    if tight_max > tight_min:\n        tight_norm = (tightness - tight_min) / (tight_max - tight_min + 1e-9)\n    else:\n        tight_norm.fill(0.5)\n    \n    proximity_norm = np.zeros_like(proximity)\n    prox_min, prox_max = proximity.min(), proximity.max()\n    if prox_max > prox_min:\n        proximity_norm = 1.0 - (proximity - prox_min) / (prox_max - prox_min + 1e-9)\n    else:\n        proximity_norm.fill(0.5)\n    \n    # Reinforcement-inspired usability factor\n    fragility_factor = np.clip(usability, 0, None)\n    reinforcer = 1.0 + 0.3 * fragility_factor\n    \n    # Dynamic weight allocation\n    if large_item:\n        w_tight, w_var, w_prox = 0.5, 0.4, 0.1\n    else:\n        w_tight, w_var, w_prox = 0.3, 0.3, 0.4\n    \n    # Final priority calculation\n    priority_components = (\n        w_tight * tight_norm +\n        w_var * var_score[eligible] +\n        w_prox * proximity_norm\n    ) * reinforcer\n    \n    result = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    result[eligible] = priority_components\n    \n    return result\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}