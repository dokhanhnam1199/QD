```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            bins_remain_cap - item + 1e-9,
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    if not np.any(eligible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    # System metrics
    system_avg = bins_remain_cap.mean()
    system_std = bins_remain_cap.std()
    system_cv = system_std / (system_avg + 1e-9)
    
    # Entropy calculation with discretization
    rounded_caps = np.round(bins_remain_cap, 3)
    _, counts = np.unique(rounded_caps, return_counts=True)
    probs = counts / counts.sum()
    system_entropy = -np.sum(probs * np.log(probs + 1e-9))
    max_entropy = np.log(len(bins_remain_cap)) if len(bins_remain_cap) > 1 else 1.0
    entropy_factor = system_entropy / (max_entropy + 1e-9)
    
    # Eligible bin metrics
    bin_remain = bins_remain_cap[eligible]
    fit_tightness = item / (bin_remain + 1e-9)
    util_after = (orig_cap - bin_remain + item) / (orig_cap + 1e-9)
    leftover = bin_remain - item
    
    # Adaptive normalization
    ft_min, ft_max = fit_tightness.min(), fit_tightness.max()
    fit_norm = 0.5 if ft_max <= ft_min else (fit_tightness - ft_min) / (ft_max - ft_min)
    
    ua_min, ua_max = util_after.min(), util_after.max()
    util_norm = 0.5 if ua_max <= ua_min else (util_after - ua_min) / (ua_max - ua_min)
    
    # Hybrid score with entropy-driven weights
    weight_fit = np.clip(1.0 - entropy_factor, 0.1, 0.9)
    weight_util = 1.0 - weight_fit
    hybrid = (weight_fit * fit_norm) + (weight_util * util_norm)
    
    # Nonlinear boost
    boosted = hybrid ** 2
    
    # Entropy-driven proximity term
    proximity = np.abs(leftover - system_avg) / (system_std + 1e-9)
    proximity_penalty = np.exp(-proximity)
    
    # Shape factor using z-score
    ls_z = (leftover - system_avg) / (system_std + 1e-9)
    shape_factor = np.exp(-np.abs(ls_z))
    
    # Reinforcement-inspired terms
    fragility = util_after  # High fragility = nearly full bin
    usability = np.clip((system_avg - leftover) / (system_std + 1e-9), -1.0, 1.0)
    closeness_weight = np.clip(1.0 - entropy_factor, 0.2, 1.0)
    
    reinforcer = 1.0 + (fragility * np.abs(usability) * closeness_weight)
    
    # Final priority calculation
    priority = boosted * proximity_penalty * shape_factor * reinforcer
    
    # Build result array
    result = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    result[eligible] = priority
    
    return result
```
