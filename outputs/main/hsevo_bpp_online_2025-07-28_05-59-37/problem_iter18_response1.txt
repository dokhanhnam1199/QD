```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            bins_remain_cap - item + 1e-9,
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    if not np.any(eligible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    n = bins_remain_cap.shape[0]
    delta = item
    
    # Predictive variance modeling
    S = bins_remain_cap.sum()
    Q = (bins_remain_cap ** 2).sum()
    mean_new = (S - delta) / n
    sum_sq_new = Q - 2 * delta * bins_remain_cap + delta ** 2
    var_new = (sum_sq_new / n) - (mean_new ** 2)
    
    # Variance score normalization (lower variance is better)
    eligible_var = var_new[eligible]
    var_min, var_max = eligible_var.min(), eligible_var.max()
    if var_max > var_min:
        norm_var = (var_max - var_new) / (var_max - var_min + 1e-9)
    else:
        norm_var = np.zeros_like(var_new)
    
    # Leftover space normalization
    leftover = bins_remain_cap - delta
    eligible_left = leftover[eligible]
    left_min, left_max = eligible_left.min(), eligible_left.max()
    if left_max > left_min:
        norm_left = (leftover - left_min) / (left_max - left_min + 1e-9)
    else:
        norm_left = np.zeros_like(leftover)
    
    # Tightness normalization
    tightness = delta / (bins_remain_cap + 1e-9)
    eligible_tight = tightness[eligible]
    tight_min, tight_max = eligible_tight.min(), eligible_tight.max()
    if tight_max > tight_min:
        norm_tight = (tightness - tight_min) / (tight_max - tight_min + 1e-9)
    else:
        norm_tight = np.zeros_like(tightness)
    
    # Item classification
    system_avg = bins_remain_cap.mean()
    large_item = delta > system_avg
    
    # Static-dynamic weighting
    tight_weight = 0.7 if large_item else 0.3
    var_weight = 0.2 if large_item else 0.5
    left_weight = 0.1 if large_item else 0.2
    
    # Priority components
    priority = (
        norm_tight * tight_weight +
        norm_var * var_weight +
        norm_left * left_weight
    )
    
    # Reinforcement adjustment for future flexibility
    used_cap = orig_cap - bins_remain_cap
    utilization = used_cap / (orig_cap + 1e-9)
    if not large_item:
        priority += 0.1 * utilization  # Prefer filling partially used bins
    
    return np.where(eligible, priority, -np.inf)
```
