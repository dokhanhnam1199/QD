```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    v2: Adaptive Z-synergy + entropy-aware balancing + gradient-boosted reinforcement gains.
    Core ideas: Normalized metric blending, fragmentation-aware penalties, and 
    system-state adaptive scoring for optimal bin selection.
    """
    eps = 1e-9
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = bins_remain_cap.max()
    eligible = bins_remain_cap >= item + eps  # Strict eligibility check
    if not eligible.any():
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)

    # System statistics
    system_avg = bins_remain_cap.mean()
    system_std = bins_remain_cap.std() + eps
    system_cv = system_std / (system_avg + eps)
    
    # Core eligibility metrics
    remaining = bins_remain_cap[eligible] + eps
    leftover = remaining - item
    tightness = item / remaining  # Tightness of fit
    
    # Normalized metric synergy
    phi = (1.0 / leftover) * tightness  # Fit quality driver
    phi_z = ((phi - phi.mean()) / phi.std())[eligible]  # Z-normalized synergy
    cap_z = ((remaining - system_avg) / system_std)[eligible]  # Capacity deviation score

    # Dynamic metric weighting
    cross_weight = 1.0 / (1.0 + np.emath.logn(2, phi.std() + cap_z.std() + 1))
    composite = (1 - cross_weight) * phi_z + cross_weight * cap_z  # Adaptive blending
    
    # Reinforcement-inspired gradient boost
    margin_weight = (system_avg - leftover) / system_avg  # Exploitation margin
    entropy_offset = 0.5 * (tightness + tightness.std())  # Entropy-sensitive boosting
    enhancer = np.exp((composite * margin_weight) + entropy_offset)  # Multiplier amplification
    
    # Entropy-preserving balance term
    filled_frac = (orig_cap - remaining) / orig_cap  # Current fill level
    system_var = filled_frac.var() / (filled_frac.std() + eps)  # Entropy coefficient
    balance_factor = filled_frac * (1 + system_var)  # System state alignment weight
    balance_z = (balance_factor - balance_factor.mean()) / balance_factor.std()  # Z-normalized cost
    
    # Smart fragmentation control
    capacity_ratio = remaining / orig_cap
    frag_indicator = leftover < (0.15 * orig_cap)  # Aggressive leftover check
    fragility_penalty = np.where(
        frag_indicator,
        -tightness * 0.05 * system_var,
        -tightness * 0.01 * system_var
    )
    
    # Final score composition
    scores = np.full_like(bins_remain_cap, -np.inf)
    scores[eligible] = (
        (composite * enhancer) * (1 + system_var)  # Primary driver with variance scaling
        + (0.1 * balance_z * system_std)  # Adaptive entropy balancing
        + (0.05 * fragility_penalty)  # Fragmentation-aware penalty
    )

    return scores
```
