```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Z-optimized fit combining exp-utilized tightness with system-wide entropy scaling (higher priority to bins that reduce overall fragmentation).
    Hybridizes v0 adaptive normalization and v1 entropy-aware balance.
    """
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        # Edge-case: negligible item, prefer minimal leftover while slightly favoring large-capacity bins
        return np.where(
            bins_remain_cap >= item,
            1.0 / (bins_remain_cap - item + 1e-9) - 1e-9 * bins_remain_cap,
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    if not np.any(eligible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    # Core v0 metrics: z-score fit/capacity + exponential enhancer
    leftover = bins_remain_cap - item
    utilization = (orig_cap - bins_remain_cap) / orig_cap
    tightness = item / (bins_remain_cap + 1e-9)
    
    fit_quality = 1.0 / (leftover + 1e-9)
    elig_fit = fit_quality[eligible]
    elig_cap = bins_remain_cap[eligible]
    
    # Z-score normalization with perturbed thresholds
    mean_fit, std_fit = np.mean(elig_fit), np.std(elig_fit)
    z_fit = (fit_quality - mean_fit) / (std_fit + 1e-9)
    
    mean_cap, std_cap = np.mean(elig_cap), np.std(elig_cap)
    z_cap = (bins_remain_cap - mean_cap) / (std_cap + 1e-9)
    
    primary_score = tightness * z_fit + (1.0 - tightness) * z_cap
    enhancer = np.exp(utilization * tightness)  # Gradient-aware exponential boosting
    
    # v1-inspired entropy control with adaptive weight scaling
    system_avg = np.mean(bins_remain_cap)
    system_std = np.std(bins_remain_cap)
    system_cv = system_std / (system_avg + 1e-9)
    
    # Item classification for epsilon scaling
    threshold = np.mean(bins_remain_cap)
    large_item = item > threshold
    
    # System-aware fragmentation penalty
    balance_term = -np.abs(leftover - system_avg)  # Favours bins that reduce global variance
    balance_weight = 0.1 * system_cv * (2 if not large_item else 1)  # Reinforces entropy control
    
    # Multi-layer synergy with cross-metric variance analysis
    priority = primary_score * enhancer + balance_weight * balance_term
    
    return np.where(eligible, priority, -np.inf)
```
