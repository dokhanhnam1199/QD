```python
import numpy as np
from numpy.typing import ArrayLike

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritizes bins through multi-factorial hybridization, integrating:
    - Sigmoid transition between best/worst-fit strategies (contextual size adaptation)
    - Utilization elevation with tunable penalty for under-filled bins
    - Space erosion analysis via wavelength-weighted critical zone detection 
    - Sparsity-aware exploration-exploitation compensation
    Returns prioritized scores identifying optimal bin placement considering systemic objectives.
    """
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            1.0 / (bins_remain_cap - item + 1e-9),
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    n_elig = np.sum(eligible)
    
    if n_elig == 0:
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    rem_cap = bins_remain_cap[eligible]
    leftover = rem_cap - item
    
    # Adaptive blending coefficient using logistic sigmoid
    item_norm = item / orig_cap
    fit_preference = 1.0 / (1 + np.exp(-5.0 * (item_norm - 0.3)))
    
    # Best-fit z-score (normalized inverse leftover)
    inv_leftover = 1.0 / (leftover + 1e-9)
    inv_mean, inv_std = np.mean(inv_leftover), np.std(inv_leftover)
    best_score = ((inv_leftover - inv_mean) / (inv_std + 1e-9)) if inv_std > 0 else np.zeros_like(inv_leftover)
    
    # Worst-fit z-score (normalized rem_cap)
    worst_mean, worst_std = np.mean(rem_cap), np.std(rem_cap)
    worst_score = ((rem_cap - worst_mean) / (worst_std + 1e-9)) if worst_std > 0 else np.zeros_like(rem_cap)
    
    # Blending best/worst scores
    fit_merit = fit_preference * best_score + (1 - fit_preference) * worst_score
    
    # Utilization: calculate enhancement with sigmoidal compression
    bin_util = (orig_cap - rem_cap) / orig_cap
    util_threshold = np.maximum(0.25, 0.9 * item_norm)
    adjusted_util = np.clip((bin_util - util_threshold) * (1 + 3 * item_norm), -3, 5)
    util_gain = 1.0 / (1 + np.exp(-adjusted_util + 0.8))
    
    # Erosion penalty for critical leftover zones
    leftover_ratio = leftover / orig_cap + 1e-9
    erosion_flag = (leftover_ratio >= 0.1) & (leftover_ratio <= 0.5)
    erosion_penalty = erosion_flag * np.sin(np.pi * ((leftover_ratio - 0.1)/0.4 + 1e-9))
    
    # Sparsity adjustment
    if n_elig > 1:
        bin_edges = np.linspace(rem_cap.min(), rem_cap.max(), int(np.sqrt(n_elig)) + 2)
        digitized = np.digitize(rem_cap, bin_edges)
        hist, _ = np.histogram(rem_cap, bin_edges)
        inv_freq = 1.0 / (hist[digitized - 1] + 1e-9)
        sparsity_adjust = ((inv_freq - inv_freq.mean()) / (inv_freq.std() + 1e-9))
        fit_merit += 0.4 * sparsity_adjust
    
    # Final composite score
    prioritization = (fit_merit + util_gain) * (1 + 2 * np.sqrt(util_gain)) - 1.2 * erosion_penalty
    
    # Output population
    output = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    output[eligible] = prioritization.astype(np.float64)
    
    return output
```
