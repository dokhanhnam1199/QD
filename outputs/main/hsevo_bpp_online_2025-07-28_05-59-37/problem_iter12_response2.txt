```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Hyper-adaptive fragmentation-averse heuristic with predictive entropy control and dynamic sensitivity gradients.
    Integrates reinforcement-inspired system gain, meta-learned weight gradients, and multi-horizon balancing.
    """
    n = bins_remain_cap.size
    if n == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            bins_remain_cap * (1 + 0.1 * (bins_remain_cap > (orig_cap * 0.7))),
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    if not np.any(eligible):
        return np.full(n, -np.inf, dtype=np.float64)

    # Core adaptive metrics
    leftover = bins_remain_cap - item
    utilization = (orig_cap - bins_remain_cap) / orig_cap
    tightness = np.clip(item / (bins_remain_cap + 1e-9), 0, 1e6)
    
    # Predictive entropy modeling (MPU: Minimum Predictive Uncertainty)
    sum_c, sum_sq_c = np.sum(bins_remain_cap), np.sum(bins_remain_cap**2)
    delta_sq = -2 * item * bins_remain_cap + item**2  # Change in squared capacities
    new_sum_sq = sum_sq_c + delta_sq
    new_mean_sq = (sum_c - item) / n
    predicted_var = (new_sum_sq / n) - new_mean_sq**2
    system_var, system_std = sum_sq_c / n - (sum_c / n)**2, np.std(bins_remain_cap)
    variance_hysteresis = predicted_var - system_var  # Lower better: indicates stability

    # Reinforcement-inspired sensitivity fields
    fit_weight = np.exp(-tightness * (1 + utilization))  # Tight-fit exploration
    var_penalty_weight = 1 + 2 * np.abs(variance_hysteresis) / (system_var + 1e-9)
    
    # Z-score synergy with hyperbolic sensitivity enhancement
    mu_fit = np.mean(1.0 / (leftover[eligible] + 1e-9))
    grad_fit = 1/(leftover + 1e-9) - mu_fit  # Local-Global deviation
    fit_z = grad_fit / (np.std(1.0 / (leftover + 1e-9)) + 1e-9)
    
    mu_cap = np.mean(bins_remain_cap[eligible])
    cap_z = (bins_remain_cap - mu_cap) / (np.std(bins_remain_cap) + 1e-9)
    
    # Dynamic gain optimization via system entropy Jaccard
    system_cv = system_std / (sum_c/n + 1e-9)
    alpha_gain = 1 + 1.5 * tightness * system_cv  # Tight bins amplify sensitivity
    decay_rate = tightness * 0.3
    
    # Meta-heuristic energy balancing
    energy_gradient = np.gradient(bins_remain_cap + 1e-9)
    energy_profile = -grad_fit * np.abs(energy_gradient)
    ep_weight = 1 - tightness * (1 - system_cv)
    
    # Perturbative exploration strategy
    explore_noise = 1e-6 * np.abs(np.sin(0.1 * left_margin)) * np.random.normal(0, 1, n)
    
    # Hierarchical priority synthesis
    priority = alpha_gain * (fit_z * fit_weight + cap_z * decay_rate) - var_penalty_weight * variance_hysteresis
    priority += explore_noise + energy_profile * ep_weight
    
    return np.where(eligible, priority, -np.inf)
```
