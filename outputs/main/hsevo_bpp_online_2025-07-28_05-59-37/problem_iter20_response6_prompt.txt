{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines min-max normalization, variance-aware balance, and predictive reinforcement.\n    Prioritizes bins based on adaptive metric weights, system variance reduction, and \n    future capacity clustering.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = bins_remain_cap.max()\n    eps = 1e-9\n    \n    # Handle edge cases with zero-sized item or bins\n    if orig_cap <= eps or item <= eps:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + eps,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    eligible_rem = bins_remain_cap[eligible]\n    leftover = eligible_rem - item\n    tightness = item / (eligible_rem + eps)\n    utilization = (orig_cap - eligible_rem) / (orig_cap + eps)\n    \n    # Min-Max normalization for metrics (higher value = better)\n    max_left = leftover.max()\n    min_left = leftover.min()\n    if max_left > min_left + eps:\n        norm_left = (max_left - leftover) / (max_left - min_left + eps)\n    else:\n        norm_left = np.zeros_like(leftover)\n    \n    max_tight = tightness.max()\n    min_tight = tightness.min()\n    if max_tight > min_tight + eps:\n        norm_tight = (tightness - min_tight) / (max_tight - min_tight + eps)\n    else:\n        norm_tight = np.zeros_like(tightness)\n    \n    max_util = utilization.max()\n    min_util = utilization.min()\n    if max_util > min_util + eps:\n        norm_util = (utilization - min_util) / (max_util - min_util + eps)\n    else:\n        norm_util = np.zeros_like(utilization)\n    \n    # Item classification\n    active_caps = bins_remain_cap[bins_remain_cap > 0]\n    median_cap = np.median(active_caps) if active_caps.size else orig_cap\n    rel_size = item / (median_cap + eps)\n    small_item = rel_size < 0.75\n    \n    # Dynamic weights\n    tight_weight = 1.0 if small_item else 1.8\n    util_weight = 1.5 if small_item else 0.5\n    \n    # Primary score\n    primary = tight_weight * norm_tight + util_weight * norm_util\n    \n    # Balance contribution (variance reduction)\n    system_avg = bins_remain_cap.mean()\n    system_std = bins_remain_cap.std()\n    system_cv = system_std / (system_avg + eps) if system_avg > eps else 0.0\n    \n    if leftover.size > 1:\n        median_leftover = np.median(leftover)\n        balance_term = -np.abs(leftover - median_leftover) / (leftover.std() + eps)\n        balance_contrib = balance_term * 0.3 * system_cv\n    else:\n        balance_contrib = np.zeros_like(leftover)\n    \n    # Reinforcement: capacity clustering\n    if active_caps.size > 1:\n        active_median = np.median(active_caps)\n        active_iqr = np.percentile(active_caps, 75) - np.percentile(active_caps, 25)\n        similarity = 1.0 / (np.abs(leftover - active_median) / (active_iqr + eps) + 1.0)\n    else:\n        similarity = np.ones_like(leftover)\n    \n    reinforcer = 0.5 + 0.5 * similarity  # Scale between 0.5-1.0\n    \n    # Final priority\n    priority = (primary + balance_contrib) * reinforcer\n    \n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    scores[eligible] = priority\n    return scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # 1. Fit score: Min-max normalized tightness (higher = tighter fit)\n    leftover = np.where(eligible, bins_remain_cap - item, np.inf)\n    min_left, max_left = np.min(leftover), np.max(leftover)\n    fit_score = (max_left - leftover) / (max_left - min_left + 1e-9)\n    \n    # 2. Predictive variance score: Variance after placement (lower is better)\n    S, S2, n = bins_remain_cap.sum(), (bins_remain_cap**2).sum(), len(bins_remain_cap)\n    c_i = bins_remain_cap\n    variance_i = (S2 - 2*c_i*item + item**2)/n - ((S - item)**2)/(n**2)\n    variance_i = np.where(eligible, variance_i, np.inf)\n    \n    min_var, max_var = np.min(variance_i), np.max(variance_i)\n    var_score = (max_var - variance_i) / (max_var - min_var + 1e-9)\n    \n    # 3. Reinforcement score: Remaining capacity flexibility\n    rem_after = bins_remain_cap - item\n    rem_ratio = rem_after / (orig_cap + 1e-9)\n    min_rem, max_rem = np.min(rem_ratio[eligible]), np.max(rem_ratio[eligible])\n    reinforce_score = (rem_ratio - min_rem) / (max_rem - min_rem + 1e-9)\n    \n    # 4. Hybrid priority calculation (entropy-agnostic balance)\n    tightness_weight = 0.6  # Static weight for immediate fit\n    future_weight = 0.4      # Static weight for future flexibility\n    \n    tightness_component = fit_score * var_score\n    future_component = reinforce_score * (1.0 + var_score)  # Amplify by variance quality\n    \n    priority = tightness_weight * tightness_component + future_weight * future_component\n    \n    return np.where(eligible, priority, -np.inf)\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see adaptive Z-score normalization and dynamic item classification in 1st enhance fit tightness and future flexibility, while 20th's static weights limit adaptability. (2nd) vs (19th) shows entropy-agnostic reinforcement and proximity penalties in 2nd improve balance, whereas 19th's rigid hybrid priority lacks system-wide variance reduction. (3rd) vs (18th) highlights predictive reinforcement and capacity clustering in 3rd outperform 18th's simplistic variance modeling. (5th) vs (16th) demonstrates fragmentation penalties and synergy scores in 5th reduce entropy better than 16th's basic hybrid approach. Overall, top heuristics integrate adaptive normalization, item-size-aware weights, predictive variance control, and entropy-driven balance, while lower ones rely on static metrics and incomplete system modeling.\n- \n\u2022 **Keywords**: adaptive normalization, dynamic weights, entropy-aware metrics, reinforcement learning  \n\u2022 **Advice**: Prioritize Z-score/min-max normalization without variance-ratio synergy, dynamic weights adjusted by real-time state/utilization gradients, entropy-aware balance via layered tie-breakers (e.g., fragility, load), and reinforcement-inspired gains avoiding predictive penalties.  \n\u2022 **Avoid**: Exponential boosting, perturbation-based tie-breaking, entropy penalties modulated by global metrics, Z-score synergy with variance ratios.  \n\u2022 **Explanation**: Enhances robustness by focusing on validated dynamic adaptation (not unstable perturbations/exponential boosts) and multi-objective synergy, ensuring heuristic stability and scalability without overfitting to transient system states.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}