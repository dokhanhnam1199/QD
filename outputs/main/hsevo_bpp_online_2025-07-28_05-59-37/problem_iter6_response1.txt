```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Advanced contextual priority combining hierarchical non-linear dynamics and adaptive entropic sensitivity.
    Operates with asymptotic efficiency patterns and self-adaptive entropy minimization.
    """
    if bins_remain_cap.size == 0:
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            1.0 / (bins_remain_cap - item + 1e-9),
            -np.inf
        )
    
    eligible = (bins_remain_cap >= item)
    if not np.any(eligible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    # Base metrics
    remain = bins_remain_cap[eligible]
    leftover = remain - item
    tightness = item / (remain + 1e-9)
    utilization = 1.0 - (remain / orig_cap)
    
    # Hierarchical metric components
    fit_quality = 1.0 / (leftover + 1e-9)                          # Best-fit tightness amplifier
    entropic_score = -tightness * np.log(tightness + 1e-9)         # Information entropy minimization
    momentum_factor = np.exp(3.0 * utilization) * (1.0 - tightness) # Utilization-driven reinforcement learning proxy
    
    # Adaptive normalization context
    context_variability = bins_remain_cap.std() / (orig_cap + 1e-9) + 0.1  # Dynamic normalization coefficient
    
    # Non-linear scoring with context-switching logic
    tightness_rescale = np.clip(tightness, 0.25, 0.75)
    swing_factor = (np.log(orig_cap / (leftover + 1e-9)) *  
                   np.abs(np.log1p(orig_cap - remain)) + 1e-9)
    
    # Custom sensitivity analysis
    sensitivity_mask = np.where(
        utilization > np.quantile(utilization, 0.5),
        1.0 + 0.5 * (utilization - np.min(utilization)),
        1.0 + 0.2 * (np.max(tightness) - tightness)
    )
    
    # Final score assembly
    priority = (
        fit_quality ** (tightness_rescale * sensitivity_mask) +
        entropic_score * 0.3 +
        momentum_factor * tightness +
        np.where(leftover < 1e-3, float('inf'), 
                 np.log(swing_factor) * context_variability)
    )
    
    # Contextually-aware tiebreakers
    tiebreaker = ((tightness * 0.4 + utilization * 0.6) * 
                 (1.0 - context_variability * np.log(1 + leftover)))
    
    final_scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    final_scores[eligible] = (priority + tiebreaker) * (1 + context_variability)
    
    return final_scores
```
