```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Enhanced Z-synergy with entropy-control and dynamic reinforcement.
    Combines adaptive fit/space blending (v1), Z-normalized balance terms (v0), 
    and entropy-driven variance penalties with reinforcement multipliers."""
    
    if len(bins_remain_cap) == 0:
        return np.array([], dtype=np.float64)
    
    valid_mask = bins_remain_cap >= item
    if not np.any(valid_mask):
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)

    # System characterization
    system_avg = bins_remain_cap.mean()
    system_std = bins_remain_cap.std()
    system_cv = system_std / (system_avg + 1e-9) if system_avg > 1e-9 else 0.0
    orig_cap = bins_remain_cap.max()  # Fixed-bin assumption
    
    # Item classification
    large_item = item > system_avg
    leftover = bins_remain_cap - item
    
    # Adaptive blending components (v1)
    eligible_rem = bins_remain_cap[valid_mask]
    tightness = item / (eligible_rem + 1e-9)
    rel_size = item / (np.median(eligible_rem) + 1e-9)
    blending = 1.0 / (1.0 + np.exp(-5 * (rel_size - 0.5)))
    
    # Z-score metrics (v0 + v1 synergy)
    fit_metric = 1.0 / (leftover + 1e-9)
    space_metric = bins_remain_cap.astype(np.float64)
    
    def z_score(x, where_mask):
        mean = x[where_mask].mean()
        std = x[where_mask].std() + 1e-9
        return (x - mean) / std

    fit_z = z_score(fit_metric, valid_mask)
    space_z = z_score(space_metric, valid_mask)
    tight_z = z_score(-leftover, valid_mask)  # Natural tightness metric
    
    # Utilization boost (dynamic adaptation)
    boost_factor = 2.5 if rel_size < 0.7 else 1.5
    util_boost = np.exp(boost_factor * tightness * valid_mask)
    
    # Balance dynamics (v0 base + entropy sensitivity)
    balance_comp = -np.abs(leftover - system_avg) / (system_std + 1e-9)
    balance_weight = 1.8 * np.sqrt(system_cv) * (1.3 if not large_item else 1.0)
    
    # Reinforcement multipliers (v1)
    bin_util = (orig_cap - bins_remain_cap) / orig_cap
    fragility = np.abs(orig_cap - bins_remain_cap) / (orig_cap + 1e-9)
    reinforcer = 1 + np.clip((1 - rel_size)**2 * (1 - bin_util) * fragility, 0, 3)
    
    # Entropy tiebreaker with variance control (v1)
    bin_count = bins_remain_cap.size
    sum_total = bins_remain_cap.sum()
    sum_sq = (bins_remain_cap**2).sum()
    new_sum_sq = sum_sq - 2*item*bins_remain_cap + item**2
    mu_new = (sum_total - item) / bin_count
    var_new = (new_sum_sq / bin_count) - mu_new**2
    var_term = -0.3 * var_new / (np.sqrt(np.abs(var_new) + 1e-9) + 1e-5)
    
    # Priority construction with hybrid gains
    blended_score = blending * fit_z + (1 - blending) * space_z
    synergy = blended_score * (1 + 0.5 * tight_z + 0.3 * util_boost[valid_mask])
    
    priority = np.where(
        valid_mask,
        (synergy + balance_weight * balance_comp) * reinforcer + var_term,
        -np.inf
    )
    
    return priority
```
