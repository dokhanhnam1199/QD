```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            (1.0 / (bins_remain_cap - item + 1e-9)) - 1e-9 * bins_remain_cap,
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    if not np.any(eligible):
        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)
    
    leftover = bins_remain_cap - item
    utilization = (orig_cap - bins_remain_cap) / (orig_cap + 1e-9)
    tightness = item / (bins_remain_cap + 1e-9)
    
    # Base metrics
    fit_quality = 1.0 / (leftover + 1e-9)
    elig_fit = fit_quality[eligible]
    elig_cap = bins_remain_cap[eligible]
    
    # Z-score normalization
    mean_fit, std_fit = np.mean(elig_fit), np.std(elig_fit)
    z_fit = (fit_quality - mean_fit) / (std_fit + 1e-9)
    
    mean_cap, std_cap = np.mean(elig_cap), np.std(elig_cap)
    z_cap = (bins_remain_cap - mean_cap) / (std_cap + 1e-9)
    
    # Reinforcement-inspired gain w/meta-metric modulation
    system_avg = np.mean(bins_remain_cap)
    system_std = np.std(bins_remain_cap)
    system_skew = np.mean((bins_remain_cap - system_avg)**3) / (system_std**3 + 1e-9)
    system_cv = system_std / (system_avg + 1e-9)
    
    large_item = item > np.quantile(bins_remain_cap, 0.75)
    
    # Modulated enhancer with entropy-sensitive gradient
    gradient_energy = (1.0 - system_cv) * utilization + system_cv * tightness
    rein_enhancer = np.exp(tightness * utilization * gradient_energy + (1.0 - tightness) * (1.0 - utilization) * (1.0 - system_cv))
    
    # Multi-spectral entropy balance metrics
    distance_from_mean = leftover - system_avg
    quadratic_balance = -(distance_from_mean**2) / (1 + 0.5*system_skew)  # Forward-skew adjustment
    
    cap_fluctuations = np.std(bins_remain_cap + 1e-9)
    fluctuation_term = -np.abs(np.log1p(leftover/(cap_fluctuations + 1e-9)))
    
    # Adaptive decision layer weights
    balance_weight = 0.2 * system_cv * (1 + system_skew*(0.5 if item > system_avg else 2.0)) * np.log(2 + system_avg)
    fluctuation_weight = 0.05 * (1.0 - system_cv**2) * (1.0 + np.sqrt(tightness))
    
    # Spectral sensitivity tie-breaker with perturbations
    sensitivity_kernel = np.where(
        bins_remain_cap > system_avg,
        1.0 / (1e-9 + np.abs(bins_remain_cap - 2*system_avg - item)),
        1.0 / (1e-9 + np.abs(bins_remain_cap - 0.5*system_avg))
    )
    perturbation = 0.001 * sensitivity_kernel * (1.0 + np.random.normal(0, 1, bins_remain_cap.shape) * system_cv)
    
    # Core spectral synergy
    priority_base = tightness * z_fit + (1.0 - tightness) * z_cap
    dynamic_sensitivity = sensitivity_kernel * (1.0 - 0.5 * system_skew * tightness)
    
    # Full integration
    priority = (
        priority_base * rein_enhancer 
        + balance_weight * quadratic_balance 
        + fluctuation_weight * fluctuation_term
        + 0.005 * dynamic_sensitivity
        + perturbation
    )
    
    return np.where(eligible, priority, -np.inf)
```
