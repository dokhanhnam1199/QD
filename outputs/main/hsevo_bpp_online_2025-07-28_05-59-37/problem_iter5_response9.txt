```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Sigmoid blending of Best and Worst Fit with adaptive utilization tie-breaker and leftover variance scaling.
    
    Primary priority combines BFT tightness (negative leftover) and WFT spreading 
    (bin_remaining) through a smooth function of item size relative to system average. 
    Adaptive epsilon scaling preserves utilization dynamics for robust tie-breaking.
    """
    mask = bins_remain_cap >= item
    priority = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)

    if not bins_remain_cap.size or not np.any(mask):
        return priority

    # Core fit metrics
    leftover = bins_remain_cap - item
    bft = -leftover  # Best Fit Term (negative leftover)
    wft = bins_remain_cap  # Worst Fit candidate bins

    # Dynamic blending factor via item-to-average ratio
    avg_remaining = np.mean(bins_remain_cap)
    # Normalize difference to system-scale (prevent saturation at extreme values)
    sigmoid_input = (item - avg_remaining) / (avg_remaining + 1e-8)  
    # Higher sigmoid_weight = preferred WFT for smaller items
    sigmoid_weight = 1.0 / (1.0 + np.exp(sigmoid_input))  

    # Blend BF/WF preferences: WFT dominates for smaller items
    combined = (1 - sigmoid_weight) * bft + sigmoid_weight * wft

    # Utilization tie-breaker (item / bin_remaining where feasible)
    utilization = np.zeros_like(combined)
    np.divide(item, bins_remain_cap, where=mask, out=utilization)

    # Adaptive epsilon scaling from leftover variance
    valid_leftover = leftover[mask]
    std_leftover = np.std(valid_leftover) if valid_leftover.size > 1 else 1e-6
    epsilon = 1e-4 / (std_leftover + 1e-8)

    # Final priority with utility augmentation
    priority[mask] = combined[mask] + epsilon * utilization[mask]
    return priority
```
