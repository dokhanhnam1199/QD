```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    State-aware, entropy-sensitive priority with gradient-enhanced scoring and multi-modal tiebreakers.
    Combines dynamic Z-scores, entropy-regulated fill dynamics, and perturbed balance hierarchies.
    """
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)

    orig_max = np.max(bins_remain_cap)
    if orig_max < 1e-9 or item < 1e-9:
        return np.where(bins_remain_cap >= item, 
                       1.0 / (bins_remain_cap - item + 1e-4) - 1e-6 * bins_remain_cap,
                       -np.inf)

    eligible = bins_remain_cap >= item
    if not np.any(eligible):
        return np.full_like(bins_remain_cap, -np.inf)

    # System context tracking for adaptive normalization
    sys_mean, sys_std = np.mean(bins_remain_cap), np.std(bins_remain_cap)
    elig_caps = bins_remain_cap[eligible]
    elig_centers = bins_remain_cap - (orig_max * 0.5)

    # Core allocation metrics
    residual = bins_remain_cap - item
    tightness = item / (bins_remain_cap + 1e-6)
    fit_power = 1.0 / (residual + 1e-6)
    
    # Normalized scoring layers
    z_score = (fit_power - np.mean(fit_power)) / (np.std(fit_power) + 1e-6)  # Dynamic Z-score
    
    # Entropy-sensitive decay weight
    fill_entropy = np.abs(residual - sys_mean + item / 2) * np.sqrt(sys_std + 1e-6)
    entropy_weight = 0.05 * (sys_std / (sys_mean + 1e-6)**0.75)

    # Gradient-enhanced utilization tracking
    utilization = 1.0 - (bins_remain_cap / orig_max)
    utilization_curve = np.log(orig_max - utilization * orig_max + 1.0)  # Smooth nonlinearity
    
    # Cross-metric variance adaptive weighting
    def calc_variance_factor(metric):
        return np.std(metric) / (np.abs(np.mean(metric)) + 1e-6)

    z_weight = calc_variance_factor(z_score) * 0.6
    tightness_weight = calc_variance_factor(1-tightness) * 0.4
    
    # Hierarchical scoring with exponential decay
    base_score = z_score * z_weight * utilization_curve
    efficiency_term = tightness * tightness_weight * (orig_max - bins_remain_cap)
    
    # Tiered entropy penalty with state conditioning
    tiered_entropy = np.where(
        residual > sys_std * 1.5,  # High-margin bins
        fill_entropy * 0.1,
        np.where(
            residual < -sys_std * 0.5,  # Already overflowed bins
            fill_entropy * 1.5,
            fill_entropy * 0.5
        )
    )

    # Final composition with fragility tiebreaker
    final_score = np.where(
        eligible,
        base_score + efficiency_term - tiered_entropy * entropy_weight,
        -np.inf
    )
    
    return final_score
```
