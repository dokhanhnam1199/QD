{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Z-optimized fit combining exp-utilized tightness with system-wide entropy scaling (higher priority to bins that reduce overall fragmentation).\n    Hybridizes v0 adaptive normalization and v1 entropy-aware balance.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        # Edge-case: negligible item, prefer minimal leftover while slightly favoring large-capacity bins\n        return np.where(\n            bins_remain_cap >= item,\n            1.0 / (bins_remain_cap - item + 1e-9) - 1e-9 * bins_remain_cap,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # Core v0 metrics: z-score fit/capacity + exponential enhancer\n    leftover = bins_remain_cap - item\n    utilization = (orig_cap - bins_remain_cap) / orig_cap\n    tightness = item / (bins_remain_cap + 1e-9)\n    \n    fit_quality = 1.0 / (leftover + 1e-9)\n    elig_fit = fit_quality[eligible]\n    elig_cap = bins_remain_cap[eligible]\n    \n    # Z-score normalization with perturbed thresholds\n    mean_fit, std_fit = np.mean(elig_fit), np.std(elig_fit)\n    z_fit = (fit_quality - mean_fit) / (std_fit + 1e-9)\n    \n    mean_cap, std_cap = np.mean(elig_cap), np.std(elig_cap)\n    z_cap = (bins_remain_cap - mean_cap) / (std_cap + 1e-9)\n    \n    primary_score = tightness * z_fit + (1.0 - tightness) * z_cap\n    enhancer = np.exp(utilization * tightness)  # Gradient-aware exponential boosting\n    \n    # v1-inspired entropy control with adaptive weight scaling\n    system_avg = np.mean(bins_remain_cap)\n    system_std = np.std(bins_remain_cap)\n    system_cv = system_std / (system_avg + 1e-9)\n    \n    # Item classification for epsilon scaling\n    threshold = np.mean(bins_remain_cap)\n    large_item = item > threshold\n    \n    # System-aware fragmentation penalty\n    balance_term = -np.abs(leftover - system_avg)  # Favours bins that reduce global variance\n    balance_weight = 0.1 * system_cv * (2 if not large_item else 1)  # Reinforces entropy control\n    \n    # Multi-layer synergy with cross-metric variance analysis\n    priority = primary_score * enhancer + balance_weight * balance_term\n    \n    return np.where(eligible, priority, -np.inf)\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}