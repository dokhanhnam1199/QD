{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combined adaptive Z-synergy with entropy-weighted fragmentation and balance control.\n    Uses metric normalization, system variance-adaptive weights, and item-classification dynamics.\n    \"\"\"\n    eps = 1e-9\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    eligible = bins_remain_cap >= item\n    if not eligible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # Metrics and system descriptors\n    leftover = bins_remain_cap - item\n    origin_cap = np.max(bins_remain_cap)\n    tightness = item / (bins_remain_cap + eps)\n    utilization = (origin_cap - bins_remain_cap) / (origin_cap + eps)\n    fit_quality = 1.0 / (leftover + eps)\n    \n    system_avg = bins_remain_cap.mean()\n    system_std = bins_remain_cap.std()\n    system_cv = system_std / (system_avg + eps)\n    large_item = item > (system_avg + eps)\n    \n    # Z-score normalization across eligible bins\n    eligible_metrics = {\n        'fit': fit_quality[eligible],\n        'tight': tightness[eligible],\n        'cap': bins_remain_cap[eligible]\n    }\n    mean = {k: np.mean(v) for k, v in eligible_metrics.items()}\n    std = {k: np.std(v) for k, v in eligible_metrics.items()}\n    \n    # Z-score computation for key metrics\n    z_fit = (fit_quality - mean['fit']) / (std['fit'] + eps)\n    z_tight = (tightness - mean['tight']) / (std['tight'] + eps)\n    z_cap = (bins_remain_cap - mean['cap']) / (std['cap'] + eps)\n    \n    # Primary synergy term with exponential enhancer\n    enhancer = np.exp(utilization * tightness)\n    primary_score = (z_fit + z_tight + 0.5 * z_cap) * enhancer\n    \n    # Entropy-weighted penalties for fragmentation and balance\n    frag_penalty = 1.0 - np.exp(-leftover / (origin_cap + eps))\n    frag_weight = 0.3 * system_cv\n    \n    balance_term = -np.abs(leftover - system_avg)\n    balance_weight = 0.2 * system_cv * (2.0 if not large_item else 1.0)\n    \n    # Hybrid scoring based on multi-metric analysis\n    priority = primary_score - frag_weight * frag_penalty + balance_weight * balance_term\n    \n    return np.where(eligible, priority, -np.inf)\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}