```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    if bins_remain_cap.size == 0:
        return np.array([], dtype=np.float64)
    
    orig_cap = np.max(bins_remain_cap)
    if orig_cap <= 1e-9 or item <= 1e-9:
        return np.where(
            bins_remain_cap >= item,
            1.0 / (bins_remain_cap - item + 1e-9),
            -np.inf
        )
    
    eligible = bins_remain_cap >= item
    leftover = bins_remain_cap - item
    tightness = item / (bins_remain_cap + 1e-9)
    utilization = (orig_cap - bins_remain_cap) / orig_cap
    
    # Contextual blending of fit and capacity metrics
    rel_item = item / orig_cap
    urgency_weight = 1.0 / (1.0 + np.exp(-10 * (rel_item - 0.4)))  # Sigmoid blend control
    
    # Advanced normalization subsets
    elig_slices = [eligible, np.invert(eligible)]
    norm_funcs = lambda x: np.clip((x - np.nanmean(x[eligible])) / (np.nanstd(x[eligible]) + 1e-9), -5, 5)
    
    # Fit/tightness metrics with hierarchical protection
    fit_quality = 1.0 / (leftover + 1e-9)
    fit_norm = np.where(eligible, norm_funcs(fit_quality), -np.inf)
    
    # Sensitivity-weighted bin equilibrium
    cap_sensitivity = bins_remain_cap / orig_cap
    cap_norm = np.where(eligible, norm_funcs(cap_sensitivity), -np.inf)
    
    # Multi-stage reinforcement objective
    tight_weight = tightness * urgency_weight
    fit_weight = urgency_weight * norm_funcs(utilization)
    
    # Hybrid metric synthesis with threshold avoidance
    base_score = tight_weight * fit_norm + (1 - tight_weight) * cap_norm
    util_derivative = np.power(utilization + 1e-3, 1.5)
    
    # Recurrent feedback mechanism for context propagation
    dynamic_factor = (
        util_derivative * 
        np.exp(-0.5 * (1 - tightness) * (1 - rel_item)) * 
        (0.5 + tightness * urgency_weight)
    )
    
    return np.where(eligible, base_score * dynamic_factor + fit_weight, -np.inf)
```
