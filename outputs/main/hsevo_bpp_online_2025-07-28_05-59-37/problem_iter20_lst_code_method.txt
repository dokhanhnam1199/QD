{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines adaptive Z-score normalization, entropy-driven balance, and reinforcement learning concepts.\n    Prioritizes bins that optimize fit tightness, system-wide capacity balance, and future flexibility.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # System-wide metrics\n    system_avg = bins_remain_cap.mean()\n    system_std = bins_remain_cap.std()\n    system_cv = system_std / (system_avg + 1e-9) if system_avg > 1e-9 else 0.0\n    \n    # Item classification\n    large_item = item > system_avg\n    \n    # Core metrics\n    leftover = bins_remain_cap - item\n    tightness = item / (bins_remain_cap + 1e-9)\n    utilization = (orig_cap - bins_remain_cap) / (orig_cap + 1e-9)\n    \n    # Z-score normalization for fit and space\n    elig_fit = 1.0 / (leftover + 1e-9)\n    elig_fit_mean, elig_fit_std = np.mean(elig_fit[eligible]), np.std(elig_fit[eligible])\n    z_fit = (elig_fit - elig_fit_mean) / (elig_fit_std + 1e-9)\n    \n    elig_space = bins_remain_cap\n    elig_space_mean, elig_space_std = np.mean(elig_space[eligible]), np.std(elig_space[eligible])\n    z_cap = (elig_space - elig_space_mean) / (elig_space_std + 1e-9)\n    \n    # Primary score: adaptive tightness-weighted Z-combination\n    primary_score = tightness * z_fit + (1.0 - tightness) * z_cap\n    \n    # Exponential enhancer for utilization-tightness synergy\n    enhancer = np.exp(utilization * tightness)\n    \n    # Entropy-driven balance term\n    balance_term = -np.abs(leftover - system_avg) / (system_std + 1e-9)\n    balance_weight = 0.5 * system_cv * np.where(large_item, 1.0, 2.0)\n    balance_contrib = balance_term * balance_weight\n    \n    # Reinforcement multiplier\n    eligible_rem = bins_remain_cap[eligible]\n    rel_size = item / (np.median(eligible_rem) + 1e-9)\n    fragility = ((orig_cap - bins_remain_cap) / (orig_cap + 1e-9)).clip(0, 1)\n    rem_rel = bins_remain_cap / (orig_cap + 1e-9)\n    reinforce_factor = (1 - rel_size) ** 2 * rem_rel * fragility\n    reinforcer = 1 + 0.5 * reinforce_factor\n    \n    # Final priority calculation\n    priority = (primary_score * enhancer + balance_contrib) * reinforcer\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Predictive variance-aware packing using min-max synergy and entropy-agnostic reinforcement.\n    Combines normalized fit-tightness/utilization with proximity-based penalties and fragility-aware reinforcer.\n    \"\"\"\n    eps = 1e-9\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    eligible = bins_remain_cap >= item\n    if not eligible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    orig_cap = bins_remain_cap.max()\n    remaining_cap = bins_remain_cap[eligible]\n    leftover = remaining_cap - item + eps\n    \n    # Metric calculation\n    fit_tightness = item / (remaining_cap + eps)\n    util_after = (orig_cap - remaining_cap + item) / (orig_cap + eps)\n    \n    # System metrics\n    system_avg = bins_remain_cap.mean()\n    system_std = bins_remain_cap.std() + eps\n    \n    # Min-max normalization\n    def minmax_normalize(x):\n        xmin, xmax = x.min(), x.max()\n        if xmax > xmin:\n            return (x - xmin) / (xmax - xmin)\n        return np.full_like(x, 0.5)\n    \n    norm_fit = minmax_normalize(fit_tightness)\n    norm_util = minmax_normalize(util_after)\n    \n    # Hybrid score with static weights\n    hybrid = 0.6 * norm_fit + 0.4 * norm_util\n    boosted = hybrid ** 2  # Nonlinear amplification\n    \n    # Proximity-based penalty (distance from average leftover)\n    proximity = np.abs(leftover - system_avg) / system_std\n    proximity_penalty = np.exp(-proximity)\n    \n    # Reinforcement term: fragility * usability\n    fragility = util_after\n    usability = np.clip((system_avg - leftover) / system_std, -1.0, 1.0)\n    reinforcer = fragility * np.abs(usability)\n    \n    # Tie-breaker (epsilon-greedy preference for larger leftover)\n    tie_breaker = 0.01 * (leftover / (orig_cap + eps))\n    \n    # Final score assembly\n    eligible_scores = (\n        boosted * proximity_penalty \n        + reinforcer \n        + tie_breaker\n    )\n    \n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    scores[eligible] = eligible_scores\n    \n    return scores\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines min-max normalization, variance-aware balance, and predictive reinforcement.\n    Prioritizes bins based on adaptive metric weights, system variance reduction, and \n    future capacity clustering.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = bins_remain_cap.max()\n    eps = 1e-9\n    \n    # Handle edge cases with zero-sized item or bins\n    if orig_cap <= eps or item <= eps:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + eps,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    eligible_rem = bins_remain_cap[eligible]\n    leftover = eligible_rem - item\n    tightness = item / (eligible_rem + eps)\n    utilization = (orig_cap - eligible_rem) / (orig_cap + eps)\n    \n    # Min-Max normalization for metrics (higher value = better)\n    max_left = leftover.max()\n    min_left = leftover.min()\n    if max_left > min_left + eps:\n        norm_left = (max_left - leftover) / (max_left - min_left + eps)\n    else:\n        norm_left = np.zeros_like(leftover)\n    \n    max_tight = tightness.max()\n    min_tight = tightness.min()\n    if max_tight > min_tight + eps:\n        norm_tight = (tightness - min_tight) / (max_tight - min_tight + eps)\n    else:\n        norm_tight = np.zeros_like(tightness)\n    \n    max_util = utilization.max()\n    min_util = utilization.min()\n    if max_util > min_util + eps:\n        norm_util = (utilization - min_util) / (max_util - min_util + eps)\n    else:\n        norm_util = np.zeros_like(utilization)\n    \n    # Item classification\n    active_caps = bins_remain_cap[bins_remain_cap > 0]\n    median_cap = np.median(active_caps) if active_caps.size else orig_cap\n    rel_size = item / (median_cap + eps)\n    small_item = rel_size < 0.75\n    \n    # Dynamic weights\n    tight_weight = 1.0 if small_item else 1.8\n    util_weight = 1.5 if small_item else 0.5\n    \n    # Primary score\n    primary = tight_weight * norm_tight + util_weight * norm_util\n    \n    # Balance contribution (variance reduction)\n    system_avg = bins_remain_cap.mean()\n    system_std = bins_remain_cap.std()\n    system_cv = system_std / (system_avg + eps) if system_avg > eps else 0.0\n    \n    if leftover.size > 1:\n        median_leftover = np.median(leftover)\n        balance_term = -np.abs(leftover - median_leftover) / (leftover.std() + eps)\n        balance_contrib = balance_term * 0.3 * system_cv\n    else:\n        balance_contrib = np.zeros_like(leftover)\n    \n    # Reinforcement: capacity clustering\n    if active_caps.size > 1:\n        active_median = np.median(active_caps)\n        active_iqr = np.percentile(active_caps, 75) - np.percentile(active_caps, 25)\n        similarity = 1.0 / (np.abs(leftover - active_median) / (active_iqr + eps) + 1.0)\n    else:\n        similarity = np.ones_like(leftover)\n    \n    reinforcer = 0.5 + 0.5 * similarity  # Scale between 0.5-1.0\n    \n    # Final priority\n    priority = (primary + balance_contrib) * reinforcer\n    \n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    scores[eligible] = priority\n    return scores\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines min-max normalization, variance-aware balance, and predictive reinforcement.\n    Prioritizes bins based on adaptive metric weights, system variance reduction, and \n    future capacity clustering.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = bins_remain_cap.max()\n    eps = 1e-9\n    \n    # Handle edge cases with zero-sized item or bins\n    if orig_cap <= eps or item <= eps:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + eps,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    eligible_rem = bins_remain_cap[eligible]\n    leftover = eligible_rem - item\n    tightness = item / (eligible_rem + eps)\n    utilization = (orig_cap - eligible_rem) / (orig_cap + eps)\n    \n    # Min-Max normalization for metrics (higher value = better)\n    max_left = leftover.max()\n    min_left = leftover.min()\n    if max_left > min_left + eps:\n        norm_left = (max_left - leftover) / (max_left - min_left + eps)\n    else:\n        norm_left = np.zeros_like(leftover)\n    \n    max_tight = tightness.max()\n    min_tight = tightness.min()\n    if max_tight > min_tight + eps:\n        norm_tight = (tightness - min_tight) / (max_tight - min_tight + eps)\n    else:\n        norm_tight = np.zeros_like(tightness)\n    \n    max_util = utilization.max()\n    min_util = utilization.min()\n    if max_util > min_util + eps:\n        norm_util = (utilization - min_util) / (max_util - min_util + eps)\n    else:\n        norm_util = np.zeros_like(utilization)\n    \n    # Item classification\n    active_caps = bins_remain_cap[bins_remain_cap > 0]\n    median_cap = np.median(active_caps) if active_caps.size else orig_cap\n    rel_size = item / (median_cap + eps)\n    small_item = rel_size < 0.75\n    \n    # Dynamic weights\n    tight_weight = 1.0 if small_item else 1.8\n    util_weight = 1.5 if small_item else 0.5\n    \n    # Primary score\n    primary = tight_weight * norm_tight + util_weight * norm_util\n    \n    # Balance contribution (variance reduction)\n    system_avg = bins_remain_cap.mean()\n    system_std = bins_remain_cap.std()\n    system_cv = system_std / (system_avg + eps) if system_avg > eps else 0.0\n    \n    if leftover.size > 1:\n        median_leftover = np.median(leftover)\n        balance_term = -np.abs(leftover - median_leftover) / (leftover.std() + eps)\n        balance_contrib = balance_term * 0.3 * system_cv\n    else:\n        balance_contrib = np.zeros_like(leftover)\n    \n    # Reinforcement: capacity clustering\n    if active_caps.size > 1:\n        active_median = np.median(active_caps)\n        active_iqr = np.percentile(active_caps, 75) - np.percentile(active_caps, 25)\n        similarity = 1.0 / (np.abs(leftover - active_median) / (active_iqr + eps) + 1.0)\n    else:\n        similarity = np.ones_like(leftover)\n    \n    reinforcer = 0.5 + 0.5 * similarity  # Scale between 0.5-1.0\n    \n    # Final priority\n    priority = (primary + balance_contrib) * reinforcer\n    \n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    scores[eligible] = priority\n    return scores\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines min-max synergy metrics with predictive variance modeling.\n    Uses adaptive fragmentation control and entropy-agnostic balance.\n    \"\"\"\n    eps = 1e-9\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    # Handle negligible items\n    if item < eps:\n        return np.where(\n            bins_remain_cap >= 0,\n            0.3 / (bins_remain_cap + 1e-4) - 0.1 * bins_remain_cap,\n            -np.inf\n        )\n    \n    origin_cap = np.max(bins_remain_cap)\n    eligible = bins_remain_cap >= item - 1e-9\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf)\n    \n    # Core metrics calculation\n    leftover = bins_remain_cap - item\n    tightness = item / (bins_remain_cap + eps)\n    utilization = (origin_cap - bins_remain_cap) / (origin_cap + eps)\n    \n    # Min-Max normalization function\n    def minmax_normalize_full(metric_full, eligible_mask):\n        metric = metric_full.copy()\n        eligible_metric = metric[eligible_mask]\n        if eligible_metric.size == 0:\n            return np.full_like(metric, -np.inf)\n        same_values = np.allclose(eligible_metric, eligible_metric[0])\n        if same_values:\n            normalized = np.full_like(metric, 0.5)\n            normalized[~eligible_mask] = -np.inf\n            return normalized\n        min_val = eligible_metric.min()\n        max_val = eligible_metric.max()\n        range_val = max_val - min_val\n        eligible_normalized = (eligible_metric - min_val) / (range_val + eps)\n        eligible_normalized = np.clip(eligible_normalized, 0, 1)\n        normalized = np.full_like(metric, -np.inf)\n        normalized[eligible_mask] = eligible_normalized\n        return normalized\n    \n    # Normalize metrics\n    norm_tight = minmax_normalize_full(tightness, eligible)\n    norm_util = minmax_normalize_full(utilization, eligible)\n    \n    # Primary synergy score\n    synergy = norm_tight * (1.0 + norm_util)\n    \n    # Fragmentation penalty (entropy-agnostic)\n    frag_penalty = 1.0 - np.exp(-leftover / (origin_cap + eps))\n    frag_component = 0.2 * frag_penalty\n    \n    # Predictive variance modeling\n    N = bins_remain_cap.size\n    sum_cap = np.sum(bins_remain_cap)\n    sum_sq = np.sum(bins_remain_cap ** 2)\n    mean_old = sum_cap / N\n    var_old = (sum_sq / N) - (mean_old ** 2)\n    \n    elig_remain = bins_remain_cap[eligible]\n    delta_sq_i = (elig_remain - item) ** 2 - elig_remain ** 2\n    new_sum_sq_i = sum_sq + delta_sq_i\n    new_mean_i = (sum_cap - item) / N\n    var_new_i = (new_sum_sq_i / N) - (new_mean_i ** 2)\n    var_delta_i = var_old - var_new_i\n    \n    # Normalize variance delta\n    var_delta_full = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    var_delta_full[eligible] = var_delta_i\n    norm_var = minmax_normalize_full(var_delta_full, eligible)\n    \n    # Final components\n    var_component = norm_var\n    tie_breaker = 0.01 * (bins_remain_cap / (origin_cap + eps))\n    \n    # Final score assembly\n    scores = np.where(\n        eligible,\n        synergy - frag_component + 0.5 * var_component + tie_breaker,\n        -np.inf\n    )\n    \n    return scores\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(\n    item: float, \n    bins_remain_cap: np.ndarray,\n    eps= 7.855829525105748e-09,\n    fit_weight= 0.1620433222762539,\n    tight_weight= 0.686002280298385,\n    predictive_balance_weight= 0.8458182062767244,\n    frag_weight= 0.15228391708779007) -> np.ndarray:\n    \"\"\"\n    Predictive variance-aware binning with min-max synergy and reinforcement-inspired balance.\n    Combines normalized fit metrics with variance delta prediction and static fragmentation weights.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    el_remain = bins_remain_cap[eligible]\n    el_leftover = el_remain - item\n    \n    median_L = np.median(el_leftover)\n    range_L = el_leftover.max() - el_leftover.min()\n    if range_L > 0:\n        var_pen = np.abs(el_leftover - median_L) / range_L\n    else:\n        var_pen = np.zeros_like(el_leftover, dtype=np.float64)\n    \n    median_remain = np.median(el_remain)\n    weight_t = item / (median_remain + 1e-9)\n    weight_v = 1.0 - weight_t\n    \n    tightness = item / (el_remain + 1e-9)\n    base_priority = weight_t * tightness - weight_v * var_pen\n    \n    tie_breaker = -1e-9 * el_leftover\n    final_priority = base_priority + tie_breaker\n    \n    priority = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    priority[eligible] = final_priority\n    \n    return priority\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    el_remain = bins_remain_cap[eligible]\n    el_leftover = el_remain - item\n    \n    median_L = np.median(el_leftover)\n    range_L = el_leftover.max() - el_leftover.min()\n    if range_L > 0:\n        var_pen = np.abs(el_leftover - median_L) / range_L\n    else:\n        var_pen = np.zeros_like(el_leftover, dtype=np.float64)\n    \n    median_remain = np.median(el_remain)\n    weight_t = item / (median_remain + 1e-9)\n    weight_v = 1.0 - weight_t\n    \n    tightness = item / (el_remain + 1e-9)\n    base_priority = weight_t * tightness - weight_v * var_pen\n    \n    tie_breaker = -1e-9 * el_leftover\n    final_priority = base_priority + tie_breaker\n    \n    priority = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    priority[eligible] = final_priority\n    \n    return priority\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid priority combining min-max synergy, predictive variance analysis,\n    and stability-aware reinforcement for online BPP. Uses item classification\n    and fragmentation-anticipation penalties.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    if item <= 1e-9:\n        return np.where(bins_remain_cap >= 0, 0.01 * bins_remain_cap, -np.inf)\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf)\n    \n    C_est = bins_remain_cap.max() if bins_remain_cap.max() > 0 else item * 2\n    \n    # Metric calculations\n    leftover = bins_remain_cap - item\n    tightness = item / (bins_remain_cap + 1e-9)\n    fit_score = 1.0 / (leftover + 1e-9)\n    \n    # Min-Max normalization\n    tight_min, tight_max = tightness[eligible].min(), tightness[eligible].max()\n    fit_min, fit_max = fit_score[eligible].min(), fit_score[eligible].max()\n    norm_tight = (tightness - tight_min) / (tight_max - tight_min + 1e-9)\n    norm_fit = (fit_score - fit_min) / (fit_max - fit_min + 1e-9)\n    \n    # Item classification and adaptive weights\n    is_large = item > 0.7 * C_est\n    fit_weight = 0.8 if is_large else 0.5\n    tight_weight = 0.2 if is_large else 0.5\n    base_score = fit_weight * norm_fit + tight_weight * norm_tight\n    \n    # Predictive variance modeling\n    n = len(bins_remain_cap)\n    current_sum = bins_remain_cap.sum()\n    current_sum_sq = (bins_remain_cap ** 2).sum()\n    current_var = (current_sum_sq / n) - (current_sum / n) ** 2\n    \n    new_cap_elig = bins_remain_cap[eligible] - item\n    delta_sq_elig = new_cap_elig**2 - bins_remain_cap[eligible]**2\n    new_sum_sq_elig = current_sum_sq + delta_sq_elig\n    new_mean_elig = (current_sum - item) / n\n    new_var_elig = (new_sum_sq_elig / n) - new_mean_elig**2\n    delta_var_elig = new_var_elig - current_var\n    \n    variance_term = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    variance_term[eligible] = -delta_var_elig / (np.abs(current_var) + 1e-9)\n    \n    # Fragmentation anticipation\n    frag_term = np.zeros_like(bins_remain_cap)\n    frag_term[eligible] = np.exp(-leftover[eligible] / (C_est / 3 + 1e-9))\n    \n    # Stability preservation\n    median_cap = np.median(bins_remain_cap[eligible]) if eligible.any() else C_est\n    proximity = np.abs(bins_remain_cap - median_cap) / (C_est + 1e-9)\n    \n    # Priority assembly\n    priority = (\n        base_score\n        + 0.2 * variance_term\n        - 0.1 * frag_term\n        - 0.05 * proximity\n    )\n    \n    # Reinforcement decay\n    priority *= np.exp(-0.05 * leftover / (C_est + 1e-9))\n    \n    # Deterministic tie-breaking\n    priority += 1e-7 * (1.0 / (tightness + 1e-9)) * (1.0 / (proximity + 1e-9))\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid priority combining min-max synergy, predictive variance analysis,\n    and stability-aware reinforcement for online BPP. Uses item classification\n    and fragmentation-anticipation penalties.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    if item <= 1e-9:\n        return np.where(bins_remain_cap >= 0, 0.01 * bins_remain_cap, -np.inf)\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf)\n    \n    C_est = bins_remain_cap.max() if bins_remain_cap.max() > 0 else item * 2\n    \n    # Metric calculations\n    leftover = bins_remain_cap - item\n    tightness = item / (bins_remain_cap + 1e-9)\n    fit_score = 1.0 / (leftover + 1e-9)\n    \n    # Min-Max normalization\n    tight_min, tight_max = tightness[eligible].min(), tightness[eligible].max()\n    fit_min, fit_max = fit_score[eligible].min(), fit_score[eligible].max()\n    norm_tight = (tightness - tight_min) / (tight_max - tight_min + 1e-9)\n    norm_fit = (fit_score - fit_min) / (fit_max - fit_min + 1e-9)\n    \n    # Item classification and adaptive weights\n    is_large = item > 0.7 * C_est\n    fit_weight = 0.8 if is_large else 0.5\n    tight_weight = 0.2 if is_large else 0.5\n    base_score = fit_weight * norm_fit + tight_weight * norm_tight\n    \n    # Predictive variance modeling\n    n = len(bins_remain_cap)\n    current_sum = bins_remain_cap.sum()\n    current_sum_sq = (bins_remain_cap ** 2).sum()\n    current_var = (current_sum_sq / n) - (current_sum / n) ** 2\n    \n    new_cap_elig = bins_remain_cap[eligible] - item\n    delta_sq_elig = new_cap_elig**2 - bins_remain_cap[eligible]**2\n    new_sum_sq_elig = current_sum_sq + delta_sq_elig\n    new_mean_elig = (current_sum - item) / n\n    new_var_elig = (new_sum_sq_elig / n) - new_mean_elig**2\n    delta_var_elig = new_var_elig - current_var\n    \n    variance_term = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    variance_term[eligible] = -delta_var_elig / (np.abs(current_var) + 1e-9)\n    \n    # Fragmentation anticipation\n    frag_term = np.zeros_like(bins_remain_cap)\n    frag_term[eligible] = np.exp(-leftover[eligible] / (C_est / 3 + 1e-9))\n    \n    # Stability preservation\n    median_cap = np.median(bins_remain_cap[eligible]) if eligible.any() else C_est\n    proximity = np.abs(bins_remain_cap - median_cap) / (C_est + 1e-9)\n    \n    # Priority assembly\n    priority = (\n        base_score\n        + 0.2 * variance_term\n        - 0.1 * frag_term\n        - 0.05 * proximity\n    )\n    \n    # Reinforcement decay\n    priority *= np.exp(-0.05 * leftover / (C_est + 1e-9))\n    \n    # Deterministic tie-breaking\n    priority += 1e-7 * (1.0 / (tightness + 1e-9)) * (1.0 / (proximity + 1e-9))\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 11th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # Core metrics\n    leftover = bins_remain_cap - item\n    tightness = item / (bins_remain_cap + 1e-9)\n    \n    # Predictive variance modeling\n    n = bins_remain_cap.size\n    sum_remain = bins_remain_cap.sum()\n    sum_remain_sq = (bins_remain_cap ** 2).sum()\n    \n    sum_remain_new = sum_remain - item\n    sum_remain_sq_new = sum_remain_sq - bins_remain_cap**2 + (bins_remain_cap - item)**2\n    \n    var_new = (sum_remain_sq_new / n) - (sum_remain_new / n)**2\n    \n    # Min-max normalization for variance score\n    var_score = np.zeros_like(var_new)\n    eligible_var = var_new[eligible]\n    var_min, var_max = eligible_var.min(), eligible_var.max()\n    if var_max > var_min:\n        var_score = (var_max - var_new) / (var_max - var_min + 1e-9)\n    \n    # Min-max normalization for tightness score\n    t_score = np.zeros_like(tightness)\n    eligible_tight = tightness[eligible]\n    t_min, t_max = eligible_tight.min(), eligible_tight.max()\n    if t_max > t_min:\n        t_score = (tightness - t_min) / (t_max - t_min + 1e-9)\n    \n    # Reinforcement similarity score\n    median_remain = np.median(bins_remain_cap)\n    diff = np.abs(leftover - median_remain)\n    sim_score = np.zeros_like(diff)\n    eligible_diff = diff[eligible]\n    d_min, d_max = eligible_diff.min(), eligible_diff.max()\n    if d_max > d_min:\n        sim_score = 1.0 - (diff - d_min) / (d_max - d_min + 1e-9)\n    \n    # Static-dynamic hybrid balance weights\n    tightness_weight = 0.5\n    variance_weight = 0.3\n    similarity_weight = 0.2\n    \n    # Final priority calculation\n    priority = (\n        tightness_weight * t_score + \n        variance_weight * var_score + \n        similarity_weight * sim_score\n    )\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # Core metrics\n    leftover = bins_remain_cap - item\n    tightness = item / (bins_remain_cap + 1e-9)\n    \n    # Predictive variance modeling\n    n = bins_remain_cap.size\n    sum_remain = bins_remain_cap.sum()\n    sum_remain_sq = (bins_remain_cap ** 2).sum()\n    \n    sum_remain_new = sum_remain - item\n    sum_remain_sq_new = sum_remain_sq - bins_remain_cap**2 + (bins_remain_cap - item)**2\n    \n    var_new = (sum_remain_sq_new / n) - (sum_remain_new / n)**2\n    \n    # Min-max normalization for variance score\n    var_score = np.zeros_like(var_new)\n    eligible_var = var_new[eligible]\n    var_min, var_max = eligible_var.min(), eligible_var.max()\n    if var_max > var_min:\n        var_score = (var_max - var_new) / (var_max - var_min + 1e-9)\n    \n    # Min-max normalization for tightness score\n    t_score = np.zeros_like(tightness)\n    eligible_tight = tightness[eligible]\n    t_min, t_max = eligible_tight.min(), eligible_tight.max()\n    if t_max > t_min:\n        t_score = (tightness - t_min) / (t_max - t_min + 1e-9)\n    \n    # Reinforcement similarity score\n    median_remain = np.median(bins_remain_cap)\n    diff = np.abs(leftover - median_remain)\n    sim_score = np.zeros_like(diff)\n    eligible_diff = diff[eligible]\n    d_min, d_max = eligible_diff.min(), eligible_diff.max()\n    if d_max > d_min:\n        sim_score = 1.0 - (diff - d_min) / (d_max - d_min + 1e-9)\n    \n    # Static-dynamic hybrid balance weights\n    tightness_weight = 0.5\n    variance_weight = 0.3\n    similarity_weight = 0.2\n    \n    # Final priority calculation\n    priority = (\n        tightness_weight * t_score + \n        variance_weight * var_score + \n        similarity_weight * sim_score\n    )\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines min-max normalization, variance-aware proximity, and dynamic weighting.\n    Uses predictive proximity to reduce fragmentation, reinforcement fragility control,\n    and item-size-adaptive metrics for balanced bin selection.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    # Edge case: negligible item\n    if item < 1e-9:\n        return np.where(bins_remain_cap >= 0, bins_remain_cap, -np.inf)\n    \n    eligible = bins_remain_cap >= (item - 1e-9)\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # System metrics\n    orig_cap = np.max(bins_remain_cap)\n    system_avg = np.mean(bins_remain_cap)\n    system_std = np.std(bins_remain_cap)\n    system_cv = system_std / (system_avg + 1e-9)\n    \n    # Item classification\n    large_item = item > system_avg * (0.75 * (1 + 0.3 * system_cv))\n    \n    # Eligible bin metrics\n    bin_remain = bins_remain_cap[eligible]\n    leftover = bin_remain - item\n    tightness = item / (bin_remain + 1e-9)\n    util_after = (orig_cap - bin_remain + item) / (orig_cap + 1e-9)\n    proximity = np.abs(leftover - system_avg)\n    \n    # Min-max normalization of metrics\n    def minmax_normalize(arr):\n        min_val = np.min(arr)\n        max_val = np.max(arr)\n        if max_val - min_val < 1e-9:\n            return np.zeros_like(arr) + 0.5\n        return (arr - min_val) / (max_val - min_val + 1e-9)\n    \n    tight_norm = minmax_normalize(tightness)\n    proximity_norm = minmax_normalize(-proximity)  # Higher when closer to avg\n    util_norm = 1.0 - minmax_normalize(util_after)  # Higher when util is lower\n    \n    # Dynamic weight allocation\n    w_tight = 0.6 if large_item else 0.3\n    w_prox = 0.3 if large_item else 0.5\n    w_util = 0.1 if large_item else 0.2\n    \n    # Hybrid score with nonlinear boost\n    hybrid = (w_tight * tight_norm) + (w_prox * proximity_norm) + (w_util * util_norm)\n    boosted = hybrid ** 1.5  # Stronger nonlinear enhancement\n    \n    # Reinforcement-inspired fragility control\n    usability = (system_avg - leftover) / (system_std + 1e-9)\n    fragility_factor = util_after * np.clip(usability, 0, None) * proximity_norm\n    reinforcer = 1.0 + (0.3 * fragility_factor)  # Boosts fragility when usable\n    \n    # Predictive variance adjustment\n    variance_factor = np.exp(-proximity / (system_std + 1e-9))  # Favors proximity\n    \n    # Final score calculation\n    score = boosted * reinforcer * variance_factor\n    \n    # Build result array\n    result = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    result[eligible] = score\n    \n    return result\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines min-max normalization, variance-aware proximity, and dynamic weighting.\n    Uses predictive proximity to reduce fragmentation, reinforcement fragility control,\n    and item-size-adaptive metrics for balanced bin selection.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    # Edge case: negligible item\n    if item < 1e-9:\n        return np.where(bins_remain_cap >= 0, bins_remain_cap, -np.inf)\n    \n    eligible = bins_remain_cap >= (item - 1e-9)\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # System metrics\n    orig_cap = np.max(bins_remain_cap)\n    system_avg = np.mean(bins_remain_cap)\n    system_std = np.std(bins_remain_cap)\n    system_cv = system_std / (system_avg + 1e-9)\n    \n    # Item classification\n    large_item = item > system_avg * (0.75 * (1 + 0.3 * system_cv))\n    \n    # Eligible bin metrics\n    bin_remain = bins_remain_cap[eligible]\n    leftover = bin_remain - item\n    tightness = item / (bin_remain + 1e-9)\n    util_after = (orig_cap - bin_remain + item) / (orig_cap + 1e-9)\n    proximity = np.abs(leftover - system_avg)\n    \n    # Min-max normalization of metrics\n    def minmax_normalize(arr):\n        min_val = np.min(arr)\n        max_val = np.max(arr)\n        if max_val - min_val < 1e-9:\n            return np.zeros_like(arr) + 0.5\n        return (arr - min_val) / (max_val - min_val + 1e-9)\n    \n    tight_norm = minmax_normalize(tightness)\n    proximity_norm = minmax_normalize(-proximity)  # Higher when closer to avg\n    util_norm = 1.0 - minmax_normalize(util_after)  # Higher when util is lower\n    \n    # Dynamic weight allocation\n    w_tight = 0.6 if large_item else 0.3\n    w_prox = 0.3 if large_item else 0.5\n    w_util = 0.1 if large_item else 0.2\n    \n    # Hybrid score with nonlinear boost\n    hybrid = (w_tight * tight_norm) + (w_prox * proximity_norm) + (w_util * util_norm)\n    boosted = hybrid ** 1.5  # Stronger nonlinear enhancement\n    \n    # Reinforcement-inspired fragility control\n    usability = (system_avg - leftover) / (system_std + 1e-9)\n    fragility_factor = util_after * np.clip(usability, 0, None) * proximity_norm\n    reinforcer = 1.0 + (0.3 * fragility_factor)  # Boosts fragility when usable\n    \n    # Predictive variance adjustment\n    variance_factor = np.exp(-proximity / (system_std + 1e-9))  # Favors proximity\n    \n    # Final score calculation\n    score = boosted * reinforcer * variance_factor\n    \n    # Build result array\n    result = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    result[eligible] = score\n    \n    return result\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines min-max normalization, variance-aware proximity, and dynamic weighting.\n    Uses predictive proximity to reduce fragmentation, reinforcement fragility control,\n    and item-size-adaptive metrics for balanced bin selection.\n    \"\"\"\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    # Edge case: negligible item\n    if item < 1e-9:\n        return np.where(bins_remain_cap >= 0, bins_remain_cap, -np.inf)\n    \n    eligible = bins_remain_cap >= (item - 1e-9)\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # System metrics\n    orig_cap = np.max(bins_remain_cap)\n    system_avg = np.mean(bins_remain_cap)\n    system_std = np.std(bins_remain_cap)\n    system_cv = system_std / (system_avg + 1e-9)\n    \n    # Item classification\n    large_item = item > system_avg * (0.75 * (1 + 0.3 * system_cv))\n    \n    # Eligible bin metrics\n    bin_remain = bins_remain_cap[eligible]\n    leftover = bin_remain - item\n    tightness = item / (bin_remain + 1e-9)\n    util_after = (orig_cap - bin_remain + item) / (orig_cap + 1e-9)\n    proximity = np.abs(leftover - system_avg)\n    \n    # Min-max normalization of metrics\n    def minmax_normalize(arr):\n        min_val = np.min(arr)\n        max_val = np.max(arr)\n        if max_val - min_val < 1e-9:\n            return np.zeros_like(arr) + 0.5\n        return (arr - min_val) / (max_val - min_val + 1e-9)\n    \n    tight_norm = minmax_normalize(tightness)\n    proximity_norm = minmax_normalize(-proximity)  # Higher when closer to avg\n    util_norm = 1.0 - minmax_normalize(util_after)  # Higher when util is lower\n    \n    # Dynamic weight allocation\n    w_tight = 0.6 if large_item else 0.3\n    w_prox = 0.3 if large_item else 0.5\n    w_util = 0.1 if large_item else 0.2\n    \n    # Hybrid score with nonlinear boost\n    hybrid = (w_tight * tight_norm) + (w_prox * proximity_norm) + (w_util * util_norm)\n    boosted = hybrid ** 1.5  # Stronger nonlinear enhancement\n    \n    # Reinforcement-inspired fragility control\n    usability = (system_avg - leftover) / (system_std + 1e-9)\n    fragility_factor = util_after * np.clip(usability, 0, None) * proximity_norm\n    reinforcer = 1.0 + (0.3 * fragility_factor)  # Boosts fragility when usable\n    \n    # Predictive variance adjustment\n    variance_factor = np.exp(-proximity / (system_std + 1e-9))  # Favors proximity\n    \n    # Final score calculation\n    score = boosted * reinforcer * variance_factor\n    \n    # Build result array\n    result = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    result[eligible] = score\n    \n    return result\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # 1. Fit score: Min-max normalized tightness (higher = tighter fit)\n    leftover = np.where(eligible, bins_remain_cap - item, np.inf)\n    min_left, max_left = np.min(leftover), np.max(leftover)\n    fit_score = (max_left - leftover) / (max_left - min_left + 1e-9)\n    \n    # 2. Predictive variance score: Variance after placement (lower is better)\n    S, S2, n = bins_remain_cap.sum(), (bins_remain_cap**2).sum(), len(bins_remain_cap)\n    c_i = bins_remain_cap\n    variance_i = (S2 - 2*c_i*item + item**2)/n - ((S - item)**2)/(n**2)\n    variance_i = np.where(eligible, variance_i, np.inf)\n    \n    min_var, max_var = np.min(variance_i), np.max(variance_i)\n    var_score = (max_var - variance_i) / (max_var - min_var + 1e-9)\n    \n    # 3. Reinforcement score: Remaining capacity flexibility\n    rem_after = bins_remain_cap - item\n    rem_ratio = rem_after / (orig_cap + 1e-9)\n    min_rem, max_rem = np.min(rem_ratio[eligible]), np.max(rem_ratio[eligible])\n    reinforce_score = (rem_ratio - min_rem) / (max_rem - min_rem + 1e-9)\n    \n    # 4. Hybrid priority calculation (entropy-agnostic balance)\n    tightness_weight = 0.6  # Static weight for immediate fit\n    future_weight = 0.4      # Static weight for future flexibility\n    \n    tightness_component = fit_score * var_score\n    future_component = reinforce_score * (1.0 + var_score)  # Amplify by variance quality\n    \n    priority = tightness_weight * tightness_component + future_weight * future_component\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # 1. Fit score: Min-max normalized tightness (higher = tighter fit)\n    leftover = np.where(eligible, bins_remain_cap - item, np.inf)\n    min_left, max_left = np.min(leftover), np.max(leftover)\n    fit_score = (max_left - leftover) / (max_left - min_left + 1e-9)\n    \n    # 2. Predictive variance score: Variance after placement (lower is better)\n    S, S2, n = bins_remain_cap.sum(), (bins_remain_cap**2).sum(), len(bins_remain_cap)\n    c_i = bins_remain_cap\n    variance_i = (S2 - 2*c_i*item + item**2)/n - ((S - item)**2)/(n**2)\n    variance_i = np.where(eligible, variance_i, np.inf)\n    \n    min_var, max_var = np.min(variance_i), np.max(variance_i)\n    var_score = (max_var - variance_i) / (max_var - min_var + 1e-9)\n    \n    # 3. Reinforcement score: Remaining capacity flexibility\n    rem_after = bins_remain_cap - item\n    rem_ratio = rem_after / (orig_cap + 1e-9)\n    min_rem, max_rem = np.min(rem_ratio[eligible]), np.max(rem_ratio[eligible])\n    reinforce_score = (rem_ratio - min_rem) / (max_rem - min_rem + 1e-9)\n    \n    # 4. Hybrid priority calculation (entropy-agnostic balance)\n    tightness_weight = 0.6  # Static weight for immediate fit\n    future_weight = 0.4      # Static weight for future flexibility\n    \n    tightness_component = fit_score * var_score\n    future_component = reinforce_score * (1.0 + var_score)  # Amplify by variance quality\n    \n    priority = tightness_weight * tightness_component + future_weight * future_component\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    n = bins_remain_cap.shape[0]\n    delta = item\n    \n    # Predictive variance modeling\n    S = bins_remain_cap.sum()\n    Q = (bins_remain_cap ** 2).sum()\n    mean_new = (S - delta) / n\n    sum_sq_new = Q - 2 * delta * bins_remain_cap + delta ** 2\n    var_new = (sum_sq_new / n) - (mean_new ** 2)\n    \n    # Variance score normalization (lower variance is better)\n    eligible_var = var_new[eligible]\n    var_min, var_max = eligible_var.min(), eligible_var.max()\n    if var_max > var_min:\n        norm_var = (var_max - var_new) / (var_max - var_min + 1e-9)\n    else:\n        norm_var = np.zeros_like(var_new)\n    \n    # Leftover space normalization\n    leftover = bins_remain_cap - delta\n    eligible_left = leftover[eligible]\n    left_min, left_max = eligible_left.min(), eligible_left.max()\n    if left_max > left_min:\n        norm_left = (leftover - left_min) / (left_max - left_min + 1e-9)\n    else:\n        norm_left = np.zeros_like(leftover)\n    \n    # Tightness normalization\n    tightness = delta / (bins_remain_cap + 1e-9)\n    eligible_tight = tightness[eligible]\n    tight_min, tight_max = eligible_tight.min(), eligible_tight.max()\n    if tight_max > tight_min:\n        norm_tight = (tightness - tight_min) / (tight_max - tight_min + 1e-9)\n    else:\n        norm_tight = np.zeros_like(tightness)\n    \n    # Item classification\n    system_avg = bins_remain_cap.mean()\n    large_item = delta > system_avg\n    \n    # Static-dynamic weighting\n    tight_weight = 0.7 if large_item else 0.3\n    var_weight = 0.2 if large_item else 0.5\n    left_weight = 0.1 if large_item else 0.2\n    \n    # Priority components\n    priority = (\n        norm_tight * tight_weight +\n        norm_var * var_weight +\n        norm_left * left_weight\n    )\n    \n    # Reinforcement adjustment for future flexibility\n    used_cap = orig_cap - bins_remain_cap\n    utilization = used_cap / (orig_cap + 1e-9)\n    if not large_item:\n        priority += 0.1 * utilization  # Prefer filling partially used bins\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # 1. Fit score: Min-max normalized tightness (higher = tighter fit)\n    leftover = np.where(eligible, bins_remain_cap - item, np.inf)\n    min_left, max_left = np.min(leftover), np.max(leftover)\n    fit_score = (max_left - leftover) / (max_left - min_left + 1e-9)\n    \n    # 2. Predictive variance score: Variance after placement (lower is better)\n    S, S2, n = bins_remain_cap.sum(), (bins_remain_cap**2).sum(), len(bins_remain_cap)\n    c_i = bins_remain_cap\n    variance_i = (S2 - 2*c_i*item + item**2)/n - ((S - item)**2)/(n**2)\n    variance_i = np.where(eligible, variance_i, np.inf)\n    \n    min_var, max_var = np.min(variance_i), np.max(variance_i)\n    var_score = (max_var - variance_i) / (max_var - min_var + 1e-9)\n    \n    # 3. Reinforcement score: Remaining capacity flexibility\n    rem_after = bins_remain_cap - item\n    rem_ratio = rem_after / (orig_cap + 1e-9)\n    min_rem, max_rem = np.min(rem_ratio[eligible]), np.max(rem_ratio[eligible])\n    reinforce_score = (rem_ratio - min_rem) / (max_rem - min_rem + 1e-9)\n    \n    # 4. Hybrid priority calculation (entropy-agnostic balance)\n    tightness_weight = 0.6  # Static weight for immediate fit\n    future_weight = 0.4      # Static weight for future flexibility\n    \n    tightness_component = fit_score * var_score\n    future_component = reinforce_score * (1.0 + var_score)  # Amplify by variance quality\n    \n    priority = tightness_weight * tightness_component + future_weight * future_component\n    \n    return np.where(eligible, priority, -np.inf)\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n    \n    orig_cap = np.max(bins_remain_cap)\n    if orig_cap <= 1e-9 or item <= 1e-9:\n        return np.where(\n            bins_remain_cap >= item,\n            bins_remain_cap - item + 1e-9,\n            -np.inf\n        )\n    \n    eligible = bins_remain_cap >= item\n    if not np.any(eligible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    \n    # 1. Fit score: Min-max normalized tightness (higher = tighter fit)\n    leftover = np.where(eligible, bins_remain_cap - item, np.inf)\n    min_left, max_left = np.min(leftover), np.max(leftover)\n    fit_score = (max_left - leftover) / (max_left - min_left + 1e-9)\n    \n    # 2. Predictive variance score: Variance after placement (lower is better)\n    S, S2, n = bins_remain_cap.sum(), (bins_remain_cap**2).sum(), len(bins_remain_cap)\n    c_i = bins_remain_cap\n    variance_i = (S2 - 2*c_i*item + item**2)/n - ((S - item)**2)/(n**2)\n    variance_i = np.where(eligible, variance_i, np.inf)\n    \n    min_var, max_var = np.min(variance_i), np.max(variance_i)\n    var_score = (max_var - variance_i) / (max_var - min_var + 1e-9)\n    \n    # 3. Reinforcement score: Remaining capacity flexibility\n    rem_after = bins_remain_cap - item\n    rem_ratio = rem_after / (orig_cap + 1e-9)\n    min_rem, max_rem = np.min(rem_ratio[eligible]), np.max(rem_ratio[eligible])\n    reinforce_score = (rem_ratio - min_rem) / (max_rem - min_rem + 1e-9)\n    \n    # 4. Hybrid priority calculation (entropy-agnostic balance)\n    tightness_weight = 0.6  # Static weight for immediate fit\n    future_weight = 0.4      # Static weight for future flexibility\n    \n    tightness_component = fit_score * var_score\n    future_component = reinforce_score * (1.0 + var_score)  # Amplify by variance quality\n    \n    priority = tightness_weight * tightness_component + future_weight * future_component\n    \n    return np.where(eligible, priority, -np.inf)\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}