{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                nearly_full_bonus_weight: float = 18.39595116881296, nearly_full_exponent_scale: float = 19.354450569770187,\n                valid_bins_priority: float = 0.7383144022815835, overall_fullness_divisor: float = 0.7231068935017757, valid_bins_sum_threshold: float = -0.7268254955315205) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        inverse_diff_epsilon: Small value to avoid division by zero when calculating the inverse of the space difference.\n        nearly_full_bonus_weight: Weight of the bonus given to nearly full bins.\n        nearly_full_exponent_scale: Scaling factor in the exponent for the nearly full bonus.\n        valid_bins_priority: default priority for valid bins.\n        overall_fullness_divisor: divisor for overall fullness calculation.\n        valid_bins_sum_threshold: threshold for valid bins sum.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate remaining capacity after adding the item. Negative values indicate infeasibility.\n    remaining_after_add = bins_remain_cap - item\n\n    # Give high priority to bins that can accommodate the item, but avoid almost-full bins (first fit decreasing consideration).\n    # Slightly favor bins with space close to the item size to avoid excessive fragmentation.\n    valid_bins = remaining_after_add >= 0\n\n    if np.any(valid_bins):\n        space_diff = np.abs(remaining_after_add)\n        priorities[valid_bins] = valid_bins_priority / (space_diff[valid_bins] + inverse_diff_epsilon)  # Inverse of difference, add small value to avoid division by zero\n        # Heuristics to promote bins that are sufficiently full (avoid too much space)\n        fill_ratios = (bins_remain_cap[valid_bins] - remaining_after_add[valid_bins]) / bins_remain_cap[valid_bins]\n\n        #Promote nearly full bins but penalize excessively small remainders\n        priorities[valid_bins] = priorities[valid_bins] + nearly_full_bonus_weight*np.exp(-nearly_full_exponent_scale*(remaining_after_add[valid_bins]/item)**2)\n\n\n    #Heuristic: Consider the overall fullness of the bins. If a bin is very full (high fill_ratio), it should receive a lower priority as that is more prone to produce unusable fragments\n    overall_fullness = (np.sum(bins_remain_cap) - np.sum(bins_remain_cap[remaining_after_add>=0]) + np.sum(item*np.ones_like(bins_remain_cap)[remaining_after_add>=0])) / np.sum(np.ones_like(bins_remain_cap) * np.max(bins_remain_cap))\n    #Consider the worst case bin that could not store the item as a dissuader\n\n    if np.sum(valid_bins) == valid_bins_sum_threshold:\n      priorities = 1/(overall_fullness_divisor+np.abs(remaining_after_add))\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                nearly_full_bonus_weight: float = 11.372940705301689, nearly_full_exponent_scale: float = 12.350984135114247) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        inverse_diff_epsilon: Small value to avoid division by zero when calculating the inverse of the space difference.\n        nearly_full_bonus_weight: Weight of the bonus given to nearly full bins.\n        nearly_full_exponent_scale: Scaling factor in the exponent for the nearly full bonus.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate remaining capacity after adding the item. Negative values indicate infeasibility.\n    remaining_after_add = bins_remain_cap - item\n\n    # Give high priority to bins that can accommodate the item, but avoid almost-full bins (first fit decreasing consideration).\n    # Slightly favor bins with space close to the item size to avoid excessive fragmentation.\n    valid_bins = remaining_after_add >= 0\n\n    if np.any(valid_bins):\n        space_diff = np.abs(remaining_after_add)\n        priorities[valid_bins] = 1.0 / (space_diff[valid_bins] + inverse_diff_epsilon)  # Inverse of difference, add small value to avoid division by zero\n        # Heuristics to promote bins that are sufficiently full (avoid too much space)\n        fill_ratios = (bins_remain_cap[valid_bins] - remaining_after_add[valid_bins]) / bins_remain_cap[valid_bins]\n\n        #Promote nearly full bins but penalize excessively small remainders\n        priorities[valid_bins] = priorities[valid_bins] + nearly_full_bonus_weight*np.exp(-nearly_full_exponent_scale*(remaining_after_add[valid_bins]/item)**2)\n\n\n    #Heuristic: Consider the overall fullness of the bins. If a bin is very full (high fill_ratio), it should receive a lower priority as that is more prone to produce unusable fragments\n    overall_fullness = (np.sum(bins_remain_cap) - np.sum(bins_remain_cap[remaining_after_add>=0]) + np.sum(item*np.ones_like(bins_remain_cap)[remaining_after_add>=0])) / np.sum(np.ones_like(bins_remain_cap) * np.max(bins_remain_cap))\n    #Consider the worst case bin that could not store the item as a dissuader\n\n    if np.sum(valid_bins) == 0:\n      priorities = 1/(1+np.abs(remaining_after_add))\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic incorporates bin utilization awareness, item size consideration, a dynamic fragmentation penalty, and a fallback strategy, while the worst uses a Gaussian-like priority based on remaining capacity closeness to item size, a \"desperation\" factor, and slight randomness.\n\n(2nd) vs (19th): Very similar to (1st) vs (20th).\n\nComparing (1st) vs (2nd), we see no differences. They are exactly the same.\n\nComparing (3rd) vs (4th), we see no differences. They are exactly the same.\n\nComparing (19th) vs (20th), the heuristic in (19th) calculates the ratio of remaining capacity *after* adding the item to the original remaining capacity, adds a bonus to bins with a remaining capacity close to the item size, and normalizes the final priorities to the range of [0,1]. The heuristic in (20th) uses a Gaussian-like priority based on remaining capacity closeness to item size, a \"desperation\" factor, and slight randomness.\n\nComparing (11th) vs (12th), we see (12th) combines ratio-based prioritization with dynamic fill-up bonus and randomness, it normalizes the priorities to the range [0, 1]. (11th) uses parameters and no normalization.\n\nOverall: The better heuristics emphasize a combination of factors, including bin utilization, item size, fragmentation penalties, and fallback strategies, along with normalization, while also employing adaptive randomness to diversify bin selection. The poorer heuristics focus primarily on closeness to item size (using a Gaussian-like function) and a desperation factor, with less attention to these other elements.\n- \nOkay, here's a redefined \"Current Self-Reflection\" for designing better heuristics, avoiding pitfalls:\n\n*   **Keywords:** Quantitative metrics (bin utilization, fragmentation), adaptive parameters, normalization methods (scaling, ranking), exploration-exploitation balance, fine-grained control.\n\n*   **Advice:** Focus on measurable impact: define clear performance metrics and track them. Implement adaptive parameter control based on problem instance characteristics.\n\n*   **Avoid:** Vague notions of \"balance\" and \"stability\". Resist adding randomness without a clear justification.\n\n*   **Explanation:** Shift from general feelings to specific, quantifiable techniques. Instead of \"stability,\" consider things like reducing solution variance across similar instances. Instead of vaguely \"balancing,\" define the exploration/exploitation trade-off explicitly through parameters that can be tuned.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}