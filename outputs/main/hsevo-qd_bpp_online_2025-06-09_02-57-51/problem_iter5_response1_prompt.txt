{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                nearly_full_bonus_weight: float = 11.372940705301689, nearly_full_exponent_scale: float = 12.350984135114247) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        inverse_diff_epsilon: Small value to avoid division by zero when calculating the inverse of the space difference.\n        nearly_full_bonus_weight: Weight of the bonus given to nearly full bins.\n        nearly_full_exponent_scale: Scaling factor in the exponent for the nearly full bonus.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate remaining capacity after adding the item. Negative values indicate infeasibility.\n    remaining_after_add = bins_remain_cap - item\n\n    # Give high priority to bins that can accommodate the item, but avoid almost-full bins (first fit decreasing consideration).\n    # Slightly favor bins with space close to the item size to avoid excessive fragmentation.\n    valid_bins = remaining_after_add >= 0\n\n    if np.any(valid_bins):\n        space_diff = np.abs(remaining_after_add)\n        priorities[valid_bins] = 1.0 / (space_diff[valid_bins] + inverse_diff_epsilon)  # Inverse of difference, add small value to avoid division by zero\n        # Heuristics to promote bins that are sufficiently full (avoid too much space)\n        fill_ratios = (bins_remain_cap[valid_bins] - remaining_after_add[valid_bins]) / bins_remain_cap[valid_bins]\n\n        #Promote nearly full bins but penalize excessively small remainders\n        priorities[valid_bins] = priorities[valid_bins] + nearly_full_bonus_weight*np.exp(-nearly_full_exponent_scale*(remaining_after_add[valid_bins]/item)**2)\n\n\n    #Heuristic: Consider the overall fullness of the bins. If a bin is very full (high fill_ratio), it should receive a lower priority as that is more prone to produce unusable fragments\n    overall_fullness = (np.sum(bins_remain_cap) - np.sum(bins_remain_cap[remaining_after_add>=0]) + np.sum(item*np.ones_like(bins_remain_cap)[remaining_after_add>=0])) / np.sum(np.ones_like(bins_remain_cap) * np.max(bins_remain_cap))\n    #Consider the worst case bin that could not store the item as a dissuader\n\n    if np.sum(valid_bins) == 0:\n      priorities = 1/(1+np.abs(remaining_after_add))\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function incorporates several factors to determine the priority:\n    1. Remaining capacity: Bins with capacity closer to the item size\n       are given higher priority (using a Gaussian-like function).  This\n       encourages filling bins reasonably well.\n    2. A \"desperation\" factor: If no bins can fit the item, prioritize\n       the least-full bin to minimize wasted space. This only applies if `item` is larger than the largest `bins_remain_cap`.\n    3.  Slight randomness:  To avoid being stuck in local optima and\n        explore slightly different packings.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Gaussian-like priority based on remaining capacity closeness to item size.\n    # The narrower the Gaussian, the more specific we are in matching item size to bin capacity.  Experiment with different widths (std).\n    gaussian_width = np.mean(bins_remain_cap)/5 #tuneable.  Smaller = more picky.\n\n    priorities = np.exp(-((bins_remain_cap - item)**2) / (2 * gaussian_width**2))\n\n\n    #Desperation: item doesn't fit in any bin. Prioritize least full bin.\n    if np.all(item > bins_remain_cap):\n\n        min_cap = np.min(bins_remain_cap)\n        priorities = (bins_remain_cap == min_cap).astype(float)  # Highest priority to least full.  Tie goes to the first.\n\n    #Add a bit of randomness to avoid local optima\n    randomness_strength = 0.001 #Tuneable. Keep very small.\n\n    priorities += np.random.rand(len(bins_remain_cap)) * randomness_strength\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that 1st has more fine-grained control over bin selection, using parameters like `inverse_diff_epsilon`, `nearly_full_bonus_weight`, and `nearly_full_exponent_scale` to tune bin priorities and 20th uses gaussian-like function. 2nd vs 19th are similar to 1st vs 20th in terms of fine-grained control. Comparing (5th) vs (20th), 5th contains randomness for exploration. Comparing (1st) vs (5th), 1st does not contain randomness, the penalty or boosting term is different, and also the parameter of 1st is more than 5th. Comparing (13th) vs (14th), they are very similar and both are gaussian-like function with randomness. Comparing (15th) vs (13th), 15th function normalizes the priorities to the range of [0, 1] and uses infeasible mask. Comparing (17th) vs (18th), 17th function normalizes the priorities to the range of [0, 1] and uses infeasible mask while 18th uses gaussian-like function. Comparing (second worst) vs (worst), they are similar. Overall: The better heuristics incorporate more sophisticated strategies like remaining capacity ratios, normalization, infeasibility handling, fine-grained control over bin selection, while also considering trade-offs like exploration with randomness. Simpler heuristics rely on Gaussian-like functions and less parameters.\n- \nOkay, I'm ready to help you design better heuristics! Let's redefine \"Current self-reflection\" to be more effective.\n\n*   **Keywords:** Adaptability, Learning, Performance Metrics, Constraint Awareness.\n*   **Advice:** Design heuristics that adapt based on problem instance characteristics and learn from past performance. Track key metrics to identify weaknesses and adjust strategies accordingly.\n*   **Avoid:** Generic \"one-size-fits-all\" approaches. Focus on context-specific adaptations.\n*   **Explanation:** Instead of passively incorporating features, design heuristics that actively analyze the problem and *dynamically* adjust their behavior for improved efficiency.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}