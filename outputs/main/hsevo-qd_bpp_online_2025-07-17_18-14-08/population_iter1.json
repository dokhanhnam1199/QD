[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # First, filter out bins that can't fit the item\n    feasible_bins = bins_remain_cap >= item\n    \n    if not np.any(feasible_bins):\n        # If no bin can fit the item, prioritize the fullest bin\n        priorities = bins_remain_cap.copy()\n        return priorities\n\n    # Calculate remaining capacity AFTER placing the item (only for feasible bins)\n    remaining_cap_after = bins_remain_cap[feasible_bins] - item\n    \n    # Prioritize bins where the item fits best (smallest remaining capacity)\n    priorities[feasible_bins] = 1.0 / (remaining_cap_after + 0.000001) # Avoid division by zero\n\n    # Give a bonus to bins that are already somewhat full (avoid fragmenting empty bins).\n    priorities[feasible_bins] += bins_remain_cap[feasible_bins] / np.max(bins_remain_cap)\n        \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 84.7726366174711,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Considers both remaining capacity and a \"gravitational pull\"\n    towards bins that are already somewhat full.\n    Inspired by gravitational lensing and spacetime curvature -\n    items \"prefer\" to be near existing \"mass\" (filled bins).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero:\n    bins_remain_cap = np.clip(bins_remain_cap, 1e-9, None)\n\n    # 1. Capacity Consideration (Similar to First Fit Decreasing):\n    capacity_priority = bins_remain_cap - item  # Higher is better\n\n    # If the item doesn't fit, give very low priority.\n    capacity_priority[capacity_priority < 0] = -np.inf\n\n    # 2. \"Gravitational\" Factor (Encourages filling nearly-full bins):\n    # Higher remaining cap means weaker \"gravity\", so use inverse.\n    # Small constant added to avoid division by zero, and to tweak the influence\n    # Note, the greater the item, the larger its effect is to \"pull\" to itself\n    gravitational_constant = 0.1\n    gravity = item / (bins_remain_cap + gravitational_constant)  # The closer it is to filled, the higher priority\n    gravity = np.nan_to_num(gravity, neginf=0)\n\n    # 3. Combine Priorities (Relativistic Addition - loosely inspired):\n    # Add some small factor such that a large change to either parameter doesn't change the total by as much.\n    #   - We should favor adding to any bin with cap sufficiently large rather than prioritizing the full bins.\n\n    alpha = 0.9 # Tunable constant\n\n    priorities = alpha * capacity_priority + (1-alpha) * gravity\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a combination of factors inspired by physical principles\n    (though adapted for this computational problem).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A 'gravitational' attraction: Higher priority for bins closer to item size.\n    # Use squared difference for a stronger pull when very close\n    diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (1e-6 + diff**2)  # 1e-6 avoids division by zero\n\n    # Inverse 'repulsion': lower priority for bins with very little space.\n    # Mimicking Pauli Exclusion Principle (sort of). Prevent overfilling attempts.\n    small_space_penalty = np.where(bins_remain_cap < item, -np.inf, 0)\n    priorities += small_space_penalty\n\n    # Favor bins with more capacity available (but not too much)\n    # A larger bin reduces the number of bins in total, improving our goal\n    capacity_bonus = np.clip(bins_remain_cap - item, 0, item * 2) # Cap bonus\n    priorities += capacity_bonus * 0.1 # Tune bonus effect, otherwise domination.\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 29.736737136019155,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       This version prioritizes bins that have enough space, but not too much.\n       It aims to avoid fragmentation and utilize bins more efficiently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Enough space: prioritize based on how much space will be left.\n            remaining_space = cap - item\n            # Give higher priority to bins that will have a small amount of space left.\n            # Avoid excessive fragmentation, but also don't greedily fill bins if a better fit is possible.\n            # The closer to zero the remaining space is, the higher the priority, with diminishing returns.\n            priorities[i] = np.exp(-remaining_space) # try to make bins almost full.\n\n            #Boosting bins that leave a bit space that might be usable later\n            if 0 < remaining_space < 0.3 :\n                priorities[i]+=0.1\n        else:\n            # Not enough space: priority is 0.\n            priorities[i] = 0.0\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999973480000335 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Tesla's embodiment of electrical elegance: A symphony of potential.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid zero capacity bins and division by zero.\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)  # Default to negative infinity.\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n\n        # Calculate the waste if we place the item in each bin. A lower waste\n        # suggests a better fit. Avoid negative waste using max(0).\n        waste = np.maximum(0, remaining_capacities - item)\n\n        # Score based on the inverse of the waste. To give higher preference to minimal waste\n        waste_score = 1 / (waste + 1e-9) # Adding a small value to avoid division by zero\n        \n        # Fit Score\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/3)**2)) # Gaussian Fit score favoring item to fit nicely in the bin.\n\n        # Preference for bins that can accommodate the item. Also incorporate remaining capacity\n        # to prioritize using more full bins first.\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Combine the scoring components. Give weights to components\n        combined_score = 0.6 * waste_score + 0.3 * fit_score + 0.1 * capacity_utilization\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Employs a combination of factors:\n         1. Space Utilization: Favor bins where the item fits reasonably well,\n            but not perfectly, to encourage filling.\n         2. Avoidance of near-empty bins: Penalize bins that will become nearly empty after packing.\n         3. Capacity Considerations: Give priority to bins with sufficient, but not excessive, remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 1e-9  # Small constant to avoid division by zero and log of zero\n\n    # 1. Space Utilization:  Calculate how well the item fits (ratio).\n    utilization_ratio = item / (bins_remain_cap + epsilon)\n    utilization_priority = np.exp(-np.abs(utilization_ratio - 1))  # Gaussian-like peak around ratio=1\n\n    # 2. Avoidance of near-empty bins: Penalize bins becoming nearly empty.\n    remaining_after_pack = np.clip(bins_remain_cap - item, 0, np.inf)\n    empty_bin_penalty = np.exp(-5 * remaining_after_pack / (bins_remain_cap + epsilon)) # strong penalty if remaining is small relative to original.  Larger coefficient gives stronger penalty.\n    # Make sure that utilization_priority is always zero when remaining_after_pack is zero. This ensures there is no inf values and correct behaviour\n    empty_bin_penalty[remaining_after_pack <= epsilon] = 0.0\n\n\n    # 3. Capacity Considerations:  Bins with very little remaining space\n    #    or too much remaining space get lower priority.\n    capacity_priority = np.sqrt(bins_remain_cap) # Gives preference to bins with some space. Using sqrt rather than linear\n\n    # Combine the factors:\n    priorities = utilization_priority * (1 - empty_bin_penalty) * capacity_priority\n    priorities[bins_remain_cap < item] = -np.inf  # Impossible bins get negative infinity priority to avoid ever using\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 86.60749900279218,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version considers both remaining capacity and waste.  Bins that\n    have enough capacity and leave minimal waste are preferred.  We also\n    introduce a small exploration factor to avoid getting stuck in local minima.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Avoid division by zero\n    bins_remain_cap = np.clip(bins_remain_cap, 1e-9, None)\n\n    # Calculate waste if item is placed in each bin. Negative values indicate not enough space\n    waste = bins_remain_cap - item\n\n    # Give bins that can accommodate the item a baseline priority of 1, and others 0\n    priority = np.where(waste >= 0, 1.0, 0.0)\n\n    # Further increase priority based on how *little* waste there is. This encourages filling bins well.\n    # Using a Gaussian-like curve centered around zero waste\n    priority += np.where(waste >= 0, np.exp(-(waste**2) / (2 * (item/5)**2)), 0.0)\n\n    # Add a tiny amount proportional to the remaining capacity. This favors using less-full bins *slightly*.\n    # Important that this is significantly smaller than other terms. This promotes even distribution but cares more about fitting well.\n    priority += bins_remain_cap * 0.001\n\n    # Add a small exploration factor to sometimes deviate from the \"best\" choice and potentially find better packings\n    priority += np.random.rand(len(bins_remain_cap)) * 0.0001\n\n    return priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 12.913841244515359,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.  Inspired by energy minimization and a bit of quantum tunneling.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the \"potential energy\" increase by adding the item. Lower energy preferred.\n    potential_energy = (bins_remain_cap - item)**2\n    potential_energy[bins_remain_cap - item < 0] = np.inf # Infinite energy if it doesn't fit\n\n    # \"Quantum tunneling\" probability: Higher chance to tunnel into nearly full bins if we're desperate.\n    tunneling_factor = np.exp(-10 * np.abs(bins_remain_cap - item) / item) #Exponential decay. Experiment with the scaling.\n\n    # A small term to encourage using emptier bins (explore). This can prevent local optima.\n    exploration_bonus = 0.01 * bins_remain_cap\n\n    # Combine these to get a priority: Want to minimize energy, maximize tunneling when needed, and explore.\n    priority = -potential_energy + tunneling_factor + exploration_bonus\n    \n    return priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Prioritize bins that can fit the item reasonably well\n    # but aren't too empty afterwards. Avoid fragmentation.\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Give a high score if the item fits and the remaining capacity is not too large\n    fit_mask = bins_remain_cap >= item\n    remaining_after_fit = bins_remain_cap[fit_mask] - item\n\n    # Scale based on how full the bin will be after packing, prefer bins close to full.\n    priorities[fit_mask] = (1 - (remaining_after_fit / bins_remain_cap[fit_mask]))\n    # Apply scaling to really encourage filling the almost-full bin\n    priorities[fit_mask] = priorities[fit_mask]**2\n    # Prefer bins whose remain_cap is a bit larger than item.\n    priorities[fit_mask] = priorities[fit_mask] / (1 + abs(bins_remain_cap[fit_mask]-item))\n    # Negatively penalize bins that are too large or empty before placing the item. This discourages bins with much capacity relative to item\n    priorities = priorities - (bins_remain_cap / np.max(bins_remain_cap)) * 0.01\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Uses a combination of factors to determine priority:\n    1. Remaining capacity relative to item size. Bins with capacity close to the item size are preferred (First-Fit Decreasing heuristic).\n    2. Waste minimization. Small waste is preferred.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Calculate the wasted space if the item is placed in this bin.\n            waste = cap - item\n\n            # Prioritize bins where the remaining capacity is close to the item size.\n            # This encourages filling bins more completely (FFD principle)\n            capacity_difference = np.abs(cap - item)\n\n            # Prioritize bins that minimize waste\n            # Avoid division by zero by adding a small epsilon value.\n            priorities[i] = (1.0 / (capacity_difference + 1e-9)) + (1.0 / (waste + 1e-9))\n\n\n        else:\n            # Bin is not suitable, assign a very low priority.\n            priorities[i] = -np.inf\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99996434999957 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Feasibility: Prioritize bins that can actually fit the item\n    feasible_bins = bins_remain_cap >= item\n    priorities[feasible_bins] += 1\n\n    # Remaining capacity: Prioritize bins where item fits best (minimize wasted space)\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Ignore infeasible bins in waste calculation\n\n    # Give higher priority to bins with smaller waste (larger negative value when inverted)\n    priorities[feasible_bins] -= waste[feasible_bins]\n\n    # Bonus for almost full bins *after* placing the item to consolidate space.\n    almost_full_threshold = 0.1 # e.g., if remaining cap after placement is < 10% of bin size. Adjust for better performance\n    remaining_after_placement = bins_remain_cap - item\n    almost_full = (remaining_after_placement > 0) & (remaining_after_placement / bins_remain_cap <= almost_full_threshold)\n    priorities[almost_full] += 2  # Substantially higher priority\n\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 24, in priority_v2\n    \nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n3\n88.0\n78.11172779494449\n131\n"
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a combination of remaining capacity and waste minimization,\n    inspired by the principles of efficient space-time utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero by adding a small epsilon\n    epsilon = 1e-9\n    \n    # Calculate waste if the item is placed in each bin\n    waste = bins_remain_cap - item\n    \n    # Give negative infinite priority to bins that cannot contain the item\n    waste[waste < -epsilon] = np.inf\n\n    # Score based on remaining capacity\n    capacity_score = bins_remain_cap / (np.sum(bins_remain_cap) + epsilon)\n\n    #Score based on waste, higher priority when there is minimal waste\n    waste_score = np.exp(-10 * waste / (item + epsilon)) #Exponential decay for waste close to 0, item scaled decay rate\n\n    # Combine scores\n    priorities = capacity_score * waste_score #Prefer bigger free bins and smaller waste\n\n    # Set invalid bins to -inf\n    priorities[waste == np.inf] = -np.inf\n    \n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the waste if the item is placed in the bin\n    waste = bins_remain_cap - item\n\n    # Give a very low priority (high negative number) to bins that can't fit the item\n    priority = np.where(waste < 0, -1e9, 0)\n\n    # Prioritize bins that have the smallest waste (smallest remaining space).\n    # Use a slightly different approach to avoid dividing by zero or taking the log of zero\n    # and to add some small randomness to break ties and explore different packings.\n    valid_bins = waste[waste >= 0]\n    if valid_bins.size > 0:\n        min_waste = np.min(valid_bins)\n\n        # Add a bonus for bins that have waste close to the minimum waste\n        priority[waste >= 0] += 1 / (1 + np.abs(waste[waste >= 0] - min_waste)) + np.random.rand(waste[waste>=0].size)*0.1 # add tiny random element\n\n    # Further prioritize bins with capacity closest to twice the item size. The item should preferably fill half the space left.\n    target_capacity = 2 * item\n    proximity = np.abs(bins_remain_cap - target_capacity)\n    priority = priority - proximity/bins_remain_cap #Smaller proximity to target_capacity gives larger score (more negative is better)\n\n    return priority",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.836457917830076,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Initialize priority scores\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give high priority to bins that can fit the item without much waste\n    # This encourages filling bins efficiently\n    fit_mask = bins_remain_cap >= item\n    waste = bins_remain_cap - item\n    priorities[fit_mask] = 1.0 / (waste[fit_mask] + 0.0001) # Avoid division by zero and prioritize smaller waste\n\n    # Give a slightly lower priority to bins that are nearly full before adding the item\n    # Avoid very small remaining capacities\n    nearly_full_mask = (bins_remain_cap > 0) & (bins_remain_cap < item)\n    priorities[nearly_full_mask] = 0.5\n\n    # Penalize bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf # Never add to bins that cannot fit\n\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Utilizes a combination of factors including capacity, waste minimization,\n    and a slight preference for partially filled bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Initialize priorities with a base score based on whether the item fits.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n    priorities[fits] = 1.0  # Bins where the item fits get a base priority.\n\n    # Adjust priority based on waste minimization.  Smaller waste is better.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Effectively ignore bins where the item doesn't fit\n\n    # Scale the inverse of the waste to contribute to the priority.  Avoid division by zero.\n    waste_scores = np.where(waste > 0, 1.0 / (waste + 0.0001), 0.0) #Small constant to avoid division by zero.\n\n    #Add scaled waste score.\n    priorities += waste_scores* fits #only if it fits\n\n\n    # Encourage filling bins that already have some items (but aren't full), subtly\n    # to avoid prematurely closing bins, by rewarding a specific range of capacity usage\n    partially_filled = (bins_remain_cap > item) & (bins_remain_cap < np.max(bins_remain_cap))\n    priorities[partially_filled] += 0.5 #Adds a moderate bias for partially filled bins.\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a combination of remaining capacity and item size to determine priority.\n    Bins with capacity slightly larger than the item are prioritized,\n    while bins that are too small or too large receive lower priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Avoid division by zero. Set priority to a very low value if remaining capacity is 0\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[bins_remain_cap == 0] = -np.inf\n\n    # Give higher priority to bins that can fit the item closely\n    fit_score = np.where(bins_remain_cap >= item, np.exp(-np.abs(bins_remain_cap - item) / item), -np.inf)\n\n    # Penalize bins with very large remaining capacity\n    capacity_penalty = np.where(bins_remain_cap > item, - (bins_remain_cap - item) / np.max(bins_remain_cap), 0)\n\n    priorities = fit_score + capacity_penalty\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several heuristics:\n    1.  If a bin fits the item perfectly, assign a very high priority.\n    2.  If a bin doesn't have enough capacity, assign a very low priority.\n    3.  Favor bins that are already somewhat full (higher utilization).\n    4.  Consider the waste (remaining capacity after packing) \u2013 minimize it.\n    5.  Add a tiny bit of randomness to avoid getting stuck in local optima.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # small constant to prevent division by zero\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            priorities[i] = -np.inf  # Cannot fit\n        elif abs(cap - item) < epsilon:\n            priorities[i] = np.inf  # Perfect fit!\n        else:\n            # Heuristic 1: Favor bins with higher utilization (already full)\n            utilization = 1 - (cap / (cap + item)) if (cap + item)> 0 else 0\n            priorities[i] += utilization * 0.5 #scale utilization factor\n            \n            # Heuristic 2: Minimize waste (remaining capacity after packing)\n            waste = cap - item\n            priorities[i] -= waste * 0.1 #scale waste factor\n\n            # Heuristic 3: A slight preference to fill any space available\n            priorities[i] += 0.01\n            \n    # Add tiny bit of randomness to break ties and explore different solutions\n    priorities += np.random.normal(0, 0.001, size=len(bins_remain_cap))\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999974471000314 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors:\n    1. How well the item fits (smaller wasted space is better).\n    2. A probabilistic element to explore different bin choices (inspired by quantum randomness).\n    3. A penalty for bins that are almost full (risk of overfilling).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero\n    bins_remain_cap = np.clip(bins_remain_cap, 1e-6, None)\n\n    # 1. Fit Score: Smaller wasted space is better\n    wasted_space = bins_remain_cap - item\n    fit_score = np.exp(-np.abs(wasted_space)) # Gaussian-like, peaked at 0 wasted space. exp(-waste) more sensitive to small wastes\n\n    # Adjust fit score: Penalize if waste is very high. Use the original capacity for scaling\n    fit_score = np.where(wasted_space < 0, -1e9, fit_score)  # Assign extremely low score if overfill.  Make really small\n\n    # 2. Probabilistic Element: \"Quantum Tunneling\" - Allow some exploration\n    # Inspired by the idea that a particle can tunnel through barriers.\n    #  Add small random numbers (proportional to the item size). This encourages exploration.\n    probabilistic_boost = np.random.rand(len(bins_remain_cap)) * item * 0.01  # Small boost\n\n    # 3. Risk Factor: Penalize bins that are close to full (Higher risk of overfilling with subsequent items).\n    # This is an exponentially decaying penalty near capacity.\n    capacity_ratio = item / bins_remain_cap\n    risk_penalty = np.exp(10 * (capacity_ratio - 1))\n    risk_penalty = np.clip(risk_penalty, 0, 1e9)  # limit penalty effect to prevent nan. The lower this upper bound, the less sensitive\n\n    # Combine all factors\n    priorities = fit_score + probabilistic_boost - risk_penalty\n\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 98.29477463103312,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers several factors:\n\n    1.  Whether the item fits in the bin.  If not, priority is -inf.\n    2.  The fill ratio (item size / remaining capacity). Higher fill ratio is generally better,\n        but we also want to avoid filling a bin *too* much (leaving very little space).\n    3. A bonus for bins that are nearly full after adding the item, but not quite full\n       (this encourages good packing but avoids perfect fits too early which may lead to\n       inefficient packing later on.)\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full(bins_remain_cap.shape, -np.inf)  # Initialize with -inf\n\n    # Bins where the item fits\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n      return priorities # Return -inf if no bins fit.\n\n    # Calculate fill ratios for valid bins\n    fill_ratios = np.zeros_like(bins_remain_cap, dtype=float)\n    fill_ratios[valid_bins] = item / bins_remain_cap[valid_bins]\n\n    # Priority based on fill ratio (with a bit of a tweak)\n    priorities[valid_bins] = fill_ratios[valid_bins]\n\n    # Add a bonus for bins that are close to full after adding the item,\n    # but not perfectly full\n    remaining_after_fit = bins_remain_cap - item\n    nearly_full_bonus = np.exp(-10 * remaining_after_fit) * valid_bins # Apply the bonus. Larger K -> closer to full is preferred.\n\n    priorities += nearly_full_bonus\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins): # Ensure at least one feasible bin exists.\n        # Calculate wasted space if the item is placed in each feasible bin\n        wasted_space = bins_remain_cap[feasible_bins] - item\n\n        # Prioritize bins with smaller wasted space.  Use the inverse to make it a priority (higher is better)\n        # Add a small constant to avoid division by zero. We scale the wasted space to have reasonable priority values.\n        priorities[feasible_bins] = 1.0 / (0.001 + wasted_space)\n\n        # Add a bonus for bins that are nearly full *after* placement. This encourages\n        # using up the bins and leaving less unused capacity.  This is scaled.\n        near_full_threshold = 0.95 #Bins filled over this ratio after packing get a bonus.\n        filled_ratio_after_packing = (bins_remain_cap[feasible_bins]-item) / bins_remain_cap[feasible_bins] + item/ bins_remain_cap[feasible_bins] #Ratio after packing\n        bonus_mask = filled_ratio_after_packing >= near_full_threshold\n        priorities[feasible_bins][bonus_mask] += 10 #Increase priority by a const if it passes the threshold\n\n        # Slightly prioritise bins with higher remaining capacity before packing for load balancing reasons (unless they are almost full)\n        # Only add priority if the bin isn't almost full\n        # Scale to be a modest influence\n        # The intention is to break ties for the smallest-waste bin strategy.\n        nearly_full = bins_remain_cap[feasible_bins] / bins_remain_cap[feasible_bins] +item / bins_remain_cap[feasible_bins] > 0.95\n        priorities[feasible_bins][~nearly_full] += 0.1 * bins_remain_cap[feasible_bins][~nearly_full]/np.max(bins_remain_cap) # Scale the original capacity\n\n\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 39, in priority_v2\n    return priorities\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n3\n88.0\n78.11172779494449\n131\n"
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Invalid bins are given a very low priority\n    invalid_bins = bins_remain_cap < item\n    priorities[invalid_bins] = -np.inf\n\n    # Calculate the remaining capacity after adding the item\n    remaining_capacity_after_add = bins_remain_cap - item\n    \n    # Prioritize bins where the item fits, considering different heuristics\n    \n    # 1. Try to fill bins as much as possible without overfilling\n    #    priorities[~invalid_bins] = remaining_capacity_after_add[~invalid_bins] # Minimize remaining capacity\n\n    # 2. Give higher priority to bins where item is a good fit (fills a significant portion)\n    fit_ratio = item / bins_remain_cap\n    priorities[~invalid_bins] = fit_ratio[~invalid_bins]\n\n    # 3. Moderate the fit_ratio by remaining capacity to avoid filling almost empty bins\n    # priorities[~invalid_bins] = fit_ratio[~invalid_bins] * bins_remain_cap[~invalid_bins]\n\n    # 4. Prioritize nearly full bins while avoiding exact full capacity situation:\n    nearly_full_threshold = 0.9\n    nearly_full = (fit_ratio > nearly_full_threshold) & (~invalid_bins)\n    priorities[nearly_full] += 1 # A significant boost for nearly full bins.\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function considers several factors to determine the priority of placing an item into a bin:\n    1.  Residual Capacity: Bins with residual capacity closest to the item size get higher priority.\n    2.  Space Utilization: A penalty is applied for bins where the item would leave very little unused space (fragmentation).\n    3.  Bin Fullness: Bins that are already reasonably full are preferred.\n    4.  Handling cases where item exceeds available bin capacity.\n    5.  Relative fit based on standard deviation from average available capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Ineligible bins receive a very negative priority\n    ineligible_bins = bins_remain_cap < item\n    priorities[ineligible_bins] = -np.inf\n\n    # Calculate capacity differences, and make sure small positive values exist\n    cap_diffs = np.abs(bins_remain_cap - item)\n    cap_diffs[cap_diffs == 0] = 1e-6\n    \n    # Prefer bins with space equal to the size of the item, penalized when the item is too large\n    priorities = 1.0 / (cap_diffs + 0.00001)  # Adding a small number avoids division by zero\n    \n    # Penalize bins that would leave a tiny fragment of space\n    fragmentation_threshold = 0.1  # Define what constitutes \"tiny\" (e.g., 10% of bin size)\n    tiny_space_indices = (bins_remain_cap - item) < fragmentation_threshold\n    priorities[tiny_space_indices] *= 0.5  # Reduce priority if fragmentation would occur\n\n    # Promote bins that are already reasonably full\n    fullness = (1.0 - bins_remain_cap) # high fullness = low remaining cap, max value = 1\n    priorities += fullness * 0.2  # Add a bonus for fullness\n\n    # Add some stochastic noise to resolve near-identical fit choices.  A little random noise\n    # prevents being stuck at similar or same available capacities.\n    noise = np.random.normal(0, 0.01, size=bins_remain_cap.shape)\n    priorities += noise\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are a \"good fit\" for the item,\n    meaning the item fills a significant portion of the bin's remaining\n    capacity without leaving excessive wasted space.  It also introduces\n    a small penalty for bins that are almost completely full, as filling\n    them could lead to inefficient packing of subsequent items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            # Calculate fill ratio:  How much of the bin will be filled?\n            fill_ratio = item / capacity\n\n            # Base priority: Higher ratio (item fills more of the bin) is better.\n            priorities[i] = fill_ratio\n\n            # \"Sweet spot\" bonus: Give a bonus for fill ratios near a target\n            #  For example, aiming to fill roughly 75% of the bin\n            target_ratio = 0.75\n            bonus_strength = 0.5  # Adjust this to control the bonus effect\n            ratio_difference = abs(fill_ratio - target_ratio)\n            priorities[i] += bonus_strength * np.exp(-ratio_difference * 10) # gaussian peak centered around target_ratio\n\n            # Penalty for almost-full bins (discourages extremely small gaps)\n            if capacity - item < 0.1 * item: #Less than 10% of item left in the bin\n                priorities[i] -= 0.2 # Adjust this to control the penalty\n\n            #Extra Bonus if this fills the bin *almost* entirely\n            if capacity - item <= 0.01 * item:\n              priorities[i] += 1 # incentivize perfect fit.\n        else:\n            priorities[i] = -np.inf  # Impossible to place the item\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999974650000695 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Higher priority means we prefer adding the item to that bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Avoid division by zero\n    valid_bins = bins_remain_cap > 0\n\n    if not np.any(valid_bins):\n        return priorities # All bins are full or invalid\n\n    # 1. Immediate Fit: Bins that can fit the item perfectly or nearly perfectly\n    perfect_fit = np.abs(bins_remain_cap - item) < 1e-6  # Using a small tolerance\n    priorities[perfect_fit] += 100  # High priority for perfect fits\n\n    # 2. Best Fit: Bins with the smallest remaining capacity after adding the item (that still fits)\n    fits = bins_remain_cap >= item\n    if np.any(fits):\n        remaining_after_fit = bins_remain_cap[fits] - item\n        best_fit_idx = np.argmin(remaining_after_fit)\n        #Need to translate from the filtered index back to the index in the whole array\n        indices = np.where(fits)[0]\n        best_fit_full_idx = indices[best_fit_idx]\n        priorities[best_fit_full_idx] += 50 # Medium-High priority\n\n    # 3. Consider bin utilization\n    utilization_ratio = item / bins_remain_cap[valid_bins]\n    priorities[valid_bins] += utilization_ratio * 10  # Medium Priority, prioritize higher utilization\n\n    # 4. Avoid bins that barely fit the item\n    nearly_full = (bins_remain_cap > item) & (bins_remain_cap < item * 1.1) #avoid creating near empty bins.\n    priorities[nearly_full] -= 20 # Slightly negative priority\n\n    # 5. Penalize bins that don't fit at all (makes them less likely to be chosen if there are multiple options and the other bonuses balance out)\n    no_fit = bins_remain_cap < item\n    priorities[no_fit] -= 1  #Very slightly negative\n\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Utilizes a combination of remaining capacity, waste, and a touch of chaos.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to zero\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give a high priority to bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] += 1.0  # Base priority for fitting\n\n    # Prioritize bins that leave minimal waste after fitting. Scale by item size to prefer packing smaller items first.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Avoid negative waste calculation for bins that cannot fit\n    waste_priority = np.exp(-waste / item)  # Exponential decay: Less waste = Higher priority. Scaled by item.\n    priorities += waste_priority\n\n    # Slight bonus for bins that are closer to being full after adding the item. Sigmoid function to limit boost.\n    fraction_full = (1 - (bins_remain_cap - item) / np.max(bins_remain_cap)) * fit_mask\n    fullness_priority = 1 / (1 + np.exp(-5 * (fraction_full - 0.5)))  # Sigmoid around 0.5\n    priorities += fullness_priority * 0.5  # Limited boost\n\n    # Add a tiny bit of random noise to break ties. This might lead to better exploration.\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.001\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Considers remaining capacity and avoids nearly-full bins if possible.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Give very low priority to bins that cannot fit the item\n    infeasible = bins_remain_cap < item\n    priorities[infeasible] = -np.inf\n    \n    # Give higher priority to bins that are close to being full after adding the item,\n    # but avoid extremely tight fits\n    \n    feasible = ~infeasible\n    \n    if np.any(feasible):\n        fill_ratios = item / bins_remain_cap[feasible]\n        \n        # Scale to give bins that are filled the most a higher value but less than one that can not fit.\n        priorities[feasible] = 1.0 / (1.0 + np.abs(1 - fill_ratios))\n        \n        #Adjust priorities based on remaining space after adding the item\n        remaining_space = bins_remain_cap[feasible] - item\n        \n        # AVOID SMALL REMAINING SPACE\n        # Penalize bins that would have a very small remaining capacity after placing the item.\n        small_space_penalty = np.exp(-remaining_space) # exponentially decaying penalty\n        priorities[feasible] *= small_space_penalty\n\n        # If all bins that can fit have very low score, boost bin the lowest fill_ratio for the sake of progress\n        if np.all(priorities[feasible] < 0.01):\n           fill_ratios = item / bins_remain_cap[feasible]\n           idx_min = np.argmin(fill_ratios) # Pick minimum remaining\n           priorities[feasible][idx_min] = 0.1\n\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Incorporates several heuristics:\n       1. First-Fit Decreasing (FFD) inspired: Prioritizes bins with enough space, penalizes almost-full bins.\n       2. Best-Fit inspired: Maximizes used space, avoiding excessive fragmentation.\n       3. Prevents thrashing: Penalizes bins very close in size to the item, leading to small remaining space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Base priority: higher remaining capacity means higher initial priority, encouraging first fit.\n            priorities[i] = cap\n\n            # Best-fit inspired: prioritize bins that are a close fit\n            priorities[i] += (item / cap)\n\n            # Prevent thrashing/fragmentation\n            remaining_after_fit = cap - item\n            if remaining_after_fit > 0:\n                priorities[i] -= np.abs(item - cap) / (item + cap + 1e-9)  # Penalize similar sized bins. Prevent trivial division by zero\n                priorities[i] -= (1/(remaining_after_fit + 0.0001)) if remaining_after_fit < 0.2 else 0 # strongly penalize if remmainder is very small\n\n            else:\n                 priorities[i] -=100  # make the bin very unattractive.\n                 # Ensure it's heavily penalized for completely filling the bin or creating negative remaining capacity\n\n        else:\n            priorities[i] = -np.inf # impossible to fit -> extremely low priority.\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. First-Fit Decreasing Heuristic Inspired:  Prioritize bins that can fit the item with least wasted space.\n    #    This reduces fragmentation.\n    potential_waste = bins_remain_cap - item\n    fit_mask = potential_waste >= 0\n    \n    if np.any(fit_mask):\n        priorities[fit_mask] += 1.0 / (potential_waste[fit_mask] + 1e-9) # avoid div by zero\n        \n    # 2. Encourage re-use: Prioritize bins that are already somewhat full, to fill them up completely.\n    #   This reduces the number of bins opened.  Sigmoid-like behavior to boost priority for near-full bins.\n    fill_ratio = (bins_remain_cap - item) / bins_remain_cap if np.any(bins_remain_cap >0) else 0\n    fill_ratio = np.clip(fill_ratio, 0, 1)\n    \n    priorities[fit_mask] += (1 / (1 + np.exp(-10 * (1 - fill_ratio[fit_mask])))) *0.5  # scale it down, exp can explode\n\n    # 3. Penalty for bins that are too empty for this item\n    empty_mask = potential_waste < 0\n    priorities[empty_mask] -= 0.1 # Small penalty\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Avoid division by zero\n    valid_bins = bins_remain_cap > 0\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    if np.any(valid_bins):\n        remaining_cap_valid = bins_remain_cap[valid_bins]\n\n        # First priority: Can the item fit at all?\n        can_fit = item <= remaining_cap_valid\n        \n        #If it cannot fit anywhere, assign all priorities 0\n        if not np.any(can_fit):\n            return priorities\n        \n        # Next priority: Minimize wasted space.  The closer the item size\n        # is to the remaining capacity, the higher the priority.  We want\n        # to fill the bins as completely as possible. Use only bins where the item fits.\n        waste = remaining_cap_valid - item\n        waste[waste < 0] = np.inf # very large value\n\n        #Give only the available bins priorities\n        valid_bins_indices = np.where(valid_bins)[0]\n        \n        waste_valid_can_fit = waste[can_fit]\n\n        priorities_valid_can_fit = -waste_valid_can_fit # Smaller waste is better (negative of waste).\n\n        can_fit_indices_in_valid = np.where(can_fit)[0]\n        can_fit_global_indices = valid_bins_indices[can_fit_indices_in_valid]\n\n        priorities[can_fit_global_indices] = priorities_valid_can_fit\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can accommodate the item with minimal wasted space,\n    but also penalizes bins that are nearly full to encourage more balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        if remaining_capacity >= item:\n            # Calculate wasted space\n            wasted_space = remaining_capacity - item\n\n            # Prioritize bins with smaller wasted space (higher priority)\n            # Add a small constant to avoid division by zero and extreme values. Also, prevents inf from arising from np.exp(-x) = inf when x approaches -inf\n\n            priorities[i] = np.exp(-wasted_space)  # Exponential decay for wasted space\n            # Penalize bins that are almost full. Avoids putting small items in near-full bins.\n            # Scale this penalty based on how full the bin becomes after placing the item. Prevents bins that become very full from being excessively favored.\n\n            fullness_after = item / remaining_capacity\n            priorities[i] *= (1 - fullness_after)**0.5  # Apply diminishing returns penalty for nearly full bins\n        else:\n            priorities[i] = -np.inf  # Disqualify bins that cannot fit the item\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  }
]