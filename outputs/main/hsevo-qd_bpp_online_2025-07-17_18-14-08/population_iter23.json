[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Tesla's embodiment of electrical elegance: A symphony of potential.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid zero capacity bins and division by zero.\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)  # Default to negative infinity.\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n\n        # Calculate the waste if we place the item in each bin. A lower waste\n        # suggests a better fit. Avoid negative waste using max(0).\n        waste = np.maximum(0, remaining_capacities - item)\n\n        # Score based on the inverse of the waste. To give higher preference to minimal waste\n        waste_score = 1 / (waste + 1e-9) # Adding a small value to avoid division by zero\n        \n        # Fit Score\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/3)**2)) # Gaussian Fit score favoring item to fit nicely in the bin.\n\n        # Preference for bins that can accommodate the item. Also incorporate remaining capacity\n        # to prioritize using more full bins first.\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Combine the scoring components. Give weights to components\n        combined_score = 0.6 * waste_score + 0.3 * fit_score + 0.1 * capacity_utilization\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 4,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 88.0,
    "mi": 78.11172779494449,
    "token_count": 131.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, perfect-fit, and waste minimization strategies.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Perfect Fit: Highest priority\n    perfect_fit = np.abs(bins_remain_cap - item) < 1e-6\n    priorities[perfect_fit] += 100\n\n    # 2. Best Fit: Reward bins that fit with minimal waste.\n    fits = bins_remain_cap >= item\n    if np.any(fits):\n        waste = bins_remain_cap[fits] - item\n        best_fit_idx = np.argmin(waste)\n        indices = np.where(fits)[0]\n        best_fit_full_idx = indices[best_fit_idx]\n        priorities[best_fit_full_idx] += 50\n\n    # 3. Utilization Ratio:  Prioritize bins that are well-utilized after placing item.\n    valid_bins = bins_remain_cap > 0\n    utilization_ratio = item / bins_remain_cap[valid_bins]\n    priorities[valid_bins] += utilization_ratio * 10\n\n    # 4. Waste Minimization with Exponential Decay: Penalize larger waste values heavily.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Ignore bins that don't fit\n    priorities -= np.exp(-(waste**2) / (2 * (item / 5)**2)) * 20\n\n    # 5. Avoid Nearly Full: Discourage leaving tiny spaces.\n    nearly_full = (bins_remain_cap > item) & (bins_remain_cap < item * 1.1)\n    priorities[nearly_full] -= 30\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 210.90827503317323,
    "mi": 89.26677282872086,
    "token_count": 152.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Enhanced heuristic combining waste, fit, and remaining capacity considerations with adaptive elements.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n        \n        # Waste Score (Prioritize minimal waste)\n        waste = np.maximum(0, remaining_capacities - item)\n        waste_score = 1 / (waste + 1e-9)\n\n        # Fit Score (Gaussian-like, penalizing very tight or loose fits)\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item / 2)**2))  # Adjusted std for potentially better fit\n\n        # Capacity Utilization Score (Encourage filling bins)\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Remaining Capacity Score (favor bins with low remianing capacity)\n        remaining_capacity_score = 1 / (remaining_capacities + 1e-9)\n        \n        # Adaptive Weighting based on Item Size relative to Average Bin Size\n        avg_bin_capacity = np.mean(bins_remain_cap[bins_remain_cap > 0]) if np.any(bins_remain_cap > 0) else 1  # Avoid division by zero if all bins are full\n        item_ratio = item / avg_bin_capacity if avg_bin_capacity > 0 else 0 # normalize the item size relative to the average bin capacity\n\n        # Dynamic weight adjustment\n        if item_ratio < 0.2:\n             w_waste, w_fit, w_capacity, w_rem_cap = 0.3, 0.5, 0.1, 0.1  # Favor Fit for small items\n        elif item_ratio > 0.8:\n            w_waste, w_fit, w_capacity, w_rem_cap = 0.6, 0.1, 0.2, 0.1  # Favor Waste for large items\n        else:\n            w_waste, w_fit, w_capacity, w_rem_cap = 0.4, 0.3, 0.2, 0.1 # balanced weights otherwise\n\n        # Combined Score with Adaptive Weights\n        combined_score = (\n            w_waste * waste_score +\n            w_fit * fit_score +\n            w_capacity * capacity_utilization +\n            w_rem_cap * remaining_capacity_score\n        )\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 31.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 424.4571500548079,
    "mi": 78.30227068447415,
    "token_count": 279.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, perfect-fit, and waste minimization dynamically.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Perfect Fit: Highest priority\n    perfect_fit = np.abs(bins_remain_cap - item) < 1e-6\n    priorities[perfect_fit] += 100\n\n    # 2. Best Fit: Reward bins that fit with minimal waste.\n    fits = bins_remain_cap >= item\n    if np.any(fits):\n        waste = bins_remain_cap[fits] - item\n        best_fit_idx = np.argmin(waste)\n        indices = np.where(fits)[0]\n        best_fit_full_idx = indices[best_fit_idx]\n        priorities[best_fit_full_idx] += 50\n\n    # 3. Utilization Ratio:  Prioritize bins that are well-utilized after placing item.\n    valid_bins = bins_remain_cap > 0\n    utilization_ratio = item / bins_remain_cap[valid_bins]\n    priorities[valid_bins] += utilization_ratio * 10\n\n    # 4. Waste Minimization with Exponential Decay: Penalize larger waste values heavily.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Ignore bins that don't fit\n    priorities -= np.exp(-(waste**2) / (2 * (item / 5)**2)) * 20\n\n    # 5. Avoid Nearly Full: Discourage leaving tiny spaces.\n    nearly_full = (bins_remain_cap > item) & (bins_remain_cap < item * 1.1)\n    priorities[nearly_full] -= 30\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 6.0,
    "halstead": 380.5489597580819,
    "mi": 80.09612404056372,
    "token_count": 275.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, waste_score_weight: float = 0.41627733379514453,\n                fit_score_weight: float = 0.5933483607555398, capacity_utilization_weight: float = 0.9062105720810719,\n                gaussian_fit_scale: float = 1.19900708155265,  avoid_zero_division: float = 6.252288452065697e-07) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Tesla's embodiment of electrical elegance: A symphony of potential.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_score_weight: Weight for waste score in combined score.\n        fit_score_weight: Weight for fit score in combined score.\n        capacity_utilization_weight: Weight for capacity utilization in combined score.\n        gaussian_fit_scale: Scale factor for Gaussian fit score calculation.\n        avoid_zero_division: Small value to avoid division by zero.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid zero capacity bins and division by zero.\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)  # Default to negative infinity.\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n\n        # Calculate the waste if we place the item in each bin. A lower waste\n        # suggests a better fit. Avoid negative waste using max(0).\n        waste = np.maximum(0, remaining_capacities - item)\n\n        # Score based on the inverse of the waste. To give higher preference to minimal waste\n        waste_score = 1 / (waste + avoid_zero_division) # Adding a small value to avoid division by zero\n        \n        # Fit Score\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/gaussian_fit_scale)**2)) # Gaussian Fit score favoring item to fit nicely in the bin.\n\n        # Preference for bins that can accommodate the item. Also incorporate remaining capacity\n        # to prioritize using more full bins first.\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Combine the scoring components. Give weights to components\n        combined_score = waste_score_weight * waste_score + fit_score_weight * fit_score + capacity_utilization_weight * capacity_utilization\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 284.3458750793272,
    "mi": 70.4017182826777,
    "token_count": 213.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste, fit, and capacity utilization with adaptive weighting.\"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n        waste = np.maximum(0, remaining_capacities - item)\n        waste_score = 1 / (waste + 1e-9)\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/3)**2))\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Adaptive Weighting (simplified example)\n        waste_weight = 0.5\n        fit_weight = 0.4\n        capacity_weight = 0.1\n\n        combined_score = waste_weight * waste_score + fit_weight * fit_score + capacity_weight * capacity_utilization\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 382.1602133046108,
    "mi": 77.98648916677364,
    "token_count": 222.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       A bin-packing heuristic that adapts based on item size and bin availability.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if not np.any(valid_bins):\n        return priorities\n\n    remaining_capacities = bins_remain_cap[valid_bins]\n\n    # Waste calculation with avoidance of negative values\n    waste = np.maximum(0, remaining_capacities - item)\n\n    # Waste score: inverse of waste, with a small constant to avoid division by zero\n    waste_score = 1 / (waste + 1e-9)\n\n    # Fit score: Gaussian fit score, penalizing significant deviations from the ideal fit.\n    fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item / 3)**2))\n\n    # Capacity utilization score: Prioritize filling bins that are already relatively full.\n    capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n    # Item size-adaptive weighting: adjust weights based on the item size\n    if item > np.mean(bins_remain_cap):  # Large item\n        waste_weight = 0.2\n        fit_weight = 0.6\n        capacity_weight = 0.2\n    elif item < np.mean(bins_remain_cap) / 2:  # Small item\n        waste_weight = 0.6\n        fit_weight = 0.2\n        capacity_weight = 0.2\n    else:  # Medium item\n        waste_weight = 0.4\n        fit_weight = 0.4\n        capacity_weight = 0.2\n\n    # Combined score with dynamically adjusted weights\n    combined_score = (waste_weight * waste_score +\n                      fit_weight * fit_score +\n                      capacity_weight * capacity_utilization)\n\n    priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 340.6033980727912,
    "mi": 79.58491521503973,
    "token_count": 214.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit and waste minimization, with adaptive weighting.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Perfect Fit: Highest priority\n    perfect_fit = np.abs(bins_remain_cap - item) < 1e-6\n    priorities[perfect_fit] += 100\n\n    # Best Fit: Reward bins that fit with minimal waste.\n    fits = bins_remain_cap >= item\n    if np.any(fits):\n        waste = bins_remain_cap[fits] - item\n        best_fit_idx = np.argmin(waste)\n        indices = np.where(fits)[0]\n        best_fit_full_idx = indices[best_fit_idx]\n        priorities[best_fit_full_idx] += 50\n\n    #Adaptive Weighting, prioritizing bins that utilize capacity well\n    valid_bins = bins_remain_cap > 0\n    utilization_ratio = item / bins_remain_cap[valid_bins]\n    avg_utilization = np.mean(utilization_ratio) if utilization_ratio.size > 0 else 0\n    weight_utilization = 10 if avg_utilization > 0.5 else 5 #Increase weight for high avg utilization\n    priorities[valid_bins] += utilization_ratio * weight_utilization\n\n    # Penalize larger waste exponentially.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf\n    priorities -= np.exp(-(waste**2) / (2 * (item / 5)**2)) * 20\n\n    # Avoid Nearly Full bins, discourages leaving tiny spaces.\n    nearly_full = (bins_remain_cap > item) & (bins_remain_cap < item * 1.1)\n    priorities[nearly_full] -= 30\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 247.1753118485642,
    "mi": 76.56534287473863,
    "token_count": 203.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       An improved version incorporating adaptive weighting and contextual awareness.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins = bins_remain_cap >= item\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n\n        # Waste Score: Prioritize bins with minimal waste after placement.\n        waste = remaining_capacities - item\n        waste_score = 1 / (waste + 1e-9)\n\n        # Fit Score: Gaussian distribution centered around ideal remaining capacity.\n        fit_score = np.exp(-(remaining_capacities - 2 * item/3)**2 / (2 * (item/3)**2))\n\n        # Capacity Utilization: Encourage filling bins to a higher percentage.\n        capacity_utilization = remaining_capacities / np.max(bins_remain_cap)\n\n        # Number of Possible items that can fit in each bin\n        possible_items_fit = np.floor(remaining_capacities/item)\n\n        # Adaptive Weighting based on Item Size and Bin Capacities:\n        item_ratio = item / np.max(bins_remain_cap) # Ratio of the item size to the maximum bin capacity.\n\n        # Adjust weights based on item size relative to bin sizes.\n        waste_weight = 0.5 if item_ratio < 0.3 else 0.3\n        fit_weight = 0.3 if item_ratio < 0.3 else 0.5\n        capacity_weight = 0.2\n\n        # Combined Score with Adaptive Weights:\n        combined_score = (waste_weight * waste_score +\n                          fit_weight * fit_score +\n                          capacity_weight * (1 - capacity_utilization))\n\n        priorities[valid_bins] = combined_score\n\n    # If no bin can accommodate the item, consider bins with enough space to use later.\n    else:\n        valid_bins = bins_remain_cap > 0\n        if np.any(valid_bins):\n          remaining_capacities = bins_remain_cap[valid_bins]\n\n          # Prioritize bins with larger remaining capacity even if they cannot fit the current item\n          capacity_score = remaining_capacities / np.max(bins_remain_cap)\n          priorities[valid_bins] = capacity_score / 10  # Lower priority since the item doesn't fit\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "halstead": 342.88332829555736,
    "mi": 81.96238466087821,
    "token_count": 240.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, waste minimization, and adaptive weighting.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Perfect Fit: Highest priority\n    perfect_fit = np.abs(bins_remain_cap - item) < 1e-6\n    priorities[perfect_fit] += 100\n\n    # Best Fit: Reward bins that fit with minimal waste.\n    fits = bins_remain_cap >= item\n    if np.any(fits):\n        waste = bins_remain_cap[fits] - item\n        best_fit_idx = np.argmin(waste)\n        indices = np.where(fits)[0]\n        best_fit_full_idx = indices[best_fit_idx]\n        priorities[best_fit_full_idx] += 50\n\n    #Adaptive Weighting, prioritizing bins that utilize capacity well\n    valid_bins = bins_remain_cap > 0\n    utilization_ratio = item / bins_remain_cap[valid_bins]\n    avg_utilization = np.mean(utilization_ratio) if utilization_ratio.size > 0 else 0\n    weight_utilization = 10 if avg_utilization > 0.5 else 5 #Increase weight for high avg utilization\n    priorities[valid_bins] += utilization_ratio * weight_utilization\n\n    # Penalize larger waste exponentially. Gaussian fit score\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf\n    priorities -= np.exp(-(waste**2) / (2 * (item / 5)**2)) * 20\n\n    # Avoid Nearly Full bins, discourages leaving tiny spaces.\n    nearly_full = (bins_remain_cap > item) & (bins_remain_cap < item * 1.1)\n    priorities[nearly_full] -= 30\n    \n    #Waste Score: Adaptive Weighting, combines best-fit and waste minimization.\n    waste_score = np.zeros_like(bins_remain_cap, dtype=float)\n    fits = bins_remain_cap >= item\n    if np.any(fits):\n        waste = bins_remain_cap[fits] - item\n        waste_score[fits] = np.exp(-waste / (item + 1e-9)) #Adaptive scaling\n        priorities += waste_score * 10 # Combine with existing priorities\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 351.24725426256595,
    "mi": 75.80685537628476,
    "token_count": 219.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response0.txt_stdout.txt",
    "code_path": "problem_iter15_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    A refined heuristic for bin packing, leveraging adaptive weighting.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n\n        waste = np.maximum(0, remaining_capacities - item)\n        waste_score = 1 / (waste + 1e-9)\n\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/3)**2))\n\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Adaptive Weighting based on item size and remaining capacities\n        item_size_ratio = item / np.max(bins_remain_cap) #Relative to largest bin\n        \n        #Weight adjustments\n        waste_weight = 0.5 if item_size_ratio < 0.3 else 0.3 #Smaller items prioritize waste\n        fit_weight = 0.4 if item_size_ratio > 0.5 else 0.6 #Larger items prioritize fit\n        capacity_weight = 0.1\n\n        # Combined Score\n        combined_score = waste_weight * waste_score + fit_weight * fit_score + capacity_weight * capacity_utilization\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 401.6905686335309,
    "mi": 80.73619208458098,
    "token_count": 234.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste, fit, and capacity with adaptive weighting for bin selection.\"\"\"\n\n    valid_bins = bins_remain_cap >= item\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n\n        # Waste Score\n        waste = remaining_capacities - item\n        waste_score = 1 / (waste + 1e-9)\n\n        # Fit Score\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/2)**2))\n\n        # Capacity Utilization\n        capacity_utilization = remaining_capacities / np.max(bins_remain_cap)\n\n        # Adaptive Weighting\n        item_ratio = item / np.max(bins_remain_cap)\n        waste_weight = 0.5 if item_ratio < 0.4 else 0.3\n        fit_weight = 0.3 if item_ratio < 0.4 else 0.5\n        capacity_weight = 0.2\n\n        combined_score = (waste_weight * waste_score +\n                          fit_weight * fit_score +\n                          capacity_weight * (1 - capacity_utilization))\n\n        priorities[valid_bins] = combined_score\n    else:\n        valid_bins = bins_remain_cap > 0\n        if np.any(valid_bins):\n          remaining_capacities = bins_remain_cap[valid_bins]\n          capacity_score = remaining_capacities / np.max(bins_remain_cap)\n          priorities[valid_bins] = capacity_score / 10\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "halstead": 441.88495648456103,
    "mi": 78.27825679842032,
    "token_count": 253.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Adaptive weights based on bin utilization and item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n        \n        waste = np.maximum(0, remaining_capacities - item)\n        waste_score = 1 / (waste + 1e-9)\n\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/3)**2))\n\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Adaptive weights based on item size and bin utilization.\n        item_size_ratio = item / np.max(bins_remain_cap)  # Ratio of item size to max bin capacity\n        bin_utilization_ratio = 1 - (remaining_capacities / np.max(bins_remain_cap)) # Current bin utilization\n\n        # Adjust weights based on item size.\n        if item_size_ratio > 0.5:\n            # Large item: Prioritize waste and fit to avoid fragmentation.\n            waste_weight = 0.7\n            fit_weight = 0.3\n            capacity_weight = 0.0\n        elif item_size_ratio > 0.2:\n            # Medium item: Balance waste, fit, and utilization.\n            waste_weight = 0.5\n            fit_weight = 0.3\n            capacity_weight = 0.2\n        else:\n            # Small item: Prioritize utilization to fill bins.\n            waste_weight = 0.3\n            fit_weight = 0.3\n            capacity_weight = 0.4\n            \n        # Adaptive weight adjustment based on bin utilization\n        if np.any(bin_utilization_ratio > 0.8): # If any bin is more than 80% full, prioritize fitting.\n            waste_weight += 0.1\n            fit_weight += 0.1\n            capacity_weight -= 0.2\n            \n        waste_weight = np.clip(waste_weight, 0, 1) #Making sure weights are between 0 and 1\n        fit_weight = np.clip(fit_weight, 0, 1)\n        capacity_weight = np.clip(capacity_weight, 0, 1)\n\n        combined_score = waste_weight * waste_score + fit_weight * fit_score + capacity_weight * capacity_utilization\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 29.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 361.28526732617695,
    "mi": 77.61177417928876,
    "token_count": 269.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, gaussian fit score, and capacity utilization.\"\"\"\n\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n\n        waste = np.maximum(0, remaining_capacities - item)\n        waste_score = 1 / (waste + 1e-9)\n\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/3)**2))\n\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        combined_score = 0.5 * waste_score + 0.4 * fit_score + 0.1 * capacity_utilization\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 31.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 630.168208774188,
    "mi": 74.49231552017007,
    "token_count": 352.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response4.txt_stdout.txt",
    "code_path": "problem_iter21_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       A multifactorial, adaptive approach to bin selection.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n    valid_bins = bins_remain_cap > 0\n\n    if not np.any(valid_bins):\n        return priorities\n\n    remaining_capacities = bins_remain_cap[valid_bins]\n\n    # Waste Score: Prioritize bins with minimal waste\n    waste = np.maximum(0, remaining_capacities - item)\n    waste_score = 1 / (waste + 1e-9)\n\n    # Fit Score: Gaussian fit, as before, but potentially refined\n    fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item / 3)**2))\n\n    # Capacity Utilization: Favor bins that are already somewhat full\n    capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n    # Remaining Capacity Score: Discourage very small remaining capacity\n    remaining_capacity_score = np.where(remaining_capacities > item, remaining_capacities / np.max(bins_remain_cap), 0) # Only if it can fit, favor higher remaining capacity.\n\n    # Item Size Score: adapt based on item size. Big items need better fit.\n    item_size_factor = min(1, item)  # Scale factor based on item size.  Cap at 1.\n\n    # Adaptive Weighting: Adjust weights based on item size.  Heuristic core.\n    waste_weight = 0.4 * (1 - item_size_factor/2) # smaller item, higher waste weight.\n    fit_weight = 0.4 * (0.5 + item_size_factor/2)   # Bigger item, higher fit weight.\n    capacity_weight = 0.1 * (1 - item_size_factor/2) # smaller item, higher capacity weight.\n    remaining_weight = 0.1 * (0.5 + item_size_factor/2)  # Bigger item, higher remaining capacity.\n\n    # Combined Score\n    combined_score = (\n        waste_weight * waste_score +\n        fit_weight * fit_score +\n        capacity_weight * capacity_utilization +\n        remaining_weight * remaining_capacity_score\n    )\n\n    priorities[valid_bins] = combined_score\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 3.8990825688073536,
    "SLOC": 24.0,
    "cyclomatic_complexity": 2.0,
    "halstead": 607.0427699200893,
    "mi": 79.15008125946002,
    "token_count": 278.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter22_response0.txt_stdout.txt",
    "code_path": "problem_iter22_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, waste_score_epsilon: float = 2.3676299678948093e-09,\n                large_item_threshold: float = 0.5152608427120331, medium_item_threshold: float = 0.11232322272170905,\n                large_item_waste_weight: float = 0.7922777406161803, large_item_fit_weight: float = 0.366663934509556, large_item_capacity_weight: float = -0.042049719220680216,\n                medium_item_waste_weight: float = 0.5847694031591075, medium_item_fit_weight: float = 0.3765469275232734, medium_item_capacity_weight: float = 0.10612888335318736,\n                small_item_waste_weight: float = 0.23402459284841715, small_item_fit_weight: float = 0.22412856156232097, small_item_capacity_weight: float = 0.38991632701567336,\n                bin_utilization_threshold: float = 0.8178247005642613, bin_utilization_waste_adjust: float = 0.1947381836237003,\n                bin_utilization_fit_adjust: float = 0.1659780275520785, bin_utilization_capacity_adjust: float = -0.19020181378233386) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       Adaptive weights based on bin utilization and item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_score_epsilon: Small value to prevent division by zero in waste score calculation.\n        large_item_threshold: Item size ratio above which an item is considered large.\n        medium_item_threshold: Item size ratio above which an item is considered medium.\n        large_item_waste_weight: Weight for waste score when item is large.\n        large_item_fit_weight: Weight for fit score when item is large.\n        large_item_capacity_weight: Weight for capacity utilization when item is large.\n        medium_item_waste_weight: Weight for waste score when item is medium.\n        medium_item_fit_weight: Weight for fit score when item is medium.\n        medium_item_capacity_weight: Weight for capacity utilization when item is medium.\n        small_item_waste_weight: Weight for waste score when item is small.\n        small_item_fit_weight: Weight for fit score when item is small.\n        small_item_capacity_weight: Weight for capacity utilization when item is small.\n        bin_utilization_threshold: Bin utilization ratio above which adjustment to weights is applied.\n        bin_utilization_waste_adjust: Adjustment to waste weight when bin utilization is high.\n        bin_utilization_fit_adjust: Adjustment to fit weight when bin utilization is high.\n        bin_utilization_capacity_adjust: Adjustment to capacity weight when bin utilization is high.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n        \n        waste = np.maximum(0, remaining_capacities - item)\n        waste_score = 1 / (waste + waste_score_epsilon)\n\n        fit_score = np.exp(-(remaining_capacities - item)**2 / (2 * (item/3)**2))\n\n        capacity_utilization = 1 - (remaining_capacities / np.max(bins_remain_cap))\n\n        # Adaptive weights based on item size and bin utilization.\n        item_size_ratio = item / np.max(bins_remain_cap)  # Ratio of item size to max bin capacity\n        bin_utilization_ratio = 1 - (remaining_capacities / np.max(bins_remain_cap)) # Current bin utilization\n\n        # Adjust weights based on item size.\n        if item_size_ratio > large_item_threshold:\n            # Large item: Prioritize waste and fit to avoid fragmentation.\n            waste_weight = large_item_waste_weight\n            fit_weight = large_item_fit_weight\n            capacity_weight = large_item_capacity_weight\n        elif item_size_ratio > medium_item_threshold:\n            # Medium item: Balance waste, fit, and utilization.\n            waste_weight = medium_item_waste_weight\n            fit_weight = medium_item_fit_weight\n            capacity_weight = medium_item_capacity_weight\n        else:\n            # Small item: Prioritize utilization to fill bins.\n            waste_weight = small_item_waste_weight\n            fit_weight = small_item_fit_weight\n            capacity_weight = small_item_capacity_weight\n            \n        # Adaptive weight adjustment based on bin utilization\n        if np.any(bin_utilization_ratio > bin_utilization_threshold): # If any bin is more than 80% full, prioritize fitting.\n            waste_weight += bin_utilization_waste_adjust\n            fit_weight += bin_utilization_fit_adjust\n            capacity_weight += bin_utilization_capacity_adjust\n            \n        waste_weight = np.clip(waste_weight, 0, 1) #Making sure weights are between 0 and 1\n        fit_weight = np.clip(fit_weight, 0, 1)\n        capacity_weight = np.clip(capacity_weight, 0, 1)\n\n        combined_score = waste_weight * waste_score + fit_weight * fit_score + capacity_weight * capacity_utilization\n\n        priorities[valid_bins] = combined_score\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 39.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 455.4762858375663,
    "mi": 74.63024451098171,
    "token_count": 432.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response0.txt_stdout.txt",
    "code_path": "problem_iter23_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with a capacity ratio, adaptively.\"\"\"\n    valid_bins = bins_remain_cap > 0\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    if np.any(valid_bins):\n        remaining_capacities = bins_remain_cap[valid_bins]\n        waste = np.maximum(0, remaining_capacities - item)\n        waste_score = 1 / (waste + 1e-9)  # Avoid division by zero\n\n        capacity_ratio = item / remaining_capacities\n        capacity_score = np.exp(-np.abs(capacity_ratio - 1)) # Prefer bins where item size approx matches remaining capacity\n\n        combined_score = 0.7 * waste_score + 0.3 * capacity_score\n        priorities[valid_bins] = combined_score\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 34.0,
    "cyclomatic_complexity": 5.0,
    "halstead": 466.5854635409216,
    "mi": 46.95734920314081,
    "token_count": 318.0,
    "exec_success": true
  }
]