{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a combination of factors inspired by physical principles\n    (though adapted for this computational problem).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A 'gravitational' attraction: Higher priority for bins closer to item size.\n    # Use squared difference for a stronger pull when very close\n    diff = np.abs(bins_remain_cap - item)\n    priorities = 1.0 / (1e-6 + diff**2)  # 1e-6 avoids division by zero\n\n    # Inverse 'repulsion': lower priority for bins with very little space.\n    # Mimicking Pauli Exclusion Principle (sort of). Prevent overfilling attempts.\n    small_space_penalty = np.where(bins_remain_cap < item, -np.inf, 0)\n    priorities += small_space_penalty\n\n    # Favor bins with more capacity available (but not too much)\n    # A larger bin reduces the number of bins in total, improving our goal\n    capacity_bonus = np.clip(bins_remain_cap - item, 0, item * 2) # Cap bonus\n    priorities += capacity_bonus * 0.1 # Tune bonus effect, otherwise domination.\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see 1st uses a combined score of capacity and waste, with exponential decay for waste close to 0, while 20th prioritizes based on remaining capacity, item/cap ratio, and penalizes similar sized bins. 1st's approach of combining capacity and waste appears more effective.\n\nComparing (2nd) vs (19th), we see 2nd prioritizes bins that fit the item well and aren't too empty afterwards with scaling and negative penalization, while 19th simply uses log ratios of item size to remaining capacity. The more complex scaling and penalization in 2nd are beneficial.\n\nComparing (1st) vs (2nd), we see 1st uses exponential decay for waste minimization and combines capacity and waste scores, while 2nd focuses on scaling based on bin fullness after packing and penalizing bins that are too large or empty. The difference lies in the specific functions used to combine capacity and waste.\n\nComparing (3rd) vs (4th), we see 3rd gives high priority to bins that can fit the item with small waste and penalizes bins that cannot fit, while 4th prioritizes based on perfect fit, best fit, utilization ratio, and avoids nearly full bins. 4th uses specific bonuses and penalties, while 3rd is simpler with waste minimization.\n\nComparing (2nd) vs (3rd), we see that 2nd uses a squared ratio and capacity normalization, while 3rd uses simple inverse of waste and assigns binary priorities based on nearly full condition.\n\nComparing (19th) vs (20th), we see that 19th uses the log ratio, while 20th computes the priority based on remaining capacity, item/cap ratio and penalizes similar sized bins as the items.\n\nOverall: The better heuristics incorporate a balance between remaining capacity, waste minimization, and avoidance of nearly full bins, often using exponential functions or scaling to fine-tune the priorities. Simpler approaches such as just log ratio are less effective. The best heuristics contain several components of First-Fit-Decreasing and Best-Fit. The more elaborate and fine-grained that the penalties were, the better.\n- \nOkay, let's redefine current self-reflection for heuristic design, focusing on actionable insights and avoiding pitfalls.\n\n*   **Keywords:** Adaptive, Iterative, Performance Metrics, Solution Space Analysis.\n*   **Advice:** Design heuristics iteratively, using performance metrics to guide refinements. Analyze the solution space to understand heuristic behavior. Adapt the heuristic's parameters based on feedback.\n*   **Avoid:** Premature optimization, neglecting edge cases, rigid parameter settings, lack of performance tracking.\n*   **Explanation:** Move beyond static combinations. Focus on adaptive strategies that learn from past performance, explore the solution space effectively, and dynamically adjust to different problem instances.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}