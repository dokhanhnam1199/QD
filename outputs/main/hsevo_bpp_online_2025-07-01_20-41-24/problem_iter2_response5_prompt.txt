{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Eliminate bins that cannot fit the item.\n    feasible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Prioritize bins where the item fills a significant portion of the remaining space\n    # but doesn't overfill it too much.\n\n    fill_ratio = item / bins_remain_cap\n    priorities[feasible_bins] = fill_ratio[feasible_bins]\n\n    # Add a bonus for bins that are almost full after adding the item\n    almost_full = (bins_remain_cap - item) < 0.1  # Threshold for \"almost full\"\n    priorities[feasible_bins & almost_full] += 0.5 # add a fixed score to increase chances of near-perfect fit\n   \n    # Introduce a penalty for fragmentation -- smaller remainder gives higher priority\n    remainder = bins_remain_cap - item\n    priorities[feasible_bins] += (1 - (remainder[feasible_bins] / np.max(bins_remain_cap)))*0.2\n   \n    # Invert remaining capacity; smaller gives bigger priority.  Scales remaining capacity based on item size for fair comparison between near full bins vs large bins.\n    priorities[feasible_bins] += (item/(bins_remain_cap[feasible_bins]+0.0001)) *0.1 #Added 0.0001 to deal with divide by zero errors\n\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version uses a combination of remaining capacity and a \"near miss\" bonus to prioritize bins.\n    It prefers bins where the item fits reasonably well but also gives a small bonus to bins that are\n    close to being full after the item is added. This encourages filling bins as much as possible.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Option 1: Penalize bins that are too small: big time\n    too_small = bins_remain_cap < item\n    priorities[too_small] = -np.inf\n\n    # Option 2: Prioritize bins that fit the item reasonably well. Using relative fit.\n    fit_scores = (bins_remain_cap - item) / bins_remain_cap\n    fit_scores[fit_scores < 0] = 0 # ensure priorities are not negative\n\n    # Add a small bonus for bins that will be nearly full after adding the item\n    near_full_bonus = np.exp(-10 * (bins_remain_cap - item))\n\n    # Overall Priority.  Mix up the fitness score and bonus to get a good filling algorithm.\n    priorities = fit_scores + 0.5 * near_full_bonus\n    return priorities\n\n### Analyze & experience\n- *   **Comparing (1st) vs (20th),** the best heuristic uses an exponential function to prioritize partially filled bins, giving a capped boost based on remaining space relative to the total capacity, and a hard penalty for bins that cannot fit the item. The worst heuristic uses a fill ratio and quadratic penalty, normalizing the penalty by the maximum bin capacity. The first one focuses on efficient fitting using relative space, while the last attempts to balance fill ratio and a penalty, but may over-penalize.\n\n*   **Comparing (2nd) vs (19th),** the second best heuristic uses a combination of heuristics, including minimizing remaining space, prioritizing initially full bins, and slightly preferring bins just big enough. The 19th (duplicate of 18th), calculates a \"fit\" score, a normalized \"fullness\" score, and a \"rarity\" score based on exponential decay. The second best balances multiple factors with heuristics while the 19th normalizes remain capacity to calculate fullness.\n\n*   **Comparing (3rd) vs (4th),** the 3rd prioritizes bins where the item fits with a combined `cap*item / (remaining_space + 1e-9)` score and uses a simple negative value for bins that cannot fit. The 4th prioritizes bins based on fill ratio, adds a bonus for almost full bins after item addition, introduces a fragmentation penalty, and inverts remaining capacity scaled by item size. The 3rd is simpler but less nuanced than the 4th, which incorporates more factors.\n\n*   **Comparing (second worst) vs (worst),** the second worst heuristic (19th), which calculates a \"fit\" score, a normalized \"fullness\" score, and a \"rarity\" score based on exponential decay, heavily penalizing bins where the item doesn't fit. The worst heuristic (20th),uses a fill ratio and quadratic penalty, normalizing the penalty by the maximum bin capacity. The 19th uses a combination of scores whereas the last one uses ratio and penalty functions.\n\n*   **Overall:** The better heuristics use a combination of strategies like prioritizing almost full bins, penalizing waste, and considering the initial capacity of the bins. They often involve exponential functions or ratios to create a nuanced priority score. The worse heuristics tend to rely on simpler calculations or penalties that may not effectively balance the various factors involved in bin packing. Normalization plays a crucial role in several heuristics. Also, several heuristics are repeated (e.g., 6th and 4th, 10th and 9th, 19th and 18th).\n- \nOkay, let's redefine \"Current Self-Reflection\" to make it more effective for designing better bin packing heuristics, focusing on avoiding pitfalls that lead to ineffective analysis.\n\nHere's a refined approach:\n\n*   **Keywords:** Data-driven, adaptive, iterative, performance metrics, failure analysis, diversity.\n\n*   **Advice:** Analyze heuristic performance on diverse datasets. Track key metrics (bin count, runtime, waste). Use failures to refine priority functions and explore parameter tuning. Encourage exploration of diverse heuristic combinations.\n\n*   **Avoid:** Over-reliance on intuition, neglecting edge cases, ignoring computational cost, lack of performance measurement.\n\n*   **Explanation:** Shift from solely formula-based to data-driven. Emphasize iterative improvement using performance data across varied scenarios. Actively identify failure points to drive refinement and adaptation.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}