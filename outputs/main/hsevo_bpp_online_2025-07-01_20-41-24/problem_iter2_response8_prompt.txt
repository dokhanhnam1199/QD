{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the concept of event horizons. Bins closer to being 'filled' (item size approaching remaining capacity)\n    experience a higher 'gravitational pull' and thus are prioritized.  Bins that cannot accommodate are assigned -inf priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n      return np.full_like(bins_remain_cap, fill_value=-np.inf)\n\n    priorities[~eligible_bins] = -np.inf\n    \n    # Calculate how well the item 'fits' into each bin, considering the \"event horizon\" (perfect fit)\n    fit_score = 1.0 - np.abs(item - bins_remain_cap) / (bins_remain_cap[eligible_bins] + item)  #Normalize based on total size\n    #The \"fit score\" closer to 1 has a higher priority.\n\n    priorities[eligible_bins] = fit_score\n    \n    # Add a term which adds some importance for filling a bin up almost fully, resembling a final \"infall\"\n\n    close_to_full = (bins_remain_cap[eligible_bins] - item) / bins_remain_cap[eligible_bins] < 0.1\n\n    priorities[eligible_bins][close_to_full] += 0.5 #A \"bonus\" for full bins\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a very low value\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    # Calculate the remaining capacity after adding the item\n    remaining_after_add = bins_remain_cap - item\n\n    # Give higher priority to bins that can accommodate the item\n    can_accommodate = remaining_after_add >= 0\n    priorities[can_accommodate] = bins_remain_cap[can_accommodate] - item # favour smaller waste\n\n    #If a bin can accommodate perfectly, increase priority significantly\n    perfect_fit = remaining_after_add == 0\n    priorities[perfect_fit] = np.inf\n\n    # Normalize priorities for stability.\n    if np.any(np.isfinite(priorities)): # prevent infs from messing up scaling\n        max_priority = np.max(priorities[np.isfinite(priorities)])\n        min_priority = np.min(priorities[np.isfinite(priorities)])\n        priorities[np.isfinite(priorities)] = (priorities[np.isfinite(priorities)] - min_priority) / (max_priority - min_priority)\n\n\n    return priorities\n\n### Analyze & experience\n- *   **Comparing (1st) vs (20th),** the best heuristic uses an exponential function to prioritize partially filled bins, giving a capped boost based on remaining space relative to the total capacity, and a hard penalty for bins that cannot fit the item. The worst heuristic uses a fill ratio and quadratic penalty, normalizing the penalty by the maximum bin capacity. The first one focuses on efficient fitting using relative space, while the last attempts to balance fill ratio and a penalty, but may over-penalize.\n\n*   **Comparing (2nd) vs (19th),** the second best heuristic uses a combination of heuristics, including minimizing remaining space, prioritizing initially full bins, and slightly preferring bins just big enough. The 19th (duplicate of 18th), calculates a \"fit\" score, a normalized \"fullness\" score, and a \"rarity\" score based on exponential decay. The second best balances multiple factors with heuristics while the 19th normalizes remain capacity to calculate fullness.\n\n*   **Comparing (3rd) vs (4th),** the 3rd prioritizes bins where the item fits with a combined `cap*item / (remaining_space + 1e-9)` score and uses a simple negative value for bins that cannot fit. The 4th prioritizes bins based on fill ratio, adds a bonus for almost full bins after item addition, introduces a fragmentation penalty, and inverts remaining capacity scaled by item size. The 3rd is simpler but less nuanced than the 4th, which incorporates more factors.\n\n*   **Comparing (second worst) vs (worst),** the second worst heuristic (19th), which calculates a \"fit\" score, a normalized \"fullness\" score, and a \"rarity\" score based on exponential decay, heavily penalizing bins where the item doesn't fit. The worst heuristic (20th),uses a fill ratio and quadratic penalty, normalizing the penalty by the maximum bin capacity. The 19th uses a combination of scores whereas the last one uses ratio and penalty functions.\n\n*   **Overall:** The better heuristics use a combination of strategies like prioritizing almost full bins, penalizing waste, and considering the initial capacity of the bins. They often involve exponential functions or ratios to create a nuanced priority score. The worse heuristics tend to rely on simpler calculations or penalties that may not effectively balance the various factors involved in bin packing. Normalization plays a crucial role in several heuristics. Also, several heuristics are repeated (e.g., 6th and 4th, 10th and 9th, 19th and 18th).\n- \nOkay, let's redefine \"Current Self-Reflection\" to make it more effective for designing better bin packing heuristics, focusing on avoiding pitfalls that lead to ineffective analysis.\n\nHere's a refined approach:\n\n*   **Keywords:** Data-driven, adaptive, iterative, performance metrics, failure analysis, diversity.\n\n*   **Advice:** Analyze heuristic performance on diverse datasets. Track key metrics (bin count, runtime, waste). Use failures to refine priority functions and explore parameter tuning. Encourage exploration of diverse heuristic combinations.\n\n*   **Avoid:** Over-reliance on intuition, neglecting edge cases, ignoring computational cost, lack of performance measurement.\n\n*   **Explanation:** Shift from solely formula-based to data-driven. Emphasize iterative improvement using performance data across varied scenarios. Actively identify failure points to drive refinement and adaptation.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}