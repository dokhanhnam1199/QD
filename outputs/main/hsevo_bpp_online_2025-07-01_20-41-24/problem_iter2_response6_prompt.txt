{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins with capacity closest to the item size,\n    but also penalizes bins that are too full (risk of waste) or too empty\n    (inefficient packing).  It uses a combination of heuristics,\n    inspired by the idea of wave functions collapsing into lower energy states.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Avoid division by zero, replace with a large negative number\n    safe_bins_remain_cap = np.where(bins_remain_cap <= 0, -1e9, bins_remain_cap)\n\n    # Proximity to ideal fit (item size)\n    proximity = -np.abs(bins_remain_cap - item)\n\n    # Penalize bins that are too full (waste potential). Use exponential to heavily penalize near zero remain cap.\n    waste_penalty = -np.exp(-bins_remain_cap/item*5) #Heavily penalize approaching 0 cap\n\n    # Penalize bins that are too empty. Using item*2 to check how much bigger can the bin be than the item.  Make it soft.\n    emptiness_penalty = -np.abs(bins_remain_cap - item * 1.5)**0.5\n\n\n    # Combine the factors\n    priorities = proximity + waste_penalty + emptiness_penalty\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version prioritizes bins where the item fills a significant portion\n    of the remaining capacity, but also avoids near-full bins to prevent\n    excessive fragmentation.  A quadratic term penalizes bins that are\n    almost full after packing the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    remaining_after_packing = bins_remain_cap - item\n    \n    # Bins where the item doesn't fit get a very low priority.\n    priorities = np.where(remaining_after_packing >= 0, 0.0, -np.inf)\n\n    # Prioritize bins based on fill ratio *after* packing. We want high utilization.\n    fill_ratio_after = item / bins_remain_cap\n\n    # Add a bonus for filling a significant portion of the remaining space, up to a point.\n    # This promotes utilization, but not at the cost of over-filling.\n    priorities = np.where(remaining_after_packing >=0, fill_ratio_after, priorities)\n    \n    # A penalty for bins that are close to full after the item is packed.\n    # If remaining_after_packing is small, the penalty becomes larger.\n    # A quadratic penalty helps to strongly avoid very tight fits.\n    # Only apply penalty when packing is possible\n    penalty = np.where(remaining_after_packing >= 0, (1 - remaining_after_packing / np.max(bins_remain_cap))**2, 0)  # Normalize penalty by max capacity\n    priorities = np.where(remaining_after_packing >= 0, priorities - penalty, priorities)\n    \n    # Handle the case of division by zero for any bins with zero remaining capacity\n    # by setting them to lowest possible priority before fit consideration.\n    priorities = np.nan_to_num(priorities, nan=-np.inf)\n\n    return priorities\n\n### Analyze & experience\n- *   **Comparing (1st) vs (20th),** the best heuristic uses an exponential function to prioritize partially filled bins, giving a capped boost based on remaining space relative to the total capacity, and a hard penalty for bins that cannot fit the item. The worst heuristic uses a fill ratio and quadratic penalty, normalizing the penalty by the maximum bin capacity. The first one focuses on efficient fitting using relative space, while the last attempts to balance fill ratio and a penalty, but may over-penalize.\n\n*   **Comparing (2nd) vs (19th),** the second best heuristic uses a combination of heuristics, including minimizing remaining space, prioritizing initially full bins, and slightly preferring bins just big enough. The 19th (duplicate of 18th), calculates a \"fit\" score, a normalized \"fullness\" score, and a \"rarity\" score based on exponential decay. The second best balances multiple factors with heuristics while the 19th normalizes remain capacity to calculate fullness.\n\n*   **Comparing (3rd) vs (4th),** the 3rd prioritizes bins where the item fits with a combined `cap*item / (remaining_space + 1e-9)` score and uses a simple negative value for bins that cannot fit. The 4th prioritizes bins based on fill ratio, adds a bonus for almost full bins after item addition, introduces a fragmentation penalty, and inverts remaining capacity scaled by item size. The 3rd is simpler but less nuanced than the 4th, which incorporates more factors.\n\n*   **Comparing (second worst) vs (worst),** the second worst heuristic (19th), which calculates a \"fit\" score, a normalized \"fullness\" score, and a \"rarity\" score based on exponential decay, heavily penalizing bins where the item doesn't fit. The worst heuristic (20th),uses a fill ratio and quadratic penalty, normalizing the penalty by the maximum bin capacity. The 19th uses a combination of scores whereas the last one uses ratio and penalty functions.\n\n*   **Overall:** The better heuristics use a combination of strategies like prioritizing almost full bins, penalizing waste, and considering the initial capacity of the bins. They often involve exponential functions or ratios to create a nuanced priority score. The worse heuristics tend to rely on simpler calculations or penalties that may not effectively balance the various factors involved in bin packing. Normalization plays a crucial role in several heuristics. Also, several heuristics are repeated (e.g., 6th and 4th, 10th and 9th, 19th and 18th).\n- \nOkay, let's redefine \"Current Self-Reflection\" to make it more effective for designing better bin packing heuristics, focusing on avoiding pitfalls that lead to ineffective analysis.\n\nHere's a refined approach:\n\n*   **Keywords:** Data-driven, adaptive, iterative, performance metrics, failure analysis, diversity.\n\n*   **Advice:** Analyze heuristic performance on diverse datasets. Track key metrics (bin count, runtime, waste). Use failures to refine priority functions and explore parameter tuning. Encourage exploration of diverse heuristic combinations.\n\n*   **Avoid:** Over-reliance on intuition, neglecting edge cases, ignoring computational cost, lack of performance measurement.\n\n*   **Explanation:** Shift from solely formula-based to data-driven. Emphasize iterative improvement using performance data across varied scenarios. Actively identify failure points to drive refinement and adaptation.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}