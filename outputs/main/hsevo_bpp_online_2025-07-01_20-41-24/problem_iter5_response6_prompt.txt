{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines fill ratio and waste penalty for bin selection.\"\"\"\n    remaining_after_packing = bins_remain_cap - item\n    \n    # Bins where the item doesn't fit get a very low priority.\n    priorities = np.where(remaining_after_packing >= 0, 0.0, -np.inf)\n\n    # Prioritize bins based on fill ratio *after* packing. We want high utilization.\n    fill_ratio_after = item / bins_remain_cap\n\n    # Add a bonus for filling a significant portion of the remaining space, up to a point.\n    # This promotes utilization, but not at the cost of over-filling.\n    priorities = np.where(remaining_after_packing >=0, fill_ratio_after, priorities)\n    \n    # Penalize bins that are too full (waste potential). Use exponential to heavily penalize near zero remain cap.\n    waste_penalty = -np.exp(-bins_remain_cap/item*5) #Heavily penalize approaching 0 cap\n    priorities = np.where(remaining_after_packing >= 0, priorities + waste_penalty, priorities)\n    \n    # Handle the case of division by zero for any bins with zero remaining capacity\n    # by setting them to lowest possible priority before fit consideration.\n    priorities = np.nan_to_num(priorities, nan=-np.inf)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Initialize priority array.\n    priority = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify valid bins (bins with enough remaining capacity).\n    valid_bins = bins_remain_cap >= item\n\n    # If no valid bins, return -inf priority for all bins.\n    if not np.any(valid_bins):\n        return np.full_like(bins_remain_cap, -np.inf)\n\n    # Calculate remaining capacity after placing the item in each bin.\n    remaining_capacity = bins_remain_cap - item\n\n    # Calculate waste for valid bins; otherwise, set to infinity.\n    waste = np.copy(remaining_capacity)\n    waste[remaining_capacity < 0] = np.inf\n\n    # Calculate fill ratio (how full the bin would be).\n    fill_ratio = (bins_remain_cap - waste) / bins_remain_cap\n    fill_ratio[np.isinf(fill_ratio)] = 0  # Handle cases where bins_remain_cap is zero\n    fill_ratio[fill_ratio < 0] = 0 #ensure fill ratio is not negative\n\n    # Prioritize bins based on fill ratio (higher fill ratio is better).\n    priority = fill_ratio * 100\n\n    # Adjust priority based on waste. Bins with very little waste get a bonus.\n    # Use a scaled exponential function to provide a sharper cutoff.\n    waste_penalty = np.exp(-waste * 5)  # Higher scaling factor for sharper cutoff\n    waste_penalty[np.isinf(waste_penalty)] = 0  #prevent inf values\n    priority += waste_penalty * 50  # Scale waste_penalty\n\n    # Add a bonus for bins that are nearly full *before* adding the item\n    pre_fill_ratio = (bins_remain_cap / np.max(bins_remain_cap)) # Normalize remaining capacity for consistent effect\n    priority += pre_fill_ratio * 20 #scale this effect\n\n    # Further refine the waste penalty based on item size.\n    # If item is relatively large, heavily penalize bins with very small waste\n    item_size_ratio = item / np.max(bins_remain_cap) # Normalize item size\n\n    if item_size_ratio > 0.5:  # If item is more than half the maximum bin capacity.\n        close_fit_penalty = np.exp(waste * 10) # Increased waste multiplier\n        close_fit_penalty[np.isinf(close_fit_penalty)] = 0\n        priority -= close_fit_penalty * 10\n\n    # Invalidate bins that can't fit the item.\n    priority[bins_remain_cap < item] = -np.inf\n\n    return priority\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st uses fill-based priority with perfect fit bonus and considers initial capacity, while the 20th combines tight fit, larger bins, and almost full bins but penalizes bins that are close to fitting. The 1st prioritizes minimizing waste and higher fill, while the 20th focuses on space utilization but does not handle infeasible bins as effectively, potentially leading to less optimal packing. Comparing (2nd best) vs (second worst), the 2nd uses fill ratio, near-full bonus, anti-fragmentation, and scaled capacity, whereas the 19th, which is the same as 20th, combines tight fit, larger bins, and almost full bins, but heavily penalizes bins that are close to fitting but don't fit. Comparing (1st) vs (2nd), we see that the 1st gives a very big bonus to perfect fits, whereas the 2nd promotes an almost-full bonus. (3rd) vs (4th) the 3rd penalizes bins where the item barely fits, whereas the 4th uses gravitational force and the \"almost full\" heuristic. Comparing (second worst) vs (worst), they are identical. Overall: The better heuristics tend to prioritize minimizing waste and achieving high fill ratios, often incorporating bonuses for perfect or near-perfect fits. They also effectively penalize infeasible bins and may consider initial capacity. The inferior heuristics sometimes over-penalize near misses or lack a clear strategy for space utilization and fragmentation.\n- \nOkay, let's refine \"Current self-reflection\" to be more effective for heuristic design, specifically addressing the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a breakdown:\n\n*   **Keywords:** Objective measurement, Adaptability, Realistic Constraints, Iterative Improvement.\n*   **Advice:** Focus on *quantifiable* metrics like items packed per unit time, solution feasibility rate, and solution quality variance. Design for adaptability to different dataset characteristics.\n*   **Avoid:** Overly complex formulas (exponential, ratios without clear justification), vague priorities (near-full), and reliance on intuition without empirical validation.\n*   **Explanation:** Emphasize measuring performance to guide heuristic refinement. Design heuristics that adapt to various data patterns and avoid unnecessary complexity.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}