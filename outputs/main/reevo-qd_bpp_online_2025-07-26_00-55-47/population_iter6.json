[
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins. It also penalizes fragmentation by minimizing gaps\n    and encourages filling larger bins first.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 5% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.05)).astype(int) * 50\n    \n    # Penalize bins that are almost full but cannot fit the item (within 5% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.95)).astype(int) * -20\n    \n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 10 if item <= np.max(bins_remain_cap) else 0\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 10\n    \n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.2).astype(int)\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty \n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 0.9573195053849246,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    dynamically adjusts penalties based on the remaining capacity of the bins, and minimizes gaps\n    to avoid fragmentation. It also encourages filling larger bins first.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Perfect fit score\n    perfect_fit_scores = (bins_remain_cap == item).astype(int) * 100\n\n    # Near fit score (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap > item) & (bins_remain_cap <= item * 1.1)).astype(int) * 50\n\n    # Penalty for bins that are almost full but cannot fit the item (within 10% of bin's current space)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.1)).astype(int) * -30\n\n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 20\n\n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 15\n\n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.2).astype(int)\n\n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty\n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n\n    return priority_scores",
    "response_id": 3,
    "obj": 1.5556441962505008,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]