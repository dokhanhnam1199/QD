[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item in each bin\n    remaining_after_item = bins_remain_cap - item\n    \n    # Penalize bins where the item does not fit\n    penalty_for_overflow = np.where(bins_remain_cap < item, -np.inf, 0)\n    \n    # Penalize bins with larger remaining space after placing the item\n    priority_scores = remaining_after_item - remaining_after_item ** 2\n    \n    # Combine penalties\n    priority_scores += penalty_for_overflow\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.11846828879138,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that can fit the item, penalizes bins that cannot,\n    and encourages bins that will result in less fragmentation by filling larger gaps first.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority score array\n    priority = np.zeros_like(bins_remain_cap)\n    \n    # Mask for bins that can fit the item\n    can_fit_item_mask = bins_remain_cap >= item\n    \n    # Penalize bins that cannot fit the item\n    priority[~can_fit_item_mask] -= 2\n    \n    # Calculate the remaining capacity after adding the item for bins that can fit it\n    remaining_capacity_after_item = bins_remain_cap[can_fit_item_mask] - item\n    \n    if np.any(can_fit_item_mask):\n        # Prioritize bins that will leave larger gaps to reduce fragmentation\n        sorted_remaining_capacities = np.sort(remaining_capacity_after_item)\n        highest_remaining_capacity = sorted_remaining_capacities[-1] if sorted_remaining_capacities.size > 0 else 0\n        second_highest_remaining_capacity = sorted_remaining_capacities[-2] if sorted_remaining_capacities.size > 1 else 0\n        \n        # Boost bins that will leave the highest and second highest gaps\n        highest_cap_mask = np.isclose(bins_remain_cap - item, highest_remaining_capacity)\n        second_highest_cap_mask = np.isclose(bins_remain_cap - item, second_highest_remaining_capacity)\n        \n        priority[highest_cap_mask] += 1.5  # Strong preference for the perfect fit or largest gap reduction\n        priority[second_highest_cap_mask] += 1  # Moderate preference for the second largest gap reduction\n\n    return priority",
    "response_id": 1,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 42, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n5\n1\n"
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that are empty or nearly empty and can fit the item,\n    aligning with a First-Fit Decreasing strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority scores\n    priority_scores = np.zeros_like(bins_remain_cap)\n    \n    # Calculate which bins can fit the item\n    can_fit = bins_remain_cap >= item\n    \n    # For bins that can fit the item, prioritize those with more remaining capacity\n    priority_scores[can_fit] = bins_remain_cap[can_fit]\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers perfect and near-perfect fits, penalizes bins with small remaining capacities,\n    and simplifies the calculation to avoid division pitfalls.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give moderate priority to bins where the item fits nearly perfectly (within 10% of bin's remaining capacity)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.1)).astype(int) * 50\n    \n    # Penalize bins with small remaining capacities\n    size_penalty = - np.minimum(bins_remain_cap, item * 0.5)\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = perfect_fit_scores + near_fit_scores + size_penalty\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.008775428799367,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give somewhat lower priority to bins where the item fits almost perfectly (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.1)).astype(int) * 50\n    \n    # Penalize bins that are almost full but cannot fit the item\n    almost_full_penalty = ((bins_remain_cap - item < 0) & (bins_remain_cap - item > -0.1 * item)).astype(int) * -20\n    \n    # Penalize bins that are already very small (less than 10% of the maximum remaining capacity)\n    size_penalty = (bins_remain_cap / np.max(bins_remain_cap, initial=1) < 0.1).astype(int) * -30\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = perfect_fit_scores + near_fit_scores + almost_full_penalty + size_penalty\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.008775428799367,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that can fit the item with minimal gaps,\n    harshly penalizes non-fit bins, and encourages using larger residual spaces progressively.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority scores with zeros\n    priority = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins that can fit the item\n    can_fit_item_mask = bins_remain_cap >= item\n    if np.any(can_fit_item_mask):\n        # Calculate gaps for bins that can fit the item\n        gaps = bins_remain_cap[can_fit_item_mask] - item\n        \n        # Penalize bins with larger gaps less harshly\n        min_gap = np.min(gaps)\n        gap_penalty = 1 - (gaps - min_gap) / (np.max(gaps) - min_gap) if np.max(gaps) != min_gap else 0\n        \n        # Reduce penalty for bins with the smallest gaps\n        priority[can_fit_item_mask] = gap_penalty + 1\n    \n    # Harshly penalize bins that cannot fit the item\n    priority[~can_fit_item_mask] -= 2\n    \n    # Encourage using larger residual spaces progressively\n    # Normalize remaining capacities to a smaller range where larger capacities get higher scores\n    remaining_cap_score = bins_remain_cap / np.max(bins_remain_cap) * 0.1\n    priority += remaining_cap_score\n    \n    return priority",
    "response_id": 5,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 42, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n5\n1\n"
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.1)).astype(int) * 50\n    \n    # Penalize bins that are almost full but cannot fit the item (within 10% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.9)).astype(int) * -20\n    \n    # Penalize bins that are already very small\n    size_penalty = - ((bins_remain_cap / np.max(bins_remain_cap, initial=1)) ** 2) * 10\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 10\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = perfect_fit_scores + near_fit_scores + almost_full_penalty + size_penalty + fill_large_bins\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 3.4603111288392543,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Priority for bins that can fit the item\n    can_fit_item_mask = bins_remain_cap >= item\n    priority = np.where(can_fit_item_mask, bins_remain_cap - item, -np.inf)\n    \n    # Encourage bins with less remaining capacity to reduce fragmentation\n    priority = -np.abs(priority)\n    \n    return priority",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits well and penalizes\n    bins that are overfull. It avoids large mismatches between the item size and\n    the bin's remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize scores with zeros\n    scores = np.zeros_like(bins_remain_cap)\n\n    # Calculate difference between remaining capacity and item size\n    diff = bins_remain_cap - item\n\n    # Assign scores: prioritize bins where item fits well\n    scores[diff == 0] = 1.0  # Perfect fit, highest priority\n    scores[(diff > 0) & (diff < item)] = 0.9  # Good fits, high priority\n    scores[(diff > 0) & (diff >= item)] = 0.7  # Acceptable fits, medium priority\n    scores[diff < 0] = -1  # Overfull bins, lowest priority\n\n    return scores",
    "response_id": 8,
    "obj": 4.198244914240141,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Prioritize bins where adding the item will leave the least space unused\n    fullness_penalty = (bins_remain_cap - item) ** 2\n    # Penalize overflows harshly to reduce fragmentation\n    overflow_penalty = np.where(bins_remain_cap < item, 10 * (bins_remain_cap - item) ** 2, 0)\n    priority_scores = -(fullness_penalty + overflow_penalty)\n\n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]