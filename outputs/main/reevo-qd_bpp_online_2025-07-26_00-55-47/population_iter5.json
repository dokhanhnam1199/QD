[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Prioritize bins where adding the item will leave the least space unused\n    fullness_penalty = (bins_remain_cap - item) ** 2\n    # Penalize overflows harshly to reduce fragmentation\n    overflow_penalty = np.where(bins_remain_cap < item, 10 * (bins_remain_cap - item) ** 2, 0)\n    # Encourage bins that are not empty to be filled further to reduce fragmentation\n    non_empty_bonus = np.where(bins_remain_cap < np.max(bins_remain_cap), bins_remain_cap, 0)\n    \n    priority_scores = -(fullness_penalty + overflow_penalty) + non_empty_bonus\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.11846828879138,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins. It also penalizes fragmentation by minimizing gaps\n    and encourages filling larger bins first.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 5% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.05)).astype(int) * 50\n    \n    # Penalize bins that are almost full but cannot fit the item (within 5% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.95)).astype(int) * -20\n    \n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 10 if item <= np.max(bins_remain_cap) else 0\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 10\n    \n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.2).astype(int)\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty \n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 0.9573195053849246,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers perfect fits, near-perfect fits, and penalizes bins with small remaining capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority scores\n    priority_scores = np.zeros_like(bins_remain_cap)\n    \n    # Perfect fit: item fits exactly into the bin\n    perfect_fit = (bins_remain_cap == item)\n    priority_scores[perfect_fit] += 100\n    \n    # Near-perfect fit: item fits leaving less than 10% of bin's capacity\n    near_perfect_fit = (bins_remain_cap > item) & (bins_remain_cap - item < 0.1 * item)\n    priority_scores[near_perfect_fit] += 50\n    \n    # Penalize bins with small remaining capacity (less than or equal to 50% of the item's size)\n    small_capacity_penalty = np.where(bins_remain_cap <= 0.5 * item, -50, 0)\n    priority_scores += small_capacity_penalty\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority score for adding an item to each bin in the online Bin Packing Problem.\n\n    This implementation aims to:\n    - Prioritize bins where the item fits perfectly.\n    - Prioritize bins where the item fits almost perfectly (within 10% of item size).\n    - Penalize bins that are almost full but cannot fit the item (within 10% of item size).\n    - Favor bins that have more remaining capacity, dynamically adjusting based on the current state of bins.\n\n    Args:\n        item: Size of the item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of the same size as bins_remain_cap with the priority score of each bin.\n    \"\"\"\n    # Calculate the maximum remaining capacity to normalize scores\n    max_cap = np.max(bins_remain_cap, initial=1)\n    \n    # Perfect fit score\n    perfect_fit_scores = (bins_remain_cap == item).astype(int) * 100\n    \n    # Near fit score (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap > item) & (bins_remain_cap <= item * 1.1)).astype(int) * 50\n    \n    # Penalty for bins that are almost full but cannot fit the item (within 10% of bin's current space)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.1)).astype(int) * -20\n    \n    # Penalty for small bins to avoid filling very small spaces\n    size_penalty = - ((bins_remain_cap / max_cap) ** 2) * 10\n    \n    # Favor bins that have more remaining capacity relative to the maximum capacity\n    fill_advanced_bins = (bins_remain_cap / max_cap) * 25\n    \n    # Calculate the final priority score as a weighted sum of all the factors\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty +\n                       size_penalty + fill_advanced_bins)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 77.46310331072995,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority score for adding an item to each bin in the online Bin Packing Problem.\n\n    This implementation aims to:\n    - Prioritize bins where the item fits perfectly.\n    - Prioritize bins where the item fits almost perfectly (within 10% of item size).\n    - Penalize bins that are almost full but cannot fit the item (within 10% of item size).\n    - Favor bins that have more remaining capacity, dynamically adjusting based on the current state of bins.\n\n    Args:\n        item: Size of the item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of the same size as bins_remain_cap with the priority score of each bin.\n    \"\"\"\n    # Calculate the maximum remaining capacity to normalize scores\n    max_cap = np.max(bins_remain_cap, initial=1)\n    \n    # Perfect fit score\n    perfect_fit_scores = (bins_remain_cap == item).astype(int) * 100\n    \n    # Near fit score (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap > item) & (bins_remain_cap <= item * 1.1)).astype(int) * 50\n    \n    # Penalty for bins that are almost full but cannot fit the item (within 10% of bin's current space)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.1)).astype(int) * -20\n    \n    # Penalty for small bins to avoid filling very small spaces\n    size_penalty = - ((bins_remain_cap / max_cap) ** 2) * 10\n    \n    # Favor bins that have more remaining capacity relative to the maximum capacity\n    fill_advanced_bins = (bins_remain_cap / max_cap) * 25\n    \n    # Calculate the final priority score as a weighted sum of all the factors\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty +\n                       size_penalty + fill_advanced_bins)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 77.46310331072995,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Priority for bins that can fit the item, prioritizing those with less remaining capacity to reduce fragmentation\n    can_fit_item_mask = bins_remain_cap >= item\n    priority = np.where(can_fit_item_mask, -(bins_remain_cap - item), -np.inf)\n    \n    return priority",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item in each bin\n    remaining_after_item = bins_remain_cap - item\n    \n    # Penalize bins where the item does not fit\n    penalty_for_overflow = np.where(bins_remain_cap < item, -np.inf, 0)\n    \n    # Penalize bins with larger remaining space after placing the item\n    priority_scores = remaining_after_item - remaining_after_item ** 2\n    \n    # Combine penalties\n    priority_scores += penalty_for_overflow\n    \n    # Prioritize bins with less space left after adding the item\n    priority_scores += (bins_remain_cap - item) ** -1 * (bins_remain_cap >= item)\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after placing the item in each bin\n    remaining_after_item = bins_remain_cap - item\n    \n    # Penalize bins where the item does not fit\n    penalty_for_overflow = np.where(bins_remain_cap < item, -np.inf, 0)\n    \n    # Prioritize bins with lower post-insertion remaining capacity\n    priority_scores = -remaining_after_item\n    \n    # Combine penalties\n    priority_scores += penalty_for_overflow\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on perfect and near-perfect fits, penalizes fragmentation\n    and near-overfull bins, dynamically weighs capacities, and discourages small gaps.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize scores with zeros\n    scores = np.zeros_like(bins_remain_cap)\n    \n    # Perfect fit\n    perfect_fit_mask = bins_remain_cap == item\n    scores[perfect_fit_mask] = 100\n    \n    # Near perfect fit (within 5% of item size)\n    near_fit_mask = (bins_remain_cap > item) & (bins_remain_cap <= item * 1.05)\n    scores[near_fit_mask] += 50\n    \n    # Penalty for bins that are almost full but cannot fit the item (within 5% of item size)\n    almost_full_penalty_mask = (bins_remain_cap < item) & (bins_remain_cap >= item * 0.95)\n    scores[almost_full_penalty_mask] -= 20\n    \n    # Penalize small remaining capacity after placing the item\n    post_fit_remain = bins_remain_cap - item\n    small_gap_penalty = (post_fit_remain > 0) & (post_fit_remain < item * 0.1)\n    scores[small_gap_penalty] -= 10 * (item - post_fit_remain[small_gap_penalty]) / item\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = (bins_remain_cap / np.max(bins_remain_cap, initial=np.inf)) * 20\n    scores += fill_large_bins\n\n    return scores",
    "response_id": 8,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 37, in priority_v2\n    priorities = perfect_fit + near_perfect_fit + almost_full_penalty + \\\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n10\n1\n"
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority score for placing an item into each bin, considering perfect fits, near fits,\n    remaining capacity, and penalizing large gaps and bins that are almost full.\n    \n    Args:\n        item: Size of the item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of the same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Priority for perfect fit\n    perfect_fit = np.where(bins_remain_cap == item, 100, 0)\n    \n    # Priority for nearly perfect fit (within 5% of item size)\n    near_perfect_fit = np.where((bins_remain_cap < item) & (bins_remain_cap >= item * 0.95), 50, 0)\n    \n    # Penalty for bins that are almost full but cannot fit the item (within 10% of item size)\n    almost_full_penalty = np.where((bins_remain_cap < item) & (bins_remain_cap >= item * 0.9), -20, 0)\n    \n    # Penalty for a small remaining capacity (less than 10% of item size)\n    small_remaining_penalty = np.where(bins_remain_cap < item * 0.1, -10, 0)\n    \n    # Penalty for large gaps (remaining capacity is much larger than the item size)\n    large_gap_penalty = np.where(bins_remain_cap > item * 2, -15, 0)\n    \n    # Reward for bins with more remaining capacity\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 5\n    \n    # Calculate the final priority as a combination of all factors\n    priorities = perfect_fit + near_perfect_fit + almost_full_penalty + \\\n                 small_remaining_penalty + large_gap_penalty + fill_large_bins\n    \n    return priorities",
    "response_id": 9,
    "obj": 4.238133226964499,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins. It also penalizes fragmentation by minimizing gaps\n    and encourages filling larger bins first. Improved version with adjusted weights and penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.1)).astype(int) * 40\n    \n    # Penalize bins that are almost full but cannot fit the item (within 10% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.9)).astype(int) * -30\n    \n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 15 if item <= np.max(bins_remain_cap) else 0\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 8\n    \n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.25).astype(int)\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty \n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 2.6625448743518194,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins. It also penalizes fragmentation by minimizing gaps\n    and encourages filling larger bins first.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 5% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.05)).astype(int) * 50\n    \n    # Penalize bins that are almost full but cannot fit the item (within 5% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.95)).astype(int) * -30\n    \n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 15 if item <= np.max(bins_remain_cap) else 0\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 8\n    \n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.2).astype(int) * 10\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty \n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 3.220981252493015,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins. It also penalizes fragmentation by minimizing gaps\n    and encourages filling larger bins first.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 5% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.05)).astype(int) * 50\n    \n    # Penalize bins that are almost full but cannot fit the item (within 5% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.95)).astype(int) * -30\n    \n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 15 if item <= np.max(bins_remain_cap) else 0\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 20\n    \n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.2).astype(int)\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty \n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 59.802552852014365,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins. It also penalizes fragmentation by minimizing gaps\n    and encourages filling larger bins first. Improved version with adjusted weights and penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.1)).astype(int) * 40\n    \n    # Penalize bins that are almost full but cannot fit the item (within 10% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.9)).astype(int) * -30\n    \n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 5 if item <= np.max(bins_remain_cap) else 0\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 15\n    \n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.15).astype(int)\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty \n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 79.57718388512166,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins where the item fits perfectly or almost perfectly,\n    penalizes bins that are almost full but cannot fit the item, and dynamically adjusts weights\n    based on the remaining capacity of the bins. It also penalizes fragmentation by minimizing gaps\n    and encourages filling larger bins first.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Give higher priority to bins where the item fits perfectly\n    perfect_fit_scores = (bins_remain_cap - item == 0).astype(int) * 100\n    \n    # Give higher priority to bins where the item fits almost perfectly (within 10% of item size)\n    near_fit_scores = ((bins_remain_cap - item > 0) & (bins_remain_cap - item <= item * 0.1)).astype(int) * 50\n    \n    # Penalize bins that are almost full but cannot fit the item (within 10% of item size)\n    almost_full_penalty = ((bins_remain_cap < item) & (bins_remain_cap >= item * 0.9)).astype(int) * -30\n    \n    # Penalize bins that have a small remaining capacity after placing the item\n    post_fit_penalty = - ((bins_remain_cap - item) / np.max(bins_remain_cap, initial=1)) ** 2 * 15 if item <= np.max(bins_remain_cap) else 0\n    \n    # Encourage bins that have more remaining capacity to be filled first\n    fill_large_bins = bins_remain_cap / np.max(bins_remain_cap, initial=1) * 20\n    \n    # Penalize fragmentation by minimizing gaps\n    fragmentation_penalty = - (bins_remain_cap - item) * ((bins_remain_cap - item) < item * 0.2).astype(int)\n    \n    # Calculate the final priority as a weighted sum\n    priority_scores = (perfect_fit_scores + near_fit_scores + almost_full_penalty \n                     + post_fit_penalty + fill_large_bins + fragmentation_penalty)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 55.94335859593139,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]