{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics function for CVRP: Combines adaptive pruning, demand, depot proximity, angle, and sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    depot_index = 0\n\n    # Heuristic 1: Basic inverse distance\n    heuristics = 1 / (distance_matrix + 1e-9)\n\n    # Heuristic 2: Depot connection encouragement based on demand and distance\n    for j in range(1, n):  # Iterate over customers (excluding depot)\n        # Encourage connections from the depot to customers\n        if demands[j] <= capacity:  # Only consider if demand is within capacity\n            heuristics[depot_index, j] += 0.5 / (distance_matrix[depot_index, j] + 1e-6)  # Boost, scaled by inverse distance\n            heuristics[j, depot_index] = 0  # no incoming edges to depot except from depot.\n        else:\n            heuristics[depot_index, j] = 0  # prune edges if single demand exceeds capacity.\n\n    # Heuristic 3: Depot proximity with adaptive pruning\n    depot_distances = distance_matrix[:, depot_index]\n    mean_depot_distance = np.mean(depot_distances)\n\n    for i in range(n):\n        for j in range(n):\n            if i != depot_index and j == depot_index:\n                heuristics[i, j] = 0  # Remove edges to depot (except from depot)\n            elif i != depot_index and j != depot_index:\n                # Penalize edges based on detour from direct depot route.  Simpler calculation.\n                detour_penalty = (depot_distances[i] + depot_distances[j]) / (2 * mean_depot_distance + 1e-9)\n                heuristics[i, j] -= 0.05 * detour_penalty  # Reduced weight\n\n                # Adaptive pruning based on demand and distance.  Less aggressive than v1.\n                if distance_matrix[i, j] > np.mean(distance_matrix) and demands[i] + demands[j] > capacity / 3:  # Only prune if nodes have considerable demand compared to vehicle capacity.\n                    heuristics[i, j] = 0\n\n    # Heuristic 4: Angle from Depot\n    for i in range(1, n):\n        for j in range(1, n):\n            if i != j:\n                # Dot product to find the cosine of the angle between vectors\n                vector_i = coordinates[i] - coordinates[depot_index]\n                vector_j = coordinates[j] - coordinates[depot_index]\n\n                norm_i = np.linalg.norm(vector_i)\n                norm_j = np.linalg.norm(vector_j)\n\n                if norm_i > 0 and norm_j > 0:\n                    cos_angle = np.dot(vector_i, vector_j) / (norm_i * norm_j)\n                    angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n\n                    heuristics[i, j] += 0.1 * (1 - angle / np.pi)\n\n    # Heuristic 5: Demand-based Sparsification: Adaptive threshold (Combined metric)\n    mean_distance = np.mean(distance_matrix)\n    mean_demand = np.mean(demands[1:])\n    threshold = mean_distance * mean_demand * 1.5\n\n    for i in range(1, n):\n        for j in range(1, n):\n            if i == j:\n                heuristics[i, j] = 0\n                continue\n\n            combined_metric = distance_matrix[i, j] * (demands[i] + demands[j])\n\n            if combined_metric > threshold:\n                heuristics[i, j] = 0\n\n    # Heuristic 6: Sparsification: zero out small heuristic values\n    threshold = 0.01 * np.mean(heuristics)\n    heuristics[heuristics < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristics)\n    if max_heuristic > 0:\n        heuristics = heuristics / max_heuristic\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    CVRP heuristic: Combines distance, demand, depot proximity, adaptive sparsification, and route completion.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    depot_index = 0\n\n    # 1. Inverse Distance Component\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n    heuristics += inverse_distance\n\n    # 2. Demand Consideration and Hard Pruning\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                heuristics[i, j] = 0\n                continue\n            if i == depot_index and demands[j] > capacity:\n                heuristics[i, j] = 0  # Prune infeasible edges from depot\n            elif i != depot_index and j != depot_index and demands[i] + demands[j] > capacity and j==depot_index:\n                heuristics[i,j] = 0 # Prune edges exceeding capacity towards the depot.\n\n    # 3. Depot Proximity Incentive (Adaptive Scaling)\n    depot_distances = distance_matrix[:, depot_index]\n    mean_depot_distance = np.mean(depot_distances) + 1e-9\n    for i in range(n):\n        for j in range(n):\n            if i != depot_index and j == depot_index:\n                heuristics[i,j] = 0 #Except handled in route completion incentives\n            if i != depot_index and j != depot_index:\n                depot_proximity_penalty = 0.05 * (depot_distances[i] + depot_distances[j]) / mean_depot_distance\n                heuristics[i, j] -= depot_proximity_penalty\n\n                #Sparsification based on combined metric relative to averages\n                combined_metric = distance_matrix[i, j] * demands[j]\n                threshold = np.mean(distance_matrix) * np.mean(demands) * 1.5\n                if combined_metric > threshold:\n                    heuristics[i, j] = 0\n\n    # 4. Route Completion Incentive\n    for i in range(n):\n        if i != depot_index:\n            heuristics[i, depot_index] += 0.3\n\n    # 5. Depot Connection Boost\n    for j in range(1, n):  # Start from 1 to exclude depot itself\n        if demands[j] <= capacity:\n             heuristics[0, j] += 0.7 # strong boost from depot if demand feasible\n        else:\n             heuristics[0, j] = 0 # hard prune infeasible depot edges\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristics)\n    if max_heuristic > 0:\n        heuristics = heuristics / max_heuristic\n\n    # 7. Post-processing: Ensure depot has outgoing edges and no incoming edges (except route end).\n    for i in range(n):\n        if i != depot_index:\n            heuristics[depot_index, i] = max(0, heuristics[depot_index, i])\n\n    return heuristics\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic incorporates inverse distance, demand/capacity considerations, depot proximity with adaptive pruning and k-NN, angle from depot, and sparsification, while the worst uses only inverse distance, demand-aware pruning, depot proximity, and sparsification. (2nd) vs (19th) shows k-NN dropped. Comparing (1st) vs (2nd), we see they are identical. (3rd) vs (4th) shows the more complex logic with different weighting and aggressive sparsification helps. Comparing (second worst) vs (worst), the second worst included K-NN while the worst does not. Overall: Better heuristics tend to incorporate more features (distance, demand, depot proximity, angles), adaptive pruning/sparsification, and intensification techniques (k-NN). They also carefully manage edge cases and normalize the heuristic values. Simpler heuristics are often outperformed by more complex, well-tuned ones.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine self-reflection for designing better heuristics. We need to move beyond just listing techniques and focus on *why* and *how* to apply them effectively.\n\n*   **Keywords:** Adaptive learning, problem-specific knowledge, iterative refinement, evaluation metrics, trade-off analysis.\n*   **Advice:** Frame heuristic design as an iterative learning process driven by problem-specific insights and performance evaluation. Focus on understanding the underlying problem structure.\n*   **Avoid:** Blindly adding features or tuning weights without a clear rationale. Avoid complexity without demonstrated performance improvement.\n*   **Explanation:** Instead of simply stating techniques, emphasize adapting heuristic components based on *observed* performance and a deep understanding of the problem's characteristics.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}