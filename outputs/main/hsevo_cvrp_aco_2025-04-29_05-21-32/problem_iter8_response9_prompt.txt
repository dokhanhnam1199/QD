{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Combines inverse distance, demand, depot proximity, k-NN, and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n    depot_index = 0\n\n    # Inverse distance\n    heuristics = 1 / (distance_matrix + 1e-9)\n\n    # Demand consideration\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                heuristics[i, j] = 0\n                continue\n            if i == depot_index and j != depot_index:\n                if capacity - demands[j] < 0:\n                    heuristics[i, j] = 0\n                else:\n                    heuristics[i, j] += 0.3  # depot boost\n            elif i != depot_index and j == depot_index:\n                heuristics[i, j] += 0.1\n\n    # Depot proximity\n    depot_distances = distance_matrix[:, depot_index]\n    for i in range(n):\n        if i != depot_index:\n            heuristics[i, depot_index] += 0.1 * (1 / (depot_distances[i] + 1e-9))\n\n    # K-Nearest Neighbor Bonus\n    k_nearest_neighbors = 4\n    for i in range(n):\n        neighbors_idx = np.argsort(distance_matrix[i, :])[1:k_nearest_neighbors + 1]\n        for neighbor in neighbors_idx:\n            heuristics[i, neighbor] += 0.2\n\n    # Sparsification\n    distance_threshold = np.mean(distance_matrix) * 1.2\n    for i in range(n):\n        for j in range(n):\n            if distance_matrix[i, j] > distance_threshold:\n                heuristics[i, j] = 0\n\n    # Normalization\n    max_heuristic = np.max(heuristics)\n    if max_heuristic > 0:\n        heuristics = heuristics / max_heuristic\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Heuristic combining distance, demand, depot proximity, k-NN, sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # Inverse distance\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)\n\n    # Demand consideration, boost edges emanating from depot\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n            if i == 0:  # Depot departure boost with remaining capacity\n                remaining_capacity = capacity - demands[j]\n                if remaining_capacity > 0:\n                    heuristic_matrix[i, j] += 0.7\n                else:\n                    heuristic_matrix[i, j] = 0  #Invalid\n            else:\n                heuristic_matrix[i, j] /= (demands[j] + 1e-9)\n\n\n    # Depot proximity boost\n    for i in range(n):\n        for j in range(n):\n            if i == 0 or j == 0:\n                heuristic_matrix[i, j] += 0.6\n\n    # k-Nearest Neighbors\n    k_nearest_neighbors = 4\n    for i in range(n):\n        neighbors_idx = np.argsort(distance_matrix[i, :])[1:k_nearest_neighbors + 1]\n        for nn in neighbors_idx:\n            heuristic_matrix[i, nn] += 0.3\n\n    # Sparsification\n    threshold = np.quantile(heuristic_matrix[heuristic_matrix > 0], 0.2)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix = heuristic_matrix / max_heuristic\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the top heuristic uses depot proximity with adaptive pruning, angle from depot, and sparsification based on the mean of heuristic values, while the bottom heuristic relies on inverse distance, demand consideration, depot proximity, k-NN, and sparsification using a quantile-based threshold. The top heuristic also focuses on pruning infeasible edges related to capacity early on.\nComparing (2nd best) vs (2nd worst), the second-best also contains depot proximity, angle from depot, and sparsification but lacks the explicit adaptive pruning based on capacity constraints. The second-worst only calculates demand penalty instead of hard pruning edges.\nComparing (1st) vs (2nd), we see the top heuristic includes stronger depot connection boosts and considers a normalized angle reward, while the second heuristic omits the route completion incentive.\nComparing (3rd) vs (4th), the 3rd and 4th heuristic are similar, but the 4th heuristic incorporates route completion incentives, stronger depot connection boosts, and a more sophisticated sparsification approach based on combined distance and demand. Comparing (second worst) vs (worst), both functions are virtually identical. Overall: The better heuristics incorporate more nuanced adaptive sparsification techniques (based on means and combined metrics), depot proximity and angle considerations and prioritize pruning infeasible edges.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine \"Current self-reflection\" for designing better heuristics, avoiding the pitfalls of \"Ineffective self-reflection\" (which is currently empty, implying all current reflections are potentially valuable). Here's a redefinition:\n\n*   **Keywords:** Adaptive pruning, problem constraints, factor combinations (distance, demand, angles), normalization, iterative refinement, k-NN intensification, sparsification, depot-specific adjustments, weight tuning.\n*   **Advice:** Begin with simple, intuitive heuristics. Incrementally add sophistication (k-NN, sparsification, depot adjustments) while prioritizing weight tuning for parameter control and balance.\n*   **Avoid:** Overly complex combinations or excessively specific calculations early on. Prematurely dismissing the value of weight optimization.\n*   **Explanation:** Start simple, normalize to stabilize, adapt based on problem constraints, tune weights to balance factors, and iteratively improve the heuristic's components.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}