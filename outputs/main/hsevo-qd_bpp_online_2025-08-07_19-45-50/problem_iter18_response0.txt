```python
import numpy as np
from collections import deque

_adaptive_state = {
    "usage_counts": np.array([], dtype=int),
    "waste_window": deque(maxlen=200)
}

def _ensure_state_len(n):
    global _adaptive_state
    uc = _adaptive_state["usage_counts"]
    if uc.shape[0] < n:
        _adaptive_state["usage_counts"] = np.concatenate([uc, np.zeros(n-uc.shape[0], dtype=int)])

def priority_v2(item, bins_remain_cap):
    global _adaptive_state
    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)
    n_bins = bins_remain_cap.shape[0]
    _ensure_state_len(n_bins)
    feasible = bins_remain_cap >= item
    if not np.any(feasible):
        return np.zeros_like(bins_remain_cap, dtype=float)
    residual = bins_remain_cap - item
    resid_feas = residual[feasible]
    tight_thr = np.percentile(resid_feas, 20) if resid_feas.size > 0 else 0.0
    tight_mask = (residual <= tight_thr) & feasible
    tight_ratio = tight_mask.sum() / feasible.sum()
    alpha = 0.5 + 0.5 * tight_ratio
    if _adaptive_state["waste_window"]:
        avg_waste = sum(_adaptive_state["waste_window"]) / len(_adaptive_state["waste_window"])
        waste_factor = avg_waste / (bins_remain_cap.mean() + 1e-9)
        alpha = np.clip(alpha + 0.2 * waste_factor, 0, 1)
    beta = 1.0 - alpha
    usage = _adaptive_state["usage_counts"]
    usage_norm = usage.astype(float) / (usage.max() + 1e-9)
    raw = np.full_like(bins_remain_cap, -np.inf, dtype=float)
    raw[feasible] = -alpha * residual[feasible] - beta * usage_norm[feasible]
    max_raw = np.max(raw)
    exp_scores = np.exp(raw - max_raw)
    sum_exp = np.sum(exp_scores)
    probs = exp_scores / sum_exp if sum_exp > 0 else np.zeros_like(exp_scores)
    chosen = np.argmax(probs)
    _adaptive_state["usage_counts"][chosen] += 1
    _adaptive_state["waste_window"].append(residual[chosen])
    return probs
```
