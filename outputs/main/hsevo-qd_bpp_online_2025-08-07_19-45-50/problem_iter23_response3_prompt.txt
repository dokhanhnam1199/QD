{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    epsilon: float = 0.0,\n    temperature: float = 1.0,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"Combine waste\u2011based score (-remaining) with \u03b5\u2011greedy random component and temperature\u2011scaled softmax for balanced exploration/exploitation.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    feasible = bins >= item\n    if not np.any(feasible):\n        return np.full_like(bins, -np.inf, dtype=float)\n    rng = np.random.default_rng(random_state)\n    deterministic = -(bins - item)\n    random_scores = rng.random(bins.shape)\n    mixed = (1.0 - epsilon) * deterministic + epsilon * random_scores\n    mixed = np.where(feasible, mixed, -np.inf)\n    temp = max(temperature, 1e-12)\n    max_val = np.max(mixed[feasible])\n    shifted = mixed - max_val\n    exp_vals = np.exp(shifted / temp)\n    exp_vals = np.where(feasible, exp_vals, 0.0)\n    probs = exp_vals / exp_vals.sum()\n    return probs\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    epsilon: float = 0.0,\n    temperature: float = 1.0,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"Blend waste\u2011based score, rank weighting, \u03b5\u2011greedy perturbation, and temperature.\"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    waste = bins_remain_cap[feasible] - item\n    deterministic = -waste\n    rng = np.random.default_rng(random_state)\n    random_scores = rng.random(waste.shape)\n    mixed = (1.0 - epsilon) * deterministic + epsilon * random_scores\n    order = np.argsort(waste)\n    ranks = np.empty_like(order)\n    ranks[order] = np.arange(waste.size)\n    mixed *= 1.0 / (ranks + 1.0)\n    if temperature != 1.0:\n        mixed = mixed / temperature\n    scores[feasible] = mixed\n    return scores\n\n### Analyze & experience\n- - **Best (Heuristic\u202f1) vs Worst (Heuristic\u202f20):**\u202fHeuristic\u202f1 has a concise docstring, explicit feasibility mask, early exit, optional RNG injection, \u03b5\u2011greedy uniform exploration, temperature\u2011scaled softmax with log\u2011sum\u2011exp stability, and returns a proper probability distribution.\u202fHeuristic\u202f20 blends waste, rank weighting, and \u03b5\u2011perturbation but never normalises, lacks log\u2011sum\u2011exp, uses ad\u2011hoc scaling, and returns raw scores, making it numerically unstable and harder to interpret.  \n- **Second\u2011best (Heuristic\u202f2) vs Second\u2011worst (Heuristic\u202f19):**\u202fBoth implement the same softmax idea, but Heuristic\u202f2 is clean, has no stray comments, and uses a direct \u201cif rng is None\u201d pattern.\u202fHeuristic\u202f19 contains a placeholder comment (`temp  # placeholder to avoid unused variable warning`), duplicated logic from 18, and less\u2011direct variable naming, slightly reducing readability and hinting at sloppy maintenance.  \n- **Heuristic\u202f1 vs Heuristic\u202f2:**\u202fThe source code and docstring are identical; no functional or stylistic difference, confirming the ranking is based on external criteria rather than code quality.  \n- **Heuristic\u202f3 vs Heuristic\u202f4:**\u202fAgain identical implementations, showing redundancy; both share the same docstring and logic, indicating no quality distinction.  \n- **Second\u2011worst (Heuristic\u202f19) vs Worst (Heuristic\u202f20):**\u202fHeuristic\u202f19 performs a stable softmax (subtract max, exponentiate, normalise) and respects temperature scaling, while Heuristic\u202f20 applies rank\u2011based weighting on raw waste, does not apply a softmax nor temperature, and leaves the output unnormalised.\u202fThe former yields a well\u2011behaved probability distribution; the latter can produce arbitrary magnitudes and is more sensitive to scale.  \n- **Additional illustrative pairs:**  \n  - **Heuristic\u202f5 vs Heuristic\u202f6:**\u202fHeuristic\u202f5 returns deterministic \u2013waste without normalisation; Heuristic\u202f6 adds a stable softmax with \u03b5\u2011greedy, producing proper probabilities and smoother exploration.  \n  - **Heuristic\u202f7 vs Heuristic\u202f8:**\u202fHeuristic\u202f7 uses a hard\u2011coded huge constant for exact fits; Heuristic\u202f8 blends deterministic waste, random noise, and temperature\u2011scaled softmax, giving a tunable exploration\u2011exploitation balance.  \n  - **Heuristic\u202f13 vs Heuristic\u202f14:**\u202fHeuristic\u202f13 augments negative waste with a logistic fill\u2011ratio term before softmax, enriching the feature set; Heuristic\u202f14 uses plain softmax on waste only, simpler but potentially less discriminative.  \n\n**Overall:**\u202fTop\u2011ranked heuristics consistently (i) provide clear documentation, (ii) mask infeasible bins early, (iii) employ a numerically stable softmax (log\u2011sum\u2011exp), (iv) expose a controllable \u03b5\u2011greedy exploration with an injectable RNG, and (v) return normalized probability vectors. Lower\u2011ranked versions omit one or more of these pillars, leading to instability, ambiguous outputs, or harder tuning.\n- \n- **Keywords**: Dynamic weighting, ensemble, feedback\u2011driven, meta\u2011learning.  \n- **Advice**: Combine multiple scoring functions into an ensemble, continuously update each component\u2019s influence from observed outcomes, and let a meta\u2011learner propose parameter tweaks when performance deviates from expectations.  \n- **Avoid**: Fixed thresholds, static weight assignments, hand\u2011crafted parameters that never change, and isolated heuristics lacking self\u2011tuning.  \n- **Explanation**: Dynamic ensembles keep the search diverse, feedback refines component relevance, meta\u2011learning automates tuning, while static designs quickly become brittle across varied problem instances.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}