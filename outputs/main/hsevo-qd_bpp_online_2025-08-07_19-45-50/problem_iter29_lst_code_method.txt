{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.1, tau: float = 1.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Temperature-scaled softmax with optional epsilon-greedy exploration; returns normalized priorities for feasible bins.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if rng is None:\n        rng = np.random.default_rng()\n    if rng.random() < epsilon:\n        probs = np.zeros_like(bins_remain_cap, dtype=float)\n        probs[feasible] = 1.0 / np.count_nonzero(feasible)\n        return probs\n    residual = bins_remain_cap.astype(float) - item\n    raw_scores = -residual / tau\n    raw_scores[~feasible] = -np.inf\n    max_score = np.max(raw_scores)\n    exp_scores = np.exp(raw_scores - max_score)\n    sum_exp = np.sum(exp_scores)\n    return exp_scores / sum_exp if sum_exp > 0 else np.zeros_like(exp_scores)\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns softmax-based priority for placing an item into each bin.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    caps = bins_remain_cap.astype(float)\n    residual = caps - item\n    raw_scores = np.where(feasible, -residual, -np.inf)\n    max_score = raw_scores.max()\n    exp_scores = np.exp(raw_scores - max_score)\n    sum_exp = exp_scores.sum()\n    priorities = exp_scores / sum_exp if sum_exp > 0 else np.zeros_like(exp_scores)\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                temperature: float = 1.0,\n                epsilon: float = 0.0,\n                rng: np.random.Generator | None = None) -> np.ndarray:\n    \"\"\"Combine epsilon\u2011greedy random exploration with a temperature\u2011scaled softmax on negative residual (waste) to produce a normalized probability vector over feasible bins.\"\"\"\n    # Epsilon\u2011greedy + temperature\u2011scaled softmax on waste\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0.0 and rng.random() < epsilon:\n        rand_vals = rng.random(bins_remain_cap.shape)\n        scores = np.where(feasible, rand_vals, 0.0)\n        total = scores.sum()\n        return scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float) \n    temp = max(temperature, 1e-12)\n    raw = np.where(feasible, -residual / temp, -np.inf)\n    max_raw = np.max(raw)\n    exp_raw = np.exp(raw - max_raw)\n    sum_exp = exp_raw.sum()\n    return exp_raw / sum_exp if sum_exp > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 4th]\nimport numpy as np\n\n# Priority function combining stable softmax and epsilon\u2011greedy exploration.\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                temperature: float = 1.0,\n                epsilon: float = 0.0,\n                rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Compute bin selection probabilities via temperature\u2011scaled softmax on negative waste, with optional epsilon\u2011greedy random exploration.\"\"\"\n    if rng is None:\n        rng = 0  # placeholder, will be overridden\n    # Initialize RNG lazily to avoid default_rng call overhead when not needed\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_vals = rng.random(bins_remain_cap.shape)\n        scores = np.where(feasible, rand_vals, 0.0)\n        total = scores.sum()\n        return scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n    raw = -residual\n    raw[~feasible] = -np.inf\n    temp = max(temperature, 1e-12)\n    scaled = raw / temp\n    max_score = scaled[feasible].max()\n    exp_scores = np.exp(scaled - max_score)\n    exp_scores[~feasible] = 0.0\n    total = exp_scores.sum()\n    return exp_scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 5th]\nimport numpy as np\nfrom typing import Optional\n\n# Priority function for online bin packing: waste + rank + \u03b5\u2011weighted random.\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                *,\n                temperature: float = 1.0,\n                epsilon: float = 0.0,\n                rank_power: float = 1.0,\n                rng: Optional[np.random.Generator] = None) -> np.ndarray:\n    \"\"\"Combine waste, rank weight, and \u03b5\u2011weighted random perturbation; temperature scales waste.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    residual = bins - item\n    feasible = residual >= 0\n    scores = np.full_like(bins, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    waste = -residual[feasible] / max(temperature, 1e-12)\n    feas_res = residual[feasible]\n    sorted_idx = np.argsort(feas_res)\n    rank = np.empty_like(feas_res, dtype=int)\n    rank[sorted_idx] = np.arange(len(feas_res))\n    num_feas = len(feas_res)\n    rank_weight = (num_feas - rank) ** rank_power\n    deterministic = waste + np.log(rank_weight + 1e-12)\n    if epsilon > 0.0:\n        rand = rng.random(num_feas)\n        deterministic = (1 - epsilon) * deterministic + epsilon * rand\n    scores[feasible] = deterministic\n    return scores\n\n[Heuristics 6th]\nimport numpy as np\nfrom typing import Optional\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.0,\n                random_state: Optional[int] = None) -> np.ndarray:\n    \"\"\"Compute bin priority using negative waste and optional \u03b5\u2011greedy random scores; returns a probability vector.\"\"\"\n    # Combine deterministic waste minimization with \u03b5\u2011greedy exploration.\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    rng = np.random.default_rng(random_state)\n    if epsilon > 0.0 and rng.random() < epsilon:\n        scores = np.where(feasible, rng.random(bins_remain_cap.shape[0]), -np.inf)\n    else:\n        waste = bins_remain_cap - item\n        scores = np.where(feasible, -waste, -np.inf)\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)\n    exp_scores[~feasible] = 0.0\n    prob = exp_scores / np.sum(exp_scores)\n    return prob\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                tau: float = 1.0,\n                epsilon: float = 0.0,\n                rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Softmax priority with temperature and optional epsilon\u2011greedy exploration.\"\"\"\n    # feasible bins: enough remaining capacity for the item\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if rng is None:\n        rng = np.random.default_rng()\n    # epsilon\u2011greedy: uniform random scores over feasible bins\n    if rng.random() < epsilon:\n        rand = rng.random(bins_remain_cap.shape[0])\n        rand[~feasible] = 0.0\n        s = rand.sum()\n        return rand / s if s > 0 else np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    # temperature\u2011scaled softmax on negative waste (higher score \u2192 less waste)\n    scores = np.where(feasible, -(bins_remain_cap - item) / tau, -np.inf)\n    max_score = np.max(scores[feasible])\n    exp_scores = np.exp(scores - max_score)          # infeasible become 0\n    total = exp_scores.sum()\n    return exp_scores / total if total > 0 else np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                invalid_penalty: float = -399791891471.3008,\n                k: float = 10.75578991421134,\n                valid_threshold: float = -8.081944853392542,\n                target_ratio: float = 1.8029961731356514,\n                max_priority: float = 5.707291766401017,\n                denominator_offset: float = 9.926378914375567) -> np.ndarray:\n    caps = bins_remain_cap.astype(float)\n    space_left = caps - item\n    valid = space_left >= valid_threshold\n    priorities = np.full_like(space_left, invalid_penalty, dtype=float)\n    if np.any(valid):\n        ratio = space_left[valid] / caps[valid]\n        priorities[valid] = max_priority / (\n            denominator_offset + np.exp(-k * (target_ratio - ratio))\n        )\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Priority based on logistic slack ratio with \u03b5\u2011greedy softmax exploration.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    ratio = residual / bins_remain_cap\n    k = 12.0\n    deterministic = 1.0 / (1.0 + np.exp(-k * (1.0 - ratio)))\n    deterministic[~feasible] = -np.inf\n    random_scores = rng.random(bins_remain_cap.shape[0])\n    random_scores[~feasible] = -np.inf\n    combined = (1.0 - epsilon) * deterministic + epsilon * random_scores\n    max_comb = combined[feasible].max()\n    exp_comb = np.exp(combined - max_comb)\n    exp_comb[~feasible] = 0.0\n    probs = exp_comb / exp_comb.sum()\n    return probs\n\n[Heuristics 10th]\nimport numpy as np\n\n# Priority function combining exact-fit bias with softmax waste scoring and epsilon\u2011greedy exploration.\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                epsilon: float = 0.0,\n                temperature: float = 1.0,\n                rng: np.random.Generator | None = None) -> np.ndarray:\n    \"\"\"Exact\u2011fit bias, softmax on waste, optional epsilon\u2011greedy randomization.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0.0 and rng.random() < epsilon:\n        rand_vals = rng.random(bins_remain_cap.shape[0])\n        scores = np.where(feasible, rand_vals, 0.0)\n        total = scores.sum()\n        if total > 0.0:\n            return scores / total\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    exact = (residual == 0) & feasible\n    if np.any(exact):\n        prob = np.where(exact, 1.0, 0.0)\n        return prob / prob.sum()\n    waste = residual\n    raw = -waste\n    raw[~feasible] = -np.inf\n    scaled = raw / max(temperature, 1e-12)\n    max_raw = np.max(scaled[feasible])\n    exp_scores = np.exp(scaled - max_raw)\n    exp_scores[~feasible] = 0.0\n    total = exp_scores.sum()\n    if total > 0.0:\n        return exp_scores / total\n    return np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.01) -> np.ndarray:\n    \"\"\"Exact-fit-first priority with optional epsilon-greedy exploration.\"\"\"\n    # Feasibility mask and deterministic priority (negative waste)\n    feasible = bins_remain_cap >= item\n    deterministic = np.where(feasible, -(bins_remain_cap - item), -np.inf)\n    # With probability epsilon, use random scores for feasible bins\n    if np.random.rand() < epsilon:\n        random_scores = np.random.rand(bins := bins_remain_cap.shape[0])\n        return np.where(feasible, random_scores, -np.inf)\n    return deterministic\n\n[Heuristics 12th]\nimport numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    temperature: float = 1.0,\n    epsilon: float = 0.0,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"Waste\u2011based deterministic scores blended with \u03b5\u2011greedy random, temperature\u2011scaled logits, and Gumbel noise.\"\"\"\n    caps = bins_remain_cap = bins_remain_cap.astype(float)\n    feasible = caps >= item\n    scores = np.full_like(caps, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    waste = caps[feasible] - item\n    deterministic = -waste\n    rng = np.random.default_rng(random_state)\n    random_scores = rng.random(waste.shape)\n    mixed = (1.0 - epsilon) * deterministic + epsilon * random_scores\n    # temperature scales deterministic logits; lower temperature => more deterministic\n    logits = mixed / max(temperature, 1e-12)\n    # Gumbel perturbation for stochastic exploration\n    u = rng.random(logits.shape)\n    eps = 1e-9\n    gumbel = -np.log(-np.log(u + eps) + eps)\n    final = logits + gumbel\n    scores[feasible] = final\n    return scores\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, tau: float = 1.0,\n                epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Softmax fit (temp\u202ftau) with epsilon\u2011greedy random exploration.\"\"\"\n    # Combine stable softmax scoring of waste with occasional random scoring.\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    mask = residual >= 0\n    if not np.any(mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_scores = rng.random(bins_remain_cap.shape[0])\n        rand_scores[~mask] = -np.inf\n        max_rand = rand_scores[mask].max()\n        exp_rand = np.exp(rand_scores - max_rand)\n        exp_rand[~mask] = 0.0\n        total_rand = exp_rand.sum()\n        return exp_rand / total_rand if total_rand > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    temperature: float = 1.0,\n    epsilon: float = 0.0,\n    rng: np.random.Generator | None = None,\n) -> np.ndarray:\n    \"\"\"Probability over bins via temperature\u2011scaled softmax on negative waste with epsilon\u2011greedy exploration.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand = rng.random(bins_remain_cap.shape)\n        scores = np.where(feasible, rand, 0.0)\n        total = scores.sum()\n        return scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n    scores = -residual\n    scores = np.where(feasible, scores, -np.inf)\n    temp  # placeholder to avoid unused variable warning\n    temp = max(temperature, 1e-12)\n    scaled = scores / temp\n    max_score = np.max(scaled[feasible])\n    exp_scores = np.exp(scaled - max_score)\n    exp_scores = np.where(feasible, exp_scores, 0.0)\n    total = exp_scores.sum()\n    return exp_scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    temperature: float = 1.0,\n    epsilon: float = 0.0,\n    rng: np.random.Generator | None = None,\n) -> np.ndarray:\n    \"\"\"Probability over bins via temperature\u2011scaled softmax on negative waste with epsilon\u2011greedy exploration.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand = rng.random(bins_remain_cap.shape)\n        scores = np.where(feasible, rand, 0.0)\n        total = scores.sum()\n        return scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n    scores = -residual\n    scores = np.where(feasible, scores, -np.inf)\n    temp  # placeholder to avoid unused variable warning\n    temp = max(temperature, 1e-12)\n    scaled = scores / temp\n    max_score = np.max(scaled[feasible])\n    exp_scores = np.exp(scaled - max_score)\n    exp_scores = np.where(feasible, exp_scores, 0.0)\n    total = exp_scores.sum()\n    return exp_scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    temperature: float = 1.0,\n    epsilon: float = 0.0,\n    rng: np.random.Generator | None = None,\n) -> np.ndarray:\n    \"\"\"Probability over bins via temperature\u2011scaled softmax on negative waste with epsilon\u2011greedy exploration.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand = rng.random(bins_remain_cap.shape)\n        scores = np.where(feasible, rand, 0.0)\n        total = scores.sum()\n        return scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n    scores = -residual\n    scores = np.where(feasible, scores, -np.inf)\n    temp  # placeholder to avoid unused variable warning\n    temp = max(temperature, 1e-12)\n    scaled = scores / temp\n    max_score = np.max(scaled[feasible])\n    exp_scores = np.exp(scaled - max_score)\n    exp_scores = np.where(feasible, exp_scores, 0.0)\n    total = exp_scores.sum()\n    return exp_scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    temperature: float = 1.0,\n    epsilon: float = 0.0,\n    rng: np.random.Generator | None = None,\n) -> np.ndarray:\n    \"\"\"Probability over bins via temperature\u2011scaled softmax on negative waste with epsilon\u2011greedy exploration.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand = rng.random(bins_remain_cap.shape)\n        scores = np.where(feasible, rand, 0.0)\n        total = scores.sum()\n        return scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n    scores = -residual\n    scores = np.where(feasible, scores, -np.inf)\n    temp  # placeholder to avoid unused variable warning\n    temp = max(temperature, 1e-12)\n    scaled = scores / temp\n    max_score = np.max(scaled[feasible])\n    exp_scores = np.exp(scaled - max_score)\n    exp_scores = np.where(feasible, exp_scores, 0.0)\n    total = exp_scores.sum()\n    return exp_scores / total if total > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 18th]\nimport numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    epsilon: float = 0.0,\n    temperature: float = 1.0,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"Blend waste\u2011based score, rank weighting, \u03b5\u2011greedy perturbation, and temperature.\"\"\"\n    feasible = bins_remain_cap >= item\n    scores = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return scores\n    waste = bins_remain_cap[feasible] - item\n    deterministic = -waste\n    rng = np.random.default_rng(random_state)\n    random_scores = rng.random(waste.shape)\n    mixed = (1.0 - epsilon) * deterministic + epsilon * random_scores\n    order = np.argsort(waste)\n    ranks = np.empty_like(order)\n    ranks[order] = np.arange(waste.size)\n    mixed *= 1.0 / (ranks + 1.0)\n    if temperature != 1.0:\n        mixed = mixed / temperature\n    scores[feasible] = mixed\n    return scores\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, rng: np.random.Generator = None,\n                tau: float = 1.0, alpha: float = 1.5, penalty_factor: float = 0.5,\n                noise_base: float = 0.1, risk_factor: float = 0.1) -> np.ndarray:\n    \"\"\"Rank\u2011based adaptive priority for online bin packing.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    penalty = np.where(feasible, 0.0, (item - bins_remain_cap) * penalty_factor)\n    base_score = -residual - penalty\n    max_residual = np.max(residual[feasible])\n    risk = np.where(feasible, 1 - residual / (max_residual + 1e-12), 0.0)\n    base_score -= risk_factor * risk\n    order = np.argsort(-base_score)\n    rank = np.empty_like(order)\n    rank[order] = np.arange(len(base_score))\n    weight = 1.0 / (rank + 1) ** alpha\n    raw_scores = base_score * weight\n    noise_scale = noise_base * (residual / (max_residual + 1e-12))\n    noise_scale = np.maximum(noise_scale, 0.0)\n    noise = rng.normal(0.0, noise_scale, size=bins_remain_cap.shape)\n    raw_scores += noise\n    max_raw = np.max(raw_scores)\n    exp_scores = np.exp((raw_scores - max_raw) / tau)\n    probs = exp_scores / np.sum(exp_scores)\n    return probs\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, rng: np.random.Generator = None,\n                tau: float = 1.0, alpha: float = 1.5, penalty_factor: float = 0.5,\n                noise_base: float = 0.1, risk_factor: float = 0.1) -> np.ndarray:\n    \"\"\"Rank\u2011based adaptive priority for online bin packing.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    penalty = np.where(feasible, 0.0, (item - bins_remain_cap) * penalty_factor)\n    base_score = -residual - penalty\n    max_residual = np.max(residual[feasible])\n    risk = np.where(feasible, 1 - residual / (max_residual + 1e-12), 0.0)\n    base_score -= risk_factor * risk\n    order = np.argsort(-base_score)\n    rank = np.empty_like(order)\n    rank[order] = np.arange(len(base_score))\n    weight = 1.0 / (rank + 1) ** alpha\n    raw_scores = base_score * weight\n    noise_scale = noise_base * (residual / (max_residual + 1e-12))\n    noise_scale = np.maximum(noise_scale, 0.0)\n    noise = rng.normal(0.0, noise_scale, size=bins_remain_cap.shape)\n    raw_scores += noise\n    max_raw = np.max(raw_scores)\n    exp_scores = np.exp((raw_scores - max_raw) / tau)\n    probs = exp_scores / np.sum(exp_scores)\n    return probs\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}