```python
import numpy as np

# Softmax of negative waste with exact‑fit boost and ε‑greedy exploration.
def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                *,
                epsilon: float = 0.0,
                tau: float = 1.0,
                exact_fit_bonus: float = 2.0,
                rng: np.random.Generator = None) -> np.ndarray:
    """Return normalized priorities: softmax(-waste/τ) + bias for exact fits."""
    if rng is None:
        rng = np.random.default_rng()
    feasible = bins_remain_cap >= item
    if not np.any(feasible):
        return np.zeros_like(bins_remain_cap, dtype=float)
    if epsilon > 0.0 and rng.random() < epsilon:
        probs = np.zeros_like(bins_remain_cap, dtype=float)
        probs[feasible] = 1.0 / feasible.sum()
        return probs
    waste = bins_remain_cap - item
    bias = np.where(waste == 0, exact_fit_bonus, 0.0)
    raw_scores = -(waste) / tau + bias
    raw_scores[~feasible] = -np.inf
    max_score = np.max(raw_scores)
    # stable softmax
    exp_scores = np.exp(raw_scores - max_score)
    sum_exp = np.sum(exp_scores)
    if sum_exp == 0.0:
        return np.zeros_like(bins_remain_cap, dtype=float)
    return exp_scores / sum_exp
```
