{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\nCurrent heuristics:\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Temperature-scaled softmax with optional epsilon-greedy exploration; returns normalized priorities for feasible bins.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if rng is None:\n        rng = np.random.default_rng()\n    if rng.random() < epsilon:\n        probs = np.zeros_like(bins_remain_cap, dtype=float)\n        probs[feasible] = 1.0 / np.count_nonzero(feasible)\n        return probs\n    residual = bins_remain_cap.astype(float) - item\n    raw_scores = -residual / tau\n    raw_scores[~feasible] = -np.inf\n    max_score = np.max(raw_scores)\n    exp_scores = np.exp(raw_scores - max_score)\n    sum_exp = np.sum(exp_scores)\n    return exp_scores / sum_exp if sum_exp > 0 else np.zeros_like(exp_scores)\n\nNow, think outside the box write a mutated function `priority_v2` better than current version.\nYou can use some hints below:\n- \n- **Keywords:** temperature scaling, max\u2011value subtraction, prune invalid choices, calibrated randomness, minimal hyper\u2011parameters, reproducibility.  \n- **Advice:** use temperature\u2011scaled scores after subtracting the max; ignore invalid candidates at the start; add calibrated Gumbel perturbations for exploration; expose only knobs, leave other parts unchanged.  \n- **Avoid:** hard\u2011coded magic numbers, layered penalty transforms, redundant branches, hidden randomness, over\u2011engineered feature combos.  \n- **Explanation:** subtracting the max score before exponentiation prevents overflow while preserving relative ordering; ignoring invalid candidates early ensures no probability goes to them; calibrated perturbations give controlled exploration without destabilizing the search; a hyper\u2011parameter set stays transparent, easy to tune, and reproducible with seeded RNG.\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}