{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.1, tau: float = 1.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Temperature-scaled softmax with optional epsilon-greedy exploration; returns normalized priorities for feasible bins.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if rng is None:\n        rng = np.random.default_rng()\n    if rng.random() < epsilon:\n        probs = np.zeros_like(bins_remain_cap, dtype=float)\n        probs[feasible] = 1.0 / np.count_nonzero(feasible)\n        return probs\n    residual = bins_remain_cap.astype(float) - item\n    raw_scores = -residual / tau\n    raw_scores[~feasible] = -np.inf\n    max_score = np.max(raw_scores)\n    exp_scores = np.exp(raw_scores - max_score)\n    sum_exp = np.sum(exp_scores)\n    return exp_scores / sum_exp if sum_exp > 0 else np.zeros_like(exp_scores)\n\n[Heuristics 2nd]\nimport numpy as np\n\n# Stable softmax priority with optional \u03b5\u2011greedy exploration for online bin packing.\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                tau: float = 0.5, epsilon: float = 0.0,\n                rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Return probability scores for each bin based on remaining capacity, using a temperature\u2011scaled softmax; optionally explore randomly via \u03b5\u2011greedy.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    scores = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return scores\n    if epsilon > 0.0 and rng.random() < epsilon:\n        rand = rng.random(feasible.sum())\n        probs = rand / rand.sum()\n        scores[feasible] = probs\n        return scores\n    slack = bins_remain_cap[feasible] - item\n    raw = -slack / tau\n    max_raw = raw.max()\n    exp_vals = np.exp(raw - max_raw)\n    probs = exp_vals / exp_vals.sum()\n    scores[feasible] = probs\n    return scores\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    caps = bins_remain_cap.astype(float)\n    space_left = caps - item\n    valid = space_left >= 0\n    priorities = np.full_like(space_left, -1e9, dtype=float)\n    if np.any(valid):\n        ratio = space_left[valid] / caps[valid]\n        k = 12.0\n        priorities[valid] = 1.0 / (1.0 + np.exp(-k * (1.0 - ratio)))\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\nfrom typing import Optional\n\n# Priority function combining deterministic waste and optional epsilon\u2011greedy exploration\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.0,\n                random_state: Optional[int] = None) -> np.ndarray:\n    \"\"\"Priority = -waste for feasible bins; optional epsilon\u2011greedy random scores.\"\"\"\n    feasible = bins_remain_cap >= item\n    if epsilon > 0.0:\n        rng = np.random.default_rng(random_state)\n        if rng.random() < epsilon:\n            rand_scores = rng.random(bins_remain_cap.shape[0])\n            return np.where(feasible, rand_scores, -np.inf)\n    waste = bins_remain_cap - item\n    return np.where(feasible, -waste, -np.inf)\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    priorities[feasible] = -residual[feasible]\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.0, temperature: float = 1.0) -> np.ndarray:\n    \"\"\"Epsilon\u2011greedy softmax: random scores with prob \u03b5, else residual\u2011based softmax.\"\"\"\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if np.random.rand() < epsilon:\n        rand_scores = np.random.rand(bins_remain_cap.shape[0])\n        raw = np.where(feasible, rand_scores, -np.inf)\n    else:\n        residual = bins_remain_cap.astype(float) - item\n        raw = np.where(feasible, -residual / max(temperature, 1e-12), -np.inf)\n    max_raw = np.max(raw)\n    exp_raw = np.exp(raw - max_raw)\n    sum_exp = exp_raw.sum()\n    return exp_raw / sum_exp if sum_exp > 0 else np.zeros_like(exp_raw)\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                tau: float = 1.0,\n                epsilon: float = 0.1,\n                rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"\n    Temperature-scaled softmax with epsilon-greedy exploration over feasible bins; returns probability vector.\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    det_score = np.where(feasible, -(bins_remain_cap - item), -np.inf)\n    max_score = np.max(det_score[feasible])\n    shifted = (det_score - max_score) / max(tau, 1e-12)\n    exp_shifted = np.exp(shifted) * feasible\n    sum_exp = exp_shifted.sum()\n    if sum_exp > 0:\n        softmax = exp_shifted / sum_exp\n    else:\n        max_mask = (det_score == max_score) & feasible\n        count_max = max_mask.sum()\n        softmax = np.where(max_mask, 1.0 / count_max, 0.0)\n    rand_vals = rng.random(bins_remain_cap.shape) * feasible\n    sum_rand = rand_vals.sum()\n    if sum_rand > 0:\n        rand_dist = rand_vals / sum_rand\n    else:\n        rand_dist = np.zeros_like(bins_remain_cap, dtype=float)\n    combined = (1.0 - epsilon) * softmax + epsilon * rand_dist\n    return np.where(feasible, combined, -np.inf)\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, temperature: float = 1.0,\n                epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"\n    Softmax fit with temperature and optional epsilon\u2011greedy randomization.\n    Tighter fits get higher probability; random selection occurs with probability epsilon.\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    feasible = residual >= 0\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_vals = rng.random(bins_remain_cap.shape[0])\n        scores = np.where(feasible, rand_vals, 0.0)\n        total = scores.sum()\n        if total == 0:\n            return np.zeros_like(bins_remain_cap, dtype=float)\n        return scores / total\n    raw = -residual\n    raw[~feasible] = -np.inf\n    scaled = raw / max(temperature, 1e-12)\n    max_score = scaled[feasible].max()\n    exp_scores = np.exp(scaled - max_score)\n    exp_scores[~feasible] = 0.0\n    total = exp_scores.sum()\n    if total == 0:\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    return exp_scores / total\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, tau: float = 1.0, epsilon: float = 0.0) -> np.ndarray:\n    \"\"\"Softmax of negative slack with temperature and optional epsilon\u2011greedy exploration.\"\"\"\n    feasible = bins_remain_cap >= item\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    if np.any(feasible):\n        slack = bins_remain_cap[feasible] - item\n        idx = np.nonzero(feasible)[0]\n        priorities[idx] = -slack\n        exact_idx = idx[slack == 0]\n        priorities[exact_idx] = 1e12\n        if tau > 0:\n            priorities[idx] = priorities[idx] / tau\n        if epsilon > 0 and np.random.rand() < epsilon:\n            priorities[idx] = np.random.rand(len(idx))\n        else:\n            max_val = np.max(priorities[idx])\n            exp_vals = np.exp(priorities[idx] - max_val)\n            probs = exp_vals / np.sum(exp_vals)\n            priorities[idx] = probs\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    feasible = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n    priorities[feasible] = -residual[feasible]\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.01) -> np.ndarray:\n    \"\"\"Exact-fit-first priority with optional epsilon-greedy exploration.\"\"\"\n    # Feasibility mask and deterministic priority (negative waste)\n    feasible = bins_remain_cap >= item\n    deterministic = np.where(feasible, -(bins_remain_cap - item), -np.inf)\n    # With probability epsilon, use random scores for feasible bins\n    if np.random.rand() < epsilon:\n        random_scores = np.random.rand(bins := bins_remain_cap.shape[0])\n        return np.where(feasible, random_scores, -np.inf)\n    return deterministic\n\n[Heuristics 12th]\nimport numpy as np\n\n_EPSILON = 0.05\n_TEMPERATURE = 0.1\n_RNG = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Softmax priority with epsilon\u2011greedy exploration, stable and masked.\"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap)\n    if _RNG.random() < _EPSILON:\n        probs = np.zeros_like(bins_remain_cap)\n        probs[feasible] = 1.0 / feasible.sum()\n        return probs\n    residual = bins_remain_cap[feasible] - item\n    temperature = max(_TEMPERATURE, 1e-12)\n    logits = -residual / temperature\n    max_logit = np.max(logits)\n    exp_shifted = np.exp(logits - max_logit)\n    softmax = exp_shifted / np.sum(exp_shifted)\n    scores = np.zeros_like(bins_remain_cap)\n    scores[feasible] = softmax\n    return scores\n\n[Heuristics 13th]\nimport numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.1,\n    temperature: float = 0.1,\n    rng: Optional[np.random.Generator] = None,\n) -> np.ndarray:\n    \"\"\"Epsilon\u2011greedy softmax: random logits with prob \u03b5, else residual\u2011based softmax.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    feasible = bins >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins, dtype=float)\n    if rng is None:\n        rng = np.random.default_rng()\n    # Exploration: random logits; Exploitation: residual\u2011based logits.\n    if rng.random() < epsilon:\n        logits = np.where(feasible, rng.random(bins.shape), -np.inf)\n    else:\n        residual = bins - item\n        temp = max(temperature, 1e-12)\n        logits = np.where(feasible, -residual / temp, -np.inf)\n    # Stable softmax over feasible bins.\n    max_logit = np.max(logits[feasible])\n    exp_shifted = np.exp(logits - max_logit)\n    probs = exp_shifted / exp_shifted.sum()\n    return probs\n\n[Heuristics 14th]\nimport numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.1,\n    temperature: float = 0.1,\n    rng: Optional[np.random.Generator] = None,\n) -> np.ndarray:\n    \"\"\"Epsilon\u2011greedy softmax: random logits with prob \u03b5, else residual\u2011based softmax.\"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    feasible = bins >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins, dtype=float)\n    if rng is None:\n        rng = np.random.default_rng()\n    # Exploration: random logits; Exploitation: residual\u2011based logits.\n    if rng.random() < epsilon:\n        logits = np.where(feasible, rng.random(bins.shape), -np.inf)\n    else:\n        residual = bins - item\n        temp = max(temperature, 1e-12)\n        logits = np.where(feasible, -residual / temp, -np.inf)\n    # Stable softmax over feasible bins.\n    max_logit = np.max(logits[feasible])\n    exp_shifted = np.exp(logits - max_logit)\n    probs = exp_shifted / exp_shifted.sum()\n    return probs\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, tau: float = 1.0,\n                epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Softmax fit (temp\u202ftau) with epsilon\u2011greedy random exploration.\"\"\"\n    # Combine stable softmax scoring of waste with occasional random scoring.\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    mask = residual >= 0\n    if not np.any(mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_scores = rng.random(bins_remain_cap.shape[0])\n        rand_scores[~mask] = -np.inf\n        max_rand = rand_scores[mask].max()\n        exp_rand = np.exp(rand_scores - max_rand)\n        exp_rand[~mask] = 0.0\n        total_rand = exp_rand.sum()\n        return exp_rand / total_rand if total_rand > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, tau: float = 1.0,\n                epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Softmax fit (temp\u202ftau) with epsilon\u2011greedy random exploration.\"\"\"\n    # Combine stable softmax scoring of waste with occasional random scoring.\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    mask = residual >= 0\n    if not np.any(mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_scores = rng.random(bins_remain_cap.shape[0])\n        rand_scores[~mask] = -np.inf\n        max_rand = rand_scores[mask].max()\n        exp_rand = np.exp(rand_scores - max_rand)\n        exp_rand[~mask] = 0.0\n        total_rand = exp_rand.sum()\n        return exp_rand / total_rand if total_rand > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, tau: float = 1.0,\n                epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Softmax fit (temp\u202ftau) with epsilon\u2011greedy random exploration.\"\"\"\n    # Combine stable softmax scoring of waste with occasional random scoring.\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    mask = residual >= 0\n    if not np.any(mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_scores = rng.random(bins_remain_cap.shape[0])\n        rand_scores[~mask] = -np.inf\n        max_rand = rand_scores[mask].max()\n        exp_rand = np.exp(rand_scores - max_rand)\n        exp_rand[~mask] = 0.0\n        total_rand = exp_rand.sum()\n        return exp_rand / total_rand if total_rand > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, tau: float = 1.0,\n                epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Softmax fit (temp\u202ftau) with epsilon\u2011greedy random exploration.\"\"\"\n    # Combine stable softmax scoring of waste with occasional random scoring.\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    mask = residual >= 0\n    if not np.any(mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_scores = rng.random(bins_remain_cap.shape[0])\n        rand_scores[~mask] = -np.inf\n        max_rand = rand_scores[mask].max()\n        exp_rand = np.exp(rand_scores - max_rand)\n        exp_rand[~mask] = 0.0\n        total_rand = exp_rand.sum()\n        return exp_rand / total_rand if total_rand > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, tau: float = 1.0,\n                epsilon: float = 0.0, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Softmax fit (temp\u202ftau) with epsilon\u2011greedy random exploration.\"\"\"\n    # Combine stable softmax scoring of waste with occasional random scoring.\n    if rng is None:\n        rng = np.random.default_rng()\n    residual = bins_remain_cap - item\n    mask = residual >= 0\n    if not np.any(mask):\n        return np.zeros_like(bins_remain_cap, dtype=float)\n    if epsilon > 0 and rng.random() < epsilon:\n        rand_scores = rng.random(bins_remain_cap.shape[0])\n        rand_scores[~mask] = -np.inf\n        max_rand = rand_scores[mask].max()\n        exp_rand = np.exp(rand_scores - max_rand)\n        exp_rand[~mask] = 0.0\n        total_rand = exp_rand.sum()\n        return exp_rand / total_rand if total_rand > 0 else np.zeros_like(bins_remain_cap, dtype=float)\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.1, rng: np.random.Generator = None) -> np.ndarray:\n    \"\"\"Best\u2011fit logistic score blended with \u03b5\u2011greedy random exploration via stable softmax.\"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    feasible = bins_remain_cap >= item\n    if not feasible.any():\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    caps = bins_remain_cap.astype(float)\n    space_left = caps - item\n    ratio = np.empty_like(caps, dtype=float)\n    ratio[feasible] = space_left[feasible] / caps[feasible]\n    k = 12.0\n    deterministic = np.empty_like(caps, dtype=float)\n    deterministic[feasible] = 1.0 / (1.0 + np.exp(-k * (1.0 - ratio[feasible])))\n    random_scores = np.empty_like(caps, dtype=float)\n    random_scores[feasible] = rng.random(feasible.sum())\n    combined = (1.0 - epsilon) * deterministic + epsilon * random_scores\n    max_combined = combined[feasible].max()\n    exps = np.empty_like(caps, dtype=float)\n    exps[feasible] = np.exp(combined[feasible] - max_combined)\n    sum_exps = exps[feasible].sum()\n    probs = np.full_like(caps, -np.inf, dtype=float)\n    probs[feasible] = exps[feasible] / sum_exps\n    return probs\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}