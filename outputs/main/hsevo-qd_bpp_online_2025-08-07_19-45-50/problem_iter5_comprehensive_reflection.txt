
- **Keywords:** Softmax, numerical stability, explicit masking, early pruning, controlled randomness, temperature scaling, reproducible RNG, clear documentation.  
- **Advice:** Apply log‑sum‑exp softmax after masking infeasible entries; prune impossible bins early; tune temperature to balance exploration/exploitation; seed random generators for repeatable runs; document each scoring step.  
- **Avoid:** Raw `-inf`/NaN scores, unchecked overflow/underflow, fixed tie‑breakers that bias results, uncontrolled randomness that breaks reproducibility.  
- **Explanation:** Stabilized softmax keeps rankings reliable under extreme values; masking + early exit saves compute; temperature + seeded randomness yields diverse yet repeatable search; thorough docs prevent misuse and simplify debugging.