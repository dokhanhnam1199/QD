[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            # Prioritize bins where the item fits\n            remaining_space = cap - item\n            priorities[i] = 1 / (remaining_space + 0.00001)  # Inverse of remaining space; avoid division by zero\n        else:\n            priorities[i] = -1  # Penalize bins where the item doesn't fit\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99996754901076 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version considers both space utilization (how full the bin would become)\n    and fragmentation (how much space would be wasted if the item is added).\n    Bins with capacity closest to the item size get the highest priority,\n    followed by bins that would be filled close to full if the item were added.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give high priority to bins where the item almost fits perfectly\n    close_fit = np.abs(bins_remain_cap - item)\n    priorities = np.exp(-close_fit)  # Exponential decay around perfect fit\n\n    # Penalize bins where the item doesn't fit (assign zero priority)\n    priorities[bins_remain_cap < item] = 0\n\n    # Also reward bins that become nearly full after adding the item\n    remaining_after_fit = bins_remain_cap - item\n    nearly_full = np.exp(-np.abs(remaining_after_fit) )\n\n    priorities += nearly_full\n    # Prioritize bins with higher utilization after placement\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by gravitational attraction: Larger remaining capacity (mass) attracts more strongly,\n    but the attraction diminishes with distance (difference between item size and remaining capacity).\n    Also incorporates a penalty for bins where the item doesn't fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the difference between bin capacity and item size.  A smaller\n    # positive difference means a tighter fit.  Use 0 for bins where the item does not fit.\n    difference = bins_remain_cap - item\n    difference = np.where(difference >= 0, difference, np.inf) # Inf if item doesn't fit, otherwise the gap\n\n    # Create a baseline priority based on inverse difference (smaller gap is better, avoid overflow)\n    priorities = np.where(difference != np.inf, 1 / (difference + 0.0001), -np.inf)\n\n    # Enhance priority: larger capacity is also attractive (Newtonian Gravitation concept):\n    priorities = priorities * (bins_remain_cap**0.5)\n\n    # Penalize bins where the item does not fit.\n    priorities = np.where(difference == np.inf, -np.inf, priorities)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Prioritizes bins with remaining capacity slightly larger than the item size,\n    but also penalizes bins that are too empty. A sweet spot is targeted.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # High priority for bins where item fits and remaining space is small\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] = (bins_remain_cap[fit_mask] - item) / bins_remain_cap[fit_mask]  # Fraction of waste\n        priorities[fit_mask] = 1 - priorities[fit_mask] # Make the less waste the highest priority\n        # Small penalty for bins where remaining capacity is significantly more than item.\n        # This encourages filling bins without leaving too much space.\n        waste_mask = bins_remain_cap > 2 * item\n        priorities[waste_mask] -= 0.1\n\n    # Penalize bins where item does not fit.\n    no_fit_mask = bins_remain_cap < item\n    priorities[no_fit_mask] = -np.inf #ensure that we never pick them\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a heuristic that considers both the remaining capacity and the item size,\n    favoring bins that can accommodate the item with minimal wasted space, but also\n    penalizing bins that are already close to full (to avoid creating overly fragmented bins).\n    A tesla-inspired touch involves considering \"resonance\" - when the item size aligns\n    well with a certain fraction of the bin capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Very small bins (smaller than item size) should get extremely low priority\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Reward bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n    remaining_space = bins_remain_cap[fit_mask] - item\n    \n    # Prioritize bins with smaller wasted space, but add some noise\n    # This is the core heuristic: smaller remainder is better\n    priorities[fit_mask] = -remaining_space + np.random.normal(0, 0.01, size=remaining_space.shape)  # Add a touch of randomness\n\n    # Add a penalty for bins that are nearly full.\n    fullness_ratio = 1 - (bins_remain_cap / np.max(bins_remain_cap))  # Normalize to range [0,1] representing fullness. bins_remain_cap must be non-negative\n    priorities -= (fullness_ratio**3) * 0.5 # Cubing it allows small values to not contribute much, and prioritizes high fullness penalty\n    \n\n    # \"Resonance\" effect (Tesla inspired):\n    # Favor bins where the item size is a multiple of some \"fundamental frequency\" of the bin\n    # This is a highly speculative addition to improve the quality of the fit, but not necessarily time efficent\n    resonance_strength = 0.1 # Can be tuned based on experiment\n    for i in range(len(bins_remain_cap)):\n      if bins_remain_cap[i] >= item:\n            if item > 0:\n                fundamental_frequency = bins_remain_cap[i] / 2\n                resonance_factor = np.exp(-((item % fundamental_frequency)**2) / (2 * (fundamental_frequency/5)**2) ) # Gaussian curve that peaks at 0\n\n                priorities[i] += resonance_strength * resonance_factor # Adding to priority of current bin\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\n    else:\nOverflowError: cannot convert float infinity to integer\n"
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Favors bins with sufficient capacity, while penalizing near-full bins and bins that cannot accommodate the item.\n    Also includes a 'tidiness' term that slightly favors bins that, after packing the item, would have a remaining capacity\n    close to a power of 2. This encourages more structured packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            priorities[i] = -np.inf  # Cannot fit, lowest priority\n        else:\n            # Base priority based on remaining capacity after packing\n            remaining_after_pack = cap - item\n            priority = remaining_after_pack  # Higher remaining capacity is initially better\n\n            # Penalize near-full bins: avoid leaving very small gaps\n            if remaining_after_pack < 0.1:\n                priority -= 10 # Strong penalty\n\n            # Bonus for leaving a remainder near a power of 2, creating tidiness\n            powers_of_2 = np.array([0.125, 0.25, 0.5, 1.0, 2.0, 4.0, 8.0, 16.0]) # Reasonable power of 2 in cap range\n            closest_power_of_2 = powers_of_2[np.argmin(np.abs(powers_of_2 - remaining_after_pack))]\n            tidiness_bonus = -abs(remaining_after_pack - closest_power_of_2) / 10  # Smaller difference is better\n            priority += tidiness_bonus\n\n\n            priorities[i] = priority\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999992299999576 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: Consider only bins that can accommodate the item\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if not np.any(valid_bins):\n        # If no bin can fit, prioritize the fullest one to minimise waste when a new bin is eventually used.\n        priorities = bins_remain_cap  #Prioritise higher remaining capacity for the item, acting like First Fit Decreasing.\n        return priorities\n    else:\n        # Heuristic 2: First fit considering fill ratio, otherwise 0 priority\n\n        fill_ratios = item / bins_remain_cap\n        fill_ratios[~valid_bins] = -1  # Set to negative if it doesn't fit to exclude\n\n        # Heuristic 3: Prioritize bins with fill ratios close to optimal, but above a threshold.\n        optimal_fill_ratio = 0.9  # Aim for a 90% filled bin\n        priority_boost = np.exp(-np.abs(fill_ratios - optimal_fill_ratio) * 10) # Penalise strongly deviation from the optima\n\n        priorities[valid_bins] = priority_boost[valid_bins] # Only valid bins get a priority\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.557239728759479,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version incorporates several heuristics:\n    1. Reward bins that can *almost* perfectly fit the item (minimize wasted space).\n    2. Penalize bins that would become nearly full (risk of wasted capacity).\n    3. Exclude bins that cannot accommodate the item.\n    4. Add a small randomness for exploration\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Exclude bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Calculate wasted space if item were added to each bin\n    wasted_space = bins_remain_cap - item\n    wasted_space[infeasible_mask] = np.inf #effectively exclude those bins\n\n    # Reward bins with small wasted space (close fit)\n    close_fit_reward = np.exp(-wasted_space) # Exponential decay. Closer fit is exponentially better\n\n    # Penalize bins that become nearly full after adding the item\n    nearly_full_penalty = np.exp( - 1 / (wasted_space + 1e-9))  # Avoid division by zero\n\n    # Combine reward and penalty\n    priorities = close_fit_reward * nearly_full_penalty\n\n    # Add small randomness for exploration (Gaussian noise)\n    noise = np.random.normal(0, 0.01, size=bins_remain_cap.shape) #consider making magnitude of noise item-size dependent.\n    priorities += noise\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 35.40087754287994,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    if not np.any(possible_bins):\n        return priorities # all zeros. This should trigger adding new bin in the higher level function\n\n    # Calculate space utilization if the item were placed in the bin\n    utilization = item / bins_remain_cap\n    utilization[~possible_bins] = -1  # Mark impossible bins\n\n    # Give high priority to bins that would be filled reasonably well, but not overfilled\n    # penalize almost full, empty, or impossible bins\n    priorities = np.where(possible_bins, 1 - np.abs(utilization - 0.7), -100) #0.7 is the target remaining ratio\n\n    # Prefer to fill bins that are already somewhat filled\n    priorities += bins_remain_cap * 0.01\n\n    # Slight penalty for adding item to bins with very large capacity (prevent too much waste), only if item is smaller than the median capacity\n    median_capacity = np.median(bins_remain_cap)\n    if item < median_capacity:\n       priorities -= (bins_remain_cap > median_capacity) * (bins_remain_cap - median_capacity) * 0.005\n\n    #Very large remaining capacities get very small priority\n    priorities -= (bins_remain_cap > item*5)* bins_remain_cap*0.001\n\n    #Ensure that the bins that do not fit the item get a very negative priority, if fit at all is impossible, trigger new bin\n    priorities[~possible_bins] = -1000\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 85.49062624650978,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give a high priority to bins that can accommodate the item snugly\n    # (i.e., the remaining capacity is close to the item size).\n\n    # Also, avoid bins that are too full (remaining capacity close to 0).\n    # Consider available bins and only compute the ratio for those\n    available_bins = bins_remain_cap >= item\n    if np.any(available_bins):\n        capacity_differences = bins_remain_cap[available_bins] - item\n        # Use squared differences to emphasize smaller gaps\n        priorities[available_bins] = np.exp(-10 * (capacity_differences / bins_remain_cap[available_bins])**2)\n        # Penalize almost full bins by adding a small penalty\n        almost_full = (bins_remain_cap[available_bins] < 1.2 * item) & (bins_remain_cap[available_bins] > item)\n        priorities[available_bins][almost_full] *= 0.9\n    else:\n        #if no bins are available return all zeros\n        return priorities\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate remaining capacity after adding the item\n    remaining_after_add = bins_remain_cap - item\n\n    # Give high priority to bins that can fit the item snugly\n    fit_indices = remaining_after_add >= 0\n    if np.any(fit_indices):\n        # Calculate wasted space if item is added\n        wasted_space = remaining_after_add[fit_indices]\n        \n        # Give higher priority to bins where the wasted space is smaller, but not too small.\n        # This encourages filling bins effectively without creating extremely small gaps.\n        priorities[fit_indices] = 1.0 / (wasted_space + 0.01)  # Adding small value to prevent division by zero\n        \n        # Boost priority for \"almost full\" bins a bit more\n        almost_full_indices = (wasted_space <= 0.1) & fit_indices[fit_indices]\n        priorities[fit_indices][almost_full_indices] += 2\n            \n    # Slightly penalize bins that cannot fit the item\n    else:\n        priorities = -1 * np.abs(remaining_after_add)  # Give increasingly negative priority if the fit is really bad\n            \n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Einstein's Intuition:\n    # Maximize space utilization while preventing near-empty bins.\n    # Employ a non-linear combination of factors to balance exploration and exploitation.\n\n    # 1. Feasibility: Disqualify bins that are too small.\n    feasible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[~feasible_bins] = -np.inf  # Assign lowest priority if not feasible\n\n    # 2. Space Utilization Factor:\n    # How much of the bin's capacity will be used.\n    utilization = item / bins_remain_cap[feasible_bins]\n\n    # 3. Remaining Capacity Factor:\n    # We prefer bins where there will still be some capacity left.\n    remaining_capacity_after_fit = bins_remain_cap[feasible_bins] - item\n    normalized_remaining = remaining_capacity_after_fit / np.max(bins_remain_cap)  # Normalize to [0,1]\n\n\n    # 4. Einsteinian Blend: A non-linear combination.\n    # Emphasis on near full, without penalizing more filled bins too much\n    # Balance utilization (avoiding waste) with leaving some room for future items.\n    # The square root adds a damping effect. Small changes when bin near full\n\n    # Avoiding small values for remaining cap which could have caused instability:\n    priorities[feasible_bins] = np.sqrt(utilization) * (1 + normalized_remaining)\n\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 64.31990426804947,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic based on \"best fit\" with a penalty for excessive wasted space.\n    # Also includes a small stochastic element (a touch of God's will, perhaps?)\n\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(valid_bins):\n        return priorities # Return all zeros to signal no valid bins.\n\n    remaining_space = bins_remain_cap - item\n    remaining_space[~valid_bins] = np.inf # Disqualify invalid bins\n\n    # Calculate the difference between bin capacity and item size (smaller is better)\n    space_diff = np.abs(bins_remain_cap - item)\n\n    # Prioritize bins that can accommodate the item well, without too much waste.\n    # A combination of negative remaining space (higher values are better as less is wasted) and some tiny random number.\n    priorities[valid_bins] = -space_diff[valid_bins] + 0.0001 * np.random.rand(np.sum(valid_bins))\n\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item without excessive wasted space.\n    It combines several heuristics:\n    1.  Bins that can't fit the item get a very low priority.\n    2.  Bins with a remaining capacity close to the item's size get higher priority (first-fit-decreasing style).\n    3.  Bins with small remaining capacity gets a small penalty to avoid small fragmentation\n    4.  Empty bins get a penalty\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Bins that can't fit the item get a very low priority\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Bins that can fit get a base priority inversely proportional to the wasted space.  Also, adding 1 avoids division by zero.\n\n    feasible_mask = bins_remain_cap >= item\n    wasted_space = bins_remain_cap[feasible_mask] - item\n    priorities[feasible_mask] = 1.0 / (wasted_space + 0.01) # Smaller wasted space is better\n\n    # Add a bonus to bins with remaining capacity that is closest to item size to prioritize first fit\n    diff_abs = np.abs(bins_remain_cap - item)\n    priorities = priorities + 1.0/(diff_abs+0.1)\n\n    # Penalize bins with very small remaining capacity to reduce small waste creation\n    small_cap_mask = bins_remain_cap < 0.15 #tunable hyperparameter\n    priorities[small_cap_mask] = priorities[small_cap_mask] * 0.5\n\n\n    #Empty bin penality, tunable hyperparameter\n\n    empty_bin_mask = bins_remain_cap == 1.0 # Assuming bin cap of 1.0\n\n    priorities[empty_bin_mask] = priorities[empty_bin_mask] * 0.75 #Tunable\n\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a base value (e.g., 0)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give higher priority to bins that can accommodate the item\n    # with minimal remaining capacity. This aims to fill bins efficiently.\n    available_bins = bins_remain_cap >= item\n    if np.any(available_bins):\n        remaining_after_fit = bins_remain_cap[available_bins] - item\n        priorities[available_bins] = 1.0 / (remaining_after_fit + 0.0001)  # Add small value to avoid division by zero\n        # Additionally, penalize bins that are too large to avoid wasting space drastically.\n        large_bins = remaining_after_fit > (2 * item) # Threshold dynamically adapts. Maybe this value could depend on bins_remain_cap.mean()?\n        priorities[available_bins][large_bins] *= 0.1 # Further reduce priorities if it's a very large bin\n    else:\n      #If the item is larger than all available bins, add it to the one with the greatest capacity so we at least reduce the item count.\n      priorities = bins_remain_cap/np.sum(bins_remain_cap)\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    A good bin should have enough capacity to fit the item but not too much,\n    avoiding excessive waste. Also, favor bins that are already somewhat full.\n    \n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Give a very low priority to bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n    \n    # For feasible bins, calculate the fill ratio after adding the item\n    feasible_mask = ~infeasible_mask\n    remaining_capacity_after_packing = bins_remain_cap[feasible_mask] - item\n    \n    #Calculate waste after packing.\n    waste_ratio = remaining_capacity_after_packing / 1.0 #Assumes bin capacity = 1\n    \n    \n    #Priority function.\n    #Penalize high waste\n    priorities[feasible_mask] = -waste_ratio \n\n    # Also prioritize bins that are already partially full (Avoid creating new bins)\n    # original_fill_ratio = (1.0 - bins_remain_cap[feasible_mask]) #bin capacity = 1 assumed\n    priorities[feasible_mask] += (1.0 - bins_remain_cap[feasible_mask]) #prioritizes usage of partially filled bins\n   \n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Initialize priority scores. Avoid operating directly on bins_remain_cap\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Extremely small value to avoid division by zero and log(0)\n    epsilon = 1e-9\n\n    # Find bins that can accommodate the item. This is key to avoid overflowing.\n    feasible_bins = bins_remain_cap >= item\n\n    # If no feasible bins are available, return a low priority for all bins, essentially signaling failure.\n    if not np.any(feasible_bins):\n        return np.full_like(bins_remain_cap, -np.inf) #Return -infinity to signal impossible placement. Prevents errors.\n\n    #Calculate remaining capacity AFTER placing item\n    post_placement_capacities = bins_remain_cap - item\n\n    #Heuristic 1: Maximize filled space, but prioritize near full bins that CAN accommodate item\n    fill_ratios = item / (bins_remain_cap + epsilon) #How \"full\" is this item?\n\n    #Heuristic 2: Emphasize completely filling a bin (minimize waste).\n    #This calculates the amount of space that would be wasted if the item is placed in each bin.\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf #Inf waste if the item doesn't fit.\n    waste_penalty = -waste  #Penalize high waste values.\n    # Apply a discount factor. This determines how important it is to fully fill the bin relative to other factors.\n    # A smaller discount makes bin filling less important.\n    waste_discount = 0.5\n\n    #Heuristic 3: Moderate the influence of fill_ratios and encourage better balanced bins in the long run.\n    cap_ratios = post_placement_capacities / (bins_remain_cap.max()+ epsilon) #post placement capacity to overall size of largest bin\n\n    # Combined priority scores, weighting each factor.\n    priorities[feasible_bins] = fill_ratios[feasible_bins] + waste_discount * waste_penalty[feasible_bins] + 0.2 * cap_ratios[feasible_bins]\n    #If a bin is feasible it gets the fill ratio, waste penality, and bin balancing terms added together.\n\n    #For any infeasible bins, assign them the lowest possible priority to minimize changes they are used.\n    priorities[~feasible_bins] = -np.inf\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by Feynman's path integral formulation, we consider all possible \"paths\" (bins) and weight them based on a \"quantum action.\"\n    The \"action\" here is related to how well the item fits into the bin's remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Give zero priority to bins that cannot fit the item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities  # No feasible bins, return all zeros\n\n    # Action: How much space is wasted if we place the item in this bin\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf # Penalize infeasible bins very heavily (infinity)\n\n    # \"Quantum amplitude\": e^(-action)  (More negative waste means better fit)\n    amplitudes = np.exp(-waste)\n\n    # Normalize amplitudes (to get a probability-like distribution, Feynman-style)\n    amplitudes[~feasible_bins] = 0 #ensure that we only consider feasible bins\n    if np.sum(amplitudes) > 0:\n      amplitudes = amplitudes / np.sum(amplitudes)\n    else:\n      amplitudes = np.ones_like(amplitudes) / len(amplitudes) #if they are all zero, then just divide them evenly\n\n    priorities = amplitudes # Assign probability/priority according to quantum amplitudes\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a small value\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Assign high priority to bins where the item fits\n    fit_indices = np.where(bins_remain_cap >= item)[0]\n    if len(fit_indices) > 0:\n        # Prioritize bins that are filled most efficiently (minimize wasted space). Avoid very small remaining space to improve the chances of packing a large item later.\n        wasted_space = bins_remain_cap[fit_indices] - item\n        # Prioritize those with small wasted space and a buffer\n        buffer = np.where(wasted_space > 0.1 * item, wasted_space, np.inf)\n        best_fit_indices = fit_indices[np.argmin(buffer)] #prefer larger wasted space that exceeds buffer\n\n        priorities[best_fit_indices] = 1.0 + (bins_remain_cap[best_fit_indices] - item)/np.max(bins_remain_cap)  # Normalize based on maximum bin capacity\n    else:\n        # If the item doesn't fit in any bin, assign low priority. No bin will be selected.\n        priorities = np.zeros_like(bins_remain_cap)\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 7.658556043079373,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    A more sophisticated priority function considering multiple factors:\n    1.  Wasted Space: Penalizes bins with remaining capacity close to the item size, promoting better fill.\n    2.  Remaining Capacity: Prioritizes bins with enough, but not excessively large, remaining capacity. Avoids creating very empty bins early on.\n    3.  Fit Score: Rewards bins where the item fits snugly (small waste), but not bins already close to full.\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity < item:\n            priorities[i] = -np.inf  # Cannot fit\n\n        else:\n            #Wasted Space penalty. lower values are better, exponentially scaled\n            waste = capacity - item\n            waste_penalty = np.exp(-waste)  # Higher penalty for larger waste, decreasing rapidly\n\n            #remaining capacity reward, peaking at item size, but decreases slower when smaller/ larger than the item\n            capacity_reward = np.exp(-np.abs(capacity-item)/item)\n\n            #fit_score. Higher for bins where placing the item leads to nearing 100% fill but not above\n            fit_score = 1 - (waste / (item + 0.0001)) # small constant for items close to zero. This also increases score with tighter fits\n            if capacity <= 2*item:\n                fit_score = fit_score*2 #extra boost to tight fit\n            elif capacity >= 3*item: #less desireable fit\n                 fit_score = fit_score * 0.5\n\n            #combine these rewards and penalties\n            priorities[i] = waste_penalty + capacity_reward + fit_score\n\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99999191099778 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # First, filter out bins that cannot accommodate the item\n    valid_bins = bins_remain_cap >= item\n    \n    if np.any(valid_bins):\n        # Calculate remaining capacity after placing the item (only for valid bins)\n        remaining_capacity = bins_remain_cap[valid_bins] - item\n        \n        # Prioritize bins where the remaining capacity is small, but not zero (almost full)\n        priorities[valid_bins] = 1 / (remaining_capacity + 1e-9) # Avoid division by zero\n\n        # Slightly boost priority for bins where item fills more than half of the bin's capacity\n        fill_ratio = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += (fill_ratio > 0.5) * 0.5\n\n        # Penalize bins with remaining capacity close to the item size \n        # to encourage packing more than one item into a bin (prevent fragmentation)\n        close_to_item_size = np.abs(remaining_capacity - item)\n        priorities[valid_bins] -= np.exp(-close_to_item_size) * 0.2\n    else:\n        #If no bin can fit the item, assign lowest priority to all bins.\n        priorities[:] = -np.inf\n        \n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.108496210610296,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by general relativity: maximizing 'gravitational potential' (utilization) while minimizing 'space-time distortion' (fragmentation).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # \"Gravitational Potential\" - How much the item 'fills' the bin relative to its remaining capacity. Maximize this.\n            utilization = item / cap\n\n            # \"Space-time Distortion\" - How much is the remaining space after the item is added. Minimize this. This introduces a \"penalty\" if the remaining space is too small. A small remainder results in high 'distortion', while large remainders don't add much penalty.\n            remainder = cap - item\n            distortion = np.exp(-remainder / item) if remainder > 0 else float('inf')  #exponential decay penalty; small remainder -> large distortion, large remainder -> little distortion. 'inf' penalty for remainder <= 0, we do not want to assign bins without capacity.\n\n            # Combine \"Gravitational Potential\" and inverse of \"Space-time Distortion\"\n            #Prioritizes bins that efficiently accommodate the item while minimizing wasted space. Adding a little epsilon for the edge case of zero distortion to keep values reasonable\n            epsilon = 1e-9\n            priorities[i] = utilization / (distortion + epsilon)\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99998781099566 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a small negative value to avoid selecting infeasible bins.\n    priorities = -np.inf * np.ones_like(bins_remain_cap)\n\n    # Find feasible bins (bins with enough remaining capacity).\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        return priorities  # No feasible bins, all remain -inf\n\n    # Calculate the wasted space after placing the item in each feasible bin.\n    wasted_space = bins_remain_cap[feasible_bins] - item\n\n    # Prioritize bins with less wasted space (First-Fit Decreasing-like behavior).\n    # But also add a slight preference for bins that are already somewhat full (to encourage packing).\n    fullness_factor = bins_remain_cap[feasible_bins] / np.sum(bins_remain_cap)\n\n    priorities[feasible_bins] = -wasted_space + 0.1 * fullness_factor # Trade-off between wasted space and already-filled bins\n\n    # Add a bonus for bins that would become exactly full after adding the item\n    exact_fit = wasted_space == 0\n    priorities[feasible_bins][exact_fit] += 1.0 # large number to prefer perfect fit\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Give very high priority to bins that can fit the item almost perfectly\n    fit_threshold = 0.95\n    perfect_fit_mask = (bins_remain_cap >= item) & (item / bins_remain_cap >= fit_threshold)\n    priorities[perfect_fit_mask] += 100  # Large bonus for near-perfect fit\n\n    # Reward bins that can fit the item (First-Fit Decreasing heuristic influence)\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] += bins_remain_cap[can_fit_mask] - item # Favor bins with smaller waste\n\n    # Penalize bins that cannot fit the item to 0, this will effectively remove them from consideration\n    cannot_fit_mask = bins_remain_cap < item\n    priorities[cannot_fit_mask] = -np.inf  # Large penalty for overflow\n\n    # Bonus for bins with higher remaining capacity (encourages using more full bins first, less fragmentation)\n    priorities += bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0 # Normalise the remaining capacity\n    \n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 81.3721579577184,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    My design utilizes a multi-faceted approach, blending the concepts\n    of space utilization, proximity to perfect fit, and a touch of\n    stochasticity to simulate the unpredictable nature of electrical arcs.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Tesla's Coil: Maximize Space Utilization (avoid small bins if possible)\n    space_utilization = bins_remain_cap - item\n    space_utilization[space_utilization < 0] = -np.inf # Disqualify bins that can't fit\n\n    # Wardenclyffe Tower: Aim for a Perfect Fit (minimize wasted space)\n    proximity_to_fit = np.abs(space_utilization)\n    proximity_to_fit = -proximity_to_fit # Invert to prioritize smaller waste\n\n    # Tesla's Oscillator: Introduce controlled randomness (avoid local optima)\n    random_fluctuations = np.random.rand(len(bins_remain_cap)) * 0.01  # Small random values\n\n    # High-Frequency Current: Favor bins that are already somewhat full\n    fullness_factor = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    fullness_factor[bins_remain_cap < item] = 0  # Remove if bin is too small\n\n    priorities = space_utilization + proximity_to_fit + random_fluctuations + 0.5 * fullness_factor\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    My new function is inspired by the dance of planets - where there is harmony in placing new object.\n    I've incorporated the golden ratio & penalize almost-full bins, preventing over-concentration!\n    In this version, the 'fullness' of a bin (i.e., how much space would be left if the item were placed)\n    plays a significant role. Bins that would be left with a very small amount of space are penalized,\n    simulating a 'resistance' to being filled almost completely. Bins with enough remaining space are given more\n    priority to promote balanced utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    phi = 1.618  # Golden ratio, for optimal balancing\n    epsilon = 1e-6  # To prevent division by zero & log of zero issues\n\n    remaining_after_placement = bins_remain_cap - item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Penalize bins where placement results in very little space remaining\n    # High penalty where remaining is small (less than item size)\n    penalty = np.where(remaining_after_placement > 0,\n                       np.exp(-phi * remaining_after_placement / (item + epsilon)), # Exp Decay for remaining >0\n                       -np.inf) # Bin is either full, overfilled, or small capacity\n    # Reward Bins where Items can be packed i.e cap is sufficient:\n    sufficient_cap = np.where(bins_remain_cap > item,\n                       np.power(bins_remain_cap, 0.333), 0)\n\n    priorities = sufficient_cap + penalty\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 148.70362983645794,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Rule 1: Prefer bins where the item fits (avoid fragmentation)\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] += 1  # Give these bins a base priority\n\n    # Rule 2: Among bins where it fits, prioritize those with tighter fit (minimize wasted space)\n    slack = bins_remain_cap - item\n    slack[~fit_mask] = np.inf #ignore the bins that doesn't fit the item.\n\n    # Avoid division by zero in case item == remaining cap\n    slack = np.where(slack == 0, 1e-9, slack)\n\n    tightness = 1 / slack\n    priorities[fit_mask] += tightness[fit_mask]\n\n\n    # Rule 3: Give a small bonus to nearly full bins. Black Hole-esque Density bonus\n    density = (1 - (bins_remain_cap / np.max(bins_remain_cap))) #relative density compared to maximum remaining cap\n    priorities += 0.1 * density\n\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 28, in priority_v2\n    ideal_utilization = 0.75 # aiming for around 75% fill rate\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n"
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Employs a quantum-inspired approach.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros(n_bins)\n\n    for i in range(n_bins):\n        remaining_capacity = bins_remain_cap[i]\n        if remaining_capacity >= item:\n            # 'Quantum' probability of fitting (sigmoid function)\n            probability = 1 / (1 + np.exp(-10 * (remaining_capacity - item)))  # steep sigmoid around item size\n\n            # Preference for bins that are not too empty (avoid fragmentation)\n            # Higher fill rate gets higher score, but not if the item doesn't fit!\n            fill_rate_penalty = np.exp(-5 * (item/remaining_capacity-1))\n\n            # Encourages a certain \"energy level\" or bin utilization (parabola)\n            ideal_utilization = 0.75 # aiming for around 75% fill rate\n            utilization = 1 - remaining_capacity  # Assuming bin size is 1, higher value when capacity lower\n            energy_term = -10*(utilization - ideal_utilization)**2\n            \n            priorities[i] = probability * fill_rate_penalty + energy_term\n        else:\n            priorities[i] = -np.inf  # Item does not fit; assign a very low priority.\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999993229997926 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version prioritizes bins that can fit the item reasonably well\n    (avoiding near-empty bins if better options exist). It considers both\n    the remaining capacity and how much of the bin would be filled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Assign a base priority based on whether the item fits\n    can_fit = bins_remain_cap >= item\n    priorities[can_fit] = 1.0\n\n    # Adjust priorities for bins that can fit, favoring better fits:\n    fitting_bins_indices = np.where(can_fit)[0]\n    for i in fitting_bins_indices:\n        # Calculate the fill ratio after adding the item\n        fill_ratio = item / bins_remain_cap[i]\n\n        #Give a bonus for good fills. Aim for something close to filling the bin without overfilling\n\n        priorities[i] += (1-np.abs(fill_ratio - 0.7)).clip(0,1)\n        priorities[i] += (1-bins_remain_cap[i]).clip(0,1) #Bins with low capacity remaining are better, this prevents adding to almost empty bins\n\n    #Bins that can't fit get very low priorities\n    priorities[~can_fit] = -1000\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997600000643 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Heuristic 1: Prefer bins where the item fits (First Fit Decreasing inspired)\n    fits = bins_remain_cap >= item\n    priorities[fits] += 1.0\n\n    # Heuristic 2: Favor bins that would be filled relatively more completely.\n    #  A higher completion ratio is desired, but avoid filling up the bin entirely.\n    completion_ratio = item / bins_remain_cap\n    valid_completion = (completion_ratio > 0) & (completion_ratio <= 1.0)  # Check that the item can be accomodated and does not overfill\n    priorities[valid_completion] += completion_ratio[valid_completion] * 2 # Scaling factor to give emphasis\n    #Heuristic 3: Penalize bins which can barely fit, encourage full-ish usage\n    nearly_full = (bins_remain_cap - item) < (0.1 * item)  # Less than 10% of item size is remaining. Arbitrary choice for demonstration.\n    priorities[nearly_full] -= 0.5\n\n    #Heuristic 4: If bin is empty, it may be suitable but only if item is significantly large\n    empty_bins = bins_remain_cap == bins_remain_cap.max()\n    large_item = item > 0.5 * bins_remain_cap.max()  # Significant large item\n    if large_item:\n        priorities[empty_bins] += 0.75 # Add moderate priority to new bin if there is large item\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 17, in priority_v2\n    priorities[fits] += 1.0\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n"
  }
]