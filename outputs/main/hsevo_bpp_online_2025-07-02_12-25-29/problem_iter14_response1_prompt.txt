{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins, combining close fit, target fill, and fragmentation avoidance.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    item_fits = bins_remain_cap >= item\n    remaining_after_fit = bins_remain_cap - item\n\n    # Close fit bonus\n    close_fit = np.abs(bins_remain_cap - item)\n    close_fit_priority = np.exp(-close_fit_decay * close_fit)\n    priorities += close_fit_priority * item_fits\n\n    # Target fill bonus\n    fill_level = (bin_capacity - remaining_after_fit) / bin_capacity\n    threshold_bonus = np.where(item_fits & (fill_level >= filling_threshold), 1.0, 0.0)\n    priorities += threshold_bonus\n    \n    # Avoid tiny fragments\n    reasonable_fit = item_fits & (remaining_after_fit > fragment_threshold)\n    priorities += reasonable_fit_weight * reasonable_fit\n\n    priorities[bins_remain_cap < item] = penalty\n\n    # Desperation\n    if not np.any(item_fits):\n        priorities[:] = penalty\n        if len(priorities) > 0:\n            priorities[np.argmin(bins_remain_cap)] = 0\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on remaining capacity and filling target.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    item_fits = bins_remain_cap >= item\n\n    if not np.any(item_fits):\n        return priorities\n\n    feasible_bins = bins_remain_cap[item_fits]\n    feasible_indices = np.where(item_fits)[0]\n    remaining_after_fit = feasible_bins - item\n\n    # Close fit bonus\n    priorities[feasible_indices] += np.exp(-2 * np.abs(remaining_after_fit))\n\n    # Filling target bonus (0.75 of bin capacity)\n    filling_threshold = 0.75\n    fill_level = 1 - remaining_after_fit\n    threshold_bonus = np.where(fill_level >= filling_threshold, 0.5, 0.0)\n    priorities[feasible_indices] += threshold_bonus\n\n    # Fragmentation penalty\n    frag_penalty = np.where(remaining_after_fit < 0.1, -0.2, 0.0)\n    priorities[feasible_indices] += frag_penalty\n    priorities = np.maximum(priorities, 0) # Ensure non-negative\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses a combination of \"nearly full,\" \"reasonable fit,\" and \"size difference,\" along with handling the case where no item fits by assigning a large negative priority except to the bin with the smallest capacity. The worst focuses on similar concepts but is less refined. (2nd) is identical to (1st) which is a perfect clone so no differences. Comparing (1st) vs (3rd), (1st) uses a \"nearly full\" bonus with an exponential decay based on the absolute difference between remaining capacity and zero, while (3rd) uses a target fill bonus and avoids tiny fragments, adding a desperation strategy when no item fits. Comparing (3rd) vs (4th), the main difference is that (4th) is heavily parameterized, allowing for fine-tuning but potentially overfitting, while (3rd) uses hardcoded values. (15th) focuses on waste calculation, near-full bonus, and fragmentation penalty, ensuring non-negative priorities, whilst many other heuristics are similar but the weighting and combination of factors vary significantly. Comparing (16th) vs (17th), we observe similar priorities for close fit, filling target, and fragmentation, but (17th) explicitly handles the case where no items fit using an early exit strategy. Comparing (second worst) vs (worst), the difference lies in the explicit `ValueError` check for negative bin capacities and the more refined bonus/penalty calculations in the second worst. Overall: better heuristics seem to involve a combination of close-fit rewards, target fill bonuses, fragmentation penalties, and careful consideration of edge cases where no items fit or negative bin capacities exist. The weighting of these factors and the use of exponential decay functions appear to influence performance significantly.\n- \nOkay, let's redefine \"Current self-reflection\" to design better bin packing heuristics, focusing on avoiding the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a revised approach to self-reflection, designed for actionable improvements:\n\n*   **Keywords:** Objective alignment, Component Interaction, Early Exit, Parameter control.\n*   **Advice:** Focus on the *interaction* of combined factors (close-fit, fill). Iteratively refine these interactions and early exits based on *empirical performance*.\n*   **Avoid:** Vague considerations (e.g., \"handle fragmentation\" without a specific implementation). Over-parameterization without demonstrable benefit.\n*   **Explanation:** Prioritize strategies grounded in data & experimentation. Don't get lost in general considerations; test specific ideas and measure the effect on performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}