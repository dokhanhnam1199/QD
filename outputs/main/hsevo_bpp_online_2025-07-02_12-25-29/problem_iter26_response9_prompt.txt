{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that minimize wasted space after packing the item.\n    It uses a cost function based on remaining capacity to guide the packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins where the item fits\n    item_fits = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after adding the item\n    remaining_after_fit = bins_remain_cap - item\n    \n    # Cost function based on remaining capacity: penalize wasted space\n    # The closer to zero, the better the fit.  Use exponential decay to\n    # heavily penalize large remaining capacities.  Only consider bins\n    # where the item fits.\n    waste_penalty = np.exp(-5 * remaining_after_fit) * item_fits\n    \n    # Invert the penalty to get a priority (lower waste = higher priority)\n    priorities = waste_penalty\n\n    # Small bonus for bins where we can fit the item at all, \n    # to prioritize using bins over leaving items unpacked.\n    priorities += 0.1 * item_fits\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on close fit, target fill, and handles edge cases.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = 1.0\n    item_fits = bins_remain_cap >= item\n    \n    # Perfect fit early exit\n    perfect_fit = np.isclose(bins_remain_cap, item)\n    if np.any(perfect_fit):\n        priorities[perfect_fit] = 10.0\n        return priorities\n\n    # No fit: put in smallest bin\n    if not np.any(item_fits):\n        priorities[:] = -1e9 #make all bins have very low priority\n        if len(priorities) > 0:\n            priorities[np.argmin(bins_remain_cap)] = 0\n        return priorities\n\n    # Close fit bonus\n    close_fit = np.abs(bins_remain_cap - item)\n    close_fit_priority = np.exp(-5 * close_fit)\n    priorities += close_fit_priority * item_fits\n\n    # Target fill bonus\n    remaining_after_fit = bins_remain_cap - item\n    target_fill = 0.8\n    fill_level_after_fit = (bin_capacity - remaining_after_fit) / bin_capacity\n    fill_level_priority = np.exp(-5 * np.abs(fill_level_after_fit - target_fill)) * item_fits\n    priorities += fill_level_priority\n\n    # Fragmentation penalty (avoid small remaining space)\n    fragmentation_threshold = 0.15\n    fragmentation_penalty = np.where(item_fits & (remaining_after_fit/bin_capacity < fragmentation_threshold), -0.3, 0.0)\n    priorities += fragmentation_penalty\n    \n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st prioritizes minimizing wasted space by exponentially penalizing remaining capacity, while the 20th uses a target fill and fragmentation penalty. The 1st also adds a small bonus for any bin where the item fits. The 20th handles the no-fit case by putting the item in the smallest bin, while the 1st does not explicitly handle this. Comparing (2nd best) vs (second worst), we see that the 2nd incorporates a target fill level, while the second worst also handles no-fit scenarios. Comparing (1st) vs (2nd), we see that the 1st uses wasted space to calculate priorities, while the 2nd version focuses on target fill. (3rd) vs (4th), the 3rd allows parameters while the 4th has fixed hyper parameters. Comparing (second worst) vs (worst), we see the second worst has extra logic to handle a perfect fit and target fill conditions. Overall: The best heuristics generally focus on minimizing wasted space, considering target fill levels, and explicitly handling edge cases like perfect fits and situations where no bin can accommodate the item. Normalization helps. Penalizing fragmentation and considering bin selection pressure also contribute to better performance.\n- \nOkay, here's a refined perspective on self-reflection for designing heuristics, focusing on effectiveness and clarity:\n\n*   **Keywords:** Objective-driven, interpretable, incremental refinement, validated assumptions, parameter impact.\n\n*   **Advice:** Focus on direct optimization objective alignment; validate assumptions thoroughly; prioritize simplicity; evaluate the marginal benefit of added complexity.\n\n*   **Avoid:** Unnecessary complexity; over-parameterization without clear benefit; opaque combinations of factors; neglecting validation.\n\n*   **Explanation:** Heuristics should be built methodically, with each component demonstrably improving performance relative to the core objective, avoid \"black box\" design and prefer solutions you can explain.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}