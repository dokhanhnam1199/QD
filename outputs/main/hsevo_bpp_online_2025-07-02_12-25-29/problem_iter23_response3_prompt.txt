{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on close fit, target fill, avoids fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    item_fits = bins_remain_cap >= item\n    remaining_after_fit = bins_remain_cap - item\n\n    if not np.any(item_fits):\n        priorities[:] = -1e9\n        if len(priorities) > 0:\n            priorities[np.argmin(bins_remain_cap)] = 0\n        return priorities\n\n    # Perfect fit early exit\n    perfect_fit = np.isclose(bins_remain_cap, item)\n    if np.any(perfect_fit):\n        priorities[perfect_fit] = 1e9  # Max priority for perfect fit\n        return priorities\n\n    # Close fit bonus (higher priority for less waste)\n    close_fit_priority = np.exp(-2 * (bins_remain_cap - item)) * item_fits\n\n    # Target fill bonus (reward bins close to full after packing)\n    fill_threshold = 0.9\n    nearly_full_bonus = np.where(item_fits & (1 - remaining_after_fit/bin_capacity >= fill_threshold), 0.5, 0)\n\n    # Fragmentation penalty (avoid small remaining space)\n    fragmentation_threshold = 0.1\n    fragmentation_penalty = np.where(item_fits & (remaining_after_fit/bin_capacity <= fragmentation_threshold), -0.25, 0)\n\n    # Combine all factors, normalizing the close fit.\n    priorities = close_fit_priority + nearly_full_bonus + fragmentation_penalty\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins based on a combination of remaining capacity after placement,\n    the filling threshold, and normalization to balance these factors. It uses a more direct\n    and understandable approach than v1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = 1.0  # Assuming bin capacity is 1.0, modify as needed\n    \n    # Identify bins where the item fits\n    item_fits = bins_remain_cap >= item\n    \n    if not np.any(item_fits):\n        return priorities # no bin can contain the item\n\n    # Remaining capacity after adding the item.  Use clipping to avoid negative values\n    remaining_after_fit = np.clip(bins_remain_cap - item, 0, bin_capacity)  # Ensure no negative values\n\n    # Fill level after adding the item\n    fill_level = (bin_capacity - remaining_after_fit) / bin_capacity\n\n    # Prioritize bins based on closeness of fit (lower remaining capacity is better)\n    # Use inverse of remaining capacity + a small constant for stability.  Normalize.\n    fit_priority = 1.0 / (remaining_after_fit + 0.01)  # Avoid division by zero\n    fit_priority[~item_fits] = 0  # Only consider bins where the item fits\n    fit_priority /= np.sum(fit_priority) + 1e-9 # Normalize to avoid single bin dominance\n\n    # Prioritize bins that reach a filling threshold (e.g., 80%)\n    filling_threshold = 0.8\n    threshold_priority = np.where(fill_level >= filling_threshold, 1.0, 0.0)\n    threshold_priority[~item_fits] = 0\n    threshold_priority /= np.sum(threshold_priority) + 1e-9 # Normalize\n\n    # Combine fit and threshold priorities. Give slightly more weight to fit.\n    priorities = 0.6 * fit_priority + 0.4 * threshold_priority\n\n    # Small bonus to use bins that can at least fit an item, avoiding empty bins\n    larger_bins_bonus = 0.05 * item_fits / (np.sum(item_fits)+ 1e-9)\n    priorities += larger_bins_bonus\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st heuristic uses a simpler, more direct approach with clear priorities, while the 20th introduces many hyperparameters and external libraries (scipy, torch) without a clear justification, making it less understandable and potentially over-engineered. (2nd) vs (19th): Similar to above, the 2nd heuristic is simpler and more readable than the 19th.\n\nComparing (1st) vs (2nd), we see the 1st heuristic focuses on fragmentation by filling above a threshold and close fit, while 2nd adds a desperation strategy of placing items in the smallest bin if it doesn't fit, and a penalty for large remaining space. (3rd) vs (4th) - no difference. Comparing (second worst) vs (worst), we see they are identical, indicating a lack of unique strategies in the worst-performing heuristics.\n\nComparing (7th) vs (8th), (9th) vs (10th): Normalization is present in some top heuristics but absent in the later heuristics. The top heuristics make use of normalization to ensure combined factors contribute evenly.\n\nOverall: The best heuristics prioritize simplicity, clarity, and normalization of factors considered. They address fragmentation and target fill levels effectively. The worst heuristics suffer from over-parameterization, unnecessary complexity, and lack of a clear strategy. Early exits for the perfect fit are beneficial. Normalization helps in balancing the effects of different parameters. Edge case handling (no bin fits) is important.\n- \nOkay, let's redefine \"Current self-reflection\" for designing better heuristics, focusing on actionable insights and avoiding common pitfalls.\n\n**Keywords:** Clarity, Directness, Iterative Refinement, Objective-Driven.\n\n**Advice:** Design heuristics with easily understandable rules directly linked to improving the objective function (e.g., minimizing wasted space). Start with a simple baseline heuristic and iteratively add complexity based on performance evaluation.\n\n**Avoid:** Over-parameterization, multiplicative combinations of factors without strong justification, premature optimization, and complex calculations that obscure the heuristic's core logic.\n\n**Explanation:** Focus on interpretable rules that directly contribute to the objective. Build incrementally, measuring the impact of each addition. Prioritize understanding over complex parameter tuning. Handle edge cases and invalid scenarios explicitly but simply.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}