[
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits with large gaps. It normalizes priorities\n    by item size and simplifies the boosting logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    remain_cap_normalized = bins_remain_cap / max_cap if max_cap > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits with consideration of large gaps\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after, 0) / item if item > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (remain_cap_normalized + fit_boost) * order_penalties + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 5.604307937774236,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response1.txt_stdout.txt",
    "code_path": "problem_iter10_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 1.3163143199042726,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response2.txt_stdout.txt",
    "code_path": "problem_iter10_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses normalized total capacity, applies weighted fit and gap penalties,\n    and includes ordered unused bin penalties to determine the priority scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity based on total capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / (max_cap if max_cap > 0 else 1))\n\n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_ratio = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_ratio = np.nan_to_num(fit_ratio, posinf=0, neginf=0)\n    \n    # Penalize gaps for good fits\n    gap_ratio = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    gap_ratio = np.nan_to_num(gap_ratio, posinf=0, neginf=0)\n\n    # Weighted strategy: prioritize bins with better fits and less gaps\n    gap_weight = 0.3\n    fit_weight = 0.7\n    weighted_score = fit_ratio * fit_weight - gap_ratio * gap_weight\n\n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized + weighted_score) * unused_bin_penalty + non_fit_penalty\n    \n    # Ensure scores remain non-negative\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response3.txt_stdout.txt",
    "code_path": "problem_iter10_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that normalizes remaining capacities,\n    penalizes unused bins, boosts bins where the item fits well, and considers gaps for good fits.\n    It also normalizes by item size and ensures no negative scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins by considering their remaining capacity\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / item, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Ensure scores remain non-negative\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 85.00199441563623,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response4.txt_stdout.txt",
    "code_path": "problem_iter10_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits well, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Simplified gap factor\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: balance fits and gaps\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Final priority score with item size normalization\n    priority_scores = weighted_score / (item if item > 0 else 1)\n    \n    # Apply penalties for bins that cannot fit the item\n    priority_scores += non_fit_penalty\n    \n    # Enforce non-negative priority scores\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 85.25129637016356,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response5.txt_stdout.txt",
    "code_path": "problem_iter10_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well, considering large gaps and penalizing\n    non-fits. It normalizes priorities by item size and reduces complexity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / item, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (remain_cap_normalized + fit_boost) * order_penalties + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 5.604307937774236,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response6.txt_stdout.txt",
    "code_path": "problem_iter10_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits well, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        unused_bin_penalty = np.ones_like(bins_remain_cap)\n    else:\n        unused_bin_penalty = np.exp(-bins_remain_cap / max_cap)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 1.7550857598723597,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response7.txt_stdout.txt",
    "code_path": "problem_iter10_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits well, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / (max_cap if max_cap > 0 else 1))\n\n    # Assign zero priority to bins where the item cannot fit\n    can_fit = bins_remain_cap >= item\n    non_fit_penalty = np.where(~can_fit, -np.inf, 0)\n\n    # Boost bins where the item fits well\n    fit_boost = np.where(can_fit, bins_remain_cap - item, 0)\n\n    # Consider gaps for good fits\n    gap_factor = np.where(can_fit, 1 / (1 + (bins_remain_cap - item)), 0)\n\n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_fit_score = fit_boost * fit_weight + gap_factor * gap_weight\n\n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized + weighted_fit_score) * unused_bin_penalty + non_fit_penalty\n\n    return priority_scores",
    "response_id": 7,
    "obj": 149.30195452732352,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response8.txt_stdout.txt",
    "code_path": "problem_iter10_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This improved implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits well, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / (max_cap if max_cap > 0 else 1))\n\n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, 1 - available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Penalize gaps for good fits\n    gap_penalty = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    gap_penalty = np.nan_to_num(gap_penalty, posinf=0, neginf=0)\n\n    # Weighted strategy: prioritize bins with less gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = fit_boost * fit_weight - gap_penalty * gap_weight\n\n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized + weighted_score) * unused_bin_penalty + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 4.028719585161557,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response9.txt_stdout.txt",
    "code_path": "problem_iter10_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes gaps,\n    boosts bins where the item fits well, ensures positive priorities,\n    and uses a weighted strategy to balance fits and gaps.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize gaps\n    fit_boost = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    gap_penalty = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    gap_penalty = np.nan_to_num(gap_penalty, posinf=0, neginf=0)\n\n    # Weighted strategy: prioritize bins with less gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = fit_boost * fit_weight - gap_penalty * gap_weight\n\n    # Combine scores\n    priority_scores = remain_cap_normalized + weighted_score + non_fit_penalty\n    \n    # Ensure positive priorities\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.028719585161557,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores and simplifying logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins\n    unused_bin_penalty = np.where(bins_remain_cap == np.max(bins_remain_cap), 1, 0.5)\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = -np.inf * (bins_remain_cap < item)\n    \n    # Calculate the gap after placing the item\n    gap = bins_remain_cap - item\n    \n    # Boost bins where the item fits perfectly or almost perfectly\n    fit_boost = np.where(gap >= 0, 1 / (1 + gap), 0)\n    \n    # Final priority score calculation\n    priority_scores = remain_cap_normalized + fit_boost * unused_bin_penalty + non_fit_penalty\n    \n    # Ensure scores are non-negative\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    # Normalize scores to ensure consistency\n    max_score = np.max(priority_scores)\n    if max_score > 0:\n        priority_scores /= max_score\n\n    return priority_scores",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores and simplifying logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins\n    unused_bin_penalty = np.where(bins_remain_cap == np.max(bins_remain_cap), 1, 0.5)\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = -np.inf * (bins_remain_cap < item)\n    \n    # Calculate the gap after placing the item\n    gap = bins_remain_cap - item\n    \n    # Boost bins where the item fits perfectly or almost perfectly\n    fit_boost = np.where(gap >= 0, 1 / (1 + gap), 0)\n    \n    # Final priority score calculation\n    priority_scores = remain_cap_normalized + fit_boost * unused_bin_penalty + non_fit_penalty\n    \n    # Ensure scores are non-negative\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    # Normalize scores to ensure consistency\n    max_score = np.max(priority_scores)\n    if max_score > 0:\n        priority_scores /= max_score\n\n    return priority_scores",
    "response_id": 1,
    "obj": 4.487435181491823,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores and simplifying logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins\n    unused_bin_penalty = np.where(bins_remain_cap == np.max(bins_remain_cap), 1, 0.5)\n    \n    # Assign zero priority to bins where the item cannot fit\n    can_fit = bins_remain_cap - item >= 0\n    non_fit_penalty = np.where(can_fit, 0, -np.inf)\n    \n    # Calculate remaining capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(can_fit, available_cap_after / bins_remain_cap, 0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(can_fit, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    fit_weight = 0.6\n    gap_weight = 0.4\n    weighted_score = fit_boost * fit_weight + gap_factor * gap_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize final scores\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Ensure scores are non-negative\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 142.33147187873953,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores and simplifying logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins\n    unused_bin_penalty = np.where(bins_remain_cap == np.max(bins_remain_cap), 1, 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    gap_factor = np.nan_to_num(gap_factor, posinf=0, neginf=0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized * 0.2 + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization to ensure consistency\n    priority_scores = priority_scores / np.max(priority_scores) if np.max(priority_scores) > 0 else priority_scores\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 149.30195452732352,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores and simplifying logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins based on remaining capacity\n    unused_bin_penalty = bins_remain_cap / np.max(bins_remain_cap, initial=1)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after, 0)\n    \n    # Calculate gap factor\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score * unused_bin_penalty\n    \n    # Apply non-fit penalty\n    priority_scores = priority_scores + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 149.30195452732352,
    "SLOC": 18.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]