[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation penalizes bins that cannot fit the item, boosts bins with smaller gaps,\n    and uses weighted strategies to encourage less fragmentation and more efficient bin usage.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority as zero\n    priority = np.zeros_like(bins_remain_cap)\n\n    # Penalize bins that cannot fit the item\n    priority[bins_remain_cap < item] -= 5  # Heavily penalize incapacity\n\n    # Calculate base priority for bins that can fit the item\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[can_fit_item_mask] = bins_remain_cap[can_fit_item_mask] - item\n\n    # Boost bins with the second smallest gaps (excluding the largest gap)\n    if np.any(can_fit_item_mask):\n        # Sort the gaps for bins that can fit the item\n        gaps = bins_remain_cap[can_fit_item_mask] - item\n        sorted_indices = np.argsort(gaps)\n\n        # Boost the second smallest gap if it exists\n        if len(sorted_indices) > 1:\n            second_smallest_index = sorted_indices[1]\n            priority[can_fit_item_mask][second_smallest_index] += 2\n\n        # Consider the smallest gap as the highest priority\n        smallest_index = sorted_indices[0]\n        priority[can_fit_item_mask][smallest_index] += 3\n\n    return priority",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well, considering large gaps and penalizing\n    non-fits. It normalizes priorities by item size and reduces complexity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (remain_cap_normalized + fit_boost) * order_penalties + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 5.384922217790187,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well, considering large gaps and penalizing\n    non-fits. It normalizes priorities by item size and reduces complexity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (remain_cap_normalized + fit_boost) * order_penalties + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 5.384922217790187,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well, considering large gaps and penalizing\n    non-fits. It normalizes priorities by item size and reduces complexity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        normalized_remain_cap = np.zeros_like(bins_remain_cap)\n    else:\n        normalized_remain_cap = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / item, 0)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (normalized_remain_cap + fit_boost) * order_penalties + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 5.604307937774236,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well, considering large gaps and penalizing\n    non-fits. It normalizes priorities by item size and reduces complexity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (remain_cap_normalized + fit_boost) * order_penalties + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 5.384922217790187,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well, considering large gaps and penalizing\n    non-fits. It normalizes priorities by item size and reduces complexity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (remain_cap_normalized + fit_boost) * order_penalties + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 5.384922217790187,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity, penalizes deviations from\n    perfect fits, applies order penalties to distribute load, and ensures that items\n    are only placed in bins where they can fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize for number of bins used (smaller the index, the more penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) / len(bins_remain_cap))\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    can_fit = available_cap_after >= 0\n    priority_scores = np.where(can_fit, available_cap_after, 0)\n    \n    # Penalize bins inversely with how much remains if the item is too large to fit perfectly\n    deviation_from_perfect_fit = np.abs(available_cap_after / bins_remain_cap)\n    priority_scores -= (bins_remain_cap != 0) * deviation_from_perfect_fit\n    \n    # Normalize remaining capacity\n    max_remaining_capacity = np.max(bins_remain_cap)\n    if max_remaining_capacity > 0:\n        priority_scores /= max_remaining_capacity\n    \n    # Apply order penalties\n    priority_scores *= order_penalties\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 113.36258476266454,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits perfectly, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized * gap_factor + fit_boost) * unused_bin_penalty + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. It normalizes the priority by the item size,\n    penalizes bins that cannot fit the item, and boosts bins with the second smallest gaps\n    to encourage less fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priority as zero\n    priority = np.zeros_like(bins_remain_cap)\n\n    # Calculate base priority for bins that can fit the item\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[can_fit_item_mask] = (bins_remain_cap[can_fit_item_mask] - item) / item\n\n    # Penalize bins that cannot fit the item\n    priority[~can_fit_item_mask] = -2\n\n    # Boost bins with the second smallest gaps (excluding the largest gap)\n    if np.any(can_fit_item_mask):\n        # Get the gaps for bins that can fit the item\n        gaps = bins_remain_cap[can_fit_item_mask] - item\n        \n        # Sort the gaps and get the second smallest\n        sorted_indices = np.argsort(gaps)\n        \n        # Boost the second smallest gap if it exists\n        if len(sorted_indices) > 1:\n            second_smallest_index = sorted_indices[1]\n            priority[can_fit_item_mask][second_smallest_index] += 1\n\n    return priority",
    "response_id": 8,
    "obj": 35.41084962106105,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well, considering large gaps and penalizing\n    non-fits. It normalizes priorities by item size and reduces complexity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        normalized_remain_cap = np.zeros_like(bins_remain_cap)\n    else:\n        normalized_remain_cap = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (smaller the index, the higher the penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / item, 0)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (normalized_remain_cap + fit_boost) * order_penalties + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 5.604307937774236,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits perfectly, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized + weighted_score) * unused_bin_penalty + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 1.7550857598723597,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits perfectly, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized + weighted_score) * unused_bin_penalty + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 1.7550857598723597,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits perfectly, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and normalize by item size\n    weighted_gap_factor = gap_factor * (1 - remain_cap_normalized)\n    \n    # Combine scores: consider fit boost, fit gaps, apply penalties, and normalize by item size\n    priority_scores = (remain_cap_normalized * weighted_gap_factor + fit_boost) * unused_bin_penalty + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 62.79417630634225,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits perfectly, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and normalize by item size\n    weighted_gap_factor = gap_factor * (1 - remain_cap_normalized)\n    \n    # Combine scores: consider fit boost, fit gaps, apply penalties, and normalize by item size\n    priority_scores = (remain_cap_normalized * weighted_gap_factor + fit_boost) * unused_bin_penalty + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 62.79417630634225,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits perfectly, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and normalize by item size\n    weighted_gap_factor = gap_factor * (1 - remain_cap_normalized)\n    \n    # Combine scores: consider fit boost, fit gaps, apply penalties, and normalize by item size\n    priority_scores = (remain_cap_normalized * weighted_gap_factor + fit_boost) * unused_bin_penalty + non_fit_penalty\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 62.79417630634225,
    "SLOC": 15.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]