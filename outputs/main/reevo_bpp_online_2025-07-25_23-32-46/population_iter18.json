[
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins effectively, penalizes bins where\n    the item cannot fit, and boosts bins where the item fits well with consideration\n    of gaps. It ensures a balance by normalizing scores by the item size and applying\n    penalties and boosts more strategically.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with more remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    \n    # Consider gaps for good fits with a diminishing return\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with balanced gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized + weighted_score) * unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize gap_factor and fit_boost for better balance\n    priority_scores = np.nan_to_num(priority_scores, posinf=0, neginf=0)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    # Normalize final scores if possible\n    if np.sum(priority_scores) > 0:\n        priority_scores /= np.sum(priority_scores)\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 1.7351416035101808,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response1.txt_stdout.txt",
    "code_path": "problem_iter18_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity by total capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    unused_bin_penalty = np.nan_to_num(unused_bin_penalty, posinf=0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after / bins_remain_cap), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, and boosts bins where the item\n    fits well with consideration of gaps. It ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity based on total capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Simplified unused bin penalty calculation\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap)) if np.max(bins_remain_cap) > 0 else np.ones_like(bins_remain_cap)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Prevent negative scores\n    priority_scores[priority_scores < 0] = 0\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 1.3163143199042726,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response3.txt_stdout.txt",
    "code_path": "problem_iter18_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes bins where the item cannot fit,\n    boosts bins where the item fits well, considers gaps for good fits, and uses a weighted strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well using a linear fit boost\n    fit_boost = np.where(available_cap_after >= 0, 1 - available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Penalize gaps for good fits using a linear gap penalty\n    gap_penalty = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    gap_penalty = np.nan_to_num(gap_penalty, posinf=0, neginf=0)\n\n    # Weighted strategy: prioritize bins with less gaps and better fits\n    gap_weight = 0.3\n    fit_weight = 0.7\n    weighted_score = fit_boost * fit_weight - gap_penalty * gap_weight\n\n    # Combine scores: consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation refines fit and gap calculations, balances penalties,\n    ensures non-fit exclusion, normalizes scores, and leverages exponential penalties for emptier bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins with exponential decay for emptier bins\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / (max_cap if max_cap > 0 else 1))\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Calculate fit boost (ratio of item to bin capacity when item fits)\n    fit_boost = np.where(available_cap_after >= 0, item / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Calculate gap factor (smaller gap is better, thus larger score)\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Dual weighted score considering both fit and gap\n    weight_fit = 0.6\n    weight_gap = 0.4\n    weighted_score = fit_boost * weight_fit + gap_factor * weight_gap\n    \n    # Combine scores: normalize remaining capacity, apply unused bin penalties, fit and gap boosts\n    priority_scores = remain_cap_normalized + weighted_score * unused_bin_penalty\n    \n    # Apply non-fit exclusion\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size to balance scores\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Ensure no negative scores to prevent selecting invalid bins\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response5.txt_stdout.txt",
    "code_path": "problem_iter18_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation emphasizes penalizing unused bins, boosting fit gaps,\n    weighting gaps more heavily, normalizing scores, and preventing negative scores.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap, initial=1))\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign very low score to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, item / bins_remain_cap, 0)\n    gap_factor = np.nan_to_num(gap_factor, posinf=0, neginf=0)\n    \n    # Adjust weights: prioritize bins with larger gaps more heavily and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response6.txt_stdout.txt",
    "code_path": "problem_iter18_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation further refines the prioritization strategy by emphasizing\n    gaps and unused bin penalties, and normalized capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins where the item cannot fit\n    non_fit_penalty = np.where(bins_remain_cap - item < 0, -np.inf, 0)\n    \n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    remain_cap_normalized = bins_remain_cap / total_capacity if total_capacity > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Penalize unused bins using exponential decay\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / max_cap) if max_cap > 0 else 1\n    \n    # Simplified fit calculation\n    fit_factor = np.where(bins_remain_cap - item >= 0, 1, 0)\n    \n    # Simplified gap calculation, emphasizing gaps\n    gap_factor = np.where(bins_remain_cap - item >= 0, (bins_remain_cap - item) / bins_remain_cap, 0)\n    \n    # Weighted score combining fit and gap, prioritizing gaps\n    weighted_score = 0.3 * fit_factor + 0.7 * gap_factor\n    \n    # Combine scores considering normalized capacity, gaps, and fit\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize scores\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Ensure no negative scores\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 24.720781810929406,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response7.txt_stdout.txt",
    "code_path": "problem_iter18_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    unused_bin_penalty = np.nan_to_num(unused_bin_penalty, posinf=10.0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits (lower gaps are prioritized)\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after / bins_remain_cap), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: consider normalized remaining capacity, fit boost and gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response8.txt_stdout.txt",
    "code_path": "problem_iter18_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    unused_bin_penalty = np.nan_to_num(unused_bin_penalty, posinf=1.0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after / bins_remain_cap), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response9.txt_stdout.txt",
    "code_path": "problem_iter18_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    unused_bin_penalty = np.nan_to_num(unused_bin_penalty, posinf=10.0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]