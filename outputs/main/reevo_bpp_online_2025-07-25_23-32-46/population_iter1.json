[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 0,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 1,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 2,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 3,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 4,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 5,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 6,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 7,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher priority,\n    but the priority is reduced for bins that would cause additional bins to be used.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate a base score based on how much of the bin would be filled with the item added.\n    base_score = (bins_remain_cap - item) / bins_remain_cap\n    \n    # We want bins that are nearly full (high occupancy) but do not exceed max capacity.\n    occupancy_score = 1 - base_score\n    \n    # Discourage adding to a new bin if current ones can suffice; penalize each new bin.\n    penalties = np.zeros_like(bins_remain_cap)\n    # Penalty: maximize score = min(value) -> penalty = 1 - value\n    penalty_term = 1 - (bins_remain_cap > item)  # Penalize new bin starting\n    penalties += penalty_term\n    \n    # Combine the occupancy score with penalties for potential new bin usage\n    combined_score = occupancy_score - penalties * 10  # High penalty for new bins\n\n    return combined_score",
    "response_id": 8,
    "obj": 5.195452732349436,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is lower if that bin choice increases the number of\n    bins used.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Discount factor for using a new bin\n    discount_factor = 0.9\n    num_bins = len(bins_remain_cap)\n    \n    # Create an array indicating which bins are already full (0 capacity left)\n    is_full = (bins_remain_cap == 0).astype(int)\n    \n    # Calculate the reduction of remaining capacity if item is added\n    capacity_reduction = bins_remain_cap - item\n    \n    # Handle cases where the item is too big to fit in the remaining space\n    # Negative capacity reduction is set to zero as those bins Items won't fit\n    capacity_reduction[capacity_reduction < 0] = 0\n    \n    # Calculate the number of new bins that would be used if this item were placed\n    # among the new finish (bins_capacity == item)\n    newly_used_bins = (capacity_reduction == 0).astype(int) - is_full\n    \n    # Decision matrix: Calculate the priority score\n    priority_score = capacity_reduction.copy()\n    # Penalize bins that would need new bins due to not fitting\n    priority_score[newly_used_bins > 0] *= discount_factor ** (np.sum(newly_used_bins) + 1)\n    \n    # Apply\u307e\u3057\u3066, apply discounts if would be needing a new optimized additional bins \n    # This discount further reduces allocation to bins leading to high fragmentation \n    n_items_in_bin_except_large_fit = (bins_remain_cap - bins_remain_cap[newly_used_bins==0]!=0) .sum()\n    additional_penalties = (bins_remain_cap - bins_remain_cap[newly_used_bins==0]) ** 0.5   \n    priority_score[newly_used_bins == 0]  *=  0.99 ** sum.addITIONAL_penalties\n    \n    return priority_score",
    "response_id": 9,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 45, in priority_v2\nAttributeError: 'builtin_function_or_method' object has no attribute 'addITIONAL_penalties'\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used considering future space efficiency. We compute the priority as a\n    combination of how much space is left in the bin after placing the item and a\n    penalty for using smaller bins prematurely. Smaller penalties are given to bins\n    that have nearly achieved their target capacity, avoiding excessive splitting\n    of small items across many bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Ensure item can be placed in bin\n    possible_bins = bins_remain_cap >= item\n\n    if not np.any(possible_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    # Initialize priority scores with penalties forBins maximizing remaining space and minimizing bin count\n    scores = np.where(possible_bins,\n                      # Base priority for unutilized capacity + penalty for larger remaining space as it suggests lessSnap-Filling (i.e., under usage).\n                      bins_remain_cap - 0.1 * np.abs(bins_remain_cap - item),\n                      -np.inf)  # Infeasible or over-com\ud83c\udf0c limit capacityAssignment bins\n    \n    # Deduct larger scores for bins which have more remaining capacity among feasible choices, prioritizingtight filling.\n    tightness = np.max(scores) - scores\n    scores -= (tightness > 0) * tightness\n    \n    # Ensure lower priorities for more empty bins to balance load and packing efficiency(next bin open chances flat).\r\n    penalty_empty_expansion = (bins_remain_cap.size - np.argsort(-bins_remain_cap)).astype(float) / bins_remain_cap.size\n    scores[max(np.where(scores != -np.inf)[0])] += penalty_empty_expansion[possible_bins][scores != -np.inf]\n    \n    # Given larger weights for bins having minimizing bins empotiments Balanced relocation account +(compact agent)\n    penalty_bin.getWritableDatabaseStrategy = np.argsort(-bins_remain_cap) * np.average(bins_remain_cap)\n    scores[max(np.where(scores != -np.inf)[0])] += penalty_bin.getWritableDatabaseStrategy[possible_bins]\n       \n    return scores",
    "response_id": 10,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 38, in priority_v2\nValueError: setting an array element with a sequence.\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero, especially when the bin is already full\n    # Ideal fit or nearly ideal fit should get high priority\n    priority_scores = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            priority_scores[i] = -np.inf  # Trash items that can't fit\n        else:\n            # Encourage fits that use up more space\n            # Penalize less for items that still leave room\n            priority_scores[i] = -(cap - item) + 1 / (cap + 1)\n    return priority_scores",
    "response_id": 11,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997085999348 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero for empty bins\n    bins_remain_cap_safe = bins_remain_cap.copy()\n    bins_remain_cap_safe[bins_remain_cap_safe == 0] = np.inf\n    \n    # Priority is higher for bins that have a larger remaining capacity after placing the item\n    priority_scores = bins_remain_cap - item\n    \n    # Pack the item into the bin that will leave the bin with the least fragmentation\n    # This can be achieved by minimizing the remaining capacity\n    priority_scores[bins_remain_cap <= item] = -np.inf  # Prevent placing item in bins that cannot hold it\n    \n    return priority_scores",
    "response_id": 12,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 15, in priority_v2\n    \"\"\"\nOverflowError: cannot convert float infinity to integer\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used penalties to encourage efficient packing while distributing load.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    remaining_capacity = bins_remain_cap - item\n    normalized_capacity = remaining_capacity / np.max(bins_remain_cap, initial=1)\n    \n    # Penalize bins that cannot fit the item\n    penalized_capacity = np.where(normalized_capacity < 0, -np.inf, normalized_capacity)\n    \n    # Calculate the frequency of each bin being used heuristic\n    usage_heuristic = 1 / (np.sum(bins_remain_cap != np.max(bins_remain_cap), axis=0) + 1)\n    \n    # Final priority score\n    priority_scores = penalized_capacity * usage_heuristic\n    return priority_scores",
    "response_id": 13,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used penalties to encourage efficient packing while distributing load.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    remain_cap_normalized = bins_remain_cap / np.max(bins_remain_cap)\n    \n    # Penalize for each unused bin to encourage filling existing bins\n    num_bins_penalty = np.nan_to_num(1 / (np.count_nonzero(bins_remain_cap) + 1e-6), posinf=0)\n    \n    # Avoid negative priority scores (e.g., if item is larger than a bin)\n    priority_scores = (remain_cap_normalized - item) + num_bins_penalty\n    priority_scores[priority_scores < 0] = 0\n    \n    # Encourage using bins with large enough space for the item\n    priority_scores[bins_remain_cap >= item] += 1\n    \n    return priority_scores",
    "response_id": 14,
    "obj": 4.487435181491823,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used penalties to encourage efficient packing while distributing load.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    remain_cap_normalized = bins_remain_cap / np.max(bins_remain_cap, initial=1)\n    \n    # Favor bins that have enough space to fit the item\n    can_fit_scores = np.where(bins_remain_cap >= item, 1, 0)\n    \n    # Encourage adding to bins that are less full by using their remaining capacity\n    priority_scores = remain_cap_normalized * can_fit_scores\n    \n    # Penalize fills to the fullest bin slightly to promote distributing load amongbins\n    # This is a softer policy encouraging less full bins to be used primarily.\n    # Avoid zero maximum cap encounter, small epsilon is added.\n    # Note: This\u91d1\u878dcurve corrforms a wide concave cup during small range where bit could dissolve but somewhat work independ Wyoming significant.\n    epsilon = 1e-6\n    max_remaining_capacity = np.max(bins_remain_cap, initial=epsilon)\n    penalty_weight = 0.1  # Adjust this to softer or tighter control.\n    fullest_penalty = (\n        1 - (bins_remain_cap - (max_remaining_capacity - item)) / max_remaining_capacity\n    ) ** penalty_weight\n    # Apply the penalty only if the bin can fit the item\n    fullest_penalty *= can_fit_scores\n\n    # Total priority now adds understurdy contrast often NEED compliant\u78fbstone nun optimize imply\u82f1\u683c\ub77c\uc774;');\n    total_priorities = priority_scores - fullest_penalty\n    \n    # Ensure that bins that can't fit the item get a score below all viable options\n    total_priorities *= can_fit_scores\n\n    return total_priorities",
    "response_id": 15,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used penalties to encourage efficient packing while distributing load.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    remain_cap_normalized = bins_remain_cap / np.max(bins_remain_cap)\n    \n    # Penalize for number of bins used (smaller the index, the more penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)))\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    np.place(available_cap_after, available_cap_after < 0, 0)\n    \n    # Higher scores for higher available capacity and negative penalty\n    priority_scores = remain_cap_normalized * order_penalties\n    \n    # Penalize binschema\uc801\uc73c\ub85c pero inversely with how much remains if the item is too large to fit perfectly\n    deviation_from_perfect_fit = np.abs(available_cap_after / bins_remain_cap)\n    priority_scores -= (bins_remain_cap == 0) * deviation_from_perfect_fit\n    \n    return priority_scores",
    "response_id": 16,
    "obj": 4.397686477862,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # To avoid incapacity bins to be prioritized, we substract a penalty\n    incapacity_penalty = np.where(bins_remain_cap < item, 0.5, 0)  # Penalty for bins that cannot contain the item\n    \n    return priority - incapacity_penalty",
    "response_id": 17,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities if item is larger than remaining capacity\n    base_priority = np.maximum(bins_remain_cap - item, 0)\n\n    # Penalize bins that do not have enough remaining capacity to fit the item\n    penalty = np.where(bins_remain_cap < item, -np.abs(bins_remain_cap - item), 0)\n\n    # Integrated priority calculation\n    priority = base_priority + penalty\n\n    return priority",
    "response_id": 18,
    "obj": 149.30195452732352,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 19,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 20,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 21,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 22,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 23,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 24,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 25,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        bin_item_gaps_priority = np.where(can_fit_item_mask, 1/(np.abs(parity_after_check - highest_remaining_capacities.mean()) + 0.1), 0)\n        priority = (priority + bin_item_gaps_priority) / 2\n    \n    return priority\n\n# Example usage snippet - How this priority mapping works for dummy data.\n\nif __name__ == '__main__\":\n    bins_remaining_cap_demo = np.array([6, 4 ,5, 7, 3])\n    item_example = 3\n\n    print(\"Based priority rules for the given bins and item clip ; \\n Priority Scores = {} \\n\".format(\n    priority_v2(item_example, bins_remaining_cap_demo)))",
    "response_id": 26,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 38\n    if __name__ == '__main__\":\n                   ^\nSyntaxError: unterminated string literal (detected at line 38)\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item itself (setting them to a very low priority), and further\n    reduced if they are too small relative to the item's size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with remaining capacity\n    priorities = bins_remain_cap.copy()\n    \n    # Penalize bins that cannot even fit the item\n    priorities[bins_remain_cap < item] = -float('inf')\n    \n    # Prioritize bins where remaining capacity is more than the item size (regular use case)\n    # But low if significantly smaller than bin capacity\n    priority_bonus = np.where(bins_remain_cap >= item + item*0.2, bins_remain_cap, 0.1)\n    \n    # Multiply a factor to make sure the bonus has a fair impact on larger bins\n    factor = 2.0 # arbitrary factor; can be tuned\n    priorities = priorities + factor * priority_bonus\n    \n    # Penalize bins that are extremely full (Objective to avoid half-empty bins)\n    extreme_full_threshold = 0.1\n    priorities[bins_remain_cap <= item * extreme_full_threshold] -= item * 10\n    \n    return priorities",
    "response_id": 27,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 23, in priority_v2\n    can_fit_item_mask = bins_remain_cap >= item\nOverflowError: cannot convert float infinity to integer\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        differences = np.unique(priority_after_check[np.where(can_fit_item_mask).squeeze()])\n        if len(differences) > 1:\n            priority[np.where(priority_after_check == differences[1])] += 0.1\n    \n    return priority",
    "response_id": 28,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 30, in priority_v2\n    highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\nAttributeError: 'tuple' object has no attribute 'squeeze'\n12\n4\n"
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[np.where(~can_fit_item_mask)] -= 2\n    \n    # Encourage the second smallest gaps (fill bigger empty spots\u5c3d\u65e9 to encourage less fragmentation)\n    # Less penalty for bins pediatric returning subtle fragments after an insertion\n    if np.any(can_fit_item_mask):\n        priority_after_check = bins_remain_cap - item\n        highest_remaining_capacities = np.partition(priority_after_check[can_fit_item_mask], 1)[:2]\n        low = highest_remaining_capacities[0] if len(highest_remaining_capacities) > 1 else 0\n        low_idx = np.where(np.isclose(priority_after_check, low))[0]\n        if len(low_idx) == 1:\n            priority[low_idx[0]] += 1  # boost solitare other fragment accent withok followers much step-water pour toplant\u0131\n    \n    return priority",
    "response_id": 29,
    "obj": 145.26326286398086,
    "SLOC": 12.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  }
]