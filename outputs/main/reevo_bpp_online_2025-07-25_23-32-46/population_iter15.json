[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, strongly penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It ensures a balance by normalizing scores by the item size and gives higher weight to bins\n    that have a good fit with larger gaps.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins based on remaining capacity\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well, penalize for larger gaps\n    fit_boost = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Calculate gap quality factor for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after / bins_remain_cap), 0)\n    gap_factor = np.nan_to_num(gap_factor, posinf=0, neginf=0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.7\n    fit_weight = 0.3\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies fit and gap calculations, balances weights,\n    and uses exponential penalties consistently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins where the item cannot fit\n    non_fit_penalty = np.where(bins_remain_cap - item < 0, -np.inf, 0)\n    \n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    remain_cap_normalized = bins_remain_cap / total_capacity if total_capacity > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Penalize unused bins using exponential decay\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / max_cap) if max_cap > 0 else 1\n    \n    # Simplified fit calculation\n    fit_factor = np.where(bins_remain_cap - item >= 0, 1.0 - (bins_remain_cap - item) / bins_remain_cap, 0)\n    \n    # Simplified gap calculation\n    gap_factor = np.where(bins_remain_cap - item >= 0, (bins_remain_cap - item) / bins_remain_cap, 0)\n    \n    # Weighted score combining fit and gap\n    weighted_score = 0.5 * fit_factor + 0.5 * gap_factor\n    \n    # Combine scores considering normalized capacity, gaps, and fit\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize scores\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Ensure no negative scores\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size and adds\n    penalties for bins with lower remaining capacity to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    max_remain_cap = np.max(bins_remain_cap) if np.any(bins_remain_cap) else 1\n    unused_bin_penalty = 1 - (bins_remain_cap / max_remain_cap)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits (penalty for larger gaps)\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with smaller gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores -= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 140.99521340247307,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on minimizing gaps and maximizing fit efficiency. It simplifies\n    penalty calculations and normalizes weights effectively.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins where the item cannot fit\n    non_fit_penalty = np.where(bins_remain_cap < item, -np.inf, 0)\n\n    # Calculate gaps after placing the item\n    gaps = np.where(bins_remain_cap >= item, bins_remain_cap - item, 0)\n\n    # Minimize gaps and maximize fit efficiency\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = (1 - gaps / np.where(bins_remain_cap >= item, bins_remain_cap, 1)) * gap_weight + \\\n                     (gaps / bins_remain_cap) * fit_weight\n\n    # Normalize by total remaining capacity, avoiding division by zero\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n\n    # Penalize unused bins using exponential decay\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        unused_bin_penalty = np.ones_like(bins_remain_cap)\n    else:\n        unused_bin_penalty = np.exp(-bins_remain_cap / max_cap)\n\n    # Combine scores and apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n\n    # Ensure scores remain non-negative\n    priority_scores = np.clip(priority_scores + non_fit_penalty, 0, None)\n\n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on normalized capacities, penalizes unused bins,\n    and boosts bins where the item fits well with large gaps. It simplifies the\n    boosting logic and ensures all scores are non-negative.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    remain_cap_normalized = bins_remain_cap / max_cap if max_cap > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Penalize unused bins based on their index (smaller index, higher penalty)\n    order_penalties = np.exp(-np.arange(len(bins_remain_cap)) * 0.1)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well with large gaps\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / item, 0) if item > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Combine scores: normalize by item size, consider fit boost, and apply penalties\n    priority_scores = (remain_cap_normalized + fit_boost) * order_penalties + non_fit_penalty\n    \n    # Ensure all scores are non-negative\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 9.46350219385721,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This improved implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits well, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy and considers order penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / (max_cap if max_cap > 0 else 1))\n\n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well\n    fit_boost = np.where(available_cap_after >= 0, 1 - available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Penalize gaps for good fits\n    gap_penalty = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    gap_penalty = np.nan_to_num(gap_penalty, posinf=0, neginf=0)\n\n    # Weighted strategy: prioritize bins with less gaps and better fits\n    gap_weight = 0.3\n    fit_weight = 0.7\n    weighted_score = fit_boost * fit_weight - gap_penalty * gap_weight\n\n    # Combine scores: consider fit boost and fit gaps, apply penalties and unused bin penalty\n    priority_scores = remain_cap_normalized + weighted_score * unused_bin_penalty + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a balanced strategy that considers normalized\n    remaining capacities, penalizes gaps, encourages bins with better fits,\n    and penalizes unused bins. It ensures normalization by item size and avoids\n    negative scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of the same size as bins_remain_cap with priority score for each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    remain_cap_normalized = bins_remain_cap / total_capacity if total_capacity > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Penalize gaps: higher penalty for larger gaps\n    gap_penalty_factor = 1 / (1 + bins_remain_cap - item)\n    gap_penalty = np.where(gap_penalty_factor < 0, 0, gap_penalty_factor)  # Avoid negative penalties\n    \n    # Boost bins where the item fits well\n    fit_boost = np.where(bins_remain_cap >= item, bins_remain_cap - item, 0)\n    fit_boost_normalized = fit_boost / total_capacity if total_capacity > 0 else fit_boost  # Normalize fit boost\n    \n    # Penalize unused bins: exponentially higher penalty for bins with less remaining capacity\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap)) if np.max(bins_remain_cap) > 0 else 0\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(bins_remain_cap < item, -np.inf, 0)\n    \n    # Weighted strategy: balance between normalized remaining capacity,\n    # gap penalties, fit boosts, and penalties for unused bins\n    gap_weight = 0.3\n    fit_weight = 0.4\n    capacity_weight = 0.2\n    penalty_weight = 0.1\n    \n    weighted_score = (\n        capacity_weight * remain_cap_normalized -\n        gap_weight * gap_penalty +\n        fit_weight * fit_boost_normalized +\n        penalty_weight * unused_bin_penalty\n    )\n    \n    # Combine scores\n    priority_scores = weighted_score\n    \n    # Apply penalties for non-fitting bins\n    priority_scores += non_fit_penalty\n    \n    # Normalize scores by item size\n    priority_scores /= item if item > 0 else 1\n    \n    # Ensure scores are non-negative\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 22.357399282010377,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, and boosts bins where the item\n    fits well with consideration of gaps. It ensures a balance by normalizing scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    max_cap = np.max(bins_remain_cap)\n    if max_cap == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / max_cap\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / max_cap) if max_cap > 0 else np.ones_like(bins_remain_cap)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: consider fit boost and fit gaps\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 27.67251695253291,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies the fit boost calculation, balances the gap and fit weights,\n    and consistently normalizes capacities.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    remain_cap_normalized = bins_remain_cap / total_capacity if total_capacity > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Simplified boost for bins where the item fits well\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n\n    # Balanced weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n\n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n\n    # Final normalization by item size for balance\n    priority_scores /= item if item > 0 else 1\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n\n    return priority_scores",
    "response_id": 8,
    "obj": 1.3163143199042726,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes unused bins,\n    boosts bins where the item fits well, considers gaps for good fits,\n    and normalizes by item size. It also penalizes bins where the item cannot fit.\n    Additionally, it uses a weighted strategy to balance fit boosting and gap penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins using a quadratic decay for remaining capacity\n    unused_bin_penalty = np.power(bins_remain_cap / (np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1), 2)\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(bins_remain_cap - item < 0, -np.inf, 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Boost bins where the item fits well (using a negative exponential decay of the gap)\n    fit_boost = np.where(available_cap_after >= 0, np.exp(-available_cap_after / bins_remain_cap), 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Penalize gaps for good fits using a quadratic function of the gap\n    gap_penalty = np.where(available_cap_after >= 0, np.power(available_cap_after / bins_remain_cap, 2), 0)\n    gap_penalty = np.nan_to_num(gap_penalty, posinf=0, neginf=0)\n\n    # Weighted strategy: prioritize bins with less gaps and better fits\n    gap_weight = 0.3\n    fit_weight = 0.7\n    weighted_score = fit_boost * fit_weight - gap_penalty * gap_weight\n\n    # Combine scores considering fit boost and fit gaps, apply penalties and unused bin penalty\n    priority_scores = remain_cap_normalized + weighted_score * unused_bin_penalty + non_fit_penalty\n    \n    # Normalize scores by item size to balance weights\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Ensure no negative scores\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 146.92859992022335,
    "SLOC": 20.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response0.txt_stdout.txt",
    "code_path": "problem_iter15_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / np.sqrt(1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize gap_factor and fit_boost for better balance\n    priority_scores = np.nan_to_num(priority_scores, posinf=0, neginf=0)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response1.txt_stdout.txt",
    "code_path": "problem_iter15_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / np.sqrt(1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize gap_factor and fit_boost for better balance\n    priority_scores = np.nan_to_num(priority_scores, posinf=0, neginf=0)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response2.txt_stdout.txt",
    "code_path": "problem_iter15_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    unused_bin_penalty = np.nan_to_num(unused_bin_penalty, posinf=1)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.6\n    fit_weight = 0.4\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 3.5500598324691004,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response3.txt_stdout.txt",
    "code_path": "problem_iter15_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / np.sqrt(1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response4.txt_stdout.txt",
    "code_path": "problem_iter15_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.where(max_cap > 0, np.exp(-bins_remain_cap / max_cap), 1)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, item / (bins_remain_cap + 1e-6), 0)  # Avoid division by zero\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 7.828081372157958,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]