[
  {
    "stdout_filepath": "problem_iter16_response0.txt_stdout.txt",
    "code_path": "problem_iter16_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on simplicity, consistent normalization, and balanced weighting.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    remain_cap_normalized = bins_remain_cap / np.sum(bins_remain_cap) if np.sum(bins_remain_cap) > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(bins_remain_cap - item < 0, -np.inf, 0)\n    \n    # Simplified boost for bins where the item fits well\n    fit_boost = np.where(bins_remain_cap - item >= 0, bins_remain_cap - item, 0) / bins_remain_cap\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gaps = bins_remain_cap - item\n    gap_factor = np.where(gaps >= 0, gaps / bins_remain_cap, 0)\n    gap_factor = np.nan_to_num(gap_factor, posinf=0, neginf=0)\n\n    # Balanced weighted strategy: prioritize bins with better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = fit_boost * fit_weight + gap_factor * gap_weight\n\n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n\n    # Final normalized score by item size\n    priority_scores /= item if item > 0 else 1\n\n    # Add non-fit penalty\n    priority_scores += non_fit_penalty\n\n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n\n    return priority_scores",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response1.txt_stdout.txt",
    "code_path": "problem_iter16_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies fit and gap calculations, balances weights,\n    and uses exponential penalties consistently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins where the item cannot fit\n    non_fit_penalty = np.where(bins_remain_cap - item < 0, -np.inf, 0)\n    \n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    remain_cap_normalized = bins_remain_cap / total_capacity if total_capacity > 0 else np.zeros_like(bins_remain_cap)\n    \n    # Penalize unused bins using exponential decay\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / max_cap) if max_cap > 0 else 1\n    \n    # Simplified fit calculation\n    fit_factor = np.where(bins_remain_cap - item >= 0, 1, 0)\n    \n    # Simplified gap calculation\n    gap_factor = np.where(bins_remain_cap - item >= 0, (bins_remain_cap - item) / bins_remain_cap, 0)\n    \n    # Weighted score combining fit and gap\n    weighted_score = 0.5 * fit_factor + 0.5 * gap_factor\n    \n    # Combine scores considering normalized capacity, gaps, and fit\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize scores\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Ensure no negative scores\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 11.597526924611085,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response2.txt_stdout.txt",
    "code_path": "problem_iter16_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies penalties, boosts, and weights, focusing on\n    normalized remaining capacities, penalized unused bins, and bins where the item\n    fits well with consideration of gaps. It ensures a balance by normalizing scores\n    by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap, initial=1))\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign very low score to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, item / bins_remain_cap, 0)\n    gap_factor = np.nan_to_num(gap_factor, posinf=0, neginf=0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 7.828081372157958,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response3.txt_stdout.txt",
    "code_path": "problem_iter16_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies penalties, boosts, and weights, focusing on\n    normalized remaining capacities, penalized unused bins, and boosting bins\n    where the item fits well with a consideration of gaps. It normalizes scores\n    regularly and avoids excessive transformations.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins using an exponential decay\n    max_cap = np.max(bins_remain_cap)\n    unused_bin_penalty = np.exp(-bins_remain_cap / (max_cap if max_cap > 0 else 1))\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Calculate fit boost (how well the item fits in the bin)\n    fit_boost = np.where(available_cap_after >= 0, item / (bins_remain_cap + 1e-6), 0)\n    \n    # Calculate gap factor (how small the gap is after placing the item)\n    gap_factor = np.where(available_cap_after >= 0, available_cap_after / (bins_remain_cap + 1e-6), 1)\n    \n    # Weights for fit boost and gap factor\n    fit_weight = 0.6\n    gap_weight = 0.4\n    \n    # Weighted score combining fit boost and gap factor\n    weighted_score = fit_weight * fit_boost + gap_weight * gap_factor\n    \n    # Combine scores including penalties\n    priority_scores = remain_cap_normalized * unused_bin_penalty + weighted_score\n    \n    # Apply non-fit penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize by item size if greater than zero\n    priority_scores = np.where(item > 0, priority_scores / item, priority_scores)\n    \n    # Ensure no negative scores\n    priority_scores = np.maximum(priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response4.txt_stdout.txt",
    "code_path": "problem_iter16_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins effectively, penalizes bins where\n    the item cannot fit, and boosts bins where the item fits well with consideration\n    of gaps. It ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / np.sqrt(1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with balances gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = (remain_cap_normalized + weighted_score) * unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Normalize gap_factor and fit_boost for better balance\n    priority_scores = np.nan_to_num(priority_scores, posinf=0, neginf=0)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    # Normalize final scores\n    if np.sum(priority_scores) > 0:\n        priority_scores /= np.sum(priority_scores)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response5.txt_stdout.txt",
    "code_path": "problem_iter16_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a weighted strategy that considers normalized\n    remaining capacities, penalizes unused bins using an exponential decay, \n    penalizes bins where the item cannot fit, and boosts bins where the item \n    fits well with consideration of gaps. It also ensures a balance by normalizing \n    scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins using exponential decay\n    unused_bin_penalty = np.exp(-bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Simplified gap factor calculation\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 1.3163143199042726,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response6.txt_stdout.txt",
    "code_path": "problem_iter16_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation further simplifies the unused bin penalty, removes unnecessary normalizations,\n    and focuses on balancing fits and gaps.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Simplified boost for bins where the item fits well\n    fit_boost = np.where(available_cap_after >= 0, item / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n\n    # Balanced weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.5\n    fit_weight = 0.5\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n\n    # Combine scores: consider fit boost and fit gaps, apply penalties\n    priority_scores = weighted_score + bins_remain_cap / np.sum(bins_remain_cap)\n\n    # Add a small penalty for bins that are almost full but not quite\n    almost_full_penalty = np.where((available_cap_after > 0) & (available_cap_after < 0.1), -0.1, 0)\n    priority_scores += almost_full_penalty\n    \n    # Apply fit penalty\n    priority_scores += non_fit_penalty\n\n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n\n    return priority_scores",
    "response_id": 6,
    "obj": 149.30195452732352,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response7.txt_stdout.txt",
    "code_path": "problem_iter16_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses a simple strategy that penalizes bins where the item\n    cannot fit and boosts bins based on the remaining capacity after placing the item.\n    It ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well\n    fit_boost = np.where(available_cap_after >= 0, available_cap_after, 0)\n    \n    # Normalize fit_boost by item size\n    normalized_fit_boost = fit_boost / (item if item > 0 else 1)\n    \n    # Combine scores: consider fit boost and fit gaps, apply penalties\n    priority_scores = normalized_fit_boost\n    priority_scores += non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 149.30195452732352,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response8.txt_stdout.txt",
    "code_path": "problem_iter16_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation normalizes the remaining capacities, penalizes bins where the item cannot fit,\n    boosts bins where the item fits well, considers gaps for good fits, and uses a weighted strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well using a linear fit boost\n    fit_boost = np.where(available_cap_after >= 0, 1 - available_cap_after / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Penalize gaps for good fits using a linear gap penalty\n    gap_penalty = np.where(available_cap_after >= 0, available_cap_after / bins_remain_cap, 0)\n    gap_penalty = np.nan_to_num(gap_penalty, posinf=0, neginf=0)\n\n    # Weighted strategy: prioritize bins with less gaps and better fits\n    gap_weight = 0.3\n    fit_weight = 0.7\n    weighted_score = fit_boost * fit_weight - gap_penalty * gap_weight\n\n    # Combine scores: consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score + non_fit_penalty\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response9.txt_stdout.txt",
    "code_path": "problem_iter16_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on a refined strategy that considers normalized\n    remaining capacities, penalizes unused bins, penalizes bins where the item\n    cannot fit, and boosts bins where the item fits well with consideration of gaps.\n    It also ensures a balance by normalizing scores by the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate normalized remaining capacity\n    total_capacity = np.sum(bins_remain_cap)\n    if total_capacity == 0:\n        remain_cap_normalized = np.zeros_like(bins_remain_cap)\n    else:\n        remain_cap_normalized = bins_remain_cap / total_capacity\n    \n    # Penalize unused bins (higher penalty for bins with less remaining capacity)\n    unused_bin_penalty = np.where(bins_remain_cap > 0, 1 / bins_remain_cap, 0)\n    unused_bin_penalty = np.nan_to_num(unused_bin_penalty, posinf=0.5)\n    \n    # Calculate available capacity after placing the item\n    available_cap_after = bins_remain_cap - item\n    \n    # Assign zero priority to bins where the item cannot fit\n    non_fit_penalty = np.where(available_cap_after < 0, -np.inf, 0)\n    \n    # Boost bins where the item fits well and penalize if not fitting perfectly\n    fit_boost = np.where(available_cap_after >= 0, (bins_remain_cap - available_cap_after) / bins_remain_cap, 0)\n    fit_boost = np.nan_to_num(fit_boost, posinf=0, neginf=0)\n    \n    # Consider gaps for good fits\n    gap_factor = np.where(available_cap_after >= 0, 1 / (1 + available_cap_after / bins_remain_cap), 0)\n    \n    # Weighted strategy: prioritize bins with larger gaps and better fits\n    gap_weight = 0.4\n    fit_weight = 0.6\n    weighted_score = gap_factor * gap_weight + fit_boost * fit_weight\n    \n    # Combine scores: normalize by item size, consider fit boost and fit gaps, apply penalties\n    priority_scores = remain_cap_normalized + weighted_score\n    priority_scores *= unused_bin_penalty\n    priority_scores += non_fit_penalty\n    \n    # Final normalization by item size for balance\n    priority_scores /= (item if item > 0 else 1)\n    \n    # Prevent negative scores that might lead to selection of invalid bins\n    priority_scores[priority_scores < 0] = 0\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]