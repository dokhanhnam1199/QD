{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.75,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.05,\n    tie_breaker_scale: float = 1e-12,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online Bin Packing problem.\n\n    The score is higher for bins that:\n      * fit the item well (fit ratio near ``target_fit``),\n      * leave little waste after placement (waste below ``waste_target``),\n      * break ties deterministically by bin index,\n      * optionally explore via random noise or \u03b5\u2011greedy exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining free capacity of each currently open bin.\n    epsilon : float, default 0.02\n        Probability of replacing the deterministic scores with random scores\n        (\u03b5\u2011greedy exploration).\n    noise_scale : float, default 1e-5\n        Scale of uniform additive noise added to each feasible bin's score.\n    alpha_fit : float, default 10.0\n        Logistic steepness for the *fit\u2011ratio* component.\n    target_fit : float, default 0.75\n        Desired fit ratio (item / remaining capacity) where the fit component\n        reaches 0.5.\n    alpha_waste : float, default 12.0\n        Logistic steepness for the *waste* component.\n    waste_target : float, default 0.05\n        Desired waste fraction (relative to bin capacity) where the waste\n        component reaches 0.5.\n    tie_breaker_scale : float, default 1e-12\n        Small multiplier for bin index to break exact ties deterministically.\n    random_state : int or None, default None\n        Seed for the internal RNG (useful for reproducibility).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = better) for each bin. Infeasible bins receive\n        ``-np.inf`` so they will never be selected by ``np.argmax``.\n    \"\"\"\n    # Ensure proper NumPy array\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n    n_bins = bins_remain_cap.size\n\n    if n_bins == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasibility mask: can the item fit?\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No feasible bin \u2192 all scores -inf\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate static bin capacity (assume all bins share the same capacity)\n    bin_capacity = float(np.max(bins_remain_cap))\n    if bin_capacity <= 0.0:\n        # Defensive: capacity non\u2011positive, treat as infeasible\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng(random_state)\n\n    # ------------------------------------------------------------------\n    # 1) Fit\u2011ratio component (item size relative to remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    # Compute ratio only for feasible bins to avoid divide\u2011by\u2011zero warnings\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n\n    # Logistic: high when fit_ratio \u2248 target_fit\n    # Clip exponent to avoid overflow\n    exp_fit = np.exp(-np.clip(alpha_fit * (fit_ratio - target_fit), -500, 500))\n    fit_score = 1.0 / (1.0 + exp_fit)\n\n    # ------------------------------------------------------------------\n    # 2) Waste component (leftover capacity after placement)\n    # ------------------------------------------------------------------\n    waste_norm = np.clip((bins_remain_cap - item) / bin_capacity, 0.0, 1.0)\n    # Logistic decreasing: small waste \u2192 high score\n    exp_waste = np.exp(np.clip(alpha_waste * (waste_norm - waste_target), -500, 500))\n    waste_score = 1.0 / (1.0 + exp_waste)\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively\n    # ------------------------------------------------------------------\n    combined_score = fit_score * waste_score\n\n    # Infeasible bins must be penalised with -inf\n    combined_score[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Deterministic tie\u2011breaker (tiny index\u2011based bias)\n    # ------------------------------------------------------------------\n    combined_score += np.arange(n_bins, dtype=np.float64) * tie_breaker_scale\n\n    # ------------------------------------------------------------------\n    # Add small random noise for stochastic tie\u2011breaking\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(n_bins) * noise_scale\n        combined_score[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration: occasionally replace scores with random ranks\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_scores = np.full_like(combined_score, -np.inf, dtype=np.float64)\n        random_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        combined_score = random_scores\n\n    return combined_score\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n    exact_fit_bonus: float = 1e6\n) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin\u2011packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    epsilon : float, default 0.05\n        Probability of selecting a completely random feasible bin (\u03b5\u2011greedy exploration).\n    noise_scale : float, default 1e-4\n        Scale of the uniform noise added to the raw scores. The noise magnitude\n        is attenuated by (1\u2011fit_ratio) so that bins that almost perfectly fit\n        the item receive less random perturbation.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Parameters of the sigmoid used to score the fit\u2011ratio\n        (item / remaining_capacity).\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Parameters of the sigmoid used to score the waste\n        (remaining_capacity - item).\n    alpha_used, used_target : float, default 10.0, 0.40\n        Parameters of the sigmoid used to score the used\u2011fraction\n        ((max_capacity - remaining_capacity) / max_capacity).\n    temperature : float or None, default None\n        If provided, the final scores are passed through a\n        temperature\u2011scaled softmax so that they sum to one.\n        If ``None`` the raw scores are returned.\n    exact_fit_bonus : float, default 1e6\n        Bonus added to a bin that fits the item exactly (remaining_capacity == item).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher is better).  Feasible\n        bins receive a value in [0,1] (or a probability when\n        ``temperature`` is set).  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Input validation\n    # ------------------------------------------------------------------\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    if bins_remain_cap.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a 1\u2011D array\")\n    if item <= 0.0:\n        raise ValueError(\"item must be positive\")\n    if not 0.0 <= epsilon <= 1.0:\n        raise ValueError(\"epsilon must be between 0 and 1\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive if provided\")\n\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # 2. Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # 3. Common auxiliary quantities\n    # ------------------------------------------------------------------\n    max_capacity = bins_remain_cap.max()\n    # Avoid division by zero \u2013 but if there is at least one feasible bin,\n    # max_capacity must be > 0 because feasible bins have capacity >= item > 0.\n    if max_capacity <= 0.0:\n        max_capacity = 1.0  # safety, will not be used due to feasibility check\n\n    # --------------------------------------------------------------\n    # Helper: numerically stable logistic\n    # --------------------------------------------------------------\n    def _logistic(z: np.ndarray) -> np.ndarray:\n        \"\"\"1/(1+exp(-z)) with clipping to avoid overflow.\"\"\"\n        z = np.clip(z, -700.0, 700.0)\n        return 1.0 / (1.0 + np.exp(-z))\n\n    # ------------------------------------------------------------------\n    # 4. Component scores\n    # ------------------------------------------------------------------\n    # 4.1 Fit ratio\n    fit_ratio = np.empty_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio = np.clip(fit_ratio, 0.0, 1.0)\n    fit_z = alpha_fit * (fit_ratio - target_fit)\n    fit_score = _logistic(fit_z)\n\n    # 4.2 Waste (remaining capacity after placement)\n    waste = bins_remain_cap - item\n    waste_norm = waste / max_capacity\n    waste_norm = np.clip(waste_norm, 0.0, 1.0)\n    waste_z = -alpha_waste * (waste_norm - waste_target)\n    waste_score = _logistic(waste_z)\n\n    # 4.3 Used fraction\n    used_fraction = (max_capacity - bins_remain_cap) / max_capacity\n    used_fraction = np.clip(used_fraction, 0.0, 1.0)\n    used_z = alpha_used * (used_fraction - used_target)\n    used_score = _logistic(used_z)\n\n    # ------------------------------------------------------------------\n    # 5. Raw priority (product of the three sigmoids)\n    # ------------------------------------------------------------------\n    priorities = fit_score * waste_score * used_score\n    priorities[~feasible] = 0.0  # will be set to -inf later\n\n    # ------------------------------------------------------------------\n    # 6. Add noise proportional to (1 - fit_ratio)\n    # ------------------------------------------------------------------\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=priorities.shape)\n        noise_factor = np.where(feasible, 1.0 - fit_ratio, 0.0)\n        priorities += noise * noise_factor\n\n    # ------------------------------------------------------------------\n    # 7. Bonus for exact fits\n    # ------------------------------------------------------------------\n    exact_fit_mask = feasible & np.isclose(waste, 0.0, atol=1e-9)\n    priorities[exact_fit_mask] += exact_fit_bonus\n\n    # ------------------------------------------------------------------\n    # 8. \u03b5\u2011greedy exploration\n    # ------------------------------------------------------------------\n    if rng.random() < epsilon:\n        priorities = rng.random(size=priorities.shape)\n        priorities[~feasible] = -np.inf\n    else:\n        priorities[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # 9. Optional temperature\u2011scaled softmax\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            max_score = feasible_scores.max()\n            # Stabilize by subtracting max\n            exp_scores = np.exp((feasible_scores - max_score) / temperature)\n            probs = exp_scores / exp_scores.sum()\n            priorities[feasible] = probs\n        # infeasible bins get zero probability\n        priorities[~feasible] = 0.0\n\n    return priorities\n\n[Reflection]\nAdd used\u2011fraction component, exact\u2011fit bonus, temperature softmax, proportional noise, tighter sigmoids, robust input validation.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}