{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global constants (tuned offline)\nCAP = 1.0            # Bin capacity (assumed 1.0 for normalized terms)\nK_BASE = 10.0        # Base steepness for the variance\u2011adapted sigmoid\nVAR_MAX = 0.25       # Max variance for a uniform [0,1] distribution\nEPSILON = 0.01       # Exploration probability for \u03b5\u2011greedy\nHUGE_BONUS = 1e6     # Exact\u2011fit bonus\n\n    \"\"\"\n    Priority scores for online bin\u2011packing with variance\u2011adapted sigmoids,\n    product scoring, exact\u2011fit bonus, and \u03b5\u2011greedy exploration.\n    Feasible bins receive a finite score; infeasible bins get -inf.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = more desirable).  Infeasible bins receive\n        ``-np.inf`` so they are never selected.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    feasible = caps >= item\n    n_bins = caps.shape[0]\n\n    # Return -inf for all bins if none can accommodate the item\n    if not np.any(feasible):\n        return np.full(n_bins, -np.inf, dtype=float)\n\n    # Remaining capacity after placing the item\n    leftover = caps - item\n\n    # Basic terms (all lie in [0,1] because CAP == 1.0)\n    norm_leftover = np.where(feasible, leftover / CAP, 0.0)\n    fit_ratio    = np.where(feasible, item / CAP, 0.0)\n    usage_after  = np.where(feasible, 1.0 - leftover / CAP, 0.0)\n\n    def sigmoid_term(term_arr: np.ndarray) -> np.ndarray:\n        \"\"\"Variance\u2011adapted sigmoid centered at 0.5.\"\"\"\n        # Compute variance only over feasible bins\n        if np.any(feasible):\n            var = np.var(term_arr[feasible])\n        else:\n            var = 0.0\n        var_norm = min(var / VAR_MAX, 1.0)\n        k = K_BASE * (1.0 - var_norm)  # lower variance \u2192 steeper sigmoid\n        return 1.0 / (1.0 + np.exp(-k * (term_arr - 0.5)))\n\n    # Sigmoid transforms for each term\n    sig_leftover = sigmoid_term(norm_leftover)\n    sig_fit      = sigmoid_term(fit_ratio)\n    sig_usage    = sigmoid_term(usage_after)\n\n    # Product of weighted sigmoid scores (weights are exponents; tuned offline)\n    weighted_score = (sig_leftover ** 1.0) * \\\n                     (sig_fit     ** 1.0) * \\\n                     (sig_usage   ** 1.0)\n\n    # Add a huge bonus for exact\u2011fit placements\n    exact_fit_mask = feasible & np.isclose(leftover, 0.0, atol=1e-9)\n    weighted_score[exact_fit_mask] += HUGE_BONUS\n\n    # \u03b5\u2011greedy exploration: mix with uniform random scores\n    rng = np.random.default_rng()\n    random_score = rng.random(n_bins)\n    final_score = (1.0 - EPSILON) * weighted_score + EPSILON * random_score\n\n    # Ensure infeasible bins are never chosen\n    final_score[~feasible] = -np.inf\n\n    return final_score\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                bins_remain_cap: np.ndarray,\n                *,\n                epsilon: float = 0.05,\n                noise_scale: float = 1e-4,\n                alpha_fit: float = 12.0,\n                target_fit: float = 0.80,\n                alpha_waste: float = 12.0,\n                waste_target: float = 0.07,\n                alpha_used: float = 10.0,\n                used_target: float = 0.40,\n                temperature: float | None = None) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing that combines multiple\n    sigmoid\u2011based criteria, optional noise, \u03b5\u2011greedy exploration and an\n    optional temperature\u2011scaled softmax.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities in the currently open bins.\n    epsilon : float, default 0.05\n        Probability of selecting a completely random feasible bin\n        (\u03b5\u2011greedy exploration).\n    noise_scale : float, default 1e-4\n        Scale of the uniform noise added to the raw scores. The noise\n        magnitude is attenuated by (1\u2011fit_ratio) so that bins that\n        almost perfectly fit the item receive less random perturbation.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Parameters of the sigmoid used to score the fit\u2011ratio\n        (item / remaining_capacity).\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Parameters of the sigmoid used to score the waste\n        (remaining_capacity - item).\n    alpha_used, used_target : float, default 10.0, 0.40\n        Parameters of the sigmoid used to score the used\u2011fraction\n        ((max_capacity - remaining_capacity) / max_capacity).\n    temperature : float or None, default None\n        If provided, the final scores are passed through a\n        temperature\u2011scaled softmax so that they sum to one.\n        If ``None`` the raw scores are returned.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher is better).  Feasible\n        bins receive a value in [0,1] (or a probability when\n        ``temperature`` is set).  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Input validation\n    if bins_remain_cap.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a 1\u2011D array\")\n    if item <= 0:\n        raise ValueError(\"item size must be positive\")\n    if not 0 <= epsilon <= 1:\n        raise ValueError(\"epsilon must be between 0 and 1\")\n    if noise_scale < 0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0:\n        raise ValueError(\"temperature must be positive if provided\")\n\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasible bins mask\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate of the maximum capacity among current bins\n    max_capacity = bins_remain_cap.max()\n\n    # Compute individual components\n    # 1. Fit ratio\n    fit_ratio = np.empty_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio = np.clip(fit_ratio, 0.0, 1.0)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n    fit_score[~feasible] = 0.0\n\n    # 2. Waste component\n    waste = bins_remain_cap - item\n    waste_norm = np.clip(waste / max_capacity, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # 3. Used\u2011fraction component\n    used_fraction = (max_capacity - bins_remain_cap) / max_capacity\n    used_fraction = np.clip(used_fraction, 0.0, 1.0)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n    used_score[~feasible] = 0.0\n\n    # Combined raw priority\n    priorities = fit_score * waste_score * used_score\n\n    # Add random noise to break ties and add exploration\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=priorities.shape)\n        # Dampen noise for bins that already have a good fit\n        noise *= (1.0 - fit_ratio)\n        priorities += noise\n\n    # \u03b5\u2011greedy: with probability epsilon, choose a random feasible bin\n    if rng.random() < epsilon:\n        random_scores = rng.random(size=priorities.shape)\n        random_scores[~feasible] = -np.inf\n        priorities = random_scores\n\n    # Set infeasible bins to -inf\n    priorities[~feasible] = -np.inf\n\n    # Optional temperature\u2011scaled softmax\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            max_score = feasible_scores.max()\n            exp_scores = np.exp((feasible_scores - max_score) / temperature)\n            prob_scores = exp_scores / exp_scores.sum()\n            priorities[feasible] = prob_scores\n\n    return priorities\n\n[Reflection]\nMask infeasible bins, normalize components, tune sigmoid steepness, add noise proportional to fit, use \u03b5\u2011greedy, optional softmax.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}