```python
import numpy as np
from typing import Optional


def priority_v2(
    item: float,
    bins_remain_cap: np.ndarray,
    # ------------------- optional parameters -------------------
    capacity: Optional[float] = None,
    epsilon: float = 0.05,
    noise_scale: float = 1e-4,
    alpha_fit: float = 12.0,
    target_fit: float = 0.80,
    alpha_waste: float = 12.0,
    waste_target: float = 0.07,
    alpha_used: float = 10.0,
    used_target: float = 0.40,
    temperature: Optional[float] = None,
    rng: Optional[np.random.Generator] = None,
) -> np.ndarray:
    """
    Compute a priority score for each open bin in an online bin‑packing
    setting.

    The function evaluates three sigmoid‑scaled features for each feasible
    bin:

    * **Fit ratio**      – item / remaining_capacity.
    * **Waste**          – (remaining_capacity - item) / capacity.
    * **Used fraction**  – (capacity - remaining_capacity) / capacity.

    The three feature scores are multiplied together, optionally perturbed
    by small noise (damped by (1‑fit_ratio)), optionally replaced by a
    random ε‑greedy choice, and finally (if ``temperature`` is given)
    transformed into a probability distribution via a temperature‑scaled
    softmax.  Infeasible bins receive ``-np.inf``.

    Parameters
    ----------
    item : float
        Size of the incoming item (must be positive).
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.
    capacity : float | None, optional
        Fixed bin capacity.  If ``None`` the maximum remaining capacity
        among the current bins is used as an estimate.
    epsilon : float, default 0.05
        Probability of performing ε‑greedy random selection among the
        feasible bins.
    noise_scale : float, default 1e-4
        Uniform noise magnitude added to the raw scores.  The noise is
        damped by ``(1 - fit_ratio)``.
    alpha_fit, target_fit : float, default 12.0, 0.80
        Sigmoid parameters for the *fit‑ratio* component.
    alpha_waste, waste_target : float, default 12.0, 0.07
        Sigmoid parameters for the *waste* component.
    alpha_used_​, used_target : float, default 10.0, 0.40
        Sigmoid parameters for the *used‑fraction* component.
    temperature : float | None, optional
        If provided, the final scores are transformed into a probability
        distribution using a temperature‑scaled softmax.
    rng : np.random.Generator | None, optional
        Random number generator for reproducibility.  If ``None`` a new
        default generator is created.

    Returns
    -------
    np.ndarray
        Priority scores (or probabilities) for each bin.  Feasible bins
        have finite values; infeasible bins are marked ``-np.inf``.
    """
    # ------------------------------------------------------------------
    # RNG setup
    # ------------------------------------------------------------------
    if rng is None:
        rng = np.random.default_rng()

    # ------------------------------------------------------------------
    # Input validation and conversion
    # ------------------------------------------------------------------
    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()
    if bins.ndim != 1:
        raise ValueError("bins_remain_cap must be a one‑dimensional array")
    if item <= 0.0:
        raise ValueError("item size must be positive")
    if not (0.0.0 <= epsilon <= 1.0):
        raise ValueError("epsilon must be in [0, 1]")
    if noise_scale < 0.0:
        raise ValueError("noise_scale must be non‑negative")
    if temperature is not None and temperature <= 0.0:
        raise ValueError("temperature must be positive when provided")

    n_bins = bins.size
    if n_bins == 0:
        return np.array([], dtype=np.float64)

    # ------------------------------------------------------------------
    # Feasibility mask
    # ------------------------------------------------------------------
    feasible = bins >= item
    if not np.any(feasible):
        # No feasible bin – everything is -inf
        return np.full_like(bins, -np.inf, dtype=np.float64)

    # ------------------------------------------------------------------
    # Determine bin capacity
    # ------------------------------------------------------------------
    if capacity is None:
        # Use the largest observed remaining capacity as an estimate.
        cap_est = float(bins.max())
        capacity = cap_est if cap_est > 0.0 else 1.0
    else:
        if capacity <= 0.0:
            raise ValueError("capacity must be positive")

    # ------------------------------------------------------------------
    # Helper sigmoid
    # ------------------------------------------------------------------
    def _sigmoid(x: np.ndarray) -> np.ndarray:
        # Numerically stable sigmoid
        return 1.0 / (1.0 + np.exp(-x))

    # ------------------------------------------------------------------
    # Component 1 – Fit ratio (item / remaining capacity)
    # ------------------------------------------------------------------
    fit_ratio = np.zeros_like(bins, dtype=np.float64)
    np.divide(item, bins, out=fit_ratio, where=feasible)
    np.clip(fit_ratio, 0.0, 1.0, out=fit_ratio)
    fit_score = _sigmoid(alpha_fit * (fit_ratio - target_fit))
    fit_score[~feasible] = 0.0

    # ------------------------------------------------------------------
    # Component 2 – Waste after placement, normalised by capacity
    # ------------------------------------------------------------------
    waste = bins - item                     # remaining capacity after placement
    waste_norm = waste / capacity           # normalised waste in [0, 1]
    np.clip(waste_norm, 0.0, 1.0, out=waste_norm)
    # Logistic decreasing: small waste => high score
    waste_score = _sigmoid(-alpha_waste * (waste_norm - waste_target))
    waste_score[~feasible := feasible] = 0.0  # type: ignore

    # ------------------------------------------------------------------
    # Component 3 – Used fraction (how full the bin already is)
    # ------------------------------------------------------------------
    used_fraction = (capacity - bins) / capacity
    np.clip(used_fraction, 0.0, 1.0, out=used_fraction)
    used_score = _sigmoid(alpha_used * (used_fraction - used_target))
    used_score[~feasible] = 0.0

    # ------------------------------------------------------------------
    # Combine components multiplicatively
    # ------------------------------------------------------------------
    raw_score = fit_score * waste_score * used_score

    # ------------------------------------------------------------------
    # Add exploration noise, damped by (1 - fit_ratio)
    # ------------------------------------------------------------------
    if noise_scale > 0.0:
        noise = rng.uniform(-noise_scale, noise_scale, size=n_bins)
        # Dampen where fit is already good and only on feasible bins
        noise *= (1.0 - fit_ratio) * feasible
        raw_score += noise

    # ------------------------------------------------------------------
    # ε‑greedy random exploration
    # ------------------------------------------------------------------
    if rng.random() < epsilon:
        rand_vals = rng.random(size=n_bins)
        rand_vals[~feasible] = -np.inf  # type: ignore
        raw_score = rand_vals

    # ------------------------------------------------------------------
    # Mark infeasible bins explicitly
    # ------------------------------------------------------------------
    raw_score[~feasible] = -np.inf

    # ------------------------------------------------------------------
    # Optional temperature‑scaled softmax → probability distribution
    # ------------------------------------------------------------------
    if temperature is not None:
        feas_scores = raw_score[feasible]
        if feas_scores.size == 0:
            # All infeasible – keep -inf everywhere
            return raw_score
        # Stabilise exponentiation
        max_score = feas_scores.max()
        exp_vals = np.exp((feas_scores - max_score) / temperature)
        probs = exp_vals / exp_vals.sum()
        out = np.full_like(raw_score, -np.inf, dtype=np.float64)
        out[feasible] = probs
        return out

    return raw_score
```
