{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 1.0,\n    alpha: float = 0.5,\n    fit_weight: float = 1.0,\n) -> np.ndarray:\n    \"\"\"\n    Softmax\u2011based priority for online bin packing.\n\n    The score for each *feasible* bin i combines three criteria:\n        \u2022 leftover capacity after placement (smaller is better)\n        \u2022 fit ratio   = item / remaining_capacity (larger is better)\n        \u2022 variance of the remaining capacities after placement\n          (smaller variance promotes load\u2011balancing)\n\n    The raw score for bin i is\n        s_i = - (remaining_i - item)\n              + fit_weight * (item / remaining_i)\n              - alpha * var_i\n\n    where var_i is the variance of the capacities after hypothetically\n    placing the item into bin i.\n\n    The scores are transformed with a temperature\u2011scaled softmax:\n        priority_i = exp((s_i - max(s)) / temperature)\n                     / \u03a3_j exp((s_j - max(s)) / temperature)\n\n    Infeasible bins (remaining capacity < item) receive priority 0.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n    temperature : float, optional\n        Softmax temperature (>0). Small values make the selection\n        more deterministic; larger values yield a flatter distribution.\n    alpha : float, optional\n        Weight of the variance penalty. Larger values favour a more\n        balanced load across bins.\n    fit_weight : float, optional\n        Weight of the fit\u2011ratio term. Larger values give preference to\n        bins that fit the item tightly.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``).\n        The values sum to 1 across feasible bins; infeasible bins have\n        priority 0.\n    \"\"\"\n    # Convert input to a float array and handle empty input\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = bins_remain_cap.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive number\")\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n\n    # If no bin can accommodate the item, return all zeros\n    if not feasible.any():\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    # --- Component 1: leftover capacity after placement ---\n    leftover = bins_remain_cap - item                     # shape (n_bins,)\n\n    # --- Component 2: fit ratio ---\n    # item / capacity; safe because bins_remain_cap > 0 (feasible implies >= item > 0)\n    fit_ratio = np.empty_like(bins_remain_cap)\n    # Avoid division by zero for zero-capacity bins (should be infeasible anyway)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fit_ratio[:] = item / bins_remain_cap\n    fit_ratio[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # --- Component 3: variance after placement ---\n    # Compute total sum and sum of squares once\n    total_sum = bins_remain_cap.sum()\n    total_sq_sum = np.square(bins_remain_cap).sum()\n    new_sum = total_sum - item  # total remaining capacity after placing the item\n\n    # Variance after placing the item into each bin i:\n    # var_i = (total_sq_sum - 2*item*cap_i + item**2) / n_bins - (new_sum / n_bins)**2\n    var_after = (\n        (total_sq_sum - 2.0 * item * bins_remain_cap + item ** 2) / n_bins\n        - (new_sum / n_bins) ** 2\n    )\n    var_after[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # --- Raw score ---\n    # We want high score for good bins, so combine with signs accordingly\n    raw_score = -leftover + fit_weight * fit_ratio - alpha * var_after\n\n    # Infeasible bins should never be selected: assign -inf before softmax\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # --- Softmax transformation ---\n    # Numerical stability: subtract the max of feasible scores\n    max_feas = raw_score[feasible].max()\n    scaled = (raw_score - max_feas) / temperature\n\n    # Exponentiate; exp(-inf) -> 0 automatically\n    exp_scaled = np.exp(scaled)\n\n    # Normalise to obtain probabilities (priorities)\n    total_exp = exp_scaled[feasible].sum()\n    if total_exp == 0.0:\n        # Edge case: all feasible scores were -inf (should not happen)\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    else:\n        priorities = exp_scaled / total_exp\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                bins_remain_cap: np.ndarray,\n                *,\n                epsilon: float = 0.05,\n                noise_scale: float = 1e-4,\n                alpha_fit: float = 12.0,\n                target_fit: float = 0.80,\n                alpha_waste: float = 12.0,\n                waste_target: float = 0.07,\n                alpha_used: float = 10.0,\n                used_target: float = 0.40) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing based on a multiplicative\n    combination of three sigmoid\u2011based criteria (fit, waste, usage)\n    with adaptive noise and optional \u03b5\u2011greedy exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacity in each currently open bin.\n    epsilon : float, optional\n        Probability of choosing a completely random feasible bin.\n    noise_scale : float, optional\n        Base scale of the additive uniform noise.\n    alpha_fit, target_fit : float, optional\n        Sigmoid hyper\u2011parameters for the fit\u2011ratio component.\n    alpha_waste, waste_target : float, optional\n        Sigmoid hyper\u2011parameters for the waste component.\n    alpha_used, used_target : float, optional\n        Sigmoid hyper\u2011parameters for the used\u2011fraction component.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better); infeasible bins receive\n        ``-np.inf``.  The returned array has the same shape as\n        ``bins_remain_cap``.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    est_capacity = float(np.max(bins_remain_cap))\n\n    # Fit\u2011ratio component\n    fit_ratio = np.zeros_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio = np.clip(fit_ratio, 0.0, 1.0)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n    fit_score[~feasible] = 0.0\n\n    # Waste component\n    waste = bins_remain_cap - item\n    waste_norm = np.clip(waste / est_capacity, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # Used\u2011fraction component\n    used_fraction = (est_capacity - bins_remain_cap) / est_capacity\n    used_fraction[~feasible] = 0.0\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n    used_score[~feasible] = 0.0\n\n    priorities = fit_score * waste_score * used_score\n\n    rng = np.random.default_rng()\n\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=bins_remain_cap.shape)\n        noise *= (1.0 - fit_ratio)\n        priorities += noise\n\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_scores = rng.random(bins_remain_cap.shape)\n        random_scores[~feasible] = -np.inf\n        priorities = random_scores\n\n    priorities[~feasible] = -np.inf\n    return priorities\n\n[Reflection]\nMultiplicative sigmoid scores, add noise, \u03b5\u2011greedy, scale by capacity; prioritize tight fit, low waste, balanced usage.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}