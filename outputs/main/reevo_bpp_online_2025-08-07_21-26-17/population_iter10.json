[
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 20.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 20.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 15.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n    tie_breaker_scale: float = 1e-12,\n    exact_fit_bonus: float = 1e6,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"Priority function for online bin\u2011packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    epsilon : float, default 0.05\n        Probability of selecting a completely random feasible bin (\u03b5\u2011greedy exploration).\n    noise_scale : float, default 1e-4\n        Scale of the uniform noise added to the raw scores. The noise magnitude\n        is attenuated by (1\u2011fit_ratio) so that bins that almost perfectly fit\n        the item receive less random perturbation.\n    alpha_fit, target_fit : float, default 20.0, 0.80\n        Parameters of the sigmoid used to score the fit\u2011ratio\n        (item / remaining_capacity).\n    alpha_waste, waste_target : float, default 20.0, 0.07\n        Parameters of the sigmoid used to score the waste\n        (remaining_capacity - item).\n    alpha_used, used_target : float, default 15.0, 0.40\n        Parameters of the sigmoid used to score the used\u2011fraction\n        ((max_capacity - remaining_capacity) / max_capacity).\n    temperature : float or None, default None\n        If provided, the final scores are passed through a\n        temperature\u2011scaled softmax so that they sum to one.\n        If ``None`` the raw scores are returned.\n    tie_breaker_scale : float, default 1e-12\n        Tiny multiplier for bin index to break exact ties deterministically.\n    exact_fit_bonus : float, default 1e6\n        Bonus added to a bin that fits the item exactly (remaining_capacity == item).\n    random_state : int or None, default None\n        Seed for the internal RNG (useful for reproducibility).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better) for each bin.  Feasible\n        bins receive a value in [0,1] (or a probability when\n        ``temperature`` is set).  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # ----- Input validation -----\n    if not isinstance(item, (int, float)):\n        raise TypeError(\"item must be a numeric type\")\n    if item <= 0.0:\n        raise ValueError(\"item must be positive\")\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n    if bins_remain_cap.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a 1\u2011D array\")\n    if np.any(np.isnan(bins_remain_cap)):\n        bins_remain_cap = np.where(np.isnan(bins_remain_cap), -np.inf, bins_remain_cap)\n    if np.any(bins_remain_cap < 0):\n        bins_remain_cap = np.where(bins_remain_cap < 0, -np.inf, bins_remain_cap)\n    if not 0.0 <= epsilon <= 1.0:\n        raise ValueError(\"epsilon must be between 0 and 1\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive if provided\")\n    if tie_breaker_scale < 0.0:\n        raise ValueError(\"tie_breaker_scale must be non\u2011negative\")\n    if exact_fit_bonus < 0.0:\n        raise ValueError(\"exact_fit_bonus must be non\u2011negative\")\n    if random_state is not None and not isinstance(random_state, (int, np.integer)):\n        raise TypeError(\"random_state must be an int or None\")\n\n    n_bins = bins_remain_cap.size\n    if n_bins == 0:\n        return np.array([], dtype=np.float64)\n\n    # ----- Feasibility mask -----\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full(n_bins, -np.inf, dtype=np.float64)\n\n    # ----- RNG -----\n    rng = np.random.default_rng(random_state)\n\n    # ----- Max capacity estimate -----\n    max_capacity = float(bins_remain_cap.max())\n    if max_capacity <= 0.0:\n        max_capacity = 1.0\n\n    # ----- Logistic helper (numerically stable) -----\n    def _logistic(z: np.ndarray) -> np.ndarray:\n        z = np.clip(z, -700.0, 700.0)\n        return 1.0 / (1.0 + np.exp(-z))\n\n    # ----- Fit ratio component -----\n    fit_ratio = np.empty_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio = np.clip(fit_ratio, 0.0, 1.0)\n    fit_z = alpha_fit * (fit_ratio - target_fit)\n    fit_score = _logistic(fit_z)\n\n    # ----- Waste component -----\n    waste = bins_remain_cap - item\n    waste_norm = np.clip(waste / max_capacity, 0.0, 1.0)\n    waste_z = -alpha_waste * (waste_norm - waste_target)\n    waste_score = _logistic(waste_z)\n\n    # ----- Used fraction component -----\n    used_fraction = np.clip((max_capacity - bins_remain_cap) / max_capacity, 0.0, 1.0)\n    used_z = alpha_used * (used_fraction - used_target)\n    used_score = _logistic(used_z)\n\n    # ----- Raw priority -----\n    priorities = fit_score * waste_score * used_score\n    priorities[~feasible] = 0.0\n\n    # ----- Tie\u2011breaker -----\n    priorities += np.arange(n_bins, dtype=np.float64) * tie_breaker_scale\n\n    # ----- Proportional noise -----\n    if noise_scale > 0.0:\n        noise_factor = np.where(feasible, 1.0 - fit_ratio, 0.0)\n        noise = rng.uniform(-noise_scale, noise_scale, size=n_bins) * noise_factor\n        priorities += noise\n\n    # ----- Exact fit bonus -----\n    exact_fit_mask = feasible & np.isclose(waste, 0.0, atol=1e-9)\n    priorities[exact_fit_mask] += exact_fit_bonus\n\n    # ----- \u03b5\u2011greedy exploration -----\n    if rng.random() < epsilon:\n        priorities = np.full(n_bins, -np.inf, dtype=np.float64)\n        priorities[feasible] = rng.random(np.count_nonzero(feasible))\n    else:\n        priorities[~feasible] = -np.inf\n\n    # ----- Temperature\u2011scaled softmax -----\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            max_score = feasible_scores.max()\n            exp_scores = np.exp((feasible_scores - max_score) / temperature)\n            probs = exp_scores / exp_scores.sum()\n            priorities[feasible] = probs\n        priorities[~feasible] = 0.0\n\n    return priorities",
    "response_id": 0,
    "obj": 4.537295572397288,
    "SLOC": 88.0,
    "cyclomatic_complexity": 21.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response1.txt_stdout.txt",
    "code_path": "problem_iter10_code1.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    capacity: Optional[float] = None,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n    rng: Optional[np.random.Generator] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing\n    setting. The score combines three sigmoid components (fit, waste,\n    used\u2011fraction) multiplicatively, adds fit\u2011scaled noise, and optionally\n    applies \u03b5\u2011greedy exploration and temperature\u2011scaled softmax.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    capacity : float | None, optional\n        Fixed bin capacity. If ``None`` the maximum remaining capacity among\n        the current bins is used as a surrogate.\n    epsilon : float, default 0.05\n        Probability of performing \u03b5\u2011greedy random selection among feasible bins.\n    noise_scale : float, default 1e-4\n        Uniform noise magnitude added to the raw score. Scaled by ``(1\u2011fit_ratio)``.\n    alpha_fit, target_fit : float, default 12.0, 0.80.0\n        Sigmoid steepness and target for the *fit ratio* component.\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Sigmoid steepness and target for the *waste* component.\n    alpha_used, used_target : float, default 10.0, 0.40\n        Sigmoid steepness and target for the *used\u2011fraction* component.\n    temperature : float | None, optional\n        If provided, the final scores are transformed into a probability\n        distribution using a temperature\u2011scaled softmax.\n    rng : np.random.Generator | None, optional\n        Random number generator for reproducibility. If ``None`` a new default\n        generator is created.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (or probabilities when ``temperature`` is set) for each\n        bin. Infeasible bins receive ``-np.inf`` (or zero probability).\n    \"\"\"\n    # ------------------------------------------------------------------\n    # RNG setup\n    # ------------------------------------------------------------------\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Input handling & validation\n    # ------------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n    if bins.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a one\u2011dimensional array\")\n    if item <= 0.0:\n        raise ValueError(\"item size must be positive\")\n    if not (0.0 <= epsilon <= 1.0):\n        raise ValueError(\"epsilon must be in [0, 1]\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive when provided\")\n\n    # Early exit for empty bin list\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins >= item\n    if not np.any(feasible):\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Determine bin capacity\n    # ------------------------------------------------------------------\n    if capacity is None:\n        # Use the largest observed remaining capacity as an estimate.\n        capacity_est = float(bins.max())\n        capacity = capacity_est if capacity_est > 1e-12 else 1.0\n    else:\n        if capacity <= 0.0:\n            raise ValueError(\"capacity must be positive\")\n\n    # ------------------------------------------------------------------\n    # Component 1 \u2013 Fit ratio (item / remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins, dtype=np.float64)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    np.clip(fit_ratio, 0.0, 1.0, out=fit_ratio)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n    fit_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 2 \u2013 Waste (remaining capacity after placement)\n    # ------------------------------------------------------------------\n    waste = bins - item\n    waste_norm = waste / capacity\n    np.clip(waste_norm, 0.0, 1.0, out=waste_norm)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 3 \u2013 Used fraction (how full the bin already is)\n    # ------------------------------------------------------------------\n    used_fraction = (capacity - bins) / capacity\n    np.clip(used_fraction, 0.0, 1.0, out=used_fraction)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n    used_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively\n    # ------------------------------------------------------------------\n    priorities = fit_score * waste_score * used_score\n\n    # ------------------------------------------------------------------\n    # Add fit\u2011scaled exploration noise\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=priorities.shape)\n        noise *= (1.0 - fit_ratio) * feasible  # damp noise for good fits\n        priorities += noise\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy random exploration\n    # ------------------------------------------------------------------\n    if rng.random() < epsilon:\n        rand_scores = rng.random(size=priorities.shape)\n        rand_scores[~feasible] = -np.inf\n        priorities = rand_scores\n\n    # ------------------------------------------------------------------\n    # Explicitly mark infeasible bins\n    # ------------------------------------------------------------------\n    priorities[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Optional temperature\u2011scaled softmax \u2192 probability distribution\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            # Stabilise exponentiation\n            max_score = feasible_scores.max()\n            exp_vals = np.exp((feasible_scores - max_score) / temperature)\n            probs = exp_vals / exp_vals.sum()\n            out = np.full_like(priorities, -np.inf, dtype=np.float64)\n            out[feasible] = probs\n            priorities = out\n        else:\n            # No feasible bins \u2013 return -inf everywhere\n            priorities = np.full_like(priorities, -np.inf, dtype=np.float64)\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 76.0,
    "cyclomatic_complexity": 17.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response2.txt_stdout.txt",
    "code_path": "problem_iter10_code2.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.75,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.05,\n    tie_breaker_scale: float = 1e-12,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing\n    problem. The bin with the highest score is selected.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining free capacity of each currently open bin.\n    epsilon : float, default 0.02\n        Probability of performing \u03b5\u2011greedy exploration.\n    noise_scale : float, default 1e-5\n        Scale of uniform additive noise added to each feasible bin's score.\n    alpha_fit : float, default 10.0\n        Logistic steepness for the *fit\u2011ratio* component.\n    target_fit : float, default 0.75\n        Desired fit ratio (item / remaining capacity) where the fit component\n        reaches 0.5.\n    alpha_waste : float, default 12.0\n        Logistic steepness for the *waste* component.\n    waste_target : float, default 0.05\n        Desired waste fraction (relative to bin capacity) where the waste\n        component reaches 0.5.\n    tie_breaker_scale : float, default 1e-12\n        Small multiplier for bin index to break exact ties deterministically.\n    random_state : int or None, default None\n        Seed for the internal RNG (useful for reproducibility).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = better) for each bin. Infeasible bins receive\n        ``-np.inf`` so they will never be selected by ``np.argmax``.\n    \"\"\"\n    # Ensure a NumPy array of floats\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n    n_bins = bins_remain_cap.size\n    if n_bins == 0:\n        return np.empty(0, dtype=np.float64)\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate bin capacity (assume all bins share the same capacity)\n    bin_capacity = float(np.max(bins_remain_cap))\n    if bin_capacity <= 0.0:\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng(random_state)\n\n    # --- 1) Fit\u2011ratio component -------------------------------------------\n    fit_ratio = np.zeros_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n\n    max_exp = 700.0  # limit to avoid overflow\n    exp_fit = np.exp(\n        -np.clip(alpha_fit * (fit_ratio - target_fit), -max_exp, max_exp)\n    )\n    fit_score = 1.0 / (1.0 + exp_fit)\n\n    # --- 2) Waste component -----------------------------------------------\n    waste_norm = np.clip((bins_remain_cap - item) / bin_capacity, 0.0, 1.0)\n    exp_waste = np.exp(\n        np.clip(alpha_waste * (waste_norm - waste_target), -max_exp, max_exp)\n    )\n    waste_score = 1.0 / (1.0 + exp_waste)\n\n    # --- 3) Combine multiplicatively --------------------------------------\n    combined_score = fit_score * waste_score\n    combined_score[~feasible] = -np.inf\n\n    # --- 4) Deterministic tie\u2011breaker ------------------------------------\n    combined_score += np.arange(n_bins, dtype=np.float64) * tie_breaker_scale\n\n    # --- 5) Small random noise for stochastic tie\u2011breaking ----------------\n    if noise_scale > 0.0:\n        noise = rng.random(n_bins) * noise_scale\n        combined_score[feasible] += noise[feasible]\n\n    # --- 6) \u03b5\u2011greedy exploration -----------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_scores = np.full_like(combined_score, -np.inf, dtype=np.float64)\n        random_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        combined_score = random_scores\n\n    return combined_score",
    "response_id": 2,
    "obj": 4.198244914240141,
    "SLOC": 47.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response3.txt_stdout.txt",
    "code_path": "problem_iter10_code3.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    random_state: Optional[int] = None,\n    epsilon_min: float = 0.05,\n    epsilon_max: float = 0.25,\n    tie_breaker_scale: float = 1e-12,\n    eps: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    random_state : int or None, optional\n        Seed for reproducibility of the random exploration component.\n    epsilon_min, epsilon_max : float, optional\n        Minimum and maximum exploration probability. The actual epsilon is\n        adapted based on the variance of leftover space among feasible bins.\n    tie_breaker_scale : float, optional\n        Tiny coefficient to break exact ties deterministically by bin index.\n    eps : float, optional\n        Small constant to avoid division by zero when computing the base score.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Ensure numpy array\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask: can the item fit into the bin?\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Compute leftover capacity after placing the item\n    leftover = bins_remain_cap - item\n\n    # Base exploitation score: tighter fits get higher scores\n    base_score = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    base_score[feasible] = 1.0 / (leftover[feasible] + eps)\n\n    # Adaptive epsilon based on variance of leftover space among feasible bins\n    lo = leftover[feasible]\n    var = np.var(lo)  # population variance (ddof=0)\n    max_lo = np.max(lo)\n    if max_lo > 0.0:\n        # Max possible variance for values in [0, max_lo] is (max_lo^2)/4\n        var_max = (max_lo ** 2) / 4.0\n        var_norm = np.clip(var / var_max, 0.0, 1.0)\n    else:\n        var_norm = 0.0\n    epsilon = epsilon_min + (epsilon_max - epsilon_min) * (1.0 - var_norm)\n\n    # Random exploration component\n    rng = np.random.default_rng(random_state)\n    random_score = rng.random(bins_remain_cap.shape)\n\n    # Combine exploitation and exploration\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    priorities[feasible] = (\n        (1.0 - epsilon) * base_score[feasible] + epsilon * random_score[feasible]\n    )\n\n    # Deterministic tie\u2011breaker (tiny index\u2011based bias)\n    priorities += np.arange(bins_remain_cap.size, dtype=np.float64) * tie_breaker_scale\n\n    return priorities",
    "response_id": 3,
    "obj": 3.320702034303945,
    "SLOC": 34.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response4.txt_stdout.txt",
    "code_path": "problem_iter10_code4.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    weight_leftover: float = 1.0,\n    weight_fit: float = 1.0,\n    weight_variance: float = 0.5,\n    temperature: float = 0.1,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    random_state: Optional[int] = None\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin when an item arrives in an online\n    bin\u2011packing problem.\n\n    The raw priority is a weighted combination of three intuitive criteria:\n\n    * **Leftover capacity** after placing the item.  Smaller leftover\n      (i.e. tighter fit) is preferred \u2013 contributes with a negative weight.\n    * **Fit ratio** \u2013 the ratio of the item size to the bin capacity\n      (``item / bins``).  Larger ratio indicates a tighter fit relative to\n      the bin size \u2013 contributes with a positive weight.\n    * **Post\u2011placement variance** of the remaining capacities of all bins.\n      Lower variance is preferred \u2013 contributes with a negative weight.\n\n    The raw scores are optionally perturbed with a small uniform noise\n    (``noise_scale``) and, with probability ``epsilon``, replaced by a\n    uniformly random value to encourage exploration.\n\n    Finally a temperature\u2011scaled softmax turns the scores into a probability\n    distribution; the bin with the highest probability is chosen by the\n    calling routine.  If no bin can accommodate the item, a vector of zeros\n    is returned.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining capacity of each currently open\n        bin.\n    weight_leftover : float, default=1.0\n        Weight for the leftover capacity term (negative contribution).\n    weight_fit : float, default=1.0\n        Weight for the fit\u2011ratio term (positive contribution).\n    weight_variance : float, default=0.5\n        Weight for the variance penalty term (negative contribution).\n    temperature : float, default=0.1\n        Temperature for the softmax; lower values sharpen the distribution.\n    epsilon : float, default=0.05\n        Probability of performing \u03b5\u2011greedy exploration (random feasible\n        bin).  Set to 0 to disable.\n    noise_scale : float, default=1e-4\n        Scale of uniform noise added to the raw scores before the softmax.\n    random_state : int or None, optional\n        Seed for reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        Probability of selecting each bin.  Infeasible bins receive a\n        probability of zero.  If no bin can accommodate the item, the\n        returned array consists entirely of zeros.\n    \"\"\"\n    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n    n_bins = bins.size\n\n    if n_bins == 0:\n        return np.array([], dtype=np.float64)\n\n    if item <= 0:\n        raise ValueError(\"Item size must be positive.\")\n    if temperature <= 0:\n        raise ValueError(\"Temperature must be positive.\")\n    if not (0 <= epsilon <= 1):\n        raise ValueError(\"Epsilon must be in [0, 1].\")\n\n    rng = np.random.default_rng(random_state)\n\n    # Feasibility mask\n    feasible = bins >= item\n    if not np.any(feasible):\n        return np.zeros_like(bins, dtype=np.float64)\n\n    # Leftover capacity after placement\n    leftover = bins - item\n\n    # Fit ratio: item / bin capacity (valid only for feasible bins)\n    fit_ratio = np.empty_like(bins)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0\n\n    # Variance of remaining capacities after placing the item into each bin\n    total_sum = bins.sum()\n    total_sq = np.square(bins).sum()\n    sum_x = total_sum - item                    # \u03a3 all capacities after placement\n    sum_sq = total_sq - 2 * item * bins + item**2  # \u03a3 squares after placement\n    mean = sum_x / n_bins\n    var = sum_sq / n_bins - mean**2\n    var[~feasible] = 0.0\n\n    # Raw priority: weighted sum of the three criteria\n    raw_score = (\n        -weight_leftover * leftover\n        + weight_fit * fit_ratio\n        - weight_variance * var\n    )\n    raw_score[~feasible] = -np.inf  # infeasible bins cannot be chosen\n\n    # Optional exploration noise\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=feasible.sum())\n        raw_score[feasible] += noise\n\n    # \u03b5\u2011greedy exploration\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_vals = rng.uniform(0.0, 1.0, size=feasible.sum())\n        raw_score[feasible] = random_vals\n\n    # Temperature\u2011scaled softmax to obtain probabilities\n    max_feasible = raw_score[feasible].max()\n    # Shift to avoid overflow\n    shifted = (raw_score - max_feasible) / temperature\n    exp_vals = np.exp(shifted)\n    exp_vals[~feasible] = 0.0\n    total = exp_vals.sum()\n    if total == 0.0:\n        # Should not happen, but keep robust\n        return np.zeros_like(bins, dtype=np.float64)\n    priorities = exp_vals / total\n\n    return priorities",
    "response_id": 4,
    "obj": 4.228161148783416,
    "SLOC": 58.0,
    "cyclomatic_complexity": 10.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response5.txt_stdout.txt",
    "code_path": "problem_iter10_code5.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    capacity: Optional[float] = None,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    fit_alpha: float = 12.0,\n    fit_target: float = 0.80,\n    waste_alpha: float = 12.0,\n    waste_target: float = 0.07,\n    usage_alpha: float = 10.0,\n    usage_target: float = 0.40,\n    weight_fit: float = 1.0,\n    weight_waste: float = 1.0,\n    weight_usage: float = 1.0,\n    temperature: Optional[float] = None,\n    rng: Optional[np.random.Generator] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing setting.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    capacity : float | None, optional\n        Fixed bin capacity. If ``None`` the maximum remaining capacity among\n        the current bins is used as an estimate.\n    epsilon : float, default 0.05\n        Probability of \u03b5\u2011greedy random exploration. When ``epsilon``>0 the\n        final scores are blended with uniform random scores.\n    noise_scale : float, default 1e-4\n        Uniform noise magnitude added to the raw scores. The noise is\n        damped by ``(1 - fit_ratio)`` so that bins that already fit well\n        are perturbed less.\n    fit_alpha, fit_target : float, default 12.0, 0.80\n        Sigmoid steepness and centre for the *fit\u2011ratio* component\n        (``item / remaining_capacity``).\n    waste_alpha, waste_target : float, default 12.0, 0.07\n        Sigmoid steepness and centre for the *waste* component\n        (``remaining_capacity - item`` normalised by ``capacity``).  Smaller\n        waste is preferred.\n    usage_alpha, usage_target : float, default 10.0, 0.40\n        Sigmoid steepness and centre for the *usage* component\n        (how full the bin already is).\n    weight_fit, weight_waste, weight_usage : float, default 1.0\n        Relative importance of the three components. The weights are\n        normalised internally.\n    temperature : float | None, optional\n        If provided, the final scores are transformed into a probability\n        distribution using a temperature\u2011scaled softmax. ``temperature`` must\n        be positive.\n    rng : np.random.Generator | None, optional\n        Random number generator for reproducibility.  If ``None`` a fresh\n        default generator is created.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Feasible bins receive a finite value\n        (or a probability when ``temperature`` is set); infeasible bins\n        receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # RNG\n    # ------------------------------------------------------------------\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Input validation & conversion\n    # ------------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n    if bins.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a one\u2011dimensional array\")\n    if item <= 0.0:\n        raise ValueError(\"item size must be positive\")\n    if not (0.0 <= epsilon <= 1.0):\n        raise ValueError(\"epsilon must be in [0, 1]\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive when provided\")\n\n    # Early exit for empty input\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Capacity handling\n    # ------------------------------------------------------------------\n    if capacity is None:\n        # Use the maximum remaining capacity seen so far as a proxy.\n        # This works for the classic BPP where all bins have the same\n        # nominal capacity.\n        cap_est = float(bins.max())\n        capacity = cap_est if cap_est > 0.0 else 1.0\n    else:\n        if capacity <= 0.0:\n            raise ValueError(\"capacity must be positive\")\n\n    # ------------------------------------------------------------------\n    # Component 1 \u2013 Fit ratio (item / remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins, dtype=np.float64)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    np.clip(fit_ratio, 0.0, 1.0, out=fit_ratio)\n    # Sigmoid: high score when fit_ratio is close to target (i.e. tight fit)\n    fit_score = 1.0 / (1.0 + np.exp(-fit_alpha * (fit_ratio - fit_target)))\n    fit_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 2 \u2013 Waste (remaining capacity after placement)\n    # ------------------------------------------------------------------\n    waste = bins - item                     # non\u2011negative for feasible bins\n    waste_norm = waste / capacity           # normalised waste \u2208 [0, 1]\n    np.clip(waste_norm, 0.0, 1.0, out=waste_norm)\n    # Prefer small waste: sigmoid decreasing with waste_norm\n    waste_score = 1.0 / (1.0 + np.exp(waste_alpha * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 3 \u2013 Usage (how full the bin already is)\n    # ------------------------------------------------------------------\n    usage_fraction = (capacity - bins) / capacity\n    np.clip(usage_fraction, 0.0, 1.0, out=usage_fraction)\n    usage_score = 1.0 / (1.0 + np.exp(-usage_alpha * (usage_fraction - usage_target)))\n    usage_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Combine components using weighted sum (weights are normalised)\n    # ------------------------------------------------------------------\n    total_weight = weight_fit + weight_waste + weight_usage\n    if total_weight == 0.0:\n        raise ValueError(\"At least one of the component weights must be positive\")\n    w_f = weight_fit / total_weight\n    w_w = weight_waste / total_weight\n    w_u = weight_usage / total_weight\n\n    base_score = w_f * fit_score + w_w * waste_score + w_u * usage_score\n\n    # ------------------------------------------------------------------\n    # Add exploration noise scaled by (1 - fit_ratio)\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=bins.shape)\n        noise = noise * (1.0 - fit_ratio) * feasible   # damp for good fits\n        base_score = base_score + noise\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy mixing: blend with uniform random scores\n    # ------------------------------------------------------------------\n    if epsilon > 0.0:\n        random_scores = rng.random(size=bins.shape)\n        random_scores[~feasible] = 0.0\n        base_score = (1.0 - epsilon) * base_score + epsilon * random_scores\n\n    # ------------------------------------------------------------------\n    # Mark infeasible bins explicitly\n    # ------------------------------------------------------------------\n    priorities = np.full_like(bins, -np.inf, dtype=np.float64)\n    priorities[feasible] = base_score[feasible]\n\n    # ------------------------------------------------------------------\n    # Optional temperature\u2011scaled softmax \u2192 probability distribution\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        # Compute softmax only over feasible bins\n        feasible_scores = priorities[feasible]\n        max_score = feasible_scores.max()\n        exp_vals = np.exp((feasible_scores - max_score) / temperature)\n        probs = exp_vals / exp_vals.sum()\n        # Fill output array\n        priorities = np.full_like(bins, -np.inf, dtype=np.float64)\n        priorities[feasible] = probs\n\n    # ------------------------------------------------------------------\n    # Tiny deterministic tie\u2011breaker (optional but useful)\n    # ------------------------------------------------------------------\n    if priorities.size > 0:\n        priorities = priorities + np.arange(priorities.size, dtype=np.float64) * 1e-12\n\n    return priorities",
    "response_id": 5,
    "obj": 4.028719585161557,
    "SLOC": 84.0,
    "cyclomatic_complexity": 18.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response6.txt_stdout.txt",
    "code_path": "problem_iter10_code6.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    random_state: Optional[int] = None,\n    epsilon_min: float = 0.05,\n    epsilon_max: float = 0.25,\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of currently open bins.\n    random_state : int or None, optional\n        Seed for reproducible random exploration.\n    epsilon_min, epsilon_max : float, optional\n        Minimum and maximum exploration/exploitation mixing factor.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; infeasible bins receive -inf.\n        The bin with the highest score should be chosen for the item.\n    \"\"\"\n    # Convert to a NumPy array of float64 for safe arithmetic.\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Identify bins that can accommodate the item.\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No feasible bin \u2013 return -inf for all entries.\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Remaining capacity after placing the item.\n    leftover = bins_remain_cap - item\n\n    # Base score: tighter fits (smaller leftover) get larger scores.\n    eps = 1e-12  # avoid division by zero.\n    base = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    base[feasible] = 1.0 / (leftover[feasible] + eps)\n\n    # Adaptive epsilon based on variance of leftover space among feasible bins.\n    lo = leftover[feasible]\n    var = np.var(lo, ddof=0)          # variance of leftovers.\n    L = np.max(lo)                   # maximal leftover.\n    if L > 0.0:\n        # Maximum possible variance on [0, L] is (L^2)/4.\n        var_max = (L ** 2) / 4.0\n        var_norm = np.clip(var / var_max, 0.0, 1.0)\n    else:\n        var_norm = 0.0\n\n    # Low variance \u2192 larger epsilon (more exploration), high variance \u2192 smaller epsilon.\n    epsilon = epsilon_min + (epsilon_max - epsilon_min) * (1.0 - var_norm)\n\n    # Random exploration component.\n    rng = np.random.default_rng(random_state)\n    random_score = rng.random(bins_remain_cap.shape)\n\n    # Blend exploitation (tight\u2011fit) and exploration (random).\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    priorities[feasible] = (1.0 - epsilon) * base[feasible] + epsilon * random_score[feasible]\n\n    # Minimal deterministic tie\u2011breaker: a tiny offset based on index.\n    priorities += np.arange(bins_remain_cap.size, dtype=np.float64) * 1e-12\n\n    return priorities",
    "response_id": 6,
    "obj": 3.2708416433984797,
    "SLOC": 31.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response7.txt_stdout.txt",
    "code_path": "problem_iter10_code7.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.75,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.05,\n    alpha_used: float = 8.0,\n    used_target: float = 0.40,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for an online bin\u2011packing decision.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of currently open bins.\n    epsilon : float, optional\n        Probability of performing \u03b5\u2011greedy exploration (choose a random\n        feasible bin). Default is 0.02.\n    noise_scale : float, optional\n        Scale of uniform additive noise to break ties. Default is 1e\u20115.\n    alpha_fit, target_fit : float, optional\n        Logistic steepness and target for the *fit\u2011ratio* component.\n    alpha_waste, waste_target : float, optional\n        Logistic steepness and target for the *waste* component (smaller waste\n        is better).\n    alpha_used, used_target : float, optional\n        Logistic steepness and target for the *used\u2011fraction* component.\n    random_state : int or None, optional\n        Seed for reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        Priority score for each bin (higher = more desirable). Infeasible\n        bins receive ``-np.inf`` so they will never be selected.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Input validation & conversion\n    # ------------------------------------------------------------------\n    if item <= 0:\n        raise ValueError(\"Item size must be positive.\")\n    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n    n_bins = bins.size\n    if n_bins == 0:\n        return np.array([], dtype=np.float64)\n\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # Estimate bin capacity (assume the largest remaining capacity equals the full size)\n    bin_capacity = float(np.max(bins))\n    if bin_capacity <= 0.0:\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng(random_state)\n\n    # ------------------------------------------------------------------\n    # Component 1: Fit\u2011ratio (item / remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins, dtype=np.float64)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n\n    # ------------------------------------------------------------------\n    # Component 2: Waste after placement (normalized)\n    # ------------------------------------------------------------------\n    waste_norm = np.clip((bins - item) / bin_capacity, 0.0, 1.0)\n\n    # ------------------------------------------------------------------\n    # Component 3: Used\u2011fraction after placement (normalized)\n    # ------------------------------------------------------------------\n    used_before = (bin_capacity - bins) / bin_capacity\n    used_after = np.clip(used_before + item / bin_capacity, 0.0, 1.0)\n\n    # ------------------------------------------------------------------\n    # Helper: normalized variance (0\u20111) for a component over feasible bins\n    # ------------------------------------------------------------------\n    def _norm_var(arr: np.ndarray, mask: np.ndarray) -> float:\n        if np.any(mask):\n            var = np.var(arr[mask])\n        else:\n            var = 0.0\n        # Max variance for a [0,1] variable is 0.25\n        return min(var / 0.25, 1.0)\n\n    var_fit = _norm_var(fit_ratio, feasible)\n    var_waste = _norm_var(waste_norm, feasible)\n    var_used = _norm_var(used_after, feasible)\n\n    # ------------------------------------------------------------------\n    # Adjust logistic steepness inversely with variance\n    # ------------------------------------------------------------------\n    adj_alpha_fit = max(alpha_fit * (1.0 - var_fit), 1e-3)\n    adj_alpha_waste = max(alpha_waste * (1.0 - var_waste), 1e-3)\n    adj_alpha_used = max(alpha_used * (1.0 - var_used), 1e-3)\n\n    # ------------------------------------------------------------------\n    # Logistic scoring function\n    # ------------------------------------------------------------------\n    def _logistic(x: np.ndarray, target: float, alpha: float) -> np.ndarray:\n        \"\"\"Standard logistic: 1/(1+exp(-alpha*(x-target))).\"\"\"\n        return 1.0 / (1.0 + np.exp(-alpha * (x - target)))\n\n    # Fit\u2011ratio: higher is better (positive alpha)\n    fit_score = _logistic(fit_ratio, target_fit, adj_alpha_fit)\n\n    # Waste: lower is better \u2192 use negative alpha to flip the curve\n    waste_score = _logistic(waste_norm, waste_target, -adj_alpha_waste)\n\n    # Used\u2011fraction: aim for a moderate fill level\n    used_score = _logistic(used_after, used_target, adj_alpha_used)\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively\n    # ------------------------------------------------------------------\n    combined = fit_score * waste_score * used_score\n\n    # Exact\u2011fit bonus (encourage using up a bin completely)\n    exact_fit = feasible & np.isclose(bins - item, 0.0, 1e-12)\n    combined[exact_fit] += 1e6\n\n    # Infeasible bins get -inf so they are never chosen\n    combined[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Deterministic tie\u2011breaker (tiny index\u2011based offset)\n    # ------------------------------------------------------------------\n    tie_breaker = np.arange(n_bins, dtype=np.float64) * 1e-12\n    combined += tie_breaker\n\n    # ------------------------------------------------------------------\n    # Add small random noise (optional)\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(n_bins) * noise_scale\n        combined[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        rand_scores = np.full_like(combined, -np.inf, dtype=np.float64)\n        rand_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        combined = rand_scores\n\n    return combined",
    "response_id": 7,
    "obj": 4.11846828879138,
    "SLOC": 63.0,
    "cyclomatic_complexity": 8.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response8.txt_stdout.txt",
    "code_path": "problem_iter10_code8.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    # ------------------- optional parameters -------------------\n    capacity: Optional[float] = None,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n    rng: Optional[np.random.Generator] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing\n    setting.\n\n    The function evaluates three sigmoid\u2011scaled features for each feasible\n    bin:\n\n    * **Fit ratio**      \u2013 item / remaining_capacity.\n    * **Waste**          \u2013 (remaining_capacity - item) / capacity.\n    * **Used fraction**  \u2013 (capacity - remaining_capacity) / capacity.\n\n    The three feature scores are multiplied together, optionally perturbed\n    by small noise (damped by (1\u2011fit_ratio)), optionally replaced by a\n    random \u03b5\u2011greedy choice, and finally (if ``temperature`` is given)\n    transformed into a probability distribution via a temperature\u2011scaled\n    softmax.  Infeasible bins receive ``-np.inf``.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    capacity : float | None, optional\n        Fixed bin capacity.  If ``None`` the maximum remaining capacity\n        among the current bins is used as an estimate.\n    epsilon : float, default 0.05\n        Probability of performing \u03b5\u2011greedy random selection among the\n        feasible bins.\n    noise_scale : float, default 1e-4\n        Uniform noise magnitude added to the raw scores.  The noise is\n        damped by ``(1 - fit_ratio)``.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Sigmoid parameters for the *fit\u2011ratio* component.\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Sigmoid parameters for the *waste* component.\n    alpha_used_\u200b, used_target : float, default 10.0, 0.40\n        Sigmoid parameters for the *used\u2011fraction* component.\n    temperature : float | None, optional\n        If provided, the final scores are transformed into a probability\n        distribution using a temperature\u2011scaled softmax.\n    rng : np.random.Generator | None, optional\n        Random number generator for reproducibility.  If ``None`` a new\n        default generator is created.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (or probabilities) for each bin.  Feasible bins\n        have finite values; infeasible bins are marked ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # RNG setup\n    # ------------------------------------------------------------------\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Input validation and conversion\n    # ------------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n    if bins.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a one\u2011dimensional array\")\n    if item <= 0.0:\n        raise ValueError(\"item size must be positive\")\n    if not (0.0.0 <= epsilon <= 1.0):\n        raise ValueError(\"epsilon must be in [0, 1]\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive when provided\")\n\n    n_bins = bins.size\n    if n_bins == 0:\n        return np.array([], dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No feasible bin \u2013 everything is -inf\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Determine bin capacity\n    # ------------------------------------------------------------------\n    if capacity is None:\n        # Use the largest observed remaining capacity as an estimate.\n        cap_est = float(bins.max())\n        capacity = cap_est if cap_est > 0.0 else 1.0\n    else:\n        if capacity <= 0.0:\n            raise ValueError(\"capacity must be positive\")\n\n    # ------------------------------------------------------------------\n    # Helper sigmoid\n    # ------------------------------------------------------------------\n    def _sigmoid(x: np.ndarray) -> np.ndarray:\n        # Numerically stable sigmoid\n        return 1.0 / (1.0 + np.exp(-x))\n\n    # ------------------------------------------------------------------\n    # Component 1 \u2013 Fit ratio (item / remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins, dtype=np.float64)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    np.clip(fit_ratio, 0.0, 1.0, out=fit_ratio)\n    fit_score = _sigmoid(alpha_fit * (fit_ratio - target_fit))\n    fit_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 2 \u2013 Waste after placement, normalised by capacity\n    # ------------------------------------------------------------------\n    waste = bins - item                     # remaining capacity after placement\n    waste_norm = waste / capacity           # normalised waste in [0, 1]\n    np.clip(waste_norm, 0.0, 1.0, out=waste_norm)\n    # Logistic decreasing: small waste => high score\n    waste_score = _sigmoid(-alpha_waste * (waste_norm - waste_target))\n    waste_score[~feasible := feasible] = 0.0  # type: ignore\n\n    # ------------------------------------------------------------------\n    # Component 3 \u2013 Used fraction (how full the bin already is)\n    # ------------------------------------------------------------------\n    used_fraction = (capacity - bins) / capacity\n    np.clip(used_fraction, 0.0, 1.0, out=used_fraction)\n    used_score = _sigmoid(alpha_used * (used_fraction - used_target))\n    used_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively\n    # ------------------------------------------------------------------\n    raw_score = fit_score * waste_score * used_score\n\n    # ------------------------------------------------------------------\n    # Add exploration noise, damped by (1 - fit_ratio)\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=n_bins)\n        # Dampen where fit is already good and only on feasible bins\n        noise *= (1.0 - fit_ratio) * feasible\n        raw_score += noise\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy random exploration\n    # ------------------------------------------------------------------\n    if rng.random() < epsilon:\n        rand_vals = rng.random(size=n_bins)\n        rand_vals[~feasible] = -np.inf  # type: ignore\n        raw_score = rand_vals\n\n    # ------------------------------------------------------------------\n    # Mark infeasible bins explicitly\n    # ------------------------------------------------------------------\n    raw_score[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Optional temperature\u2011scaled softmax \u2192 probability distribution\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        feas_scores = raw_score[feasible]\n        if feas_scores.size == 0:\n            # All infeasible \u2013 keep -inf everywhere\n            return raw_score\n        # Stabilise exponentiation\n        max_score = feas_scores.max()\n        exp_vals = np.exp((feas_scores - max_score) / temperature)\n        probs = exp_vals / exp_vals.sum()\n        out = np.full_like(raw_score, -np.inf, dtype=np.float64)\n        out[feasible] = probs\n        return out\n\n    return raw_score",
    "response_id": 8,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 86\n    if not (0.0.0 <= epsilon <= 1.0):\n            ^^^^^^^^^^^^^^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 86\n    if not (0.0.0 <= epsilon <= 1.0):\n            ^^^^^^^^^^^^^^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 86\n    if not (0.0.0 <= epsilon <= 1.0):\n            ^^^^^^^^^^^^^^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\n"
  },
  {
    "stdout_filepath": "problem_iter10_response9.txt_stdout.txt",
    "code_path": "problem_iter10_code9.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    random_state: Optional[int] = None,\n    epsilon_min: float = 0.05,\n    epsilon_max: float = 0.25,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each bin when packing an online Bin Packing\n    Problem (BPP) item.\n\n    The priority is higher for bins that would leave less leftover space after\n    placing the item (tight\u2011fit). An epsilon\u2011greedy exploration component is\n    adapted based on the normalized variance of the leftover space among\n    feasible bins.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    random_state : int or None, optional\n        Seed for reproducibility of the random exploration component.\n    epsilon_min, epsilon_max : float, optional\n        Minimum and maximum exploration probabilities. The actual epsilon is\n        interpolated based on the normalized variance of leftover space.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin. Infeasible bins (capacity < item) receive\n        ``-np.inf``. The bin with the highest score should be selected for the\n        item.\n    \"\"\"\n    # Ensure we work with a NumPy float64 array.\n    caps = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask: bins that can accommodate the item.\n    feasible = caps >= item\n    if not np.any(feasible):\n        # No bin can hold the item \u2013 all scores are -inf.\n        return np.full_like(caps, -np.inf, dtype=np.float64)\n\n    # Leftover capacity after (hypothetically) placing the item.\n    leftover = caps - item\n\n    # Base exploitation score: tighter fits (smaller leftover) get higher scores.\n    eps = 1e-12  # avoid division by zero.\n    base = np.zeros_like(caps, dtype=np.float64)\n    base[feasible] = 1.0 / (leftover[feasible] + eps)\n\n    # --- Adaptive epsilon based on variance of leftover space ---\n    lo = leftover[feasible]\n    L = np.max(lo) if lo.size > 0 else 0.0\n    var = np.var(lo) if lo.size > 0 else 0.0\n\n    # Normalized variance in [0, 1]; max variance for a uniform distribution on [0, L] is L^2/12,\n    # but a tighter bound L^2/4 is used to keep the scaling simple.\n    var_norm = 0.0\n    if L > 0.0:\n        var_max = (L ** 2) / 4.0\n        var_norm = np.clip(var / var_max, 0.0, 1.0)\n\n    # Higher variance \u2192 higher exploration (epsilon closer to epsilon_max).\n    epsilon = epsilon_min + (epsilon_max - epsilon_min) * var_norm\n\n    # Random exploration component (uniform in [0, 1]).\n    rng = np.random.default_rng(random_state)\n    random_score = rng.random(caps.shape)\n\n    # Combine exploitation and exploration.\n    priorities = np.full_like(caps, -np.inf, dtype=np.float64)\n    priorities[feasible] = (1.0 - epsilon) * base[feasible] + epsilon * random_score[feasible]\n\n    # Deterministic tie\u2011breaker: add a vanishingly small unique offset to each bin.\n    priorities += np.arange(caps.size, dtype=np.float64) * 1e-12\n\n    return priorities",
    "response_id": 9,
    "obj": 4.447546868767465,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  }
]