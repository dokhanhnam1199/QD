```python
import numpy as np

def priority_v2(
    item: float,
    bins_remain_cap: np.ndarray,
    *,
    temperature: float = 1.0,
    alpha: float = 0.5,
    fit_weight: float = 1.0,
    leftover_weight: float = 1.0,
    noise_scale: float = 1e-4,
    epsilon: float = 0.05,
) -> np.ndarray:
    """
    Compute priority scores for the online Bin Packing Problem.

    The score for each *feasible* bin (remaining capacity ≥ item) is a
    linear combination of three intuitive terms:

    * **Leftover capacity** after placement – smaller is better.
    * **Fit ratio** = item / remaining_capacity – larger is better.
    * **Variance penalty** – variance of the capacities after placing the
      item into the candidate bin; lower variance (more balanced) is
      better.

    The raw scores are perturbed with modest uniform noise, optionally
    replaced by an ε‑greedy random distribution, and finally turned into
    a probability distribution using a temperature‑scaled softmax.
    Infeasible bins receive probability 0.

    Parameters
    ----------
    item : float
        Size of the incoming item (must be > 0).
    bins_remain_cap : array_like
        1‑D array with the remaining capacities of the currently open bins.
    temperature : float, default=1.0
        Softmax temperature.  Lower values make the choice more
        deterministic; higher values flatten the distribution.
    alpha : float, default=0.5
        Weight of the variance‑penalty term (larger ⇒ stronger load‑balancing).
    fit_weight : float, default=1.0
        Weight of the fit‑ratio term (larger ⇒ tighter fits are favoured).
    leftover_weight : float, default=1.0
        Weight applied to the leftover capacity term (larger ⇒ tighter
        leftover is more important).
    noise_scale : float, default=1e-4
        Scale of uniform random noise added to raw scores.  Set to 0 to
        disable.
    epsilon : float, default=0.05
        Probability of ε‑greedy exploration: with probability `epsilon`
        a random probability vector over the feasible bins is returned.

    Returns
    -------
    np.ndarray
        Priority probabilities for each bin (sum to 1 over feasible bins).
        Infeasible bins have probability 0.  If no bin can accommodate the
        item, an all‑zero vector is returned.
    """
    # --------------------------------------------------------------------
    # Input validation
    # --------------------------------------------------------------------
    if item <= 0:
        raise ValueError("item size must be positive")
    caps = np.asarray(bins_remain_cap, dtype=float).ravel()
    n_bins = caps.size
    if n_bins == 0:
        return np.array([], dtype=float)
    if temperature <= 0.0:
        raise ValueError("temperature must be positive")

    # --------------------------------------------------------------------
    # Feasibility mask
    # --------------------------------------------------------------------
    feasible = caps >= item

    # If nothing fits, return zero probabilities
    if not np.any(feasible):
        return np.zeros_like(caps, dtype=float)

    # --------------------------------------------------------------------
    # Compute the three base terms
    # --------------------------------------------------------------------
    # 1) Leftover capacity after placement (lower is better)
    leftover = caps - item

    # 2) Fit‑ratio (higher is better)
    fit_ratio = np.empty_like(caps)
    with np.errstate(divide="ignore", invalid="ignore"):
        np.divide(item, caps, out=fit_ratio, where=feasible)
    fit_ratio[~feasible] = 0.0

    # 3) Variance of capacities after placing the item into each bin
    total_sum = caps.sum()
    total_sq_sum = np.square(caps).sum()
    new_sum = total_sum - item                # total capacity after placing
    mean_new = new_sum / n_bins
    # Sum of squares after placing the item into bin i
    sq_sum_after = total_sq_sum - 2.0 * item * caps + item**2
    var_after = sq_sum_after / n_bins - mean_new**2
    var_after[~feasible] = 0.0

    # --------------------------------------------------------------------
    # Linear combination of terms → raw score
    # --------------------------------------------------------------------
    raw_score = (
        -leftover_weight * leftover
        + fit_weight * fit_ratio
        - alpha * var_after
    )
    # Infeasible bins must never win the softmax → -inf
    raw_score[0 if feasible[i] else -np.inf for i in range(n_bins)] = np.where(
        feasible, raw_score, -np.inf
    )
    raw_score[~feasible] = -np.inf

    # --------------------------------------------------------------------
    # Optional modest noise
    # --------------------------------------------------------------------
    if noise_scale > 0.0:
        rng = np.random.default_rng()
        noise = rng.random(n_bins) * noise_scale
        raw_score[feasible] += noise[feasible]

    # --------------------------------------------------------------------
    # ε‑greedy exploration
    # --------------------------------------------------------------------
    rng = np.random.default_rng()
    if epsilon > 0.0 and rng.random() < epsilon:
        probs = np.zeros_like(caps, dtype=float)
        feasible_idx = np.where(feasible)[0]
        if feasible_idx.size > 0:
            rand = rng.random(feasible_idx.size)
            rand /= rand.sum()
            probs[feasible_idx] = rand
        return probs

    # --------------------------------------------------------------------
    # Temperature‑scaled softmax over feasible scores
    # --------------------------------------------------------------------
    max_feas = raw_score[feasible].max()
    scaled = (raw_score - max_feas) / temperature
    exp_scaled = np.exp(scaled)
    exp_scaled[~feasible] = 0.0
    sum_exp = exp_scaled.sum()
    if sum_exp == 0.0:
        # Degenerate case (should not happen unless all feasible scores are -inf)
        return np.zeros_like(caps, dtype=float)
    priorities = exp_scaled / sum_exp
    return priorities
```
