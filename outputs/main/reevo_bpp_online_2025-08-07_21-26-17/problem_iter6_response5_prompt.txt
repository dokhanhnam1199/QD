{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Compute a priority score for each bin in the online Bin Packing Problem.\n\n    The heuristic normalises the leftover capacity after hypothetically placing the\n    item, then feeds this value into a sigmoid that rewards tight fits.  When\n    ``adaptive`` behaviour is enabled (hard\u2011coded to True), the steepness of the\n    sigmoid is scaled by the standard deviation of the normalised leftovers among\n    feasible bins, allowing the method to react to the current distribution of\n    bin utilizations.  A tiny deterministic tie\u2011breaker proportional to the tightness\n    of the fit ensures a unique selection when scores are otherwise equal.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins (non\u2011negative).\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores with the same shape as ``bins_remain_cap``.\n        Infeasible bins (where the item does not fit) receive ``-np.inf``.\n    \"\"\"\n    # Ensure a NumPy array of floats for safe vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute leftover capacity after (hypothetically) placing the item\n    leftover = caps - item\n\n    # Feasibility mask: True where the item fits\n    feasible = leftover >= 0\n\n    # Initialise all priorities to -inf (infeasible)\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return early\n    if not np.any(feasible):\n        return priorities\n\n    # Normalised leftover fraction: 0 \u2192 perfect fit, 1 \u2192 empty bin\n    # Guard division by zero (possible only when caps == 0 and item == 0)\n    norm_leftover = np.empty_like(caps, dtype=float)\n    caps_feas = caps[feasible]\n    leftover_feas = leftover[feasible]\n    with np.errstate(divide='ignore', invalid='ignore'):\n        norm_leftover[feasible] = np.where(\n            caps_feas > 0,\n            leftover_feas / caps_feas,\n            0.0\n        )\n    # Infeasible entries are irrelevant; set to zero for completeness\n    norm_leftover[~feasible] = 0.0\n\n    # Adaptive steepness scaling based on variance of normalised leftovers\n    adaptive = True  # hard\u2011coded as per reflection\n    if adaptive:\n        std = np.std(norm_leftover[feasible])\n        scale = std if std > 1e-12 else 1.0  # avoid division by zero\n    else:\n        scale = 1.0\n\n    # Sigmoid parameters (tuned for typical bin\u2011packing ranges)\n    a = 5.0   # offset \u2013 shifts the curve upward\n    b = 10.0  # base steepness \u2013 larger \u2192 sharper drop for looser fits\n\n    # Logits for the sigmoid: larger when norm_leftover is small (tight fit)\n    logits = a - (b / scale) * norm_leftover[feasible]\n\n    # Numerically stable sigmoid using tanh formulation:\n    # sigmoid(x) = 0.5 * (1 + tanh(x/2))\n    scores = 0.5 * (1.0 + np.tanh(logits / 2.0))\n\n    # Deterministic tie\u2011breaker: favour tighter fits (smaller norm_leftover)\n    eps_tie = 1e-8\n    tie = eps_tie * (1.0 - norm_leftover[feasible])\n\n    # Assign final priority scores to feasible bins\n    priorities[feasible] = scores + tie\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n) -> np.ndarray:\n    \"\"\"\n    Multi\u2011sigmoid priority function for online bin packing.\n\n    For each currently open bin the function returns a priority score that\n    combines three independent sigmoid components:\n\n    * **Fit ratio** \u2013 how close the item size is to the remaining capacity.\n      A ratio above *target_fit* is rewarded.\n    * **Waste** \u2013 the leftover free space after the item is placed.\n      Smaller waste is preferred; waste values below *waste_target* are\n      rewarded strongly.\n    * **Used fraction** \u2013 how much of the bin is already occupied.\n      Partially filled bins are favored, encouraging reuse before opening\n      new bins.\n\n    The three scores are multiplied to form the final priority.  A small\n    uniform noise is added to break ties and an \u03b5\u2011greedy policy can replace\n    the deterministic ranking with a random one with probability *epsilon*.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item \u2264 bin capacity).\n    bins_remain_cap : array_like\n        1\u2011D array of remaining capacities of the currently open bins.\n    epsilon : float, optional\n        Probability of picking a random feasible bin instead of using the\n        computed priorities.\n    noise_scale : float, optional\n        Scale of the additive noise used to break ties.\n    alpha_fit, target_fit, alpha_waste, waste_target,\n    alpha_used, used_target : float, optional\n        Hyper\u2011parameters of the sigmoid transforms.\n    Returns\n    -------\n    np.ndarray\n        Priority scores; higher is better.  Bins that cannot accommodate\n        the item receive ``-np.inf``.\n    \"\"\"\n    # Convert to a NumPy array of float64 for consistency\n    bins = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Handle the empty\u2011bin case immediately\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasibility mask: bins that can hold the item\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No bin can fit the item\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # Estimate the true bin capacity from the largest remaining capacity\n    # observed.  This is robust when we have no explicit capacity value.\n    est_capacity = float(np.max(bins))\n    if est_capacity <= 0:\n        est_capacity = 1.0  # Fallback to avoid division by zero\n\n    # ---------- 1) Fit\u2011ratio component ----------\n    fit_ratio = np.empty_like(bins)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0  # dummy value for infeasible bins\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n\n    # ---------- 2) Waste component ----------\n    waste = bins - item\n    waste_norm = np.clip(waste / est_capacity, 0.0, 1.0)  # Normalised waste [0,1]\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n\n    # ---------- 3) Used\u2011fraction component ----------\n    used_fraction = (est_capacity - bins) / est_capacity\n    used_fraction[~feasible] = 0.0  # dummy for infeasible bins\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n\n    # ---------- Combine signals ----------\n    combined_score = fit_score * waste_score * used_score\n\n    # ---------- Add exploration noise ----------\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.random(bins.shape) * noise_scale\n        combined_score += noise\n\n    # ---------- \u03b5\u2011greedy exploration ----------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_score = rng.random(bins.shape)\n        random_score[~feasible] = -np.inf\n        return random_score\n\n    # Mark infeasible bins explicitly\n    combined_score[~feasible] = -np.inf\n    return combined_score\n\n[Reflection]\nBlend normalized fit, waste, and usage scores; adapt sigmoid steepness; add noise and \u03b5\u2011greedy; deterministic tie\u2011breaking.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}