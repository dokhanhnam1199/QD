{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n) -> np.ndarray:\n    \"\"\"\n    Multi\u2011sigmoid priority function for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacity of each currently open bin.\n    epsilon : float, optional\n        Probability of replacing the deterministic score with a random ranking.\n    noise_scale : float, optional\n        Scale of the additive uniform noise applied before the \u03b5\u2011greedy decision.\n    alpha_fit, target_fit : float, optional\n        Sigmoid parameters for the fit\u2011ratio component.\n    alpha_waste, waste_target : float, optional\n        Sigmoid parameters for the waste component.\n    alpha_used, used_target : float, optional\n        Sigmoid parameters for the used\u2011fraction component.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better) for each bin.  Infeasible\n        bins receive ``-np.inf``.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Empty array handling\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate the true bin capacity from the current open bins\n    est_capacity = float(np.max(bins_remain_cap))\n    if est_capacity <= 0:\n        # All bins are full \u2013 impossible to pack\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng()\n\n    # 1) Fit\u2011ratio component (item size relative to remaining capacity)\n    fit_ratio = np.empty_like(bins_remain_cap, dtype=np.float64)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0  # dummy for infeasible bins\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n\n    # 2) Waste component (leftover capacity after placement)\n    waste_norm = np.clip((bins_remain_cap - item) / est_capacity, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n\n    # 3) Used\u2011fraction component (how much of the bin is already occupied)\n    used_fraction = (est_capacity - bins_remain_cap) / est_capacity\n    # After placement\n    used_fraction_after = np.clip(used_fraction + item / est_capacity, 0.0, 1.0)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction_after - used_target)))\n\n    # Combine the three signals multiplicatively\n    combined_score = fit_score * waste_score * used_score\n    combined_score[~feasible] = -np.inf\n\n    # Add small exploration noise\n    if noise_scale > 0.0:\n        noise = rng.random(bins_remain_cap.shape) * noise_scale\n        combined_score[feasible] += noise[feasible]\n\n    # \u03b5\u2011greedy exploration\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_score = np.where(feasible, rng.random(bins_remain_cap.shape), -np.inf)\n        combined_score = random_score\n\n    return combined_score\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 1.0,\n    alpha: float = 0.5,\n    fit_weight: float = 1.0,\n) -> np.ndarray:\n    \"\"\"\n    Softmax\u2011based priority for online bin packing.\n\n    The score for each *feasible* bin i combines three criteria:\n        \u2022 leftover capacity after placement (smaller is better)\n        \u2022 fit ratio   = item / remaining_capacity (larger is better)\n        \u2022 variance of the remaining capacities after placement\n          (smaller variance promotes load\u2011balancing)\n\n    The raw score for bin i is\n        s_i = - (remaining_i - item)\n              + fit_weight * (item / remaining_i)\n              - alpha * var_i\n\n    where var_i is the variance of the capacities after hypothetically\n    placing the item into bin i.\n\n    The scores are transformed with a temperature\u2011scaled softmax:\n        priority_i = exp((s_i - max(s)) / temperature)\n                     / \u03a3_j exp((s_j - max(s)) / temperature)\n\n    Infeasible bins (remaining capacity < item) receive priority 0.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n    temperature : float, optional\n        Softmax temperature (>0). Small values make the selection\n        more deterministic; larger values yield a flatter distribution.\n    alpha : float, optional\n        Weight of the variance penalty. Larger values favour a more\n        balanced load across bins.\n    fit_weight : float, optional\n        Weight of the fit\u2011ratio term. Larger values give preference to\n        bins that fit the item tightly.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``).\n        The values sum to 1 across feasible bins; infeasible bins have\n        priority 0.\n    \"\"\"\n    # Convert input to a float array and handle empty input\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = bins_remain_cap.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive number\")\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n\n    # If no bin can accommodate the item, return all zeros\n    if not feasible.any():\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    # --- Component 1: leftover capacity after placement ---\n    leftover = bins_remain_cap - item                     # shape (n_bins,)\n\n    # --- Component 2: fit ratio ---\n    # item / capacity; safe because bins_remain_cap > 0 (feasible implies >= item > 0)\n    fit_ratio = np.empty_like(bins_remain_cap)\n    # Avoid division by zero for zero-capacity bins (should be infeasible anyway)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fit_ratio[:] = item / bins_remain_cap\n    fit_ratio[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # --- Component 3: variance after placement ---\n    # Compute total sum and sum of squares once\n    total_sum = bins_remain_cap.sum()\n    total_sq_sum = np.square(bins_remain_cap).sum()\n    new_sum = total_sum - item  # total remaining capacity after placing the item\n\n    # Variance after placing the item into each bin i:\n    # var_i = (total_sq_sum - 2*item*cap_i + item**2) / n_bins - (new_sum / n_bins)**2\n    var_after = (\n        (total_sq_sum - 2.0 * item * bins_remain_cap + item ** 2) / n_bins\n        - (new_sum / n_bins) ** 2\n    )\n    var_after[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # --- Raw score ---\n    # We want high score for good bins, so combine with signs accordingly\n    raw_score = -leftover + fit_weight * fit_ratio - alpha * var_after\n\n    # Infeasible bins should never be selected: assign -inf before softmax\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # --- Softmax transformation ---\n    # Numerical stability: subtract the max of feasible scores\n    max_feas = raw_score[feasible].max()\n    scaled = (raw_score - max_feas) / temperature\n\n    # Exponentiate; exp(-inf) -> 0 automatically\n    exp_scaled = np.exp(scaled)\n\n    # Normalise to obtain probabilities (priorities)\n    total_exp = exp_scaled[feasible].sum()\n    if total_exp == 0.0:\n        # Edge case: all feasible scores were -inf (should not happen)\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    else:\n        priorities = exp_scaled / total_exp\n\n    return priorities\n\n[Reflection]\nBalance leftover, fit ratio, variance; use temperature\u2011scaled softmax; exclude infeasible bins; tune weights; add controlled noise.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}