[
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                *,\n                epsilon: float = 0.05,\n                noise_scale: float = 1e-4,\n                alpha_fit: float = 12.0,\n                target_fit: float = 0.80,\n                alpha_waste: float = 12.0,\n                waste_target: float = 0.07,\n                alpha_used: float = 10.0,\n                used_target: float = 0.40,\n                temperature: float | None = None) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing that combines multiple\n    sigmoid\u2011based criteria, optional noise, \u03b5\u2011greedy exploration and an\n    optional temperature\u2011scaled softmax.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities in the currently open bins.\n    epsilon : float, default 0.05\n        Probability of selecting a completely random feasible bin\n        (\u03b5\u2011greedy exploration).\n    noise_scale : float, default 1e-4\n        Scale of the uniform noise added to the raw scores. The noise\n        magnitude is attenuated by (1\u2011fit_ratio) so that bins that\n        almost perfectly fit the item receive less random perturbation.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Parameters of the sigmoid used to score the fit\u2011ratio\n        (item / remaining_capacity).\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Parameters of the sigmoid used to score the waste\n        (remaining_capacity - item).\n    alpha_used, used_target : float, default 10.0, 0.40\n        Parameters of the sigmoid used to score the used\u2011fraction\n        ((max_capacity - remaining_capacity) / max_capacity).\n    temperature : float or None, default None\n        If provided, the final scores are passed through a\n        temperature\u2011scaled softmax so that they sum to one.\n        If ``None`` the raw scores are returned.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher is better).  Feasible\n        bins receive a value in [0,1] (or a probability when\n        ``temperature`` is set).  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Input validation\n    if bins_remain_cap.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a 1\u2011D array\")\n    if item <= 0:\n        raise ValueError(\"item size must be positive\")\n    if not 0 <= epsilon <= 1:\n        raise ValueError(\"epsilon must be between 0 and 1\")\n    if noise_scale < 0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0:\n        raise ValueError(\"temperature must be positive if provided\")\n\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasible bins mask\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate of the maximum capacity among current bins\n    max_capacity = bins_remain_cap.max()\n\n    # Compute individual components\n    # 1. Fit ratio\n    fit_ratio = np.empty_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio = np.clip(fit_ratio, 0.0, 1.0)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n    fit_score[~feasible] = 0.0\n\n    # 2. Waste component\n    waste = bins_remain_cap - item\n    waste_norm = np.clip(waste / max_capacity, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # 3. Used\u2011fraction component\n    used_fraction = (max_capacity - bins_remain_cap) / max_capacity\n    used_fraction = np.clip(used_fraction, 0.0, 1.0)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n    used_score[~feasible] = 0.0\n\n    # Combined raw priority\n    priorities = fit_score * waste_score * used_score\n\n    # Add random noise to break ties and add exploration\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=priorities.shape)\n        # Dampen noise for bins that already have a good fit\n        noise *= (1.0 - fit_ratio)\n        priorities += noise\n\n    # \u03b5\u2011greedy: with probability epsilon, choose a random feasible bin\n    if rng.random() < epsilon:\n        random_scores = rng.random(size=priorities.shape)\n        random_scores[~feasible] = -np.inf\n        priorities = random_scores\n\n    # Set infeasible bins to -inf\n    priorities[~feasible] = -np.inf\n\n    # Optional temperature\u2011scaled softmax\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            max_score = feasible_scores.max()\n            exp_scores = np.exp((feasible_scores - max_score) / temperature)\n            prob_scores = exp_scores / exp_scores.sum()\n            priorities[feasible] = prob_scores\n\n    return priorities",
    "response_id": 0,
    "obj": 3.9688871160749857,
    "SLOC": 61.0,
    "cyclomatic_complexity": 13.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\n# Minimum and maximum exploration probabilities.\n_EPSILON_MIN = 0.05\n_EPSILON_MAX = 0.25\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for the online Bin Packing Problem.\n\n    A tight\u2011fit score (inverse leftover space) is blended with a random\n    exploration term.  The blending weight (epsilon) adapts to the variance\n    of the leftover space among bins that can accommodate the item:\n    low variance \u21d2 higher epsilon (more exploration), high variance \u21d2 lower\n    epsilon (more exploitation).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = more desirable).  Infeasible bins receive\n        ``-np.inf`` so they are never selected.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    feasible = caps >= item\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Compute leftover capacity if the item were placed.\n    leftover = caps - item\n\n    # Base priority: inverse leftover (tight fits get larger scores).\n    eps = 1e-12  # avoids division by zero.\n    base = np.where(feasible, 1.0 / (leftover + eps), 0.0)\n\n    # --- Adaptive epsilon ----------------------------------------------------\n    # Variance of the leftover among feasible bins.\n    lo = leftover[feasible]\n    var = np.var(lo)\n\n    # Upper bound for variance of a bounded interval [0, L] is L^2 / 4.\n    L = np.max(lo)\n    if L > 0:\n        var_max = (L * L) / 4.0\n        var_norm = np.clip(var / var_max, 0.0, 1.0)\n    else:\n        var_norm = 0.0\n\n    # More variance \u2192 smaller epsilon (more exploitation).\n    epsilon = _EPSILON_MIN + (_EPSILON_MAX - _EPSILON_MIN) * (1.0 - var_norm)\n\n    # --- Exploration component -----------------------------------------------\n    rng = np.random.default_rng()\n    random_score = rng.random(caps.shape)\n\n    # Blend exploitation (tight\u2011fit) and exploration (random).\n    blended = (1.0 - epsilon) * base + epsilon * random_score\n\n    # Infeasible bins get -inf to guarantee they are never chosen.\n    priorities = np.where(feasible, blended, -np.inf)\n    return priorities",
    "response_id": 1,
    "obj": 3.41045073793379,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.75,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.05,\n    alpha_used: float = 8.0,\n    used_target: float = 0.40,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online Bin Packing problem.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining free capacity of each currently open bin.\n    epsilon : float, optional\n        Probability of replacing the deterministic score with a random ranking\n        (\u03b5\u2011greedy exploration). Default 0.02.\n    noise_scale : float, optional\n        Scale of uniform additive noise used to break ties. Default 1e\u20115.\n    alpha_fit, target_fit : float, optional\n        Logistic parameters for the *fit\u2011ratio* component.\n        ``fit_ratio = item / remaining_capacity``.\n        The component is high when the ratio is near ``target_fit``.\n    alpha_waste, waste_target : float, optional\n        Logistic parameters for the *waste* component.\n        ``waste_norm = (remaining_capacity - item) / bin_capacity``.\n        The component is high when waste is below ``waste_target``.\n    alpha_used, used_target : float, optional\n        Logistic parameters for the *used\u2011fraction* component.\n        ``used_after = (capacity - remaining_capacity + item) / capacity``.\n        The component is high when the used fraction after placement is near\n        ``used_target``.\n    random_state : int or None, optional\n        Seed for the internal RNG. Useful for reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = better) for each bin. Infeasible bins receive\n        ``-np.inf`` so they will never be selected by ``np.argmax``.\n    \"\"\"\n    # Ensure a NumPy array of float64\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Edge case: no bins currently open\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2192 all scores -inf\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate the (static) bin capacity \u2013 the largest remaining capacity\n    bin_capacity = float(np.max(bins_remain_cap))\n    if bin_capacity <= 0.0:\n        # Defensive: all bins are full\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng(random_state)\n\n    # ------------------------------------------------------------------\n    # 1) Fit\u2011ratio component (item size relative to remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    # compute only for feasible bins to avoid division by zero\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    # logistic: high when fit_ratio \u2248 target_fit (i.e., fills a good fraction)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n\n    # ------------------------------------------------------------------\n    # 2) Waste component (leftover capacity after placement)\n    # ------------------------------------------------------------------\n    waste_norm = np.clip((bins_remain_cap - item) / bin_capacity, 0.0, 1.0)\n    # logistic decreasing: small waste \u2192 high score\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n\n    # ------------------------------------------------------------------\n    # 3) Used\u2011fraction component (how much of the bin will be occupied)\n    # ------------------------------------------------------------------\n    used_before = (bin_capacity - bins_remain_cap) / bin_capacity\n    used_after = np.clip(used_before + item / bin_capacity, 0.0, 1.0)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_after - used_target)))\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively (stronger signal)\n    # ------------------------------------------------------------------\n    combined_score = fit_score * waste_score * used_score\n\n    # Infeasible bins must be penalised with -inf (they will never be chosen)\n    combined_score[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Small deterministic tie\u2011breaker (bin index)\n    # ------------------------------------------------------------------\n    tie_breaker = np.arange(bins_remain_cap.shape[0], dtype=np.float64) * 1e-12\n    combined_score += tie_breaker\n\n    # ------------------------------------------------------------------\n    # Add exploration noise\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(bins_remain_cap.shape) * noise_scale\n        combined_score[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration: with probability epsilon replace scores by random\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        # Random ranking only for feasible bins\n        random_scores = np.full_like(combined_score, -np.inf, dtype=np.float64)\n        random_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        combined_score = random_scores\n\n    return combined_score",
    "response_id": 2,
    "obj": 4.01874750698045,
    "SLOC": 44.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\n# Exploration vs. exploitation balance (0 = pure greedy, 1 = pure random)\n_EPSILON = 0.15\n\n# Weights for the exploitation component\n_WFIT = 0.7   # Preference for tighter fits (inverse leftover)\n_WUSE = 0.3   # Preference for higher usage ratio\n\n# Global RNG to avoid re\u2011creating it on every call\n_rng = np.random.default_rng()\n\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a simple priority score for each bin in an online Bin Packing\n    problem.\n\n    The score favours bins that fit the item tightly (large inverse leftover)\n    while also rewarding bins that utilise a larger fraction of their remaining\n    capacity (usage ratio). An epsilon\u2011greedy term adds random exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacity of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more desirable). Infeasible\n        bins receive a score of 0.\n    \"\"\"\n    # Ensure a NumPy array of floats.\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Bins that can accommodate the item.\n    can_fit = caps >= item\n    # If no bin can fit, return zeros so the caller can open a new bin.\n    if not np.any(can_fit):\n        return np.zeros_like(caps)\n\n    # Remaining capacity after placing the item.\n    leftover = caps - item\n\n    # --- Exploitation component ------------------------------------------------\n    # Inverse leftover: tighter fits get higher values.\n    inv_leftover = np.where(can_fit, 1.0 / (leftover + 1e-12), 0.0)\n\n    # Usage ratio: fraction of the bin's capacity that will be used.\n    usage_ratio = np.where(can_fit, item / (caps + 1e-12), 0.0)\n\n    # Linear combination of the two exploitation signals.\n    base_priority = _WFIT * inv_leftover + _WUSE * usage_ratio\n\n    # --- Exploration component -------------------------------------------------\n    # Random scores for all bins, masked to keep infeasible bins at zero.\n    random_score = _rng.random(caps.shape)\n    random_score = np.where(can_fit, random_score, 0.0)\n\n    # --- Blend exploitation and exploration ------------------------------------\n    priority = (1.0 - _EPSILON) * base_priority + _EPSILON * random_score\n\n    ----------\n    return priority",
    "response_id": 3,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 66\n    ----------\n              ^\nSyntaxError: invalid syntax\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 66\n    ----------\n              ^\nSyntaxError: invalid syntax\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 66\n    ----------\n              ^\nSyntaxError: invalid syntax\n"
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                *,\n                temperature: float = 1.0,\n                alpha: float = 0.5,\n                fit_weight: float = 1.0,\n                noise_scale: float = 1e-4,\n                epsilon: float = 0.05) -> np.ndarray:\n    \"\"\"\n    Computes a probability distribution over the currently open bins\n    for an incoming item in the online bin\u2011packing problem.\n\n    The score for each *feasible* bin i is a weighted combination of:\n\n    * **Leftover capacity** after placement \u2013 smaller is better\n    * **Fit ratio**   : item / remaining_capacity \u2013 larger is better\n    * **Load\u2011balance penalty** \u2013 the variance of the remaining\n      capacities after placement (smaller variance is better)\n\n    The raw scores are turned into probabilities using a temperature\n   \u2011scaled softmax.  Infeasible bins (remaining capacity < item) receive a\n    score of ``0``.  Optional small noise and \u03b5\u2011greedy exploration can be\n    enabled to avoid deterministic ties.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.  Must be positive.\n    bins_remain_cap : array\u2011like of shape (n_bins,)\n        Remaining capacity of each currently open bin.\n    temperature : float, default=1.0\n        Softmax temperature.  Lower values produce a more deterministic\n        choice; higher values make the distribution flatter.\n    alpha : float, default=0.5\n        Weight of the variance penalty.  Larger values encourage a more\n        balanced load across bins.\n    fit_weight : float, default=1.0\n        Weight of the fit\u2011ratio term.  Larger values favour bins that\n        fit the item more tightly.\n    noise_scale : float, default=1e-4\n        Scale of random noise added to the raw scores before softmax.\n        Set to ``0`` to disable.\n    epsilon : float, default=0.05\n        Probability of selecting a random distribution over the\n        feasible bins (\u03b5\u2011greedy exploration).  Set to ``0`` to\n        disable.\n\n    Returns\n    -------\n    priorities : ndarray of shape (n_bins,)\n        Probabilities for selecting each bin.  Feasible bins sum to\n        ``1``; infeasible bins receive ``0``.  If no bin can accommodate\n        the item, all priorities are zero.\n\n    Notes\n    -----\n    * The function is fully vectorised and performs only a few\n      arithmetic operations per bin.\n    * It assumes that ``bins_remain_cap`` is a one\u2011dimensional\n      array; any shape will be flattened.\n    * The computation of the variance penalty uses the analytic\n      formula for the variance of the remaining capacities after\n      placing the item into each candidate bin.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> bins = np.array([5.0, 3.0, 7.0])  # remaining capacities\n    >>> priority_v2(2.5, bins)\n    array([0.280..., 0.546..., 0.174...])  # example output\n    \"\"\"\n    # Input sanitisation ----------------------------------------------------\n    if item <= 0:\n        raise ValueError(\"item size must be positive\")\n\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = bins_remain_cap.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive number\")\n\n    rng = np.random.default_rng()\n\n    # Feasibility ------------------------------------------------------------\n    feasible = bins_remain_cap >= item\n\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2013 all priorities zero\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Leftover capacity after placement ------------------------------------\n    leftover = bins_remain_cap - item\n\n    # Fit ratio -------------------------------------------------------------\n    fit_ratio = np.empty_like(bins_remain_cap)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # Variance penalty after placement --------------------------------------\n    total_sum = bins_remain_cap.sum()\n    total_sq_sum = np.square(bins_remain_cap).sum()\n    new_sum = total_sum - item\n    mean_new = new_sum / n_bins\n    var_after = (total_sq_sum - 2.0 * item * bins_remain_cap + item**2) / n_bins\n    var_after -= mean_new**2\n    var_after[~feasible] = 0.0  # ignore infeasible bins\n\n    # Raw score: weighted combination --------------------------------------\n    raw_score = -leftover + fit_weight * fit_ratio - alpha * var_after\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # Optional noise --------------------------------------------------------\n    if noise_scale != 0.0:\n        noise = rng.random(bins_remain_cap.shape) * noise_scale\n        raw_score[feasible] += noise[feasible]\n\n    # \u03b5\u2011greedy exploration --------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        idx = np.nonzero(feasible)[0]\n        if idx.size > 0:\n            random_priorities[idx] = rng.random(idx.size)\n            random_priorities[idx] /= random_priorities[idx].sum()\n        return random_priorities\n\n    # Softmax transformation -------------------------------------------------\n    # Numerical stability: subtract max of feasible scores\n    max_feasible = raw_score[feasible].max()\n    scaled = (raw_score - max_feasible) / temperature\n    exp_scaled = np.exp(scaled)\n\n    # Normalise only over feasible bins\n    exp_feasible = exp_scaled[feasible]\n    total_exp = exp_feasible.sum()\n    if total_exp == 0.0:\n        # All feasible scores were -inf \u2013 return zeros\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[feasible] = exp_feasible / total_exp\n    return priorities",
    "response_id": 4,
    "obj": 4.068607897885915,
    "SLOC": 54.0,
    "cyclomatic_complexity": 10.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response5.txt_stdout.txt",
    "code_path": "problem_iter6_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.0,\n    noise_scale: float = 1e-6,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.9,\n    alpha_waste: float = 10.0,\n    waste_target: float = 0.05,\n    alpha_used: float = 8.0,\n    used_target: float = 0.4,\n    tie_eps: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Priority function for the online Bin Packing Problem.\n\n    The score blends three sigmoid\u2011based components:\n      * Fit ratio \u2013 closeness of the item size to the remaining capacity.\n      * Waste \u2013 leftover space after the item would be placed.\n      * Used fraction \u2013 how much of the bin is already occupied.\n\n    The steepness of each sigmoid is scaled adaptively by the standard\n    deviation of the corresponding metric over feasible bins.  A tiny\n    deterministic tie\u2011breaker favours tighter fits, random noise (scaled\n    by ``noise_scale``) breaks exact ties, and an \u03b5\u2011greedy exploration\n    (probability ``epsilon``) can replace the deterministic ranking with a\n    random choice.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    epsilon : float, optional\n        Probability of picking a random feasible bin (exploration).\n    noise_scale : float, optional\n        Scale of uniform additive noise added to the scores.\n    alpha_fit, target_fit, alpha_waste, waste_target,\n    alpha_used, used_target : float, optional\n        Hyper\u2011parameters for the three sigmoid transforms.\n    tie_eps : float, optional\n        Tiny deterministic factor used for tie\u2011breaking.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better). Infeasible bins receive ``-inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Normalise input\n    # ------------------------------------------------------------------\n    caps = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n\n    # Edge case: no open bins\n    if caps.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasibility mask\n    feasible = caps >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item\n        return np.full_like(caps, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Estimate the (unknown) bin capacity.\n    # Use the largest observed remaining capacity, but never smaller than the item.\n    # ------------------------------------------------------------------\n    est_capacity = max(caps.max(), item)\n\n    # ------------------------------------------------------------------\n    # Extract metrics for feasible bins\n    # ------------------------------------------------------------------\n    caps_feas = caps[feasible]                     # remaining capacities where item fits\n    waste = caps_feas - item                        # leftover space after placement\n    waste_norm = waste / est_capacity               # normalised waste in [0,1]\n    fit_ratio = item / caps_feas                    # ratio in (0,1]; 1 = perfect fit\n    used_frac = (est_capacity - caps_feas) / est_capacity  # fraction already occupied\n\n    # ------------------------------------------------------------------\n    # Adaptive sigmoid steepness helpers\n    # ------------------------------------------------------------------\n    def adaptive_scale(metric: np.ndarray) -> float:\n        \"\"\"Return a scale factor based on the metric's std (>=1e-12).\"\"\"\n        if metric.size <= 1:\n            return 1.0\n        std = np.std(metric)\n        return std if std > 1e-12 else 1.0\n\n    # ------------------------------------------------------------------\n    # 1) Fit\u2011ratio component (reward ratios close to 1)\n    # ------------------------------------------------------------------\n    scale_fit = adaptive_scale(fit_ratio)\n    logits_fit = (fit_ratio - target_fit) * (alpha_fit / scale_fit)\n    fit_score = 1.0 / (1.0 + np.exp(-logits_fit))\n\n    # ------------------------------------------------------------------\n    # 2) Waste component (reward small waste)\n    # ------------------------------------------------------------------\n    scale_waste = adaptive_scale(waste_norm)\n    # Negative sign flips the sigmoid to give higher scores for smaller waste\n    logits_waste = -(waste_norm - waste_target) * (alpha_waste / scale_waste)\n    waste_score = 1.0 / (1.0 + np.exp(-logits_waste))\n\n    # ------------------------------------------------------------------\n    # 3) Used\u2011fraction component (reward partially filled bins)\n    # ------------------------------------------------------------------\n    scale_used = adaptive_scale(used_frac)\n    logits_used = (used_frac - used_target) * (alpha_used / scale_used)\n    used_score = 1.0 / (1.0.0 + np.exp(-logits_used))\n\n    # ------------------------------------------------------------------\n    # Combine the three signals multiplicatively\n    # ------------------------------------------------------------------\n    combined = fit_score * waste_score * used_score\n\n    # ------------------------------------------------------------------\n    # Deterministic tie\u2011breaker: favour tighter fits (smaller waste)\n    # ------------------------------------------------------------------\n    combined += tie_eps * (1.0 - waste_norm)\n\n    # ------------------------------------------------------------------\n    # Add small random noise to break exact ties\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        rng = np.random.default_rng()\n        combined += rng.random(combined.shape) * noise_scale\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration: with probability epsilon pick a random feasible bin\n    # ------------------------------------------------------------------\n    if epsilon > 0.0:\n        rng = np.random.default_rng()\n        if rng.random() < epsilon:\n            random_scores = rng.random(caps.shape)\n            random_scores[~feasible] = -np.inf\n            return random_scores\n\n    # ------------------------------------------------------------------\n    # Assemble final scores (infeasible bins get -inf)\n    # ------------------------------------------------------------------\n    scores = np.full_like(caps, -np.inf, dtype=np.float64)\n    scores[feasible] = combined\n    # The above line had a syntax error; fix it:\n    scores[feasible] = combined\n    return scores",
    "response_id": 5,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 113\n    used_score = 1.0 / (1.0.0 + np.exp(-logits_used))\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 113\n    used_score = 1.0 / (1.0.0 + np.exp(-logits_used))\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 113\n    used_score = 1.0 / (1.0.0 + np.exp(-logits_used))\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSyntaxError: invalid syntax. Perhaps you forgot a comma?\n"
  },
  {
    "stdout_filepath": "problem_iter6_response6.txt_stdout.txt",
    "code_path": "problem_iter6_code6.py",
    "code": "import numpy as np\n\n# Hyperparameters\n_BASE_EPSILON = 0.15      # Base exploration weight (0 = pure greedy, 1 = pure random)\n_EXACT_FIT_BONUS = 1e4    # Bonus for bins that become exactly full\n_WASTE_PENALTY = 0.5      # Penalty per unit of leftover capacity\n_LOOKAHEAD_BONUS = 10.0   # Bonus for bins that can still fit another item of the same size\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each bin for online bin packing.\n\n    The priority combines:\n    1. Tight\u2011fit bias: bins that leave less leftover space after placing the item receive a higher base priority.\n    2. Adaptive exploration: the amount of random exploration is scaled by the proportion of bins that can accommodate the item.\n    3. Exact\u2011fit bonus: bins that become exactly full after placement receive a large bonus.\n    4. Waste penalty: bins with a larger remaining capacity after placement are penalized proportionally to the waste.\n    5. Limited lookahead: a small bonus is added to bins that can still accommodate another item of the same size\n       (an approximate lookahead).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining capacity of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; the bin with the highest score will be selected to place the item.\n    \"\"\"\n    # Ensure a NumPy array and compute basic variables\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = caps.size\n    feasible = caps >= item\n\n    # Compute leftover capacity if the item is placed\n    eps = 1e-12\n    leftover = caps - item\n\n    # Base priority: tighter fit => higher priority\n    base_priority = np.full_like(caps, -np.inf, dtype=float)\n    base_priority[feasible] = 1.0 / (leftover[feasible] + eps)\n\n    # Adaptive exploration weight based on the fraction of feasible bins\n    feasible_count = np.count_nonzero(feasible)\n    exploration_weight = min(1.0, _BASE_EPSILON * feasible_count / n_bins) if n_bins > 0 else 0.0\n\n    # Random exploration component\n    rng = np.random.default_rng()\n    random_component = rng.random(n_bins)\n\n    # Blend exploitation and exploration\n    priority = (1.0 - exploration_weight) * base_priority + exploration_weight * random_component\n\n    # Exact\u2011fit bonus\n    exact_fit = feasible & np.isclose(leftover, 0.0, atol=eps)\n    priority[exact_fit] += _EXACT_FIT_BONUS\n\n    # Waste penalty (only for feasible bins)\n    priority[feasible] -= _WASTE_PENALTY * leftover[feasible]\n\n    # Limited lookahead: bonus for bins that can still fit another item of the same size\n    leftover_next = leftover - item  # space after placing another similar item\n    can_fit_next = leftover_next >= 0\n    priority[can_fit_next] += _LOOKAHEAD_BONUS\n\n    # Ensure infeasible bins have very low priority\n    priority[~feasible] = -np.inf\n\n    return priority",
    "response_id": 6,
    "obj": 3.9389708815317115,
    "SLOC": 21.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response7.txt_stdout.txt",
    "code_path": "problem_iter6_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float,\n                bins_remain_cap,\n                *,\n                capacity: float | None = None,\n                epsilon: float = 0.05,\n                noise_scale: float = 1e-4,\n                alpha_fit: float = 12.0,\n                target_fit: float = 0.80,\n                alpha_waste: float = 12.0,\n                waste_target: float = 0.07,\n                alpha_used: float = 10.0,\n                used_target: float = 0.40,\n                weight_fit: float = 1.0,\n                weight_waste: float = 1.0,\n                weight_used: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item \u2264 bin capacity).\n    bins_remain_cap : array_like\n        1\u2011D array of remaining capacities of the currently open bins.\n    capacity : float, optional\n        Explicit bin capacity.  If None, it is estimated from the\n        maximum remaining capacity observed among open bins.\n    epsilon : float, optional\n        Probability of selecting a random feasible bin instead of the\n        deterministic ranking.\n    noise_scale : float, optional\n        Standard deviation of a small uniform noise added to the scores\n        to break ties.\n    alpha_fit, target_fit : float, optional\n        Sigmoid parameters for the *fit ratio* component.\n    alpha_waste, waste_target : float, optional\n        Sigmoid parameters for the *waste* component.\n    alpha_used, used_target : float, optional\n        Sigmoid parameters for the *used\u2011fraction* component.\n    weight_fit, weight_waste, weight_used : float, optional\n        Exponential weights applied to the three components when\n        combining them into the final score.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores; higher is better.  Bins that cannot accommodate\n        the item receive ``-np.inf``.\n    \"\"\"\n    # Ensure numpy array\n    bins = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasible bins: capacity must be >= item and non\u2011negative\n    feasible = (bins >= item) & (bins >= 0.0)\n    if not np.any(feasible):\n        # No bin can fit the item\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # Estimate the bin capacity if not provided\n    if capacity is None:\n        capacity = float(np.max(bins))\n        if capacity <= 0.0:\n            capacity = 1.0  # fallback to avoid division by zero\n\n    # 1) Fit\u2011ratio component\n    fit_ratio = np.zeros_like(bins)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n\n    # 2) Waste component\n    waste = bins - item\n    waste_norm = np.clip(waste / capacity, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n\n    # 3) Used\u2011fraction component\n    used_fraction = (capacity - bins) / capacity\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n\n    # Combine with weighted product\n    combined_score = (fit_score ** weight_fit) * \\\n                     (waste_score ** weight_waste) * \\\n                     (used_score ** weight_used)\n\n    # Add exploration noise\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.random(bins.shape) * noise_scale\n        combined_score += noise\n\n    # \u03b5\u2011greedy exploration\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_score = rng.random(bins.shape)\n        random_score[~feasible] = -np.inf\n        return random_score\n\n    # Mask infeasible bins\n    combined_score[~feasible] = -np.inf\n    return combined_score",
    "response_id": 7,
    "obj": 4.1284403669724865,
    "SLOC": 46.0,
    "cyclomatic_complexity": 8.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response8.txt_stdout.txt",
    "code_path": "problem_iter6_code8.py",
    "code": "import numpy as np\n\n# Global RNG to avoid re\u2011creating it on every call\n_GLOBAL_RNG = np.random.default_rng()\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing setting.\n\n    The score combines three sigmoid\u2011shaped components:\n    * **Fit\u2011ratio** \u2013 how close the item size is to the remaining capacity.\n    * **Waste** \u2013 normalised leftover capacity after placement.\n    * **Used fraction** \u2013 how much of the bin is already occupied.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item \u2264 bin capacity).\n    bins_remain_cap : array_like\n        1\u2011D array with the remaining capacities of currently open bins.\n    epsilon : float, optional\n        Probability of choosing a random feasible bin (\u03b5\u2011greedy exploration).\n    noise_scale : float, optional\n        Uniform noise magnitude added to break ties.\n    alpha_fit, target_fit, alpha_waste, waste_target,\n    alpha_used, used_target : float, optional\n        Hyper\u2011parameters shaping the sigmoid components.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher is better).  Bins that cannot accommodate the\n        item receive ``-np.inf``.\n    \"\"\"\n    # --------------------------------------------------------------\n    # 1. Normalise input & early exits\n    # --------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    if bins.size == 0:\n        # No open bins \u2013 nothing to score\n        return np.empty(0, dtype=np.float64)\n\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No bin can hold the item\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # Estimate true bin capacity from the largest remaining capacity observed.\n    # This avoids a hard\u2011coded capacity and works even if bins are partially filled.\n    est_capacity = float(bins[feasible].max())\n    if est_capacity <= 0.0:\n        # Defensive fallback \u2013 should not happen in well\u2011formed inputs\n        est_capacity = 1.0\n\n    # --------------------------------------------------------------\n    # 2. Compute component scores (vectorised)\n    # --------------------------------------------------------------\n    # Fit\u2011ratio component\n    fit_ratio = np.empty_like item= item, bins=bins\n    fit_ratio = np.empty_like(bins)\n    fit_ratio[feasible] = item / bins[feasible]\n    fit_ratio[~feasible] = 0.0  # dummy, will be masked later\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n\n    # Waste component (normalised leftover space)\n    waste_norm = np.empty_like(bins)\n    waste_norm[feasible] = (bins[feasible] - item) / est_capacity\n    waste_norm[~feasible] = 0.0\n    waste_norm = np.clip(waste_norm, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n\n    # Used\u2011fraction component (how filled the bin already is)\n    used_fraction = (est_capacity - bins) / est_capacity\n    used_fraction[~feasible] = 0.0  # dummy for infeasible bins\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n\n    # --------------------------------------------------------------\n    # 3. Combine components\n    # --------------------------------------------------------------\n    combined = fit_score * waste_score * used_score\n\n    # --------------------------------------------------------------\n    # 4. Add tiny exploration noise (only to feasible bins)\n    # --------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = _GLOBAL_RNG.random(bins.shape) * noise_scale\n        combined[feasible] += noise[feasible]\n\n    # --------------------------------------------------------------\n    # 5. \u03b5\u2011greedy randomisation (limited to feasible bins)\n    # --------------------------------------------------------------\n    if epsilon > 0.0 and _GLOBAL_RNG.random() < epsilon:\n        rand_scores = _GLOBAL_RNG.random(bins.shape)\n        rand_scores[~feasible] = -np.inf\n        return rand_scores\n\n    # --------------------------------------------------------------\n    # 6. Mask infeasible bins and return\n    # --------------------------------------------------------------\n    combined[~feasible] = -np.inf\n    return combined",
    "response_id": 8,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 73\n    fit_ratio = np.empty_like item= item, bins=bins\n                              ^^^^\nSyntaxError: invalid syntax\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 73\n    fit_ratio = np.empty_like item= item, bins=bins\n                              ^^^^\nSyntaxError: invalid syntax\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 73\n    fit_ratio = np.empty_like item= item, bins=bins\n                              ^^^^\nSyntaxError: invalid syntax\n"
  },
  {
    "stdout_filepath": "problem_iter6_response9.txt_stdout.txt",
    "code_path": "problem_iter6_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 1.0,\n    alpha: float = 0.5,\n    fit_weight: float = 1.0\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for bins in an online bin\u2011packing problem.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of existing bins.\n    temperature : float, optional\n        Softmax temperature (>0). Small values make the selection more\n        deterministic; larger values yield a flatter distribution.\n    alpha : float, optional\n        Weight for the variance penalty. Larger values favour a more\n        balanced load across bins.\n    fit_weight : float, optional\n        Weight for the fit\u2011ratio term. Larger values give preference to\n        bins that fit the item tightly.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``).\n        The values sum to 1 across feasible bins; infeasible bins have\n        priority 0.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = bins_remain_cap.size\n\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be positive\")\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n\n    # No feasible bin -> zero priorities\n    if not feasible.any():\n        return np.zeros_like(bins_remain_cap)\n\n    # --- Component 1: leftover after placement ---\n    leftover = bins_remain_cap - item\n\n    # --- Component 2: fit ratio (larger is better) ---\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fit_ratio = np.where(feasible, item / bins_remain_cap, 0.0)\n\n    # --- Component 3: variance after placement ---\n    total_sum = bins_remain_cap.sum()\n    total_sq_sum = np.square(bins_remain_cap).sum()\n    new_sum = total_sum - item  # total remaining capacity after placement\n\n    var_after = (\n        (total_sq_sum - 2.0 * item * bins_remain_cap + item ** 2) / n_bins\n        - (new_sum / n_bins) ** 2\n    )\n    var_after[~feasible] = 0.0\n\n    # --- Raw score: higher is better ---\n    raw = -leftover + fit_weight * fit_ratio - alpha * var_after\n    raw[~feasible] = -np.inf\n\n    # --- Softmax transformation ---\n    max_raw = raw[feasible].max()\n    exp_vals = np.exp((raw - max_raw) / temperature)\n    total_exp = exp_vals[feasible].sum()\n\n    if total_exp == 0.0:\n        # Fallback: uniform distribution over feasible bins\n        probs = np.zeros_like(bins_remain_cap)\n        probs[feasible] = 1.0 / feasible.sum()\n        return probs\n\n    probs = np.where(feasible, exp_vals / total_exp, 0.0)\n\n    return probs",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 39.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\n\n# Global constants (tuned offline)\nCAP = 1.0            # Bin capacity (assumed 1.0 for normalized terms)\nK_BASE = 10.0        # Base steepness for the variance\u2011adapted sigmoid\nVAR_MAX = 0.25       # Max variance for a uniform [0,1] distribution\nEPSILON = 0.01       # Exploration probability for \u03b5\u2011greedy\nHUGE_BONUS = 1e6     # Exact\u2011fit bonus\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority scores for online bin\u2011packing with variance\u2011adapted sigmoids,\n    product scoring, exact\u2011fit bonus, and \u03b5\u2011greedy exploration.\n    Feasible bins receive a finite score; infeasible bins get -inf.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = more desirable).  Infeasible bins receive\n        ``-np.inf`` so they are never selected.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    feasible = caps >= item\n    n_bins = caps.shape[0]\n\n    # Return -inf for all bins if none can accommodate the item\n    if not np.any(feasible):\n        return np.full(n_bins, -np.inf, dtype=float)\n\n    # Remaining capacity after placing the item\n    leftover = caps - item\n\n    # Basic terms (all lie in [0,1] because CAP == 1.0)\n    norm_leftover = np.where(feasible, leftover / CAP, 0.0)\n    fit_ratio    = np.where(feasible, item / CAP, 0.0)\n    usage_after  = np.where(feasible, 1.0 - leftover / CAP, 0.0)\n\n    def sigmoid_term(term_arr: np.ndarray) -> np.ndarray:\n        \"\"\"Variance\u2011adapted sigmoid centered at 0.5.\"\"\"\n        # Compute variance only over feasible bins\n        if np.any(feasible):\n            var = np.var(term_arr[feasible])\n        else:\n            var = 0.0\n        var_norm = min(var / VAR_MAX, 1.0)\n        k = K_BASE * (1.0 - var_norm)  # lower variance \u2192 steeper sigmoid\n        return 1.0 / (1.0 + np.exp(-k * (term_arr - 0.5)))\n\n    # Sigmoid transforms for each term\n    sig_leftover = sigmoid_term(norm_leftover)\n    sig_fit      = sigmoid_term(fit_ratio)\n    sig_usage    = sigmoid_term(usage_after)\n\n    # Product of weighted sigmoid scores (weights are exponents; tuned offline)\n    weighted_score = (sig_leftover ** 1.0) * \\\n                     (sig_fit     ** 1.0) * \\\n                     (sig_usage   ** 1.0)\n\n    # Add a huge bonus for exact\u2011fit placements\n    exact_fit_mask = feasible & np.isclose(leftover, 0.0, atol=1e-9)\n    weighted_score[exact_fit_mask] += HUGE_BONUS\n\n    # \u03b5\u2011greedy exploration: mix with uniform random scores\n    rng = np.random.default_rng()\n    random_score = rng.random(n_bins)\n    final_score = (1.0 - EPSILON) * weighted_score + EPSILON * random_score\n\n    # Ensure infeasible bins are never chosen\n    final_score[~feasible] = -np.inf\n\n    return final_score",
    "response_id": 0,
    "obj": 36.89668927004388,
    "SLOC": 31.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]