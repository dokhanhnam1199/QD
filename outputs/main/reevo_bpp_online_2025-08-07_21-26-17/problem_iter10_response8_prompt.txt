{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    weight_leftover: float = 1.0,\n    weight_fit: float = 1.0,\n    weight_variance: float = 0.5,\n    temperature: float = 0.1,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority (probability) for each currently open bin for an\n    incoming item in the online bin\u2011packing problem.\n\n    The raw score for a feasible bin *i* is a linear combination of three\n    intuitive components:\n\n    * **Leftover capacity** after placement (negative weight; smaller is\n      better).\n    * **Fit ratio** = item / remaining_capacity (positive weight; larger\n      is better).\n    * **Variance penalty** \u2013 variance of the remaining capacities after\n      placement (negative weight; lower variance is better).\n\n    The raw scores are transformed into a probability distribution using\n    a temperature\u2011scaled softmax.  Infeasible bins (remaining capacity <\n    item) receive a priority of ``0``.  Optional \u03b5\u2011greedy exploration and a\n    tiny random noise can be enabled to break ties and encourage\n    exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : array\u2011like of shape (n_bins,)\n        Remaining capacity of each open bin.\n    weight_leftover : float, default=1.0\n        Linear weight for the leftover\u2011capacity term.\n    weight_fit : float, default=1.0\n        Linear weight for the fit\u2011ratio term.\n    weight_variance : float, default=0.5\n        Linear weight for the variance\u2011penalty term.\n    temperature : float, default=0.1\n        Softmax temperature; lower values make the distribution sharper.\n    epsilon : float, default=0.05\n        Probability of performing \u03b5\u2011greedy exploration (choose a random\n        feasible bin).  Set to ``0`` to disable.\n    noise_scale : float, default=1e-4\n        Scale of uniform random noise added to raw scores before the\n        softmax.  Set to ``0`` to disable.\n\n    Returns\n    -------\n    priorities : ndarray of shape (n_bins,)\n        Probability for selecting each bin.  Infeasible bins have priority\n        ``0``.  If no bin can accommodate the item, all priorities are\n        ``0``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Input validation and conversion\n    # ------------------------------------------------------------------\n    if item <= 0:\n        raise ValueError(\"Item size must be positive.\")\n    if temperature <= 0:\n        raise ValueError(\"Temperature must be positive.\")\n    bins = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = bins.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No bin can hold the item \u2013 return zeros\n        return np.zeros_like(bins, dtype=float)\n\n    # ------------------------------------------------------------------\n    # Component calculations (vectorised)\n    # ------------------------------------------------------------------\n    # Leftover capacity after placement\n    leftover = bins - item\n\n    # Fit ratio (item / remaining capacity)\n    fit_ratio = np.empty_like(bins)\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        np.divide(item, bins, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0\n\n    # Variance of remaining capacities after placing the item into each bin\n    total_sum = bins.sum()\n    total_sq = np.square(bins).sum()\n    mean_new = (total_sum - item) / n_bins\n    sq_new = total_sq - 2.0 * item * bins + item ** 2\n    var_after = sq_new / n_bins - mean_new ** 2\n    var_after[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Linear combination \u2192 raw score\n    # ------------------------------------------------------------------\n    raw_score = (\n        -weight_leftover * leftover\n        + weight_fit * fit_ratio\n        - weight_variance * var_after\n    )\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # ------------------------------------------------------------------\n    # Optional exploration noise\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(n_bins) * noise_scale\n        raw_score[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        rand_scores = np.full_like(bins, -np.inf)\n        rand_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        raw_score = rand_scores\n\n    # ------------------------------------------------------------------\n    # Softmax with temperature \u2192 probability distribution\n    # ------------------------------------------------------------------\n    max_feas = raw_score[feasible].max()\n    shifted = (raw_score - max_feas) / temperature\n    exp_vals = np.exp(shifted)\n    exp_vals[~feasible] = 0.0\n    total = exp_vals.sum()\n    if total == 0.0:\n        return np.zeros_like(bins, dtype=float)\n    priorities = exp_vals / total\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    capacity: Optional[float] = None,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n    rng: Optional[np.random.Generator] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing\n    setting.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    capacity : float | None, optional\n        Fixed bin capacity.  If ``None`` the maximum remaining capacity\n        among the current bins is used as an estimate.\n    epsilon : float, default 0.05\n        Probability of performing \u03b5\u2011greedy random selection among the\n        feasible bins.\n    noise_scale : float, default 1e-4\n        Uniform noise magnitude added to the raw scores.  The noise_scale\n        is damped by ``(1 - fit_ratio)`` so that near\u2011perfect fits are\n        perturbed less.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Sigmoid parameters for the *fit\u2011ratio* component\n        (``item / remaining_capacity``).\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Sigmoid parameters for the *waste* component\n        (``remaining_capacity - item`` normalised by ``capacity``).\n    alpha_used, used_target : float, default 10.0, 0.40\n        Sigmoid parameters for the *used\u2011fraction* component\n        (``(capacity - remaining_capacity) / capacity``).\n    temperature : float | None, optional\n        If provided, the final scores are transformed into a probability\n        distribution using a temperature\u2011scaled softmax.\n    rng : np.random.Generator | None, optional\n        Random number generator for reproducibility.  If ``None`` a new\n        default generator is created.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Feasible bins receive a finite\n        value (or a probability when ``temperature`` is set); infeasible\n        bins receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # RNG setup\n    # ------------------------------------------------------------------\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Input handling & validation\n    # ------------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n    if bins.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a one\u2011dimensional array\")\n    if item <= 0.0:\n        raise ValueError(\"item size must be positive\")\n    if not (0.0 <= epsilon <= 1.0):\n        raise ValueError(\"epsilon must be in [0, 1]\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive when provided\")\n\n    # Early exit for an empty bin list\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Feasibility mask\n    # ------------------------------------------------------------------\n    # A bin is feasible if it can accommodate the item.\n    feasible = bins >= item\n    if not np.any(feasible):\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Bin capacity (fixed size) handling\n    # ------------------------------------------------------------------\n    if capacity is None:\n        # Estimate from the largest remaining capacity seen so far.\n        cap_est = float(bins.max())\n        capacity = cap_est if cap_est > 0.0 else 1.0\n    else:\n        if capacity <= 0.0:\n            raise ValueError(\"capacity must be positive\")\n\n    # ------------------------------------------------------------------\n    # Component 1 \u2013 Fit ratio (item / remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins, dtype=np.float64)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    np.clip(fit_ratio, 0.0, 1.0, out=fit_ratio)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n    fit_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 2.0 \u2013 Waste (remaining capacity after placement)\n    # ------------------------------------------------------------------\n    waste = bins - item\n    waste_norm = waste / capacity\n    np.clip(waste_norm, 0.0, 1.0, out=waste_norm)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 3 \u2013 Used fraction (how full the bin already is)\n    # ------------------------------------------------------------------\n    used_fraction = (capacity - bins) / capacity\n    np.clip(used_fraction, 0.0, 1.0, out=used_fraction)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n    used_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Combine the three components multiplicatively\n    # ------------------------------------------------------------------\n    priorities = fit_score * waste_score * used_score\n\n    # ------------------------------------------------------------------\n    # Add exploration noise, damped by (1 - fit_ratio)\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise_scale = float(noise_scale)  # ensure python float for rng\n        noise = rng.uniform(-noise_scale, noise_scale, size=priorities.shape)\n        # Dampen noise for bins that already fit well\n        noise *= (1.0 - fit_ratio) * feasible\n        priorities += noise\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy random exploration\n    # ------------------------------------------------------------------\n    if rng.random() < epsilon:\n        rand_scores = rng.random(size=priorities.shape)\n        rand_scores[~feasible] = -np.inf\n        priorities = rand_scores\n\n    # ------------------------------------------------------------------\n    # Explicitly mark infeasible bins\n    # ------------------------------------------------------------------\n    priorities[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Optional temperature\u2011scaled softmax \u2192 probability distribution\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            # Stabilise exponentiation by subtracting the max\n            max_score = feasible_scores.max()\n            exp_vals = np.exp((feasible_scores - max_score) / temperature)\n            probs = exp_vals / exp_vals.sum()\n            out = np.full_like(priorities, -np.inf, dtype=np.float64)\n            out[feasible] = probs\n            priorities = out\n\n    return priorities\n\n[Reflection]\nScale features sigmoidally, combine multiplicatively, normalize to capacity, damp noise by fit, mark infeasibles \u2013inf, optional softmax.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}