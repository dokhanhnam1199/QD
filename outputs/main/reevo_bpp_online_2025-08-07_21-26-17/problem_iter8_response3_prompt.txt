{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                bins_remain_cap,\n                *,\n                capacity: float | None = None,\n                epsilon: float = 0.05,\n                noise_scale: float = 1e-4,\n                alpha_fit: float = 12.0,\n                target_fit: float = 0.80,\n                alpha_waste: float = 12.0,\n                waste_target: float = 0.07,\n                alpha_used: float = 10.0,\n                used_target: float = 0.40,\n                weight_fit: float = 1.0,\n                weight_waste: float = 1.0,\n                weight_used: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item \u2264 bin capacity).\n    bins_remain_cap : array_like\n        1\u2011D array of remaining capacities of the currently open bins.\n    capacity : float, optional\n        Explicit bin capacity.  If None, it is estimated from the\n        maximum remaining capacity observed among open bins.\n    epsilon : float, optional\n        Probability of selecting a random feasible bin instead of the\n        deterministic ranking.\n    noise_scale : float, optional\n        Standard deviation of a small uniform noise added to the scores\n        to break ties.\n    alpha_fit, target_fit : float, optional\n        Sigmoid parameters for the *fit ratio* component.\n    alpha_waste, waste_target : float, optional\n        Sigmoid parameters for the *waste* component.\n    alpha_used, used_target : float, optional\n        Sigmoid parameters for the *used\u2011fraction* component.\n    weight_fit, weight_waste, weight_used : float, optional\n        Exponential weights applied to the three components when\n        combining them into the final score.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores; higher is better.  Bins that cannot accommodate\n        the item receive ``-np.inf``.\n    \"\"\"\n    # Ensure numpy array\n    bins = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasible bins: capacity must be >= item and non\u2011negative\n    feasible = (bins >= item) & (bins >= 0.0)\n    if not np.any(feasible):\n        # No bin can fit the item\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # Estimate the bin capacity if not provided\n    if capacity is None:\n        capacity = float(np.max(bins))\n        if capacity <= 0.0:\n            capacity = 1.0  # fallback to avoid division by zero\n\n    # 1) Fit\u2011ratio component\n    fit_ratio = np.zeros_like(bins)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n\n    # 2) Waste component\n    waste = bins - item\n    waste_norm = np.clip(waste / capacity, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n\n    # 3) Used\u2011fraction component\n    used_fraction = (capacity - bins) / capacity\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n\n    # Combine with weighted product\n    combined_score = (fit_score ** weight_fit) * \\\n                     (waste_score ** weight_waste) * \\\n                     (used_score ** weight_used)\n\n    # Add exploration noise\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.random(bins.shape) * noise_scale\n        combined_score += noise\n\n    # \u03b5\u2011greedy exploration\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_score = rng.random(bins.shape)\n        random_score[~feasible] = -np.inf\n        return random_score\n\n    # Mask infeasible bins\n    combined_score[~feasible] = -np.inf\n    return combined_score\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n                bins_remain_cap: np.ndarray,\n                *,\n                temperature: float = 1.0,\n                alpha: float = 0.5,\n                fit_weight: float = 1.0,\n                noise_scale: float = 1e-4,\n                epsilon: float = 0.05) -> np.ndarray:\n    \"\"\"\n    Computes a probability distribution over the currently open bins\n    for an incoming item in the online bin\u2011packing problem.\n\n    The score for each *feasible* bin i is a weighted combination of:\n\n    * **Leftover capacity** after placement \u2013 smaller is better\n    * **Fit ratio**   : item / remaining_capacity \u2013 larger is better\n    * **Load\u2011balance penalty** \u2013 the variance of the remaining\n      capacities after placement (smaller variance is better)\n\n    The raw scores are turned into probabilities using a temperature\n   \u2011scaled softmax.  Infeasible bins (remaining capacity < item) receive a\n    score of ``0``.  Optional small noise and \u03b5\u2011greedy exploration can be\n    enabled to avoid deterministic ties.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.  Must be positive.\n    bins_remain_cap : array\u2011like of shape (n_bins,)\n        Remaining capacity of each currently open bin.\n    temperature : float, default=1.0\n        Softmax temperature.  Lower values produce a more deterministic\n        choice; higher values make the distribution flatter.\n    alpha : float, default=0.5\n        Weight of the variance penalty.  Larger values encourage a more\n        balanced load across bins.\n    fit_weight : float, default=1.0\n        Weight of the fit\u2011ratio term.  Larger values favour bins that\n        fit the item more tightly.\n    noise_scale : float, default=1e-4\n        Scale of random noise added to the raw scores before softmax.\n        Set to ``0`` to disable.\n    epsilon : float, default=0.05\n        Probability of selecting a random distribution over the\n        feasible bins (\u03b5\u2011greedy exploration).  Set to ``0`` to\n        disable.\n\n    Returns\n    -------\n    priorities : ndarray of shape (n_bins,)\n        Probabilities for selecting each bin.  Feasible bins sum to\n        ``1``; infeasible bins receive ``0``.  If no bin can accommodate\n        the item, all priorities are zero.\n\n    Notes\n    -----\n    * The function is fully vectorised and performs only a few\n      arithmetic operations per bin.\n    * It assumes that ``bins_remain_cap`` is a one\u2011dimensional\n      array; any shape will be flattened.\n    * The computation of the variance penalty uses the analytic\n      formula for the variance of the remaining capacities after\n      placing the item into each candidate bin.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> bins = np.array([5.0, 3.0, 7.0])  # remaining capacities\n    >>> priority_v2(2.5, bins)\n    array([0.280..., 0.546..., 0.174...])  # example output\n    \"\"\"\n    # Input sanitisation ----------------------------------------------------\n    if item <= 0:\n        raise ValueError(\"item size must be positive\")\n\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = bins_remain_cap.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive number\")\n\n    rng = np.random.default_rng()\n\n    # Feasibility ------------------------------------------------------------\n    feasible = bins_remain_cap >= item\n\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2013 all priorities zero\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Leftover capacity after placement ------------------------------------\n    leftover = bins_remain_cap - item\n\n    # Fit ratio -------------------------------------------------------------\n    fit_ratio = np.empty_like(bins_remain_cap)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # Variance penalty after placement --------------------------------------\n    total_sum = bins_remain_cap.sum()\n    total_sq_sum = np.square(bins_remain_cap).sum()\n    new_sum = total_sum - item\n    mean_new = new_sum / n_bins\n    var_after = (total_sq_sum - 2.0 * item * bins_remain_cap + item**2) / n_bins\n    var_after -= mean_new**2\n    var_after[~feasible] = 0.0  # ignore infeasible bins\n\n    # Raw score: weighted combination --------------------------------------\n    raw_score = -leftover + fit_weight * fit_ratio - alpha * var_after\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # Optional noise --------------------------------------------------------\n    if noise_scale != 0.0:\n        noise = rng.random(bins_remain_cap.shape) * noise_scale\n        raw_score[feasible] += noise[feasible]\n\n    # \u03b5\u2011greedy exploration --------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        idx = np.nonzero(feasible)[0]\n        if idx.size > 0:\n            random_priorities[idx] = rng.random(idx.size)\n            random_priorities[idx] /= random_priorities[idx].sum()\n        return random_priorities\n\n    # Softmax transformation -------------------------------------------------\n    # Numerical stability: subtract max of feasible scores\n    max_feasible = raw_score[feasible].max()\n    scaled = (raw_score - max_feasible) / temperature\n    exp_scaled = np.exp(scaled)\n\n    # Normalise only over feasible bins\n    exp_feasible = exp_scaled[feasible]\n    total_exp = exp_feasible.sum()\n    if total_exp == 0.0:\n        # All feasible scores were -inf \u2013 return zeros\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    priorities[feasible] = exp_feasible / total_exp\n    return priorities\n\n[Reflection]\nCombine leftover, fit\u2011ratio, variance via softmax; linear weighting, fewer sigmoids, stable scaling, simple hyperparameters.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}