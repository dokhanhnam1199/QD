{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.75,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.05,\n    alpha_used: float = 8.0,\n    used_target: float = 0.40,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online Bin Packing problem.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining free capacity of each currently open bin.\n    epsilon : float, optional\n        Probability of replacing the deterministic score with a random ranking\n        (\u03b5\u2011greedy exploration). Default 0.02.\n    noise_scale : float, optional\n        Scale of uniform additive noise used to break ties. Default 1e\u20115.\n    alpha_fit, target_fit : float, optional\n        Logistic parameters for the *fit\u2011ratio* component.\n        ``fit_ratio = item / remaining_capacity``.\n        The component is high when the ratio is near ``target_fit``.\n    alpha_waste, waste_target : float, optional\n        Logistic parameters for the *waste* component.\n        ``waste_norm = (remaining_capacity - item) / bin_capacity``.\n        The component is high when waste is below ``waste_target``.\n    alpha_used, used_target : float, optional\n        Logistic parameters for the *used\u2011fraction* component.\n        ``used_after = (capacity - remaining_capacity + item) / capacity``.\n        The component is high when the used fraction after placement is near\n        ``used_target``.\n    random_state : int or None, optional\n        Seed for the internal RNG. Useful for reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = better) for each bin. Infeasible bins receive\n        ``-np.inf`` so they will never be selected by ``np.argmax``.\n    \"\"\"\n    # Ensure a NumPy array of float64\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Edge case: no bins currently open\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2192 all scores -inf\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate the (static) bin capacity \u2013 the largest remaining capacity\n    bin_capacity = float(np.max(bins_remain_cap))\n    if bin_capacity <= 0.0:\n        # Defensive: all bins are full\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng(random_state)\n\n    # ------------------------------------------------------------------\n    # 1) Fit\u2011ratio component (item size relative to remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    # compute only for feasible bins to avoid division by zero\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    # logistic: high when fit_ratio \u2248 target_fit (i.e., fills a good fraction)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n\n    # ------------------------------------------------------------------\n    # 2) Waste component (leftover capacity after placement)\n    # ------------------------------------------------------------------\n    waste_norm = np.clip((bins_remain_cap - item) / bin_capacity, 0.0, 1.0)\n    # logistic decreasing: small waste \u2192 high score\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n\n    # ------------------------------------------------------------------\n    # 3) Used\u2011fraction component (how much of the bin will be occupied)\n    # ------------------------------------------------------------------\n    used_before = (bin_capacity - bins_remain_cap) / bin_capacity\n    used_after = np.clip(used_before + item / bin_capacity, 0.0, 1.0)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_after - used_target)))\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively (stronger signal)\n    # ------------------------------------------------------------------\n    combined_score = fit_score * waste_score * used_score\n\n    # Infeasible bins must be penalised with -inf (they will never be chosen)\n    combined_score[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Small deterministic tie\u2011breaker (bin index)\n    # ------------------------------------------------------------------\n    tie_breaker = np.arange(bins_remain_cap.shape[0], dtype=np.float64) * 1e-12\n    combined_score += tie_breaker\n\n    # ------------------------------------------------------------------\n    # Add exploration noise\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(bins_remain_cap.shape) * noise_scale\n        combined_score[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration: with probability epsilon replace scores by random\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        # Random ranking only for feasible bins\n        random_scores = np.full_like(combined_score, -np.inf, dtype=np.float64)\n        random_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        combined_score = random_scores\n\n    return combined_score\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Minimum and maximum exploration probabilities.\n_EPSILON_MIN = 0.05\n_EPSILON_MAX = 0.25\n\n    \"\"\"\n    Adaptive priority for the online Bin Packing Problem.\n\n    A tight\u2011fit score (inverse leftover space) is blended with a random\n    exploration term.  The blending weight (epsilon) adapts to the variance\n    of the leftover space among bins that can accommodate the item:\n    low variance \u21d2 higher epsilon (more exploration), high variance \u21d2 lower\n    epsilon (more exploitation).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = more desirable).  Infeasible bins receive\n        ``-np.inf`` so they are never selected.\n    \"\"\"\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    feasible = caps >= item\n    if not np.any(feasible):\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Compute leftover capacity if the item were placed.\n    leftover = caps - item\n\n    # Base priority: inverse leftover (tight fits get larger scores).\n    eps = 1e-12  # avoids division by zero.\n    base = np.where(feasible, 1.0 / (leftover + eps), 0.0)\n\n    # --- Adaptive epsilon ----------------------------------------------------\n    # Variance of the leftover among feasible bins.\n    lo = leftover[feasible]\n    var = np.var(lo)\n\n    # Upper bound for variance of a bounded interval [0, L] is L^2 / 4.\n    L = np.max(lo)\n    if L > 0:\n        var_max = (L * L) / 4.0\n        var_norm = np.clip(var / var_max, 0.0, 1.0)\n    else:\n        var_norm = 0.0\n\n    # More variance \u2192 smaller epsilon (more exploitation).\n    epsilon = _EPSILON_MIN + (_EPSILON_MAX - _EPSILON_MIN) * (1.0 - var_norm)\n\n    # --- Exploration component -----------------------------------------------\n    rng = np.random.default_rng()\n    random_score = rng.random(caps.shape)\n\n    # Blend exploitation (tight\u2011fit) and exploration (random).\n    blended = (1.0 - epsilon) * base + epsilon * random_score\n\n    # Infeasible bins get -inf to guarantee they are never chosen.\n    priorities = np.where(feasible, blended, -np.inf)\n    return priorities\n\n[Reflection]\nUse variance\u2011driven adaptive epsilon, inverse leftover scoring, simple weighting, -inf for infeasibles, avoid heavy logistic combos.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}