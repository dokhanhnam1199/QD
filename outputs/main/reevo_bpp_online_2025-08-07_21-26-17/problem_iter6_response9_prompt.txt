{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Compute priority scores for each bin in an online Bin Packing Problem.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; higher scores indicate more desirable bins.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    leftover = bins_remain_cap - item\n    feasible = leftover >= 0\n\n    # If no bin can accommodate the item, return zeros (caller may open a new bin)\n    if not np.any(feasible):\n        return np.zeros_like(bins_remain_cap)\n\n    # Normalized leftover: fraction of bin remaining after placing the item\n    normalized_leftover = np.where(feasible, leftover / (bins_remain_cap + 1e-12), np.nan)\n\n    # Sigmoid transform with variance\u2011adapted steepness\n    var = np.var(normalized_leftover[feasible]) if np.any(feasible) else 0.0\n    base_steepness = 10.0\n    steepness = base_steepness / (1.0 + var)\n    mu = 0.3  # pivot for the sigmoid\n    sigmoid_score = np.where(\n        feasible,\n        1.0 / (1.0 + np.exp(steepness * (normalized_leftover - mu))),\n        0.0,\n    )\n\n    # Fit score: tighter fits get higher value\n    fit_score = np.where(feasible, 1.0 - normalized_leftover, 0.0)\n\n    # Usage score: fraction of the bin's remaining capacity that will be used\n    usage_score = np.where(\n        feasible, item / (bins_remain_cap + item + 1e-12), 0.0\n    )\n\n    # Combine scores\n    alpha_fit = 0.5\n    alpha_sig = 0.3\n    alpha_use = 0.2\n    raw_score = alpha_fit * fit_score + alpha_sig * sigmoid_score + alpha_use * usage_score\n\n    # Exact\u2011fit bonus\n    exact_fit_bonus = 1e6\n    raw_score = np.where(\n        (feasible) & np.isclose(leftover, 0.0, atol=1e-9),\n        raw_score + exact_fit_bonus,\n        raw_score,\n    )\n\n    # Forecast next item (assume same size as current)\n    next_item_estimate = item\n    forecast_leftover = leftover - next_item_estimate\n    forecast_feasible = forecast_leftover >= 0\n    alpha_forecast = 0.2\n    forecast_score = np.where(\n        forecast_feasible,\n        1.0 - (forecast_leftover / (bins_remain_cap + 1e-12)),\n        0.0,\n    )\n    big_penalty = 1e5\n    raw_score = np.where(\n        feasible,\n        np.where(\n            forecast_feasible,\n            raw_score - alpha_forecast * forecast_score,\n            raw_score - big_penalty,\n        ),\n        raw_score,\n    )\n\n    # Convert raw scores to probabilities via softmax (low temperature)\n    raw_score = np.where(feasible, raw_score, -np.inf)\n    max_raw = np.max(raw_score)\n    # Temperature T\n    T = 0.1\n    exp_shift = np.exp((raw_score - max_raw) / T)\n    sum_exp = np.sum(exp_shift)\n    probs = np.where(sum_exp > 0, exp_shift / sum_exp, np.zeros_like(exp_shift))\n\n    # Tiny deterministic tie\u2011breaker\n    tie_breaker = np.arange(len(bins_remain_cap), dtype=float) * 1e-9\n    probs += tie_breaker\n\n    # \u03b5\u2011greedy component\n    epsilon = 0.15\n    rng = np.random.default_rng()\n    random_component = rng.random(len(bins_remain_cap))\n    # Ensure infeasible bins are not selected via randomness\n    random_component = np.where(feasible, random_component, 0.0)\n\n    final_priority = (1.0 - epsilon) * probs + epsilon * random_component\n\n    return final_priority\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 1.0,\n    alpha: float = 0.5,\n    fit_weight: float = 1.0,\n) -> np.ndarray:\n    \"\"\"\n    Softmax\u2011based priority for online bin packing.\n\n    The score for each *feasible* bin i combines three criteria:\n        \u2022 leftover capacity after placement (smaller is better)\n        \u2022 fit ratio   = item / remaining_capacity (larger is better)\n        \u2022 variance of the remaining capacities after placement\n          (smaller variance promotes load\u2011balancing)\n\n    The raw score for bin i is\n        s_i = - (remaining_i - item)\n              + fit_weight * (item / remaining_i)\n              - alpha * var_i\n\n    where var_i is the variance of the capacities after hypothetically\n    placing the item into bin i.\n\n    The scores are transformed with a temperature\u2011scaled softmax:\n        priority_i = exp((s_i - max(s)) / temperature)\n                     / \u03a3_j exp((s_j - max(s)) / temperature)\n\n    Infeasible bins (remaining capacity < item) receive priority 0.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n    temperature : float, optional\n        Softmax temperature (>0). Small values make the selection\n        more deterministic; larger values yield a flatter distribution.\n    alpha : float, optional\n        Weight of the variance penalty. Larger values favour a more\n        balanced load across bins.\n    fit_weight : float, optional\n        Weight of the fit\u2011ratio term. Larger values give preference to\n        bins that fit the item tightly.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``).\n        The values sum to 1 across feasible bins; infeasible bins have\n        priority 0.\n    \"\"\"\n    # Convert input to a float array and handle empty input\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n    n_bins = bins_remain_cap.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive number\")\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n\n    # If no bin can accommodate the item, return all zeros\n    if not feasible.any():\n        return np.zeros_like(bins_remain_cap, dtype=float)\n\n    # --- Component 1: leftover capacity after placement ---\n    leftover = bins_remain_cap - item                     # shape (n_bins,)\n\n    # --- Component 2: fit ratio ---\n    # item / capacity; safe because bins_remain_cap > 0 (feasible implies >= item > 0)\n    fit_ratio = np.empty_like(bins_remain_cap)\n    # Avoid division by zero for zero-capacity bins (should be infeasible anyway)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        fit_ratio[:] = item / bins_remain_cap\n    fit_ratio[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # --- Component 3: variance after placement ---\n    # Compute total sum and sum of squares once\n    total_sum = bins_remain_cap.sum()\n    total_sq_sum = np.square(bins_remain_cap).sum()\n    new_sum = total_sum - item  # total remaining capacity after placing the item\n\n    # Variance after placing the item into each bin i:\n    # var_i = (total_sq_sum - 2*item*cap_i + item**2) / n_bins - (new_sum / n_bins)**2\n    var_after = (\n        (total_sq_sum - 2.0 * item * bins_remain_cap + item ** 2) / n_bins\n        - (new_sum / n_bins) ** 2\n    )\n    var_after[~feasible] = 0.0  # irrelevant for infeasible bins\n\n    # --- Raw score ---\n    # We want high score for good bins, so combine with signs accordingly\n    raw_score = -leftover + fit_weight * fit_ratio - alpha * var_after\n\n    # Infeasible bins should never be selected: assign -inf before softmax\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # --- Softmax transformation ---\n    # Numerical stability: subtract the max of feasible scores\n    max_feas = raw_score[feasible].max()\n    scaled = (raw_score - max_feas) / temperature\n\n    # Exponentiate; exp(-inf) -> 0 automatically\n    exp_scaled = np.exp(scaled)\n\n    # Normalise to obtain probabilities (priorities)\n    total_exp = exp_scaled[feasible].sum()\n    if total_exp == 0.0:\n        # Edge case: all feasible scores were -inf (should not happen)\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    else:\n        priorities = exp_scaled / total_exp\n\n    return priorities\n\n[Reflection]\nSimplify: combine leftover, fit ratio, variance; linear weighted sum; temperature\u2011scaled softmax; avoid arbitrary bonuses, forecasts, and \u03b5\u2011greedy randomness.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}