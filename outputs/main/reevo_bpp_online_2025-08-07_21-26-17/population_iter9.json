[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 1.0,\n    alpha: float = 0.5,\n    fit_weight: float = 1.0,\n    leftover_weight: float = 1.0,\n    noise_scale: float = 1e-4,\n    epsilon: float = 0.05,\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for the online Bin Packing Problem.\n\n    The score for each *feasible* bin (remaining capacity \u2265 item) is a\n    linear combination of three intuitive terms:\n\n    * **Leftover capacity** after placement \u2013 smaller is better.\n    * **Fit ratio** = item / remaining_capacity \u2013 larger is better.\n    * **Variance penalty** \u2013 variance of the capacities after placing the\n      item into the candidate bin; lower variance (more balanced) is\n      better.\n\n    The raw scores are perturbed with modest uniform noise, optionally\n    replaced by an \u03b5\u2011greedy random distribution, and finally turned into\n    a probability distribution using a temperature\u2011scaled softmax.\n    Infeasible bins receive probability 0.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be > 0).\n    bins_remain_cap : array_like\n        1\u2011D array with the remaining capacities of the currently open bins.\n    temperature : float, default=1.0\n        Softmax temperature.  Lower values make the choice more\n        deterministic; higher values flatten the distribution.\n    alpha : float, default=0.5\n        Weight of the variance\u2011penalty term (larger \u21d2 stronger load\u2011balancing).\n    fit_weight : float, default=1.0\n        Weight of the fit\u2011ratio term (larger \u21d2 tighter fits are favoured).\n    leftover_weight : float, default=1.0\n        Weight applied to the leftover capacity term (larger \u21d2 tighter\n        leftover is more important).\n    noise_scale : float, default=1e-4\n        Scale of uniform random noise added to raw scores.  Set to 0 to\n        disable.\n    epsilon : float, default=0.05\n        Probability of \u03b5\u2011greedy exploration: with probability `epsilon`\n        a random probability vector over the feasible bins is returned.\n\n    Returns\n    -------\n    np.ndarray\n        Priority probabilities for each bin (sum to 1 over feasible bins).\n        Infeasible bins have probability 0.  If no bin can accommodate the\n        item, an all\u2011zero vector is returned.\n    \"\"\"\n    # --------------------------------------------------------------------\n    # Input validation\n    # --------------------------------------------------------------------\n    if item <= 0:\n        raise ValueError(\"item size must be positive\")\n    caps = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = caps.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be positive\")\n\n    # --------------------------------------------------------------------\n    # Feasibility mask\n    # --------------------------------------------------------------------\n    feasible = caps >= item\n\n    # If nothing fits, return zero probabilities\n    if not np.any(feasible):\n        return np.zeros_like(caps, dtype=float)\n\n    # --------------------------------------------------------------------\n    # Compute the three base terms\n    # --------------------------------------------------------------------\n    # 1) Leftover capacity after placement (lower is better)\n    leftover = caps - item\n\n    # 2) Fit\u2011ratio (higher is better)\n    fit_ratio = np.empty_like(caps)\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        np.divide(item, caps, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0\n\n    # 3) Variance of capacities after placing the item into each bin\n    total_sum = caps.sum()\n    total_sq_sum = np.square(caps).sum()\n    new_sum = total_sum - item                # total capacity after placing\n    mean_new = new_sum / n_bins\n    # Sum of squares after placing the item into bin i\n    sq_sum_after = total_sq_sum - 2.0 * item * caps + item**2\n    var_after = sq_sum_after / n_bins - mean_new**2\n    var_after[~feasible] = 0.0\n\n    # --------------------------------------------------------------------\n    # Linear combination of terms \u2192 raw score\n    # --------------------------------------------------------------------\n    raw_score = (\n        -leftover_weight * leftover\n        + fit_weight * fit_ratio\n        - alpha * var_after\n    )\n    # Infeasible bins must never win the softmax \u2192 -inf\n    raw_score[0 if feasible[i] else -np.inf for i in range(n_bins)] = np.where(\n        feasible, raw_score, -np.inf\n    )\n    raw_score[~feasible] = -np.inf\n\n    # --------------------------------------------------------------------\n    # Optional modest noise\n    # --------------------------------------------------------------------\n    if noise_scale > 0.0:\n        rng = np.random.default_rng()\n        noise = rng.random(n_bins) * noise_scale\n        raw_score[feasible] += noise[feasible]\n\n    # --------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration\n    # --------------------------------------------------------------------\n    rng = np.random.default_rng()\n    if epsilon > 0.0 and rng.random() < epsilon:\n        probs = np.zeros_like(caps, dtype=float)\n        feasible_idx = np.where(feasible)[0]\n        if feasible_idx.size > 0:\n            rand = rng.random(feasible_idx.size)\n            rand /= rand.sum()\n            probs[feasible_idx] = rand\n        return probs\n\n    # --------------------------------------------------------------------\n    # Temperature\u2011scaled softmax over feasible scores\n    # --------------------------------------------------------------------\n    max_feas = raw_score[feasible].max()\n    scaled = (raw_score - max_feas) / temperature\n    exp_scaled = np.exp(scaled)\n    exp_scaled[~feasible] = 0.0\n    sum_exp = exp_scaled.sum()\n    if sum_exp == 0.0:\n        # Degenerate case (should not happen unless all feasible scores are -inf)\n        return np.zeros_like(caps, dtype=float)\n    priorities = exp_scaled / sum_exp\n    return priorities",
    "response_id": 0,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 113\n    raw_score[0 if feasible[i] else -np.inf for i in range(n_bins)] = np.where(\n                                            ^^^\nSyntaxError: invalid syntax\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 113\n    raw_score[0 if feasible[i] else -np.inf for i in range(n_bins)] = np.where(\n                                            ^^^\nSyntaxError: invalid syntax\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 113\n    raw_score[0 if feasible[i] else -np.inf for i in range(n_bins)] = np.where(\n                                            ^^^\nSyntaxError: invalid syntax\n"
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n    exact_fit_bonus: float = 1e6\n) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin\u2011packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    epsilon : float, default 0.05\n        Probability of selecting a completely random feasible bin (\u03b5\u2011greedy exploration).\n    noise_scale : float, default 1e-4\n        Scale of the uniform noise added to the raw scores. The noise magnitude\n        is attenuated by (1\u2011fit_ratio) so that bins that almost perfectly fit\n        the item receive less random perturbation.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Parameters of the sigmoid used to score the fit\u2011ratio\n        (item / remaining_capacity).\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Parameters of the sigmoid used to score the waste\n        (remaining_capacity - item).\n    alpha_used, used_target : float, default 10.0, 0.40\n        Parameters of the sigmoid used to score the used\u2011fraction\n        ((max_capacity - remaining_capacity) / max_capacity).\n    temperature : float or None, default None\n        If provided, the final scores are passed through a\n        temperature\u2011scaled softmax so that they sum to one.\n        If ``None`` the raw scores are returned.\n    exact_fit_bonus : float, default 1e6\n        Bonus added to a bin that fits the item exactly (remaining_capacity == item).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher is better).  Feasible\n        bins receive a value in [0,1] (or a probability when\n        ``temperature`` is set).  Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Input validation\n    # ------------------------------------------------------------------\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    if bins_remain_cap.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a 1\u2011D array\")\n    if item <= 0.0:\n        raise ValueError(\"item must be positive\")\n    if not 0.0 <= epsilon <= 1.0:\n        raise ValueError(\"epsilon must be between 0 and 1\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive if provided\")\n\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # 2. Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # 3. Common auxiliary quantities\n    # ------------------------------------------------------------------\n    max_capacity = bins_remain_cap.max()\n    # Avoid division by zero \u2013 but if there is at least one feasible bin,\n    # max_capacity must be > 0 because feasible bins have capacity >= item > 0.\n    if max_capacity <= 0.0:\n        max_capacity = 1.0  # safety, will not be used due to feasibility check\n\n    # --------------------------------------------------------------\n    # Helper: numerically stable logistic\n    # --------------------------------------------------------------\n    def _logistic(z: np.ndarray) -> np.ndarray:\n        \"\"\"1/(1+exp(-z)) with clipping to avoid overflow.\"\"\"\n        z = np.clip(z, -700.0, 700.0)\n        return 1.0 / (1.0 + np.exp(-z))\n\n    # ------------------------------------------------------------------\n    # 4. Component scores\n    # ------------------------------------------------------------------\n    # 4.1 Fit ratio\n    fit_ratio = np.empty_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio = np.clip(fit_ratio, 0.0, 1.0)\n    fit_z = alpha_fit * (fit_ratio - target_fit)\n    fit_score = _logistic(fit_z)\n\n    # 4.2 Waste (remaining capacity after placement)\n    waste = bins_remain_cap - item\n    waste_norm = waste / max_capacity\n    waste_norm = np.clip(waste_norm, 0.0, 1.0)\n    waste_z = -alpha_waste * (waste_norm - waste_target)\n    waste_score = _logistic(waste_z)\n\n    # 4.3 Used fraction\n    used_fraction = (max_capacity - bins_remain_cap) / max_capacity\n    used_fraction = np.clip(used_fraction, 0.0, 1.0)\n    used_z = alpha_used * (used_fraction - used_target)\n    used_score = _logistic(used_z)\n\n    # ------------------------------------------------------------------\n    # 5. Raw priority (product of the three sigmoids)\n    # ------------------------------------------------------------------\n    priorities = fit_score * waste_score * used_score\n    priorities[~feasible] = 0.0  # will be set to -inf later\n\n    # ------------------------------------------------------------------\n    # 6. Add noise proportional to (1 - fit_ratio)\n    # ------------------------------------------------------------------\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=priorities.shape)\n        noise_factor = np.where(feasible, 1.0 - fit_ratio, 0.0)\n        priorities += noise * noise_factor\n\n    # ------------------------------------------------------------------\n    # 7. Bonus for exact fits\n    # ------------------------------------------------------------------\n    exact_fit_mask = feasible & np.isclose(waste, 0.0, atol=1e-9)\n    priorities[exact_fit_mask] += exact_fit_bonus\n\n    # ------------------------------------------------------------------\n    # 8. \u03b5\u2011greedy exploration\n    # ------------------------------------------------------------------\n    if rng.random() < epsilon:\n        priorities = rng.random(size=priorities.shape)\n        priorities[~feasible] = -np.inf\n    else:\n        priorities[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # 9. Optional temperature\u2011scaled softmax\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            max_score = feasible_scores.max()\n            # Stabilize by subtracting max\n            exp_scores = np.exp((feasible_scores - max_score) / temperature)\n            probs = exp_scores / exp_scores.sum()\n            priorities[feasible] = probs\n        # infeasible bins get zero probability\n        priorities[~feasible] = 0.0\n\n    return priorities",
    "response_id": 1,
    "obj": 3.9988033506182825,
    "SLOC": 74.0,
    "cyclomatic_complexity": 14.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    capacity: Optional[float] = None,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n    rng: Optional[np.random.Generator] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing\n    setting.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    capacity : float | None, optional\n        Fixed bin capacity.  If ``None`` the maximum remaining capacity\n        among the current bins is used as an estimate.\n    epsilon : float, default 0.05\n        Probability of performing \u03b5\u2011greedy random selection among the\n        feasible bins.\n    noise_scale : float, default 1e-4\n        Uniform noise magnitude added to the raw scores.  The noise_scale\n        is damped by ``(1 - fit_ratio)`` so that near\u2011perfect fits are\n        perturbed less.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Sigmoid parameters for the *fit\u2011ratio* component\n        (``item / remaining_capacity``).\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Sigmoid parameters for the *waste* component\n        (``remaining_capacity - item`` normalised by ``capacity``).\n    alpha_used, used_target : float, default 10.0, 0.40\n        Sigmoid parameters for the *used\u2011fraction* component\n        (``(capacity - remaining_capacity) / capacity``).\n    temperature : float | None, optional\n        If provided, the final scores are transformed into a probability\n        distribution using a temperature\u2011scaled softmax.\n    rng : np.random.Generator | None, optional\n        Random number generator for reproducibility.  If ``None`` a new\n        default generator is created.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Feasible bins receive a finite\n        value (or a probability when ``temperature`` is set); infeasible\n        bins receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # RNG setup\n    # ------------------------------------------------------------------\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Input handling & validation\n    # ------------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()\n    if bins.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a one\u2011dimensional array\")\n    if item <= 0.0:\n        raise ValueError(\"item size must be positive\")\n    if not (0.0 <= epsilon <= 1.0):\n        raise ValueError(\"epsilon must be in [0, 1]\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive when provided\")\n\n    # Early exit for an empty bin list\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Feasibility mask\n    # ------------------------------------------------------------------\n    # A bin is feasible if it can accommodate the item.\n    feasible = bins >= item\n    if not np.any(feasible):\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # ------------------------------------------------------------------\n    # Bin capacity (fixed size) handling\n    # ------------------------------------------------------------------\n    if capacity is None:\n        # Estimate from the largest remaining capacity seen so far.\n        cap_est = float(bins.max())\n        capacity = cap_est if cap_est > 0.0 else 1.0\n    else:\n        if capacity <= 0.0:\n            raise ValueError(\"capacity must be positive\")\n\n    # ------------------------------------------------------------------\n    # Component 1 \u2013 Fit ratio (item / remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins, dtype=np.float64)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n    np.clip(fit_ratio, 0.0, 1.0, out=fit_ratio)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n    fit_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 2.0 \u2013 Waste (remaining capacity after placement)\n    # ------------------------------------------------------------------\n    waste = bins - item\n    waste_norm = waste / capacity\n    np.clip(waste_norm, 0.0, 1.0, out=waste_norm)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Component 3 \u2013 Used fraction (how full the bin already is)\n    # ------------------------------------------------------------------\n    used_fraction = (capacity - bins) / capacity\n    np.clip(used_fraction, 0.0, 1.0, out=used_fraction)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n    used_score[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Combine the three components multiplicatively\n    # ------------------------------------------------------------------\n    priorities = fit_score * waste_score * used_score\n\n    # ------------------------------------------------------------------\n    # Add exploration noise, damped by (1 - fit_ratio)\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise_scale = float(noise_scale)  # ensure python float for rng\n        noise = rng.uniform(-noise_scale, noise_scale, size=priorities.shape)\n        # Dampen noise for bins that already fit well\n        noise *= (1.0 - fit_ratio) * feasible\n        priorities += noise\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy random exploration\n    # ------------------------------------------------------------------\n    if rng.random() < epsilon:\n        rand_scores = rng.random(size=priorities.shape)\n        rand_scores[~feasible] = -np.inf\n        priorities = rand_scores\n\n    # ------------------------------------------------------------------\n    # Explicitly mark infeasible bins\n    # ------------------------------------------------------------------\n    priorities[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Optional temperature\u2011scaled softmax \u2192 probability distribution\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        feasible_scores = priorities[feasible]\n        if feasible_scores.size > 0:\n            # Stabilise exponentiation by subtracting the max\n            max_score = feasible_scores.max()\n            exp_vals = np.exp((feasible_scores - max_score) / temperature)\n            probs = exp_vals / exp_vals.sum()\n            out = np.full_like(priorities, -np.inf, dtype=np.float64)\n            out[feasible] = probs\n            priorities = out\n\n    return priorities",
    "response_id": 2,
    "obj": 4.078579976067022,
    "SLOC": 75.0,
    "cyclomatic_complexity": 17.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    weight_leftover: float = 1.0,\n    weight_fit: float = 1.0,\n    weight_variance: float = 0.5,\n    temperature: float = 0.1,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority (probability) for each currently open bin for an\n    incoming item in the online bin\u2011packing problem.\n\n    The raw score for a feasible bin *i* is a linear combination of three\n    intuitive components:\n\n    * **Leftover capacity** after placement (negative weight; smaller is\n      better).\n    * **Fit ratio** = item / remaining_capacity (positive weight; larger\n      is better).\n    * **Variance penalty** \u2013 variance of the remaining capacities after\n      placement (negative weight; lower variance is better).\n\n    The raw scores are transformed into a probability distribution using\n    a temperature\u2011scaled softmax.  Infeasible bins (remaining capacity <\n    item) receive a priority of ``0``.  Optional \u03b5\u2011greedy exploration and a\n    tiny random noise can be enabled to break ties and encourage\n    exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (must be positive).\n    bins_remain_cap : array\u2011like of shape (n_bins,)\n        Remaining capacity of each open bin.\n    weight_leftover : float, default=1.0\n        Linear weight for the leftover\u2011capacity term.\n    weight_fit : float, default=1.0\n        Linear weight for the fit\u2011ratio term.\n    weight_variance : float, default=0.5\n        Linear weight for the variance\u2011penalty term.\n    temperature : float, default=0.1\n        Softmax temperature; lower values make the distribution sharper.\n    epsilon : float, default=0.05\n        Probability of performing \u03b5\u2011greedy exploration (choose a random\n        feasible bin).  Set to ``0`` to disable.\n    noise_scale : float, default=1e-4\n        Scale of uniform random noise added to raw scores before the\n        softmax.  Set to ``0`` to disable.\n\n    Returns\n    -------\n    priorities : ndarray of shape (n_bins,)\n        Probability for selecting each bin.  Infeasible bins have priority\n        ``0``.  If no bin can accommodate the item, all priorities are\n        ``0``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Input validation and conversion\n    # ------------------------------------------------------------------\n    if item <= 0:\n        raise ValueError(\"Item size must be positive.\")\n    if temperature <= 0:\n        raise ValueError(\"Temperature must be positive.\")\n    bins = np.asarray(bins_remain_cap, dtype=float).ravel()\n    n_bins = bins.size\n    if n_bins == 0:\n        return np.array([], dtype=float)\n\n    rng = np.random.default_rng()\n\n    # ------------------------------------------------------------------\n    # Feasibility mask\n    # ------------------------------------------------------------------\n    feasible = bins >= item\n    if not np.any(feasible):\n        # No bin can hold the item \u2013 return zeros\n        return np.zeros_like(bins, dtype=float)\n\n    # ------------------------------------------------------------------\n    # Component calculations (vectorised)\n    # ------------------------------------------------------------------\n    # Leftover capacity after placement\n    leftover = bins - item\n\n    # Fit ratio (item / remaining capacity)\n    fit_ratio = np.empty_like(bins)\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        np.divide(item, bins, out=fit_ratio, where=feasible)\n    fit_ratio[~feasible] = 0.0\n\n    # Variance of remaining capacities after placing the item into each bin\n    total_sum = bins.sum()\n    total_sq = np.square(bins).sum()\n    mean_new = (total_sum - item) / n_bins\n    sq_new = total_sq - 2.0 * item * bins + item ** 2\n    var_after = sq_new / n_bins - mean_new ** 2\n    var_after[~feasible] = 0.0\n\n    # ------------------------------------------------------------------\n    # Linear combination \u2192 raw score\n    # ------------------------------------------------------------------\n    raw_score = (\n        -weight_leftover * leftover\n        + weight_fit * fit_ratio\n        - weight_variance * var_after\n    )\n    raw_score = np.where(feasible, raw_score, -np.inf)\n\n    # ------------------------------------------------------------------\n    # Optional exploration noise\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(n_bins) * noise_scale\n        raw_score[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        rand_scores = np.full_like(bins, -np.inf)\n        rand_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        raw_score = rand_scores\n\n    # ------------------------------------------------------------------\n    # Softmax with temperature \u2192 probability distribution\n    # ------------------------------------------------------------------\n    max_feas = raw_score[feasible].max()\n    shifted = (raw_score - max_feas) / temperature\n    exp_vals = np.exp(shifted)\n    exp_vals[~feasible] = 0.0\n    total = exp_vals.sum()\n    if total == 0.0:\n        return np.zeros_like(bins, dtype=float)\n    priorities = exp_vals / total\n    return priorities",
    "response_id": 3,
    "obj": 4.2181890706023095,
    "SLOC": 56.0,
    "cyclomatic_complexity": 9.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    capacity: float | None = None,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-6,\n    base_k_fit: float = 12.0,\n    base_k_waste: float = 12.0,\n    base_k_used: float = 10.0,\n    var_max: float = 0.25,\n    target_fit: float = 0.80,\n    waste_target: float = 0.07,\n    used_target: float = 0.40,\n    weight_fit: float = 1.0,\n    weight_waste: float = 1.0,\n    weight_used: float = 1.0,\n    exact_fit_bonus: float = 1e6,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online bin\u2011packing\n    setting. Higher scores indicate more desirable bins for placing the\n    incoming ``item``. Infeasible bins receive ``-np.inf`` so they are\n    never selected.\n\n    The function combines three sigmoid\u2011based components:\n    * fit\u2011ratio (item / bin capacity),\n    * waste (remaining capacity after placement),\n    * used\u2011fraction (how full the bin already is).\n\n    The steepness of each sigmoid is adapted to the variance of the\n    underlying component over the feasible bins, providing more decisive\n    preferences when the data is concentrated.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (0 < item \u2264 bin capacity).\n    bins_remain_cap : array_like\n        Remaining capacities of the currently open bins.\n    capacity : float, optional\n        Bin capacity. If ``None`` it is inferred as the maximum observed\n        remaining capacity.\n    epsilon : float, optional\n        Probability of performing pure exploration (random feasible bin).\n    noise_scale : float, optional\n        Scale of a small Gaussian perturbation added to break ties.\n    base_k_fit, base_k_waste, base_k_used : float, optional\n        Base steepness for the three sigmoid components.\n    var_max : float, optional\n        Maximum variance used for normalising the adaptive steepness.\n    target_fit, waste_target, used_target : float, optional\n        Target values for the three components; the sigmoid is centred\n        around each target.\n    weight_fit, weight_waste, weight_used : float, optional\n        Exponential weights applied to each component when combining them.\n    exact_fit_bonus : float, optional\n        Large additive bonus for bins that fit the item exactly.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = more desirable). Infeasible bins are\n        marked with ``-np.inf``.\n    \"\"\"\n    # ----------------------------------------------------------------------\n    # Normalise inputs\n    # ----------------------------------------------------------------------\n    bins = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    if bins.size == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasibility mask\n    feasible = (bins >= item) & (bins >= 0.0)\n\n    # Early exit if nothing fits\n    if not np.any(feasible):\n        return np.full_like(bins, -np.inf, dtype=np.float64)\n\n    # Estimate capacity if not provided\n    if capacity is None:\n        capacity = float(np.max(bins))\n        if capacity <= 0.0:\n            capacity = 1.0  # fallback to avoid division by zero\n\n    # ----------------------------------------------------------------------\n    # Component 1: Fit ratio (item / bin_capacity)\n    # ----------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins)\n    np.divide(item, bins, out=fit_ratio, where=feasible)\n\n    var_fit = np.var(fit_ratio[feasible]) if np.any(feasible) else 0.0\n    k_fit = base_k_fit * (1.0 - min(var_fit / var_max, 1.0))\n    k_fit = max(k_fit, 1e-3)  # avoid zero steepness\n\n    fit_score = 1.0 / (1.0 + np.exp(-k_fit * (fit_ratio - target_fit)))\n\n    # ----------------------------------------------------------------------\n    # Component 2: Waste (leftover capacity after placement)\n    # ----------------------------------------------------------------------\n    leftover = bins - item\n    waste_norm = np.clip(leftover / capacity, 0.0, 1.0)\n\n    var_waste = np.var(waste_norm[feasible]) if np.any(feasible) else 0.0\n    k_waste = base_k_waste * (1.0 - min(var_waste / var_max, 1.0))\n    k_waste = max(k_waste, 1e-3)\n\n    # Want low waste; sigmoid decreasing with waste\n    waste_score = 1.0 / (1.0 + np.exp(k_waste * (waste_norm - waste_target)))\n\n    # ----------------------------------------------------------------------\n    # Component 3: Used fraction (how full the bin already is)\n    # ----------------------------------------------------------------------\n    used_frac = (capacity - bins) / capacity\n\n    var_used = np.var(used_frac[feasible]) if np.any(feasible) else 0.0\n    k_used = base_k_used * (1.0 - min(var_used / var_max, 1.0))\n    k_used = max(k_used, 1e-3)\n\n    used_score = 1.0 / (1.0 + np.exp(-k_used * (used_frac - used_target)))\n\n    # ----------------------------------------------------------------------\n    # Combine components\n    # ----------------------------------------------------------------------\n    combined = (fit_score ** weight_fit) * \\\n               (waste_score ** weight_waste) * \\\n               (used_score ** weight_used)\n\n    # Exact\u2011fit bonus\n    exact_fit = feasible & np.isclose(leftover, 0.0, atol=1e-9)\n    combined[exact_fit] += exact_fit_bonus\n\n    # Small Gaussian noise for tie\u2011breaking\n    if noise_scale > 0.0:\n        rng = np.random.default_rng()\n        combined += rng.normal(scale=noise_scale, size=combined.shape)\n\n    # ----------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration\n    # ----------------------------------------------------------------------\n    if epsilon > 0.0:\n        rng = np.random.default_rng()\n        if rng.random() < epsilon:\n            rand_scores = rng.random(bins.shape)\n            rand_scores[~feasible] = -np.inf\n            return rand_scores\n\n    # Mask infeasible bins\n    combined[~feasible] = -np.inf\n\n    return combined",
    "response_id": 4,
    "obj": 4.148384523334677,
    "SLOC": 62.0,
    "cyclomatic_complexity": 11.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\nfrom typing import Optional\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.05,\n    noise_scale: float = 1e-4,\n    alpha_fit: float = 12.0,\n    target_fit: float = 0.80,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.07,\n    alpha_used: float = 10.0,\n    used_target: float = 0.40,\n    temperature: Optional[float] = None,\n) -> np.ndarray:\n    \"\"\"\n    Priority function for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item (assumed positive).\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    epsilon : float, default 0.05\n        Mixing weight for \u03b5\u2011greedy exploration (0 \u2192 deterministic,\n        1 \u2192 pure random).\n    noise_scale : float, default 1e-4\n        Amplitude of uniform noise added to raw scores.\n    alpha_fit, target_fit : float, default 12.0, 0.80\n        Sigmoid steepness and target for the fit\u2011ratio\n        (item / remaining_capacity).\n    alpha_waste, waste_target : float, default 12.0, 0.07\n        Sigmoid steepness and target for the waste\n        ((remaining_capacity - item) / max_capacity).\n    alpha_used, used_target : float, default 10.0, 0.40\n        Sigmoid steepness and target for the used\u2011fraction\n        ((max_capacity - remaining_capacity) / max_capacity).\n    temperature : float | None, default None\n        If provided, applies a temperature\u2011scaled softmax to the\n        feasible scores, turning them into a probability distribution.\n        ``temperature`` must be positive.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher = more desirable).  Infeasible\n        bins receive ``-np.inf``.  If ``temperature`` is set, feasible scores\n        sum to one.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Input validation and preprocessing\n    # ------------------------------------------------------------------\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n    if bins_remain_cap.ndim != 1:\n        raise ValueError(\"bins_remain_cap must be a 1\u2011D array\")\n    if item <= 0:\n        raise ValueError(\"item size must be positive\")\n    if not (0.0 <= epsilon <= 1.0):\n        raise ValueError(\"epsilon must be in the interval [0, 1]\")\n    if noise_scale < 0.0:\n        raise ValueError(\"noise_scale must be non\u2011negative\")\n    if temperature is not None and temperature <= 0.0:\n        raise ValueError(\"temperature must be positive when provided\")\n\n    n_bins = bins_remain_cap.shape[0]\n    if n_bins == 0:\n        return np.array([], dtype=np.float64)\n\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No bin can accommodate the item\n        return np.full(n_bins, -np.inf, dtype=np.float64)\n\n    # Estimate the (normalized) bin capacity \u2013 assuming all bins share the same max.\n    max_capacity = bins_remain_cap.max()\n\n    # ------------------------------------------------------------------\n    # 2. Component scores (sigmoid\u2011based)\n    # ------------------------------------------------------------------\n    # Fit ratio: item size relative to remaining capacity\n    fit_ratio = np.zeros_like(bins_remain_cap)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n    fit_ratio = np.clip(fit_ratio, 0.0, 1.0)\n    fit_score = 1.0 / (1.0 + np.exp(-alpha_fit * (fit_ratio - target_fit)))\n    fit_score[~feasible] = 0.0\n\n    # Waste: remaining space after placing the item\n    waste = bins_remain_cap - item\n    waste_norm = np.clip(waste / max_capacity, 0.0, 1.0)\n    waste_score = 1.0 / (1.0 + np.exp(alpha_waste * (waste_norm - waste_target)))\n    waste_score[~feasible] = 0.0\n\n    # Used fraction: how much of the bin is already filled\n    used_fraction = (max_capacity - bins_remain_cap) / max_capacity\n    used_fraction = np.clip(used_capacity if (used_capacity := used_fraction) else used_fraction, 0.0, 1.0)\n    used_score = 1.0 / (1.0 + np.exp(-alpha_used * (used_fraction - used_target)))\n    used_score[~feasible] = 0.0\n\n    # Combined raw priority (product of components)\n    raw_priority = fit_score * waste_score * used_score\n\n    # Small exact\u2011fit bump (moderate, not huge)\n    exact_fit_mask = feasible & np.isclose(waste, 0.0, atol=1e-9)\n    raw_priority[exact_fit_mask] += 1e-3\n\n    # ------------------------------------------------------------------\n    # 3. Add stochastic perturbations\n    # ------------------------------------------------------------------\n    rng = np.random.default_rng()\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=n_bins)\n        # Dampen noise for bins already scoring high on fit\n        noise *= (1.0 - fit_score)\n        raw_priority += noise\n\n    # \u03b5\u2011greedy mixing: blend raw scores with uniform random scores\n    if epsilon > 0.0:\n        random_scores = rng.random(size=n_bins)  # uniform [0,1)\n        combined = (1.0 - epsilon) * raw_priority + epsilon * random_scores\n    else:\n        combined = raw_priority\n\n    # Infeasible bins must never be selected\n    combined[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # 4. Optional temperature\u2011scaled softmax\n    # ------------------------------------------------------------------\n    if temperature is not None:\n        feasible_scores = combined[feasible]\n        if feasible_scores.size > 0:\n            max_score = feasible_scores.max()\n            exp_vals = np.exp((feasible_scores - max_score) / temperature)\n            probs = exp_vals / exp_vals.sum()\n            combined[feasible] = probs\n        else:\n            combined[feasible] = -np.inf\n\n    return combined",
    "response_id": 5,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 99, in priority_v2\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n69\n14\n"
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for the online Bin Packing Problem.\n\n    Uses an inverse-leftover (tight\u2011fit) score blended with random exploration.\n    The exploration weight \u03b5 adapts to the variance of leftover capacities\n    among feasible bins.  An exact\u2011fit bonus is added for zero leftover.\n    \"\"\"\n    # Constants\n    EPSILON_MIN = 0.05\n    EPSILON_MAX = 0.25\n    HUGE_BONUS = 1e6\n    eps = 1e-12  # avoid division by zero\n\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    feasible = caps >= item\n\n    # No feasible bin\n    if not np.any(feasible):\n        return np.full(caps.shape, -np.inf, dtype=float)\n\n    # Remaining capacity if the item is placed\n    leftover = caps - item\n\n    # Base priority: inverse leftover (tight fits get larger scores)\n    base = np.where(feasible, 1.0 / (leftover + eps), 0.0)\n\n    # Adaptive \u03b5 based on leftover variance among feasible bins\n    lo = leftover[feasible]\n    var = np.var(lo)\n    L = np.max(lo)\n    var_max = (L * L) / 4.0 if L > 0 else 0.0\n    var_norm = var / var_max if var_max > 0 else 0.0\n    var_norm = np.clip(var_norm, 0.0, 1.0)\n    epsilon = EPSILON_MIN + (EPSILON_MAX - EPSILON_MIN) * (1.0 - var_norm)\n\n    # Random exploration component\n    rng = np.random.default_rng()\n    random_score = rng.random(caps.shape)\n\n    # Blend exploitation (tight\u2011fit) and exploration (random)\n    blended = (1.0 - epsilon) * base + epsilon * random_score\n\n    # Add exact\u2011fit bonus\n    exact_fit_mask = feasible & np.isclose(leftover, 0.0, atol=1e-9)\n    blended[exact_fit_mask] += HUGE_BONUS\n\n    # Infeasible bins should never be chosen\n    priorities = np.where(feasible, blended, -np.inf)\n    return priorities",
    "response_id": 6,
    "obj": 3.280813721579586,
    "SLOC": 25.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.75,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.05,\n    tie_breaker_scale: float = 1e-12,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority score for each open bin in an online Bin Packing problem.\n\n    The score is higher for bins that:\n      * fit the item well (fit ratio near ``target_fit``),\n      * leave little waste after placement (waste below ``waste_target``),\n      * break ties deterministically by bin index,\n      * optionally explore via random noise or \u03b5\u2011greedy exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining free capacity of each currently open bin.\n    epsilon : float, default 0.02\n        Probability of replacing the deterministic scores with random scores\n        (\u03b5\u2011greedy exploration).\n    noise_scale : float, default 1e-5\n        Scale of uniform additive noise added to each feasible bin's score.\n    alpha_fit : float, default 10.0\n        Logistic steepness for the *fit\u2011ratio* component.\n    target_fit : float, default 0.75\n        Desired fit ratio (item / remaining capacity) where the fit component\n        reaches 0.5.\n    alpha_waste : float, default 12.0\n        Logistic steepness for the *waste* component.\n    waste_target : float, default 0.05\n        Desired waste fraction (relative to bin capacity) where the waste\n        component reaches 0.5.\n    tie_breaker_scale : float, default 1e-12\n        Small multiplier for bin index to break exact ties deterministically.\n    random_state : int or None, default None\n        Seed for the internal RNG (useful for reproducibility).\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = better) for each bin. Infeasible bins receive\n        ``-np.inf`` so they will never be selected by ``np.argmax``.\n    \"\"\"\n    # Ensure proper NumPy array\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n    n_bins = bins_remain_cap.size\n\n    if n_bins == 0:\n        return np.array([], dtype=np.float64)\n\n    # Feasibility mask: can the item fit?\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        # No feasible bin \u2192 all scores -inf\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate static bin capacity (assume all bins share the same capacity)\n    bin_capacity = float(np.max(bins_remain_cap))\n    if bin_capacity <= 0.0:\n        # Defensive: capacity non\u2011positive, treat as infeasible\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng(random_state)\n\n    # ------------------------------------------------------------------\n    # 1) Fit\u2011ratio component (item size relative to remaining capacity)\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    # Compute ratio only for feasible bins to avoid divide\u2011by\u2011zero warnings\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n\n    # Logistic: high when fit_ratio \u2248 target_fit\n    # Clip exponent to avoid overflow\n    exp_fit = np.exp(-np.clip(alpha_fit * (fit_ratio - target_fit), -500, 500))\n    fit_score = 1.0 / (1.0 + exp_fit)\n\n    # ------------------------------------------------------------------\n    # 2) Waste component (leftover capacity after placement)\n    # ------------------------------------------------------------------\n    waste_norm = np.clip((bins_remain_cap - item) / bin_capacity, 0.0, 1.0)\n    # Logistic decreasing: small waste \u2192 high score\n    exp_waste = np.exp(np.clip(alpha_waste * (waste_norm - waste_target), -500, 500))\n    waste_score = 1.0 / (1.0 + exp_waste)\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively\n    # ------------------------------------------------------------------\n    combined_score = fit_score * waste_score\n\n    # Infeasible bins must be penalised with -inf\n    combined_score[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Deterministic tie\u2011breaker (tiny index\u2011based bias)\n    # ------------------------------------------------------------------\n    combined_score += np.arange(n_bins, dtype=np.float64) * tie_breaker_scale\n\n    # ------------------------------------------------------------------\n    # Add small random noise for stochastic tie\u2011breaking\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(n_bins) * noise_scale\n        combined_score[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration: occasionally replace scores with random ranks\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_scores = np.full_like(combined_score, -np.inf, dtype=np.float64)\n        random_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        combined_score = random_scores\n\n    return combined_score",
    "response_id": 7,
    "obj": 4.0885520542481055,
    "SLOC": 42.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                *, random_state: Optional[int] = None,\n                epsilon_min: float = 0.05,\n                epsilon_max: float = 0.25) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    random_state : int or None, optional\n        Seed for reproducibility.\n    epsilon_min, epsilon_max : float, optional\n        Bounds for the exploration probability epsilon.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores; infeasible bins receive -np.inf.\n    \"\"\"\n    # Ensure array\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Leftover after placing the item\n    leftover = bins_remain_cap - item\n\n    # Base score: tight fits get higher values\n    eps = 1e-12  # avoid division by zero\n    base = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    base[feasible] = 1.0 / (leftover[feasible] + eps)\n\n    # Adaptive exploration rate based on variance of leftover space\n    lo = leftover[feasible]\n    var = np.var(lo)\n    L = np.max(lo)\n    var_norm = 0.0\n    if L > 0:\n        var_max = (L ** 2) / 4.0  # max variance in [0, L]\n        var_norm = np.clip(var / var_max, 0.0, 1.0)\n\n    epsilon = epsilon_min + (epsilon_max - epsilon_min) * (1.0 - var_norm)\n\n    # Random exploration component\n    rng = np.random.default_rng(random_state)\n    random_score = rng.random(bins_remain_cap.shape)\n\n    # Combine exploitation (tight\u2011fit) and exploration (random)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    priorities[feasible] = (1.0 - epsilon) * base[feasible] + epsilon * random_score[feasible]\n\n    # Deterministic tie\u2011breaker: very small incremental value\n    priorities += np.arange(bins_remain_cap.size, dtype=np.float64) * 1e-12\n\n    return priorities",
    "response_id": 8,
    "obj": 3.250897487036312,
    "SLOC": 26.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    epsilon: float = 0.02,\n    noise_scale: float = 1e-5,\n    alpha_fit: float = 10.0,\n    target_fit: float = 0.75,\n    alpha_waste: float = 12.0,\n    waste_target: float = 0.05,\n    alpha_used: float = 8.0,\n    used_target: float = 0.40,\n    random_state: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Compute priority scores for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the open bins.\n    epsilon : float, optional\n        Probability of selecting a random bin instead of the deterministic\n        score (\u03b5\u2011greedy exploration).\n    noise_scale : float, optional\n        Scale of uniform additive noise used to break ties.\n    alpha_fit, target_fit : float, optional\n        Logistic parameters for the fit\u2011ratio component.\n    alpha_waste, waste_target : float, optional\n        Logistic parameters for the waste component.\n    alpha_used, used_target : float, optional\n        Logistic parameters for the used\u2011fraction component.\n    random_state : int or None, optional\n        Random seed for reproducibility.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (higher = more desirable). Infeasible bins receive\n        ``-np.inf`` so they will never be selected.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Empty bin list: nothing to score\n    if bins_remain_cap.size == 0:\n        return np.array([], dtype=np.float64)\n\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Estimate bin capacity from the maximum remaining capacity\n    bin_capacity = float(np.max(bins_remain_cap))\n    if bin_capacity <= 0.0:\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    rng = np.random.default_rng(random_state)\n\n    # ------------------------------------------------------------------\n    # 1) Fit\u2011ratio component\n    # ------------------------------------------------------------------\n    fit_ratio = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    np.divide(item, bins_remain_cap, out=fit_ratio, where=feasible)\n\n    # ------------------------------------------------------------------\n    # 2) Waste component (leftover after placement)\n    # ------------------------------------------------------------------\n    waste_norm = np.clip((bins_remain_cap - item) / bin_capacity, 0.0, 1.0)\n\n    # ------------------------------------------------------------------\n    # 3) Used\u2011fraction component\n    # ------------------------------------------------------------------\n    used_before = (bin_capacity - bins_remain_cap) / bin_capacity\n    used_after = np.clip(used_before + item / bin_capacity, 0.0, 1.0)\n\n    # ------------------------------------------------------------------\n    # Helper: variance\u2011based steepness adjustment\n    # ------------------------------------------------------------------\n    def _var_norm(arr: np.ndarray, mask: np.ndarray) -> float:\n        \"\"\"Return normalized variance (0\u20111) of `arr` over indices where `mask`.\"\"\"\n        if np.any(mask):\n            var = np.var(arr[mask])\n        else:\n            var = 0.0\n        # Max variance for a [0,1] distribution is 0.25\n        return min(var / 0.25, 1.0)\n\n    var_fit = _var_norm(fit_ratio, feasible)\n    var_waste = _var_norm(waste_norm, feasible)\n    var_used = _var_norm(used_after, feasible)\n\n    # Adjust logistic steepness inversely with variance\n    alpha_fit_adj = alpha_fit * (1.0 - var_fit)\n    alpha_waste_adj = alpha_waste * (1.0 - var_waste)\n    alpha_used_adj = alpha_used * (1.0 - var_used)\n\n    # Prevent zero steepness\n    alpha_fit_adj = max(alpha_fit_adj, 1e-3)\n    alpha_waste_adj = max(alpha_waste_adj, 1e-3)\n    alpha_used_adj = max(alpha_used_adj, 1e-3)\n\n    # ------------------------------------------------------------------\n    # Logistic scoring functions\n    # ------------------------------------------------------------------\n    def _logistic(x: np.ndarray, target: float, alpha: float) -> np.ndarray:\n        return 1.0 / (1.0 + np.exp(-alpha * (x - target)))\n\n    fit_score = _logistic(fit_ratio, target_fit, alpha_fit_adj)\n    # Waste score is decreasing: use negative alpha\n    waste_score = _logistic(waste_norm, waste_target, -alpha_waste_adj)\n    used_score = _logistic(used_after, used_target, alpha_used_adj)\n\n    # ------------------------------------------------------------------\n    # Combine components multiplicatively\n    # ------------------------------------------------------------------\n    combined_score = fit_score * waste_score * used_score\n\n    # Add exact\u2011fit bonus\n    exact_fit = feasible & np.isclose(bins_remain_cap - item, 0.0, atol=1e-9)\n    combined_score[exact_fit] += 1e6\n\n    # Set infeasible bins to -inf\n    combined_score[~feasible] = -np.inf\n\n    # ------------------------------------------------------------------\n    # Tie\u2011breaker: small deterministic offset\n    # ------------------------------------------------------------------\n    tie_breaker = np.arange(bins_remain_cap.size, dtype=np.float64) * 1e-12\n    combined_score += tie_breaker\n\n    # ------------------------------------------------------------------\n    # Add random noise\n    # ------------------------------------------------------------------\n    if noise_scale > 0.0:\n        noise = rng.random(bins_remain_cap.size) * noise_scale\n        combined_score[feasible] += noise[feasible]\n\n    # ------------------------------------------------------------------\n    # \u03b5\u2011greedy exploration\n    # ------------------------------------------------------------------\n    if epsilon > 0.0 and rng.random() < epsilon:\n        random_scores = np.full_like(combined_score, -np.inf, dtype=np.float64)\n        random_scores[feasible] = rng.random(np.count_nonzero(feasible))\n        combined_score = random_scores\n\n    return combined_score",
    "response_id": 9,
    "obj": 4.15835660151576,
    "SLOC": 63.0,
    "cyclomatic_complexity": 7.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\nfrom typing import Optional\n\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                *,\n                random_state: Optional[int] = None,\n                epsilon_min: float = 0.05,\n                epsilon_max: float = 0.25) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for online bin packing using a variance\u2011aware sigmoid\n    and epsilon\u2011greedy exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    random_state : int or None, optional\n        Seed for reproducibility.\n    epsilon_min, epsilon_max : float, optional\n        Bounds for the exploration probability epsilon.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores; infeasible bins receive -np.inf.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask\n    feasible = bins_remain_cap >= item\n    if not np.any(feasible):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n\n    # Remaining capacity after placing the item\n    leftover = bins_remain_cap - item\n\n    # Statistics on the leftover space of feasible bins\n    lo = leftover[feasible]\n    L = np.max(lo) if lo.size > 0 else 0.0\n    var = np.var(lo)\n    var_norm = var / ((L**2) / 4.0) if L > 0 else 0.0\n    var_norm = np.clip(var_norm, 0.0, 1.0)\n\n    # Temperature / steepness of the sigmoid\n    k_min, k_max = 1.0, 10.0\n    k = k_min + (k_max - k_min) * (1.0 - var_norm)\n\n    # Center of the sigmoid at half of the maximal leftover\n    c = L / 2.0\n\n    # Base score: tighter fits (smaller leftover) get higher scores\n    base = np.zeros_like(bins_remain_cap)\n    base[feasible] = 1.0 / (1.0 + np.exp(k * (leftover[feasible] - c)))\n\n    # Exploration probability (epsilon\u2011greedy)\n    epsilon = epsilon_min + (epsilon_max - epsilon_min) * (1.0 - var_norm)\n    rng = np.random.default_rng(random_state)\n    random_score = rng.random(bins_remain_cap.shape)\n\n    # Combine exploitation and exploration\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=np.float64)\n    priorities[feasible] = (1.0 - epsilon) * base[feasible] + epsilon * random_score[feasible]\n\n    # Deterministic tie\u2011breaker: very small incremental value\n    priorities += np.arange(bins_remain_cap.size, dtype=np.float64) * 1e-12\n\n    return priorities",
    "response_id": 0,
    "obj": 5.564419625049856,
    "SLOC": 28.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  }
]