```python
import numpy as np

def priority_v2(
    item: float,
    bins_remain_cap: np.ndarray,
    *,
    epsilon: float = 0.0,
    noise_scale: float = 1e-6,
    alpha_fit: float = 10.0,
    target_fit: float = 0.9,
    alpha_waste: float = 10.0,
    waste_target: float = 0.05,
    alpha_used: float = 8.0,
    used_target: float = 0.4,
    tie_eps: float = 1e-12,
) -> np.ndarray:
    """
    Priority function for the online Bin Packing Problem.

    The score blends three sigmoid‑based components:
      * Fit ratio – closeness of the item size to the remaining capacity.
      * Waste – leftover space after the item would be placed.
      * Used fraction – how much of the bin is already occupied.

    The steepness of each sigmoid is scaled adaptively by the standard
    deviation of the corresponding metric over feasible bins.  A tiny
    deterministic tie‑breaker favours tighter fits, random noise (scaled
    by ``noise_scale``) breaks exact ties, and an ε‑greedy exploration
    (probability ``epsilon``) can replace the deterministic ranking with a
    random choice.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.
    epsilon : float, optional
        Probability of picking a random feasible bin (exploration).
    noise_scale : float, optional
        Scale of uniform additive noise added to the scores.
    alpha_fit, target_fit, alpha_waste, waste_target,
    alpha_used, used_target : float, optional
        Hyper‑parameters for the three sigmoid transforms.
    tie_eps : float, optional
        Tiny deterministic factor used for tie‑breaking.

    Returns
    -------
    np.ndarray
        Priority scores (higher is better). Infeasible bins receive ``-inf``.
    """
    # ------------------------------------------------------------------
    # Normalise input
    # ------------------------------------------------------------------
    caps = np.asarray(bins_remain_cap, dtype=np.float64).ravel()

    # Edge case: no open bins
    if caps.size == 0:
        return np.array([], dtype=np.float64)

    # Feasibility mask
    feasible = caps >= item
    if not np.any(feasible):
        # No bin can accommodate the item
        return np.full_like(caps, -np.inf, dtype=np.float64)

    # ------------------------------------------------------------------
    # Estimate the (unknown) bin capacity.
    # Use the largest observed remaining capacity, but never smaller than the item.
    # ------------------------------------------------------------------
    est_capacity = max(caps.max(), item)

    # ------------------------------------------------------------------
    # Extract metrics for feasible bins
    # ------------------------------------------------------------------
    caps_feas = caps[feasible]                     # remaining capacities where item fits
    waste = caps_feas - item                        # leftover space after placement
    waste_norm = waste / est_capacity               # normalised waste in [0,1]
    fit_ratio = item / caps_feas                    # ratio in (0,1]; 1 = perfect fit
    used_frac = (est_capacity - caps_feas) / est_capacity  # fraction already occupied

    # ------------------------------------------------------------------
    # Adaptive sigmoid steepness helpers
    # ------------------------------------------------------------------
    def adaptive_scale(metric: np.ndarray) -> float:
        """Return a scale factor based on the metric's std (>=1e-12)."""
        if metric.size <= 1:
            return 1.0
        std = np.std(metric)
        return std if std > 1e-12 else 1.0

    # ------------------------------------------------------------------
    # 1) Fit‑ratio component (reward ratios close to 1)
    # ------------------------------------------------------------------
    scale_fit = adaptive_scale(fit_ratio)
    logits_fit = (fit_ratio - target_fit) * (alpha_fit / scale_fit)
    fit_score = 1.0 / (1.0 + np.exp(-logits_fit))

    # ------------------------------------------------------------------
    # 2) Waste component (reward small waste)
    # ------------------------------------------------------------------
    scale_waste = adaptive_scale(waste_norm)
    # Negative sign flips the sigmoid to give higher scores for smaller waste
    logits_waste = -(waste_norm - waste_target) * (alpha_waste / scale_waste)
    waste_score = 1.0 / (1.0 + np.exp(-logits_waste))

    # ------------------------------------------------------------------
    # 3) Used‑fraction component (reward partially filled bins)
    # ------------------------------------------------------------------
    scale_used = adaptive_scale(used_frac)
    logits_used = (used_frac - used_target) * (alpha_used / scale_used)
    used_score = 1.0 / (1.0.0 + np.exp(-logits_used))

    # ------------------------------------------------------------------
    # Combine the three signals multiplicatively
    # ------------------------------------------------------------------
    combined = fit_score * waste_score * used_score

    # ------------------------------------------------------------------
    # Deterministic tie‑breaker: favour tighter fits (smaller waste)
    # ------------------------------------------------------------------
    combined += tie_eps * (1.0 - waste_norm)

    # ------------------------------------------------------------------
    # Add small random noise to break exact ties
    # ------------------------------------------------------------------
    if noise_scale > 0.0:
        rng = np.random.default_rng()
        combined += rng.random(combined.shape) * noise_scale

    # ------------------------------------------------------------------
    # ε‑greedy exploration: with probability epsilon pick a random feasible bin
    # ------------------------------------------------------------------
    if epsilon > 0.0:
        rng = np.random.default_rng()
        if rng.random() < epsilon:
            random_scores = rng.random(caps.shape)
            random_scores[~feasible] = -np.inf
            return random_scores

    # ------------------------------------------------------------------
    # Assemble final scores (infeasible bins get -inf)
    # ------------------------------------------------------------------
    scores = np.full_like(caps, -np.inf, dtype=np.float64)
    scores[feasible] = combined
    # The above line had a syntax error; fix it:
    scores[feasible] = combined
    return scores
```
