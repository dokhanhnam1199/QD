{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Compute a priority score for each bin in the online Bin Packing Problem.\n\n    The heuristic normalises the leftover capacity after hypothetically placing the\n    item, then feeds this value into a sigmoid that rewards tight fits.  When\n    ``adaptive`` behaviour is enabled (hard\u2011coded to True), the steepness of the\n    sigmoid is scaled by the standard deviation of the normalised leftovers among\n    feasible bins, allowing the method to react to the current distribution of\n    bin utilizations.  A tiny deterministic tie\u2011breaker proportional to the tightness\n    of the fit ensures a unique selection when scores are otherwise equal.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins (non\u2011negative).\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores with the same shape as ``bins_remain_cap``.\n        Infeasible bins (where the item does not fit) receive ``-np.inf``.\n    \"\"\"\n    # Ensure a NumPy array of floats for safe vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute leftover capacity after (hypothetically) placing the item\n    leftover = caps - item\n\n    # Feasibility mask: True where the item fits\n    feasible = leftover >= 0\n\n    # Initialise all priorities to -inf (infeasible)\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return early\n    if not np.any(feasible):\n        return priorities\n\n    # Normalised leftover fraction: 0 \u2192 perfect fit, 1 \u2192 empty bin\n    # Guard division by zero (possible only when caps == 0 and item == 0)\n    norm_leftover = np.empty_like(caps, dtype=float)\n    caps_feas = caps[feasible]\n    leftover_feas = leftover[feasible]\n    with np.errstate(divide='ignore', invalid='ignore'):\n        norm_leftover[feasible] = np.where(\n            caps_feas > 0,\n            leftover_feas / caps_feas,\n            0.0\n        )\n    # Infeasible entries are irrelevant; set to zero for completeness\n    norm_leftover[~feasible] = 0.0\n\n    # Adaptive steepness scaling based on variance of normalised leftovers\n    adaptive = True  # hard\u2011coded as per reflection\n    if adaptive:\n        std = np.std(norm_leftover[feasible])\n        scale = std if std > 1e-12 else 1.0  # avoid division by zero\n    else:\n        scale = 1.0\n\n    # Sigmoid parameters (tuned for typical bin\u2011packing ranges)\n    a = 5.0   # offset \u2013 shifts the curve upward\n    b = 10.0  # base steepness \u2013 larger \u2192 sharper drop for looser fits\n\n    # Logits for the sigmoid: larger when norm_leftover is small (tight fit)\n    logits = a - (b / scale) * norm_leftover[feasible]\n\n    # Numerically stable sigmoid using tanh formulation:\n    # sigmoid(x) = 0.5 * (1 + tanh(x/2))\n    scores = 0.5 * (1.0 + np.tanh(logits / 2.0))\n\n    # Deterministic tie\u2011breaker: favour tighter fits (smaller norm_leftover)\n    eps_tie = 1e-8\n    tie = eps_tie * (1.0 - norm_leftover[feasible])\n\n    # Assign final priority scores to feasible bins\n    priorities[feasible] = scores + tie\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global epsilon controlling the exploration vs. exploitation balance.\n_EPSILON = 0.15  # Typical values: 0.0 (pure greedy) to 1.0 (pure random).\n\n    \"\"\"\n    Compute a priority score for each bin using an epsilon\u2011greedy strategy.\n\n    The function prefers bins that fit the item tightly (exploitation) while\n    preserving a chance of exploring sub\u2011optimal bins (exploration) by blending\n    a random component weighted by epsilon.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacity of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin; higher scores indicate more desirable bins.\n    \"\"\"\n    # Ensure input is a NumPy array of floats.\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item.\n    can_fit = bins_remain_cap >= item\n\n    # --- Exploitation component ------------------------------------------------\n    # Preference for tighter fits: smaller leftover space => larger priority.\n    # Inverse of leftover space is used; a tiny epsilon avoids division by zero.\n    leftover = bins_remain_cap - item\n    base_priority = np.where(\n        can_fit,\n        1.0 / (leftover + 1e-12),\n        0.0\n    )\n\n    # --- Exploration component -------------------------------------------------\n    # Random scores to enable exploration of less obvious bins.\n    rng = np.random.default_rng()\n    random_priority = rng.random(bins_remain_cap.shape)\n\n    # --- Blend the two components -----------------------------------------------\n    # (1 - epsilon) weight for exploitation, epsilon weight for exploration.\n    blended_priority = (1.0 - _EPSILON) * base_priority + _EPSILON * random_priority\n\n    # Bins that cannot fit the item should be assigned zero priority to never be selected.\n    priorities = np.where(can_fit, blended_priority, 0.0)\n\n    return priorities\n\n[Reflection]\nBlend tight\u2011fit inverse leftover with adaptive epsilon; keep calculations cheap; use variance to tune exploration.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}