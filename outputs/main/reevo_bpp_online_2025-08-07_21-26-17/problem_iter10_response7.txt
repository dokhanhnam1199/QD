```python
import numpy as np
from typing import Optional


def priority_v2(
    item: float,
    bins_remain_cap: np.ndarray,
    *,
    epsilon: float = 0.02,
    noise_scale: float = 1e-5,
    alpha_fit: float = 10.0,
    target_fit: float = 0.75,
    alpha_waste: float = 12.0,
    waste_target: float = 0.05,
    alpha_used: float = 8.0,
    used_target: float = 0.40,
    random_state: Optional[int] = None,
) -> np.ndarray:
    """
    Compute priority scores for an online bin‑packing decision.

    Parameters
    ----------
    item : float
        Size of the incoming item (must be positive).
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of currently open bins.
    epsilon : float, optional
        Probability of performing ε‑greedy exploration (choose a random
        feasible bin). Default is 0.02.
    noise_scale : float, optional
        Scale of uniform additive noise to break ties. Default is 1e‑5.
    alpha_fit, target_fit : float, optional
        Logistic steepness and target for the *fit‑ratio* component.
    alpha_waste, waste_target : float, optional
        Logistic steepness and target for the *waste* component (smaller waste
        is better).
    alpha_used, used_target : float, optional
        Logistic steepness and target for the *used‑fraction* component.
    random_state : int or None, optional
        Seed for reproducibility.

    Returns
    -------
    np.ndarray
        Priority score for each bin (higher = more desirable). Infeasible
        bins receive ``-np.inf`` so they will never be selected.
    """
    # ------------------------------------------------------------------
    # Input validation & conversion
    # ------------------------------------------------------------------
    if item <= 0:
        raise ValueError("Item size must be positive.")
    bins = np.asarray(bins_remain_cap, dtype=np.float64).ravel()
    n_bins = bins.size
    if n_bins == 0:
        return np.array([], dtype=np.float64)

    feasible = bins >= item
    if not np.any(feasible):
        # No bin can accommodate the item
        return np.full_like(bins, -np.inf, dtype=np.float64)

    # Estimate bin capacity (assume the largest remaining capacity equals the full size)
    bin_capacity = float(np.max(bins))
    if bin_capacity <= 0.0:
        return np.full_like(bins, -np.inf, dtype=np.float64)

    rng = np.random.default_rng(random_state)

    # ------------------------------------------------------------------
    # Component 1: Fit‑ratio (item / remaining capacity)
    # ------------------------------------------------------------------
    fit_ratio = np.zeros_like(bins, dtype=np.float64)
    np.divide(item, bins, out=fit_ratio, where=feasible)

    # ------------------------------------------------------------------
    # Component 2: Waste after placement (normalized)
    # ------------------------------------------------------------------
    waste_norm = np.clip((bins - item) / bin_capacity, 0.0, 1.0)

    # ------------------------------------------------------------------
    # Component 3: Used‑fraction after placement (normalized)
    # ------------------------------------------------------------------
    used_before = (bin_capacity - bins) / bin_capacity
    used_after = np.clip(used_before + item / bin_capacity, 0.0, 1.0)

    # ------------------------------------------------------------------
    # Helper: normalized variance (0‑1) for a component over feasible bins
    # ------------------------------------------------------------------
    def _norm_var(arr: np.ndarray, mask: np.ndarray) -> float:
        if np.any(mask):
            var = np.var(arr[mask])
        else:
            var = 0.0
        # Max variance for a [0,1] variable is 0.25
        return min(var / 0.25, 1.0)

    var_fit = _norm_var(fit_ratio, feasible)
    var_waste = _norm_var(waste_norm, feasible)
    var_used = _norm_var(used_after, feasible)

    # ------------------------------------------------------------------
    # Adjust logistic steepness inversely with variance
    # ------------------------------------------------------------------
    adj_alpha_fit = max(alpha_fit * (1.0 - var_fit), 1e-3)
    adj_alpha_waste = max(alpha_waste * (1.0 - var_waste), 1e-3)
    adj_alpha_used = max(alpha_used * (1.0 - var_used), 1e-3)

    # ------------------------------------------------------------------
    # Logistic scoring function
    # ------------------------------------------------------------------
    def _logistic(x: np.ndarray, target: float, alpha: float) -> np.ndarray:
        """Standard logistic: 1/(1+exp(-alpha*(x-target)))."""
        return 1.0 / (1.0 + np.exp(-alpha * (x - target)))

    # Fit‑ratio: higher is better (positive alpha)
    fit_score = _logistic(fit_ratio, target_fit, adj_alpha_fit)

    # Waste: lower is better → use negative alpha to flip the curve
    waste_score = _logistic(waste_norm, waste_target, -adj_alpha_waste)

    # Used‑fraction: aim for a moderate fill level
    used_score = _logistic(used_after, used_target, adj_alpha_used)

    # ------------------------------------------------------------------
    # Combine components multiplicatively
    # ------------------------------------------------------------------
    combined = fit_score * waste_score * used_score

    # Exact‑fit bonus (encourage using up a bin completely)
    exact_fit = feasible & np.isclose(bins - item, 0.0, 1e-12)
    combined[exact_fit] += 1e6

    # Infeasible bins get -inf so they are never chosen
    combined[~feasible] = -np.inf

    # ------------------------------------------------------------------
    # Deterministic tie‑breaker (tiny index‑based offset)
    # ------------------------------------------------------------------
    tie_breaker = np.arange(n_bins, dtype=np.float64) * 1e-12
    combined += tie_breaker

    # ------------------------------------------------------------------
    # Add small random noise (optional)
    # ------------------------------------------------------------------
    if noise_scale > 0.0:
        noise = rng.random(n_bins) * noise_scale
        combined[feasible] += noise[feasible]

    # ------------------------------------------------------------------
    # ε‑greedy exploration
    # ------------------------------------------------------------------
    if epsilon > 0.0 and rng.random() < epsilon:
        rand_scores = np.full_like(combined, -np.inf, dtype=np.float64)
        rand_scores[feasible] = rng.random(np.count_nonzero(feasible))
        combined = rand_scores

    return combined
```
