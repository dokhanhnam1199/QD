{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths + adaptive degree bias + sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Degree bias (adaptive penalty)\n    degree_penalty = np.ones((n, n))  # Initialize to 1 for no penalty by default\n    avg_degree = 0\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Adaptive degree penalty: only penalize if degree > avg\n                penalty_i = max(1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove edges with low heuristic values\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20) # Keep top 80%\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:  # Avoid division by zero\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 2nd]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths + adaptive degree bias + sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Degree bias (adaptive penalty)\n    degree_penalty = np.ones((n, n))  # Initialize to 1 for no penalty by default\n    avg_degree = 0\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Adaptive degree penalty: only penalize if degree > avg\n                penalty_i = max(1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove edges with low heuristic values\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20) # Keep top 80%\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:  # Avoid division by zero\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 3rd]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths + degree bias.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Degree bias (adaptive penalty)\n    degree_penalty = np.zeros((n, n))\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n                # Adaptive degree penalty: only penalize if degree > avg\n                penalty_i = max(1, avg_degree / (degree_i + 1e-9))\n                penalty_j = max(1, avg_degree / (degree_j + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n    \n    # 5. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 4th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths + adaptive degree bias + controlled randomness.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Degree bias (adaptive penalty)\n    degree_penalty = np.ones((n, n))  # Initialize with ones for no penalty by default\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n\n                # Adaptive degree penalty: only penalize if degree > avg\n                if degree_i > avg_degree or degree_j > avg_degree:\n                    penalty_i = max(0.5, avg_degree / (degree_i + 1e-9))  # Reduced penalty\n                    penalty_j = max(0.5, avg_degree / (degree_j + 1e-9))  # Reduced penalty\n                    degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics (emphasize shortest paths and inverse distance)\n    heuristic_matrix = inverse_distance**1.2 * degree_penalty / (shortest_paths + 1e-9)**0.8\n\n    # 5. Sparsification (remove less promising edges)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)  # Keep top 70%\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    # 7. Controlled Randomness (only when no strong signal)\n    if np.sum(heuristic_matrix > 0) < n:  # If too sparse, add some noise\n        random_matrix = np.random.rand(n, n) * 0.1\n        heuristic_matrix += random_matrix\n        max_heuristic = np.max(heuristic_matrix)\n        heuristic_matrix /= max_heuristic\n\n\n    return heuristic_matrix\n\n[Heuristics 5th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths, adaptive degree bias, and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)  # Initialize with ones\n\n    # Calculate degrees and average degree based on inverse distances\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance).reshape(-1)\n    avg_degree = np.mean(degrees)\n\n    # Apply penalty only to edges connected to nodes with above-average degree\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))  # Reduced penalty\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))  # Reduced penalty\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove weak edges\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)  # Dynamic threshold\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n      heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 6th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths, adaptive degree bias, and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)  # Initialize with ones\n\n    # Calculate degrees and average degree based on inverse distances\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance).reshape(-1)\n    avg_degree = np.mean(degrees)\n\n    # Apply penalty only to edges connected to nodes with above-average degree\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))  # Reduced penalty\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))  # Reduced penalty\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove weak edges\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)  # Dynamic threshold\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n      heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 7th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths, adaptive degree bias, and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)  # Initialize with ones\n\n    # Calculate degrees and average degree based on inverse distances\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance).reshape(-1)\n    avg_degree = np.mean(degrees)\n\n    # Apply penalty only to edges connected to nodes with above-average degree\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))  # Reduced penalty\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))  # Reduced penalty\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove weak edges\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)  # Dynamic threshold\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n      heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 8th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, shortest paths, and degree penalty.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest paths (Dijkstra's)\n    shortest_paths = np.zeros((n, n))\n    for i in range(n):\n        dist = np.full(n, np.inf)\n        visited = np.zeros(n, dtype=bool)\n        dist[i] = 0\n        for _ in range(n):\n            u = np.argmin(dist + visited * np.inf)\n            visited[u] = True\n            for v in range(n):\n                if distance_matrix[u, v] > 0 and dist[v] > dist[u] + distance_matrix[u, v]:\n                    dist[v] = dist[u] + distance_matrix[u, v]\n        shortest_paths[i, :] = dist\n\n    # Node degree (inverse distance based)\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                h = inverse_distance[i, j]\n\n                # Penalize connections between high-degree nodes (subtly)\n                h *= 1 / (np.sqrt(node_degree[i] * node_degree[j]) + 1e-9)\n\n                # Favor edges on shorter paths\n                h *= np.exp(-shortest_paths[i, j] / np.mean(distance_matrix[distance_matrix > 0]))\n\n                heuristics[i, j] = h\n\n    # Normalize\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + 1e-9)\n\n    return heuristics\n\n[Heuristics 9th]\nimport numpy as np\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance with shortest path estimates to prioritize promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Inverse distance\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n) * 1e-6)\n    np.fill_diagonal(inverse_distance, 0)\n\n    # Shortest path estimates (using Dijkstra)\n    shortest_paths = dijkstra(distance_matrix, return_predecessors=False)\n    max_path_length = np.max(shortest_paths[np.isfinite(shortest_paths)])\n    path_penalty = shortest_paths / max_path_length  # Normalize to [0, 1]\n\n    heuristic_matrix = inverse_distance * (1 - path_penalty)\n\n    # Normalize\n    heuristic_matrix = (heuristic_matrix + 1e-9) / np.sum(heuristic_matrix + 1e-9)\n\n    return heuristic_matrix\n\n[Heuristics 10th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Dijkstra shortest paths, inverse distance, degree penalty.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Dijkstra shortest path heuristic\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = np.zeros_like(distance_matrix)\n    for i in range(n):\n        shortest_paths[i] = dijkstra(graph, indices=i, unweighted=False)\n\n    heuristic_matrix = 1 / (shortest_paths + 1e-9)\n\n    # Node degree penalty\n    neighbor_counts = np.sum(distance_matrix < np.mean(distance_matrix[distance_matrix != np.inf]), axis=0)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] /= (1 + (distance_matrix[i,j] * neighbor_counts[i]/n) +  (distance_matrix[i,j] * neighbor_counts[j]/n))\n    return heuristic_matrix\n\n[Heuristics 11th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Dijkstra shortest paths, inverse distance, degree penalty.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Dijkstra shortest path heuristic\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = np.zeros_like(distance_matrix)\n    for i in range(n):\n        shortest_paths[i] = dijkstra(graph, indices=i, unweighted=False)\n\n    heuristic_matrix = 1 / (shortest_paths + 1e-9)\n\n    # Node degree penalty\n    neighbor_counts = np.sum(distance_matrix < np.mean(distance_matrix[distance_matrix != np.inf]), axis=0)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] /= (1 + (distance_matrix[i,j] * neighbor_counts[i]/n) +  (distance_matrix[i,j] * neighbor_counts[j]/n))\n    return heuristic_matrix\n\n[Heuristics 12th]\nimport numpy as np\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, Dijkstra shortest paths, and degree bias.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)\n    heuristic_matrix = inverse_distance.copy() # Initialize\n\n    # Dijkstra shortest path heuristic\n    dist_matrix = dijkstra(csgraph=distance_matrix, directed=False, unweighted=False)\n    shortest_path_heuristic = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            if i != j and np.isfinite(dist_matrix[i, j]):\n                shortest_path_heuristic[i, j] = 1.0 / (dist_matrix[i, j] + 1e-9)\n\n    heuristic_matrix += shortest_path_heuristic # Add shortest path\n\n    # Degree bias: penalize connection between high-degree nodes\n    degree = np.sum(np.isfinite(distance_matrix), axis=0)\n    for i in range(n):\n      for j in range(n):\n        if i!=j:\n          heuristic_matrix[i,j] /= (degree[i] + degree[j]) # Penality\n\n    # Remove self-loops\n    for i in range(n):\n        heuristic_matrix[i, i] = 0.0\n\n    return heuristic_matrix\n\n[Heuristics 13th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, shortest paths, and controlled node degree bias.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # 1. Inverse distance\n    heuristics = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path influence (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    dist_matrix = dijkstra(csgraph=graph, directed=False, unweighted=False)\n    normalized_dist_matrix = dist_matrix / np.max(dist_matrix)  # Normalize\n\n    heuristics += 1 / (normalized_dist_matrix + 1e-9)\n\n    # 3. Node degree bias (controlled)\n    row_sums = np.sum(distance_matrix, axis=1)\n    mean_row_sum = np.mean(row_sums)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Penalize edges connected to nodes with above-average degree\n                if row_sums[i] > mean_row_sum and row_sums[j] > mean_row_sum:\n                    penalty = (row_sums[i] + row_sums[j]) / (2 * mean_row_sum)\n                    heuristics[i, j] /= penalty # Reduce the heuristic\n\n    # 4. Normalization\n    max_heuristic = np.max(heuristics)\n    heuristics /= max_heuristic\n\n    return heuristics\n\n[Heuristics 14th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance with node degree penalty and shortest-path approximation.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Inverse distance\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    inverse_distance[np.diag_indices_from(inverse_distance)] = 0.0\n\n    # Node degree penalty (penalize links between popular nodes)\n    node_degrees = np.sum(inverse_distance, axis=0)\n    degree_matrix = np.outer(node_degrees, node_degrees)\n    degree_penalty = 1.0 / (degree_matrix + 1e-9)\n\n    # Heuristic combination\n    heuristic_matrix = inverse_distance * degree_penalty\n\n    return heuristic_matrix\n\n[Heuristics 15th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance with shortest path penalization and node\n    degree influence for informed edge selection.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Basic desirability: inverse of distance\n    base_heuristic = 1.0 / (distance_matrix + 1e-9)\n\n    # Shortest path lengths (using the distance matrix)\n    path_lengths = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            path_lengths[i, j] = distance_matrix[i, j]\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                path_lengths[i, j] = min(path_lengths[i, j], path_lengths[i, k] + path_lengths[k, j])\n    connectivity_bonus = path_lengths / (np.max(path_lengths) + 1e-9)\n    heuristic_matrix = base_heuristic + (1 - connectivity_bonus)\n\n    # Node degree penalty\n    degrees = np.sum(distance_matrix < np.inf, axis=0) -1 #exclude self-loop\n\n    degree_penalty = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            degree_penalty[i, j] = (degrees[i] + degrees[j])\n    degree_penalty = degree_penalty / np.max(degree_penalty) if np.max(degree_penalty) > 0 else 0\n\n    heuristic_matrix = heuristic_matrix * (1 - 0.1 * degree_penalty) # Penalize higher degree connections\n\n    # Controlled randomness\n    heuristic_matrix = heuristic_matrix + np.random.rand(*heuristic_matrix.shape) * 0.01\n    heuristic_matrix = np.where(heuristic_matrix <= 0, 0.0001, heuristic_matrix) # Ensure non-zero\n    return heuristic_matrix\n\n[Heuristics 16th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance with shortest path penalization and node\n    degree influence for informed edge selection.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Basic desirability: inverse of distance\n    base_heuristic = 1.0 / (distance_matrix + 1e-9)\n\n    # Shortest path lengths (using the distance matrix)\n    path_lengths = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            path_lengths[i, j] = distance_matrix[i, j]\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                path_lengths[i, j] = min(path_lengths[i, j], path_lengths[i, k] + path_lengths[k, j])\n    connectivity_bonus = path_lengths / (np.max(path_lengths) + 1e-9)\n    heuristic_matrix = base_heuristic + (1 - connectivity_bonus)\n\n    # Node degree penalty\n    degrees = np.sum(distance_matrix < np.inf, axis=0) -1 #exclude self-loop\n\n    degree_penalty = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            degree_penalty[i, j] = (degrees[i] + degrees[j])\n    degree_penalty = degree_penalty / np.max(degree_penalty) if np.max(degree_penalty) > 0 else 0\n\n    heuristic_matrix = heuristic_matrix * (1 - 0.1 * degree_penalty) # Penalize higher degree connections\n\n    # Controlled randomness\n    heuristic_matrix = heuristic_matrix + np.random.rand(*heuristic_matrix.shape) * 0.01\n    heuristic_matrix = np.where(heuristic_matrix <= 0, 0.0001, heuristic_matrix) # Ensure non-zero\n    return heuristic_matrix\n\n[Heuristics 17th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance with shortest path penalization and node\n    degree influence for informed edge selection.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Basic desirability: inverse of distance\n    base_heuristic = 1.0 / (distance_matrix + 1e-9)\n\n    # Shortest path lengths (using the distance matrix)\n    path_lengths = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            path_lengths[i, j] = distance_matrix[i, j]\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                path_lengths[i, j] = min(path_lengths[i, j], path_lengths[i, k] + path_lengths[k, j])\n    connectivity_bonus = path_lengths / (np.max(path_lengths) + 1e-9)\n    heuristic_matrix = base_heuristic + (1 - connectivity_bonus)\n\n    # Node degree penalty\n    degrees = np.sum(distance_matrix < np.inf, axis=0) -1 #exclude self-loop\n\n    degree_penalty = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            degree_penalty[i, j] = (degrees[i] + degrees[j])\n    degree_penalty = degree_penalty / np.max(degree_penalty) if np.max(degree_penalty) > 0 else 0\n\n    heuristic_matrix = heuristic_matrix * (1 - 0.1 * degree_penalty) # Penalize higher degree connections\n\n    # Controlled randomness\n    heuristic_matrix = heuristic_matrix + np.random.rand(*heuristic_matrix.shape) * 0.01\n    heuristic_matrix = np.where(heuristic_matrix <= 0, 0.0001, heuristic_matrix) # Ensure non-zero\n    return heuristic_matrix\n\n[Heuristics 18th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    TSP heuristics: Combines inverse distance, shortest paths, and node centrality.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest Path (approximated via Floyd-Warshall)\n    dist = np.copy(distance_matrix)\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                dist[i, j] = min(dist[i, j], dist[i, k] + dist[k, j])\n\n    #Edge Centrality based on shortest path\n    closeness_centrality = np.zeros((n,n))\n    for i in range(n):\n      for j in range(n):\n        closeness_centrality[i][j] = 1/(dist[i,j] + 1e-9)\n\n\n    # 3. Node Centrality (degree approximation) - softened penalty\n    node_centrality = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n    centrality_matrix = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            centrality_matrix[i, j] = np.sqrt(node_centrality[i] * node_centrality[j])\n\n    # Combine and normalize\n    heuristics = inverse_distance + closeness_centrality #+ centrality_matrix*0.1 #soft penalty\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + 1e-9)\n\n    # Add small randomness\n    randomness = np.random.rand(n, n) * 0.01\n    heuristics += randomness\n    heuristics = np.clip(heuristics, 0, 1)\n\n    return heuristics\n\n[Heuristics 19th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    TSP heuristics: Combines inverse distance, shortest paths, and node centrality.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest Path (approximated via Floyd-Warshall)\n    dist = np.copy(distance_matrix)\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                dist[i, j] = min(dist[i, j], dist[i, k] + dist[k, j])\n\n    #Edge Centrality based on shortest path\n    closeness_centrality = np.zeros((n,n))\n    for i in range(n):\n      for j in range(n):\n        closeness_centrality[i][j] = 1/(dist[i,j] + 1e-9)\n\n\n    # 3. Node Centrality (degree approximation) - softened penalty\n    node_centrality = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n    centrality_matrix = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            centrality_matrix[i, j] = np.sqrt(node_centrality[i] * node_centrality[j])\n\n    # Combine and normalize\n    heuristics = inverse_distance + closeness_centrality #+ centrality_matrix*0.1 #soft penalty\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + 1e-9)\n\n    # Add small randomness\n    randomness = np.random.rand(n, n) * 0.01\n    heuristics += randomness\n    heuristics = np.clip(heuristics, 0, 1)\n\n    return heuristics\n\n[Heuristics 20th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: shortest paths + adaptive degree bias + controlled randomness.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive degree bias (only penalize high degree nodes)\n    degree_penalty = np.ones_like(distance_matrix)\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n\n                # Penalize only if degree is significantly above average\n                if degree_i > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_i + 1e-9)) # Reduced penalty\n                if degree_j > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_j + 1e-9)) # Reduced penalty\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics: Prioritize inverse distance and shortest paths\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Controlled Randomness (only add if heuristic value is non-zero)\n    randomness_factor = 0.01  # Reduced randomness\n    for i in range(n):\n        for j in range(n):\n            if heuristic_matrix[i, j] > 0:\n                heuristic_matrix[i, j] += randomness_factor * np.random.rand()\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    heuristic_matrix /= max_heuristic\n\n    # 7. Sparsify: Remove edges with very low heuristic value\n    threshold = 0.01 #Adjust threshold to control sparcity\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    return heuristic_matrix\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}