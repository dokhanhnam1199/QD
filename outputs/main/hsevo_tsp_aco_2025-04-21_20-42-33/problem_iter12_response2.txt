```python
import numpy as np
import scipy.sparse
from scipy.sparse.csgraph import dijkstra

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """TSP heuristic: Combines inverse distance, adaptive degree bias,
    shortest paths, informed randomness, and component normalization with sparsification.
    """
    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Inverse distance
    inverse_distance = 1 / (distance_matrix + 1e-9)

    # Shortest path estimate (Dijkstra)
    graph = scipy.sparse.csr_matrix(distance_matrix)
    shortest_paths = dijkstra(graph, directed=False, indices=range(n))

    # Adaptive degree bias
    degree_penalty = np.ones((n, n))
    degrees = np.sum(inverse_distance, axis=1)
    avg_degree = np.mean(degrees)

    for i in range(n):
        for j in range(n):
            if i != j:
                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9))
                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))
                degree_penalty[i, j] = penalty_i * penalty_j
            else:
                degree_penalty[i, j] = 0

    # Combine heuristics (before sparsification)
    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)

    # Sparsification (before normalization)
    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20)
    heuristic_matrix[heuristic_matrix < threshold] = 0

    # Informed randomness (add small random values to encourage exploration of near-optimal edges)
    randomness_factor = 0.05 * np.random.rand(n, n)
    heuristic_matrix += randomness_factor * heuristic_matrix.max()


    # Component normalization (normalize each component separately)
    max_heuristic = np.max(heuristic_matrix)
    if max_heuristic > 0:
        heuristic_matrix /= max_heuristic


    return heuristic_matrix
```
