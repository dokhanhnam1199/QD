{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, and shortest paths with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 2nd]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, and shortest paths with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 3rd]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest paths, adaptive degree penalty, sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive degree bias\n    degree_penalty = np.ones_like(distance_matrix)\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n\n                if degree_i > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_i + 1e-9))\n                if degree_j > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_j + 1e-9))\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance**1.2 * degree_penalty / (shortest_paths + 1e-9)**0.8\n\n    # 5. Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    # 7. Controlled Randomness\n    if np.sum(heuristic_matrix > 0) < n:\n        random_matrix = np.random.rand(n, n) * 0.1\n        heuristic_matrix += random_matrix\n        max_heuristic = np.max(heuristic_matrix)\n        heuristic_matrix /= max_heuristic\n    \n    # Node Degree as adaptive penalty (inspired from v1, but applied late)\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n) * 1e-6), axis=1)\n    degree_penalty_v1 = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            degree_penalty_v1[i, j] = np.sqrt(node_degree[i] * node_degree[j])\n\n    heuristic_matrix = heuristic_matrix / (1 + degree_penalty_v1) # Apply adaptive degree penalty\n\n    return heuristic_matrix\n\n[Heuristics 4th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest paths, and adaptive degree penalty, sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive degree bias\n    degree_penalty = np.ones_like(distance_matrix)\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n\n                if degree_i > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_i + 1e-9))\n                if degree_j > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_j + 1e-9))\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance**1.2 * degree_penalty / (shortest_paths + 1e-9)**0.8\n\n    # 5. Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 5th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, degree bias, shortest paths, and introduces controlled randomness and adaptive sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Degree bias - adaptive based on iteration\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    \n    # Adaptive degree penalty\n    alpha = 0.5  # Adjustable parameter for degree influence\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9))  # Ensure penalty > 0\n                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = (penalty_i * penalty_j)**alpha\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Controlled randomness\n    randomness_factor = 0.01  # Adjustable randomness parameter\n    random_matrix = np.random.rand(n, n) * randomness_factor\n    heuristic_matrix += random_matrix\n\n    # Adaptive sparsification (adjust percentile based on density)\n    density = np.sum(heuristic_matrix > 0) / (n * n)\n    percentile = max(10, min(50, 30 + (density - 0.5) * 50))  # Adjust percentile dynamically\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], percentile)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 6th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, degree bias, shortest paths, and introduces controlled randomness and adaptive sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Degree bias - adaptive based on iteration\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    \n    # Adaptive degree penalty\n    alpha = 0.5  # Adjustable parameter for degree influence\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9))  # Ensure penalty > 0\n                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = (penalty_i * penalty_j)**alpha\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Controlled randomness\n    randomness_factor = 0.01  # Adjustable randomness parameter\n    random_matrix = np.random.rand(n, n) * randomness_factor\n    heuristic_matrix += random_matrix\n\n    # Adaptive sparsification (adjust percentile based on density)\n    density = np.sum(heuristic_matrix > 0) / (n * n)\n    percentile = max(10, min(50, 30 + (density - 0.5) * 50))  # Adjust percentile dynamically\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], percentile)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 7th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest paths, and adaptive degree penalty with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)\n\n    # Calculate degrees and average degree based on inverse distances\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance)\n    avg_degree = np.mean(degrees)\n\n    # Apply penalty only to edges connected to nodes with above-average degree\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))  # Reduced penalty\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))  # Reduced penalty\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Normalize before sparsification\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    # 6. Sparsification: Remove weak edges based on percentile\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 25)  # More aggressive\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    return heuristic_matrix\n\n[Heuristics 8th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree penalty, shortest paths and stochasticity.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias - geometric mean\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    degree_penalty = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_penalty[i, j] = (avg_degree / (degrees[i] + 1e-9)) * (avg_degree / (degrees[j] + 1e-9))\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics - multiplicative\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Introduce stochasticity\n    temperature = 0.1 / (heuristic_matrix + 0.01)\n    random_matrix = np.random.rand(n, n) * temperature\n    heuristic_matrix += random_matrix\n\n    # Sparsification - more aggressive\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 9th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest path, and adaptive degree bias with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)\n\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance).reshape(-1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove weak edges\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Controlled randomness and ensure non-zero\n    heuristic_matrix = heuristic_matrix + np.random.rand(*heuristic_matrix.shape) * 0.01\n    heuristic_matrix = np.where(heuristic_matrix <= 0, 0.0001, heuristic_matrix)\n\n    # 7. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 10th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths,\n    and introduces a randomized component with controlled sparsification and normalization.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.5, avg_degree / (degrees[i] + 1e-9))  # Adjusted min value\n                penalty_j = max(0.5, avg_degree / (degrees[j] + 1e-9))  # Adjusted min value\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Randomized component (scaled inverse distance)\n    random_component = np.random.rand(n, n) * inverse_distance * 0.1  # Reduced magnitude\n\n\n    # Combine heuristics (weighted combination)\n    heuristic_matrix = (0.6 * inverse_distance * degree_penalty / (shortest_paths + 1e-9) +\n                         0.4 * random_component) # added weight to random component\n\n\n\n    # Sparsification (adaptive threshold based on heuristic values)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjusted percentile\n\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 11th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths,\n    and introduces a randomized component with controlled sparsification and normalization.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.5, avg_degree / (degrees[i] + 1e-9))  # Adjusted min value\n                penalty_j = max(0.5, avg_degree / (degrees[j] + 1e-9))  # Adjusted min value\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Randomized component (scaled inverse distance)\n    random_component = np.random.rand(n, n) * inverse_distance * 0.1  # Reduced magnitude\n\n\n    # Combine heuristics (weighted combination)\n    heuristic_matrix = (0.6 * inverse_distance * degree_penalty / (shortest_paths + 1e-9) +\n                         0.4 * random_component) # added weight to random component\n\n\n\n    # Sparsification (adaptive threshold based on heuristic values)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjusted percentile\n\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 12th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths with aggressive sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))\n\n    # Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Aggressive Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 25)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 13th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance,adaptive degree bias,shortest paths,and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics: Incorporate exponential decay based on shortest path\n    heuristic_matrix = inverse_distance * degree_penalty * np.exp(-shortest_paths / (np.mean(distance_matrix[distance_matrix > 0]) + 1e-9))\n\n    # Sparsification: More aggressive sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 50)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 14th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths, and introduces controlled randomness.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias with refined penalty\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = np.clip(avg_degree / (degrees[i] + 1e-9), 0.5, 2.0)  # Clip to avoid extreme penalties\n                penalty_j = np.clip(avg_degree / (degrees[j] + 1e-9), 0.5, 2.0)  # Clip to avoid extreme penalties\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Controlled randomness to escape local optima\n    randomness = np.random.rand(n, n) * 0.1  # Scale randomness\n\n    # Combine heuristics with weighted components\n    heuristic_matrix = (0.6 * inverse_distance) + (0.3 * (inverse_distance * degree_penalty)) - (0.1 * (shortest_paths / np.max(shortest_paths + 1e-9))) + randomness\n\n\n    # Sparsification - applied earlier for efficiency and exploration\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjust percentile\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 15th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree penalty, and shortest paths with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path heuristic\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = np.zeros_like(distance_matrix)\n    for i in range(n):\n        shortest_paths[i] = dijkstra(graph, indices=i, unweighted=False)\n\n    # Adaptive Node degree penalty\n    row_sums = np.sum(distance_matrix, axis=1)\n    mean_row_sum = np.mean(row_sums)\n\n    degree_penalty = np.ones_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if row_sums[i] > mean_row_sum and row_sums[j] > mean_row_sum:\n                    penalty = (row_sums[i] + row_sums[j]) / (2 * mean_row_sum)\n                    degree_penalty[i, j] = 1/penalty\n\n    heuristic_matrix = inverse_distance * degree_penalty + 1 / (shortest_paths + 1e-9)\n\n\n    # Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 16th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree penalty, and shortest paths with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path heuristic\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = np.zeros_like(distance_matrix)\n    for i in range(n):\n        shortest_paths[i] = dijkstra(graph, indices=i, unweighted=False)\n\n    # Adaptive Node degree penalty\n    row_sums = np.sum(distance_matrix, axis=1)\n    mean_row_sum = np.mean(row_sums)\n\n    degree_penalty = np.ones_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if row_sums[i] > mean_row_sum and row_sums[j] > mean_row_sum:\n                    penalty = (row_sums[i] + row_sums[j]) / (2 * mean_row_sum)\n                    degree_penalty[i, j] = 1/penalty\n\n    heuristic_matrix = inverse_distance * degree_penalty + 1 / (shortest_paths + 1e-9)\n\n\n    # Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 17th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, degree bias, shortest paths, and introduces controlled randomness with adaptive scaling.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Degree bias\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    degree_penalty = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_penalty[i, j] = max(0.1, avg_degree / (degrees[i] + degrees[j] + 1e-9)) # Smoother penalty\n            else:\n                degree_penalty[i, j] = 0\n\n    # Shortest path estimate (Dijkstra) - using sparse matrix for efficiency\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n    shortest_paths_penalty = 1 / (shortest_paths + 1e-9)\n\n    # Introduce controlled randomness - scaled by inverse distance\n    randomness_factor = 0.05  # Adjust for desired exploration\n    random_matrix = np.random.rand(n, n) * randomness_factor * inverse_distance\n\n\n    # Combine heuristics with adaptive scaling\n    alpha = 0.6 # Weight for distance\n    beta = 0.3  # Weight for degree\n    gamma = 0.1 # Weight for shortest path\n\n    heuristic_matrix = alpha * inverse_distance + beta * degree_penalty + gamma * shortest_paths_penalty + random_matrix\n\n    # Sparsification (remove less promising edges early)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjusted percentile\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    # Normalize the heuristic matrix\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 18th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, degree bias, shortest paths, and introduces controlled randomness with adaptive scaling.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Degree bias\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    degree_penalty = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_penalty[i, j] = max(0.1, avg_degree / (degrees[i] + degrees[j] + 1e-9)) # Smoother penalty\n            else:\n                degree_penalty[i, j] = 0\n\n    # Shortest path estimate (Dijkstra) - using sparse matrix for efficiency\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n    shortest_paths_penalty = 1 / (shortest_paths + 1e-9)\n\n    # Introduce controlled randomness - scaled by inverse distance\n    randomness_factor = 0.05  # Adjust for desired exploration\n    random_matrix = np.random.rand(n, n) * randomness_factor * inverse_distance\n\n\n    # Combine heuristics with adaptive scaling\n    alpha = 0.6 # Weight for distance\n    beta = 0.3  # Weight for degree\n    gamma = 0.1 # Weight for shortest path\n\n    heuristic_matrix = alpha * inverse_distance + beta * degree_penalty + gamma * shortest_paths_penalty + random_matrix\n\n    # Sparsification (remove less promising edges early)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjusted percentile\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    # Normalize the heuristic matrix\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 19th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combination strategy: weighted geometric mean\n    alpha = 0.7\n    beta = 0.3 #weights\n\n    heuristic_matrix = (inverse_distance**alpha) * (degree_penalty**beta)\n\n\n    # Sparsification (adaptive threshold)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    # Post-Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 20th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combination strategy: weighted geometric mean\n    alpha = 0.7\n    beta = 0.3 #weights\n\n    heuristic_matrix = (inverse_distance**alpha) * (degree_penalty**beta)\n\n\n    # Sparsification (adaptive threshold)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    # Post-Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}