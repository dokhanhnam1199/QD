{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, and shortest paths with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(1, avg_degree / (degrees[i] + 1e-9))\n                penalty_j = max(1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 20)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 2nd]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest paths, degree bias and controlled randomness.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Degree bias (adaptive penalty)\n    degree_penalty = np.zeros((n, n))\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n                # Adaptive degree penalty: only penalize if degree > avg\n                penalty_i = max(1, avg_degree / (degree_i + 1e-9))\n                penalty_j = max(1, avg_degree / (degree_j + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Add controlled randomness\n    temperature = 0.01  # Tunable parameter\n    randomness = np.random.rand(n, n) * temperature\n    heuristic_matrix += randomness\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    heuristic_matrix /= max_heuristic\n\n    #7. Sparsification (percentile-based)\n    threshold = np.percentile(heuristic_matrix, 75)  # Keep top 25%\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    return heuristic_matrix\n\n[Heuristics 3rd]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, degree bias, shortest paths, and introduces stochasticity.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias with a bit more sophistication\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    degree_penalty = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_penalty[i, j] = (avg_degree / (degrees[i] + 1e-9)) * (avg_degree / (degrees[j] + 1e-9))\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics - multiplicative and additive components\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # Introduce stochasticity based on heuristic values. Higher heuristic -> lower temperature\n    temperature = 0.1 / (heuristic_matrix + 0.01) # Avoid division by zero.  Temperature is inversely proportional to heuristic\n    random_matrix = np.random.rand(n, n) * temperature\n    heuristic_matrix += random_matrix # Adding noise to the heuristic scores\n\n    # Sparsification - more aggressive\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Higher percentile for sparsification\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    # Normalize the heuristic matrix\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 4th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest path, and adaptive degree bias.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)\n\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance).reshape(-1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove weak edges\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Controlled randomness and ensure non-zero\n    heuristic_matrix = heuristic_matrix + np.random.rand(*heuristic_matrix.shape) * 0.01\n    heuristic_matrix = np.where(heuristic_matrix <= 0, 0.0001, heuristic_matrix)\n\n    # 7. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n      heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 5th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Adaptive penalty, shortest paths, sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)\n\n    # Calculate degrees and average degree based on inverse distances\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance)\n    avg_degree = np.mean(degrees)\n\n    # Apply penalty only to edges connected to nodes with above-average degree\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))  # Reduced penalty\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))  # Reduced penalty\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove weak edges based on percentile\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 25)  # More aggressive\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n      heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 6th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Adaptive penalty, shortest paths, sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive Degree Bias\n    degree_penalty = np.ones_like(distance_matrix)\n\n    # Calculate degrees and average degree based on inverse distances\n    degrees = np.sum(inverse_distance, axis=1) - np.diag(inverse_distance)\n    avg_degree = np.mean(degrees)\n\n    # Apply penalty only to edges connected to nodes with above-average degree\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if degrees[i] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[i] + 1e-9))  # Reduced penalty\n                if degrees[j] > avg_degree:\n                    degree_penalty[i, j] *= max(0.1, avg_degree / (degrees[j] + 1e-9))  # Reduced penalty\n\n    # 4. Combine heuristics: Favor short edges on short paths, penalized by degree\n    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)\n\n    # 5. Sparsification: Remove weak edges based on percentile\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 25)  # More aggressive\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n      heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 7th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest paths, adaptive degree penalty, sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive degree bias\n    degree_penalty = np.ones_like(distance_matrix)\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n\n                if degree_i > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_i + 1e-9))\n                if degree_j > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_j + 1e-9))\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance**1.2 * degree_penalty / (shortest_paths + 1e-9)**0.8\n\n    # 5. Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    # 7. Controlled Randomness\n    if np.sum(heuristic_matrix > 0) < n:\n        random_matrix = np.random.rand(n, n) * 0.1\n        heuristic_matrix += random_matrix\n        max_heuristic = np.max(heuristic_matrix)\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 8th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, shortest paths, adaptive degree penalty, sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # 2. Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # 3. Adaptive degree bias\n    degree_penalty = np.ones_like(distance_matrix)\n    avg_degree = 0\n    for i in range(n):\n        degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n        avg_degree += degree_i\n    avg_degree /= n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i, i]\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j, j]\n\n                if degree_i > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_i + 1e-9))\n                if degree_j > 1.5 * avg_degree:\n                    degree_penalty[i, j] *= max(0.5, avg_degree / (degree_j + 1e-9))\n            else:\n                degree_penalty[i, j] = 0\n\n    # 4. Combine heuristics\n    heuristic_matrix = inverse_distance**1.2 * degree_penalty / (shortest_paths + 1e-9)**0.8\n\n    # 5. Sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # 6. Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    # 7. Controlled Randomness\n    if np.sum(heuristic_matrix > 0) < n:\n        random_matrix = np.random.rand(n, n) * 0.1\n        heuristic_matrix += random_matrix\n        max_heuristic = np.max(heuristic_matrix)\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 9th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths, and node potential with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9)) # Ensure penalty is never zero to avoid division by zero later\n                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Node potential (a global heuristic - closeness centrality approximation)\n    total_distance = np.sum(distance_matrix, axis=1)\n    node_potential = np.mean(total_distance) / (total_distance + 1e-9)\n    potential_matrix = np.outer(node_potential, node_potential)\n\n    # Combination strategy: weighted geometric mean\n    alpha = 0.6\n    beta = 0.3\n    gamma = 0.1 #weights\n\n    heuristic_matrix = (inverse_distance**alpha) * (degree_penalty**beta) * (potential_matrix**(gamma)) / (shortest_paths + 1e-9)\n\n\n    # Sparsification (adaptive threshold)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjusted percentile\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    # Post-Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 10th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths, and node potential with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9)) # Ensure penalty is never zero to avoid division by zero later\n                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Node potential (a global heuristic - closeness centrality approximation)\n    total_distance = np.sum(distance_matrix, axis=1)\n    node_potential = np.mean(total_distance) / (total_distance + 1e-9)\n    potential_matrix = np.outer(node_potential, node_potential)\n\n    # Combination strategy: weighted geometric mean\n    alpha = 0.6\n    beta = 0.3\n    gamma = 0.1 #weights\n\n    heuristic_matrix = (inverse_distance**alpha) * (degree_penalty**beta) * (potential_matrix**(gamma)) / (shortest_paths + 1e-9)\n\n\n    # Sparsification (adaptive threshold)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjusted percentile\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    # Post-Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 11th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, inverse_distance_epsilon: float = 4.892960093309955e-09, degree_penalty_epsilon: float = 6.176150985278622e-09, shortest_paths_exp_divisor: float = 1.4551410131086657, sparsification_percentile: float = 78.95315541183543, normalization_epsilon: float = 1.197423398474004e-09) -> np.ndarray:\n    \"\"\"Combines inverse distance, shortest paths, and adaptive degree penalty.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + inverse_distance_epsilon)\n\n    # Shortest paths (Dijkstra's)\n    shortest_paths = np.zeros((n, n))\n    for i in range(n):\n        dist = np.full(n, np.inf)\n        visited = np.zeros(n, dtype=bool)\n        dist[i] = 0\n        for _ in range(n):\n            u = np.argmin(dist + visited * np.inf)\n            visited[u] = True\n            for v in range(n):\n                if distance_matrix[u, v] > 0 and dist[v] > dist[u] + distance_matrix[u, v]:\n                    dist[v] = dist[u] + distance_matrix[u, v]\n        shortest_paths[i, :] = dist\n\n    # Node degree (inverse distance based)\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n    mean_distance = np.mean(distance_matrix[distance_matrix > 0])\n\n    if shortest_paths_exp_divisor is None:\n        shortest_paths_exp_divisor = mean_distance\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                h = inverse_distance[i, j]\n\n                # Adaptive degree penalty\n                degree_penalty = 1 / (np.sqrt(node_degree[i] * node_degree[j]) + degree_penalty_epsilon)\n                h *= degree_penalty\n\n                # Favor edges on shorter paths\n                h *= np.exp(-shortest_paths[i, j] / shortest_paths_exp_divisor)\n\n                heuristics[i, j] = h\n\n    # Normalize\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + normalization_epsilon)\n\n    # Sparsify based on percentile threshold.  More aggressive sparsification.\n    threshold = np.percentile(heuristics[heuristics > 0], sparsification_percentile)\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 12th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, inverse_distance_epsilon: float = 4.892960093309955e-09, degree_penalty_epsilon: float = 6.176150985278622e-09, shortest_paths_exp_divisor: float = 1.4551410131086657, sparsification_percentile: float = 78.95315541183543, normalization_epsilon: float = 1.197423398474004e-09) -> np.ndarray:\n    \"\"\"Combines inverse distance, shortest paths, and adaptive degree penalty.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + inverse_distance_epsilon)\n\n    # Shortest paths (Dijkstra's)\n    shortest_paths = np.zeros((n, n))\n    for i in range(n):\n        dist = np.full(n, np.inf)\n        visited = np.zeros(n, dtype=bool)\n        dist[i] = 0\n        for _ in range(n):\n            u = np.argmin(dist + visited * np.inf)\n            visited[u] = True\n            for v in range(n):\n                if distance_matrix[u, v] > 0 and dist[v] > dist[u] + distance_matrix[u, v]:\n                    dist[v] = dist[u] + distance_matrix[u, v]\n        shortest_paths[i, :] = dist\n\n    # Node degree (inverse distance based)\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n    mean_distance = np.mean(distance_matrix[distance_matrix > 0])\n\n    if shortest_paths_exp_divisor is None:\n        shortest_paths_exp_divisor = mean_distance\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                h = inverse_distance[i, j]\n\n                # Adaptive degree penalty\n                degree_penalty = 1 / (np.sqrt(node_degree[i] * node_degree[j]) + degree_penalty_epsilon)\n                h *= degree_penalty\n\n                # Favor edges on shorter paths\n                h *= np.exp(-shortest_paths[i, j] / shortest_paths_exp_divisor)\n\n                heuristics[i, j] = h\n\n    # Normalize\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + normalization_epsilon)\n\n    # Sparsify based on percentile threshold.  More aggressive sparsification.\n    threshold = np.percentile(heuristics[heuristics > 0], sparsification_percentile)\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 13th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"Combines inverse distance, shortest paths, and adaptive degree penalty.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest paths (Dijkstra's)\n    shortest_paths = np.zeros((n, n))\n    for i in range(n):\n        dist = np.full(n, np.inf)\n        visited = np.zeros(n, dtype=bool)\n        dist[i] = 0\n        for _ in range(n):\n            u = np.argmin(dist + visited * np.inf)\n            visited[u] = True\n            for v in range(n):\n                if distance_matrix[u, v] > 0 and dist[v] > dist[u] + distance_matrix[u, v]:\n                    dist[v] = dist[u] + distance_matrix[u, v]\n        shortest_paths[i, :] = dist\n\n    # Node degree (inverse distance based)\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n    mean_distance = np.mean(distance_matrix[distance_matrix > 0])\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                h = inverse_distance[i, j]\n\n                # Adaptive degree penalty\n                degree_penalty = 1 / (np.sqrt(node_degree[i] * node_degree[j]) + 1e-9)\n                h *= degree_penalty\n\n                # Favor edges on shorter paths\n                h *= np.exp(-shortest_paths[i, j] / mean_distance)\n\n                heuristics[i, j] = h\n\n    # Normalize\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + 1e-9)\n\n    # Sparsify based on percentile threshold.  More aggressive sparsification.\n    threshold = np.percentile(heuristics[heuristics > 0], 50)\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 14th]\nimport numpy as np\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, shortest path estimates, and adaptive degree penalty.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Inverse distance\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n) * 1e-6)\n    np.fill_diagonal(inverse_distance, 0)\n\n    # Shortest path estimates (using Dijkstra)\n    shortest_paths = dijkstra(distance_matrix, return_predecessors=False)\n    max_path_length = np.max(shortest_paths[np.isfinite(shortest_paths)])\n    path_penalty = shortest_paths / max_path_length  # Normalize to [0, 1]\n\n    # Node Degree as adaptive penalty\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n) * 1e-6), axis=1)\n    degree_penalty = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            degree_penalty[i, j] = np.sqrt(node_degree[i] * node_degree[j])\n\n    heuristic_matrix = inverse_distance * (1 - path_penalty)  # Combine inverse dist and shortest path\n    heuristic_matrix = heuristic_matrix / (1 + degree_penalty) # Apply adaptive degree penalty\n\n    # Normalize\n    heuristic_matrix = (heuristic_matrix + 1e-9) / np.sum(heuristic_matrix + 1e-9)\n\n    # Sparsification via percentile\n    threshold = np.percentile(heuristic_matrix, 75)\n    heuristic_matrix[heuristic_matrix < threshold] = 0.0\n\n    return heuristic_matrix\n\n[Heuristics 15th]\nimport numpy as np\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, shortest path estimates, and adaptive degree penalty.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # Inverse distance\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n) * 1e-6)\n    np.fill_diagonal(inverse_distance, 0)\n\n    # Shortest path estimates (using Dijkstra)\n    shortest_paths = dijkstra(distance_matrix, return_predecessors=False)\n    max_path_length = np.max(shortest_paths[np.isfinite(shortest_paths)])\n    path_penalty = shortest_paths / max_path_length  # Normalize to [0, 1]\n\n    # Node Degree as adaptive penalty\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n) * 1e-6), axis=1)\n    degree_penalty = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            degree_penalty[i, j] = np.sqrt(node_degree[i] * node_degree[j])\n\n    heuristic_matrix = inverse_distance * (1 - path_penalty)  # Combine inverse dist and shortest path\n    heuristic_matrix = heuristic_matrix / (1 + degree_penalty) # Apply adaptive degree penalty\n\n    # Normalize\n    heuristic_matrix = (heuristic_matrix + 1e-9) / np.sum(heuristic_matrix + 1e-9)\n\n    # Sparsification via percentile\n    threshold = np.percentile(heuristic_matrix, 75)\n    heuristic_matrix[heuristic_matrix < threshold] = 0.0\n\n    return heuristic_matrix\n\n[Heuristics 16th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths, and pheromone-inspired updates.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias\n    degree_penalty = np.ones((n, n))\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9))  # Avoid zero division and ensure a minimum penalty\n                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))\n                degree_penalty[i, j] = penalty_i * penalty_j\n            else:\n                degree_penalty[i, j] = 0\n\n    # Pheromone-inspired component (initialized to a small value)\n    pheromone_influence = np.ones_like(distance_matrix) * 0.01\n\n\n    # Heuristic combination (weighted sum)\n    alpha = 0.5  # Weight for distance/degree\n    beta = 0.3   # Weight for shortest path\n    gamma = 0.2  # Weight for pheromone\n\n    heuristic_matrix = (alpha * inverse_distance * degree_penalty) + \\\n                       (beta * (1 / (shortest_paths + 1e-9))) + \\\n                       (gamma * pheromone_influence)\n\n\n    # Sparsification (more aggressive)\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 40) # Increase sparsification\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n\n    # Normalize\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 17th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Dijkstra shortest paths, inverse distance, adaptive degree penalty.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Dijkstra shortest path heuristic\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = np.zeros_like(distance_matrix)\n    for i in range(n):\n        shortest_paths[i] = dijkstra(graph, indices=i, unweighted=False)\n\n    heuristic_matrix = 1 / (distance_matrix + 1e-9) + 1 / (shortest_paths + 1e-9)\n\n    # Adaptive Node degree penalty\n    row_sums = np.sum(distance_matrix, axis=1)\n    mean_row_sum = np.mean(row_sums)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if row_sums[i] > mean_row_sum and row_sums[j] > mean_row_sum:\n                    penalty = (row_sums[i] + row_sums[j]) / (2 * mean_row_sum)\n                    heuristic_matrix[i, j] /= penalty\n\n    # Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    heuristic_matrix /= max_heuristic\n    return heuristic_matrix\n\n[Heuristics 18th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Dijkstra shortest paths, inverse distance, adaptive degree penalty.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Dijkstra shortest path heuristic\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = np.zeros_like(distance_matrix)\n    for i in range(n):\n        shortest_paths[i] = dijkstra(graph, indices=i, unweighted=False)\n\n    heuristic_matrix = 1 / (distance_matrix + 1e-9) + 1 / (shortest_paths + 1e-9)\n\n    # Adaptive Node degree penalty\n    row_sums = np.sum(distance_matrix, axis=1)\n    mean_row_sum = np.mean(row_sums)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                if row_sums[i] > mean_row_sum and row_sums[j] > mean_row_sum:\n                    penalty = (row_sums[i] + row_sums[j]) / (2 * mean_row_sum)\n                    heuristic_matrix[i, j] /= penalty\n\n    # Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    heuristic_matrix /= max_heuristic\n    return heuristic_matrix\n\n[Heuristics 19th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths,\n    and node potential with controlled sparsification and temperature scaling.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance with a small constant to avoid division by zero\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias (penalize high-degree nodes, encourage exploration)\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    degree_penalty = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_penalty[i, j] = max(0.1, avg_degree / (degrees[i] * degrees[j] + 1e-9))  #Min penalty to avoid div by zero problems\n            else:\n                degree_penalty[i, j] = 0\n\n    # Node potential (estimate of node \"importance\" based on connections)\n    node_potential = np.sum(inverse_distance, axis=0)  # Sum of inverse distances to each node\n    node_potential_matrix = np.outer(node_potential, node_potential)\n\n    # Combine heuristics (weighted combination)\n    alpha = 0.6  # Weight for inverse distance\n    beta = 0.2   # Weight for degree penalty\n    gamma = 0.2  # Weight for node potential\n\n    heuristic_matrix = (alpha * inverse_distance +\n                        beta * degree_penalty +\n                        gamma * node_potential_matrix / (shortest_paths + 1e-9)) # Avoid div by 0\n\n\n    # Sparsification (remove less promising edges)\n    temperature = 0.8 # Control level of sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], temperature*20)  # Adjust percentile\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Post-Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n[Heuristics 20th]\nimport numpy as np\nimport scipy.sparse\nfrom scipy.sparse.csgraph import dijkstra\n\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths,\n    and node potential with controlled sparsification and temperature scaling.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance with a small constant to avoid division by zero\n    inverse_distance = 1 / (distance_matrix + 1e-9)\n\n    # Shortest path estimate (Dijkstra)\n    graph = scipy.sparse.csr_matrix(distance_matrix)\n    shortest_paths = dijkstra(graph, directed=False, indices=range(n))\n\n    # Adaptive degree bias (penalize high-degree nodes, encourage exploration)\n    degrees = np.sum(inverse_distance, axis=1)\n    avg_degree = np.mean(degrees)\n    degree_penalty = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                degree_penalty[i, j] = max(0.1, avg_degree / (degrees[i] * degrees[j] + 1e-9))  #Min penalty to avoid div by zero problems\n            else:\n                degree_penalty[i, j] = 0\n\n    # Node potential (estimate of node \"importance\" based on connections)\n    node_potential = np.sum(inverse_distance, axis=0)  # Sum of inverse distances to each node\n    node_potential_matrix = np.outer(node_potential, node_potential)\n\n    # Combine heuristics (weighted combination)\n    alpha = 0.6  # Weight for inverse distance\n    beta = 0.2   # Weight for degree penalty\n    gamma = 0.2  # Weight for node potential\n\n    heuristic_matrix = (alpha * inverse_distance +\n                        beta * degree_penalty +\n                        gamma * node_potential_matrix / (shortest_paths + 1e-9)) # Avoid div by 0\n\n\n    # Sparsification (remove less promising edges)\n    temperature = 0.8 # Control level of sparsification\n    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], temperature*20)  # Adjust percentile\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    # Post-Normalization\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n\n    return heuristic_matrix\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}