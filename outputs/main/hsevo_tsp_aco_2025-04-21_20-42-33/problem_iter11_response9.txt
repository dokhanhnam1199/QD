```python
import numpy as np
import scipy.sparse
from scipy.sparse.linalg import dijkstra

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """TSP heuristic: Combines inverse distance, degree bias, shortest paths, randomness, adaptive sparsification, normalization."""
    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Inverse distance
    inverse_distance = 1 / (distance_matrix + 1e-9)

    # Shortest path estimate (Dijkstra)
    graph = scipy.sparse.csr_matrix(distance_matrix)
    shortest_paths = dijkstra(graph, directed=False, indices=range(n))

    # Degree bias - adaptive
    degree_penalty = np.ones((n, n))
    degrees = np.sum(inverse_distance, axis=1)
    avg_degree = np.mean(degrees)
    alpha = 0.5  # Adjustable parameter for degree influence
    for i in range(n):
        for j in range(n):
            if i != j:
                penalty_i = max(0.1, avg_degree / (degrees[i] + 1e-9))
                penalty_j = max(0.1, avg_degree / (degrees[j] + 1e-9))
                degree_penalty[i, j] = (penalty_i * penalty_j)**alpha
            else:
                degree_penalty[i, j] = 0

    # Combine heuristics
    heuristic_matrix = inverse_distance * degree_penalty / (shortest_paths + 1e-9)

    # Controlled randomness
    randomness_factor = 0.01
    random_matrix = np.random.rand(n, n) * randomness_factor
    heuristic_matrix += random_matrix

    # Adaptive sparsification (adjust percentile based on density) before normalization
    density = np.sum(heuristic_matrix > 0) / (n * n)
    percentile = max(10, min(50, 30 + (density - 0.5) * 50))
    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], percentile)
    heuristic_matrix[heuristic_matrix < threshold] = 0

    # Normalize
    max_heuristic = np.max(heuristic_matrix)
    if max_heuristic > 0:
        heuristic_matrix /= max_heuristic

    return heuristic_matrix
```
