{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for TSP based on a combination of distance, node degree,\n    and shortest path information.  Aims to identify promising edges\n    for inclusion in solutions, weighting shorter edges connecting\n    less-connected nodes more favorably.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the\n                                      distance matrix between nodes.\n                                      distance_matrix[i, j] is the distance\n                                      between node i and node j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n                    representing heuristic values for each edge. Higher\n                    values indicate more promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate node degree (number of neighbors) based on inverse distance\n    # High inverse distance = strong connection = high degree contribution\n    node_degree = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n\n    # Calculate shortest paths using Dijkstra's algorithm to estimate proximity\n    # (This could be precomputed for efficiency in a real application.)\n    shortest_paths = np.zeros((n, n))\n    for i in range(n):\n        dist = np.full(n, np.inf)\n        visited = np.zeros(n, dtype=bool)\n        dist[i] = 0\n        for _ in range(n):\n            u = np.argmin(dist + visited * np.inf)  # select minimum unseen index\n            visited[u] = True\n            for v in range(n):\n                if distance_matrix[u, v] > 0 and dist[v] > dist[u] + distance_matrix[u, v]:\n                    dist[v] = dist[u] + distance_matrix[u, v]\n\n        shortest_paths[i, :] = dist\n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Base heuristic: inverse distance.  Smaller distance = better\n                h = 1 / (distance_matrix[i, j] + 1e-9)  # Avoid division by zero\n\n                # Penalize connections between high-degree nodes\n                h *= 1 / (node_degree[i] * node_degree[j] + 1e-9)\n\n                # Favor edges that are part of a short path (less importance)\n                h *= np.exp(-shortest_paths[i,j] / np.mean(distance_matrix[distance_matrix > 0])) # Penalize edges within \"long\" min path distances\n                # assign value. The closer the two nodes are in shortest paths, the more impact it has\n\n                heuristics[i, j] = h\n    return heuristics\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more sophisticated heuristic for the Traveling Salesman Problem.\n\n    This heuristic combines several factors:\n    1. Inverse distance: Shorter distances are generally more desirable.\n    2. Node degree bias: Preferentially selects edges connected to nodes with fewer connected edges so far\n    3. Global average distance: Adjusts edge weights based on the overall average distance in the matrix.  Edges significantly shorter than average are boosted.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i, j] is the distance between node i and node j.  Inf or 0 indicates no direct connection. Diagonal elements should be Inf.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                      indicates how promising that edge is. Higher values indicate more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse distance\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Avoid division by zero\n\n    # 2. Degree bias (initially uniform). Later to be adjusted iteratively, but not within the pure heuristic function. This simulates the concept of \"nearest neighbor\" like behavior.\n    degree_bias = np.ones((n, n))\n\n    # 3. Global average distance (robustly calculated)\n    valid_distances = distance_matrix[distance_matrix != np.inf]\n    avg_distance = np.mean(valid_distances) if valid_distances.size > 0 else 0.0 # in case all edges are blocked\n\n    # Combine the factors. Significantly shorter edges get a boost.\n    heuristic_matrix = inverse_distance * degree_bias * (1 + np.maximum(0.0, (avg_distance - distance_matrix) / avg_distance))\n\n    # Ensure no connection to self\n    for i in range(n):\n        heuristic_matrix[i, i] = 0.0  # No loops\n\n    return heuristic_matrix\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more sophisticated heuristic for the Traveling Salesman Problem (TSP).\n\n    This version considers:\n    1. Inverse distance (as in v1): Shorter distances are more desirable.\n    2. Node degree desirability: Nodes with fewer close neighbors should be prioritized\n       to be connected early, preventing them from being isolated later.  This\n       encourages a more globally optimal arrangement.\n    3. Avoid long edges to already well-connected nodes: Edges connecting to high-degree nodes are penalized proportionally to their length.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i, j]\n                                      is the distance between node i and node j.\n                                      It is assumed that distance_matrix[i, i] = np.inf.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                    represents the desirability of including the corresponding edge\n                    in a TSP solution. Higher values indicate more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # 1. Inverse Distance: Base desirability on the inverse of the distance.  Avoid division by zero by adding a small constant to the denominator.\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)\n\n    # 2. Node Degree Desirability\n    neighbor_counts = np.sum(distance_matrix < np.mean(distance_matrix[distance_matrix != np.inf]), axis=0)  # Count the neighbors each node has within a reasonable mean distance.\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Prioritize edges connecting to nodes with few neighbors\n                heuristic_matrix[i, j] *= (1 + (n - neighbor_counts[i] - neighbor_counts[j])/n) #Boost for poorly connected nodes. Avoid connecting poorly connected nodes with poorly connected nodes.\n\n    #3. Penalize Long edges to already well-connected nodes\n    for i in range(n):\n        for j in range(n):\n            if i!= j:\n                heuristic_matrix[i, j] /= (1 + (distance_matrix[i,j] * neighbor_counts[i]/n) +  (distance_matrix[i,j] * neighbor_counts[j]/n))\n\n\n\n    return heuristic_matrix\n\n[Heuristics 4th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a heuristic function for the Traveling Salesman Problem (TSP).\n    This function prioritizes shorter edges and penalizes edges that are\n    part of longer connections between nodes. It also adds a small amount\n    of randomness to avoid getting stuck in local optima and ensures a non-zero heuristic value.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i][j]\n                                       represents the distance between node i and node j.\n\n    Returns:\n        np.ndarray: A heuristic matrix of the same shape as the distance_matrix,\n                      representing the desirability of including each edge in the solution.\n    \"\"\"\n\n    # Avoid division by zero\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n\n    # Prioritize shorter edges (inverse of distance)\n    heuristic = 1 / distance_matrix\n\n    # Penalize edges part of longer paths to discourage long detours.\n    # We consider the shortest path length between other nodes besides i and j.\n    # The longer the paths, the greater the penalization of edge(i,j).\n    num_nodes = distance_matrix.shape[0]\n    penalty = np.zeros_like(distance_matrix)\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i != j:\n                shortest_path_sum = 0\n                for k in range(num_nodes):\n                    if k != i and k != j:\n                        min_dist_k = np.inf\n                        for l in range(num_nodes):\n                            if l != i and l != j and l != k:\n                                min_dist_k = min(min_dist_k, distance_matrix[k][l])\n                        shortest_path_sum += min_dist_k\n                penalty[i][j] = shortest_path_sum / (num_nodes - 2) if (num_nodes > 2) else 0\n\n\n    penalty = penalty / np.max(penalty) if np.max(penalty) > 0 else 0 # Normalize for balanced influence\n\n    heuristic = heuristic * (1 - 0.5 * penalty)  # Reduce weight on edge(i,j) based on the shortest path sum penalty.\n\n    # Add small random factor to avoid local optima\n    heuristic = heuristic + np.random.rand(*heuristic.shape) * 0.01\n\n    # Ensure the heuristic is not zero (important for stochastic sampling)\n    heuristic = np.where(heuristic <= 0, 0.0001, heuristic)\n\n    return heuristic\n\n[Heuristics 5th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Newtonian Heuristic for TSP.\n\n    Inspired by gravitational force and shortest path principles.\n    Edges between closer nodes are more attractive (higher heuristic value),\n    and nodes in sparsely connected regions get a boost to encourage exploration.\n\n    Args:\n        distance_matrix: A numpy array representing the distance matrix of the TSP.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix, representing heuristic values for each edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # 1. Inverse distance, akin to gravitational attraction\n    heuristics = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero.\n\n    # 2. Connectivity boost - encourage exploration of sparser regions.  Nodes with higher connection cost receive higher boost.\n    #    This will use the sum of row elements as the connection costs\n    row_sums = np.sum(distance_matrix, axis=1)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] *= (row_sums[i] + row_sums[j]) / (2 * np.mean(row_sums))  # Normalized scaling factor\n\n    # 3. Normalization\n    max_heuristic = np.max(heuristics)\n    heuristics /= max_heuristic\n\n    return heuristics\n\n[Heuristics 6th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Newtonian Heuristic for TSP.\n\n    Inspired by gravitational force and shortest path principles.\n    Edges between closer nodes are more attractive (higher heuristic value),\n    and nodes in sparsely connected regions get a boost to encourage exploration.\n\n    Args:\n        distance_matrix: A numpy array representing the distance matrix of the TSP.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix, representing heuristic values for each edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # 1. Inverse distance, akin to gravitational attraction\n    heuristics = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero.\n\n    # 2. Connectivity boost - encourage exploration of sparser regions.  Nodes with higher connection cost receive higher boost.\n    #    This will use the sum of row elements as the connection costs\n    row_sums = np.sum(distance_matrix, axis=1)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] *= (row_sums[i] + row_sums[j]) / (2 * np.mean(row_sums))  # Normalized scaling factor\n\n    # 3. Normalization\n    max_heuristic = np.max(heuristics)\n    heuristics /= max_heuristic\n\n    return heuristics\n\n[Heuristics 7th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for TSP based on distance and node degree.\n\n    This version combines inverse distance with a penalty for high-degree nodes\n    to encourage a more balanced exploration of the solution space.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix between nodes.\n\n    Returns:\n        np.ndarray: Prior indicators of how promising it is to include each edge.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance heuristic\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # Degree-based penalty (encourages low-degree nodes)\n    degree_penalty = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Approximating the degree penalty based on the sum of inverse distances from each node\n                degree_i = np.sum(inverse_distance[i, :]) - inverse_distance[i,i] #subtract diagonal\n                degree_j = np.sum(inverse_distance[j, :]) - inverse_distance[j,j] #subtract diagonal\n                degree_penalty[i, j] = 1 / (degree_i * degree_j + 1e-9)  # Encourage connections to low degree nodes, avoid zero division.\n            else:\n                degree_penalty[i, j] = 0\n\n    # Combine heuristics\n    heuristic_matrix = inverse_distance * degree_penalty\n    return heuristic_matrix\n\n[Heuristics 8th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improves upon simple inverse distance by considering the average distance\n    to a node's nearest neighbors.  This favors edges that connect\n    nodes to their closer neighbors, increasing the likelihood of\n    locally optimal segments.  Also introduces a small amount of random\n    noise to encourage exploration.\n\n    Args:\n        distance_matrix: A numpy ndarray representing the distance matrix.\n\n    Returns:\n        A numpy ndarray of the same shape as the input, representing\n        prior indicators of how promising each edge is.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    for i in range(n):\n        # Find nearest neighbors for node i, excluding itself.\n        neighbors = np.argsort(distance_matrix[i, :])[1:min(4, n)]  # Top 3 nearest neighbors (or fewer if n < 4)\n\n        # Calculate the average distance to the nearest neighbors.\n        avg_neighbor_distance = np.mean(distance_matrix[i, neighbors])\n\n        for j in range(n):\n            if i != j:\n                # Heuristic is the inverse of the distance, adjusted by the\n                # average distance to nearest neighbors. The closer the neighbors on average,\n                # the higher the weighting. The closer two given nodes (i and j), the higher the weighting.\n                # The adjustment also ensures we favor more densely connected graphs by giving them an edge.\n                heuristics[i, j] = (avg_neighbor_distance / distance_matrix[i, j])\n\n                # Add some noise to the heuristic value to explore potentially suboptimal paths\n                noise = np.random.normal(0, 0.05)\n                heuristics[i, j] += noise\n\n                # Ensure the values are not zero.\n                heuristics[i, j] = max(heuristics[i, j], 0.0001) # Prevents zero divide, gives a base value.\n\n    return heuristics\n\n[Heuristics 9th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more sophisticated heuristic for the Traveling Salesman Problem (TSP).\n    This version combines inverse distance with a node centrality measure\n    to estimate the desirability of including each edge in the tour.\n    Feynman's stochastic sampling hints, informed by \"potentiality.\"\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse distance: Closer cities are generally better connected.\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n)) # avoid division by zero and self-loops\n    np.fill_diagonal(inverse_distance, 0) #remove self-loops\n\n    # 2. Node centrality (degree centrality approximation): Nodes that are \n    #    centrally located tend to have shorter paths.  Approximate degree\n    #    centrality using inverse sum of distances from each node. This\n    #    captures nodes close to other nodes, thereby reduces total path lengths.\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality_matrix = np.outer(node_centrality, node_centrality)\n\n    # 3. Combine the two factors.  Emphasize the effect of the central nodes\n    #    as it is related to reducing global path length.\n    heuristic_matrix = inverse_distance * np.sqrt(node_centrality_matrix) #Geometric Mean\n    np.fill_diagonal(heuristic_matrix, 0) # self-loop will influence stochastic sampler\n\n    # Normalize to make it a probability-like prior. Helps the stochastic sampler\n    # use the heuristic better.\n    heuristic_matrix = (heuristic_matrix + 1e-9) / np.sum(heuristic_matrix + 1e-9)  #Adding tiny values to avoid zero probability\n\n    return heuristic_matrix\n\n[Heuristics 10th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Tesla's Intuition for TSP Edge Importance.\n\n    This function estimates the \"promise\" of each edge in a TSP problem\n    based on a combination of factors: distance, neighborhood density,\n    and overall connectivity. It leverages principles of electromagnetic\n    induction (where proximity enhances interaction) and network theory.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances\n                                     between cities.  distance_matrix[i, j] is the\n                                     distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each\n                    element represents the heuristic score of including the\n                    corresponding edge in the TSP tour. Higher scores indicate\n                    more promising edges.\n\n    Technical details:\n    1. Inverse Distance: Shorter distances are generally more desirable, so we\n       start with the inverse of the distance.  This represents a basic attraction.\n    2. Neighborhood Influence: We calculate a \"neighborhood density\" for each city.\n       This is based on the idea that a city with many close neighbors might be a\n       good \"hub\" for connecting different parts of the tour. We sum the inverse\n       distances to nearby cities as a measure of neighborhood density.\n       The score is adjusted using (1 + neighbor_influence[i] + neighbor_influence[j]), so a city near highly connected hubs will have a good chance to be a part of the route.\n    3. Connectivity Reinforcement: A penalty is applied if two cities are highly inter-connected to other hubs, otherwise it will lead to sub-optimal convergence.\n\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Tesla's Principle #1: Inverse Distance\n    inverse_distance = 1.0 / (distance_matrix + 1e-6)  # Avoid division by zero\n\n    # Tesla's Principle #2: Neighborhood Influence (Electromagnetic Induction Analogy)\n    neighbor_influence = np.sum(inverse_distance, axis=1)\n\n    # Combine the factors, with a focus on local density and a tempering effect from direct distance\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = inverse_distance[i, j] * (1 + neighbor_influence[i] + neighbor_influence[j])\n            else:\n                heuristics[i, j] = 0 # Avoid self-loops\n    return heuristics\n\n[Heuristics 11th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improves upon the simple inverse distance heuristic by incorporating\n    a factor that favors edges connecting to nodes with higher average distance\n    to other nodes. This encourages connections to nodes that are more \"central\"\n    within the graph, potentially leading to shorter overall tours.\n    The intuition is to penalize choosing the shortest link between some\n    very tight cluster of nearby nodes before connecting with the rest of the points.\n\n    Args:\n        distance_matrix: A numpy array representing the distance matrix.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix, representing the heuristic values\n        for each edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    avg_distances = np.mean(distance_matrix, axis=1) # Calculate average distance from each node to all others\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] = (1 / distance_matrix[i, j]) * (avg_distances[i] + avg_distances[j]) # Scale the inverse distance\n            else:\n                heuristic_matrix[i, j] = 0.0  # No self-loops\n\n    return heuristic_matrix\n\n[Heuristics 12th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A heuristic for the Traveling Salesman Problem (TSP) that considers\n    both distance and global graph structure to estimate the desirability\n    of including each edge in the optimal tour.  It uses a combination\n    of inverse distance (basic desirability) and a measure of connectivity\n    via the shortest paths between nodes. The idea is to slightly favor edges\n    that bridge disconnected parts of the graph or connect nodes that are otherwise\n    far apart in terms of path length.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances\n                                       between nodes. distance_matrix[i, j] is the\n                                       distance between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each\n                    element represents the desirability (heuristic value) of\n                    including the corresponding edge in the TSP tour. Higher\n                    values indicate more desirable edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Basic desirability: inverse of distance\n    base_heuristic = 1.0 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # All-pairs shortest path lengths (using the distance matrix)\n    path_lengths = np.zeros((n, n))\n    for i in range(n):\n      for j in range(n):\n        path_lengths[i,j] = distance_matrix[i, j]\n    for k in range(n):\n      for i in range(n):\n        for j in range(n):\n          path_lengths[i, j] = min(path_lengths[i, j], path_lengths[i, k] + path_lengths[k, j])\n\n\n    # Connectivity bonus:\n    # The bonus is higher if nodes i and j are far apart in terms of path length,\n    # suggesting the edge (i,j) can significantly shorten the tour.\n\n    connectivity_bonus = path_lengths / (np.max(path_lengths) + 1e-9)\n\n    heuristic_matrix = base_heuristic + (1 - connectivity_bonus) # Combine with inverse distance\n    #heuristic_matrix = np.clip(heuristic_matrix, 0, 1)  # Ensure values are non-negative\n    return heuristic_matrix\n\n[Heuristics 13th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A heuristic for the Traveling Salesman Problem (TSP) that considers\n    both distance and global graph structure to estimate the desirability\n    of including each edge in the optimal tour.  It uses a combination\n    of inverse distance (basic desirability) and a measure of connectivity\n    via the shortest paths between nodes. The idea is to slightly favor edges\n    that bridge disconnected parts of the graph or connect nodes that are otherwise\n    far apart in terms of path length.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances\n                                       between nodes. distance_matrix[i, j] is the\n                                       distance between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each\n                    element represents the desirability (heuristic value) of\n                    including the corresponding edge in the TSP tour. Higher\n                    values indicate more desirable edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Basic desirability: inverse of distance\n    base_heuristic = 1.0 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # All-pairs shortest path lengths (using the distance matrix)\n    path_lengths = np.zeros((n, n))\n    for i in range(n):\n      for j in range(n):\n        path_lengths[i,j] = distance_matrix[i, j]\n    for k in range(n):\n      for i in range(n):\n        for j in range(n):\n          path_lengths[i, j] = min(path_lengths[i, j], path_lengths[i, k] + path_lengths[k, j])\n\n\n    # Connectivity bonus:\n    # The bonus is higher if nodes i and j are far apart in terms of path length,\n    # suggesting the edge (i,j) can significantly shorten the tour.\n\n    connectivity_bonus = path_lengths / (np.max(path_lengths) + 1e-9)\n\n    heuristic_matrix = base_heuristic + (1 - connectivity_bonus) # Combine with inverse distance\n    #heuristic_matrix = np.clip(heuristic_matrix, 0, 1)  # Ensure values are non-negative\n    return heuristic_matrix\n\n[Heuristics 14th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristics for TSP based on a combination of distance,\n    node degree centrality, and randomness to encourage exploration.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances\n                                        between cities. distance_matrix[i][j] is the\n                                        distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each\n                    element represents the heuristic score for including that edge\n                    in a potential TSP tour.  Higher values indicate more promising\n                    edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate node degree centrality (approximation using inverse distance sum)\n    node_centrality = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Base heuristic: inverse distance (shorter distances are better)\n                h = 1 / distance_matrix[i, j]\n\n                # Incorporate node centrality: Preferentially connect to \"important\" nodes\n                # This is normalized so edges between higher degree nodes don't dominate\n\n                h *= (np.sqrt(node_centrality[i] * node_centrality[j])) #Geometric Mean\n                # Small random component to introduce exploration, especially early on\n                h += np.random.rand() * 0.1\n                heuristics[i, j] = h\n\n    return heuristics\n\n[Heuristics 15th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristics for TSP based on a combination of distance,\n    node degree centrality, and randomness to encourage exploration.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances\n                                        between cities. distance_matrix[i][j] is the\n                                        distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each\n                    element represents the heuristic score for including that edge\n                    in a potential TSP tour.  Higher values indicate more promising\n                    edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate node degree centrality (approximation using inverse distance sum)\n    node_centrality = np.sum(1 / (distance_matrix + np.eye(n)), axis=1)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Base heuristic: inverse distance (shorter distances are better)\n                h = 1 / distance_matrix[i, j]\n\n                # Incorporate node centrality: Preferentially connect to \"important\" nodes\n                # This is normalized so edges between higher degree nodes don't dominate\n\n                h *= (np.sqrt(node_centrality[i] * node_centrality[j])) #Geometric Mean\n                # Small random component to introduce exploration, especially early on\n                h += np.random.rand() * 0.1\n                heuristics[i, j] = h\n\n    return heuristics\n\n[Heuristics 16th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more sophisticated heuristics for the Traveling Salesman Problem.\n    This version considers a combination of inverse distance and node degree.\n\n    Args:\n        distance_matrix: A numpy array representing the distance between cities.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix, representing the\n        prior indicators of how promising it is to include each edge in a solution.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse Distance: Closer cities are more attractive.  Avoid divide by zero.\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))  # Add identity to avoid div by zero for self-loops\n    inverse_distance[np.diag_indices_from(inverse_distance)] = 0.0  # Ensure diagonal is zero\n\n    # 2. Nearest Neighbor Consideration: Promote edges connecting to nodes with few close neighbors.\n    #    This encourages visiting sparsely connected areas early.  A low degree\n    #    implies that connecting to this node is crucial, whereas a high-degree\n    #    is that this node will surely be linked with a lot of nodes.\n\n    # Sort distances from each city and find the indices of the k nearest neighbors\n    k = min(5, n - 1)  # Consider the k nearest neighbors, at most 5 or n-1.\n    nearest_neighbors = np.argsort(distance_matrix, axis=1)[:, 1:k + 1] # Exclude the city itself\n\n    # Calculate the sum of the inverse distances to the k nearest neighbors for each city.\n    # Higher sum implies the city has close neighbors.\n    neighbor_attractiveness = np.zeros((n, n))\n    for i in range(n):\n        total_neighbor_distance = np.sum(1.0 / distance_matrix[i, nearest_neighbors[i]])\n        for j in range(n):\n            if i != j:\n                neighbor_attractiveness[i,j] = total_neighbor_distance\n            else:\n                neighbor_attractiveness[i, j] = 0\n\n    # Normalize the neighbour attractiveness so the scaling factor would not overwhelm\n    # the inverse distance\n    neighbor_attractiveness_normalized = (neighbor_attractiveness - np.min(neighbor_attractiveness)) / (np.max(neighbor_attractiveness) - np.min(neighbor_attractiveness)) if np.max(neighbor_attractiveness) != np.min(neighbor_attractiveness) else np.zeros((n,n))\n\n    neighbor_attractiveness_scaled = 1 - neighbor_attractiveness_normalized  # Inverted to make smaller neighbour attractive values higher\n\n    # 3. Combine heuristics:  Inverse distance is primary, adjust with neighbor consideration.\n    # Consider a weighted average or multiplication of the two.  Multiplication\n    # appears more suitable in this context.\n\n    heuristics = inverse_distance * (1+neighbor_attractiveness_scaled) # Amplifying the effect of neighbour attractivness\n\n    return heuristics\n\n[Heuristics 17th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics function for solving the Traveling Salesman Problem (TSP)\n    via stochastic solution sampling. This version incorporates several\n    ideas to improve the quality of the edge priors:\n\n    1.  Inverse distance, as closer cities are more likely to be neighbors\n    2.  Edge Centrality: Edges that lie on shorter paths between many nodes are preferable\n    3.  Nearest Neighbor: Each node is more likely connected with its nearest neighbors\n    4.  A slight global randomization, allowing escaping from local minima.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n            matrix between cities. distance_matrix[i][j] is the distance\n            between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n            representing the prior probabilities (or heuristic scores) for\n            including each edge in a solution.  Higher values indicate a\n            more promising edge.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n\n    # 2. Edge Centrality heuristic: approximated via closeness centrality\n\n    # Calculate shortest paths between all pairs of nodes using Floyd-Warshall algorithm, inspired from internet\n    dist = np.copy(distance_matrix)\n    for k in range(n):\n      for i in range(n):\n        for j in range(n):\n          dist[i, j] = min(dist[i, j], dist[i, k] + dist[k, j])\n\n    closeness_centrality = np.zeros((n,n))\n    for i in range(n):\n      for j in range(n):\n        closeness_centrality[i][j] = 1/(dist[i,j] + 1e-9)\n\n\n    # 3. Nearest Neighbor heuristic.  Each node is more likely to be connected to its nearest neighbors.\n    nearest_neighbors = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        # Find the indices of the k-nearest neighbors (excluding itself). Let k be 3\n        k = min(3, n-1) # Handle the edge case that n can be smaller than 3\n\n        neighbors = np.argpartition(distance_matrix[i], k+1)[:k+1]\n        neighbors = neighbors[neighbors != i]\n        if len(neighbors)> 0:\n\n          for j in neighbors:\n            nearest_neighbors[i][j] = 1 # Prioritize to connect to neighbors.\n\n    #4. Incorporate heuristics scores\n    heuristics = inverse_distance + closeness_centrality + nearest_neighbors\n    # Normalize to be between 0 and 1\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + 1e-9)\n\n    # 5. Add a small amount of randomness to allow exploring different routes\n    randomness = np.random.rand(n, n) * 0.1\n    heuristics += randomness\n    heuristics = np.clip(heuristics, 0, 1)  # Clip values to be within [0, 1]\n\n    return heuristics\n\n[Heuristics 18th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics function for solving the Traveling Salesman Problem (TSP)\n    via stochastic solution sampling. This version incorporates several\n    ideas to improve the quality of the edge priors:\n\n    1.  Inverse distance, as closer cities are more likely to be neighbors\n    2.  Edge Centrality: Edges that lie on shorter paths between many nodes are preferable\n    3.  Nearest Neighbor: Each node is more likely connected with its nearest neighbors\n    4.  A slight global randomization, allowing escaping from local minima.\n\n    Args:\n        distance_matrix (np.ndarray): A 2D numpy array representing the distance\n            matrix between cities. distance_matrix[i][j] is the distance\n            between city i and city j.\n\n    Returns:\n        np.ndarray: A 2D numpy array of the same shape as distance_matrix,\n            representing the prior probabilities (or heuristic scores) for\n            including each edge in a solution.  Higher values indicate a\n            more promising edge.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n\n    # 2. Edge Centrality heuristic: approximated via closeness centrality\n\n    # Calculate shortest paths between all pairs of nodes using Floyd-Warshall algorithm, inspired from internet\n    dist = np.copy(distance_matrix)\n    for k in range(n):\n      for i in range(n):\n        for j in range(n):\n          dist[i, j] = min(dist[i, j], dist[i, k] + dist[k, j])\n\n    closeness_centrality = np.zeros((n,n))\n    for i in range(n):\n      for j in range(n):\n        closeness_centrality[i][j] = 1/(dist[i,j] + 1e-9)\n\n\n    # 3. Nearest Neighbor heuristic.  Each node is more likely to be connected to its nearest neighbors.\n    nearest_neighbors = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        # Find the indices of the k-nearest neighbors (excluding itself). Let k be 3\n        k = min(3, n-1) # Handle the edge case that n can be smaller than 3\n\n        neighbors = np.argpartition(distance_matrix[i], k+1)[:k+1]\n        neighbors = neighbors[neighbors != i]\n        if len(neighbors)> 0:\n\n          for j in neighbors:\n            nearest_neighbors[i][j] = 1 # Prioritize to connect to neighbors.\n\n    #4. Incorporate heuristics scores\n    heuristics = inverse_distance + closeness_centrality + nearest_neighbors\n    # Normalize to be between 0 and 1\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics) + 1e-9)\n\n    # 5. Add a small amount of randomness to allow exploring different routes\n    randomness = np.random.rand(n, n) * 0.1\n    heuristics += randomness\n    heuristics = np.clip(heuristics, 0, 1)  # Clip values to be within [0, 1]\n\n    return heuristics\n\n[Heuristics 19th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improves upon the basic inverse distance heuristic by considering\n    a combination of distance, node degree, and local density to guide\n    the TSP solver.  This is done by calculating how central a particular edge is compared to the total distances from that edge.\n\n    Args:\n        distance_matrix: A numpy array representing the distance matrix\n                         for the TSP problem. distance_matrix[i, j] is the\n                         distance between city i and city j.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix, where each\n        element represents a heuristic score indicating the desirability\n        of including the corresponding edge in the TSP tour. Higher scores\n        indicate more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # Calculate a heuristic score for each edge\n    for i in range(n):\n        for j in range(n):\n            if i != j:  # Avoid self-loops\n                # Inverse distance: Shorter edges are more desirable\n                distance_term = 1 / distance_matrix[i, j]\n\n                # Calculate local density around each node. A node with low average distance is considered to have a high density\n                i_density = np.sum(1/distance_matrix[i, :])\n                j_density = np.sum(1/distance_matrix[j, :])\n                \n                # Combines the inverse distance and the density heuristic.\n\n                heuristic_matrix[i, j] = distance_term + i_density + j_density\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops\n\n    return heuristic_matrix\n\n[Heuristics 20th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hawking-inspired heuristics for the Traveling Salesman Problem (TSP).\n\n    This function employs a combination of strategies inspired by black hole physics\n    and simulated annealing to generate edge priority indicators.\n\n    The heuristic combines:\n    1. Inverse Distance: Shorter edges are generally more desirable.  Mimics the\n       basic gravitational pull - closer objects (cities) are more attractive.\n    2. Node Degree Preference: Encourages nodes with fewer close neighbors to be\n       connected early. Analogous to a black hole consuming sparsely distributed matter first.\n    3. Simulated Annealing Inspired Perturbation: Introduces randomness with a temperature\n       parameter to explore more diverse solutions and escape local optima.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # 1. Inverse Distance (Attraction)\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Avoid division by zero\n\n    # 2. Node Degree Preference (Sparse Consumption)\n    node_degrees = np.sum(inverse_distance, axis=0)\n    node_degree_matrix = np.outer(node_degrees, node_degrees)\n    degree_penalty = 1 / (node_degree_matrix + 1e-9) # Lower score to edges that are between popular nodes\n\n    # 3. Simulated Annealing Inspired Perturbation (Exploration)\n    temperature = 0.1  # Control the randomness - can tune this\n    random_perturbation = np.random.normal(0, temperature, size=(n, n))\n    \n    # Combine the factors\n    heuristic_matrix = inverse_distance * degree_penalty + random_perturbation\n    \n    # Ensure that the diagonal elements are small\n    for i in range(n):\n        heuristic_matrix[i, i] = -np.inf # Penalize self-loops\n\n    return heuristic_matrix\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}