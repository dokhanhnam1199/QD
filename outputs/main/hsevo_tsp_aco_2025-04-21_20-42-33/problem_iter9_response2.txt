```python
import numpy as np
import scipy.sparse
from scipy.sparse.csgraph import dijkstra

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    """TSP heuristic: Combines inverse distance, adaptive degree bias, shortest paths, and introduces controlled randomness."""
    n = distance_matrix.shape[0]
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Inverse distance
    inverse_distance = 1 / (distance_matrix + 1e-9)

    # Shortest path estimate (Dijkstra)
    graph = scipy.sparse.csr_matrix(distance_matrix)
    shortest_paths = dijkstra(graph, directed=False, indices=range(n))

    # Adaptive degree bias with refined penalty
    degree_penalty = np.ones((n, n))
    degrees = np.sum(inverse_distance, axis=1)
    avg_degree = np.mean(degrees)

    for i in range(n):
        for j in range(n):
            if i != j:
                penalty_i = np.clip(avg_degree / (degrees[i] + 1e-9), 0.5, 2.0)  # Clip to avoid extreme penalties
                penalty_j = np.clip(avg_degree / (degrees[j] + 1e-9), 0.5, 2.0)  # Clip to avoid extreme penalties
                degree_penalty[i, j] = penalty_i * penalty_j
            else:
                degree_penalty[i, j] = 0

    # Controlled randomness to escape local optima
    randomness = np.random.rand(n, n) * 0.1  # Scale randomness

    # Combine heuristics with weighted components
    heuristic_matrix = (0.6 * inverse_distance) + (0.3 * (inverse_distance * degree_penalty)) - (0.1 * (shortest_paths / np.max(shortest_paths + 1e-9))) + randomness


    # Sparsification - applied earlier for efficiency and exploration
    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 30) # Adjust percentile
    heuristic_matrix[heuristic_matrix < threshold] = 0

    # Normalize
    max_heuristic = np.max(heuristic_matrix)
    if max_heuristic > 0:
        heuristic_matrix /= max_heuristic

    return heuristic_matrix
```
