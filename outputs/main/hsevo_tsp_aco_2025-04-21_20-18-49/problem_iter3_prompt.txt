{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\nCurrent heuristics:\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A more sophisticated heuristics function for the Traveling Salesman Problem (TSP).\n\n    This version combines several ideas inspired by physics and common-sense heuristics\n    to provide more informative edge priors.  It aims to balance exploration\n    (allowing for non-obvious edges) with exploitation (favoring short, promising edges).\n\n    Specifically, it uses:\n    1.  Inverse distance: Shorter edges are generally more desirable.\n    2.  Node degree desirability: Nodes with fewer short connections are made more desirable\n        as endpoints of edges.  This encourages exploring parts of the graph that\n        are less well-connected initially. This simulates a sort of 'attractive force'.\n    3.  Distance normalization: The 'temperature' variable adjusts how strongly we adhere to\n        short distances. At higher temperatures, we're more willing to explore longer edges.\n\n    Args:\n        distance_matrix (np.ndarray): The distance matrix representing the distances\n                                         between cities.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, representing the\n                     prior probabilities of including each edge in a solution. Higher\n                     values indicate a higher prior probability.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.mean(distance_matrix) / 2  # Adjust as needed for optimal performance\n\n    # Inverse distance, but avoid division by zero\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n\n    # Node degree desirability (attractiveness)\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness)) #Inverse normalized attractiveness to drive toward \"isolated\" nodes\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**2) * (node_attractiveness[i] * node_attractiveness[j]) * np.exp(-distance_matrix[i, j] / temperature)\n\n    return heuristics\n\nNow, think outside the box write a mutated function `heuristics_v2` better than current version.\nYou can use some hints below:\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, here's a refined concept of \"Current Self-Reflection\" aimed at improving heuristic design, focusing on actionable insights and avoiding common pitfalls:\n\n*   **Keywords:** Iterative Improvement, Performance Analysis, Adaptability, Bias Mitigation.\n*   **Advice:** Critically analyze heuristic performance across diverse problem instances. Identify strengths and weaknesses. Quantify the impact of individual components.\n*   **Avoid:** Over-reliance on intuition or anecdotal evidence. Neglecting edge cases or focusing solely on average performance. Premature optimization.\n*   **Explanation:** Effective reflection involves data-driven analysis, constant questioning of assumptions, and a commitment to refining heuristics based on empirical results. Focus on adaptability and identifying biases.\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}