{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 2.0,\n                  sparsification_factor: float = 4.733362140013519) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, and adaptive temperature.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 2.0,\n                  sparsification_factor: float = 4.733362140013519) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, and adaptive temperature.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 2.0,\n                  sparsification_factor: float = 4.733362140013519) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, and adaptive temperature.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 4th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 2.0,\n                  sparsification_factor: float = 4.733362140013519) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, and adaptive temperature.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 5th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 2.0,\n                  sparsification_factor: float = 4.733362140013519) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, and adaptive temperature.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 6th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 3.0577359152743138,\n                  sparsification_factor: float = 9.114303466623399,\n                  inverse_distance_offset: float = 1.481911274380233,\n                  node_attractiveness_scaling: float = 1.0640985991478287,\n                  node_centrality_scaling: float = 0.9287408648364465,\n                  temperature_scaling: float = 0.896782004013863) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, and adaptive temperature.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix) * temperature_scaling\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n) * inverse_distance_offset)\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness) * node_attractiveness_scaling)\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality) * node_centrality_scaling\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 3.0577359152743138,\n                  sparsification_factor: float = 9.114303466623399,\n                  inverse_distance_offset: float = 1.481911274380233,\n                  node_attractiveness_scaling: float = 1.0640985991478287,\n                  node_centrality_scaling: float = 0.9287408648364465,\n                  temperature_scaling: float = 0.896782004013863) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, and adaptive temperature.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix) * temperature_scaling\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n) * inverse_distance_offset)\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness) * node_attractiveness_scaling)\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality) * node_centrality_scaling\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 8th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    TSP heuristic: Combines inverse distance, node attractiveness,\n    centrality penalty, temperature scaling, and sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**2.0) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / 4.733362140013519\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 9th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    TSP heuristic: Combines inverse distance, node attractiveness,\n    centrality penalty, temperature scaling, and sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**2.0) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / 4.733362140013519\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 10th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    TSP heuristic: Combines inverse distance, node attractiveness,\n    centrality penalty, temperature scaling, and sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n    node_centrality_penalty = 1.0 / node_centrality\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**2.0) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality_penalty[i] * node_centrality_penalty[j]) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    threshold = np.mean(heuristics) / 4.733362140013519\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 11th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive heuristics for TSP combining inverse distance, node attractiveness, \n    and dynamic temperature with sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**2) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                    np.exp(-distance_matrix[i, j] / temperature)\n    threshold = np.mean(heuristics) / 5\n    heuristics[heuristics < threshold] = 0\n    return heuristics\n\n[Heuristics 12th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive heuristics for TSP combining inverse distance, node attractiveness, \n    and dynamic temperature with sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.median(distance_matrix)\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness))\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**2) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                    np.exp(-distance_matrix[i, j] / temperature)\n    threshold = np.mean(heuristics) / 5\n    heuristics[heuristics < threshold] = 0\n    return heuristics\n\n[Heuristics 13th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, node attractiveness, sparse connectivity bias, and pheromone.\n    Sparsifies to focus on promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n    temperature = np.mean(distance_matrix) / 2\n\n    inv_dist = 1.0 / (distance_matrix + np.eye(n))\n    node_attract = np.sum(inv_dist, axis=0)\n    node_attract = 1.0 / (node_attract / np.mean(node_attract))\n    connectivity = np.sum(inv_dist, axis=0)\n    sparse_bias = np.outer(connectivity, connectivity)\n    pheromone = np.zeros_like(distance_matrix, dtype=float)\n    shortest_dist = np.partition(distance_matrix.flatten(), n+1)[n+1]\n    pheromone[distance_matrix <= shortest_dist * 1.2] = 1.0\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = ((inv_dist[i, j]**2) *\n                                     (node_attract[i] * node_attract[j]) *\n                                     np.exp(-distance_matrix[i, j] / temperature) /\n                                     (sparse_bias[i, j] + 1e-6)) + pheromone[i, j]\n\n    threshold = np.percentile(heuristics[heuristics > 0], 20)\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 14th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, gravitational attraction, and adaptive randomness.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    epsilon = 1e-9\n    avg_distance = np.mean(distance_matrix)\n\n    inverse_distance = 1 / (distance_matrix + epsilon)\n    gravitational_attraction = 1 / ((distance_matrix**2) + epsilon)\n    temperature = avg_distance / 2 # Scale temperature relative to avg dist\n\n    # Adaptive randomness: Higher randomness for longer distances.\n    randomness = np.random.rand(n, n) * (temperature / (distance_matrix + epsilon))\n    randomness = (randomness + randomness.T) / 2\n\n    heuristic_matrix = (\n        0.4 * inverse_distance +\n        0.3 * gravitational_attraction +\n        0.3 * randomness\n    )\n\n    np.fill_diagonal(heuristic_matrix, 0)\n\n    # Normalizing heuristic matrix\n    max_h = np.max(heuristic_matrix)\n    min_h = np.min(heuristic_matrix)\n\n    if max_h > min_h:\n        heuristic_matrix = (heuristic_matrix - min_h) / (max_h - min_h)\n    return heuristic_matrix\n\n[Heuristics 15th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, gravity, adaptive temp, and sparsification.\n    Normalizes for robust performance.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    epsilon = 1e-9\n\n    # Inverse distance & Gravity\n    inverse_distance = 1.0 / (distance_matrix + epsilon)\n    gravity = 1.0 / (distance_matrix**2 + epsilon)\n\n    # Adaptive Temperature\n    temperature = np.mean(distance_matrix) / 2\n    random_matrix = np.random.rand(n, n) * temperature\n\n    # Combine and normalize\n    heuristic = inverse_distance + gravity + random_matrix\n    heuristic = heuristic / np.max(heuristic)\n\n    #Sparsification\n    threshold = np.percentile(heuristic, 75)\n    heuristic[heuristic < threshold] = 0\n\n    return heuristic\n\n[Heuristics 16th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distance, node attractiveness, and adaptive temperature for TSP.\n    Sparsifies based on percentile of combined heuristic matrix.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    epsilon = 1e-9\n\n    inverse_distance = 1.0 / (distance_matrix + epsilon)\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = 1.0 / (node_attractiveness / np.mean(node_attractiveness) + epsilon)\n    heuristic_matrix = inverse_distance * (node_attractiveness[:, None] * node_attractiveness[None, :])\n    temperature = np.mean(distance_matrix) / 2\n    randomness = np.random.normal(0, temperature, size=(n, n))\n    heuristic_matrix = heuristic_matrix + np.abs(randomness)\n\n    #Adaptive Sparsification\n    threshold = np.percentile(heuristic_matrix, 75)\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n    heuristic_matrix = (heuristic_matrix + heuristic_matrix.T)/2\n    heuristic_matrix = (heuristic_matrix - np.min(heuristic_matrix)) / (np.max(heuristic_matrix) - np.min(heuristic_matrix) + epsilon)\n    return heuristic_matrix\n\n[Heuristics 17th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 2.0,\n                  centrality_exponent: float = 1.0,\n                  sparsification_factor: float = 4.733362140013519,\n                  temperature_coefficient: float = 1.0) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, adaptive temperature, and dynamic range scaling.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Adaptive temperature based on distance distribution\n    temperature = np.median(distance_matrix) * temperature_coefficient\n\n    # Inverse distance calculation with self-loop avoidance\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n\n    # Node attractiveness based on inverse distance sum\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = node_attractiveness / np.mean(node_attractiveness)\n\n    # Node centrality based on inverse distance sum (normalized)\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n\n    # Edge attractiveness calculation, incorporating all factors\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality[i]**centrality_exponent + node_centrality[j]**centrality_exponent) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    # Dynamic range scaling and sparsification\n    max_heuristic = np.max(heuristics)\n    if max_heuristic > 0: # avoid division by zero\n        heuristics = heuristics / max_heuristic  # Scale to [0, 1]\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 18th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  attractiveness_exponent: float = 2.0,\n                  centrality_exponent: float = 1.0,\n                  sparsification_factor: float = 4.733362140013519,\n                  temperature_coefficient: float = 1.0) -> np.ndarray:\n    \"\"\"Enhanced heuristics using inverse distance, centrality, attractiveness, adaptive temperature, and dynamic range scaling.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Adaptive temperature based on distance distribution\n    temperature = np.median(distance_matrix) * temperature_coefficient\n\n    # Inverse distance calculation with self-loop avoidance\n    inverse_distance = 1.0 / (distance_matrix + np.eye(n))\n\n    # Node attractiveness based on inverse distance sum\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = node_attractiveness / np.mean(node_attractiveness)\n\n    # Node centrality based on inverse distance sum (normalized)\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality)\n\n    # Edge attractiveness calculation, incorporating all factors\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j]**attractiveness_exponent) * \\\n                                   (node_attractiveness[i] * node_attractiveness[j]) * \\\n                                   (node_centrality[i]**centrality_exponent + node_centrality[j]**centrality_exponent) * \\\n                                   np.exp(-distance_matrix[i, j] / temperature)\n\n    # Dynamic range scaling and sparsification\n    max_heuristic = np.max(heuristics)\n    if max_heuristic > 0: # avoid division by zero\n        heuristics = heuristics / max_heuristic  # Scale to [0, 1]\n    threshold = np.mean(heuristics) / sparsification_factor\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 19th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  distance_exponent: float = 2.0,\n                  centrality_exponent: float = 1.0,\n                  attractiveness_exponent: float = 1.5,\n                  sparsification_factor: float = 5.0,\n                  temperature_factor: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristics using distance, centrality, and attractiveness, with dynamic temperature and sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Normalize distance matrix\n    max_distance = np.max(distance_matrix[distance_matrix != np.inf])  # Avoid inf values\n    normalized_distance = distance_matrix / max_distance\n\n    # Inverse distance with exponent\n    inverse_distance = 1.0 / (normalized_distance + np.eye(n))\n    inverse_distance = np.power(inverse_distance, distance_exponent)\n\n    # Node attractiveness based on inverse distances\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = node_attractiveness / np.mean(node_attractiveness) # Normalize\n    node_attractiveness = np.power(node_attractiveness, attractiveness_exponent)\n\n    # Node centrality based on inverse distances\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality) # Normalize\n    node_centrality = np.power(node_centrality, centrality_exponent)\n\n    # Dynamic temperature based on median distance\n    temperature = np.median(distance_matrix) * temperature_factor\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j] *\n                                   node_attractiveness[i] * node_attractiveness[j] *\n                                   node_centrality[i] * node_centrality[j] *\n                                   np.exp(-distance_matrix[i, j] / temperature))\n\n    # Adaptive sparsification based on mean heuristic value\n    threshold = np.mean(heuristics[heuristics > 0]) / sparsification_factor  # ignore 0\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n[Heuristics 20th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray,\n                  distance_exponent: float = 2.0,\n                  centrality_exponent: float = 1.0,\n                  attractiveness_exponent: float = 1.5,\n                  sparsification_factor: float = 5.0,\n                  temperature_factor: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristics using distance, centrality, and attractiveness, with dynamic temperature and sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Normalize distance matrix\n    max_distance = np.max(distance_matrix[distance_matrix != np.inf])  # Avoid inf values\n    normalized_distance = distance_matrix / max_distance\n\n    # Inverse distance with exponent\n    inverse_distance = 1.0 / (normalized_distance + np.eye(n))\n    inverse_distance = np.power(inverse_distance, distance_exponent)\n\n    # Node attractiveness based on inverse distances\n    node_attractiveness = np.sum(inverse_distance, axis=0)\n    node_attractiveness = node_attractiveness / np.mean(node_attractiveness) # Normalize\n    node_attractiveness = np.power(node_attractiveness, attractiveness_exponent)\n\n    # Node centrality based on inverse distances\n    node_centrality = np.sum(inverse_distance, axis=1)\n    node_centrality = node_centrality / np.mean(node_centrality) # Normalize\n    node_centrality = np.power(node_centrality, centrality_exponent)\n\n    # Dynamic temperature based on median distance\n    temperature = np.median(distance_matrix) * temperature_factor\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristics[i, j] = (inverse_distance[i, j] *\n                                   node_attractiveness[i] * node_attractiveness[j] *\n                                   node_centrality[i] * node_centrality[j] *\n                                   np.exp(-distance_matrix[i, j] / temperature))\n\n    # Adaptive sparsification based on mean heuristic value\n    threshold = np.mean(heuristics[heuristics > 0]) / sparsification_factor  # ignore 0\n    heuristics[heuristics < threshold] = 0\n\n    return heuristics\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}