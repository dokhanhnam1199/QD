{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    item: float, \n    bins_remain_cap: np.ndarray, \n    sigmoid_steepness: float = 8.060154863007442, \n    max_cap_offset: float = 9.629999168879228e-06) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by combining normalized fit feasibility, dynamic sigmoid penalty, and adaptive item fit.\n    \"\"\"\n    ifbinsfit = (bins_remain_cap >= item).astype(float)  # Check if item fits in the bin\n    norm_remain_cap = (bins_remain_cap - np.min(bins_remain_cap)) / (np.max(bins_remain_cap) - np.min(bins_remain_cap) + max_cap_offset)\n    sigmoid_priority = 1 / (1 + np.exp(-sigmoid_steepness * (norm_remain_cap - (item / np.max(bins_remain_cap)))))  # Dynamic midpoint\n    penalty = (bins_remain_cap - item) / (np.max(bins_remain_cap) + max_cap_offset)  # Adaptive penalty\n    return ifbinsfit * sigmoid_priority / (penalty + max_cap_offset)  # Combine feasibility, sigmoid, and penalty\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines normalized fit feasibility with adaptive sigmoid penalties, integrating dynamic adjustments for fine-tuned decision-making.\n    \"\"\"\n    # Check if item fits into the bin\n    can_fit = (bins_remain_cap >= item).astype(float)\n    \n    # Normalize remaining capacity\n    norm_remain_cap = bins_remain_cap / (np.max(bins_remain_cap) + 1e-6)\n    \n    # Calculate adaptive midpoint and steepness\n    midpoint = item / (np.mean(bins_remain_cap) + 1e-6)\n    penalty_factor = 14.931397941541181 + 5 * (item / np.max(bins_remain_cap))\n    \n    # Calculate sigmoid penalty\n    sigmoid_penalty = 1 / (1 + np.exp(-penalty_factor * (norm_remain_cap - midpoint)))\n    \n    # Calculate priority score by combining feasibility and penalty\n    priority_score = can_fit * (1 - sigmoid_penalty)\n    \n    return priority_score\n\n### Analyze & experience\n- Comparing (best) Heuristics 1st vs (worst) Heuristics 20th, we see that the best version includes a more nuanced approach by using a sigmoid dynamic midpoint based on the item size and a penalty calculation that ensures stability; the worst version has less fine-grained control over the sigmoid parameters and less adaptive penalty handling. \n(Second best) Heuristics 2nd vs (second worst) Heuristics 19th, we see minor differences in parameters affecting the steepness and midpoint, but the best version remains more adaptable and robust to different item sizes and remaining capacities.\nComparing (1st) vs (2nd), we see a refinement in the midpoint calculation and improved handling of penalties, indicating that dynamic sigmoid calculations significantly enhance performance.\n(3rd) vs (4th) show identical logic, thus ranking equally; however, (3rd) still ranks above others due to adaptability in sigmoid steepness and midpoint.\nComparing (second worst) Heuristics 19th vs (worst) Heuristics 20th, the parameters differ slightly, but the fundamental adaptation mechanism and penalty calculation logic remains subpar in the worst version.\nOverall:\n- \n- **Keywords**: Normalization, adaptive sigmoid functions, dynamic parameters, bin selection, item characteristics.\n- **Advice**: Focus on adaptive dynamic parameter tuning based on item and bin characteristics, using normalization and adaptive sigmoid functions to fine-tune bin selection.\n- **Avoid**: Avoid incorporating space efficiency directly as a penalty or incorporating paradoxical adaptive factors that reduce heuristic efficiency.\n- **Explanation**: By dynamically adjusting parameters based on item and bin specifics, and using adaptive functions like sigmoids for sensitive tuning, the heuristic can better adapt to varying conditions and improve decision-making. Avoiding static penalties and paradoxical adaptability ensures the heuristic remains efficient and effective without unnecessary complexity.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}